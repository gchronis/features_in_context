{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Context evaluation of the best performing models.\n",
    "\n",
    "We now wish to evaluate each of our projection models at the token level. We construct an evaluation dataset from a set of homonyms from the McRae feature set. The dataset consists of tokens of homonymous words collected from the BNC, alongside gold feature data for disambiguated senses.\n",
    "\n",
    "We then train our models on the other words in the McRae dataset, using the parameter settings from the type level. We train \n",
    "\n",
    "4 layer ffnn (1k)\n",
    "4 layer ffnn (5k)\n",
    "4 layer ffnn (glove)\n",
    "plsr (1k)\n",
    "plsr (5k)\n",
    "plsr(glove)\n",
    "label propagation (1k)\n",
    "label propagation (5k)\n",
    "label propagation (glove)\n",
    "\n",
    "To evaluate a model, we use it to predict features in context for each token in the dataset. Then, we compare to the gold feature data. We also calculate the average distance between "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from bert import *\n",
    "from feature_data import *\n",
    "from multiprototype import *\n",
    "from models import *\n",
    "from utils import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to evaluate the model on its ability to predict features in context. First, we obtain gold vectors for both senses of 10 ambiguous words from the McRae et al. data\n",
    "\n",
    "TODO: Ensure that the models are not trained on this data. Maybe train on everything but these words?\n",
    "\n",
    "What are the words?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ambiguous_pairs = [\n",
    "    ('bat_animal', 'bat_baseball'),\n",
    "    ('board_wood', 'board_black'),\n",
    "    ('bow_ribbon', 'bow_weapon'),\n",
    "    ('cap_bottle', 'cap_hat'),\n",
    "    #('crane_machine', 'crane_animal')\n",
    "    ('hose', 'hose_leggings'),\n",
    "    ('mink', 'mink_coat'), # this one is not fully disambiguated\n",
    "    ('mouse', 'mouse_computer'),\n",
    "    ('pipe_smoking', 'pipe_plumbing'),\n",
    "    ('tank_army', 'tank_container')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bat_animal',\n",
       " 'bat_baseball',\n",
       " 'board_wood',\n",
       " 'board_black',\n",
       " 'bow_ribbon',\n",
       " 'bow_weapon',\n",
       " 'cap_bottle',\n",
       " 'cap_hat',\n",
       " 'hose',\n",
       " 'hose_leggings',\n",
       " 'mink',\n",
       " 'mink_coat',\n",
       " 'mouse',\n",
       " 'mouse_computer',\n",
       " 'pipe_smoking',\n",
       " 'pipe_plumbing',\n",
       " 'tank_army',\n",
       " 'tank_container']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[item for t in ambiguous_pairs for item in t]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "train an save best models\n",
    "\"\"\"\n",
    "from argparse import Namespace\n",
    "\n",
    "\"\"\"\n",
    "we dont need to do this if we've already got the model\n",
    "\"\"\"\n",
    "\n",
    "# # initialize model\n",
    "\n",
    "# # dummy command line options\n",
    "# args = Namespace(epochs=30, \n",
    "#                  lr=1e-3, \n",
    "#                  dropout=0.2, \n",
    "#                  layer = 8,\n",
    "#                  clusters = 5,\n",
    "#                  save_path= 'ffnn.30eps.5k.training4418.saved',\n",
    "#                  batch_size=1,\n",
    "#                  hidden_size = 300\n",
    "#                 )\n",
    "\n",
    "# # x data\n",
    "# feature_norms = BuchananFeatureNorms('data/buchanan/cue_feature_words.csv')\n",
    "# # y_hat data\n",
    "# layer = 8\n",
    "# clusters = 5\n",
    "# embedding_file = './data/multipro_embeddings/layer'+ str(args.layer) + 'clusters' + str(args.clusters) + '.txt'\n",
    "# embs = read_multiprototype_embeddings(embedding_file, layer=args.layer, num_clusters=args.clusters)\n",
    "\n",
    "\n",
    "\n",
    "# #train_words are all feature_norms except for the above words\n",
    "# #dev words are the above words\n",
    "# #test words are the above words\n",
    "# words = list(feature_norms.vocab.keys())\n",
    "# eval_words = [item for t in ambiguous_pairs for item in t]\n",
    "\n",
    "# print(\"Starting with %s words\" % len(words))\n",
    "# train_words = [i for i in words if i not in eval_words]\n",
    "# print(\"Ending up with %s training words\" % len(train_words))\n",
    "\n",
    "\n",
    "# train\n",
    "#multi_model = train_ffnn(train_words, eval_words, embs, feature_norms, args)\n",
    "# save\n",
    "#torch.save(model, args.save_path)\n",
    "# load\n",
    "multi_model = torch.load('ffnn.30eps.5k.training4418.saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "train a single prototype model\n",
    "\"\"\"\n",
    "# embs = read_multiprototype_embeddings(embedding_file, layer=args.layer, num_clusters=1)\n",
    "# single_model = train_ffnn(train_words, eval_words, embs, feature_norms, args)\n",
    "# torch.save(model, 'ffnn.30eps.1k.training4418.saved')\n",
    "single_model = torch.load('ffnn.30eps.1k.training4418.saved')\n",
    "\n",
    "\"\"\"\n",
    "train a glove model\n",
    "\"\"\"\n",
    "# embeddings_list = []\n",
    "# word_indexer = Indexer()\n",
    "# with open(\"data/glove.6B/glove.6B.300d.txt\", 'r') as f:\n",
    "#     for line in f:\n",
    "#         values = line.split()\n",
    "#         word = values[0]\n",
    "#         vector = np.asarray(values[1:], \"float32\")\n",
    "#         embeddings_list.append([vector])\n",
    "\n",
    "#         #print(embeddings_dict)\n",
    "#         #raise Exception(\"hfelfnl\")\n",
    "#         word_indexer.add_and_get_index(word)\n",
    "\n",
    "# embs = MultiProtoTypeEmbeddings(word_indexer, np.array(embeddings_list), 0, 1) # dummy layer, clusters = 1\n",
    "# glove_model = train_ffnn(train_words, eval_words, embs, feature_norms, args)\n",
    "# torch.save(model, 'ffnn.30eps.glove.training4418.saved')\n",
    "\n",
    "glove_model = torch.load('ffnn.30eps.glove.training4418.saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features for bat: {'animal': 6.779661017, 'cricket': 7.344632768, 'fly': 7.90960452, 'hit': 7.344632768, 'wood': 9.039548023}\n",
      "features for bat_baseball: {'ball': 60.0, 'heave': 16.66666667, 'hit': 96.66666667, 'long': 50.0, 'metal': 53.33333333, 'sport': 23.33333333, 'swing': 20.0, 'wood': 73.33333333}\n",
      "features for bat_animal: {'animal': 33.33333333, 'black': 53.33333333, 'blind': 33.33333333, 'cave': 46.66666667, 'down': 33.33333333, 'fang': 23.33333333, 'fly': 63.33333333, 'fur': 36.66666667, 'mammal': 23.33333333, 'navigate': 30.0, 'nocturnal': 63.33333333, 'radar': 30.0, 'scare': 20.0, 'screech': 26.66666667, 'sleep': 33.33333333, 'small': 20.0, 'vampire': 16.66666667, 'wing': 86.66666667}\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "take a look at the gold features for these words.\n",
    "\"\"\"\n",
    "norms = BuchananFeatureNorms('data/buchanan/cue_feature_words.csv')\n",
    "\n",
    "\n",
    "norms.print_features('bat')\n",
    "norms.print_features('bat_baseball')\n",
    "norms.print_features('bat_animal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to find examples of each sense and make predictions using the model for that word. We will score the predictions of each example and then average them. Here are 10 examples of bat_animal. Load these from the file we have created with these words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus.reader.wordnet import Lemma\n",
    "\n",
    "senses_to_analyze = {\n",
    "    'bat_animal': wn.lemma('bat.n.01.bat'),\n",
    "    'bat_baseball': wn.lemma('bat.n.05.bat'),\n",
    "    'board_wood': wn.lemma('board.n.02.board'),\n",
    "    'board_black': wn.lemma('blackboard.n.01.blackboard'),\n",
    "    'bow_ribbon': wn.lemma('bow.n.08.bow'),\n",
    "    'bow_weapon': wn.lemma('bow.n.04.bow'),\n",
    "    'cap_bottle': wn.lemma('cap.n.02.cap'),\n",
    "    'cap_hat': wn.lemma('cap.n.01.cap'),\n",
    "    #('crane_machine', 'crane_animal')\n",
    "    'hose': wn.lemma('hose.n.03.hose'),\n",
    "    'hose_leggings': wn.lemma('hose.n.01.hose'),\n",
    "    'mink': wn.lemma('mink.n.03.mink'),\n",
    "    'mink_coat': wn.lemma('mink.n.01.mink'), # # this one is not fully disambiguated\n",
    "    'mouse': wn.lemma('mouse.n.01.mouse'),\n",
    "    'mouse_computer': wn.lemma('mouse.n.04.mouse'),\n",
    "    'pipe_smoking':  wn.lemma('pipe.n.01.pipe'),\n",
    "    'pipe_plumbing': wn.lemma('pipe.n.02.pipe'),\n",
    "    'tank_army': wn.lemma('tank.n.01.tank'),\n",
    "    'tank_container': wn.lemma('tank.n.02.tank')\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# for k, v in senses_to_analyze.items():\n",
    "#     print(v.synset())\n",
    "#     print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found  Lemma('bat.n.01.bat')\n",
      "found  Lemma('bat.n.01.bat')\n",
      "Lemma('bat.n.01.bat')\n",
      "['Or the surging whirling sounds of bats at night , when their black bodies dived into the blackness above and below the amber street lights .', 'Out of the church and into his big car , it tooling over the road with him driving and the headlights sweeping the pike ahead and after he hit college , his expansiveness , the quaint little pine board tourist courts , cabins really , with a cute naked light bulb in the ceiling ( unfrosted and naked as a streetlight , like the one on the corner where you used to play when you were a kid , where you watched the bats swooping in after the bugs , watching in between your bouts at hopscotch ) , a room complete with moths pinging the light and the few casual cockroaches cruising the walls , an insect Highway Patrol with feelers waving .']\n",
      "Lemma('bat.n.05.bat')\n",
      "[]\n",
      "Lemma('mouse.n.04.mouse')\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import semcor\n",
    "from nltk.tree import Tree\n",
    "import itertools\n",
    "import random\n",
    "\n",
    "\n",
    "# todo check if there is hose in semcor\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def traverse_tree(tree):\n",
    "    # print(\"tree:\", tree)\n",
    "    for subtree in tree:\n",
    "        if type(subtree) == Tree:\n",
    "            print(subtree.label())\n",
    "            traverse_tree(subtree)\n",
    "\n",
    "\n",
    "def find_tokens(wn_lemma, sents):\n",
    "\n",
    "    #sents = random.shuffle(sents)\n",
    "    res = []\n",
    "    \n",
    "    for sent in sents:\n",
    "        save = False\n",
    "        sentence_string = []\n",
    "        #print(sent)\n",
    "        #for item in sent:\n",
    "            #print(item.word)\n",
    "        for chunk in sent:\n",
    "            sense = chunk.label()\n",
    "            #print(sense)\n",
    "            if isinstance(sense, str):\n",
    "                None\n",
    "            elif sense is None:\n",
    "                None\n",
    "            else:\n",
    "              #  print(sense.name())\n",
    "    #         sense = chunk.label\n",
    "    #         print(sense)\n",
    "    #         print(wordnet_sense)\n",
    "\n",
    "    #         #print(sense.type())\n",
    "                if sense.key() == wn_lemma.key():\n",
    "                    print(\"found \", sense)\n",
    "                    save = True\n",
    "            #print(\"leaves\")\n",
    "            #print(chunk.leaves())\n",
    "            sentence_string.append(chunk.leaves())\n",
    "\n",
    "        if save==True:\n",
    "            sentence_string = list(itertools.chain(*sentence_string))\n",
    "            sentence_string = ' '.join(sentence_string)\n",
    "            res.append(sentence_string)\n",
    "    \n",
    "    return res\n",
    "        \n",
    "sents = semcor.tagged_sents( tag = ' sem ' )\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "test function with three words\n",
    "\"\"\"\n",
    "wordnet_senses = [\n",
    "                #wn.lemma('produce.v.04.produce'),\n",
    "                 wn.lemma('bat.n.01.bat'),\n",
    "                 wn.lemma('bat.n.05.bat'),\n",
    "                 wn.lemma('mouse.n.04.mouse')\n",
    "                ]\n",
    "\n",
    "for sense in wordnet_senses:\n",
    "    contexts = find_tokens(sense, sents)\n",
    "    print(sense)\n",
    "    print(contexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bat_animal\n",
      "found  Lemma('bat.n.01.bat')\n",
      "found  Lemma('bat.n.01.bat')\n",
      "['Or the surging whirling sounds of bats at night , when their black bodies dived into the blackness above and below the amber street lights .', 'Out of the church and into his big car , it tooling over the road with him driving and the headlights sweeping the pike ahead and after he hit college , his expansiveness , the quaint little pine board tourist courts , cabins really , with a cute naked light bulb in the ceiling ( unfrosted and naked as a streetlight , like the one on the corner where you used to play when you were a kid , where you watched the bats swooping in after the bugs , watching in between your bouts at hopscotch ) , a room complete with moths pinging the light and the few casual cockroaches cruising the walls , an insect Highway Patrol with feelers waving .']\n",
      "bat_baseball\n",
      "[]\n",
      "board_wood\n",
      "found  Lemma('board.n.02.board')\n",
      "found  Lemma('board.n.02.board')\n",
      "found  Lemma('board.n.02.board')\n",
      "found  Lemma('board.n.02.board')\n",
      "found  Lemma('board.n.02.board')\n",
      "found  Lemma('board.n.02.board')\n",
      "found  Lemma('board.n.02.board')\n",
      "found  Lemma('board.n.02.board')\n",
      "found  Lemma('board.n.02.board')\n",
      "found  Lemma('board.n.02.board')\n",
      "found  Lemma('board.n.02.board')\n",
      "found  Lemma('board.n.02.board')\n",
      "found  Lemma('board.n.02.board')\n",
      "found  Lemma('board.n.02.board')\n",
      "found  Lemma('board.n.02.board')\n",
      "found  Lemma('board.n.02.board')\n",
      "[\"He just shot at the board and then drew circles around the holes to form a bull's-eye .\", 'Then I cover the sowing with a board .', 'When the first sprinkling of green appears I remove the board .', 'Standing in the shelter of the tent - a rejected hospital tent on which the rain now dripped , no longer drumming - Adam watched his own hands touch the objects on the improvised counter of boards laid across two beef barrels .', 'Beyond that misty gray of the rain , he saw the stretching hutment , low diminutive log cabins , chinked with mud , with doorways a man would have to crouch to get through , with roofs of tenting laid over boughs or boards from hardtack boxes , or fence rails , with cranky chimneys of sticks and dried mud .', 'Over the door was a board with large , inept lettering :', 'With enormous interest , Adam watched his hands as they touched and shifted the objects on the board directly before him .', \"Alley fences were made of solid boards higher than one 's head , but not so high as the golden glow in a corner or the hollyhocks that grew in a line against them .\", \"The first one or two roof boards ( marked `` E '' in fig. 6 ) are slipped into place across the roof beams , from outside the shelter .\", 'These boards are nailed to the roof beams by reaching up through the open space between the beams , from inside the shelter .', 'Concrete blocks are passed between the beams and put on the boards .', 'The last roof boards are covered with blocks from outside the shelter .', 'An alternate roof , perhaps more within do-it-yourself reach , could be constructed of heavy wooden roof beams , overlaid with boards and waterproofing .', 'Out of the church and into his big car , it tooling over the road with him driving and the headlights sweeping the pike ahead and after he hit college , his expansiveness , the quaint little pine board tourist courts , cabins really , with a cute naked light bulb in the ceiling ( unfrosted and naked as a streetlight , like the one on the corner where you used to play when you were a kid , where you watched the bats swooping in after the bugs , watching in between your bouts at hopscotch ) , a room complete with moths pinging the light and the few casual cockroaches cruising the walls , an insect Highway Patrol with feelers waving .', 'Mr. Mills had done some figuring on a scrap of paper and given him the various kinds of boards and two-by-fours which , properly handled , would , he had assured him , turn into a workbench .', 'Without further discussion he appeared the next morning with a pile of boards sticking over the end of his light truck and proceeded with the paneling , which he then stained and waxed according to his taste .']\n",
      "board_black\n",
      "found  Lemma('blackboard.n.01.blackboard')\n",
      "found  Lemma('blackboard.n.01.blackboard')\n",
      "['These errors were then collected and written on a blackboard , condensing similar ideas .', 'The manager sat behind the group so he could see and count the hands that went up , and the director wrote the numbers on the blackboard .']\n",
      "bow_ribbon\n",
      "[]\n",
      "bow_weapon\n",
      "found  Lemma('bow.n.04.bow')\n",
      "['To his left , the two skiffs dented their sharp bows into the soft bank .']\n",
      "cap_bottle\n",
      "found  Lemma('cap.n.02.cap')\n",
      "found  Lemma('cap.n.02.cap')\n",
      "[\"He said fussily , `` Just keep the cap on those strong emotions '' .\", 'Hans cut the foil off finally and unscrewed the cap .']\n",
      "cap_hat\n",
      "found  Lemma('cap.n.01.cap')\n",
      "found  Lemma('cap.n.01.cap')\n",
      "found  Lemma('cap.n.01.cap')\n",
      "['He , too , cocked his cap at a jaunty angle , jingled marbles in his pocket , and swaggered down Main Street .', \"He brushed back his black hair , shoving it under his pastor 's cap to keep it from blowing in his eyes .\", 'At 7 : 25 two hotel doormen came thumping down the steps , carrying a saw-horse to be set up as a barricade in front of the haberdashery store window next to the entranceway , and as I watched them in their gaudy red coats that nearly scraped the ground , their golden , fringed epaulets and spic , red visored caps , I suddenly saw just over their shoulders Jessica gracefully making her way through the crowd .']\n",
      "hose\n",
      "[]\n",
      "hose_leggings\n",
      "[]\n",
      "mink\n",
      "[]\n",
      "mink_coat\n",
      "[]\n",
      "mouse\n",
      "found  Lemma('mouse.n.01.mouse')\n",
      "found  Lemma('mouse.n.01.mouse')\n",
      "found  Lemma('mouse.n.01.mouse')\n",
      "found  Lemma('mouse.n.01.mouse')\n",
      "found  Lemma('mouse.n.01.mouse')\n",
      "found  Lemma('mouse.n.01.mouse')\n",
      "found  Lemma('mouse.n.01.mouse')\n",
      "found  Lemma('mouse.n.01.mouse')\n",
      "found  Lemma('mouse.n.01.mouse')\n",
      "found  Lemma('mouse.n.01.mouse')\n",
      "found  Lemma('mouse.n.01.mouse')\n",
      "found  Lemma('mouse.n.01.mouse')\n",
      "found  Lemma('mouse.n.01.mouse')\n",
      "found  Lemma('mouse.n.01.mouse')\n",
      "['In attempting to improve specificity of staining , the fluorescein labeled antisera used in both direct and indirect methods were treated in one of several ways : ( 1 ) They were passed through Dowex-2-chloride twice and treated with acetone insoluble powders ( Coons , 1958 ) prepared from mouse liver or from healthy sweet clover stems or crown gall tissue produced by Agrobacterium tumefaciens ( E. F. Smith + Townsend ) Conn , on sweet clover stems .', 'Two absorptions of * * f with ethyl acetate or two absorptions of * * f ( which had been passed through Dowex-2-chloride ) , NS and * * f with crown gall tissue powder , or mouse liver powder did not further improve the specificity of staining .', 'Treatment of the conjugates with ethyl acetate , and the conjugates ( which had been passed through Dowex-2-chloride ) with mouse liver powder , sweet clover crown gall tissue powder , or healthy sweet clover proteins did not satisfactorily remove nonspecifically staining substances in the conjugates .', 'In litters of eight mice from similar parents , the number of mice with straight instead of wavy hair is an integer from 0 to 8 .', \"In the examples above , the occurrence of a bull's-eye , a straight haired mouse , or an ace could be called a `` success '' .\", 'For the marksman , we study sets of five shots ( * * f ) ; for the mice , we restrict attention to litters of eight ( * * f ) ; and for the aces , we toss three dice ( * * f ) .', \"It is natural from the marksman 's viewpoint to call a bull's-eye a success , but in the mice example it is arbitrary which category corresponds to straight hair in a mouse .\", \"We classify mice as `` straight haired '' or `` wavy haired '' , but a hairless mouse appears .\", 'The debris of his other careers was piled everywhere ; a pile of wire cages for mice from his time as a geneticist and a microscope lying on its side on the window sill , vertical steel columns wired for support to the open ceiling beams with spidery steel cantilevers jutting out into the air , masonry constructions on the floor from the time he was inventing his disastrous fireplace whose smoke would pass through a whole house , visible all the way up through wire gratings on each floor .', \"`` Such as ' sending the cat to guard the mice ' , or ' the falcon to protect the dove ' , or most terribly sharp of all , ' the human being to save humanity '' ' .\", 'After heavy rains and an onslaught of mice , snow fell on October 15 , 1825 , and remained on the ground through a winter so cold that the ice on the Red was five feet thick .']\n",
      "mouse_computer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "pipe_smoking\n",
      "found  Lemma('pipe.n.01.pipe')\n",
      "found  Lemma('pipe.n.01.pipe')\n",
      "found  Lemma('pipe.n.01.pipe')\n",
      "found  Lemma('pipe.n.01.pipe')\n",
      "['He finished with the team and filled his pipe and stood looking about him .', 'He would order her to bring coffee , and would take from his vest pocket a thin black pipe which he would stuff - he would not remove his gloves - and light and smoke .', \"`` Laura , what would you say if I smoked a pipe '' ?\", 'And as for his pipe , if he wanted to smoke one , nobody would stop him .']\n",
      "pipe_plumbing\n",
      "found  Lemma('pipe.n.02.pipe')\n",
      "found  Lemma('pipe.n.02.pipe')\n",
      "found  Lemma('pipe.n.02.pipe')\n",
      "found  Lemma('pipe.n.02.pipe')\n",
      "['The effluent was collected through two pipes and discharged to the Blue River through a surface drainage ditch .', 'It consists of a series of pipes and a pressure measuring chamber which record the rise and fall of the water surface .', 'Vent pipes also are necessary ( as shown in figs. 9 , 10 , and 11 ) , but filters are not .', 'She could not count the times Herman had rapped on the door , just a couple of bangs that shook the whole damned closet and might , someday , break away the pipe connections from the wall .']\n",
      "tank_army\n",
      "found  Lemma('tank.n.01.tank')\n",
      "found  Lemma('tank.n.01.tank')\n",
      "found  Lemma('tank.n.01.tank')\n",
      "found  Lemma('tank.n.01.tank')\n",
      "found  Lemma('tank.n.01.tank')\n",
      "found  Lemma('tank.n.01.tank')\n",
      "found  Lemma('tank.n.01.tank')\n",
      "['Tanks lined up at the border will be no more helpful .', 'Somehow , the pictures and stories of Soviet T-34 tanks on Cuban beaches and Russian Mig jet fighters strafing rebel troops has brought home to all of us the stark , blunt truth of what it means to have a Russian military base 90 miles away from home .', 'Russian tanks and planes in Cuba jeopardize the security of the United States , violate the Monroe Doctrine , and threaten the security of every other Latin American republic .', 'But it took the pictures of the Migs and the T-34 tanks to do the job .', 'Primary target would be shipments of tanks , guns , aviation gasoline and ammunition coming from Russia and Czechoslovakia .', 'The decreases , which are largely in construction and in aircraft procurement , are offset in part by increases for research and development and for procurement of other military equipment such as tanks , vehicles , guns , and electronic devices .', 'Once Todman thought he had spotted a tank and went down to investigate while Greg covered him .']\n",
      "tank_container\n",
      "found  Lemma('tank.n.02.tank')\n",
      "found  Lemma('tank.n.02.tank')\n",
      "found  Lemma('tank.n.02.tank')\n",
      "[\"There are some sharp and whipping lines and some hilariously funny situations - the best of the latter being a mass impromptu plunge into a nightclub tank where a `` mermaid '' is performing .\", 'Matheson highest purity tank chlorine was passed through a tube of resublimed * * f into an evacuated Pyrex system where it was condensed with liquid air .', 'The raw sewage was introduced directly under the turbine aerator to insure maximum mixing of the raw sewage with the aeration tank contents .']\n"
     ]
    }
   ],
   "source": [
    "### We really want to ensure these models are trained on everyhing but our eval words\n",
    "\n",
    "\n",
    "# gold vectors, multiple sentences per word\n",
    "\"\"\"\n",
    "we want to take each feature cue / wordnet lemma pair and get the feature norm for the pair, \n",
    "as well as the sentences from semcor with that lemma\n",
    "\n",
    "and just put them in a list of tuples\n",
    "\"\"\"\n",
    "data = []\n",
    "\n",
    "# cue_words = []\n",
    "# for w1, w2 in ambiguous_pairs:\n",
    "#     cue_words.append(w1)\n",
    "#     cue_words.append(w1)\n",
    "# print(cue_words)\n",
    "\n",
    "for cue_word, lemma in senses_to_analyze.items():\n",
    "    print(cue_word)\n",
    "    gold_vector = norms.get_feature_vector(cue_word)\n",
    "    \n",
    "    contexts = find_tokens(lemma, sents)\n",
    "    print(contexts)\n",
    "    \n",
    "    for context in contexts:\n",
    "        row = (cue_word, lemma, context)\n",
    "        data.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "save contexts to file\n",
    "\"\"\"\n",
    "with open('bnc_contexts_for_mcrae_homonyms.csv','w') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(['cue_word', 'lemma', 'context'])\n",
    "    for cue, lemma, context in data:                \n",
    "        writer.writerow([cue, lemma, context])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Models\n",
    "\n",
    "We train a 4 layer FFNN to predict the real-valued features of each word, using buchanan (2019) feature norms as training data. We exclude only the above words, and train on all the rest. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-2449ae6b8608>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data/glove.6B/glove.6B.300d.txt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mvector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"float32\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# first prepare embeddings\n",
    "\n",
    "# glove embeddings\n",
    "glove_embeddings_list = []\n",
    "glove_indexer = Indexer()\n",
    "with open(\"data/glove.6B/glove.6B.300d.txt\", 'r') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        vector = np.asarray(values[1:], \"float32\")\n",
    "        glove_embeddings_list.append([vector])\n",
    "\n",
    "        #print(embeddings_dict)\n",
    "        #raise Exception(\"hfelfnl\")\n",
    "        glove_indexer.add_and_get_index(word)\n",
    "glove_embs = MultiProtoTypeEmbeddings(glove_word_indexer, np.array(glove_embeddings_list), 0, 1) # dummy layer, clusters = 1\n",
    "\n",
    "# multipro embeddings\n",
    "multipro_embs = read_multiprototype_embeddings(embedding_file, layer=args.layer, num_clusters=5)\n",
    "\n",
    "\n",
    "# single pro embeddings\n",
    "singlepro_embs = read_multiprototype_embeddings(embedding_file, layer=args.layer, num_clusters=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# then gather the data\n",
    "\n",
    "feature_norms = BuchananFeatureNorms('data/buchanan/cue_feature_words.csv')\n",
    "\n",
    "\n",
    "#train_words are all feature_norms except for the above words\n",
    "#dev words are the above words\n",
    "#test words are the above words\n",
    "words = list(feature_norms.vocab.keys())\n",
    "eval_words = [item for t in ambiguous_pairs for item in t]\n",
    "\n",
    "print(\"Starting with %s words\" % len(words))\n",
    "train_words = [i for i in words if i not in eval_words]\n",
    "print(\"Ending up with %s training words\" % len(train_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "train ffnn models\n",
    "\"\"\"\n",
    "single_model = train_ffnn(train_words, eval_words, embs, feature_norms, args)\n",
    "torch.save(model, 'ffnn.30eps.1k.training4418.saved')\n",
    "\n",
    "\"\"\"\n",
    "train a glove model\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# glove_model = train_ffnn(train_words, eval_words, embs, feature_norms, args)\n",
    "# torch.save(model, 'ffnn.30eps.glove.training4418.saved')\n",
    "\n",
    "glove_model = torch.load('ffnn.30eps.glove.training4418.saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "models and save paths\n",
    "\n",
    "\"\"\"\n",
    "models = [\n",
    "    'trained_models/model.plsr.buchanan.allbuthomoyms.5k.300components.500max_iters',\n",
    "    'trained_models/model.plsr.buchanan.allbuthomoyms.1k.300components.500max_iters',\n",
    "    #'trained_models/model.plsr.buchanan.allbuthomoyms.glove.300components.300max_iters',\n",
    "    'trained_models/model.ffnn.buchanan.allbuthomoyms.5k.50epochs.0.5dropout.lr1e-4.hsize300',\n",
    "    'trained_models/model.ffnn.buchanan.allbuthomoyms.1k.50epochs.0.5dropout.lr1e-4.hsize300',\n",
    "    #'trained_models/model.ffnn.buchanan.allbuthomoyms.glove.50epochs.0.5dropout.lr1e-4.hsize300',\n",
    "    'trained_models/model.modabs.buchanan.allbuthomoyms.5k',\n",
    "    'trained_models/model.modabs.buchanan.allbuthomoyms.1k',\n",
    "    #'trained_models/model.modabs.buchanan.allbuthomoyms.glove'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the models on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cue_word</th>\n",
       "      <th>lemma</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bat_animal</td>\n",
       "      <td>Lemma('bat.n.01.bat')</td>\n",
       "      <td>Or the surging whirling sounds of bats at nigh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bat_animal</td>\n",
       "      <td>Lemma('bat.n.01.bat')</td>\n",
       "      <td>Out of the church and into his big car , it to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>board_wood</td>\n",
       "      <td>Lemma('board.n.02.board')</td>\n",
       "      <td>He just shot at the board and then drew circle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>board_wood</td>\n",
       "      <td>Lemma('board.n.02.board')</td>\n",
       "      <td>Then I cover the sowing with a board .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>board_wood</td>\n",
       "      <td>Lemma('board.n.02.board')</td>\n",
       "      <td>When the first sprinkling of green appears I r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>board_wood</td>\n",
       "      <td>Lemma('board.n.02.board')</td>\n",
       "      <td>Standing in the shelter of the tent - a reject...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>board_wood</td>\n",
       "      <td>Lemma('board.n.02.board')</td>\n",
       "      <td>Beyond that misty gray of the rain , he saw th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>board_wood</td>\n",
       "      <td>Lemma('board.n.02.board')</td>\n",
       "      <td>Over the door was a board with large , inept l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>board_wood</td>\n",
       "      <td>Lemma('board.n.02.board')</td>\n",
       "      <td>With enormous interest , Adam watched his hand...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>board_wood</td>\n",
       "      <td>Lemma('board.n.02.board')</td>\n",
       "      <td>Alley fences were made of solid boards higher ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>board_wood</td>\n",
       "      <td>Lemma('board.n.02.board')</td>\n",
       "      <td>The first one or two roof boards ( marked `` E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>board_wood</td>\n",
       "      <td>Lemma('board.n.02.board')</td>\n",
       "      <td>These boards are nailed to the roof beams by r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>board_wood</td>\n",
       "      <td>Lemma('board.n.02.board')</td>\n",
       "      <td>Concrete blocks are passed between the beams a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>board_wood</td>\n",
       "      <td>Lemma('board.n.02.board')</td>\n",
       "      <td>The last roof boards are covered with blocks f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>board_wood</td>\n",
       "      <td>Lemma('board.n.02.board')</td>\n",
       "      <td>An alternate roof , perhaps more within do-it-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>board_wood</td>\n",
       "      <td>Lemma('board.n.02.board')</td>\n",
       "      <td>Out of the church and into his big car , it to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>board_wood</td>\n",
       "      <td>Lemma('board.n.02.board')</td>\n",
       "      <td>Mr. Mills had done some figuring on a scrap of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>board_wood</td>\n",
       "      <td>Lemma('board.n.02.board')</td>\n",
       "      <td>Without further discussion he appeared the nex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>board_black</td>\n",
       "      <td>Lemma('blackboard.n.01.blackboard')</td>\n",
       "      <td>These errors were then collected and written o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>board_black</td>\n",
       "      <td>Lemma('blackboard.n.01.blackboard')</td>\n",
       "      <td>The manager sat behind the group so he could s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>bow_weapon</td>\n",
       "      <td>Lemma('bow.n.04.bow')</td>\n",
       "      <td>To his left , the two skiffs dented their shar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>cap_bottle</td>\n",
       "      <td>Lemma('cap.n.02.cap')</td>\n",
       "      <td>He said fussily , `` Just keep the cap on thos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>cap_bottle</td>\n",
       "      <td>Lemma('cap.n.02.cap')</td>\n",
       "      <td>Hans cut the foil off finally and unscrewed th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>cap_hat</td>\n",
       "      <td>Lemma('cap.n.01.cap')</td>\n",
       "      <td>He , too , cocked his cap at a jaunty angle , ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>cap_hat</td>\n",
       "      <td>Lemma('cap.n.01.cap')</td>\n",
       "      <td>He brushed back his black hair , shoving it un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>cap_hat</td>\n",
       "      <td>Lemma('cap.n.01.cap')</td>\n",
       "      <td>At 7 : 25 two hotel doormen came thumping down...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>mouse</td>\n",
       "      <td>Lemma('mouse.n.01.mouse')</td>\n",
       "      <td>In attempting to improve specificity of staini...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>mouse</td>\n",
       "      <td>Lemma('mouse.n.01.mouse')</td>\n",
       "      <td>Two absorptions of * * f with ethyl acetate or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>mouse</td>\n",
       "      <td>Lemma('mouse.n.01.mouse')</td>\n",
       "      <td>Treatment of the conjugates with ethyl acetate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>mouse</td>\n",
       "      <td>Lemma('mouse.n.01.mouse')</td>\n",
       "      <td>In litters of eight mice from similar parents ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>mouse</td>\n",
       "      <td>Lemma('mouse.n.01.mouse')</td>\n",
       "      <td>In the examples above , the occurrence of a bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>mouse</td>\n",
       "      <td>Lemma('mouse.n.01.mouse')</td>\n",
       "      <td>For the marksman , we study sets of five shots...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>mouse</td>\n",
       "      <td>Lemma('mouse.n.01.mouse')</td>\n",
       "      <td>It is natural from the marksman 's viewpoint t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>mouse</td>\n",
       "      <td>Lemma('mouse.n.01.mouse')</td>\n",
       "      <td>We classify mice as `` straight haired '' or `...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>mouse</td>\n",
       "      <td>Lemma('mouse.n.01.mouse')</td>\n",
       "      <td>The debris of his other careers was piled ever...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>mouse</td>\n",
       "      <td>Lemma('mouse.n.01.mouse')</td>\n",
       "      <td>`` Such as ' sending the cat to guard the mice...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>mouse</td>\n",
       "      <td>Lemma('mouse.n.01.mouse')</td>\n",
       "      <td>After heavy rains and an onslaught of mice , s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>pipe_smoking</td>\n",
       "      <td>Lemma('pipe.n.01.pipe')</td>\n",
       "      <td>He finished with the team and filled his pipe ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>pipe_smoking</td>\n",
       "      <td>Lemma('pipe.n.01.pipe')</td>\n",
       "      <td>He would order her to bring coffee , and would...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>pipe_smoking</td>\n",
       "      <td>Lemma('pipe.n.01.pipe')</td>\n",
       "      <td>`` Laura , what would you say if I smoked a pi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>pipe_smoking</td>\n",
       "      <td>Lemma('pipe.n.01.pipe')</td>\n",
       "      <td>And as for his pipe , if he wanted to smoke on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>pipe_plumbing</td>\n",
       "      <td>Lemma('pipe.n.02.pipe')</td>\n",
       "      <td>The effluent was collected through two pipes a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>pipe_plumbing</td>\n",
       "      <td>Lemma('pipe.n.02.pipe')</td>\n",
       "      <td>It consists of a series of pipes and a pressur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>pipe_plumbing</td>\n",
       "      <td>Lemma('pipe.n.02.pipe')</td>\n",
       "      <td>Vent pipes also are necessary ( as shown in fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>pipe_plumbing</td>\n",
       "      <td>Lemma('pipe.n.02.pipe')</td>\n",
       "      <td>She could not count the times Herman had rappe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>tank_army</td>\n",
       "      <td>Lemma('tank.n.01.tank')</td>\n",
       "      <td>Tanks lined up at the border will be no more h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>tank_army</td>\n",
       "      <td>Lemma('tank.n.01.tank')</td>\n",
       "      <td>Somehow , the pictures and stories of Soviet T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>tank_army</td>\n",
       "      <td>Lemma('tank.n.01.tank')</td>\n",
       "      <td>Russian tanks and planes in Cuba jeopardize th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>tank_army</td>\n",
       "      <td>Lemma('tank.n.01.tank')</td>\n",
       "      <td>But it took the pictures of the Migs and the T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>tank_army</td>\n",
       "      <td>Lemma('tank.n.01.tank')</td>\n",
       "      <td>Primary target would be shipments of tanks , g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>tank_army</td>\n",
       "      <td>Lemma('tank.n.01.tank')</td>\n",
       "      <td>The decreases , which are largely in construct...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>tank_army</td>\n",
       "      <td>Lemma('tank.n.01.tank')</td>\n",
       "      <td>Once Todman thought he had spotted a tank and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>tank_container</td>\n",
       "      <td>Lemma('tank.n.02.tank')</td>\n",
       "      <td>There are some sharp and whipping lines and so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>tank_container</td>\n",
       "      <td>Lemma('tank.n.02.tank')</td>\n",
       "      <td>Matheson highest purity tank chlorine was pass...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>tank_container</td>\n",
       "      <td>Lemma('tank.n.02.tank')</td>\n",
       "      <td>The raw sewage was introduced directly under t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          cue_word                                lemma  \\\n",
       "0       bat_animal                Lemma('bat.n.01.bat')   \n",
       "1       bat_animal                Lemma('bat.n.01.bat')   \n",
       "2       board_wood            Lemma('board.n.02.board')   \n",
       "3       board_wood            Lemma('board.n.02.board')   \n",
       "4       board_wood            Lemma('board.n.02.board')   \n",
       "5       board_wood            Lemma('board.n.02.board')   \n",
       "6       board_wood            Lemma('board.n.02.board')   \n",
       "7       board_wood            Lemma('board.n.02.board')   \n",
       "8       board_wood            Lemma('board.n.02.board')   \n",
       "9       board_wood            Lemma('board.n.02.board')   \n",
       "10      board_wood            Lemma('board.n.02.board')   \n",
       "11      board_wood            Lemma('board.n.02.board')   \n",
       "12      board_wood            Lemma('board.n.02.board')   \n",
       "13      board_wood            Lemma('board.n.02.board')   \n",
       "14      board_wood            Lemma('board.n.02.board')   \n",
       "15      board_wood            Lemma('board.n.02.board')   \n",
       "16      board_wood            Lemma('board.n.02.board')   \n",
       "17      board_wood            Lemma('board.n.02.board')   \n",
       "18     board_black  Lemma('blackboard.n.01.blackboard')   \n",
       "19     board_black  Lemma('blackboard.n.01.blackboard')   \n",
       "20      bow_weapon                Lemma('bow.n.04.bow')   \n",
       "21      cap_bottle                Lemma('cap.n.02.cap')   \n",
       "22      cap_bottle                Lemma('cap.n.02.cap')   \n",
       "23         cap_hat                Lemma('cap.n.01.cap')   \n",
       "24         cap_hat                Lemma('cap.n.01.cap')   \n",
       "25         cap_hat                Lemma('cap.n.01.cap')   \n",
       "26           mouse            Lemma('mouse.n.01.mouse')   \n",
       "27           mouse            Lemma('mouse.n.01.mouse')   \n",
       "28           mouse            Lemma('mouse.n.01.mouse')   \n",
       "29           mouse            Lemma('mouse.n.01.mouse')   \n",
       "30           mouse            Lemma('mouse.n.01.mouse')   \n",
       "31           mouse            Lemma('mouse.n.01.mouse')   \n",
       "32           mouse            Lemma('mouse.n.01.mouse')   \n",
       "33           mouse            Lemma('mouse.n.01.mouse')   \n",
       "34           mouse            Lemma('mouse.n.01.mouse')   \n",
       "35           mouse            Lemma('mouse.n.01.mouse')   \n",
       "36           mouse            Lemma('mouse.n.01.mouse')   \n",
       "37    pipe_smoking              Lemma('pipe.n.01.pipe')   \n",
       "38    pipe_smoking              Lemma('pipe.n.01.pipe')   \n",
       "39    pipe_smoking              Lemma('pipe.n.01.pipe')   \n",
       "40    pipe_smoking              Lemma('pipe.n.01.pipe')   \n",
       "41   pipe_plumbing              Lemma('pipe.n.02.pipe')   \n",
       "42   pipe_plumbing              Lemma('pipe.n.02.pipe')   \n",
       "43   pipe_plumbing              Lemma('pipe.n.02.pipe')   \n",
       "44   pipe_plumbing              Lemma('pipe.n.02.pipe')   \n",
       "45       tank_army              Lemma('tank.n.01.tank')   \n",
       "46       tank_army              Lemma('tank.n.01.tank')   \n",
       "47       tank_army              Lemma('tank.n.01.tank')   \n",
       "48       tank_army              Lemma('tank.n.01.tank')   \n",
       "49       tank_army              Lemma('tank.n.01.tank')   \n",
       "50       tank_army              Lemma('tank.n.01.tank')   \n",
       "51       tank_army              Lemma('tank.n.01.tank')   \n",
       "52  tank_container              Lemma('tank.n.02.tank')   \n",
       "53  tank_container              Lemma('tank.n.02.tank')   \n",
       "54  tank_container              Lemma('tank.n.02.tank')   \n",
       "\n",
       "                                              context  \n",
       "0   Or the surging whirling sounds of bats at nigh...  \n",
       "1   Out of the church and into his big car , it to...  \n",
       "2   He just shot at the board and then drew circle...  \n",
       "3              Then I cover the sowing with a board .  \n",
       "4   When the first sprinkling of green appears I r...  \n",
       "5   Standing in the shelter of the tent - a reject...  \n",
       "6   Beyond that misty gray of the rain , he saw th...  \n",
       "7   Over the door was a board with large , inept l...  \n",
       "8   With enormous interest , Adam watched his hand...  \n",
       "9   Alley fences were made of solid boards higher ...  \n",
       "10  The first one or two roof boards ( marked `` E...  \n",
       "11  These boards are nailed to the roof beams by r...  \n",
       "12  Concrete blocks are passed between the beams a...  \n",
       "13  The last roof boards are covered with blocks f...  \n",
       "14  An alternate roof , perhaps more within do-it-...  \n",
       "15  Out of the church and into his big car , it to...  \n",
       "16  Mr. Mills had done some figuring on a scrap of...  \n",
       "17  Without further discussion he appeared the nex...  \n",
       "18  These errors were then collected and written o...  \n",
       "19  The manager sat behind the group so he could s...  \n",
       "20  To his left , the two skiffs dented their shar...  \n",
       "21  He said fussily , `` Just keep the cap on thos...  \n",
       "22  Hans cut the foil off finally and unscrewed th...  \n",
       "23  He , too , cocked his cap at a jaunty angle , ...  \n",
       "24  He brushed back his black hair , shoving it un...  \n",
       "25  At 7 : 25 two hotel doormen came thumping down...  \n",
       "26  In attempting to improve specificity of staini...  \n",
       "27  Two absorptions of * * f with ethyl acetate or...  \n",
       "28  Treatment of the conjugates with ethyl acetate...  \n",
       "29  In litters of eight mice from similar parents ...  \n",
       "30  In the examples above , the occurrence of a bu...  \n",
       "31  For the marksman , we study sets of five shots...  \n",
       "32  It is natural from the marksman 's viewpoint t...  \n",
       "33  We classify mice as `` straight haired '' or `...  \n",
       "34  The debris of his other careers was piled ever...  \n",
       "35  `` Such as ' sending the cat to guard the mice...  \n",
       "36  After heavy rains and an onslaught of mice , s...  \n",
       "37  He finished with the team and filled his pipe ...  \n",
       "38  He would order her to bring coffee , and would...  \n",
       "39  `` Laura , what would you say if I smoked a pi...  \n",
       "40  And as for his pipe , if he wanted to smoke on...  \n",
       "41  The effluent was collected through two pipes a...  \n",
       "42  It consists of a series of pipes and a pressur...  \n",
       "43  Vent pipes also are necessary ( as shown in fi...  \n",
       "44  She could not count the times Herman had rappe...  \n",
       "45  Tanks lined up at the border will be no more h...  \n",
       "46  Somehow , the pictures and stories of Soviet T...  \n",
       "47  Russian tanks and planes in Cuba jeopardize th...  \n",
       "48  But it took the pictures of the Migs and the T...  \n",
       "49  Primary target would be shipments of tanks , g...  \n",
       "50  The decreases , which are largely in construct...  \n",
       "51  Once Todman thought he had spotted a tank and ...  \n",
       "52  There are some sharp and whipping lines and so...  \n",
       "53  Matheson highest purity tank chlorine was pass...  \n",
       "54  The raw sewage was introduced directly under t...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('bnc_contexts_for_mcrae_homonyms.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tank.n.02.tank'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string = \"Synset('tank.n.02.tank')\"\n",
    "re.findall(r\"'(.*?)'\", string)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "\"\"\"\n",
    "data is a list of tuples of (cue word, lemma, context)\n",
    "\n",
    "for each model, we want to run an analysis of these\n",
    "\"\"\"\n",
    "\n",
    "def pluralize(string):\n",
    "    if string == 'mouse':\n",
    "        return 'mice'\n",
    "    else:\n",
    "        return string + 's'\n",
    "\n",
    "\n",
    "\n",
    "def evaluate_in_context(model, df, bert, norms):\n",
    "    n = 0\n",
    "\n",
    "    correlations = []\n",
    "    cosines = []\n",
    "    top_k_precs = []\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        cue_word = row.cue_word        \n",
    "        lemma = re.findall(r\"'(.*?)'\", row.lemma)[0]\n",
    "        lemma = wn.lemma(lemma)\n",
    "        context = row.context\n",
    "        \n",
    "        n +=1\n",
    "        singular = lemma.name()\n",
    "        plural = pluralize(singular)\n",
    "\n",
    "        gold_vector = norms.get_feature_vector(singular)\n",
    "        gold_feats = norms.get_features(singular)\n",
    "        k = len(gold_feats)\n",
    "\n",
    "\n",
    "\n",
    "        try:\n",
    "            predicted_vector = model.predict_in_context(singular, context, bert)\n",
    "            top_k =  model.predict_top_n_features_in_context(singular, context, k, bert)\n",
    "        except:\n",
    "            predicted_vector = model.predict_in_context(plural, context, bert)\n",
    "            top_k =  model.predict_top_n_features_in_context(plural, context, k, bert)\n",
    "\n",
    "        cos = 1 - cosine(predicted_vector, gold_vector)\n",
    "        cosines.append(cos)      \n",
    "\n",
    "        num_in_top_k = len(set(top_k).intersection(set(gold_feats)))\n",
    "        top_k_prec = num_in_top_k / k\n",
    "        top_k_precs.append(top_k_prec)\n",
    "\n",
    "        corr, p = spearmanr(predicted_vector, gold_vector)\n",
    "        correlations.append(corr)\n",
    "\n",
    "        #print(\"cosine: %f\" % cos)\n",
    "        #print(\"precison: %f\" % prec)\n",
    "        #print(\"correlation: %f\" % corr)\n",
    "        #print(\"top k acc: %f\" % top_k_prec)\n",
    "\n",
    "    print(\"Average cosine between gold and predicted feature norms: %s\" % np.average(cosines))\n",
    "    #print(\"average Percentage (%) of gold gold-standard features retrieved in the top 10 features of the predicted vector: \", top_10_prec)\n",
    "    #print(\"average Percentage (%) of gold gold-standard features retrieved in the top 20 features of the predicted vector: \", top_20_prec)\n",
    "    print(\"Average % @k (derby metric)\", np.average(top_k_precs))\n",
    "    #print(\"Percentage (%) of test items that retrieve their gold-standard vector in the top 10 neighbours of their predicted vector: %f\" % top_20_acc)\n",
    "    print(\"correlation between gold and predicted vectors: %s \" % np.average(correlations))\n",
    "\n",
    "    print(\"total number of predictions: \", n)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_pretrained_bert.modeling:loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /Users/gabriellachronis/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n",
      "INFO:pytorch_pretrained_bert.modeling:extracting archive file /Users/gabriellachronis/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /var/folders/9m/vzvx58rs51v_x5nm620fz4xr0000gn/T/tmppk6uvtf0\n",
      "INFO:pytorch_pretrained_bert.modeling:Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "INFO:pytorch_pretrained_bert.tokenization:loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /Users/gabriellachronis/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n"
     ]
    }
   ],
   "source": [
    "bert = BERTBase()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************\n",
      "*** Evaluating trained_models/model.plsr.buchanan.allbuthomoyms.5k.300components.500max_iters model ***\n",
      "****************************************\n",
      "Average cosine between gold and predicted feature norms: 0.35884764922915174\n",
      "Average % @k (derby metric) 0.37267609651330585\n",
      "correlation between gold and predicted vectors: 0.08174618006523028 \n",
      "total number of predictions:  55\n",
      "****************************************\n",
      "*** Evaluating trained_models/model.plsr.buchanan.allbuthomoyms.1k.300components.500max_iters model ***\n",
      "****************************************\n",
      "Average cosine between gold and predicted feature norms: 0.32875389037802444\n",
      "Average % @k (derby metric) 0.3507248565388101\n",
      "correlation between gold and predicted vectors: 0.07935979478438276 \n",
      "total number of predictions:  55\n",
      "****************************************\n",
      "*** Evaluating trained_models/model.plsr.buchanan.allbuthomoyms.glove.300components.300max_iters model ***\n",
      "****************************************\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (1,768) (300,) (1,768) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-494935abd315>\u001b[0m in \u001b[0;36mevaluate_in_context\u001b[0;34m(model, df, bert, norms)\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mpredicted_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_in_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msingular\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m             \u001b[0mtop_k\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_top_n_features_in_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msingular\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/src/features_in_context/plsr.py\u001b[0m in \u001b[0;36mpredict_in_context\u001b[0;34m(self, word, sentence, bert)\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;31m# generate bert vector for word\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0mvec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbert\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_bert_vectors_for\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0;31m# get the layer we care about\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/src/features_in_context/bert.py\u001b[0m in \u001b[0;36mget_bert_vectors_for\u001b[0;34m(self, word, text)\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0;31m# TODO should be the matching slice, because this doesnt account for repeat word  pieces\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                 \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenized_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_piece\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m                 \u001b[0mtoken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtoken_embeddings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: 'bat' is not in list",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-cbafd1cb4be4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mevaluate_in_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbert\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_norms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-56-494935abd315>\u001b[0m in \u001b[0;36mevaluate_in_context\u001b[0;34m(model, df, bert, norms)\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0mtop_k\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_top_n_features_in_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msingular\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m             \u001b[0mpredicted_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_in_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplural\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m             \u001b[0mtop_k\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_top_n_features_in_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplural\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/src/features_in_context/plsr.py\u001b[0m in \u001b[0;36mpredict_in_context\u001b[0;34m(self, word, sentence, bert)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m         \u001b[0;31m#print(\"after prediction\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;31m#print(vec.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/sklearn/cross_decomposition/_pls.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, copy)\u001b[0m\n\u001b[1;32m    495\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0;31m# Normalize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 497\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_mean_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    498\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_std_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m         \u001b[0mYpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (1,768) (300,) (1,768) "
     ]
    }
   ],
   "source": [
    "feature_norms = BuchananFeatureNorms('data/buchanan/cue_feature_words.csv')\n",
    "\n",
    "\n",
    "for save_path in models:\n",
    "    print(\"****************************************\")\n",
    "    print(\"*** Evaluating %s model ***\" % save_path)\n",
    "    print(\"****************************************\")\n",
    "    model = torch.load(save_path)\n",
    "\n",
    "    evaluate_in_context(model, df, bert, feature_norms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_pretrained_bert.modeling:loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /Users/gabriellachronis/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n",
      "INFO:pytorch_pretrained_bert.modeling:extracting archive file /Users/gabriellachronis/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /var/folders/9m/vzvx58rs51v_x5nm620fz4xr0000gn/T/tmpxb3i2j_3\n",
      "INFO:pytorch_pretrained_bert.modeling:Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "INFO:pytorch_pretrained_bert.tokenization:loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /Users/gabriellachronis/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************\n",
      "*** Evaluating multi-prototype model ***\n",
      "****************************************\n",
      "Average cosine between gold and predicted feature norms: 0.344912828355463\n",
      "Average % @k (derby metric) 0.3173354810564113\n",
      "correlation between gold and predicted vectors: 0.06995067021335617 \n",
      "total number of predictions:  55\n",
      "****************************************\n",
      "*** Evaluating PLSR model ***\n",
      "****************************************\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'plsr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-f22ba0108f96>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"*** Evaluating PLSR model ***\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"****************************************\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mevaluate_in_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplsr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plsr' is not defined"
     ]
    }
   ],
   "source": [
    "from models import *\n",
    "\n",
    "\n",
    "\n",
    "print(\"****************************************\")\n",
    "print(\"*** Evaluating multi-prototype model ***\")\n",
    "print(\"****************************************\")\n",
    "single_model = torch.load('ffnn.30eps.1k.training4418.saved')\n",
    "\n",
    "\"\"\"\n",
    "train a glove model\n",
    "\"\"\"\n",
    "# embeddings_list = []\n",
    "# word_indexer = Indexer()\n",
    "# with open(\"data/glove.6B/glove.6B.300d.txt\", 'r') as f:\n",
    "#     for line in f:\n",
    "#         values = line.split()\n",
    "#         word = values[0]\n",
    "#         vector = np.asarray(values[1:], \"float32\")\n",
    "#         embeddings_list.append([vector])\n",
    "\n",
    "#         #print(embeddings_dict)\n",
    "#         #raise Exception(\"hfelfnl\")\n",
    "#         word_indexer.add_and_get_index(word)\n",
    "\n",
    "# embs = MultiProtoTypeEmbeddings(word_indexer, np.array(embeddings_list), 0, 1) # dummy layer, clusters = 1\n",
    "# glove_model = train_ffnn(train_words, eval_words, embs, feature_norms, args)\n",
    "# torch.save(model, 'ffnn.30eps.glove.training4418.saved')\n",
    "\n",
    "glove_model = torch.load('ffnn.30eps.glove.training4418.saved')\n",
    "evaluate_in_context(multi_model, data, bert)\n",
    "\n",
    "\n",
    "print(\"****************************************\")\n",
    "print(\"*** Evaluating PLSR model ***\")\n",
    "print(\"****************************************\")\n",
    "evaluate_in_context(plsr, data, bert)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"*****************************************\")\n",
    "print(\"*** Evaluating single-prototype model ***\")\n",
    "print(\"*****************************************\")\n",
    "# evaluate_in_context(single_model, data, bert)\n",
    "\n",
    "\n",
    "# models = [single_model, multi_model, glove_model]\n",
    "\n",
    "# for model in models:\n",
    "    \n",
    "#     exs = [cue_word for cue_word, lemma, context in data]\n",
    "#     evaluate(model, exs, norms, None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-00289255a025>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \"\"\"\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"cue_word\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"lemma\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"context\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "create a list of predicted feature vectors for each of the models being evaluated\n",
    "and then stick them in the dataframe\n",
    "\"\"\"\n",
    "\n",
    "df = pd.DataFrame.from_records(data, columns=[\"cue_word\", \"lemma\", \"context\"])\n",
    "df\n",
    "\n",
    "models = {\"multi_prototype_model_preds\": multi_model,\n",
    "         \"single_prototype_model_preds\": single_model,\n",
    "          \"plsr_model_predictions\": plsr_model\n",
    "         #\"glove_model_preds\": glove_model\n",
    "         }\n",
    "for label, model in models.items():\n",
    "    predictions = []\n",
    "    for index, row in df.iterrows():\n",
    "            singular = row.lemma.name()\n",
    "            plural = pluralize(singular)\n",
    "\n",
    "            try:\n",
    "                predicted_vector = model.predict_in_context(singular, row.context, bert)\n",
    "            except:\n",
    "                predicted_vector = model.predict_in_context(plural, row.context, bert)\n",
    "\n",
    "\n",
    "            predictions.append(predicted_vector)\n",
    "\n",
    "    df[label] = predictions\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('bat.n.01')\n",
      "Synset('bat.n.01')\n",
      "1.0\n",
      "0.4567067623138428\n",
      "Synset('bat.n.01')\n",
      "Synset('bat.n.01')\n",
      "1.0\n",
      "0.4567067623138428\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.8060449361801147\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.8975709080696106\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.7775521278381348\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.6074157953262329\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.7919252514839172\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.8780756592750549\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.5728874802589417\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.5733768343925476\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.4941351115703583\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.6754421591758728\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.38706403970718384\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.5818071365356445\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.2892087996006012\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.8423282504081726\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.6744011044502258\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.8060449361801147\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.7933500409126282\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.6884191036224365\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.572281002998352\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.744902491569519\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.7700833678245544\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.45314738154411316\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.6040398478507996\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.4695160686969757\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.724359393119812\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.3955356478691101\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.6395480036735535\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.21967671811580658\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.8522797226905823\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.6811513900756836\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.8975709080696106\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.7933500409126282\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.778498113155365\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.5195254683494568\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.8349948525428772\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.8437638282775879\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.5830709338188171\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.6639347672462463\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.608262300491333\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.6362407207489014\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.47741153836250305\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.5266159176826477\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.35050544142723083\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.8347073197364807\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.7349669933319092\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.7775521278381348\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.6884191036224365\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.778498113155365\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.6535565853118896\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.7927136421203613\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.8313290476799011\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.7835986018180847\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.8089137673377991\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.7665563821792603\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.8163704872131348\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.6535317897796631\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.6584616899490356\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.43390536308288574\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.8855127096176147\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.9053715467453003\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.6074157953262329\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.572281002998352\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.5195254683494568\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.6535565853118896\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.5772702097892761\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.5836297869682312\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.6065819263458252\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.5080467462539673\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.5069180130958557\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.5582232475280762\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.5925189852714539\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.8639638423919678\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.6476215720176697\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.621620774269104\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.6288203001022339\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.7919252514839172\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.744902491569519\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.8349948525428772\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.7927136421203613\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.5772702097892761\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.864958643913269\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.601708710193634\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.7042534947395325\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.6488460302352905\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.7289243936538696\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.6029112935066223\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.6162600517272949\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.43546509742736816\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.8224192261695862\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.7105565071105957\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.8780756592750549\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.7700833678245544\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.8437638282775879\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.8313290476799011\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.5836297869682312\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.864958643913269\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.5851649641990662\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.615913450717926\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.6003682613372803\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.7735596895217896\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.47928690910339355\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.5592843294143677\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.27820682525634766\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.8464125990867615\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.7413697838783264\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.5728874802589417\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.45314738154411316\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.5830709338188171\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.7835986018180847\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.6065819263458252\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.601708710193634\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.5851649641990662\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.7907723188400269\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.817706823348999\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.7097698450088501\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.7171538472175598\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.6682813763618469\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.4614778757095337\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.6976263523101807\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.7928491830825806\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.5733768343925476\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.6040398478507996\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.6639347672462463\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.8089137673377991\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.5080467462539673\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.7042534947395325\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.615913450717926\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.7907723188400269\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.8953949809074402\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.734132707118988\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.8528676629066467\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.5816289186477661\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.44872981309890747\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.7566980719566345\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.8426641225814819\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.4941351115703583\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.4695160686969757\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.608262300491333\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.7665563821792603\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.5069180130958557\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.6488460302352905\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.6003682613372803\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.817706823348999\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.8953949809074402\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.6932477951049805\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.8567507863044739\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.535270631313324\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.42517828941345215\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.6552734375\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.8227373957633972\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.6754421591758728\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.724359393119812\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.6362407207489014\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.8163704872131348\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.5582232475280762\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.7289243936538696\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.7735596895217896\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.7097698450088501\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.734132707118988\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.6932477951049805\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.6231674551963806\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.7211548686027527\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.2400578260421753\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.8482336401939392\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.81826251745224\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.38706403970718384\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.3955356478691101\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.47741153836250305\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.6535317897796631\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.5925189852714539\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.6029112935066223\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.47928690910339355\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.7171538472175598\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.8528676629066467\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.8567507863044739\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.6231674551963806\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.5910634398460388\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.6024152040481567\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.5246497988700867\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.7070956826210022\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.5818071365356445\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.6395480036735535\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.5266159176826477\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.6584616899490356\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.8639638423919678\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.6162600517272949\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.5592843294143677\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.6682813763618469\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.5816289186477661\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.535270631313324\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.7211548686027527\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.5910634398460388\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.5092599391937256\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.715320885181427\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.6910173892974854\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.2892087996006012\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.21967671811580658\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.35050544142723083\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.43390536308288574\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.6476215720176697\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.43546509742736816\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.27820682525634766\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.4614778757095337\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.44872981309890747\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.42517828941345215\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.2400578260421753\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.6024152040481567\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.5092599391937256\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.3361162543296814\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.41680482029914856\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.8423282504081726\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.8522797226905823\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.8347073197364807\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.8855127096176147\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.621620774269104\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.8224192261695862\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.8464125990867615\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.6976263523101807\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.7566980719566345\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.6552734375\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.8482336401939392\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.5246497988700867\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.715320885181427\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.3361162543296814\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.8709886074066162\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.6744011044502258\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.6811513900756836\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.7349669933319092\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.9053715467453003\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.6288203001022339\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.7105565071105957\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.7413697838783264\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.7928491830825806\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.8426641225814819\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.8227373957633972\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.81826251745224\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.7070956826210022\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.6910173892974854\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.41680482029914856\n",
      "Synset('board.n.02')\n",
      "Synset('board.n.02')\n",
      "1.0\n",
      "0.8709886074066162\n",
      "Synset('blackboard.n.01')\n",
      "Synset('blackboard.n.01')\n",
      "1.0\n",
      "0.8144223690032959\n",
      "Synset('blackboard.n.01')\n",
      "Synset('blackboard.n.01')\n",
      "1.0\n",
      "0.8144223690032959\n",
      "Synset('cap.n.02')\n",
      "Synset('cap.n.02')\n",
      "1.0\n",
      "0.7500203251838684\n",
      "Synset('cap.n.02')\n",
      "Synset('cap.n.01')\n",
      "0.7058823529411765\n",
      "0.4981050193309784\n",
      "Synset('cap.n.02')\n",
      "Synset('cap.n.01')\n",
      "0.7058823529411765\n",
      "0.5095440745353699\n",
      "Synset('cap.n.02')\n",
      "Synset('cap.n.01')\n",
      "0.7058823529411765\n",
      "0.4990192949771881\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('cap.n.02')\n",
      "Synset('cap.n.02')\n",
      "1.0\n",
      "0.7500203251838684\n",
      "Synset('cap.n.02')\n",
      "Synset('cap.n.01')\n",
      "0.7058823529411765\n",
      "0.492215096950531\n",
      "Synset('cap.n.02')\n",
      "Synset('cap.n.01')\n",
      "0.7058823529411765\n",
      "0.5481505393981934\n",
      "Synset('cap.n.02')\n",
      "Synset('cap.n.01')\n",
      "0.7058823529411765\n",
      "0.5066812038421631\n",
      "Synset('cap.n.01')\n",
      "Synset('cap.n.02')\n",
      "0.7058823529411765\n",
      "0.4981050193309784\n",
      "Synset('cap.n.01')\n",
      "Synset('cap.n.02')\n",
      "0.7058823529411765\n",
      "0.492215096950531\n",
      "Synset('cap.n.01')\n",
      "Synset('cap.n.01')\n",
      "1.0\n",
      "0.918727695941925\n",
      "Synset('cap.n.01')\n",
      "Synset('cap.n.01')\n",
      "1.0\n",
      "0.9084489941596985\n",
      "Synset('cap.n.01')\n",
      "Synset('cap.n.02')\n",
      "0.7058823529411765\n",
      "0.5095440745353699\n",
      "Synset('cap.n.01')\n",
      "Synset('cap.n.02')\n",
      "0.7058823529411765\n",
      "0.5481505393981934\n",
      "Synset('cap.n.01')\n",
      "Synset('cap.n.01')\n",
      "1.0\n",
      "0.918727695941925\n",
      "Synset('cap.n.01')\n",
      "Synset('cap.n.01')\n",
      "1.0\n",
      "0.9624070525169373\n",
      "Synset('cap.n.01')\n",
      "Synset('cap.n.02')\n",
      "0.7058823529411765\n",
      "0.4990192949771881\n",
      "Synset('cap.n.01')\n",
      "Synset('cap.n.02')\n",
      "0.7058823529411765\n",
      "0.5066812038421631\n",
      "Synset('cap.n.01')\n",
      "Synset('cap.n.01')\n",
      "1.0\n",
      "0.9084489941596985\n",
      "Synset('cap.n.01')\n",
      "Synset('cap.n.01')\n",
      "1.0\n",
      "0.9624070525169373\n",
      "Synset('mouse.n.01')\n",
      "Synset('mouse.n.01')\n",
      "1.0\n",
      "0.9206074476242065\n",
      "Synset('mouse.n.01')\n",
      "Synset('mouse.n.01')\n",
      "1.0\n",
      "0.9619542956352234\n",
      "Synset('mouse.n.01')\n",
      "Synset('mouse.n.01')\n",
      "1.0\n",
      "0.5816661715507507\n",
      "Synset('mouse.n.01')\n",
      "Synset('mouse.n.01')\n",
      "1.0\n",
      "0.8572373986244202\n",
      "Synset('mouse.n.01')\n",
      "Synset('mouse.n.01')\n",
      "1.0\n",
      "0.8611345291137695\n",
      "Synset('mouse.n.01')\n",
      "Synset('mouse.n.01')\n",
      "1.0\n",
      "0.8149116039276123\n",
      "Synset('mouse.n.01')\n",
      "Synset('mouse.n.01')\n",
      "1.0\n",
      "0.8525148630142212\n",
      "Synset('mouse.n.01')\n",
      "Synset('mouse.n.01')\n",
      "1.0\n",
      "0.834028422832489\n",
      "Synset('mouse.n.01')\n",
      "Synset('mouse.n.01')\n",
      "1.0\n",
      "0.9266825914382935\n",
      "Synset('mouse.n.01')\n",
      "Synset('mouse.n.01')\n",
      "1.0\n",
      "0.7623757123947144\n",
      "Synset('mouse.n.01')\n",
      "Synset('mouse.n.01')\n",
      "1.0\n",
      "0.9206074476242065\n",
      "Synset('mouse.n.01')\n",
      "Synset('mouse.n.01')\n",
      "1.0\n",
      "0.9787702560424805\n",
      "Synset('mouse.n.01')\n",
      "Synset('mouse.n.01')\n",
      "1.0\n",
      "0.7314932942390442\n",
      "Synset('mouse.n.01')\n",
      "Synset('mouse.n.01')\n",
      "1.0\n",
      "0.8811306357383728\n",
      "Synset('mouse.n.01')\n",
      "Synset('mouse.n.01')\n",
      "1.0\n",
      "0.8818129301071167\n",
      "Synset('mouse.n.01')\n",
      "Synset('mouse.n.01')\n",
      "1.0\n",
      "0.9016678929328918\n",
      "Synset('mouse.n.01')\n",
      "Synset('mouse.n.01')\n",
      "1.0\n",
      "0.8990138173103333\n",
      "Synset('mouse.n.01')\n",
      "Synset('mouse.n.01')\n",
      "1.0\n",
      "0.8665425777435303\n",
      "Synset('mouse.n.01')\n",
      "Synset('mouse.n.01')\n",
      "1.0\n",
      "0.8943570256233215\n",
      "Synset('mouse.n.01')\n",
      "Synset('mouse.n.01')\n",
      "1.0\n",
      "0.824927806854248\n",
      "Synset('mouse.n.01')\n",
      "Synset('mouse.n.01')\n",
      "1.0\n",
      "0.9619542956352234\n",
      "Synset('mouse.n.01')\n",
      "Synset('mouse.n.01')\n",
      "1.0\n",
      "0.9787702560424805\n",
      "Synset('mouse.n.01')\n",
      "Synset('mouse.n.01')\n",
      "1.0\n",
      "0.6765785217285156\n",
      "Synset('mouse.n.01')\n",
      "Synset('mouse.n.01')\n",
      "1.0\n",
      "0.8908626437187195\n",
      "Synset('mouse.n.01')\n",
      "Synset('mouse.n.01')\n",
      "1.0\n",
      "0.8852578401565552\n",
      "Synset('mouse.n.01')\n",
      "Synset('mouse.n.01')\n",
      "1.0\n",
      "0.8825112581253052\n",
      "Synset('mouse.n.01')\n",
      "Synset('mouse.n.01')\n",
      "1.0\n",
      "0.9059118628501892\n",
      "Synset('mouse.n.01')\n",
      "Synset('mouse.n.01')\n",
      "1.0\n",
      "0.8681920766830444\n",
      "Synset('mouse.n.01')\n",
      "Synset('mouse.n.01')\n",
      "1.0\n",
      "0.9289447665214539\n",
      "Synset('mouse.n.01')\n",
      "Synset('mouse.n.01')\n",
      "1.0\n",
      "0.8217052221298218\n",
      "Synset('mouse.n.01')\n",
      "Synset('mouse.n.01')\n",
      "1.0\n",
      "0.5816661715507507\n",
      "Synset('mouse.n.01')\n",
      "Synset('mouse.n.01')\n",
      "1.0\n",
      "0.7314932942390442\n",
      "Synset('mouse.n.01')\n",
      "Synset('mouse.n.01')\n",
      "1.0\n",
      "0.6765785217285156\n",
      "Synset('mouse.n.01')\n",
      "Synset('mouse.n.01')\n",
      "1.0\n",
      "0.5935161113739014\n",
      "Synset('mouse.n.01')\n",
      "Synset('mouse.n.01')\n",
      "1.0\n",
      "0.7625995874404907\n",
      "Synset('mouse.n.01')\n",
      "Synset('mouse.n.01')\n",
      "1.0\n",
      "0.7266565561294556\n",
      "Synset('mouse.n.01')\n",
      "Synset('mouse.n.01')\n",
      "1.0\n",
      "0.7020885348320007\n",
      "Synset('mouse.n.01')\n",
      "Synset('mouse.n.01')\n",
      "1.0\n",
      "0.8286536335945129\n",
      "Synset('mouse.n.01')\n",
      "Synset('mouse.n.01')\n",
      "1.0\n",
      "0.6533937454223633\n",
      "Synset('mouse.n.01')\n",
      "Synset('mouse.n.01')\n",
      "1.0\n",
      "0.8012089729309082\n",
      "Synset('mouse.n.01')\n",
      "Synset('mouse.n.01')\n",
      "1.0\n",
      "0.8572373986244202\n",
      "Synset('mouse.n.01')\n",
      "Synset('mouse.n.01')\n",
      "1.0\n",
      "0.8811306357383728\n",
      "Synset('mouse.n.01')\n",
      "Synset('mouse.n.01')\n",
      "1.0\n",
      "0.8908626437187195\n",
      "Synset('mouse.n.01')\n",
      "Synset('mouse.n.01')\n",
      "1.0\n",
      "0.5935161113739014\n",
      "Synset('mouse.n.01')\n",
      "Synset('mouse.n.01')\n",
      "1.0\n",
      "0.8301121592521667\n",
      "Synset('mouse.n.01')\n",
      "Synset('mouse.n.01')\n",
      "1.0\n",
      "0.9340083003044128\n",
      "Synset('mouse.n.01')\n",
      "Synset('mouse.n.01')\n",
      "1.0\n",
      "0.953190803527832\n",
      "Synset('mouse.n.01')\n",
      "Synset('mouse.n.01')\n",
      "1.0\n",
      "0.8002690672874451\n",
      "Synset('mouse.n.01')\n",
      "Synset('mouse.n.01')\n",
      "1.0\n",
      "0.8917003870010376\n",
      "Synset('mouse.n.01')\n",
      "Synset('mouse.n.01')\n",
      "1.0\n",
      "0.783439576625824\n",
      "Synset('mouse.n.01')\n",
      "Synset('mouse.n.01')\n",
      "1.0\n",
      "0.8611345291137695\n",
      "Synset('mouse.n.01')\n",
      "Synset('mouse.n.01')\n",
      "1.0\n",
      "0.8818129301071167\n",
      "Synset('mouse.n.01')\n",
      "Synset('mouse.n.01')\n",
      "1.0\n",
      "0.8852578401565552\n",
      "Synset('mouse.n.01')\n",
      "Synset('mouse.n.01')\n",
      "1.0\n",
      "0.7625995874404907\n",
      "Synset('mouse.n.01')\n",
      "Synset('mouse.n.01')\n",
      "1.0\n",
      "0.8301121592521667\n",
      "Synset('mouse.n.01')\n",
      "Synset('mouse.n.01')\n",
      "1.0\n",
      "0.8472828269004822\n",
      "Synset('mouse.n.01')\n",
      "Synset('mouse.n.01')\n",
      "1.0\n",
      "0.8660635948181152\n",
      "Synset('mouse.n.01')\n",
      "Synset('mouse.n.01')\n",
      "1.0\n",
      "0.9253208041191101\n",
      "Synset('mouse.n.01')\n",
      "Synset('mouse.n.01')\n",
      "1.0\n",
      "0.9367669820785522\n",
      "Synset('mouse.n.01')\n",
      "Synset('mouse.n.01')\n",
      "1.0\n",
      "0.9322080016136169\n",
      "Synset('mouse.n.01')\n",
      "Synset('mouse.n.01')\n",
      "1.0\n",
      "0.8149116039276123\n",
      "Synset('mouse.n.01')\n",
      "Synset('mouse.n.01')\n",
      "1.0\n",
      "0.9016678929328918\n",
      "Synset('mouse.n.01')\n",
      "Synset('mouse.n.01')\n",
      "1.0\n",
      "0.8825112581253052\n",
      "Synset('mouse.n.01')\n",
      "Synset('mouse.n.01')\n",
      "1.0\n",
      "0.7266565561294556\n",
      "Synset('mouse.n.01')\n",
      "Synset('mouse.n.01')\n",
      "1.0\n",
      "0.9340083003044128\n",
      "Synset('mouse.n.01')\n",
      "Synset('mouse.n.01')\n",
      "1.0\n",
      "0.8472828269004822\n",
      "Synset('mouse.n.01')\n",
      "Synset('mouse.n.01')\n",
      "1.0\n",
      "0.9564082622528076\n",
      "Synset('mouse.n.01')\n",
      "Synset('mouse.n.01')\n",
      "1.0\n",
      "0.8286510705947876\n",
      "Synset('mouse.n.01')\n",
      "Synset('mouse.n.01')\n",
      "1.0\n",
      "0.8453384041786194\n",
      "Synset('mouse.n.01')\n",
      "Synset('mouse.n.01')\n",
      "1.0\n",
      "0.8340789079666138\n",
      "Synset('mouse.n.01')\n",
      "Synset('mouse.n.01')\n",
      "1.0\n",
      "0.8525148630142212\n",
      "Synset('mouse.n.01')\n",
      "Synset('mouse.n.01')\n",
      "1.0\n",
      "0.8990138173103333\n",
      "Synset('mouse.n.01')\n",
      "Synset('mouse.n.01')\n",
      "1.0\n",
      "0.9059118628501892\n",
      "Synset('mouse.n.01')\n",
      "Synset('mouse.n.01')\n",
      "1.0\n",
      "0.7020885348320007\n",
      "Synset('mouse.n.01')\n",
      "Synset('mouse.n.01')\n",
      "1.0\n",
      "0.953190803527832\n",
      "Synset('mouse.n.01')\n",
      "Synset('mouse.n.01')\n",
      "1.0\n",
      "0.8660635948181152\n",
      "Synset('mouse.n.01')\n",
      "Synset('mouse.n.01')\n",
      "1.0\n",
      "0.9564082622528076\n",
      "Synset('mouse.n.01')\n",
      "Synset('mouse.n.01')\n",
      "1.0\n",
      "0.8603931069374084\n",
      "Synset('mouse.n.01')\n",
      "Synset('mouse.n.01')\n",
      "1.0\n",
      "0.901418149471283\n",
      "Synset('mouse.n.01')\n",
      "Synset('mouse.n.01')\n",
      "1.0\n",
      "0.8650006651878357\n",
      "Synset('mouse.n.01')\n",
      "Synset('mouse.n.01')\n",
      "1.0\n",
      "0.834028422832489\n",
      "Synset('mouse.n.01')\n",
      "Synset('mouse.n.01')\n",
      "1.0\n",
      "0.8665425777435303\n",
      "Synset('mouse.n.01')\n",
      "Synset('mouse.n.01')\n",
      "1.0\n",
      "0.8681920766830444\n",
      "Synset('mouse.n.01')\n",
      "Synset('mouse.n.01')\n",
      "1.0\n",
      "0.8286536335945129\n",
      "Synset('mouse.n.01')\n",
      "Synset('mouse.n.01')\n",
      "1.0\n",
      "0.8002690672874451\n",
      "Synset('mouse.n.01')\n",
      "Synset('mouse.n.01')\n",
      "1.0\n",
      "0.9253208041191101\n",
      "Synset('mouse.n.01')\n",
      "Synset('mouse.n.01')\n",
      "1.0\n",
      "0.8286510705947876\n",
      "Synset('mouse.n.01')\n",
      "Synset('mouse.n.01')\n",
      "1.0\n",
      "0.8603931069374084\n",
      "Synset('mouse.n.01')\n",
      "Synset('mouse.n.01')\n",
      "1.0\n",
      "0.91324383020401\n",
      "Synset('mouse.n.01')\n",
      "Synset('mouse.n.01')\n",
      "1.0\n",
      "0.9168474674224854\n",
      "Synset('mouse.n.01')\n",
      "Synset('mouse.n.01')\n",
      "1.0\n",
      "0.9266825914382935\n",
      "Synset('mouse.n.01')\n",
      "Synset('mouse.n.01')\n",
      "1.0\n",
      "0.8943570256233215\n",
      "Synset('mouse.n.01')\n",
      "Synset('mouse.n.01')\n",
      "1.0\n",
      "0.9289447665214539\n",
      "Synset('mouse.n.01')\n",
      "Synset('mouse.n.01')\n",
      "1.0\n",
      "0.6533937454223633\n",
      "Synset('mouse.n.01')\n",
      "Synset('mouse.n.01')\n",
      "1.0\n",
      "0.8917003870010376\n",
      "Synset('mouse.n.01')\n",
      "Synset('mouse.n.01')\n",
      "1.0\n",
      "0.9367669820785522\n",
      "Synset('mouse.n.01')\n",
      "Synset('mouse.n.01')\n",
      "1.0\n",
      "0.8453384041786194\n",
      "Synset('mouse.n.01')\n",
      "Synset('mouse.n.01')\n",
      "1.0\n",
      "0.901418149471283\n",
      "Synset('mouse.n.01')\n",
      "Synset('mouse.n.01')\n",
      "1.0\n",
      "0.91324383020401\n",
      "Synset('mouse.n.01')\n",
      "Synset('mouse.n.01')\n",
      "1.0\n",
      "0.8824815154075623\n",
      "Synset('mouse.n.01')\n",
      "Synset('mouse.n.01')\n",
      "1.0\n",
      "0.7623757123947144\n",
      "Synset('mouse.n.01')\n",
      "Synset('mouse.n.01')\n",
      "1.0\n",
      "0.824927806854248\n",
      "Synset('mouse.n.01')\n",
      "Synset('mouse.n.01')\n",
      "1.0\n",
      "0.8217052221298218\n",
      "Synset('mouse.n.01')\n",
      "Synset('mouse.n.01')\n",
      "1.0\n",
      "0.8012089729309082\n",
      "Synset('mouse.n.01')\n",
      "Synset('mouse.n.01')\n",
      "1.0\n",
      "0.783439576625824\n",
      "Synset('mouse.n.01')\n",
      "Synset('mouse.n.01')\n",
      "1.0\n",
      "0.9322080016136169\n",
      "Synset('mouse.n.01')\n",
      "Synset('mouse.n.01')\n",
      "1.0\n",
      "0.8340789079666138\n",
      "Synset('mouse.n.01')\n",
      "Synset('mouse.n.01')\n",
      "1.0\n",
      "0.8650006651878357\n",
      "Synset('mouse.n.01')\n",
      "Synset('mouse.n.01')\n",
      "1.0\n",
      "0.9168474674224854\n",
      "Synset('mouse.n.01')\n",
      "Synset('mouse.n.01')\n",
      "1.0\n",
      "0.8824815154075623\n",
      "Synset('pipe.n.01')\n",
      "Synset('pipe.n.01')\n",
      "1.0\n",
      "0.792943000793457\n",
      "Synset('pipe.n.01')\n",
      "Synset('pipe.n.01')\n",
      "1.0\n",
      "0.7803969383239746\n",
      "Synset('pipe.n.01')\n",
      "Synset('pipe.n.01')\n",
      "1.0\n",
      "0.7848690152168274\n",
      "Synset('pipe.n.01')\n",
      "Synset('pipe.n.02')\n",
      "0.9\n",
      "0.5546069741249084\n",
      "Synset('pipe.n.01')\n",
      "Synset('pipe.n.02')\n",
      "0.9\n",
      "0.568013072013855\n",
      "Synset('pipe.n.01')\n",
      "Synset('pipe.n.02')\n",
      "0.9\n",
      "0.42459601163864136\n",
      "Synset('pipe.n.01')\n",
      "Synset('pipe.n.02')\n",
      "0.9\n",
      "0.626096248626709\n",
      "Synset('pipe.n.01')\n",
      "Synset('pipe.n.01')\n",
      "1.0\n",
      "0.792943000793457\n",
      "Synset('pipe.n.01')\n",
      "Synset('pipe.n.01')\n",
      "1.0\n",
      "0.6446219086647034\n",
      "Synset('pipe.n.01')\n",
      "Synset('pipe.n.01')\n",
      "1.0\n",
      "0.6129028797149658\n",
      "Synset('pipe.n.01')\n",
      "Synset('pipe.n.02')\n",
      "0.9\n",
      "0.5417985916137695\n",
      "Synset('pipe.n.01')\n",
      "Synset('pipe.n.02')\n",
      "0.9\n",
      "0.5011020302772522\n",
      "Synset('pipe.n.01')\n",
      "Synset('pipe.n.02')\n",
      "0.9\n",
      "0.3797031342983246\n",
      "Synset('pipe.n.01')\n",
      "Synset('pipe.n.02')\n",
      "0.9\n",
      "0.5083535313606262\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('pipe.n.01')\n",
      "Synset('pipe.n.01')\n",
      "1.0\n",
      "0.7803969383239746\n",
      "Synset('pipe.n.01')\n",
      "Synset('pipe.n.01')\n",
      "1.0\n",
      "0.6446219086647034\n",
      "Synset('pipe.n.01')\n",
      "Synset('pipe.n.01')\n",
      "1.0\n",
      "0.8551236987113953\n",
      "Synset('pipe.n.01')\n",
      "Synset('pipe.n.02')\n",
      "0.9\n",
      "0.43286341428756714\n",
      "Synset('pipe.n.01')\n",
      "Synset('pipe.n.02')\n",
      "0.9\n",
      "0.41546064615249634\n",
      "Synset('pipe.n.01')\n",
      "Synset('pipe.n.02')\n",
      "0.9\n",
      "0.4032531976699829\n",
      "Synset('pipe.n.01')\n",
      "Synset('pipe.n.02')\n",
      "0.9\n",
      "0.5735560655593872\n",
      "Synset('pipe.n.01')\n",
      "Synset('pipe.n.01')\n",
      "1.0\n",
      "0.7848690152168274\n",
      "Synset('pipe.n.01')\n",
      "Synset('pipe.n.01')\n",
      "1.0\n",
      "0.6129028797149658\n",
      "Synset('pipe.n.01')\n",
      "Synset('pipe.n.01')\n",
      "1.0\n",
      "0.8551236987113953\n",
      "Synset('pipe.n.01')\n",
      "Synset('pipe.n.02')\n",
      "0.9\n",
      "0.3642069697380066\n",
      "Synset('pipe.n.01')\n",
      "Synset('pipe.n.02')\n",
      "0.9\n",
      "0.3806242048740387\n",
      "Synset('pipe.n.01')\n",
      "Synset('pipe.n.02')\n",
      "0.9\n",
      "0.4014602303504944\n",
      "Synset('pipe.n.01')\n",
      "Synset('pipe.n.02')\n",
      "0.9\n",
      "0.4510881304740906\n",
      "Synset('pipe.n.02')\n",
      "Synset('pipe.n.01')\n",
      "0.9\n",
      "0.5546069741249084\n",
      "Synset('pipe.n.02')\n",
      "Synset('pipe.n.01')\n",
      "0.9\n",
      "0.5417985916137695\n",
      "Synset('pipe.n.02')\n",
      "Synset('pipe.n.01')\n",
      "0.9\n",
      "0.43286341428756714\n",
      "Synset('pipe.n.02')\n",
      "Synset('pipe.n.01')\n",
      "0.9\n",
      "0.3642069697380066\n",
      "Synset('pipe.n.02')\n",
      "Synset('pipe.n.02')\n",
      "1.0\n",
      "0.9067329168319702\n",
      "Synset('pipe.n.02')\n",
      "Synset('pipe.n.02')\n",
      "1.0\n",
      "0.5427469611167908\n",
      "Synset('pipe.n.02')\n",
      "Synset('pipe.n.02')\n",
      "1.0\n",
      "0.7900887131690979\n",
      "Synset('pipe.n.02')\n",
      "Synset('pipe.n.01')\n",
      "0.9\n",
      "0.568013072013855\n",
      "Synset('pipe.n.02')\n",
      "Synset('pipe.n.01')\n",
      "0.9\n",
      "0.5011020302772522\n",
      "Synset('pipe.n.02')\n",
      "Synset('pipe.n.01')\n",
      "0.9\n",
      "0.41546064615249634\n",
      "Synset('pipe.n.02')\n",
      "Synset('pipe.n.01')\n",
      "0.9\n",
      "0.3806242048740387\n",
      "Synset('pipe.n.02')\n",
      "Synset('pipe.n.02')\n",
      "1.0\n",
      "0.9067329168319702\n",
      "Synset('pipe.n.02')\n",
      "Synset('pipe.n.02')\n",
      "1.0\n",
      "0.7017116546630859\n",
      "Synset('pipe.n.02')\n",
      "Synset('pipe.n.02')\n",
      "1.0\n",
      "0.8446336984634399\n",
      "Synset('pipe.n.02')\n",
      "Synset('pipe.n.01')\n",
      "0.9\n",
      "0.42459601163864136\n",
      "Synset('pipe.n.02')\n",
      "Synset('pipe.n.01')\n",
      "0.9\n",
      "0.3797031342983246\n",
      "Synset('pipe.n.02')\n",
      "Synset('pipe.n.01')\n",
      "0.9\n",
      "0.4032531976699829\n",
      "Synset('pipe.n.02')\n",
      "Synset('pipe.n.01')\n",
      "0.9\n",
      "0.4014602303504944\n",
      "Synset('pipe.n.02')\n",
      "Synset('pipe.n.02')\n",
      "1.0\n",
      "0.5427469611167908\n",
      "Synset('pipe.n.02')\n",
      "Synset('pipe.n.02')\n",
      "1.0\n",
      "0.7017116546630859\n",
      "Synset('pipe.n.02')\n",
      "Synset('pipe.n.02')\n",
      "1.0\n",
      "0.6297407746315002\n",
      "Synset('pipe.n.02')\n",
      "Synset('pipe.n.01')\n",
      "0.9\n",
      "0.626096248626709\n",
      "Synset('pipe.n.02')\n",
      "Synset('pipe.n.01')\n",
      "0.9\n",
      "0.5083535313606262\n",
      "Synset('pipe.n.02')\n",
      "Synset('pipe.n.01')\n",
      "0.9\n",
      "0.5735560655593872\n",
      "Synset('pipe.n.02')\n",
      "Synset('pipe.n.01')\n",
      "0.9\n",
      "0.4510881304740906\n",
      "Synset('pipe.n.02')\n",
      "Synset('pipe.n.02')\n",
      "1.0\n",
      "0.7900887131690979\n",
      "Synset('pipe.n.02')\n",
      "Synset('pipe.n.02')\n",
      "1.0\n",
      "0.8446336984634399\n",
      "Synset('pipe.n.02')\n",
      "Synset('pipe.n.02')\n",
      "1.0\n",
      "0.6297407746315002\n",
      "Synset('tank.n.01')\n",
      "Synset('tank.n.01')\n",
      "1.0\n",
      "0.656605064868927\n",
      "Synset('tank.n.01')\n",
      "Synset('tank.n.01')\n",
      "1.0\n",
      "0.6073613166809082\n",
      "Synset('tank.n.01')\n",
      "Synset('tank.n.01')\n",
      "1.0\n",
      "0.8191369771957397\n",
      "Synset('tank.n.01')\n",
      "Synset('tank.n.01')\n",
      "1.0\n",
      "0.6532130837440491\n",
      "Synset('tank.n.01')\n",
      "Synset('tank.n.01')\n",
      "1.0\n",
      "0.5395865440368652\n",
      "Synset('tank.n.01')\n",
      "Synset('tank.n.01')\n",
      "1.0\n",
      "0.8406465649604797\n",
      "Synset('tank.n.01')\n",
      "Synset('tank.n.02')\n",
      "0.7\n",
      "0.6431769132614136\n",
      "Synset('tank.n.01')\n",
      "Synset('tank.n.02')\n",
      "0.7\n",
      "0.4179399311542511\n",
      "Synset('tank.n.01')\n",
      "Synset('tank.n.02')\n",
      "0.7\n",
      "0.7036234140396118\n",
      "Synset('tank.n.01')\n",
      "Synset('tank.n.01')\n",
      "1.0\n",
      "0.656605064868927\n",
      "Synset('tank.n.01')\n",
      "Synset('tank.n.01')\n",
      "1.0\n",
      "0.8308295011520386\n",
      "Synset('tank.n.01')\n",
      "Synset('tank.n.01')\n",
      "1.0\n",
      "0.7135554552078247\n",
      "Synset('tank.n.01')\n",
      "Synset('tank.n.01')\n",
      "1.0\n",
      "0.8729133605957031\n",
      "Synset('tank.n.01')\n",
      "Synset('tank.n.01')\n",
      "1.0\n",
      "0.8295100927352905\n",
      "Synset('tank.n.01')\n",
      "Synset('tank.n.01')\n",
      "1.0\n",
      "0.6784499287605286\n",
      "Synset('tank.n.01')\n",
      "Synset('tank.n.02')\n",
      "0.7\n",
      "0.4745822548866272\n",
      "Synset('tank.n.01')\n",
      "Synset('tank.n.02')\n",
      "0.7\n",
      "0.3580617308616638\n",
      "Synset('tank.n.01')\n",
      "Synset('tank.n.02')\n",
      "0.7\n",
      "0.47625890374183655\n",
      "Synset('tank.n.01')\n",
      "Synset('tank.n.01')\n",
      "1.0\n",
      "0.6073613166809082\n",
      "Synset('tank.n.01')\n",
      "Synset('tank.n.01')\n",
      "1.0\n",
      "0.8308295011520386\n",
      "Synset('tank.n.01')\n",
      "Synset('tank.n.01')\n",
      "1.0\n",
      "0.6623640656471252\n",
      "Synset('tank.n.01')\n",
      "Synset('tank.n.01')\n",
      "1.0\n",
      "0.8433539271354675\n",
      "Synset('tank.n.01')\n",
      "Synset('tank.n.01')\n",
      "1.0\n",
      "0.7044714689254761\n",
      "Synset('tank.n.01')\n",
      "Synset('tank.n.01')\n",
      "1.0\n",
      "0.5140687227249146\n",
      "Synset('tank.n.01')\n",
      "Synset('tank.n.02')\n",
      "0.7\n",
      "0.23237423598766327\n",
      "Synset('tank.n.01')\n",
      "Synset('tank.n.02')\n",
      "0.7\n",
      "0.22819620370864868\n",
      "Synset('tank.n.01')\n",
      "Synset('tank.n.02')\n",
      "0.7\n",
      "0.27929848432540894\n",
      "Synset('tank.n.01')\n",
      "Synset('tank.n.01')\n",
      "1.0\n",
      "0.8191369771957397\n",
      "Synset('tank.n.01')\n",
      "Synset('tank.n.01')\n",
      "1.0\n",
      "0.7135554552078247\n",
      "Synset('tank.n.01')\n",
      "Synset('tank.n.01')\n",
      "1.0\n",
      "0.6623640656471252\n",
      "Synset('tank.n.01')\n",
      "Synset('tank.n.01')\n",
      "1.0\n",
      "0.6294229030609131\n",
      "Synset('tank.n.01')\n",
      "Synset('tank.n.01')\n",
      "1.0\n",
      "0.5102489590644836\n",
      "Synset('tank.n.01')\n",
      "Synset('tank.n.01')\n",
      "1.0\n",
      "0.7012040019035339\n",
      "Synset('tank.n.01')\n",
      "Synset('tank.n.02')\n",
      "0.7\n",
      "0.43066006898880005\n",
      "Synset('tank.n.01')\n",
      "Synset('tank.n.02')\n",
      "0.7\n",
      "0.18474072217941284\n",
      "Synset('tank.n.01')\n",
      "Synset('tank.n.02')\n",
      "0.7\n",
      "0.4620186686515808\n",
      "Synset('tank.n.01')\n",
      "Synset('tank.n.01')\n",
      "1.0\n",
      "0.6532130837440491\n",
      "Synset('tank.n.01')\n",
      "Synset('tank.n.01')\n",
      "1.0\n",
      "0.8729133605957031\n",
      "Synset('tank.n.01')\n",
      "Synset('tank.n.01')\n",
      "1.0\n",
      "0.8433539271354675\n",
      "Synset('tank.n.01')\n",
      "Synset('tank.n.01')\n",
      "1.0\n",
      "0.6294229030609131\n",
      "Synset('tank.n.01')\n",
      "Synset('tank.n.01')\n",
      "1.0\n",
      "0.9019835591316223\n",
      "Synset('tank.n.01')\n",
      "Synset('tank.n.01')\n",
      "1.0\n",
      "0.626898467540741\n",
      "Synset('tank.n.01')\n",
      "Synset('tank.n.02')\n",
      "0.7\n",
      "0.41475173830986023\n",
      "Synset('tank.n.01')\n",
      "Synset('tank.n.02')\n",
      "0.7\n",
      "0.3394923210144043\n",
      "Synset('tank.n.01')\n",
      "Synset('tank.n.02')\n",
      "0.7\n",
      "0.47131475806236267\n",
      "Synset('tank.n.01')\n",
      "Synset('tank.n.01')\n",
      "1.0\n",
      "0.5395865440368652\n",
      "Synset('tank.n.01')\n",
      "Synset('tank.n.01')\n",
      "1.0\n",
      "0.8295100927352905\n",
      "Synset('tank.n.01')\n",
      "Synset('tank.n.01')\n",
      "1.0\n",
      "0.7044714689254761\n",
      "Synset('tank.n.01')\n",
      "Synset('tank.n.01')\n",
      "1.0\n",
      "0.5102489590644836\n",
      "Synset('tank.n.01')\n",
      "Synset('tank.n.01')\n",
      "1.0\n",
      "0.9019835591316223\n",
      "Synset('tank.n.01')\n",
      "Synset('tank.n.01')\n",
      "1.0\n",
      "0.5212622284889221\n",
      "Synset('tank.n.01')\n",
      "Synset('tank.n.02')\n",
      "0.7\n",
      "0.44163861870765686\n",
      "Synset('tank.n.01')\n",
      "Synset('tank.n.02')\n",
      "0.7\n",
      "0.3740974962711334\n",
      "Synset('tank.n.01')\n",
      "Synset('tank.n.02')\n",
      "0.7\n",
      "0.5115154385566711\n",
      "Synset('tank.n.01')\n",
      "Synset('tank.n.01')\n",
      "1.0\n",
      "0.8406465649604797\n",
      "Synset('tank.n.01')\n",
      "Synset('tank.n.01')\n",
      "1.0\n",
      "0.6784499287605286\n",
      "Synset('tank.n.01')\n",
      "Synset('tank.n.01')\n",
      "1.0\n",
      "0.5140687227249146\n",
      "Synset('tank.n.01')\n",
      "Synset('tank.n.01')\n",
      "1.0\n",
      "0.7012040019035339\n",
      "Synset('tank.n.01')\n",
      "Synset('tank.n.01')\n",
      "1.0\n",
      "0.626898467540741\n",
      "Synset('tank.n.01')\n",
      "Synset('tank.n.01')\n",
      "1.0\n",
      "0.5212622284889221\n",
      "Synset('tank.n.01')\n",
      "Synset('tank.n.02')\n",
      "0.7\n",
      "0.7656478881835938\n",
      "Synset('tank.n.01')\n",
      "Synset('tank.n.02')\n",
      "0.7\n",
      "0.403566837310791\n",
      "Synset('tank.n.01')\n",
      "Synset('tank.n.02')\n",
      "0.7\n",
      "0.696563184261322\n",
      "Synset('tank.n.02')\n",
      "Synset('tank.n.01')\n",
      "0.7\n",
      "0.6431769132614136\n",
      "Synset('tank.n.02')\n",
      "Synset('tank.n.01')\n",
      "0.7\n",
      "0.4745822548866272\n",
      "Synset('tank.n.02')\n",
      "Synset('tank.n.01')\n",
      "0.7\n",
      "0.23237423598766327\n",
      "Synset('tank.n.02')\n",
      "Synset('tank.n.01')\n",
      "0.7\n",
      "0.43066006898880005\n",
      "Synset('tank.n.02')\n",
      "Synset('tank.n.01')\n",
      "0.7\n",
      "0.41475173830986023\n",
      "Synset('tank.n.02')\n",
      "Synset('tank.n.01')\n",
      "0.7\n",
      "0.44163861870765686\n",
      "Synset('tank.n.02')\n",
      "Synset('tank.n.01')\n",
      "0.7\n",
      "0.7656478881835938\n",
      "Synset('tank.n.02')\n",
      "Synset('tank.n.02')\n",
      "1.0\n",
      "0.5344994068145752\n",
      "Synset('tank.n.02')\n",
      "Synset('tank.n.02')\n",
      "1.0\n",
      "0.8972707390785217\n",
      "Synset('tank.n.02')\n",
      "Synset('tank.n.01')\n",
      "0.7\n",
      "0.4179399311542511\n",
      "Synset('tank.n.02')\n",
      "Synset('tank.n.01')\n",
      "0.7\n",
      "0.3580617308616638\n",
      "Synset('tank.n.02')\n",
      "Synset('tank.n.01')\n",
      "0.7\n",
      "0.22819620370864868\n",
      "Synset('tank.n.02')\n",
      "Synset('tank.n.01')\n",
      "0.7\n",
      "0.18474072217941284\n",
      "Synset('tank.n.02')\n",
      "Synset('tank.n.01')\n",
      "0.7\n",
      "0.3394923210144043\n",
      "Synset('tank.n.02')\n",
      "Synset('tank.n.01')\n",
      "0.7\n",
      "0.3740974962711334\n",
      "Synset('tank.n.02')\n",
      "Synset('tank.n.01')\n",
      "0.7\n",
      "0.403566837310791\n",
      "Synset('tank.n.02')\n",
      "Synset('tank.n.02')\n",
      "1.0\n",
      "0.5344994068145752\n",
      "Synset('tank.n.02')\n",
      "Synset('tank.n.02')\n",
      "1.0\n",
      "0.5851289629936218\n",
      "Synset('tank.n.02')\n",
      "Synset('tank.n.01')\n",
      "0.7\n",
      "0.7036234140396118\n",
      "Synset('tank.n.02')\n",
      "Synset('tank.n.01')\n",
      "0.7\n",
      "0.47625890374183655\n",
      "Synset('tank.n.02')\n",
      "Synset('tank.n.01')\n",
      "0.7\n",
      "0.27929848432540894\n",
      "Synset('tank.n.02')\n",
      "Synset('tank.n.01')\n",
      "0.7\n",
      "0.4620186686515808\n",
      "Synset('tank.n.02')\n",
      "Synset('tank.n.01')\n",
      "0.7\n",
      "0.47131475806236267\n",
      "Synset('tank.n.02')\n",
      "Synset('tank.n.01')\n",
      "0.7\n",
      "0.5115154385566711\n",
      "Synset('tank.n.02')\n",
      "Synset('tank.n.01')\n",
      "0.7\n",
      "0.696563184261322\n",
      "Synset('tank.n.02')\n",
      "Synset('tank.n.02')\n",
      "1.0\n",
      "0.8972707390785217\n",
      "Synset('tank.n.02')\n",
      "Synset('tank.n.02')\n",
      "1.0\n",
      "0.5851289629936218\n"
     ]
    }
   ],
   "source": [
    "ws = []\n",
    "for index, row in df.iterrows():\n",
    "    word = row.lemma.name()\n",
    "    #print(row.lemma.name())\n",
    "    ws.append(word)\n",
    "    \n",
    "df['label'] = ws\n",
    "\n",
    "wup_sims = []\n",
    "cossine_sims = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    word = row.label\n",
    "    \n",
    "    # select other examples of this token\n",
    "    othertokens = df[df.label == word]\n",
    "    # filter out the token itself\n",
    "    othertokens = othertokens[othertokens.index != index]\n",
    "    #print(othertokens)\n",
    "    \n",
    "    for index, otherword in othertokens.iterrows():\n",
    "        # find the wordnet distance between these two wordnet senses\n",
    "        synset1 = row.lemma.synset()\n",
    "        synset2 = otherword.lemma.synset()\n",
    "        \n",
    "        wup_sim = synset1.wup_similarity(synset2)\n",
    "        wup_sims.append(wup_sim)\n",
    "        cossim = 1 - cosine(row.multi_prototype_model_preds, otherword.multi_prototype_model_preds)\n",
    "        #cossim = 1 - cosine(row.single_prototype_model_preds, otherword.single_prototype_model_preds)\n",
    "        cossine_sims.append(cossim)\n",
    "        print(synset1)\n",
    "        print(synset2)\n",
    "        print(wup_sim)\n",
    "        print(cossim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "do the correlation:\n",
    "\"\"\"\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pyplot.scatter\n",
    "pyplot.show()\n",
    "\n",
    "plt.scatter(wup_sims, cossine_sims)\n",
    "plt.title(\"Wordnet similarity of homonymous senses plotted against cosine similarity of predicted vectors of two tokens in semantic feature space\")\n",
    "plt.xlabel(\"Wu and Palmer Similarity\")\n",
    "plt.ylabel(\"Cosine Similarity\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearsons correlation: 0.483, p-value: 1.0079845463672174e-31\n",
      "Spearmans correlation: 0.506, p-value: 4.008131005337109e-35\n"
     ]
    }
   ],
   "source": [
    "# calculate Pearson's correlation\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "\n",
    "corr, p = pearsonr(wup_sims, cossine_sims)\n",
    "print('Pearsons correlation: %.3f, p-value: %s'  % (corr, p))\n",
    "\n",
    "corr, p = spearmanr(wup_sims, cossine_sims)\n",
    "print('Spearmans correlation: %.3f, p-value: %s'  % (corr, p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "520\n"
     ]
    }
   ],
   "source": [
    "print (len(wup_sims))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do the same analysis for single-prototype model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearsons correlation: 0.567, p-value: 1.1948935320905846e-45\n",
      "Spearmans correlation: 0.525, p-value: 3.035422467454594e-38\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "wup_sims = []\n",
    "cossine_sims = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    word = row.label\n",
    "    \n",
    "    # select other examples of this token\n",
    "    othertokens = df[df.label == word]\n",
    "    # filter out the token itself\n",
    "    othertokens = othertokens[othertokens.index != index]\n",
    "    #print(othertokens)\n",
    "    \n",
    "    for index, otherword in othertokens.iterrows():\n",
    "        # find the wordnet distance between these two wordnet senses\n",
    "        synset1 = row.lemma.synset()\n",
    "        synset2 = otherword.lemma.synset()\n",
    "        \n",
    "        wup_sim = synset1.wup_similarity(synset2)\n",
    "        wup_sims.append(wup_sim)\n",
    "        cossim = 1 - cosine(row.single_prototype_model_preds, otherword.single_prototype_model_preds)\n",
    "        cossine_sims.append(cossim)\n",
    "        #print(synset1)\n",
    "        #print(synset2)\n",
    "        #print(wup_sim)\n",
    "        #print(cossim)\n",
    "\n",
    "# calculate Pearson's correlation\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "\n",
    "corr, p = pearsonr(wup_sims, cossine_sims)\n",
    "print('Pearsons correlation: %.3f, p-value: %s'  % (corr, p))\n",
    "\n",
    "corr, p = spearmanr(wup_sims, cossine_sims)\n",
    "print('Spearmans correlation: %.3f, p-value: %s'  % (corr, p))  \n",
    "\n",
    "\"\"\"\n",
    "do the correlation:\n",
    "\"\"\"\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pyplot.scatter\n",
    "pyplot.show()\n",
    "\n",
    "plt.scatter(wup_sims, cossine_sims)\n",
    "plt.title(\"Wordnet similarity of homonymous senses plotted against cosine similarity of predicted vectors of two tokens in semantic feature space\")\n",
    "plt.xlabel(\"Wu and Palmer Similarity\")\n",
    "plt.ylabel(\"Cosine Similarity\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the analysis for the non-contextual model (trained on GloVe)\n",
    "\n",
    "Here we expect to see no correlation, because the model should be making the same prediction for every token of a word form, irrespective of the surrounding context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average cosine between gold and predicted feature norms: 0.2970614465680318\n",
      "correlation between gold and predicted vectors: 0.087274661537174 \n",
      "total number of predictions:  55\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "first we need to make the predictions, which we havent generated yet. we already have a trained model, called 'glove_model'\n",
    "\"\"\"\n",
    "\n",
    "correlations = []\n",
    "cosines = []\n",
    "top_k_precs = []\n",
    "n = 0\n",
    "\n",
    "glove_model_predictions = []\n",
    "\n",
    "for cue_word, lemma, context in data:\n",
    "    n +=1\n",
    "    singular = lemma.name()\n",
    "    plural = pluralize(singular)\n",
    "\n",
    "    gold_vector = norms.get_feature_vector(singular)\n",
    "    gold_feats = norms.get_features(singular)\n",
    "    k = len(gold_feats)\n",
    "\n",
    "\n",
    "\n",
    "    try:\n",
    "        predicted_vector = glove_model.predict(singular)\n",
    "        top_k =  glove_model.predict_top_n_features(singular, k)\n",
    "    except:\n",
    "        predicted_vector = glove_model.predict(plural)\n",
    "        top_k =  glove_model.predict_top_n_features(plural, k)\n",
    "\n",
    "    glove_model_predictions.append(predicted_vector)\n",
    "    cos = 1 - cosine(predicted_vector, gold_vector)\n",
    "    cosines.append(cos)      \n",
    "\n",
    "    #num_in_top_k = len(set(top_k).intersection(set(gold_feats)))\n",
    "    #top_k_prec = num_in_top_k / k\n",
    "    #top_k_precs.append(top_k_prec)\n",
    "\n",
    "    corr, p = spearmanr(predicted_vector, gold_vector)\n",
    "    correlations.append(corr)\n",
    "\n",
    "    #print(\"cosine: %f\" % cos)\n",
    "    #print(\"precison: %f\" % prec)\n",
    "    #print(\"correlation: %f\" % corr)\n",
    "    #print(\"top k acc: %f\" % top_k_prec)\n",
    "\n",
    "print(\"Average cosine between gold and predicted feature norms: %s\" % np.average(cosines))\n",
    "#print(\"average Percentage (%) of gold gold-standard features retrieved in the top 10 features of the predicted vector: \", top_10_prec)\n",
    "#print(\"average Percentage (%) of gold gold-standard features retrieved in the top 20 features of the predicted vector: \", top_20_prec)\n",
    "#print(\"Average % @k (derby metric)\", np.average(top_k_precs))\n",
    "#print(\"Percentage (%) of test items that retrieve their gold-standard vector in the top 10 neighbours of their predicted vector: %f\" % top_20_acc)\n",
    "print(\"correlation between gold and predicted vectors: %s \" % np.average(correlations))\n",
    "\n",
    "print(\"total number of predictions: \", n)\n",
    "\n",
    "\n",
    "df['glove_predictions'] = glove_model_predictions\n",
    "\n",
    "#df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearsons correlation: nan, p-value: nan\n",
      "Spearmans correlation: nan, p-value: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/site-packages/scipy/stats/stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n",
      "/usr/local/lib/python3.8/site-packages/scipy/stats/stats.py:4196: SpearmanRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(SpearmanRConstantInputWarning())\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "wup_sims = []\n",
    "cossine_sims = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    word = row.label\n",
    "    \n",
    "    # select other examples of this token\n",
    "    othertokens = df[df.label == word]\n",
    "    # filter out the token itself\n",
    "    othertokens = othertokens[othertokens.index != index]\n",
    "    #print(othertokens)\n",
    "    \n",
    "    for index, otherword in othertokens.iterrows():\n",
    "        # find the wordnet distance between these two wordnet senses\n",
    "        synset1 = row.lemma.synset()\n",
    "        synset2 = otherword.lemma.synset()\n",
    "        \n",
    "        wup_sim = synset1.wup_similarity(synset2)\n",
    "        wup_sims.append(wup_sim)\n",
    "        cossim = 1- cosine(row.glove_predictions, otherword.glove_predictions)\n",
    "        cossine_sims.append(cossim)\n",
    "        #print(synset1)\n",
    "        #print(synset2)\n",
    "        #print(wup_sim)\n",
    "        #print(cossim)\n",
    "\n",
    "# calculate Pearson's correlation\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "\n",
    "corr, p = pearsonr(wup_sims, cossine_sims)\n",
    "print('Pearsons correlation: %.3f, p-value: %s'  % (corr, p))\n",
    "\n",
    "corr, p = spearmanr(wup_sims, cossine_sims)\n",
    "print('Spearmans correlation: %.3f, p-value: %s'  % (corr, p))  \n",
    "\n",
    "\"\"\"\n",
    "do the correlation:\n",
    "\"\"\"\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pyplot.scatter\n",
    "pyplot.show()\n",
    "\n",
    "plt.scatter(wup_sims, cossine_sims)\n",
    "plt.title(\"Wordnet similarity of homonymous senses plotted against cosine similarity of predicted vectors of two tokens in semantic feature space\")\n",
    "plt.xlabel(\"Wu and Palmer Similarity\")\n",
    "plt.ylabel(\"Cosine Similarity\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_list = []\n",
    "word_indexer = Indexer()\n",
    "with open(\"data/glove.6B/glove.6B.300d.txt\", 'r') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        vector = np.asarray(values[1:], \"float32\")\n",
    "        embeddings_list.append([vector])\n",
    "\n",
    "        #print(embeddings_dict)\n",
    "        #raise Exception(\"hfelfnl\")\n",
    "        word_indexer.add_and_get_index(word)\n",
    "\n",
    "embs = MultiProtoTypeEmbeddings(word_indexer, np.array(embeddings_list), 0, 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the analysis on the PLSR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
