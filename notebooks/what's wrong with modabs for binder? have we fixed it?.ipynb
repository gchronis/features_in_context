{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9e198b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../src/\")\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from nltk.corpus import semcor\n",
    "#from nltk.tree import Tree\n",
    "#import itertools\n",
    "#import random\n",
    "import pandas as pd\n",
    "import torch\n",
    "from bert import *\n",
    "from feature_data import *\n",
    "from multiprototype import *\n",
    "import classifier_main\n",
    "import csv\n",
    "from nltk.corpus.reader.wordnet import Lemma\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "import inflect\n",
    "import os\n",
    "from scipy.stats import spearmanr, pearsonr\n",
    "import re\n",
    "from src.utils import *\n",
    "\n",
    "from scipy import spatial\n",
    "from sklearn.preprocessing import normalize\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5459593",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_pretrained_bert.modeling:loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /Users/gabriellachronis/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n",
      "INFO:pytorch_pretrained_bert.modeling:extracting archive file /Users/gabriellachronis/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /var/folders/9m/vzvx58rs51v_x5nm620fz4xr0000gn/T/tmpdyqb66ts\n",
      "INFO:pytorch_pretrained_bert.modeling:Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "INFO:pytorch_pretrained_bert.tokenization:loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /Users/gabriellachronis/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n"
     ]
    }
   ],
   "source": [
    "bert = BERTBase()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d4a69b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = '../trained_models/model.modabs.binder.1k.mu1_1.mu2_0.1.mu3_0.001.mu4_5.nnk_4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7af72e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "617c26d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = ['lamb', 'bullet', 'crayon', 'nylons', 'blackbird']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36d819d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicting features for  lamb\n",
      "[ 0.99441347  0.66744632  0.14816417 -0.29749899 -0.44161325  0.65296208\n",
      "  0.99744482  0.30307693  0.11530195 -0.03963592 -0.21354312 -0.07555666\n",
      "  0.15861231 -0.4735749  -1.10418454]\n",
      "calculating similarities with neighbors\n",
      "10.877787734202405 324\n",
      "nearest neighbor in graph:  pig_0\n",
      "predicting features for  lamb\n",
      "[ 0.99441347  0.66744632  0.14816417 -0.29749899 -0.44161325  0.65296208\n",
      "  0.99744482  0.30307693  0.11530195 -0.03963592 -0.21354312 -0.07555666\n",
      "  0.15861231 -0.4735749  -1.10418454]\n",
      "calculating similarities with neighbors\n",
      "10.877787734202405 324\n",
      "nearest neighbor in graph:  pig_0\n",
      "['Motion', 'Smell', 'Taste', 'Audition', 'Weight', 'Color', 'Shape', 'Biomotion', 'Sound', 'Vision']\n",
      "[2.1596861  0.62461746 0.26265701 1.67315974 1.03540454 1.09715834\n",
      " 0.67168715 1.47126177 2.25730077 0.93037109 0.88620692 2.12018091\n",
      " 0.74286481 0.94159584 1.03966581 0.62593199 1.0813739  1.62087611\n",
      " 0.12895818 1.70558878 1.37495458 0.71224535 1.28594648 2.14047793\n",
      " 0.17002382 0.41660318 1.53528671 1.47154971 0.47724769 0.32210155\n",
      " 0.37708843 0.18862799 0.3875656  1.19349215 0.28105159 0.44398067\n",
      " 0.17898012 0.17989256 0.05196835 0.17365523 0.25121573 0.10414586\n",
      " 0.16056228 0.09797615 0.46370787 0.06555578 0.117362   0.0517187\n",
      " 0.87746075 0.54014241 0.8495167  0.61339733 0.7552311  0.14151161\n",
      " 0.10967495 0.51714056 0.26055777 0.35938618 0.19923366 0.49246678\n",
      " 1.18334696 0.43148289]\n",
      "predicting features for  bullet\n",
      "[ 1.01469038 -0.54340926  0.10346673 -0.15355669  0.03017233 -0.47841201\n",
      "  0.0103924   0.7777149  -0.24989003  0.14794748 -0.39991804 -0.15734423\n",
      " -0.08530348  0.40991076 -1.04207403]\n",
      "calculating similarities with neighbors\n",
      "12.95991888215059 329\n",
      "nearest neighbor in graph:  rocket_0\n",
      "predicting features for  bullet\n",
      "[ 1.01469038 -0.54340926  0.10346673 -0.15355669  0.03017233 -0.47841201\n",
      "  0.0103924   0.7777149  -0.24989003  0.14794748 -0.39991804 -0.15734423\n",
      " -0.08530348  0.40991076 -1.04207403]\n",
      "calculating similarities with neighbors\n",
      "12.95991888215059 329\n",
      "nearest neighbor in graph:  rocket_0\n",
      "['Motion', 'Audition', 'Path', 'Attention', 'Loud', 'Fast', 'Shape', 'Large', 'Weight', 'Vision']\n",
      "[1.94358426 0.98529871 0.31007599 0.68473982 0.6938155  1.92560076\n",
      " 0.09967219 1.64503251 0.24687289 1.84962007 0.23994575 1.89084098\n",
      " 0.04661226 0.04823496 0.4009428  1.29335652 1.04191804 1.91662653\n",
      " 0.21794883 1.71740606 1.87184068 0.79875368 0.60331056 1.57462065\n",
      " 0.09464851 0.04805576 0.0211374  0.33616423 0.03101143 0.28194237\n",
      " 0.12244161 0.27497369 1.68831385 1.37015148 0.08802655 0.23025177\n",
      " 0.92099819 0.24048782 0.54727352 0.74680352 0.45329617 0.60218399\n",
      " 1.03177432 0.54848393 0.15770199 0.25736397 0.04159148 0.08418515\n",
      " 1.03622972 1.11124617 0.6242723  0.16927937 0.44509438 0.10108195\n",
      " 0.06881834 0.04356833 0.38591672 0.62534801 0.33697405 0.13214479\n",
      " 1.79761671 1.17410063]\n",
      "predicting features for  crayon\n",
      "[ 0.37705096  0.25009722 -0.16348471  0.60105197  1.17971833 -0.11236203\n",
      " -0.65268355  0.50939802 -0.43852876  0.23728491 -0.12092584 -0.08562424\n",
      "  0.107039    0.35841534 -0.26944147]\n",
      "calculating similarities with neighbors\n",
      "10.580504593838343 162\n",
      "nearest neighbor in graph:  sandpaper_0\n",
      "predicting features for  crayon\n",
      "[ 0.37705096  0.25009722 -0.16348471  0.60105197  1.17971833 -0.11236203\n",
      " -0.65268355  0.50939802 -0.43852876  0.23728491 -0.12092584 -0.08562424\n",
      "  0.107039    0.35841534 -0.26944147]\n",
      "calculating similarities with neighbors\n",
      "10.580504593838343 162\n",
      "nearest neighbor in graph:  sandpaper_0\n",
      "['Color', 'Small', 'Sound', 'Shape', 'Pattern', 'Weight', 'UpperLimb', 'Texture', 'Touch', 'Vision']\n",
      "[2.13688273 0.38344664 0.46430101 1.26212593 2.00630185 0.23048546\n",
      " 1.36290838 0.67441869 0.04293168 0.44278147 0.20252121 1.37095844\n",
      " 0.04571853 0.0123241  2.13804364 0.41168291 2.25981578 1.914668\n",
      " 0.28699864 1.0470975  0.81994461 0.44252273 0.36417655 1.30988536\n",
      " 0.23826823 0.00849616 0.2249263  0.40517867 0.07710894 2.06517136\n",
      " 0.02879329 0.08511393 0.51527797 0.81273395 0.61835581 0.63194094\n",
      " 0.81079168 0.21094299 0.13251288 0.24965093 0.22246202 0.28275741\n",
      " 0.83173926 0.16275628 0.05643702 0.06466475 0.09774531 0.09672574\n",
      " 1.0911464  0.430876   0.36170988 0.31194257 0.20280195 0.02069042\n",
      " 0.0085364  0.08731514 0.02273765 0.0502177  0.55385545 0.22352076\n",
      " 0.21330481 0.13581997]\n",
      "predicting features for  nylons\n",
      "[ 0.87506026 -0.28650017  0.1026062   0.7877773   0.58784706  0.68984514\n",
      " -0.68505678  0.11159241 -0.41402141  0.15734377 -0.20222843  0.15869957\n",
      " -0.56034664 -0.01302221 -0.72045698]\n",
      "calculating similarities with neighbors\n",
      "11.155994499070026 162\n",
      "nearest neighbor in graph:  sandpaper_0\n",
      "predicting features for  nylons\n",
      "[ 0.87506026 -0.28650017  0.1026062   0.7877773   0.58784706  0.68984514\n",
      " -0.68505678  0.11159241 -0.41402141  0.15734377 -0.20222843  0.15869957\n",
      " -0.56034664 -0.01302221 -0.72045698]\n",
      "calculating similarities with neighbors\n",
      "11.155994499070026 162\n",
      "nearest neighbor in graph:  sandpaper_0\n",
      "['Color', 'Small', 'Sound', 'Shape', 'Pattern', 'Weight', 'UpperLimb', 'Texture', 'Touch', 'Vision']\n",
      "[2.13688273 0.38344664 0.46430101 1.26212593 2.00630185 0.23048546\n",
      " 1.36290838 0.67441869 0.04293168 0.44278147 0.20252121 1.37095844\n",
      " 0.04571853 0.0123241  2.13804364 0.41168291 2.25981578 1.914668\n",
      " 0.28699864 1.0470975  0.81994461 0.44252273 0.36417655 1.30988536\n",
      " 0.23826823 0.00849616 0.2249263  0.40517867 0.07710894 2.06517136\n",
      " 0.02879329 0.08511393 0.51527797 0.81273395 0.61835581 0.63194094\n",
      " 0.81079168 0.21094299 0.13251288 0.24965093 0.22246202 0.28275741\n",
      " 0.83173926 0.16275628 0.05643702 0.06466475 0.09774531 0.09672574\n",
      " 1.0911464  0.430876   0.36170988 0.31194257 0.20280195 0.02069042\n",
      " 0.0085364  0.08731514 0.02273765 0.0502177  0.55385545 0.22352076\n",
      " 0.21330481 0.13581997]\n",
      "predicting features for  blackbird\n",
      "[ 0.19835691 -0.26989769  0.20713212  0.07631599  1.18570936  0.70383808\n",
      "  0.12653709  0.78838764 -0.79630775 -0.01981011 -0.0343557  -0.3067641\n",
      "  0.1258918   0.01801877 -0.74435992]\n",
      "calculating similarities with neighbors\n",
      "9.259736553482403 492\n",
      "nearest neighbor in graph:  goldfish_0\n",
      "predicting features for  blackbird\n",
      "[ 0.19835691 -0.26989769  0.20713212  0.07631599  1.18570936  0.70383808\n",
      "  0.12653709  0.78838764 -0.79630775 -0.01981011 -0.0343557  -0.3067641\n",
      "  0.1258918   0.01801877 -0.74435992]\n",
      "calculating similarities with neighbors\n",
      "9.259736553482403 492\n",
      "nearest neighbor in graph:  goldfish_0\n",
      "['Biomotion', 'Pleasant', 'Touch', 'Shape', 'Small', 'Texture', 'Pattern', 'Color', 'Weight', 'Vision']\n",
      "[0.66896511 0.24615972 0.16462213 0.50270312 0.44983755 0.19798161\n",
      " 0.40117857 0.31261379 0.35038428 0.24358114 0.15212518 0.6164311\n",
      " 0.07657514 0.10040853 0.39932584 0.25701466 0.4540504  0.53836731\n",
      " 0.06248273 0.17997226 0.14719321 0.08651016 0.11054546 0.23008824\n",
      " 0.05451575 0.02878784 0.32723296 0.34540825 0.21950868 0.23321606\n",
      " 0.06370521 0.09097225 0.16945324 0.33039816 0.1628002  0.19614562\n",
      " 0.1281118  0.06492156 0.05531785 0.06449191 0.06385394 0.08433275\n",
      " 0.11029605 0.07510317 0.06086347 0.03427736 0.03681329 0.02983569\n",
      " 0.25400335 0.17637382 0.36788907 0.10102081 0.257914   0.03499316\n",
      " 0.02761229 0.06376846 0.09093168 0.1062548  0.10148496 0.10710676\n",
      " 0.29260582 0.1823332 ]\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "        feats = model.predict_top_n_features(word, 10)\n",
    "        logits = model.predict(word)\n",
    "        print(feats)\n",
    "        print(logits)\n",
    "        #for feat in feats:\n",
    "        #    print(\"     \", feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "64635af9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicting features for  goldfish\n",
      "[ 0.3468882   0.101703    0.12439046  0.17424084  1.01339524  0.7082729\n",
      "  0.18190623  0.3048457  -0.58204003  0.00693567 -0.12144175 -0.25702423\n",
      " -0.20403546 -0.07402751 -0.39817009]\n",
      "calculating similarities with neighbors\n",
      "0.0 492\n",
      "nearest neighbor in graph:  goldfish_0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Biomotion',\n",
       " 'Pleasant',\n",
       " 'Touch',\n",
       " 'Shape',\n",
       " 'Small',\n",
       " 'Texture',\n",
       " 'Pattern',\n",
       " 'Color',\n",
       " 'Weight',\n",
       " 'Vision']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_top_n_features('goldfish', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d5d0cdf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10.877787734202405, 324)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.kd_tree\n",
    "\n",
    "embs = model.multipro_embeddings.get_embedding('lamb')\n",
    "emb =  np.average(embs, axis = 0)\n",
    "#emb = embs[0]\n",
    "model.kd_tree.query(emb)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfaeece2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5b53e450",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sandpaper_0'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.word_indexer.get_object(162)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c113ff10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Fearful',\n",
       " 'Motion',\n",
       " 'Shape',\n",
       " 'Short',\n",
       " 'Arousal',\n",
       " 'Harm',\n",
       " 'Bright',\n",
       " 'Fast',\n",
       " 'Attention',\n",
       " 'Vision']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_top_n_features('lightning', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c642c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating similarities with neighbors\n",
      "cranberry_2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1.96272683e+00, 6.74254111e-01, 9.05572504e-01, 2.16152502e+00,\n",
       "       9.87676989e-01, 8.56493933e-02, 2.08743455e+00, 2.91261919e-02,\n",
       "       4.37616450e-02, 7.31865907e-02, 1.07086494e-01, 1.83052922e+00,\n",
       "       2.89661562e-02, 4.19845650e-03, 1.01422855e+00, 7.38014056e-01,\n",
       "       1.76551591e+00, 2.17853579e+00, 5.62330977e-02, 2.61872933e-02,\n",
       "       2.42311960e-02, 4.69587934e-03, 6.95020357e-03, 2.81552772e-02,\n",
       "       9.79170919e-03, 1.31640116e-03, 2.31780681e+00, 1.56868706e+00,\n",
       "       1.70871816e+00, 6.00519489e-01, 4.43876167e-02, 1.37598497e-01,\n",
       "       9.83984507e-03, 4.28435365e-01, 4.97344384e-01, 9.97360509e-01,\n",
       "       1.04191254e-01, 1.07127051e-01, 2.00708246e-01, 2.04209961e-01,\n",
       "       8.76887827e-02, 5.25943198e-01, 5.45235556e-02, 8.08862930e-02,\n",
       "       1.54595590e-02, 9.55378591e-03, 3.29938495e-02, 4.71193439e-03,\n",
       "       1.09726004e+00, 5.22328344e-02, 1.26019034e+00, 1.81357368e-01,\n",
       "       7.45946199e-01, 3.83538544e-03, 2.11388791e-03, 1.88574482e-01,\n",
       "       4.19488906e-03, 6.51998265e-02, 2.70535177e-01, 2.42005306e-01,\n",
       "       3.81097717e-01, 2.55598164e-01])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_in_context('wart', \"I have a wart.\", bert=bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "152a033a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.31170148e-01, -1.90575443e-01,  1.85977315e-01,  6.97127034e-01,\n",
       "        1.46094282e+00,  2.07221250e-01,  2.08907897e-01,  8.56646741e-01,\n",
       "       -3.51709853e-01, -3.97673224e-02, -2.40990931e-01, -4.73089804e-01,\n",
       "       -1.23387396e-01, -2.08892323e-01, -4.38515419e-01,  1.00292381e+00,\n",
       "       -6.68874333e-02,  4.62083618e-01,  4.48083947e-01, -4.42358206e-02,\n",
       "        5.39698501e-01, -2.30750665e-01, -8.59343509e-01,  6.91173246e-01,\n",
       "        6.19649887e-01, -2.43919191e-01, -2.35159277e-01, -3.13078428e-01,\n",
       "        7.36616887e-02, -7.32403835e-01,  9.53161120e-02,  6.02608571e-01,\n",
       "       -2.31405084e-01, -2.75516622e-01, -5.39790342e-01, -4.33202262e-01,\n",
       "       -1.46759868e+00, -3.74136478e-01,  6.21872584e-01,  4.56339847e-02,\n",
       "       -4.57869073e-01, -6.34539584e-01,  5.31424855e-02,  4.42924261e-01,\n",
       "        1.97130715e-01, -4.72380618e-02, -4.31090266e-01, -6.85071597e-01,\n",
       "       -4.06007091e-01,  2.86481192e-01, -3.71659607e-01, -1.57514207e-01,\n",
       "       -8.27031334e-01, -9.08630232e-01, -2.29165035e-01,  3.64523063e-01,\n",
       "        8.20532176e-02,  1.19347330e-01,  3.61753687e-01,  4.31868364e-01,\n",
       "       -3.54217996e-01, -1.43071462e-01,  1.06958302e+00,  5.37518293e-01,\n",
       "       -4.94262512e-01, -2.15584710e-02,  7.34225313e-02, -5.45834571e-01,\n",
       "       -5.88171045e-01,  4.56059724e-01, -7.68514236e-01, -2.96677131e-01,\n",
       "        1.71818081e-01, -2.08565918e-01,  8.06030134e-01, -2.96240427e-02,\n",
       "       -8.00121049e-01, -5.29156446e-01,  3.92848988e-01,  8.53306929e-01,\n",
       "       -3.25125342e-01, -4.77320765e-01,  3.28967551e-01,  2.93967611e-01,\n",
       "       -1.78430180e-02,  6.21795297e-01,  2.76966689e-01,  3.45515927e-01,\n",
       "       -9.04551188e-01,  2.25067188e-02,  5.39248855e-02,  6.19583915e-01,\n",
       "        2.26174903e-01,  8.47555640e-02, -1.86199221e-01,  5.53468804e-01,\n",
       "       -1.96432437e-01,  8.04368489e-02,  5.61695864e-01, -5.74930236e-02,\n",
       "       -6.62726671e-01,  1.07409143e+00,  2.63543859e-01,  4.38143750e-01,\n",
       "       -3.54872733e-01,  2.82762351e-01,  9.41096395e-02,  4.42044735e-02,\n",
       "       -6.53180952e-02,  2.17862142e-02,  4.95685260e-01, -1.99959315e-01,\n",
       "        9.10394664e-02, -3.01932732e-01,  6.66521410e-01, -2.34519797e-01,\n",
       "       -1.96315020e-01,  1.45425049e-01,  7.54454682e-02, -2.69213113e-01,\n",
       "       -4.88151317e-01, -1.30474587e-01,  4.08651814e-01, -2.17665022e-01,\n",
       "       -1.66359931e-01,  1.08068043e-01, -4.18106208e-01,  7.79080967e-01,\n",
       "       -1.00054930e-01, -1.98820338e-01,  3.45208125e-01, -1.68558295e-01,\n",
       "        1.39415940e-01, -9.48132028e-02, -3.40979467e-01,  5.42195598e-01,\n",
       "       -3.01740249e-01, -4.33908006e-01,  5.39979875e-01, -1.46618277e-01,\n",
       "       -7.45952010e-01,  2.74192860e-01,  4.93826240e-01,  1.00491295e+00,\n",
       "        1.11801225e-01,  1.98914722e-01, -8.89089227e-01,  1.57095447e-01,\n",
       "       -5.82991106e-03,  9.99831458e-02,  2.94566582e-01,  5.55907081e-01,\n",
       "        8.52344315e-02,  2.44253948e-01,  6.15298400e-02,  5.71410845e-01,\n",
       "        7.87976642e-01,  3.19455946e-02,  3.13602204e-01, -2.96160865e-01,\n",
       "        3.04826791e-01, -7.50894447e-01,  4.19428507e-01,  2.17753048e-01,\n",
       "       -3.73130431e-01, -2.34775618e-01,  1.41632419e-01, -3.37336774e-01,\n",
       "       -8.03705851e-02,  7.48583992e-01, -7.72782763e-01,  2.96765324e-01,\n",
       "       -2.75628264e-01, -3.30092932e-02,  4.59165263e-02, -3.16124658e-01,\n",
       "        5.07051796e-02, -5.11326164e-01,  6.38540963e-01,  4.35761188e-01,\n",
       "        2.43315736e-01,  3.13131233e-01,  5.27480921e-01,  1.08975469e-01,\n",
       "        4.22501008e-01, -1.17789880e+00,  4.48861301e-01, -4.81824358e-01,\n",
       "        4.98351802e-01, -3.39077592e-01, -1.25266449e-03, -1.02707641e-01,\n",
       "        2.43504201e-01,  1.25454058e-01,  2.91690081e-01, -4.32346269e-01,\n",
       "       -7.92079133e-02, -2.71508438e-01,  2.61350224e-01, -7.00704575e-01,\n",
       "        4.57803071e-01,  6.34335180e-01, -1.73714745e-01,  2.68132423e-02,\n",
       "       -6.07518007e-02, -1.18574883e-01, -1.71527979e-01, -4.91754641e-01,\n",
       "       -3.45922800e-01, -4.01047488e-01, -3.15504851e-01,  6.43597504e-01,\n",
       "        4.38332220e-01, -1.04086796e-02, -5.66764782e-01, -4.03394401e-01,\n",
       "       -1.25246711e-01, -5.48005601e-01, -2.72834573e-01, -1.96391018e-03,\n",
       "       -6.43742065e-01,  3.46635456e-01, -1.96618112e-01,  2.03892474e-01,\n",
       "       -2.36654089e-01,  6.77793960e-01, -3.18464354e-01, -8.01056484e-01,\n",
       "       -1.79217895e-01, -4.84122559e-02,  5.76759549e-03, -1.01898390e-01,\n",
       "        2.71294564e-01, -1.54530150e-01, -1.33334273e-01,  5.58922092e-02,\n",
       "        4.62453276e-01,  4.95137657e-01,  8.14294179e-01,  5.46061178e-01,\n",
       "       -5.11277169e-02,  1.68739056e-01, -4.27993913e-01, -6.63688372e-01,\n",
       "        3.44057924e-01,  7.00214008e-01,  2.59687033e-01, -1.92816133e-01,\n",
       "       -5.37206630e-01, -4.22883789e-01,  4.02150502e-02,  4.06541278e-01,\n",
       "        8.35590793e-02, -1.07356218e+00,  6.33550366e-01,  7.43524656e-02,\n",
       "       -1.09279508e-01,  3.95373379e-02,  4.32487716e-01,  1.07925371e+00,\n",
       "        2.70610924e-03, -5.96843352e-01,  1.43268369e-02,  3.48711796e-01,\n",
       "       -4.01615947e-01, -1.61408443e-01,  2.22847459e-01, -2.13186378e-01,\n",
       "        1.51112956e-01,  5.12840370e-01, -2.88244826e-02, -6.49094308e-02,\n",
       "       -4.55181112e-01, -7.12575267e-03, -6.72530125e-01, -7.84733355e-01,\n",
       "       -7.27487266e-01,  1.48680285e-01,  2.58628577e-02, -4.34724132e-01,\n",
       "        4.28093293e-01,  5.19320329e-01, -1.09606591e-01, -9.79297111e-03,\n",
       "       -8.61748278e-01,  2.67718732e-02,  4.90652502e-01,  7.35938321e-01,\n",
       "       -8.54111771e-01,  7.86030069e-02, -4.32389875e-02,  4.99693871e-01,\n",
       "       -6.55173401e-01,  3.02244112e-01, -1.74101709e-02,  1.51589155e-01,\n",
       "       -1.21094217e-01,  9.17906314e-02,  1.25577656e-01,  5.63934068e-01,\n",
       "        2.57845754e-01,  3.09388027e-01,  1.46208823e-01,  3.97658984e-01,\n",
       "       -6.37952648e-02,  2.30151298e-01,  3.09999292e-01, -7.53146390e-01,\n",
       "       -4.44016854e+00, -8.52416903e-02, -3.39110424e-01,  1.94055277e-01,\n",
       "        5.98851989e-01, -4.66923386e-01, -1.10984993e+00, -5.11596513e-02,\n",
       "        2.12945019e-01,  8.14606786e-01, -2.08653164e-01, -3.91975562e-01,\n",
       "        9.02056932e-01, -7.52695675e-02,  5.35912082e-01, -9.74835018e-01,\n",
       "        1.43839312e+00, -1.87707854e-01,  7.10957885e-01,  3.24061225e-01,\n",
       "       -3.77217496e-01, -3.50890959e-01, -2.02099439e-01,  7.47559985e-01,\n",
       "        2.59854878e-01,  3.78201477e-01, -2.81479180e-01, -3.65101414e-01,\n",
       "       -3.32478785e-01, -3.59036028e-04,  6.70321435e-02, -9.15341794e-01,\n",
       "       -3.35609307e-01, -4.76981660e-01,  1.08479042e-01,  8.87554839e-01,\n",
       "       -3.30817759e-01, -1.36936385e-01,  2.14585721e-01,  7.28978192e-02,\n",
       "       -1.52733276e-01,  5.15993545e-01,  3.24972520e-02, -5.05775193e-01,\n",
       "       -2.06206600e-01, -1.21733097e-01, -2.76639720e-01, -5.65048349e-01,\n",
       "       -2.63575507e-01,  2.84574583e-01,  3.43497659e-01,  3.46335868e-01,\n",
       "       -7.00777094e-01, -1.26017995e-01,  5.47744681e-01,  6.68003678e-01,\n",
       "        1.03998504e+00, -1.73623823e-02,  2.43738721e-01, -4.58655397e-01,\n",
       "       -1.00803979e+00, -2.86994070e-01, -5.93194515e-01,  6.47339483e-01,\n",
       "        7.04045931e-01,  1.48383334e-01, -1.19908500e+00,  6.48392826e-01,\n",
       "        5.35424829e-01, -2.99234716e-01,  1.85995693e-01, -4.56251120e-01,\n",
       "        1.25106966e-01, -3.53223777e+00,  2.19158046e-01, -1.29621637e-02,\n",
       "       -4.38755391e-01, -3.64573245e-01, -1.12150812e+00, -2.33982597e-01,\n",
       "       -3.70638877e-01, -5.95424483e-01,  3.41175323e-01, -1.11608468e-01,\n",
       "       -2.36211687e-01,  1.09445040e-01, -1.94491800e-02, -2.22633394e-01,\n",
       "       -4.57151939e-01,  2.19559590e-01, -1.93065099e-01, -5.32208532e-01,\n",
       "        3.12267631e-01, -8.10973480e-02,  6.93785238e-02,  5.12159934e-01,\n",
       "        3.21320762e-01, -2.23699602e-01, -7.03607341e-01, -1.52989047e-01,\n",
       "       -3.53190886e-02,  4.41854571e-02,  9.31567550e-01, -5.04364421e-01,\n",
       "       -7.30471690e-01, -1.53515625e-01, -5.59243997e-01,  4.11259240e-01,\n",
       "        2.42361253e-01,  1.26375809e-01,  3.18489710e-01, -3.38188260e-01,\n",
       "        2.81707322e-02, -1.94286083e-02, -6.42908663e-01, -2.43059424e-01,\n",
       "        3.18444560e-01, -1.37632946e-01, -5.68955978e-01, -4.63356808e-01,\n",
       "       -1.05786618e+00,  1.30614376e-01, -2.53236857e-01, -2.46691443e-01,\n",
       "        6.49422755e-02,  7.87409325e-01,  7.11889078e-01,  4.79709069e-01,\n",
       "       -6.51666880e-01, -1.05445812e-01,  1.91898912e-01, -2.42680588e-01,\n",
       "       -8.10142299e-01, -7.20529894e-01,  3.26985965e-01, -6.80824836e-01,\n",
       "        4.80986893e-01, -6.78588847e-01, -1.47949727e+00, -2.97996634e-01,\n",
       "       -2.27283044e-01, -9.69177206e-01,  6.57439391e-01,  6.00518187e-01,\n",
       "       -7.26815641e-01,  2.34998907e-01,  5.49046437e-01, -2.36102124e-01,\n",
       "       -4.36320335e-01,  5.65981383e-01, -7.59864569e-01,  7.05745762e-01,\n",
       "        8.75015259e-02, -5.57179675e-01, -1.76426095e-01, -2.67686447e-01,\n",
       "        2.40975469e-01,  4.38372046e-01, -2.76412740e-01, -6.53546939e-01,\n",
       "       -1.47013940e-01,  3.67894600e-01, -4.65511739e-01,  1.67173447e-01,\n",
       "       -3.45265413e-01,  2.36885823e-01,  5.08976857e-01, -2.74050698e-01,\n",
       "       -4.77165530e-02,  9.99034921e-01,  4.65231177e-01, -1.09576513e-01,\n",
       "       -1.17427635e+00,  6.70838485e-01, -3.93818967e-01,  1.40539495e-03,\n",
       "        2.75658389e-01, -1.35923215e+00, -3.79311045e-01,  5.60400387e-01,\n",
       "       -9.85865772e-01,  2.65322526e-02, -3.22168926e-01,  2.88749461e-02,\n",
       "        2.19992692e-01, -4.91327246e-01,  5.82721442e-01, -3.94809147e-01,\n",
       "       -8.59996639e-02, -1.42548526e-01,  2.05698681e-01,  4.04744258e-01,\n",
       "        8.52491895e-01, -3.40495830e-01, -1.61883282e-01, -2.88698350e-01,\n",
       "       -3.35943346e-01,  1.60111588e-01, -1.49889772e-01, -1.93667484e-01,\n",
       "       -1.29417110e-01, -8.67028217e-01, -7.49504566e-01, -6.45643890e-01,\n",
       "        3.50053680e-01,  8.71126652e-02,  6.70240978e-01,  5.52158296e-01,\n",
       "        2.69330988e-01,  2.20729065e-01,  4.74010155e-01, -5.96000562e-01,\n",
       "       -1.56394775e-01, -1.14119086e-01,  6.20535543e-01,  6.16111368e-01,\n",
       "       -1.39644243e-01,  1.40991159e-01, -1.80770889e-01, -2.72552212e-01,\n",
       "        3.84179731e-01,  2.87061925e-01, -3.83376613e-01,  2.40310416e-01,\n",
       "        7.15495199e-01,  3.02439903e-01,  8.68329485e-01, -4.57432747e-01,\n",
       "       -2.97836761e-01,  9.10809994e-01,  5.75823014e-01, -6.49049940e-02,\n",
       "       -7.08861897e-02, -1.91307642e-01,  1.26886480e-01, -6.20601118e-01,\n",
       "       -1.69484839e-01,  3.87184074e-02,  3.21481188e-01, -1.12154027e-01,\n",
       "        7.53869573e-01,  3.45762824e-01,  5.95573316e-01, -3.77598464e-01,\n",
       "       -1.19009519e+00, -2.58175532e-01,  6.24906401e-01, -9.18362538e-01,\n",
       "        2.92346984e-01,  8.57061068e-01,  5.11664261e-01, -4.23664603e-01,\n",
       "        5.83445231e-02, -8.64693105e-01, -9.35050944e-02,  3.47260669e-01,\n",
       "        2.18800373e-01,  3.82248948e-01, -2.98011541e-01,  1.82173931e-01,\n",
       "       -3.81775846e-01, -3.28479906e-01, -1.74728124e-01,  2.72125542e-01,\n",
       "        5.98840912e-02, -1.52440230e-01,  1.70388944e-02,  5.44774632e-01,\n",
       "       -7.52513965e-01, -6.30717625e-02,  9.29037767e-02, -1.01860861e+00,\n",
       "       -3.30474223e-01, -1.61696037e-01,  6.36946370e-01,  1.32384454e-01,\n",
       "       -3.55543775e-01, -4.41377183e-01,  3.43485872e-01, -4.27421133e-01,\n",
       "        5.02212892e-02, -3.04907935e-01,  5.05031586e-01,  1.08568355e-01,\n",
       "        4.02820473e-01, -1.97920322e-01, -3.73980602e-01, -5.55349072e-01,\n",
       "        7.38814473e-01,  7.00479845e-01, -2.08246534e-01, -7.45567222e-01,\n",
       "       -5.00656794e-01,  1.62121398e-01, -4.32085594e-01,  1.14764098e+00,\n",
       "       -1.35856975e-01,  8.73960455e-01,  7.11915433e-01, -2.22242599e-02,\n",
       "       -9.13225671e-01, -3.22750285e-01, -5.04287690e-01,  1.19001092e-01,\n",
       "       -2.42174784e-01,  3.21728813e-01,  1.06034922e-01,  1.51505714e-01,\n",
       "       -8.68617256e-01, -6.69262707e-01, -2.93202055e-01, -2.21861983e-01,\n",
       "        7.12972333e-01, -5.13583064e-01,  2.86924198e-01,  1.42805295e-01,\n",
       "       -2.12790982e-01,  1.55641645e-01,  5.69901834e-01,  7.25565404e-01,\n",
       "        1.84359973e-01,  5.25129543e-02,  2.62946914e-01,  1.18509895e-01,\n",
       "       -5.04585157e-02,  3.73629640e-01,  2.36081590e-01, -2.29288084e-01,\n",
       "       -6.74054101e-02, -8.77596656e-01, -5.68470940e-01,  4.98071745e-01,\n",
       "       -9.00976981e-04, -3.65716517e-01,  1.80808049e-01, -3.81934807e-01,\n",
       "       -1.53430432e-01, -2.30285451e-01, -7.00643500e-01, -2.18180165e-01,\n",
       "        1.81358481e-01,  2.37865095e-01,  5.42067061e-01, -3.62890944e-01,\n",
       "        5.55989405e-01, -2.73522235e-01, -1.09280114e-01, -3.68064721e-01,\n",
       "        3.85732283e-01,  5.71663588e-01, -3.34009623e-01, -6.90677683e-01,\n",
       "        1.76339348e-02, -4.53168531e-01,  5.09408275e-01, -7.23242561e-01,\n",
       "       -3.98099323e-01, -1.06967050e-01, -6.88847333e-01,  7.68050591e-01,\n",
       "       -5.52041342e-01, -3.65010843e-01,  1.14477436e-01, -6.56522880e-01,\n",
       "       -6.76551044e-01,  4.48700582e-01, -6.89252575e-01, -8.73610695e-01,\n",
       "       -1.63472168e-01, -5.81458878e-02,  3.12701101e-01,  1.33994942e-02,\n",
       "        2.99874514e-01, -2.34479537e-01,  5.00670453e-01,  2.16313683e-01,\n",
       "       -1.97360116e-01,  7.84797668e-01,  4.08846503e-01,  2.54446665e-02,\n",
       "       -8.57524753e-01, -1.30597432e-01,  1.88482781e-01,  2.45113542e-01,\n",
       "       -5.72584709e-01,  7.43049840e-01, -1.43068366e-01,  3.10207361e-01,\n",
       "       -5.96685847e-01, -4.86703411e-01, -5.67156201e-03,  1.56775235e-01,\n",
       "        4.16980527e-01,  1.29791844e+00, -1.14506496e-01, -2.44018535e-02,\n",
       "        1.19946223e+00,  3.58292783e-01, -6.13600284e-01, -2.71430391e-01,\n",
       "       -2.89985225e-01,  2.75224616e-01, -1.64998894e-02, -2.51484414e-01,\n",
       "       -1.33638618e-01, -8.40551779e-02, -4.86924797e-01,  3.95726154e-01,\n",
       "       -6.60704990e-01,  3.17675510e-01, -3.25438825e-01, -3.57554764e-01,\n",
       "       -4.16750292e-01, -3.48270252e-01,  2.99402580e-01, -3.53183006e-01,\n",
       "       -6.54822290e-01,  2.17475628e-01, -6.95080976e-01,  2.04331289e-01,\n",
       "       -2.74443140e-01, -1.17489103e+00, -6.09435121e-01,  2.90277272e-01,\n",
       "        2.85449433e-01,  2.04494373e+00,  2.85878188e-01, -2.56279291e-01,\n",
       "        2.98544084e-01,  2.24716358e-01,  4.95128065e-01,  8.36874386e-01,\n",
       "        4.31361740e-01, -4.77477451e-01, -7.85830935e-01,  5.80301652e-01,\n",
       "       -5.47642400e-01,  7.27671683e-01, -5.13735294e-01,  5.47297964e-01,\n",
       "        8.12057892e-01,  1.79403380e-01,  8.96806320e-01, -3.75574991e-01,\n",
       "       -4.76865167e-01, -2.88010443e-01,  6.76249246e-01,  9.90815330e-02,\n",
       "       -2.45045155e-01, -4.03961231e-01, -7.21004645e-01,  1.02839989e-01,\n",
       "        7.83050259e-02,  6.07556403e-01, -1.34244991e-01, -4.14671212e-01,\n",
       "        1.36942528e-02,  9.05653497e-01,  1.69387102e-01, -8.78324509e-01])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.multipro_embeddings.get_embedding('eggplant')[0]\n",
    "#model.kd_tree.query()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2ae1cb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating similarities with neighbors\n",
      "cranberry_2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Pleasant',\n",
       " 'Smell',\n",
       " 'Head',\n",
       " 'Texture',\n",
       " 'Small',\n",
       " 'Color',\n",
       " 'Shape',\n",
       " 'Weight',\n",
       " 'Taste',\n",
       " 'Vision']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_top_n_features_in_context('eggplant', \"I like eggplant.\", 10, bert=bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "048e858e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bagpipe_0', 'restaurant_0', 'driver_0', 'guilt_0', 'zoo_0', 'empty_0', 'bar_0', 'bay_0', 'television_0', 'clever_0', 'grievance_0', 'actor_0', 'priest_0', 'desk_0', 'love_0', 'drum_0', 'arm_0', 'matinee_0', 'protest_0', 'ran_0', 'riot_0', 'jealousy_0', 'chime_0', 'sin_0', 'bell_0', 'small_0', 'folly_0', 'jungle_0', 'night_0', 'snub_0', 'winter_0', 'deceit_0', 'island_0', 'computer_0', 'verb_0', 'stole_0', 'foot_0', 'soccer_0', 'satire_0', 'zone_0', 'dropped_0', 'crow_0', 'mouse_0', 'nose_0', 'camera_0', 'limousine_0', 'spaghetti_0', 'green_0', 'worth_0', 'company_0', 'awe_0', 'black_0', 'landslide_0', 'legality_0', 'dandelion_0', 'belch_0', 'cherry_0', 'saxophone_0', 'symphony_0', 'voter_0', 'key_0', 'xylophone_0', 'destroyed_0', 'rake_0', 'landed_0', 'dictation_0', 'election_0', 'cafeteria_0', 'dime_0', 'evening_0', 'rum_0', 'truce_0', 'denial_0', 'cranberry_0', 'hawk_0', 'used_0', 'train_0', 'flew_0', 'envy_0', 'ticket_0', 'banjo_0', 'council_0', 'broccoli_0', 'table_0', 'sum_0', 'hoe_0', 'pie_0', 'sun_0', 'whole_0', 'famous_0', 'excuse_0', 'bicycle_0', 'mob_0', 'injured_0', 'butterfly_0', 'parent_0', 'fiddle_0', 'cabbage_0', 'coffee_0', 'yellow_0', 'oration_0', 'subway_0', 'hope_0', 'stone_0', 'applause_0', 'celebrated_0', 'football_0', 'number_0', 'street_0', 'bonfire_0', 'salmon_0', 'semester_0', 'piano_0', 'faucet_0', 'trust_0', 'new_0', 'penguin_0', 'heroism_0', 'umbrella_0', 'funeral_0', 'plane_0', 'leg_0', 'oak_0', 'noun_0', 'stayed_0', 'school_0', 'lived_0', 'opened_0', 'dusty_0', 'tea_0', 'man_0', 'pineapple_0', 'cloud_0', 'spiritual_0', 'lab_0', 'finger_0', 'garden_0', 'handshake_0', 'comb_0', 'advice_0', 'malice_0', 'harp_0', 'moose_0', 'broke_0', 'mosquito_0', 'river_0', 'liked_0', 'megaphone_0', 'tomato_0', 'torment_0', 'lake_0', 'expensive_0', 'summer_0', 'carnival_0', 'hurricane_0', 'peaceful_0', 'saw_0', 'built_0', 'gave_0', 'tobacco_0', 'gunshot_0', 'worker_0', 'sandpaper_0', 'asparagus_0', 'white_0', 'mushroom_0', 'office_0', 'animosity_0', 'duck_0', 'family_0', 'gong_0', 'arrested_0', 'dangerous_0', 'beach_0', 'fixed_0', 'hailstorm_0', 'victim_0', 'old_0', 'joviality_0', 'bought_0', 'artist_0', 'big_0', 'tuba_0', 'eye_0', 'luck_0', 'bread_0', 'angry_0', 'fallacy_0', 'gratitude_0', 'kiss_0', 'tribute_0', 'bribe_0', 'vice_0', 'cash_0', 'stapler_0', 'apricot_0', 'church_0', 'hair_0', 'spatula_0', 'ivy_0', 'approached_0', 'soft_0', 'pumpkin_0', 'battle_0', 'bugle_0', 'ham_0', 'editor_0', 'met_0', 'couple_0', 'truck_0', 'cab_0', 'toe_0', 'hand_0', 'plum_0', 'cheese_0', 'listened (to)_0', 'flute_0', 'attribute_0', 'magazine_0', 'field_0', 'chocolate_0', 'ended_0', 'snake_0', 'squeal_0', 'rally_0', 'cabinet_0', 'hamster_0', 'mayor_0', 'bird_0', 'paradox_0', 'ball_0', 'ate_0', 'found_0', 'politician_0', 'heredity_0', 'walked_0', 'debate_0', 'loan_0', 'pea_0', 'moral_0', 'author_0', 'survived_0', 'rose_0', 'highway_0', 'explosion_0', 'speech_0', 'plot_0', 'threw_0', 'whale_0', 'reality_0', 'fate_0', 'festival_0', 'drank_0', 'book_0', 'shouted_0', 'dolphin_0', 'boy_0', 'embassy_0', 'spoke (to)_0', 'year_0', 'theater_0', 'teacher_0', 'boat_0', 'avalanche_0', 'infinity_0', 'fun_0', 'clue_0', 'tornado_0', 'blocked_0', 'blueberry_0', 'storm_0', 'honeymoon_0', 'vacation_0', 'played_0', 'quantity_0', 'ice_0', 'volcano_0', 'pilot_0', 'beer_0', 'pan_0', 'morning_0', 'apology_0', 'submarine_0', 'journalist_0', 'elephant_0', 'tulip_0', 'grief_0', 'tired_0', 'accident_0', 'college_0', 'lost_0', 'water_0', 'helped_0', 'dog_0', 'aggressive_0', 'patent_0', 'pen_0', 'ricochet_0', 'optimism_0', 'whine_0', 'choir_0', 'crib_0', 'era_0', 'trial_0', 'cucumber_0', 'newspaper_0', 'motive_0', 'policeman_0', 'insult_0', 'egg_0', 'home_0', 'window_0', 'bus_0', 'tiger_0', 'majority_0', 'team_0', 'tangerine_0', 'spring_0', 'kitchen_0', 'radish_0', 'patient_0', 'peace_0', 'bed_0', 'red_0', 'pig_0', 'laughed_0', 'sled_0', 'took_0', 'park_0', 'rocket_0', 'meeting_0', 'girl_0', 'clang_0', 'glass_0', 'hotel_0', 'put_0', 'intellect_0', 'chair_0', 'harmonica_0', 'barbecue_0', 'child_0', 'van_0', 'business_0', 'banker_0', 'hall_0', 'gum_0', 'cheetah_0', 'tourist_0', 'flower_0', 'corkscrew_0', 'escalator_0', 'plea_0', 'horse_0', 'long_0', 'embrace_0', 'thunder_0', 'dread_0', 'baseball_0', 'student_0', 'joke_0', 'party_0', 'doctor_0', 'store_0', 'minister_0', 'forest_0', 'airport_0', 'lightning_0', 'lemonade_0', 'apartment_0', 'bridge_0', 'fish_0', 'flood_0', 'camel_0', 'ketchup_0', 'grew_0', 'sailboat_0', 'diplomat_0', 'chestnut_0', 'went_0', 'drew_0', 'theme_0', 'cold_0', 'guard_0', 'woman_0', 'axe_0', 'fireworks_0', 'farmer_0', 'wealthy_0', 'hiked_0', 'chicken_0', 'car_0', 'elevator_0', 'lust_0', 'negotiated_0', 'downpour_0', 'interviewed_0', 'scientist_0', 'wanted_0', 'blue_0', 'perjury_0', 'activist_0', 'dead_0', 'woe_0', 'scream_0', 'damaged_0', 'planned_0', 'role_0', 'law_0', 'soldier_0', 'advantage_0', 'judge_0', 'problem_0', 'jam_0', 'lip_0', 'monkey_0', 'corn_0', 'elm_0', 'mountain_0', 'young_0', 'powerful_0', 'truth_0', 'wit_0', 'theory_0', 'criminal_0', 'toaster_0', 'shelves_0', 'carriage_0', 'turtle_0', 'sympathy_0', 'alligator_0', 'door_0', 'curse_0', 'witness_0', 'cyclone_0', 'day_0', 'cellphone_0', 'scissors_0', 'shoulder_0', 'joy_0', 'ambulance_0', 'left_0', 'power_0', 'fountain_0', 'lonely_0', 'parade_0', 'dinner_0', 'screech_0', 'chipmunk_0', 'hairbrush_0', 'clarinet_0', 'kicked_0', 'belief_0', 'happy_0', 'hot_0', 'audience_0', 'court_0', 'hospital_0', 'wonder_0', 'fed_0', 'stampede_0', 'trumpet_0', 'lawyer_0', 'jaw_0', 'shame_0', 'mustard_0', 'marched_0', 'accordion_0', 'cough_0', 'raspberry_0', 'friendly_0', 'slept_0', 'prairie_0', 'shiny_0', 'pencil_0', 'commander_0', 'agreement_0', 'heavy_0', 'mystery_0', 'analogy_0', 'mandolin_0', 'fence_0', 'delivered_0', 'tax_0', 'carrot_0', 'army_0', 'delirium_0', 'trombone_0', 'banana_0', 'eggplant_0', 'medicine_0', 'knowledge_0', 'mercy_0', 'goldfish_0', 'prison_0', 'rumor_0', 'muscle_0', 'tree_0', 'ant_0', 'engineer_0', 'sick_0', 'musical_0', 'scooter_0', 'hierarchy_0', 'watched_0', 'feather_0', 'feared_0', 'worked_0', 'farm_0', 'treaty_0', 'held_0', 'carried_0', 'honey_0', 'testimony_0', 'cathedral_0', 'circus_0', 'reporter_0', 'terrorist_0', 'wrote_0', 'bee_0', 'etiquette_0', 'dark_0', 'visited_0', 'jury_0', 'ire_0', 'fee_0', 'irony_0', 'businessman_0', 'keyboard_0', 'gasp_0', 'crossed_0', 'hygiene_0', 'loud_0', 'mouth_0', 'read_0']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.word_indexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cd4efd95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "488\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.47290126, 0.22699028, 0.08035515, 0.41039638, 0.29407955,\n",
       "       0.059381  , 0.36117564, 0.06790745, 0.06886969, 0.03547469,\n",
       "       0.05774522, 0.44821897, 0.0128413 , 0.024642  , 0.31319399,\n",
       "       0.19000451, 0.32533432, 0.40289222, 0.01401412, 0.03693731,\n",
       "       0.02778014, 0.0159645 , 0.0225674 , 0.05831063, 0.01016182,\n",
       "       0.00728875, 0.32683974, 0.28750357, 0.22595652, 0.21669962,\n",
       "       0.01443539, 0.04480074, 0.03379261, 0.2009119 , 0.191606  ,\n",
       "       0.14461531, 0.04641018, 0.06446503, 0.04355739, 0.05133219,\n",
       "       0.02448051, 0.0757761 , 0.0592469 , 0.0443634 , 0.00999563,\n",
       "       0.0134318 , 0.02374603, 0.0117896 , 0.21030497, 0.04866745,\n",
       "       0.28468243, 0.03837175, 0.20287386, 0.00879221, 0.0063505 ,\n",
       "       0.02623113, 0.01063226, 0.02403504, 0.06332732, 0.10110849,\n",
       "       0.12150125, 0.07932962])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# here is a copu of the predict function from modabs.py, for debugging\n",
    "\n",
    "def predicament(model, word: str):\n",
    "        labels = [word + '_' + str(i) for i in range(0, model.num_prototypes)]\n",
    "        #print(labels)\n",
    "        vectors = np.empty([model.num_prototypes, model.output_dims])\n",
    "        #print(vectors.shape)\n",
    "        for i in range(0,len(labels)):\n",
    "            label = labels[i]\n",
    "            #print(label)\n",
    "            #print(self.word_indexer.objs_to_ints)\n",
    "            word_index = model.word_indexer.index_of(label)\n",
    "            print(word_index)\n",
    "            #print(word_index)\n",
    "            vec = model.predictions[word_index]\n",
    "            #print(vec.shape)\n",
    "\n",
    "            vectors[i,:] = vec\n",
    "        #vectors = self.predictions[word_index:(word_index + self.num_prototypes), :]\n",
    "        #print(vectors.shape)\n",
    "        avg = np.average(vectors, axis=0)\n",
    "        return avg\n",
    "    \n",
    "predicament(model, 'eggplant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1105692e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.25565978, 0.04547585, 0.02691238, 0.04820498, 0.07585004,\n",
       "       0.07171238, 0.09937557, 0.08843739, 0.16135066, 0.06175159,\n",
       "       0.05333497, 0.16013099, 0.1543207 , 0.17885093, 0.13458334,\n",
       "       0.05276306, 0.10478829, 0.12434189, 0.02147458, 0.09850257,\n",
       "       0.04154495, 0.0264197 , 0.02597206, 0.07632457, 0.02222012,\n",
       "       0.14396524, 0.04843606, 0.04921625, 0.15691896, 0.22622066,\n",
       "       0.05074005, 0.04892288, 0.07090239, 0.12622128, 0.16942215,\n",
       "       0.08425869, 0.05372874, 0.03326537, 0.06549076, 0.09347617,\n",
       "       0.07675372, 0.1065434 , 0.15143853, 0.16815375, 0.19166436,\n",
       "       0.19968061, 0.1591993 , 0.16870069, 0.24861656, 0.06741136,\n",
       "       0.22169416, 0.04566761, 0.19292754, 0.06584526, 0.0507757 ,\n",
       "       0.0368286 , 0.04592472, 0.09765196, 0.18777226, 0.16316648,\n",
       "       0.19521484, 0.1911226 ])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is the issue, that words we haven't put in our model from the beginnning don't have an index and therefore \n",
    "# when we look them up the index is negative 1 which duhhhhh - we cannot predict them. \n",
    "\n",
    "# May 19, we have to start over with all of our modebs/ label propagation results\n",
    "\n",
    "\n",
    "predicament(model, 'blackbird')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6af12599",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eggplant_0\n",
      "[ 0.23117015 -0.19057544  0.18597732  0.69712703  1.46094282  0.20722125\n",
      "  0.2089079   0.85664674 -0.35170985 -0.03976732 -0.24099093 -0.4730898\n",
      " -0.1233874  -0.20889232 -0.43851542  1.00292381 -0.06688743  0.46208362\n",
      "  0.44808395 -0.04423582  0.5396985  -0.23075066 -0.85934351  0.69117325\n",
      "  0.61964989]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.47290126, 0.22699028, 0.08035515, 0.41039638, 0.29407955,\n",
       "       0.059381  , 0.36117564, 0.06790745, 0.06886969, 0.03547469,\n",
       "       0.05774522, 0.44821897, 0.0128413 , 0.024642  , 0.31319399,\n",
       "       0.19000451, 0.32533432, 0.40289222, 0.01401412, 0.03693731,\n",
       "       0.02778014, 0.0159645 , 0.0225674 , 0.05831063, 0.01016182,\n",
       "       0.00728875, 0.32683974, 0.28750357, 0.22595652, 0.21669962,\n",
       "       0.01443539, 0.04480074, 0.03379261, 0.2009119 , 0.191606  ,\n",
       "       0.14461531, 0.04641018, 0.06446503, 0.04355739, 0.05133219,\n",
       "       0.02448051, 0.0757761 , 0.0592469 , 0.0443634 , 0.00999563,\n",
       "       0.0134318 , 0.02374603, 0.0117896 , 0.21030497, 0.04866745,\n",
       "       0.28468243, 0.03837175, 0.20287386, 0.00879221, 0.0063505 ,\n",
       "       0.02623113, 0.01063226, 0.02403504, 0.06332732, 0.10110849,\n",
       "       0.12150125, 0.07932962])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's see... is this also a problem for predict in context?\n",
    "\n",
    "def predicament_in_context(model, word, sentence, bert, glove=False):\n",
    "    if glove:\n",
    "        return self.predict(word)\n",
    "    # generate bert vector for word\n",
    "    vec = bert.get_bert_vectors_for(word, sentence)\n",
    "    # get the layer we care about\n",
    "    vec = vec[8]\n",
    "\n",
    "    # reshape to be vertical\n",
    "    vec = vec.reshape(1, -1)\n",
    "    #print(\"after reshape\")\n",
    "    #print(vec.shape)\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    find the nearest neighbor to the input vector\n",
    "    \"\"\"\n",
    "    # TODO to predict the nearest neighbor by word we have to fix the counter to an indexer and retrain all the saved models =/\n",
    "\n",
    "    # find the closest input embedding to our context vector\n",
    "    label, vec = model.multipro_embeddings.find_nearest_neighbor(vec)\n",
    "\n",
    "    print(label)\n",
    "    print(vec[:25])\n",
    "    \n",
    "    # use the label to find the projection we have stored for that embedding\n",
    "    index = model.word_indexer.index_of(label)\n",
    "\n",
    "    logits = model.predictions[index]\n",
    "\n",
    "    return logits\n",
    "\n",
    "predicament_in_context(model, 'eggplant', 'The room was the color of eggplant.', bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "06c6c690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blackbird_0\n",
      "[ 0.19835691 -0.26989769  0.20713212  0.07631599  1.18570936  0.70383808\n",
      "  0.12653709  0.78838764 -0.79630775 -0.01981011 -0.0343557  -0.3067641\n",
      "  0.1258918   0.01801877 -0.74435992  0.56796731  0.05499426  0.58305214\n",
      " -0.31193427  0.11832664  0.46985487 -0.21807169 -0.52067759  0.42566902\n",
      "  0.42490983]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.25565978, 0.04547585, 0.02691238, 0.04820498, 0.07585004,\n",
       "       0.07171238, 0.09937557, 0.08843739, 0.16135066, 0.06175159,\n",
       "       0.05333497, 0.16013099, 0.1543207 , 0.17885093, 0.13458334,\n",
       "       0.05276306, 0.10478829, 0.12434189, 0.02147458, 0.09850257,\n",
       "       0.04154495, 0.0264197 , 0.02597206, 0.07632457, 0.02222012,\n",
       "       0.14396524, 0.04843606, 0.04921625, 0.15691896, 0.22622066,\n",
       "       0.05074005, 0.04892288, 0.07090239, 0.12622128, 0.16942215,\n",
       "       0.08425869, 0.05372874, 0.03326537, 0.06549076, 0.09347617,\n",
       "       0.07675372, 0.1065434 , 0.15143853, 0.16815375, 0.19166436,\n",
       "       0.19968061, 0.1591993 , 0.16870069, 0.24861656, 0.06741136,\n",
       "       0.22169416, 0.04566761, 0.19292754, 0.06584526, 0.0507757 ,\n",
       "       0.0368286 , 0.04592472, 0.09765196, 0.18777226, 0.16316648,\n",
       "       0.19521484, 0.1911226 ])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicament_in_context(model, 'blackbird', 'The room was the color of a blackbird.', bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2253bb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's see if we can fic both of these functions...so we can update the model code\n",
    "# leaving broken code above and copying to edit below\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0a6578dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.99441347  0.66744632  0.14816417 ... -0.09310469  0.01299667\n",
      "  -0.72792843]\n",
      " [ 1.01469038 -0.54340926  0.10346673 ... -0.24732851 -0.39735755\n",
      "  -0.85013201]\n",
      " [ 0.37705096  0.25009722 -0.16348471 ...  0.1304165   0.66947503\n",
      "  -0.7857151 ]\n",
      " [ 0.87506026 -0.28650017  0.1026062  ...  0.21925569 -0.02151393\n",
      "  -0.57753804]\n",
      " [ 0.19835691 -0.26989769  0.20713212 ... -0.24054401 -0.02871272\n",
      "  -0.94904848]]\n",
      "[[ 3.51490117e-03  2.35918752e-03  5.23708139e-04 ... -3.29092264e-04\n",
      "   4.59386348e-05 -2.57297047e-03]\n",
      " [ 3.41010250e-03 -1.82625294e-03  3.47723944e-04 ... -8.31204872e-04\n",
      "  -1.33541225e-03 -2.85706592e-03]\n",
      " [ 1.34441681e-03  8.91749260e-04 -5.82922789e-04 ...  4.65014415e-04\n",
      "   2.38708712e-03 -2.80155393e-03]\n",
      " [ 3.28645247e-03 -1.07600496e-03  3.85356784e-04 ...  8.23455751e-04\n",
      "  -8.07996018e-05 -2.16905211e-03]\n",
      " [ 7.94906590e-04 -1.08160313e-03  8.30072850e-04 ... -9.63969563e-04\n",
      "  -1.15064948e-04 -3.80327010e-03]]\n"
     ]
    }
   ],
   "source": [
    "# we're going to need to put a kdtree in the model to easily look up cosine; lets make a toy one\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "The ranking your would get with cosine similarity is equivalent\n",
    "to the rank order of the euclidean distance when you normalize all \n",
    "the data points first. So you can use a KD tree to the the k nearest neighbors with KDTrees,\n",
    "but you will need to recompute what the cosine similarity is.\n",
    "\"\"\"\n",
    "\n",
    "train_exs = ['lamb', 'bullet', 'crayon', 'nylons', 'blackbird']\n",
    "\n",
    "word_indexer = Indexer()\n",
    "num_samples = len(train_exs) * model.multipro_embeddings.num_prototypes\n",
    "X = np.empty([num_samples, model.multipro_embeddings.dim])\n",
    "i=0\n",
    "\n",
    "for word in train_exs:\n",
    "\n",
    "    # look up the embedding\n",
    "    emb = model.multipro_embeddings.get_embedding(word)\n",
    "\n",
    "    # iterate through the prototypes for each word\n",
    "    #print(emb.shape)        \n",
    "    for index in range(0, emb.shape[0]):\n",
    "        # this adds something to the index like 'apple_3' so we know what the prediction is for each thing\n",
    "        word_indexer.add_and_get_index(word + '_' + str(index))\n",
    "\n",
    "\n",
    "        # add vector to training xs\n",
    "        vector = emb[index, :]\n",
    "        #print(vector.shape)\n",
    "        X[i] = vector\n",
    "        i+=1\n",
    "\n",
    "        \n",
    "print(X)\n",
    "X_normed = normalize(X, axis=1, norm='l1')\n",
    "print(X_normed)\n",
    "\n",
    "model.kd_tree = spatial.KDTree(X)\n",
    "        #     print(\"done building kdtree for nneighbor queries for modabs model\")\n",
    "        #     d, i = self.kd_tree.query(vector, 1)\n",
    "        # vector = self.kd_tree.data[i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "2395de1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.kd_tree.m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "17be40d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def _find_nearest_neighbor(model, vector):\n",
    "    vector = np.array(vector)\n",
    "    vector = np.expand_dims(vector, axis=1)\n",
    "    print(\"calculating similarities with neighbors\")\n",
    "    print(vector[:10])\n",
    "    vector = normalize(vector, axis=0, norm='l1')\n",
    "    print(vector[:10])\n",
    "    vector = vector.reshape(1, -1)\n",
    "\n",
    "    distance, index = model.kd_tree.query(vector, 1)\n",
    "    \n",
    "    print(index)\n",
    "    neighbor = model.word_indexer.get_object(index[0])\n",
    "    \n",
    "    neighbor \n",
    "    print(neighbor)\n",
    "\n",
    "    return neighbor\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def predicament(model, word: str):\n",
    "        labels = [word + '_' + str(i) for i in range(0, model.num_prototypes)]\n",
    "        #print(labels)\n",
    "        vectors = np.empty([model.num_prototypes, model.output_dims])\n",
    "        #print(vectors.shape)\n",
    "        \n",
    "        \"\"\"\n",
    "        get prediction for each prototype; or,\n",
    "        get nearest neighbor of each prototype and get prediction for that\n",
    "        \"\"\"\n",
    "        for i in range(0,len(labels)):\n",
    "            label = labels[i]\n",
    "            #print(label)\n",
    "            #print(self.word_indexer.objs_to_ints)\n",
    "            word_index = model.word_indexer.index_of(label)\n",
    "            print(word_index)\n",
    "            \n",
    "            \"\"\"\n",
    "            if this word is not in the graph, we need to find the nearest vector\n",
    "            in the graph and use the predictions we have stored for that instead. \n",
    "            really, it seems we need more words in the graph for label prop to do its work the best\n",
    "            \"\"\"\n",
    "            if word_index == -1:\n",
    "                # get multipro vector\n",
    "                mpro_vec = model.multipro_embeddings.get_embedding(word)\n",
    "                # get vector at current index\n",
    "                mpro_vec = mpro_vec[i]\n",
    "                \n",
    "                \"\"\"\n",
    "                then, we need to calculate the similarity between this and all of the mpro embeddings in our model, on the fly\n",
    "                would help if we already had them stored in the model\n",
    "                \"\"\"\n",
    "                neighbor = _find_nearest_neighbor(model, mpro_vec)\n",
    "                word_index = model.word_indexer.index_of(neighbor)\n",
    "\n",
    "                vec = model.predictions[word_index]\n",
    "            \n",
    "            # otherwise we have the word in our graph already\n",
    "            else:\n",
    "                vec = model.predictions[word_index]\n",
    "            #print(vec.shape)\n",
    "\n",
    "            vectors[i,:] = vec\n",
    "        #vectors = self.predictions[word_index:(word_index + self.num_prototypes), :]\n",
    "        #print(vectors.shape)\n",
    "        \n",
    "        # then average the predictions\n",
    "        avg = np.average(vectors, axis=0)\n",
    "        return avg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "82115c7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1\n",
      "calculating similarities with neighbors\n",
      "[[ 0.19835691]\n",
      " [-0.26989769]\n",
      " [ 0.20713212]\n",
      " [ 0.07631599]\n",
      " [ 1.18570936]\n",
      " [ 0.70383808]\n",
      " [ 0.12653709]\n",
      " [ 0.78838764]\n",
      " [-0.79630775]\n",
      " [-0.01981011]]\n",
      "[[ 7.94906590e-04]\n",
      " [-1.08160313e-03]\n",
      " [ 8.30072850e-04]\n",
      " [ 3.05832980e-04]\n",
      " [ 4.75167816e-03]\n",
      " [ 2.82060017e-03]\n",
      " [ 5.07091812e-04]\n",
      " [ 3.15942884e-03]\n",
      " [-3.19116830e-03]\n",
      " [-7.93881502e-05]]\n",
      "[4]\n",
      "zoo_0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1.99207544, 0.47264081, 0.27811963, 0.31520452, 0.38215232,\n",
       "       1.98124412, 0.04186151, 1.24152188, 0.92320346, 0.44768503,\n",
       "       0.3094939 , 0.81204462, 0.19309208, 0.34722986, 0.33279608,\n",
       "       0.1875583 , 0.40608759, 0.73290347, 0.15462763, 1.21529142,\n",
       "       0.98138945, 0.36767651, 0.45974189, 1.51569218, 0.20244071,\n",
       "       0.23843347, 0.0790597 , 1.41820999, 0.24079055, 0.44271498,\n",
       "       0.78759004, 2.06506282, 0.30945685, 1.92956247, 0.52015694,\n",
       "       0.22882335, 0.15846404, 0.24849243, 0.62172014, 0.55269538,\n",
       "       0.82020296, 0.25220971, 0.35855163, 1.29555002, 0.21475112,\n",
       "       0.34847984, 0.05211903, 0.26044125, 0.94657834, 0.39099905,\n",
       "       1.71113926, 0.18111072, 1.68201104, 0.20655957, 0.12476559,\n",
       "       0.20434929, 0.36665846, 0.70354248, 0.51334339, 0.26368636,\n",
       "       1.58520261, 1.344804  ])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicament(model, 'blackbird')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "f3722c74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating similarities with neighbors\n",
      "[[ 0.0991118 ]\n",
      " [-0.39250192]\n",
      " [ 0.16791524]\n",
      " [-0.0382616 ]\n",
      " [ 1.4904007 ]\n",
      " [ 0.34370324]\n",
      " [-0.12062914]\n",
      " [ 1.1955184 ]\n",
      " [-0.28820708]\n",
      " [-0.34894058]]\n",
      "[[ 0.00029143]\n",
      " [-0.00115414]\n",
      " [ 0.00049375]\n",
      " [-0.00011251]\n",
      " [ 0.00438247]\n",
      " [ 0.00101065]\n",
      " [-0.00035471]\n",
      " [ 0.00351538]\n",
      " [-0.00084746]\n",
      " [-0.00102605]]\n",
      "[4]\n",
      "zoo_0\n",
      "zoo_0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1.99207544, 0.47264081, 0.27811963, 0.31520452, 0.38215232,\n",
       "       1.98124412, 0.04186151, 1.24152188, 0.92320346, 0.44768503,\n",
       "       0.3094939 , 0.81204462, 0.19309208, 0.34722986, 0.33279608,\n",
       "       0.1875583 , 0.40608759, 0.73290347, 0.15462763, 1.21529142,\n",
       "       0.98138945, 0.36767651, 0.45974189, 1.51569218, 0.20244071,\n",
       "       0.23843347, 0.0790597 , 1.41820999, 0.24079055, 0.44271498,\n",
       "       0.78759004, 2.06506282, 0.30945685, 1.92956247, 0.52015694,\n",
       "       0.22882335, 0.15846404, 0.24849243, 0.62172014, 0.55269538,\n",
       "       0.82020296, 0.25220971, 0.35855163, 1.29555002, 0.21475112,\n",
       "       0.34847984, 0.05211903, 0.26044125, 0.94657834, 0.39099905,\n",
       "       1.71113926, 0.18111072, 1.68201104, 0.20655957, 0.12476559,\n",
       "       0.20434929, 0.36665846, 0.70354248, 0.51334339, 0.26368636,\n",
       "       1.58520261, 1.344804  ])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def predicament_in_context(model, word, sentence, bert, glove=False):\n",
    "    if glove:\n",
    "        return self.predict(word)\n",
    "    # generate bert vector for word\n",
    "    vec = bert.get_bert_vectors_for(word, sentence)\n",
    "    # get the layer we care about\n",
    "    vec = vec[8]\n",
    "\n",
    "    # reshape to be vertical\n",
    "    #print(\"after reshape\")\n",
    "    #print(vec.shape)\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    find the nearest neighbor to the input vector\n",
    "    \"\"\"\n",
    "    # TODO to predict the nearest neighbor by word we have to fix the counter to an indexer and retrain all the saved models =/\n",
    "\n",
    "    # find the closest input embedding to our context vector\n",
    "    label = _find_nearest_neighbor(model, vec)\n",
    "\n",
    "    print(label)\n",
    "    \n",
    "    # use the label to find the projection we have stored for that embedding\n",
    "    index = model.word_indexer.index_of(label)\n",
    "\n",
    "    logits = model.predictions[index]\n",
    "\n",
    "    return logits\n",
    "\n",
    "predicament_in_context(model, 'eggplant', 'The room was the color of eggplant.', bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56e42d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
