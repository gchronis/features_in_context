{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24900ef2",
   "metadata": {},
   "source": [
    "One off script to take a dozen pickle files of usage data and turn them into one file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f22d80a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gsc685/.conda/envs/gabriella_cwr4lsc/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import pickle\n",
    "from transformers import BertModel, BertTokenizer\n",
    "import torch\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from clustering import make_usage_matrices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d8616aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "decades = [decade for decade in np.arange(1910, 2009, 10)]\n",
    "out_path = '../data/cwr4lsc/feature_prediction/usages_16_len128.dict'\n",
    "\n",
    "all_usages = defaultdict(list)\n",
    "\n",
    "for decade in decades:\n",
    "    path = '../data/cwr4lsc/feature_prediction/usages_with_vectors_16_len128_{}.dict'.format(decade)\n",
    "    with open(path, 'rb') as f:\n",
    "        decade = pickle.load(f)\n",
    "        \n",
    "        #print(decade['leaf'])[0]\n",
    "\n",
    "        # remove annoying initial (word, vector) tuple to just vector\n",
    "        for target in decade.keys():\n",
    "            decade[target] = [(tuplo[1], x, y, z) for tuplo, x, y, z in decade[target] ] \n",
    "            #decade[target] = (big_tuple[0][1], big_tuple[1], big_tuple[2], big_tuple[3]) for big_tuple in decade[target]\n",
    "\n",
    "\n",
    "        \n",
    "        #raise Exception('not done')\n",
    "\n",
    "        for target in decade.keys():\n",
    "            all_usages[target] += (decade[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1af4f0bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6302"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_usages['parent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61b261b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.02825611,  0.01642441,  0.16426327, ...,  0.00230723,\n",
       "        -0.00927058, -0.00955612]),\n",
       " ['to',\n",
       "  'the',\n",
       "  'land',\n",
       "  'of',\n",
       "  'israel',\n",
       "  ',',\n",
       "  'to',\n",
       "  'st',\n",
       "  '##ori',\n",
       "  '##ed',\n",
       "  'galilee',\n",
       "  '.',\n",
       "  'one',\n",
       "  'swift',\n",
       "  'line',\n",
       "  'tells',\n",
       "  'all',\n",
       "  'his',\n",
       "  'youth',\n",
       "  '?',\n",
       "  '\"',\n",
       "  'ii',\n",
       "  '##e',\n",
       "  'grew',\n",
       "  'in',\n",
       "  'grace',\n",
       "  'and',\n",
       "  'stature',\n",
       "  ',',\n",
       "  'in',\n",
       "  'favor',\n",
       "  'with',\n",
       "  'god',\n",
       "  'and',\n",
       "  'man',\n",
       "  '.',\n",
       "  '\"',\n",
       "  'so',\n",
       "  'that',\n",
       "  'white',\n",
       "  'childhood',\n",
       "  'is',\n",
       "  'swept',\n",
       "  'into',\n",
       "  'the',\n",
       "  'innocent',\n",
       "  'silence',\n",
       "  'of',\n",
       "  'all',\n",
       "  'childhood',\n",
       "  '.',\n",
       "  'we',\n",
       "  'think',\n",
       "  'of',\n",
       "  'it',\n",
       "  'as',\n",
       "  'going',\n",
       "  'lightly',\n",
       "  ',',\n",
       "  'like',\n",
       "  'a',\n",
       "  'rose',\n",
       "  '-',\n",
       "  'leaf',\n",
       "  'dancing',\n",
       "  'on',\n",
       "  'the',\n",
       "  'shining',\n",
       "  'floor',\n",
       "  'of',\n",
       "  'a',\n",
       "  'river',\n",
       "  '.',\n",
       "  'the',\n",
       "  'growing',\n",
       "  'boy',\n",
       "  'spent',\n",
       "  'beautiful',\n",
       "  'years',\n",
       "  'at',\n",
       "  'nazareth',\n",
       "  ',',\n",
       "  'a',\n",
       "  'little',\n",
       "  'hill',\n",
       "  '-',\n",
       "  'nest',\n",
       "  '##ed',\n",
       "  'gal',\n",
       "  '##ile',\n",
       "  '##an',\n",
       "  'village',\n",
       "  ',',\n",
       "  'with',\n",
       "  'the',\n",
       "  'low',\n",
       "  'peaks',\n",
       "  'notch',\n",
       "  '##ing',\n",
       "  'the',\n",
       "  'skies',\n",
       "  'around',\n",
       "  'it',\n",
       "  '.',\n",
       "  'behind',\n",
       "  'him',\n",
       "  '@',\n",
       "  '@',\n",
       "  '@',\n",
       "  '@',\n",
       "  '@',\n",
       "  '@',\n",
       "  '@',\n",
       "  '@',\n",
       "  '@',\n",
       "  '@',\n",
       "  'and',\n",
       "  'yet',\n",
       "  'he',\n",
       "  'mingled',\n",
       "  'in',\n",
       "  'sweet',\n",
       "  'democracy',\n",
       "  'with',\n",
       "  'all',\n",
       "  'the'],\n",
       " 63,\n",
       " 1910)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_usages['leaf'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47b71808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save into another file with all usages, in the format tht the clusterizer expects\n",
    "\n",
    "\n",
    "with open(out_path, 'wb') as f:\n",
    "    pickle.dump(all_usages, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2acfaf88",
   "metadata": {},
   "source": [
    "now we have the right number of things to unpack in a single usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b8f197c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_usages['leaf'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5719d07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(out_path, 'rb') as f:\n",
    "    usages_test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e92a9a01",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m usages_test:\n\u001b[0;32m----> 2\u001b[0m     _, _, _, _ \u001b[38;5;241m=\u001b[39m usages_test\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 4)"
     ]
    }
   ],
   "source": [
    "for w in usages_test:\n",
    "    _, _, _, _ = usages_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07401381",
   "metadata": {},
   "source": [
    "actually it still doesn't work. the function doesn't want a llist of individual usages for a word, it wants a matrix for each word"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9bf69c",
   "metadata": {},
   "source": [
    "We have to make udsage matrices actually which is what the clusterizer really expects. there's a utility for this already but we have to do it ourselves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca92557e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 18/18 [1:42:33<00:00, 341.85s/it]\n"
     ]
    }
   ],
   "source": [
    "in_path = '../data/cwr4lsc/feature_prediction/usages_16_len128.dict'\n",
    "out_path = '../data/cwr4lsc/feature_prediction/matrix_usages_16_len128.dict'\n",
    "\n",
    "matrix_usages = make_usage_matrices(in_path, usages_out=None, ndims=3981) # make sure to use the ndims of the feature prediction model\n",
    "with open(out_path, 'wb') as f:\n",
    "    pickle.dump(matrix_usages, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2a41f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gabriella_cwr4lsc",
   "language": "python",
   "name": "gabriella_cwr4lsc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
