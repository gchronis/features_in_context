{
 "cells": [
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 11,
=======
   "execution_count": 1,
>>>>>>> 19411902941c8695225ecb5f64af6ede1b650790
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "sys.path.append(\"..\")\n",
    "from src.bert import *"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 46,
=======
   "execution_count": 2,
>>>>>>> 19411902941c8695225ecb5f64af6ede1b650790
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "INFO:pytorch_pretrained_bert.modeling:loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /Users/rfeld/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n",
      "INFO:pytorch_pretrained_bert.modeling:extracting archive file /Users/rfeld/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /var/folders/78/bnqlwlkd7t1fgn2y34x1tkfh0000gn/T/tmpg8hiyqve\n",
=======
      "INFO:pytorch_pretrained_bert.modeling:loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /Users/km/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n",
      "INFO:pytorch_pretrained_bert.modeling:extracting archive file /Users/km/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /var/folders/yl/yqkqr3kx0tjdr4wrdwv1sk500000gn/T/tmp93cpwl2c\n",
>>>>>>> 19411902941c8695225ecb5f64af6ede1b650790
      "INFO:pytorch_pretrained_bert.modeling:Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
<<<<<<< HEAD
      "INFO:pytorch_pretrained_bert.tokenization:loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /Users/rfeld/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n"
=======
      "INFO:pytorch_pretrained_bert.tokenization:loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /Users/km/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n"
>>>>>>> 19411902941c8695225ecb5f64af6ede1b650790
     ]
    }
   ],
   "source": [
    "# load bert\n",
    "bert = BERTBase()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 47,
=======
   "execution_count": 27,
>>>>>>> 19411902941c8695225ecb5f64af6ede1b650790
   "metadata": {},
   "outputs": [],
   "source": [
    "# load bertspace -> feature space projection model\n",
    "# buchanan model\n",
    "#model = torch.load('../trained_models/model.plsr.buchanan.allbuthomonyms.5k.300components.500max_iters')\n",
    "\n",
    "\n",
    "# binder model\n",
<<<<<<< HEAD
    "# model = torch.load('../trained_models/model.ffnn.binder.5k.50epochs.0.5dropout.lr1e-4.hsize300')\n",
=======
    "model = torch.load('../trained_models/model.ffnn.binder.5k.50epochs.0.5dropout.lr1e-4.hsize300')\n",
>>>>>>> 19411902941c8695225ecb5f64af6ede1b650790
    "\n",
    "# mcrae model\n",
    "# model = torch.load('main_efe0a_00006_6_clusters=5,embedding_type=bert,model=plsr,plsr_max_iter=500,plsr_n_components=100,train_data=mc_rae_real_2022-10-12_00-08-44')"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
=======
   "execution_count": 28,
   "metadata": {},
>>>>>>> 19411902941c8695225ecb5f64af6ede1b650790
   "outputs": [
    {
     "data": {
      "text/plain": [
<<<<<<< HEAD
       "array([ 0.05578806,  0.0164116 ,  0.07315334, ..., -0.0015972 ,\n",
       "       -0.00213758,  0.00103422])"
      ]
     },
     "execution_count": 48,
=======
       "array([2.9568036 , 0.61426425, 0.3744761 , 0.70247775, 0.7854624 ,\n",
       "       1.4191686 , 0.7391516 , 1.7764028 , 1.5506842 , 1.2122059 ,\n",
       "       0.7108153 , 1.7034833 , 1.277241  , 1.310958  , 0.9128889 ,\n",
       "       0.87518716, 1.0036851 , 1.512504  , 0.70719254, 3.1598284 ,\n",
       "       2.0892081 , 0.8565724 , 1.1695713 , 2.4206765 , 1.1395965 ,\n",
       "       1.828603  , 0.22622356, 0.40727967, 1.8939434 , 1.8348547 ,\n",
       "       0.57179576, 0.9359502 , 1.0819094 , 2.025812  , 0.7185721 ,\n",
       "       0.8300108 , 0.7960571 , 0.31336394, 1.0342946 , 1.4954449 ,\n",
       "       1.1481557 , 1.774804  , 2.7916858 , 2.9556499 , 1.9453566 ,\n",
       "       2.5845878 , 1.2213181 , 1.9209309 , 2.502466  , 1.5053197 ,\n",
       "       2.238748  , 1.5596702 , 1.9351563 , 0.9022642 , 0.99593234,\n",
       "       0.6680382 , 0.9449822 , 1.5471233 , 2.1278963 , 1.052221  ,\n",
       "       3.241095  , 2.838128  ], dtype=float32)"
      ]
     },
     "execution_count": 28,
>>>>>>> 19411902941c8695225ecb5f64af6ede1b650790
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict('turtle')"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
=======
   "execution_count": 29,
   "metadata": {},
>>>>>>> 19411902941c8695225ecb5f64af6ede1b650790
   "outputs": [
    {
     "data": {
      "text/plain": [
<<<<<<< HEAD
       "['photograph',\n",
       " 'compute',\n",
       " 'small',\n",
       " 'tv',\n",
       " 'inform',\n",
       " 'entertain',\n",
       " 'movie',\n",
       " 'act',\n",
       " 'show',\n",
       " 'see',\n",
       " 'sound',\n",
       " 'music',\n",
       " 'play',\n",
       " 'paint',\n",
       " 'picture']"
      ]
     },
     "execution_count": 61,
=======
       "['Motion',\n",
       " 'Speech',\n",
       " 'UpperLimb',\n",
       " 'Head',\n",
       " 'Cognition',\n",
       " 'Sound',\n",
       " 'Benefit',\n",
       " 'Loud',\n",
       " 'Pleasant',\n",
       " 'Communication',\n",
       " 'Happy',\n",
       " 'Human',\n",
       " 'Drive',\n",
       " 'Consequential',\n",
       " 'Scene',\n",
       " 'Arousal',\n",
       " 'Social',\n",
       " 'Audition',\n",
       " 'Attention',\n",
       " 'Vision']"
      ]
     },
     "execution_count": 29,
>>>>>>> 19411902941c8695225ecb5f64af6ede1b650790
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_top_n_features('video',15)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 62,
=======
   "execution_count": 30,
>>>>>>> 19411902941c8695225ecb5f64af6ede1b650790
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
<<<<<<< HEAD
       "['long',\n",
       " 'tail',\n",
       " 'fly',\n",
       " 'small',\n",
       " 'mammal',\n",
       " 'large',\n",
       " 'eat',\n",
       " 'leg',\n",
       " 'animal',\n",
       " 'fur']"
      ]
     },
     "execution_count": 62,
=======
       "['Texture',\n",
       " 'Fast',\n",
       " 'Shape',\n",
       " 'Biomotion',\n",
       " 'Motion',\n",
       " 'Weight',\n",
       " 'Pattern',\n",
       " 'Color',\n",
       " 'Attention',\n",
       " 'Vision']"
      ]
     },
     "execution_count": 30,
>>>>>>> 19411902941c8695225ecb5f64af6ede1b650790
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = \"The second largest order of mammals after rodents, bats comprise about 20% of all classified mammal species worldwide, with over 1,400 species\"\n",
    "# sent = \"The coach put away the baseball bats.\"\n",
    "\n",
    "model.predict_top_n_features_in_context('bats', sent, 10, bert=bert)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 28,
=======
   "execution_count": 37,
>>>>>>> 19411902941c8695225ecb5f64af6ede1b650790
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
<<<<<<< HEAD
       "['protect',\n",
       " 'eat',\n",
       " 'insect',\n",
       " 'large',\n",
       " 'bird',\n",
       " 'fly',\n",
       " 'small',\n",
       " 'leg',\n",
       " 'wing',\n",
       " 'animal']"
      ]
     },
     "execution_count": 28,
=======
       "['Shape',\n",
       " 'Body',\n",
       " 'Landmark',\n",
       " 'Needs',\n",
       " 'Consequential',\n",
       " 'Scene',\n",
       " 'Biomotion',\n",
       " 'Attention',\n",
       " 'Benefit',\n",
       " 'Vision']"
      ]
     },
     "execution_count": 37,
>>>>>>> 19411902941c8695225ecb5f64af6ede1b650790
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = \"wug\"\n",
    "\n",
    "model.predict_top_n_features_in_context('wug', sent, 10, bert=bert)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 29,
=======
   "execution_count": 32,
>>>>>>> 19411902941c8695225ecb5f64af6ede1b650790
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
<<<<<<< HEAD
=======
       "['Fast',\n",
       " 'Scene',\n",
       " 'Body',\n",
       " 'Shape',\n",
       " 'Biomotion',\n",
       " 'Motion',\n",
       " 'Sound',\n",
       " 'Audition',\n",
       " 'Attention',\n",
       " 'Vision']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = \"A wug is a penguin.\"\n",
    "\n",
    "model.predict_top_n_features_in_context('wug', sent, 10, bert=bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
>>>>>>> 19411902941c8695225ecb5f64af6ede1b650790
       "['house',\n",
       " 'water',\n",
       " 'material',\n",
       " 'protect',\n",
       " 'walk',\n",
       " 'person',\n",
       " 'object',\n",
       " 'hard',\n",
       " 'build',\n",
       " 'place']"
      ]
     },
<<<<<<< HEAD
     "execution_count": 29,
=======
     "execution_count": 9,
>>>>>>> 19411902941c8695225ecb5f64af6ede1b650790
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_top_n_features_in_context('foundation', 'The argument has a weak foundation', 10, bert=bert)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 30,
=======
   "execution_count": 10,
>>>>>>> 19411902941c8695225ecb5f64af6ede1b650790
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
<<<<<<< HEAD
       "['wear',\n",
       " 'light',\n",
       " 'good',\n",
       " 'grow',\n",
       " 'color',\n",
       " 'build',\n",
       " 'water',\n",
       " 'hard',\n",
       " 'material',\n",
       " 'cloth']"
      ]
     },
     "execution_count": 30,
=======
       "['wood',\n",
       " 'house',\n",
       " 'human',\n",
       " 'heave',\n",
       " 'hand',\n",
       " 'object',\n",
       " 'hard',\n",
       " 'build',\n",
       " 'person',\n",
       " 'walk']"
      ]
     },
     "execution_count": 10,
>>>>>>> 19411902941c8695225ecb5f64af6ede1b650790
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_top_n_features_in_context('foundation', 'She needed to put on foundation before applying blush.', 10, bert=bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['same', 'neck', 'man', 'hold', 'body', 'game', 'material', 'together', 'animal', 'person', 'long', 'food', 'object', 'metal', 'human', 'cloth', 'color', 'wear', 'act', 'two']\n",
      "['four', 'game', 'small', 'sport', 'fight', 'noise', 'ball', 'act', 'win', 'compete', 'same', 'two', 'animal', 'love', 'play', 'together', 'person', 'hard', 'fast', 'agree']\n",
      "['neck', 'fashion', 'object', 'style', 'cotton', 'thin', 'long', 'warm', 'wear', 'hair', 'person', 'material', 'body', 'two', 'cloth', 'cover', 'man', 'color', 'soft', 'comfort']\n"
     ]
    }
   ],
   "source": [
    "# sents = [\"Two antennas got married. The ceremony wasn’t much, but the reception was excellent.\"]\n",
    "# word = \"reception\"\n",
    "\n",
    "sents = [\"Did you hear about the silk worm race? It ended in a tie.\",\n",
    "         \"The soccer game ended in a 4-4 tie.\",\n",
    "         \"The silk worms produced a beautiful striped tie.\"\n",
    "        ]\n",
    "word = 'tie'\n",
    "\n",
    "# sents = [\"Q: What’s the best thing about Switzerland? A: Well, the flag is a big plus.\"]\n",
    "# word = 'plus'\n",
    "\n",
    "for sent in sents:\n",
    "    features = model.predict_top_n_features_in_context(word, sent, 20, bert=bert)\n",
    "    print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early\n",
      "['Short', 'Benefit', 'Drive', 'Human', 'Consequential', 'Cognition', 'Duration']\n",
      "on,\n",
      "['Scene', 'Drive', 'Consequential', 'Pleasant', 'Duration', 'Social', 'Benefit']\n",
      "the\n",
      "['Communication', 'Drive', 'Cognition', 'Benefit', 'Human', 'Consequential', 'Social']\n",
      "target\n",
      "['Communication', 'Drive', 'Arousal', 'Cognition', 'Consequential', 'Attention', 'Social']\n",
      "herd\n",
      "['Pleasant', 'Social', 'Audition', 'Biomotion', 'Benefit', 'Attention', 'Vision']\n",
      "immunity\n",
      "['Cognition', 'Benefit', 'Consequential', 'Drive', 'Needs', 'Social', 'Arousal']\n",
      "threshold\n",
      "['Communication', 'Drive', 'Arousal', 'Social', 'Cognition', 'Attention', 'Consequential']\n",
      "was\n",
      "['Body', 'Self', 'Benefit', 'Social', 'Arousal', 'Consequential', 'Human']\n",
      "estimated\n",
      "['Communication', 'Human', 'Benefit', 'Drive', 'Consequential', 'Attention', 'Cognition']\n",
      "to\n",
      "['Harm', 'Benefit', 'Drive', 'Vision', 'Consequential', 'Attention', 'Arousal']\n",
      "be\n",
      "['Cognition', 'Audition', 'Social', 'Drive', 'Attention', 'Arousal', 'Consequential']\n",
      "about\n",
      "['Audition', 'Large', 'Communication', 'Number', 'Head', 'Attention', 'Vision']\n",
      "60\n",
      "['Consequential', 'Pleasant', 'Drive', 'Arousal', 'Benefit', 'Attention', 'Vision']\n",
      "to\n",
      "['Harm', 'Benefit', 'Drive', 'Vision', 'Consequential', 'Attention', 'Arousal']\n",
      "70\n",
      "['Happy', 'Number', 'Pleasant', 'Benefit', 'Color', 'Attention', 'Vision']\n",
      "percent\n",
      "['Human', 'Large', 'Body', 'Biomotion', 'Number', 'Attention', 'Arousal']\n",
      "of\n",
      "['Number', 'Body', 'Biomotion', 'Human', 'Large', 'Attention', 'Benefit']\n",
      "the\n",
      "['Communication', 'Drive', 'Cognition', 'Benefit', 'Human', 'Consequential', 'Social']\n",
      "population.\n",
      "['Face', 'Speech', 'Human', 'Attention', 'Body', 'Biomotion', 'Vision']\n",
      "Most\n",
      "['Cognition', 'Large', 'Self', 'Body', 'Human', 'Social', 'Benefit']\n",
      "experts,\n",
      "['Social', 'Biomotion', 'Face', 'Body', 'Speech', 'Benefit', 'Human']\n",
      "including\n",
      "['UpperLimb', 'Vision', 'Benefit', 'Human', 'Social', 'Body', 'Speech']\n",
      "Dr.\n",
      "['Benefit', 'Speech', 'Body', 'Face', 'Human', 'Biomotion', 'Vision']\n",
      "Fauci,\n",
      "['Scene', 'Shape', 'UpperLimb', 'Happy', 'Pleasant', 'Benefit', 'Vision']\n",
      "expected\n",
      "['Drive', 'Happy', 'Benefit', 'Self', 'Human', 'Cognition', 'Pleasant']\n",
      "that\n",
      "['Arousal', 'Taste', 'Consequential', 'Smell', 'Pleasant', 'Short', 'Human']\n",
      "the\n",
      "['Communication', 'Drive', 'Cognition', 'Benefit', 'Human', 'Consequential', 'Social']\n",
      "United\n",
      "['Needs', 'Social', 'Attention', 'Happy', 'Pleasant', 'Benefit', 'Vision']\n",
      "States\n",
      "['Vision', 'Human', 'Pleasant', 'Biomotion', 'Needs', 'Benefit', 'Body']\n",
      "would\n",
      "['Arousal', 'Biomotion', 'Self', 'Pleasant', 'Consequential', 'Cognition', 'Human']\n",
      "be\n",
      "['Cognition', 'Audition', 'Social', 'Drive', 'Attention', 'Arousal', 'Consequential']\n",
      "able\n",
      "['Arousal', 'Attention', 'Drive', 'Needs', 'Happy', 'Pleasant', 'Benefit']\n",
      "to\n",
      "['Harm', 'Benefit', 'Drive', 'Vision', 'Consequential', 'Attention', 'Arousal']\n",
      "reach\n",
      "['Cognition', 'Benefit', 'Social', 'Drive', 'Needs', 'Communication', 'Consequential']\n",
      "it\n",
      "['Landmark', 'Needs', 'Weight', 'Benefit', 'Large', 'Shape', 'Vision']\n",
      "once\n",
      "['Self', 'Social', 'Duration', 'Drive', 'Human', 'Consequential', 'Cognition']\n",
      "vaccines\n",
      "['Small', 'Smell', 'Head', 'Vision', 'Taste', 'Consequential', 'Benefit']\n",
      "were\n",
      "['UpperLimb', 'Landmark', 'Human', 'Scene', 'Consequential', 'Benefit', 'Vision']\n",
      "available\n",
      "['Attention', 'Communication', 'Pleasant', 'Head', 'Needs', 'Vision', 'Benefit']\n"
     ]
    }
   ],
   "source": [
    "#sent = 'By the way, did everyone notice that misogynist pig served the ladies raw meat? '\n",
    "#sent = \"People travel many miles to gaze upon this natural wonder, though few are willing to approach it closely, since it is reputed to be the haunt of various demons and devils\"\n",
    "sent = \"Early on, the target herd immunity threshold was estimated to be about 60 to 70 percent of the population. Most experts, including Dr. Fauci, expected that the United States would be able to reach it once vaccines were available\"\n",
    "for word in sent.split(' '):\n",
    "    print(word)\n",
    "    feats = model.predict_top_n_features_in_context(word, sent,7, bert=bert)\n",
    "    print(feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at mcrae features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Self',\n",
       " 'Head',\n",
       " 'Touch',\n",
       " 'Weight',\n",
       " 'Texture',\n",
       " 'Color',\n",
       " 'Happy',\n",
       " 'Audition',\n",
       " 'Arousal',\n",
       " 'Pleasant',\n",
       " 'Benefit',\n",
       " 'Cognition',\n",
       " 'Communication',\n",
       " 'Social',\n",
       " 'Consequential',\n",
       " 'UpperLimb',\n",
       " 'Drive',\n",
       " 'Shape',\n",
       " 'Attention',\n",
       " 'Vision']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_top_n_features_in_context('disjoint', 'Separated sets are of course disjoint, but disjoint sets need not be separated.', 20, bert=bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Loud',\n",
       " 'High',\n",
       " 'Benefit',\n",
       " 'Head',\n",
       " 'Biomotion',\n",
       " 'Smell',\n",
       " 'Texture',\n",
       " 'Temperature',\n",
       " 'Touch',\n",
       " 'Scene',\n",
       " 'Small',\n",
       " 'Audition',\n",
       " 'Large',\n",
       " 'Taste',\n",
       " 'Pattern',\n",
       " 'Color',\n",
       " 'Sound',\n",
       " 'Vision',\n",
       " 'Shape',\n",
       " 'Weight']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = \" My place is an absolute pig sty and I have to do laundry Hahahahaha\"\n",
    "model.predict_top_n_features_in_context('pig', sent, 20, bert=bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Smell',\n",
       " 'Fearful',\n",
       " 'Happy',\n",
       " 'Texture',\n",
       " 'Path',\n",
       " 'Large',\n",
       " 'Pattern',\n",
       " 'Sound',\n",
       " 'Pleasant',\n",
       " 'Scene',\n",
       " 'Arousal',\n",
       " 'Harm',\n",
       " 'Weight',\n",
       " 'Shape',\n",
       " 'Fast',\n",
       " 'Biomotion',\n",
       " 'Motion',\n",
       " 'Color',\n",
       " 'Attention',\n",
       " 'Vision']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_top_n_features_in_context('car',\n",
    "                                        'The car sells well.', 20, bert=bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Speech',\n",
       " 'Fast',\n",
       " 'Large',\n",
       " 'Face',\n",
       " 'Pain',\n",
       " 'Body',\n",
       " 'Arousal',\n",
       " 'Harm',\n",
       " 'Consequential',\n",
       " 'Unpleasant',\n",
       " 'Scene',\n",
       " 'Sound',\n",
       " 'Loud',\n",
       " 'Audition',\n",
       " 'Fearful',\n",
       " 'Shape',\n",
       " 'Biomotion',\n",
       " 'Motion',\n",
       " 'Attention',\n",
       " 'Vision']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_top_n_features_in_context('car',\n",
    "                                        'The salesman sells the car well.', 20, bert=bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = \"production\"\n",
    "sents = [\"Here we must stress again that we are not proposing that the category of production should magically disappear, but that we depose it from the metaphysical primacy it has enjoyed for far too long in Western history, especially following the rise of capitalism.\"\n",
    "        , \"Her visit was in conjunction with the School of Theater's production of \\\" The Laramie Project, \\\" a play about Shepard's gay son,\"\n",
    "        , \"Agriculture is the birth of production, complete with its essential features and deformation of life and consciousness\"\n",
    "        , \"How to achieve such a seizure of the means of production is a political question\"\n",
    "        , \"The rig had been expected to begin oil production again later this month\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['material', 'want', 'pay', 'object', 'bad', 'grow', 'buy', 'farm', 'human', 'store', 'up', 'build', 'good', 'money', 'produce', 'food', 'work', 'person', 'act', 'create']\n",
      "['school', 'red', 'build', 'body', 'cloth', 'object', 'group', 'perform', 'carry', 'fun', 'movie', 'entertain', 'create', 'play', 'large', 'person', 'act', 'music', 'show', 'move']\n",
      "['field', 'pay', 'cook', 'produce', 'farm', 'object', 'act', 'food', 'good', 'money', 'up', 'person', 'bad', 'create', 'one', 'buy', 'human', 'grow', 'work', 'cloth']\n",
      "['need', 'long', 'pay', 'car', 'material', 'grow', 'make', 'build', 'bad', 'place', 'object', 'human', 'person', 'act', 'good', 'work', 'create', 'money', 'produce', 'food']\n",
      "['taste', 'love', 'place', 'science', 'tree', 'juice', 'new', 'make', 'food', 'produce', 'money', 'work', 'sweet', 'good', 'create', 'grow', 'eat', 'fruit', 'person', 'act']\n"
     ]
    }
   ],
   "source": [
    "for sent in sents:\n",
    "    features = model.predict_top_n_features_in_context(word, sent, 20, bert=bert)\n",
    "    print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['color', 'stone', 'ground', 'brown', 'sand', 'wheel', 'vehicle', 'white', 'water', 'land', 'earth', 'black', 'farm', 'small', 'car', 'road', 'dirt', 'hard', 'drive', 'rock']\n",
      "['water', 'car', 'drive', 'road', 'voice', 'act', 'mouth', 'earth', 'bad', 'ground', 'place', 'hard', 'soft', 'pitch', 'rock', 'noise', 'dirt', 'loud', 'sound', 'small']\n"
     ]
    }
   ],
   "source": [
    "word = \"gravel\"\n",
    "sents = [\n",
    "    \"My wheel turned to the left and down a gravel road.\"\n",
    "    , \"The speaker's voice was guttural and low, low and full of gravel and flecks of spit.\"\n",
    "]\n",
    "\n",
    "for sent in sents:\n",
    "    features = model.predict_top_n_features_in_context(word, sent, 20, bert=bert)\n",
    "    print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['brown', 'cute', 'white', 'smell', 'long', 'big', 'large', 'domestic', 'hair', 'farm', 'animal', 'food', 'fur', 'mammal', 'pet', 'tail', 'leg', 'eat', 'small', 'four']\n",
      "['human', 'water', 'bad', 'white', 'brown', 'farm', 'smell', 'food', 'tail', 'small', 'large', 'mammal', 'person', 'fur', 'long', 'four', 'eat', 'leg', 'animal', 'dirt']\n"
     ]
    }
   ],
   "source": [
    "word = \"pig\"\n",
    "sents = [\n",
    "    \"The pig trotted up to the fence.\"\n",
    "    , \"My roommate is a pig.\"\n",
    "]\n",
    "\n",
    "for sent in sents:\n",
    "    features = model.predict_top_n_features_in_context(word, sent, 20, bert=bert)\n",
    "    print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['throw', 'king', 'round', 'strong', 'human', 'act', 'small', 'large', 'yellow', 'animal', 'protect', 'eat', 'play', 'two', 'board', 'sport', 'game', 'piece', 'ball', 'wood']\n",
      "['fight', 'king', 'fast', 'fun', 'human', 'food', 'hard', 'round', 'sport', 'write', 'act', 'brown', 'game', 'paper', 'music', 'piece', 'board', 'play', 'money', 'ball']\n"
     ]
    }
   ],
   "source": [
    "word = \"chess\"\n",
    "sents = [\n",
    "    \"Old men sat around in the park waiting for acquantances to meet them for a game of chess.\"\n",
    "    , \"Sam faced up his opponent in the ring. He bounced off the ropes and swund underneath for an uppercut. This wasn't war. This was chess.\"\n",
    "]\n",
    "\n",
    "for sent in sents:\n",
    "    features = model.predict_top_n_features_in_context(word, sent, 20, bert=bert)\n",
    "    print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
<<<<<<< HEAD
   "version": "3.9.12"
=======
   "version": "3.9.9"
>>>>>>> 19411902941c8695225ecb5f64af6ede1b650790
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
