{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24900ef2",
   "metadata": {},
   "source": [
    "One off script to take a dozen pickle files of usage data and turn them into one file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f22d80a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gsc685/.conda/envs/gabriella_cwr4lsc/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import pickle\n",
    "from transformers import BertModel, BertTokenizer\n",
    "import torch\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from clustering import make_usage_matrices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d8616aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "decades = [decade for decade in np.arange(1910, 2009, 10)]\n",
    "out_path = '../data/cwr4lsc/binder/usages_16_len128.dict'\n",
    "\n",
    "all_usages = defaultdict(list)\n",
    "\n",
    "for decade in decades:\n",
    "    path = '../data/cwr4lsc/binder/usages_with_vectors_16_len128_{}.dict'.format(decade)\n",
    "    with open(path, 'rb') as f:\n",
    "        decade = pickle.load(f)\n",
    "        \n",
    "        #print(decade['leaf'])[0]\n",
    "\n",
    "        # remove annoying initial (word, vector) tuple to just vector\n",
    "        for target in decade.keys():\n",
    "            decade[target] = [(vec, x, y, z) for vec, x, y, z in decade[target] ] \n",
    "            #decade[target] = (big_tuple[0][1], big_tuple[1], big_tuple[2], big_tuple[3]) for big_tuple in decade[target]\n",
    "\n",
    "\n",
    "        \n",
    "        #raise Exception('not done')\n",
    "\n",
    "        for target in decade.keys():\n",
    "            all_usages[target] += (decade[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1af4f0bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6285"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_usages['parent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8647a46-e2a6-4a39-ae22-c91c41946c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many dimensions do our vectors have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61b261b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 5.6224475e+00,  2.8358703e+00,  1.3824366e+00,  5.3413668e+00,\n",
       "         4.2947555e+00,  8.2244134e-01,  3.0668213e+00,  1.3716707e+00,\n",
       "         1.1286278e+00,  1.0092518e+00,  1.2194594e+00,  5.4043293e+00,\n",
       "         2.8424539e-02,  3.5405785e-01,  4.5536084e+00,  2.4813056e+00,\n",
       "         4.5271816e+00,  4.4619012e+00, -1.7319861e-01,  8.3986789e-01,\n",
       "         5.7031310e-01,  4.4277871e-01,  6.6316170e-01,  1.4368700e+00,\n",
       "         4.3249574e-01, -2.4854717e-01,  9.2216694e-01,  1.5625881e+00,\n",
       "         6.0887563e-01,  1.8470562e+00,  1.0632853e-01,  2.9497525e-01,\n",
       "         9.3153203e-01,  1.9187591e+00,  2.7344732e+00,  9.1944015e-01,\n",
       "         1.0580186e+00,  4.5944220e-01,  1.2401076e-02, -2.0799415e-01,\n",
       "        -5.3534284e-03, -1.3480511e-01, -6.6288763e-01, -1.4357696e+00,\n",
       "        -6.2934172e-01,  4.0593222e-02,  3.2758760e-01, -7.1864498e-01,\n",
       "         1.5988810e+00,  2.9125583e-01,  2.6643238e+00, -8.3092999e-01,\n",
       "         1.5239185e+00, -7.0998663e-01, -7.5125724e-01, -5.0802594e-01,\n",
       "        -4.2449534e-01, -3.2199347e-01, -3.8908204e-01,  2.1658645e+00,\n",
       "         1.0287272e+00, -5.5214185e-01], dtype=float32),\n",
       " ['to',\n",
       "  'the',\n",
       "  'land',\n",
       "  'of',\n",
       "  'israel',\n",
       "  ',',\n",
       "  'to',\n",
       "  'st',\n",
       "  '##ori',\n",
       "  '##ed',\n",
       "  'galilee',\n",
       "  '.',\n",
       "  'one',\n",
       "  'swift',\n",
       "  'line',\n",
       "  'tells',\n",
       "  'all',\n",
       "  'his',\n",
       "  'youth',\n",
       "  '?',\n",
       "  '\"',\n",
       "  'ii',\n",
       "  '##e',\n",
       "  'grew',\n",
       "  'in',\n",
       "  'grace',\n",
       "  'and',\n",
       "  'stature',\n",
       "  ',',\n",
       "  'in',\n",
       "  'favor',\n",
       "  'with',\n",
       "  'god',\n",
       "  'and',\n",
       "  'man',\n",
       "  '.',\n",
       "  '\"',\n",
       "  'so',\n",
       "  'that',\n",
       "  'white',\n",
       "  'childhood',\n",
       "  'is',\n",
       "  'swept',\n",
       "  'into',\n",
       "  'the',\n",
       "  'innocent',\n",
       "  'silence',\n",
       "  'of',\n",
       "  'all',\n",
       "  'childhood',\n",
       "  '.',\n",
       "  'we',\n",
       "  'think',\n",
       "  'of',\n",
       "  'it',\n",
       "  'as',\n",
       "  'going',\n",
       "  'lightly',\n",
       "  ',',\n",
       "  'like',\n",
       "  'a',\n",
       "  'rose',\n",
       "  '-',\n",
       "  'leaf',\n",
       "  'dancing',\n",
       "  'on',\n",
       "  'the',\n",
       "  'shining',\n",
       "  'floor',\n",
       "  'of',\n",
       "  'a',\n",
       "  'river',\n",
       "  '.',\n",
       "  'the',\n",
       "  'growing',\n",
       "  'boy',\n",
       "  'spent',\n",
       "  'beautiful',\n",
       "  'years',\n",
       "  'at',\n",
       "  'nazareth',\n",
       "  ',',\n",
       "  'a',\n",
       "  'little',\n",
       "  'hill',\n",
       "  '-',\n",
       "  'nest',\n",
       "  '##ed',\n",
       "  'gal',\n",
       "  '##ile',\n",
       "  '##an',\n",
       "  'village',\n",
       "  ',',\n",
       "  'with',\n",
       "  'the',\n",
       "  'low',\n",
       "  'peaks',\n",
       "  'notch',\n",
       "  '##ing',\n",
       "  'the',\n",
       "  'skies',\n",
       "  'around',\n",
       "  'it',\n",
       "  '.',\n",
       "  'behind',\n",
       "  'him',\n",
       "  '@',\n",
       "  '@',\n",
       "  '@',\n",
       "  '@',\n",
       "  '@',\n",
       "  '@',\n",
       "  '@',\n",
       "  '@',\n",
       "  '@',\n",
       "  '@',\n",
       "  'and',\n",
       "  'yet',\n",
       "  'he',\n",
       "  'mingled',\n",
       "  'in',\n",
       "  'sweet',\n",
       "  'democracy',\n",
       "  'with',\n",
       "  'all',\n",
       "  'the'],\n",
       " 63,\n",
       " 1910)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_usages['leaf'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47b71808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save into another file with all usages, in the format tht the clusterizer expects\n",
    "\n",
    "\n",
    "with open(out_path, 'wb') as f:\n",
    "    pickle.dump(all_usages, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2acfaf88",
   "metadata": {},
   "source": [
    "now we have the right number of things to unpack in a single usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b8f197c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_usages['leaf'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5719d07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(out_path, 'rb') as f:\n",
    "    usages_test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e92a9a01",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m usages_test:\n\u001b[0;32m----> 2\u001b[0m     _, _, _, _ \u001b[38;5;241m=\u001b[39m usages_test\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 4)"
     ]
    }
   ],
   "source": [
    "for w in usages_test:\n",
    "    _, _, _, _ = usages_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07401381",
   "metadata": {},
   "source": [
    "actually it still doesn't work. the function doesn't want a llist of individual usages for a word, it wants a matrix for each word"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9bf69c",
   "metadata": {},
   "source": [
    "We have to make udsage matrices actually which is what the clusterizer really expects. there's a utility for this already but we have to do it ourselves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ca92557e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 19/19 [01:39<00:00,  5.26s/it]\n"
     ]
    }
   ],
   "source": [
    "in_path = '../data/cwr4lsc/binder/usages_16_len128.dict'\n",
    "out_path = '../data/cwr4lsc/binder/matrix_usages_16_len128.dict'\n",
    "\n",
    "matrix_usages = make_usage_matrices(in_path, usages_out=None, ndims=62) # make sure to use the ndims of the feature prediction model\n",
    "with open(out_path, 'wb') as f:\n",
    "    pickle.dump(matrix_usages, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2a41f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gabriella_cwr4lsc",
   "language": "python",
   "name": "gabriella_cwr4lsc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
