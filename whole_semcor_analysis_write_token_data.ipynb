{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data\n",
    "\n",
    "First we will create a dictionary of Semcor words, and look at them and their frequencies.\n",
    "\n",
    "\n",
    "Next, we want to create a dataset of a subsample of semcor. We want to remove the most common and least common words\n",
    "\n",
    "We also want to limit to 50 examples of each sense of a word.\n",
    "\n",
    "So, we begin iterating through a randomly shuffled semcor. For each word, we throw it out if it is too frequent or too infreqient. Then, we look at the senses.\n",
    "\n",
    "\n",
    "\n",
    "At the end, we store a list of all of the words we've collected. For each item in the dictionary, we should know:\n",
    "- the number of tokens\n",
    "- the wordnet senses\n",
    "- a list of the semcor sentence indices of the tokens of each word. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_pretrained_bert.modeling:loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /Users/gabriellachronis/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n",
      "INFO:pytorch_pretrained_bert.modeling:extracting archive file /Users/gabriellachronis/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /var/folders/9m/vzvx58rs51v_x5nm620fz4xr0000gn/T/tmpxb4o5cej\n",
      "INFO:pytorch_pretrained_bert.modeling:Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "INFO:pytorch_pretrained_bert.tokenization:loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /Users/gabriellachronis/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import semcor\n",
    "from nltk.tree import Tree\n",
    "import itertools\n",
    "import random\n",
    "import pandas as pd\n",
    "import torch\n",
    "from bert import *\n",
    "import csv\n",
    "from nltk.corpus.reader.wordnet import Lemma\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "import inflect\n",
    "import os\n",
    "from scipy.stats import spearmanr, pearsonr\n",
    "import re\n",
    "\n",
    "\n",
    "bert = BERTBase()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mice'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = inflect.engine()\n",
    "p.plural(\"mouse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "load semcor stats\n",
    "\"\"\"\n",
    "\n",
    "# uncomment for whole dataset\n",
    "# sents = semcor.sents()\n",
    "# tagged_sents = semcor.tagged_sents( tag = ' sem ' )\n",
    "# words = semcor.words()\n",
    "\n",
    "\n",
    "##########\n",
    "# DEBUG ONLY\n",
    "############\n",
    "\n",
    "tagged_sents = semcor.tagged_sents( tag = ' sem ' )[:20]\n",
    "sents = semcor.sents()[:20]\n",
    "words = semcor.words()[:1000]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_senses_in_tagged_sentence(tagged_sentence):\n",
    "#     res = []\n",
    "#     for chunk in tagged_sentence:\n",
    "#         chunk_string = ' '.join(chunk.leaves())\n",
    "\n",
    "#         \"\"\"\n",
    "#         if we find a wordnet sense (function words dont)\n",
    "#         then scoop it up\n",
    "\n",
    "#         \"\"\"            \n",
    "#         if isinstance(chunk.label() , Lemma):\n",
    "#             res.append(chunk.label())\n",
    "#     # if we get to the end of the loop. we didn't find the word we were looking for\n",
    "#     return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(sents[1])\n",
    "# get_senses_in_tagged_sentence(tagged_sents[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'impressed'"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize(\"impressed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'the': 82,\n",
       "         'fulton': 14,\n",
       "         'county': 8,\n",
       "         'grand': 4,\n",
       "         'jury': 19,\n",
       "         'said': 14,\n",
       "         'friday': 2,\n",
       "         'an': 4,\n",
       "         'investigation': 1,\n",
       "         'of': 36,\n",
       "         'atlanta': 7,\n",
       "         \"'s\": 12,\n",
       "         'recent': 1,\n",
       "         'primary': 3,\n",
       "         'election': 6,\n",
       "         'produced': 1,\n",
       "         '``': 24,\n",
       "         'no': 1,\n",
       "         'evidence': 1,\n",
       "         \"''\": 23,\n",
       "         'that': 16,\n",
       "         'any': 1,\n",
       "         'irregularity': 2,\n",
       "         'took': 2,\n",
       "         'place': 3,\n",
       "         '.': 39,\n",
       "         'further': 1,\n",
       "         'in': 18,\n",
       "         'term': 3,\n",
       "         'end': 2,\n",
       "         'presentment': 1,\n",
       "         'city': 9,\n",
       "         'executive': 1,\n",
       "         'committee': 2,\n",
       "         ',': 34,\n",
       "         'which': 7,\n",
       "         'had': 2,\n",
       "         'over-all': 1,\n",
       "         'charge': 2,\n",
       "         'deserves': 1,\n",
       "         'praise': 1,\n",
       "         'and': 27,\n",
       "         'thanks': 1,\n",
       "         'for': 10,\n",
       "         'manner': 2,\n",
       "         'wa': 6,\n",
       "         'conducted': 1,\n",
       "         'september': 1,\n",
       "         'october': 1,\n",
       "         'been': 4,\n",
       "         'charged': 2,\n",
       "         'by': 4,\n",
       "         'superior': 2,\n",
       "         'court': 5,\n",
       "         'judge': 1,\n",
       "         'durwood': 1,\n",
       "         'pye': 1,\n",
       "         'to': 14,\n",
       "         'investigate': 1,\n",
       "         'report': 2,\n",
       "         'possible': 1,\n",
       "         'hard-fought': 1,\n",
       "         'won': 1,\n",
       "         'mayor-nominate': 1,\n",
       "         'ivan': 2,\n",
       "         'allen': 2,\n",
       "         'jr.': 3,\n",
       "         'only': 1,\n",
       "         'a': 21,\n",
       "         'relative': 1,\n",
       "         'handful': 1,\n",
       "         'such': 1,\n",
       "         'received': 1,\n",
       "         'considering': 1,\n",
       "         'widespread': 1,\n",
       "         'interest': 2,\n",
       "         'number': 2,\n",
       "         'voter': 1,\n",
       "         'size': 1,\n",
       "         'this': 6,\n",
       "         'it': 12,\n",
       "         'did': 2,\n",
       "         'find': 1,\n",
       "         'many': 1,\n",
       "         'georgia': 3,\n",
       "         'registration': 1,\n",
       "         'law': 4,\n",
       "         'are': 3,\n",
       "         'outmoded': 1,\n",
       "         'or': 2,\n",
       "         'inadequate': 1,\n",
       "         'often': 1,\n",
       "         'ambiguous': 1,\n",
       "         'recommended': 4,\n",
       "         'legislator': 2,\n",
       "         'act': 1,\n",
       "         'have': 2,\n",
       "         'these': 6,\n",
       "         'studied': 1,\n",
       "         'revised': 1,\n",
       "         'modernizing': 1,\n",
       "         'improving': 1,\n",
       "         'them': 2,\n",
       "         'commented': 2,\n",
       "         'on': 5,\n",
       "         'other': 2,\n",
       "         'topic': 1,\n",
       "         'among': 1,\n",
       "         'purchasing': 2,\n",
       "         'department': 7,\n",
       "         'well': 1,\n",
       "         'operated': 2,\n",
       "         'follow': 1,\n",
       "         'generally': 1,\n",
       "         'accepted': 1,\n",
       "         'practice': 3,\n",
       "         'inure': 1,\n",
       "         'best': 1,\n",
       "         'both': 1,\n",
       "         'government': 1,\n",
       "         'however': 1,\n",
       "         'belief': 1,\n",
       "         'two': 2,\n",
       "         'office': 3,\n",
       "         'should': 4,\n",
       "         'be': 7,\n",
       "         'combined': 1,\n",
       "         'achieve': 1,\n",
       "         'greater': 1,\n",
       "         'efficiency': 1,\n",
       "         'reduce': 1,\n",
       "         'cost': 2,\n",
       "         'administration': 2,\n",
       "         'is': 3,\n",
       "         'lacking': 1,\n",
       "         'experienced': 1,\n",
       "         'clerical': 1,\n",
       "         'personnel': 2,\n",
       "         'result': 1,\n",
       "         'policy': 1,\n",
       "         'urged': 2,\n",
       "         'take': 2,\n",
       "         'step': 1,\n",
       "         'remedy': 1,\n",
       "         'problem': 1,\n",
       "         'implementation': 2,\n",
       "         'automobile': 1,\n",
       "         'title': 1,\n",
       "         'also': 2,\n",
       "         'outgoing': 1,\n",
       "         'next': 1,\n",
       "         'legislature': 1,\n",
       "         'provide': 1,\n",
       "         'enabling': 2,\n",
       "         'fund': 5,\n",
       "         're-set': 1,\n",
       "         'effective': 1,\n",
       "         'date': 1,\n",
       "         'so': 1,\n",
       "         'orderly': 1,\n",
       "         'may': 1,\n",
       "         'effected': 1,\n",
       "         'swipe': 1,\n",
       "         'at': 4,\n",
       "         'state': 3,\n",
       "         'welfare': 4,\n",
       "         'handling': 1,\n",
       "         'federal': 1,\n",
       "         'granted': 1,\n",
       "         'child': 1,\n",
       "         'service': 1,\n",
       "         'foster': 1,\n",
       "         'home': 2,\n",
       "         'one': 2,\n",
       "         'major': 1,\n",
       "         'item': 1,\n",
       "         'general': 1,\n",
       "         'assistance': 1,\n",
       "         'program': 2,\n",
       "         'but': 2,\n",
       "         'ha': 6,\n",
       "         'seen': 1,\n",
       "         'fit': 1,\n",
       "         'distribute': 1,\n",
       "         'through': 1,\n",
       "         'all': 1,\n",
       "         'with': 3,\n",
       "         'exception': 2,\n",
       "         'receives': 1,\n",
       "         'none': 1,\n",
       "         'money': 1,\n",
       "         'juror': 2,\n",
       "         'they': 2,\n",
       "         'realize': 1,\n",
       "         'proportionate': 1,\n",
       "         'distribution': 1,\n",
       "         'might': 1,\n",
       "         'disable': 1,\n",
       "         'our': 1,\n",
       "         'le': 1,\n",
       "         'populous': 1,\n",
       "         'nevertheless': 1,\n",
       "         'we': 1,\n",
       "         'feel': 1,\n",
       "         'future': 1,\n",
       "         'receive': 1,\n",
       "         'some': 1,\n",
       "         'portion': 1,\n",
       "         'available': 1,\n",
       "         'failure': 1,\n",
       "         'do': 1,\n",
       "         'will': 4,\n",
       "         'continue': 1,\n",
       "         'disproportionate': 1,\n",
       "         'burden': 1,\n",
       "         'taxpayer': 1,\n",
       "         'ordinary': 1,\n",
       "         'under': 1,\n",
       "         'fire': 1,\n",
       "         'appointment': 1,\n",
       "         'appraiser': 1,\n",
       "         'guardian': 1,\n",
       "         'administrator': 1,\n",
       "         'awarding': 1,\n",
       "         'fee': 1,\n",
       "         'compensation': 1,\n",
       "         'found': 1,\n",
       "         'incorporated': 1,\n",
       "         'into': 1,\n",
       "         'operating': 1,\n",
       "         'procedure': 1,\n",
       "         'recommendation': 1,\n",
       "         'previous': 1,\n",
       "         'bar': 1,\n",
       "         'association': 1,\n",
       "         'interim': 1,\n",
       "         'citizen': 1,\n",
       "         'action': 1,\n",
       "         'serve': 1,\n",
       "         'protect': 1,\n",
       "         'fact': 1,\n",
       "         'effect': 1,\n",
       "         'ward': 1,\n",
       "         'from': 3,\n",
       "         'undue': 1,\n",
       "         'appointed': 1,\n",
       "         'elected': 1,\n",
       "         'servant': 1,\n",
       "         'unmeritorious': 1,\n",
       "         'criticism': 1,\n",
       "         'regarding': 1,\n",
       "         'new': 2,\n",
       "         'million': 1,\n",
       "         'dollar': 1,\n",
       "         'airport': 2,\n",
       "         'when': 1,\n",
       "         'management': 1,\n",
       "         'jan.': 2,\n",
       "         '1': 2,\n",
       "         'eliminate': 1,\n",
       "         'political': 2,\n",
       "         'influence': 1,\n",
       "         'not': 3,\n",
       "         'elaborate': 1,\n",
       "         'added': 1,\n",
       "         'there': 1,\n",
       "         'periodic': 1,\n",
       "         'surveillance': 1,\n",
       "         'pricing': 1,\n",
       "         'concessionaire': 1,\n",
       "         'purpose': 1,\n",
       "         'keeping': 1,\n",
       "         'price': 1,\n",
       "         'reasonable': 1,\n",
       "         'matter': 1,\n",
       "         ':': 1,\n",
       "         'four': 1,\n",
       "         'additional': 1,\n",
       "         'deputy': 1,\n",
       "         'employed': 2,\n",
       "         'jail': 2,\n",
       "         'doctor': 1,\n",
       "         'medical': 1,\n",
       "         'intern': 1,\n",
       "         'extern': 1,\n",
       "         'night': 1,\n",
       "         'weekend': 1,\n",
       "         'duty': 1,\n",
       "         'work': 1,\n",
       "         'official': 1,\n",
       "         'pas': 1,\n",
       "         'legislation': 1,\n",
       "         'permit': 1,\n",
       "         'establishment': 1,\n",
       "         'fair': 1,\n",
       "         'equitable': 1,\n",
       "         'pension': 1,\n",
       "         'plan': 1,\n",
       "         'employes': 1,\n",
       "         'praised': 1,\n",
       "         'operation': 1,\n",
       "         'police': 1,\n",
       "         'tax': 1,\n",
       "         'commissioner': 1,\n",
       "         'bellwood': 1,\n",
       "         'alpharetta': 1,\n",
       "         'prison': 1,\n",
       "         'farm': 1,\n",
       "         'grady': 1,\n",
       "         'hospital': 1,\n",
       "         'health': 1,\n",
       "         'mayor': 7,\n",
       "         'william': 2,\n",
       "         'b.': 1,\n",
       "         'hartsfield': 5,\n",
       "         'filed': 1,\n",
       "         'suit': 1,\n",
       "         'divorce': 1,\n",
       "         'his': 6,\n",
       "         'wife': 3,\n",
       "         'pearl': 1,\n",
       "         'williams': 1,\n",
       "         'petition': 4,\n",
       "         'mental': 1,\n",
       "         'cruelty': 1,\n",
       "         'couple': 2,\n",
       "         'married': 1,\n",
       "         'aug.': 1,\n",
       "         '2': 1,\n",
       "         '1913': 1,\n",
       "         'son': 1,\n",
       "         'berry': 1,\n",
       "         'daughter': 1,\n",
       "         'mrs.': 1,\n",
       "         'j.': 1,\n",
       "         'm.': 1,\n",
       "         'cheshire': 1,\n",
       "         'griffin': 1,\n",
       "         'attorney': 3,\n",
       "         'amicable': 1,\n",
       "         'property': 1,\n",
       "         'settlement': 1,\n",
       "         'agreed': 1,\n",
       "         'upon': 1,\n",
       "         'listed': 3,\n",
       "         'occupation': 1,\n",
       "         'age': 2,\n",
       "         '71': 1,\n",
       "         '74': 1,\n",
       "         'birth': 1,\n",
       "         'opelika': 1,\n",
       "         'ala.': 1,\n",
       "         'lived': 1,\n",
       "         'together': 1,\n",
       "         'man': 1,\n",
       "         'more': 1,\n",
       "         'than': 1,\n",
       "         'year': 1,\n",
       "         '637': 1,\n",
       "         'e.': 1,\n",
       "         'pelham': 1,\n",
       "         'rd.': 1,\n",
       "         'ne': 1,\n",
       "         'henry': 1,\n",
       "         'l.': 1,\n",
       "         'bowden': 1,\n",
       "         'brief': 1,\n",
       "         'interlude': 1,\n",
       "         'since': 1,\n",
       "         '1937': 1,\n",
       "         'career': 1,\n",
       "         'go': 1,\n",
       "         'back': 1,\n",
       "         'council': 1,\n",
       "         '1923': 1,\n",
       "         'present': 1,\n",
       "         'expires': 1,\n",
       "         'he': 2,\n",
       "         'succeeded': 1,\n",
       "         'who': 1,\n",
       "         'became': 1,\n",
       "         'candidate': 2,\n",
       "         'sept.': 1,\n",
       "         '13': 1,\n",
       "         'after': 1,\n",
       "         'announced': 1,\n",
       "         'would': 1,\n",
       "         'run': 1,\n",
       "         'reelection': 1,\n",
       "         'republican': 1,\n",
       "         'getting': 1,\n",
       "         'strong': 1,\n",
       "         'encouragement': 1,\n",
       "         'enter': 1})"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "create a dictionary of tokens in semcor with counts\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "TODO is this a problem? that we have things like `group.n.01.group' which have wildly different tokens.\n",
    "\"\"\"\n",
    "from collections import Counter\n",
    "\n",
    "semcor_lexicon = Counter()\n",
    "\n",
    "for word in words:\n",
    "    word = word.lower()\n",
    "    lemma = lemmatizer.lemmatize(word)\n",
    "    semcor_lexicon[lemma] +=1\n",
    "\n",
    "# for sent in tagged_sents:\n",
    "#     sent_lemmas = get_senses_in_tagged_sentence(sent)\n",
    "#     for lemma in sent_lemmas:\n",
    "#         semcor_lexicon[lemma] += 1\n",
    "        \n",
    "        \n",
    "semcor_lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 49074), (',', 40614), ('.', 34716), ('of', 24954), ('and', 19960), ('to', 18089), ('a', 16399), ('in', 15012), ('that', 7541), ('is', 7228), ('he', 6812), ('was', 6773), ('for', 6574), ('it', 6375), ('``', 6169), (\"''\", 6097), ('with', 5145), ('as', 4953), ('on', 4818), ('his', 4604), ('be', 4552), (\"'s\", 4037), ('at', 3765), ('by', 3688), ('this', 3639), ('i', 3589), ('had', 3534), ('not', 3247), ('are', 3171), ('but', 3076), ('from', 3032), ('-', 2967), ('or', 2917), ('have', 2811), ('they', 2759), ('an', 2648), ('you', 2629), ('which', 2495), ('one', 2359), ('were', 2319), ('all', 2121), ('would', 2052), ('there', 2019), (';', 1997), ('we', 1972), ('she', 1968), ('their', 1926), ('her', 1909), ('has', 1857), ('him', 1801), ('?', 1715), ('been', 1714), ('when', 1629), ('will', 1611), ('more', 1592), ('who', 1580), ('if', 1545), (')', 1535), ('(', 1524), ('no', 1520), ('out', 1488), ('said', 1412), (\"n't\", 1407), ('so', 1384), ('can', 1379), ('what', 1377), ('do', 1358), ('up', 1343), (':', 1328), ('its', 1319), ('than', 1289), ('into', 1282), ('about', 1274), ('could', 1269), ('them', 1265), ('only', 1243), ('*', 1211), ('other', 1205), ('new', 1163), ('some', 1140), ('time', 1113), ('these', 1096), ('two', 1042), ('may', 1018), ('did', 985), ('then', 968), ('first', 965), ('any', 957), ('such', 954), ('man', 925), ('now', 921), ('like', 913), ('over', 910), ('my', 875), ('our', 861), (\"'\", 828), ('most', 818), ('made', 813), ('even', 788), ('also', 760), ('after', 744), ('many', 727), ('must', 713), ('me', 713), ('where', 702), ('through', 690), ('your', 687), ('before', 683), ('years', 679), ('each', 675), ('back', 671), ('way', 651), ('much', 643), ('state', 638), ('mr.', 635), ('f', 628), ('down', 618), ('should', 616), ('people', 616), ('how', 615), ('just', 613), ('well', 600), ('those', 591), ('good', 589), ('too', 586), ('because', 581), ('year', 566), ('make', 566), ('world', 566), ('little', 556), ('long', 555), ('here', 548), ('still', 547), ('!', 544), ('very', 541), ('get', 538), ('see', 535), ('work', 523), ('men', 519), ('last', 515), ('own', 509), ('day', 504), ('life', 503), ('under', 501), ('old', 499), ('both', 497), ('being', 496), ('same', 489), ('between', 485), ('know', 478), ('2', 477), ('1', 472), ('off', 471), ('us', 471), ('another', 468), ('three', 467), ('take', 452), ('since', 451), ('while', 451), ('never', 450), ('great', 449), ('states', 444), ('might', 442), ('go', 435), ('against', 435), ('$', 430), ('come', 429), ('right', 424), ('american', 424), ('place', 422), ('again', 421), ('house', 420), ('came', 414), ('does', 406), ('himself', 406), ('few', 406), ('mrs.', 401), ('without', 395), ('small', 393), ('home', 392), ('around', 390), ('use', 383), ('high', 381), ('however', 380), ('found', 378), ('used', 375), ('during', 370), ('every', 363), ('left', 351), ('general', 349), ('city', 345), ('away', 345), ('part', 342), ('school', 339), ('thought', 339), ('say', 339), ('united', 337), ('went', 336), ('got', 332), ('number', 331)]\n",
      "[('unrepentant', 1), ('shoestring', 1), ('unbeknownst', 1), ('moors', 1), ('inherits', 1), ('marquess', 1), ('gauntley', 1), ('farmed', 1), ('over-spent', 1), ('unfunny', 1), ('irreverent', 1), ('tasteless', 1), ('deigned', 1), ('dens', 1), ('punctually', 1), ('tailor-made', 1), ('beatification', 1), ('sainted', 1), ('screenland', 1), ('antisocial', 1), ('crosbys', 1), ('barrymores', 1), ('thalbergs', 1), ('taylors', 1), ('rathbones', 1), ('colmans', 1), ('astaires', 1), ('filmdom', 1), ('arbiter', 1), ('errol', 1), ('aquacutie', 1), ('overcooked', 1), ('collation', 1), ('trianon', 1), ('slights', 1), ('adored', 1), ('abundantly', 1), ('retort', 1), ('ungallant', 1), ('commonest', 1), ('carousing', 1), ('gaming', 1), ('monies', 1), ('dislocated', 1), ('tailor', 1), ('storming', 1), ('sulks', 1), ('helpmate', 1), ('co-star', 1), ('thespians', 1), ('casting', 1), ('unflagging', 1), ('conducive', 1), ('distractions', 1), ('imperilled', 1), ('ccc', 1), ('wpa', 1), ('pwa', 1), ('nra', 1), ('fascio-communist', 1), ('ere', 1), ('baroness', 1), ('notoriety', 1), ('manny', 1), ('governmen', 1), ('usurious', 1), ('prohibitive', 1), ('nineveh', 1), ('caligula', 1), ('belle', 1), ('broun', 1), ('litigant', 1), ('grata', 1), ('persona', 1), ('portia', 1), ('sycophants', 1), ('toadies', 1), ('henchmen', 1), ('tigress', 1), ('leftist', 1), ('hard-come-by', 1), ('relict', 1), ('iniquitous', 1), ('bolshevistic', 1), ('despoiling', 1), ('sacking', 1), ('barbarian', 1), ('lingerie', 1), ('ransacking', 1), ('larder', 1), ('bowes', 1), ('empting', 1), ('coast-to-coast', 1), ('snoop', 1), ('thrills', 1), ('icing', 1), ('bananas', 1), ('reverently', 1), ('maurier', 1), ('daphne', 1), ('85000', 1), ('parent-teacher', 1), ('gardeners', 1), ('homesteads', 1), ('unadulterated', 1), ('misty-eyed', 1), ('too-hearty', 1), ('country-squirehood', 1), ('hair-trigger', 1), ('housepaint', 1), ('ultra-modern', 1), ('sarcastic', 1), ('unfunnily', 1), ('rivals', 1), ('mesta', 1), ('perle', 1), ('cafritz', 1), ('gwen', 1), ('astringency', 1), ('valueless', 1), ('red-blooded', 1), ('souffle', 1), ('ruefulness', 1), ('marshmallows', 1), ('marinated', 1), ('baccarat', 1), ('ss.', 1), ('plaids', 1), ('centuries-old', 1), ('suburbia', 1), ('dabbler', 1), ('heiress', 1), ('woolgather', 1), ('gainer', 1), ('thuds', 1), ('screeches', 1), ('remoter', 1), ('endearments', 1), ('creamed', 1), ('sprig', 1), ('asparagus', 1), ('giblet', 1), ('ladle', 1), ('hotbed', 1), ('chaperon', 1), ('cosy', 1), ('chi-chi', 1), ('debs', 1), ('matrimonial', 1), ('trump', 1), ('hoi-polloi', 1), ('doug', 1), ('pickfair', 1), ('midsts', 1), ('aristocrats', 1), ('pickles', 1), ('heinzes', 1), ('chalmers', 1), ('budweisers', 1), ('scions', 1), ('angeles-pasadena', 1), ('czarship', 1), ('snobbishly', 1), ('commiserate', 1), ('culprit', 1), ('footwear', 1), ('southland', 1), ('prank', 1), ('unidentified', 1), ('luckier', 1), ('overvaulting', 1), ('addict', 1), ('cahoots', 1), ('gibes', 1), ('quibs', 1), ('shrub-covered', 1), ('cortege', 1), ('matter-of-factness', 1), ('cameramen', 1), ('pooh-poohed', 1), ('shifty', 1), ('mayorship', 1), ('vaulting', 1), ('lifelong', 1), ('fainted', 1), ('unhinged', 1), ('glendale', 1), ('pawnshop', 1), ('tamale', 1), ('by-the-sea', 1), ('capistrano', 1), ('gasse', 1), ('olde', 1), ('cal', 1), ('instigation', 1), ('mormon', 1), ('fancying', 1), ('hinkle', 1), ('bright-eyed', 1), ('retrieve', 1), ('despondent', 1), ('numerals', 1), ('cobblestones', 1), ('clasped', 1), ('anyplace', 1), ('arim', 1), ('slyly', 1), ('aliah', 1), ('kibbutzim', 1), ('respectfully', 1), ('messiah', 1), ('sabras', 1), ('pruta', 1), ('shabbat', 1), ('clucked', 1), ('off-key', 1), ('singsonged', 1), ('curls', 1), ('incessantly', 1), ('prayerbooks', 1), ('yellowed', 1), ('ringlets', 1), ('upturned', 1), ('shrilled', 1), ('half-closed', 1), ('surly', 1), ('bare-armed', 1), ('unclasping', 1), ('ajar', 1), ('discolored', 1), ('pivoting', 1), ('long-sleeved', 1), ('pinkish-white', 1), ('warmish', 1), ('torah', 1), ('sylphide', 1), ('gisele', 1), ('propositioned', 1), ('sun-suit', 1), ('crap', 1), ('crossroading', 1), ('stickman', 1), ('instigating', 1), ('cal-neva', 1), ('sun-tan', 1), ('chuck-a-luck', 1), ('schoolgirls', 1), ('floorshow', 1), ('flipping', 1), ('shills', 1), ('shill', 1), ('waned', 1), ('keno', 1), ('den', 1), ('jinx', 1), ('pinto', 1), ('washoe', 1), ('single-foot', 1), ('five-seventeen', 1), ('hit-and-miss', 1), ('martingale', 1), ('dried-up', 1), ('bested', 1), ('one-arm', 1), ('heavily-upholstered', 1), ('donner', 1), ('mural', 1), ('spangle', 1), ('truckee', 1), ('glisten', 1), ('alimony', 1), ('overdue', 1), ('showered', 1), ('indecisively', 1), ('crestfallen', 1), ('bucking-up', 1), ('heatedly', 1), ('waspishly', 1), ('bibles', 1), ('remonstrated', 1), ('overexcited', 1), ('hundred-and-fifty', 1), ('corridors', 1), ('forebearing', 1), ('canvassing', 1), ('sickly-tolerant', 1), ('sappy', 1), ('sparkled', 1), ('semi-professionally', 1), ('moons', 1), ('ahah', 1), ('instigator', 1), ('willows', 1), ('all-lesbian', 1), ('scrumptious', 1), ('strippers', 1), ('wow', 1), ('excursion', 1), ('gangway', 1), ('gresham', 1), ('mccafferty', 1), ('bustard', 1), ('slaughtering', 1), ('indoctrination', 1), ('perils', 1), ('appleby', 1), ('dispensed', 1), ('miuchi', 1), ('yori', 1), ('tanin', 1), ('kotowaza', 1), ('kimono', 1), ('yokusuka', 1), ('oyajima', 1), ('sulked', 1), ('soda', 1), ('bicarbonate', 1), ('put-upon', 1), ('after-duty', 1), ('transient', 1), ('doting', 1), ('whitehaired', 1), ('futotsu', 1), ('kohi', 1), ('bifutek-san', 1), ('kobayashi', 1), ('yuki', 1), ('waitresses', 1), ('brunettes', 1), ('fly-boy', 1), ('slang', 1), ('nice-looking', 1), ('likee', 1), ('boy-furiendo', 1), ('catchee', 1), ('girl-san', 1), ('harro', 1), ('fifty-fifty', 1), ('six-month', 1), ('inshore', 1), ('chaplain', 1), ('depressingly', 1), ('bremerton', 1), ('forebears', 1), ('sunburn', 1), ('willowy', 1), ('tint', 1), ('honey-in-the-sun', 1), ('tawny', 1), ('prefectures', 1), ('akita', 1), ('chants', 1), ('subsist', 1), ('caucasian', 1), ('ainus', 1), ('ainu', 1), ('honshu', 1), ('prefecture', 1), ('rock-carved', 1), ('indecipherable', 1), ('sea-damp', 1), ('tredding', 1), ('headstones', 1), ('stony', 1), ('clawing', 1), ('gabble', 1), ('mightily', 1), ('delia', 1), ('somewheres', 1), ('forgave', 1), ('piously', 1), ('owly', 1), ('sops', 1), ('porridge', 1), ('gran', 1), ('drab-haired', 1), ('big-boned', 1), ('connivance', 1), ('fishing-boat', 1), ('mariner', 1), ('blackwells', 1), ('pacifies', 1), ('womanly', 1), ('soldierly', 1), ('doubtfully', 1), ('sap', 1), ('acknowledgments', 1), ('princess-in-a-carriage', 1), ('frankest', 1), ('shuttered', 1), ('slumbered', 1), ('forepaws', 1), ('prayerful', 1), ('gleefully', 1), ('grasses', 1), ('bedstraw', 1), ('bun', 1), ('unbelievably', 1), ('femme', 1), ('nondescriptly', 1), ('dewdrops', 1), ('thorns', 1), ('rosebush', 1), ('wildness', 1), ('colloquy', 1), ('fetes', 1), ('teas', 1), ('wand', 1), ('craddock', 1), ('maneret', 1), ('garnet', 1), ('purtiest', 1), ('eph', 1), ('perk', 1), ('dang', 1), ('nigs', 1), ('dollies', 1), ('to-do', 1), ('teething', 1), ('snippy', 1), ('rakestraw', 1), ('peach', 1), ('handsomest', 1), ('boy-name', 1), ('kezziah', 1), ('jennifer', 1), ('edmonia', 1), ('flotilla', 1), ('arcilla', 1), ('trippin', 1), ('jiffy', 1), ('russe', 1), ('mash', 1), ('bran', 1), ('liniment', 1), ('quarts', 1), ('veterinarian', 1), ('aversion', 1), ('midwife', 1), ('foals', 1), ('mus', 1), ('sor', 1), ('oneasy', 1), ('imperiously', 1), ('revolting', 1), ('racin', 1), ('what-nots', 1), ('geldings', 1), ('mares', 1), ('carte', 1), ('plain-out', 1), ('howdy', 1), ('blacksmith', 1), ('easygoing', 1), ('thimble', 1), ('grandsons', 1), ('swinburne', 1), ('gathers', 1), ('feathery', 1), ('pyre', 1), ('lacerate', 1), ('deception', 1), ('pigeonhole', 1), ('asunder', 1), ('log-house', 1), ('valiant', 1), ('labans', 1), ('marrying', 1), ('overturning', 1), ('bedspread', 1), ('wallow', 1), ('mouthful', 1), ('groaning', 1), ('undressed', 1), ('bathrooms', 1), ('swabbed', 1), ('anxieties', 1), ('shipwrecked', 1), ('stormbound', 1), ('fireplaces', 1), ('ravenous', 1), ('leaks', 1), ('abernathys', 1), ('remedies', 1), ('open-handed', 1), ('bumptious', 1), ('harshened', 1), ('playroom', 1), ('cribs', 1), ('jotting', 1), ('liliputian', 1), ('ironed', 1), ('nuzzled', 1), ('starched', 1), ('pored', 1), ('washer', 1), ('peaches', 1), ('rages', 1), ('flaxen', 1), ('quench', 1), ('twigs', 1), ('wisps', 1), ('ever-tightening', 1), ('writhed', 1), ('snared', 1), ('foreclosing', 1), ('demoniac', 1), ('stifled', 1), ('incubus', 1), ('nipples', 1), ('blouse', 1), ('unwholesome', 1), ('dreamt', 1), ('mouldering', 1), ('laboriously', 1), ('spasms', 1), ('bruising', 1), ('maliciously', 1), ('numbingly', 1), ('drawbridge', 1), ('eclipsing', 1), ('hindrances', 1), ('unguided', 1), ('detours', 1), ('scoffing', 1), ('benighted', 1), ('dimly-outlined', 1), ('impinge', 1), ('tranquillity', 1), ('beneficence', 1), ('thrive', 1), ('pacifist', 1), ('unmotivated', 1), ('berries', 1), ('prowled', 1), ('darkling', 1), ('unenunciated', 1), ('reawaken', 1), ('culvers', 1), ('dewy-eyed', 1), ('chirped', 1), ('renunciation', 1), ('unnameable', 1), ('unnamed', 1), ('expiation', 1), ('desecrated', 1), ('munroe', 1), ('felony', 1), ('partaking', 1), ('ostensible', 1), ('sprite', 1), ('bribed', 1), ('folsom', 1), ('tintype', 1), ('cleanups', 1), ('hi-graders', 1), ('machinelike', 1), ('cobra', 1), ('lizard', 1), ('lidless', 1), ('mucker', 1), ('clawed', 1), ('foothill', 1), ('eardrums', 1), ('deafened', 1), ('tornadoes', 1), ('hoses', 1), ('cemented', 1), ('buckled', 1), ('tertiary', 1), ('seventy-five-foot', 1), ('dwarfed', 1), ('ione', 1), ('keg', 1), ('bloomfield', 1), ('burlingame', 1), ('entrust', 1), ('rougher', 1), ('ayres', 1), ('petered', 1), ('haulage', 1), ('easterners', 1), ('tirelessly', 1), ('auditor', 1), ('exhaled', 1), ('killers', 1), ('starve', 1), ('ex-prison', 1), ('butternut', 1), ('shedding', 1), ('ghosted', 1), ('wicket', 1), ('viciousness', 1), ('pinochle', 1), ('guard-room', 1), ('thin-lipped', 1), ('sneered', 1), ('wellbeing', 1), ('hankered', 1), ('tapdance', 1), ('perforated', 1), ('green-tinted', 1), ('footfalls', 1), ('personage', 1), ('winches', 1), ('funnels', 1), ('masts', 1), ('self-appointed', 1), ('urinals', 1), ('rearranging', 1), ('dog-eared', 1), ('tabloids', 1), ('gob', 1), ('affectation', 1), ('wail', 1), ('bellies', 1), ('hawkinses', 1), ('saddles', 1), ('hurdled', 1), ('shrilling', 1), ('stench', 1), ('acrid', 1), ('new-spilled', 1), ('sweetish', 1), ('reorganizing', 1), ('corded', 1), ('clout', 1), ('quivered', 1), ('scalp', 1), ('unconcernedly', 1), ('whinny', 1), ('coyotes', 1), ('stitched', 1), ('missy', 1), ('talkin', 1), ('hankerin', 1), ('fightin', 1), ('unruffled', 1), ('voyageurs', 1), ('dirion', 1), ('hobble', 1), ('gash', 1), ('pillar', 1), ('hustle', 1), ('lew', 1), ('grub', 1), ('gawdamighty', 1), ('mudwagon', 1), ('thudding', 1), ('hovered', 1), ('crossbars', 1), ('whipsawed', 1), ('floundered', 1), ('snatching', 1), ('shouldering', 1), ('pallet', 1), ('canisters', 1), ('half-clad', 1), ('stealin', 1), ('paches', 1), ('whoop', 1), ('ropes', 1), ('gallop', 1), ('whack', 1), ('panted', 1), ('feds', 1), ('tethers', 1), ('felling', 1), ('backlash', 1), ('parried', 1), ('slouch', 1), ('near-at-hand', 1), ('pierced', 1), ('sop', 1), ('unutterably', 1), ('blustered', 1), ('bandage', 1), ('unsteady', 1), ('gagged', 1), ('tunic', 1), ('cap-and-ball', 1), ('enfield', 1), ('reviving', 1), ('pines', 1), ('bloodless', 1), ('pursuers', 1), ('pennants', 1), ('silas', 1), ('fluttered', 1), ('nellie', 1), ('lame', 1), ('rustled', 1), ('windless', 1), ('gullies', 1), ('palely', 1), ('ambushed', 1), ('untenanted', 1), ('huskily', 1), ('bumping', 1), ('looped', 1), ('cinches', 1), ('driftin', 1), ('anythin', 1), ('pache', 1), ('croaks', 1), ('splendide', 1), ('rittenhouse', 1), ('savvy', 1), ('scissors', 1), ('innocents', 1), ('best-looking', 1), ('rafter', 1), ('dejectedly', 1), ('woebegone', 1), ('buckhorn', 1), ('half-acre', 1), ('greedily', 1), ('frowzy', 1), ('angling', 1), ('renfro', 1), ('fickle', 1), ('commingled', 1), ('geysers', 1), ('kindliness', 1), ('seating', 1), ('cow-people', 1), ('cow-man', 1), ('perplexity', 1), ('threshed', 1), ('ground-truck', 1), ('burned-out', 1), ('nicest', 1), ('teratologies', 1), ('toe-tips', 1), ('dabbed', 1), ('child-face', 1), ('senselessly', 1), ('implant', 1), ('dromozootic', 1), ('well-read', 1), ('earth-week', 1), ('earth-weeks', 1), ('lovelies', 1), ('decorticated', 1), ('dummies', 1), ('obviousness', 1), ('eye-machine', 1), ('half-transparent', 1), ('prettily', 1), ('benign', 1), ('inwardness', 1), ('friendlily', 1), ('hand-covered', 1), ('itching', 1), ('agonies', 1), ('sterilizing', 1), ('companionable', 1), ('thicken', 1), ('pinkly', 1), ('babbled', 1), ('many-bodied', 1), ('spacesuit', 1), ('hug', 1), ('two-nosed', 1), ('fingernails', 1), ('self-pitying', 1), ('scanners', 1), ('activating', 1), ('wrangled', 1), ('annals', 1), ('ambulatory', 1), ('anesthetically', 1), ('taps', 1), ('delicate-beyond-description', 1), ('extendibles', 1), ('indestructible', 1), ('titanium', 1), ('xh-834', 1), ('avocation', 1), ('mezzo', 1), ('unharmonious', 1), ('unpleased', 1), ('felicitous', 1), ('sinuses', 1), ('enunciation', 1), ('extricate', 1), ('nondefeatist', 1), ('prognosis', 1), ('schooled', 1), ('altairians', 1), ('concerti', 1), ('chromatics', 1), ('capellan', 1), ('venusians', 1), ('presley', 1), ('figaro', 1), ('nozze', 1), ('candide', 1), ('isolde', 1), ('tristan', 1), ('appreciatively', 1), ('contrite', 1), ('bugged', 1), ('unmagnified', 1), ('twittered', 1), ('reproducing', 1), ('meditation', 1), ('sheered', 1), ('unshelled', 1), ('intra-stellar', 1), ('cratered', 1), ('gurgle', 1), ('dulcet', 1), ('diaphragms', 1), ('cords', 1), ('absentmindedly', 1), ('overridden', 1), ('shelled', 1), ('inhumanities', 1), ('do-good', 1), ('sub-conscious-level', 1), ('ceteras', 1), ('philology', 1), ('power-seek', 1), ('well-oriented', 1), ('deformities', 1), ('dwarfs', 1), ('rogue', 1), ('shell-psychology', 1), ('bide', 1), ('tinkering', 1), ('side-effects', 1), ('partnered', 1), ('synapses', 1), ('matured', 1), ('manipulated', 1), ('transferral', 1), ('crabbed', 1), ('patsy', 1), ('expe', 1), ('veldt', 1), ('beasties', 1), ('burnt-red', 1), ('sleeplessly', 1), ('sterility', 1), ('pontifical', 1), ('repercussions', 1), ('no-back', 1), ('shipboard', 1), ('shipmates', 1), ('gritty-eyed', 1), ('fitfully', 1), ('birthed', 1), ('soundly', 1), ('couches', 1), ('138', 1), ('yancey-6', 1), ('ringed', 1), ('xenophobia', 1), ('blastdown', 1), ('dissect', 1), ('creepy', 1), ('wart-hog', 1), ('seismological', 1), ('mammal', 1), ('warm-blooded', 1), ('lapel', 1), ('airlock', 1), ('ambidextrous', 1), ('lug', 1), ('dials', 1), ('mis-reading', 1), ('unfathomable', 1), ('encephalographic', 1), ('interjected', 1), ('antarctica', 1), ('yancy-6', 1), ('planetoids', 1), ('infuriation', 1), ('asteroid', 1), ('swath', 1), ('facsiport', 1), ('ground-level', 1), ('hefted', 1), ('t-tau', 1), ('reinstall', 1), ('excised', 1), ('holies', 1), ('observant', 1), ('frighteningly', 1), ('nebula', 1), ('fuming', 1), ('light-year', 1), ('numenous', 1), ('unfurled', 1), ('spacesuits', 1), ('hove', 1), ('hegemony', 1), ('unreassuringly', 1), ('sanest', 1), ('codified', 1), ('ratify', 1), ('first-born', 1), ('galactic', 1), ('value-judgments', 1), ('mesmerized', 1), ('reminiscences', 1), ('chimera-chasing', 1), ('unscramble', 1), ('anagram', 1), ('kingsley', 1), ('pungency', 1), ('stone-blind', 1), ('clanged', 1), ('tomblike', 1), ('hall-mills', 1), ('iroquois', 1), ('two-line', 1), ('basketball-playing', 1), ('distract', 1), ('cropping', 1), ('plod', 1), ('casters', 1), ('burrowing', 1), ('stacks', 1), ('thrumming', 1), ('mustiness', 1), ('leather-bound', 1), ('grillework', 1), ('latches', 1), ('lindsay', 1), ('rolled-up', 1), ('reportorial', 1), ('allergy', 1), ('breaking-out', 1), ('pecked', 1), ('frizzled', 1), ('gallstone', 1), ('obituaries', 1), ('bright-green', 1), ('improbably', 1), ('azaleas', 1), ('camellias', 1), ('semitropical', 1), ('hedges', 1), ('privet', 1), ('white-stucco', 1), ('garish', 1), ('jeb', 1), ('peabody', 1), ('liz', 1), ('stowed', 1), ('skeleton', 1), ('tumble', 1), ('deceitful', 1), ('safekeeping', 1), ('undulating', 1), ('wastrel', 1), ('lamming', 1), ('sudden-end', 1), ('newel', 1), ('careened', 1), ('bloodstained', 1), ('mid-air', 1), ('feebly', 1), ('forearm', 1), ('invulnerable', 1), ('knifelike', 1), ('wrenching', 1), ('flatten', 1), ('transoms', 1), ('wall-switch', 1), ('good-humoredly', 1), ('sprinkled', 1), ('recumbent', 1), ('gum-chewing', 1), ('hatchet-faced', 1), ('half-turned', 1), ('coupe', 1), ('sipped', 1), ('conspiratorial', 1), ('twenty-dollar', 1), ('cognac', 1), ('groaned', 1), ('commending', 1), ('petey', 1), ('briefly-illumed', 1), ('palm-lined', 1), ('neon-lighted', 1), ('divider', 1), ('bracelet', 1), ('counterfeit', 1), ('aforethought', 1), ('knife-men', 1), ('buenas', 1), ('putas', 1), ('marsha', 1), ('ice-cubes', 1), ('half-melted', 1), ('slopped', 1), ('alai', 1), ('jai', 1), ('redneck', 1), ('yellow-bellied', 1), ('cabdriver', 1), ('brusquely', 1), ('estes', 1), ('siren', 1), ('reverberated', 1), ('hurtled', 1), ('pedals', 1), ('lacerated', 1), ('stone-still', 1), ('bristled', 1), ('dogtrot', 1), ('tormenters', 1), ('barbed-wire', 1), ('hyped-up', 1), ('affluent', 1), ('howling', 1), ('pained', 1), ('banshee', 1), ('chancellorsville', 1), ('eerie', 1), ('equidistant', 1), ('water-filled', 1), ('drummed', 1), ('disgraced', 1), ('toddlers', 1), ('puddles', 1), ('viscous', 1), ('mud-caked', 1), ('quagmire', 1), ('infinity', 1), ('farmhouses', 1), ('wheezing', 1), ('exuded', 1), ('filaments', 1), ('yawn', 1), ('387', 1), ('deviate', 1), ('trickling', 1), ('door-frame', 1), ('unopened', 1), ('wetly', 1), ('sniggered', 1), ('aleck', 1), ('scaring', 1), ('sullenly', 1), ('kin', 1), ('soothingly', 1), ('dispenser', 1), ('napkin', 1), ('catchup', 1), ('steiner', 1), ('coulda', 1), ('sompin', 1), ('zipper', 1), ('zombie', 1), ('howda', 1), ('musta', 1), ('corsi', 1), ('zipped', 1), ('rat-face', 1), ('sideboard', 1), ('rash', 1), ('that-a-way', 1), ('wiggle', 1), ('provocatively', 1), ('kindness', 1), ('dowling', 1), ('buzz-buzz-buzz', 1), ('ten-fifty-five', 1), ('commences', 1), ('pout', 1), ('sociable', 1), ('tightest-fitting', 1), ('bedded', 1), ('postponing', 1), ('amplifier', 1), ('cracker-box', 1), ('sidelong', 1), ('soft-drink', 1), ('alias', 1), ('transposition', 1), ('charcoal-broiled', 1), ('high-class', 1), ('quarry', 1), ('drawn-out', 1), ('snappy', 1), ('transients', 1), ('sublease', 1), ('disagreeable', 1), ('magnifies', 1), ('inconspicuous', 1), ('jym', 1), ('jyj', 1), ('once-over', 1), ('chauffeur', 1), ('shiningly', 1), ('motioned', 1), ('tenspot', 1), ('untimely', 1), ('sorrows', 1), ('bellboy', 1), ('schraffts', 1), ('counterman', 1), ('five-a-week', 1), ('croydon', 1), ('chicagoans', 1), ('sun-times', 1), ('kupcinet', 1), ('unjustified', 1), ('grade-a', 1), ('figment', 1), ('jabberings', 1), ('orphan', 1), ('remorse', 1), ('gentleness', 1), ('hallucinating', 1), ('thirty-eight', 1), ('j28-6033-1', 1), ('j28-6105', 1), ('conventionality', 1), ('guardedness', 1), ('aniseikonic', 1), ('stationary', 1), ('relinquishing', 1), ('hesitant', 1), ('abeyance', 1), ('involuntary-control', 1), ('voluntary-control', 1), ('hypnosis', 1), ('ingestion', 1), ('inhibiting', 1), ('levitation', 1), ('normals', 1), ('arm-rise', 1), ('autosuggestibility', 1), ('uninfluenced', 1), ('behaviorally', 1), ('.028', 1), ('two-tail', 1), ('2.405', 1), ('nonshifters', 1), ('shifters', 1), ('rorschach', 1), ('oagco', 1), ('gamin', 1), ('stdcr', 1), ('guilford', 1), ('structuring', 1), ('examiantion', 1), ('trimester', 1), ('childless', 1), ('reproductive', 1), ('associating', 1), ('survivor', 1), ('in-laws', 1), ('empathy', 1), ('contagious', 1), ('three-fourths', 1), ('cognizant', 1), ('re-evaluate', 1), ('encroach', 1), ('pre-marital', 1), ('digress', 1), ('premarital', 1), ('senior-graduate', 1), ('auditing', 1), ('electives', 1), ('sophomores', 1), ('rationalized', 1), ('all-married', 1), ('not-yet-married', 1), ('flemish', 1), ('expeditiously', 1), ('post-census', 1), ('calculable', 1), ('demographiques', 1), ('enquetes', 1), ('walle', 1), ('neesen', 1), ('statistique', 1), ('romaniuk', 1), ('demographie', 1), ('circumscriptions', 1), ('1100', 1), ('sub-chiefs', 1), ('officielle', 1), ('universite', 1), ('maquet', 1), ('in-migrants', 1), ('centrale', 1), ('afrique', 1), ('scientifique', 1), ('recherche', 1), ('bruxelles', 1), ('annee', 1), ('pendant', 1), ('activite', 1), ('kwango', 1), ('840503', 1), ('638560', 1), ('foreami', 1), ('aux', 1), ('medicale', 1), ('fonds', 1), ('domiciled', 1), ('non-polygynous', 1), ('polygynous', 1), ('compilations', 1), ('circonscriptions', 1), ('inoculations', 1), ('puberty', 1), ('chiefdom', 1), ('territoire', 1), ('sub-chiefdom', 1), ('circonscription', 1), ('fiche', 1), ('tabulations', 1), ('gouvernement', 1), ('oeuvre', 1), ('main-d', 1), ('affaires', 1), ('governor-general', 1), ('chiefdoms', 1), ('intergroup', 1), ('ostracism', 1), ('heterogamous', 1), ('incurs', 1), ('urban-fringe', 1), ('over-simplification', 1), ('facilitated', 1), ('institutionalization', 1), ('inter-relation', 1), ('non-social', 1), ('clustering', 1), ('inbreeding', 1), ('substructure', 1), ('affinities', 1), ('relational', 1), ('interconnected', 1), ('inter-relationships', 1), ('consanguineous', 1), ('facilitating', 1), ('consanguineously', 1), ('stringently', 1), ('self-image', 1), ('immutable', 1), ('biologically', 1), ('caste', 1), ('occupancies', 1), ('social-role', 1), ('gemeinschaft', 1), ('exogamous', 1), ('interviewees', 1), ('non-authoritative', 1), ('conjectures', 1), ('status-roles', 1), ('proscribed', 1), ('core-marginal', 1), ('core-core', 1), ('conjectured', 1), ('endogamous', 1), ('interacting', 1), ('baptisms', 1), ('meaningfully', 1), ('abounds', 1), ('afresh', 1), ('multipurpose', 1), ('middle-range', 1), ('globally', 1), ('replete', 1), ('caseworkers', 1), ('typology', 1), ('innovate', 1), ('chronically', 1), ('parent-child', 1), ('predictors', 1), ('levinger', 1), ('telescoped', 1), ('crisis-oriented', 1), ('capacities', 1), ('problem-solving', 1), ('integrative', 1), ('family-oriented', 1), ('preconscious', 1), ('precipitating', 1), ('anticipatory', 1), ('maladaptive', 1), ('ego-adaptive', 1), ('hopelessness', 1), ('maturational', 1), ('relationship-building', 1), ('information-seekingsense', 1), ('helpfulness', 1), ('out-reaching', 1), ('well-baby', 1), ('motherly', 1), ('johnnie', 1), ('perceiving', 1), ('agonized', 1), ('traumatic', 1), ('remarrying', 1), ('bone-weary', 1), ('colicky', 1), ('full-blown', 1), ('phobic-like', 1), ('locus', 1), ('jonquieres', 1), ('directrices', 1), ('bilinear', 1), ('kth', 1), ('intercepts', 1), ('reguli', 1), ('epidemiological', 1), ('bibliography', 1), ('bimonthly', 1), ('november-december', 1), ('reinstitution', 1), ('unexpended', 1), ('stapling', 1), ('typesetting', 1), ('varityping', 1), ('photo-offset', 1), ('reviews', 1), ('795586', 1), ('requesters', 1), ('surgical', 1), ('microscopes', 1), ('accessions', 1), ('short-time', 1), ('great-grandson', 1), ('macropathology', 1), ('eighty-five', 1), ('254', 1), ('885', 1), ('161', 1), ('7827', 1), ('642', 1), ('54320', 1), ('37470', 1), ('surgeons', 1), ('military-medical', 1), ('testicular', 1), ('managua', 1), ('south-east', 1), ('handbook', 1), ('splinting', 1), ('bandaging', 1), ('transparency', 1), ('projector', 1), ('manikins', 1), ('kits', 1), ('lectured', 1), ('operable', 1), ('twenty-nine', 1), ('442', 1), ('762', 1), ('fabrication', 1), ('photomicrography', 1), ('mycobacteria', 1), ('leprae', 1), ('lymphoma', 1), ('synthesizine', 1), ('diphosphopyridine', 1), ('microcytochemistry', 1), ('microchemistry', 1), ('microscopical', 1), ('biophysical', 1), ('dysplasia', 1), ('histochemical', 1), ('prostate', 1), ('carcinoma', 1), ('neuropathology', 1), ('microwaves', 1), ('cardiovasculatory', 1), ('431', 1), ('dire', 1), ('skeptically', 1), ('frugality', 1), ('intermissions', 1), ('alternated', 1), ('1581', 1), ('comique', 1), ('medicis', 1), ('1550', 1), ('flowered', 1), ('1450', 1), ('observances', 1), ('saabye', 1), ('rededicate', 1), ('fourteenth', 1), ('homestead', 1), ('commemorating', 1), ('commemorated', 1), ('commemorates', 1), ('treasuries', 1), ('cumberland', 1), ('glocester', 1), ('collectible', 1), ('coventry', 1), ('municipality', 1), ('tax-paying', 1), ('disgruntled', 1), ('equalization', 1), ('intergovernmental', 1), ('inter-town', 1), ('simplifies', 1), ('expend', 1), ('strengthens', 1), ('conformance', 1), ('ensures', 1), ('montana', 1), ('audits', 1), ('embarked', 1), ('metropolian', 1), ('turnkey', 1), ('brochure', 1), ('541', 1), ('in-state', 1), ('643', 1), ('1184', 1), ('med-chemical', 1), ('kepler', 1), ('143', 1), ('offsetting', 1), ('452', 1), ('603', 1), ('waltham', 1), ('worcester', 1), ('bridgeport', 1), ('waterbury', 1), ('soliciting', 1), ('164', 1), ('239', 1), ('6768', 1), ('1680', 1), ('location-minded', 1), ('industrialists', 1), ('availabilities', 1), ('specifics', 1), ('954', 1), ('cooperates', 1), ('copyrights', 1), ('4427', 1), ('10517', 1), ('follow-ups', 1), ('relocation', 1), ('foundry', 1), ('textron', 1), ('photek', 1), ('cornell-dubilier', 1), ('speidel', 1), ('leesona', 1), ('collyer', 1), ('post-world', 1), ('11900000', 1), ('1418000', 1), ('fifty-two', 1), ('valuations', 1), ('twenty-seven', 1), ('tabulate', 1), ('variance', 1), ('non-professional', 1), ('rateable', 1), ('airpark', 1), ('garaged', 1), ('cancelled', 1), ('non-residents', 1), ('origination', 1), ('domicile', 1), ('revaluation', 1), ('upgrading', 1), ('cost-accounting', 1), ('dispersement', 1), ('7500', 1), ('excels', 1), ('44000', 1), ('reassign', 1), ('cost-billing', 1), ('newly-created', 1), ('organizationally', 1), ('headquarter', 1), ('embraced', 1), ('problematical', 1), ('ineffective', 1), ('privately-owned', 1), ('well-regulated', 1), ('well-administered', 1), ('.09', 1), ('.076', 1), ('non-itemized', 1), ('13200', 1), ('389', 1), ('shoals', 1), ('adorn', 1), ('signally', 1), ('electrification', 1), ('speakership', 1), ('rancorous', 1), ('iron-clad', 1), ('aspire', 1), ('bonham', 1), ('devotedly', 1), ('conciliator', 1), ('succinct', 1), ('unpleasantness', 1), ('fatherly', 1), ('vexed', 1), ('workday', 1), ('refrained', 1), ('stalins', 1), ('tojos', 1), ('mussolinis', 1), ('hitlers', 1), ('kaisers', 1), ('multi-year', 1), ('slow-acting', 1), ('government-to-government', 1), ('deem', 1), ('monolithic', 1), ('anti-american', 1), ('dishonesty', 1), ('unfriendly', 1), ('officialdom', 1), ('longrun', 1), ('balance-of-payments', 1), ('ministries', 1), ('gasset', 1), ('ortega', 1), ('derangement', 1), ('apollonian', 1), ('disoriented', 1), ('ginsberg', 1), ('captures', 1), ('orgasms', 1), ('smalltime', 1), ('mecca', 1), ('spares', 1), ('loveways', 1), ('obsessions', 1), ('all-night', 1), ('self-analysis', 1), ('rhetoric', 1), ('hirelings', 1), ('malevolent', 1), ('persecutory', 1), ('leagued', 1), ('shack-up', 1), ('outcasts', 1), ('derelicts', 1), ('despairing', 1), ('lesbians', 1), ('junkies', 1), ('disordered', 1), ('disaffiliated', 1), ('tijuana', 1), ('reigns', 1), ('craving', 1), ('unbearably', 1), ('stifling', 1), ('disapproves', 1), ('pyschiatrist', 1), ('wedlock', 1), ('monogamous', 1), ('abortions', 1), ('abjectly', 1), ('monogamy', 1), ('dialectical', 1), ('obsesses', 1), ('non-conformists', 1), ('fetish', 1), ('unproductive', 1), ('undisciplined', 1), ('delinquent', 1), ('rootless', 1), ('promptings', 1), ('metaphysics', 1), ('categorical', 1), ('explodes', 1), ('apocalypse', 1), ('predestined', 1), ('nothingness', 1), ('deathward', 1), ('mysticism', 1), ('flirt', 1), ('psychoanalysis', 1), ('beatific', 1), ('glorification', 1), ('dylan', 1), ('grail', 1), ('necking', 1), ('disdain', 1), ('flappers', 1), ('domesticity', 1), ('ungratified', 1), ('sexualized', 1), ('multivalent', 1), ('orgone', 1), ('dionysus', 1), ('yahwe', 1), ('ishtar', 1), ('astarte', 1), ('godhead', 1), ('libido', 1), ('hipster', 1), ('vehemently', 1), ('70524', 1), ('confederations', 1), ('disunion', 1), ('140414', 1), ('commander-in-chief', 1), ('214938', 1), ('grimmer', 1), ('abhorred', 1), ('defence', 1), ('unalienable', 1), ('defiantly', 1), ('coerced', 1), ('drafters', 1), ('hostilities', 1), ('verbatim', 1), ('1781', 1), ('dictionaries', 1), ('alloy', 1), ('emigrating', 1), ('know-nothings', 1), ('1855', 1), ('upholders', 1), ('atlantica', 1), ('bloodiest', 1), ('arbitrate', 1), ('adheres', 1), ('inviolable', 1), ('designating', 1), ('pirouette', 1), ('slaps', 1), ('chanced', 1), ('merce', 1), ('metamorphosis', 1), ('purposive', 1), ('kaleidescope', 1), ('evolve', 1), ('godlike', 1), ('outpouring', 1), ('lyricism', 1), ('front-back', 1), ('midi', 1), ('impelled', 1), ('catapulting', 1), ('merle', 1), ('depiction', 1), ('oracles', 1), ('invert', 1), ('rotations', 1), ('urgencies', 1), ('brushwork', 1), ('incongruous', 1), ('surrealism', 1), ('metre', 1), ('disdains', 1), ('animized', 1), ('accouterments', 1), ('depersonalized', 1), ('finial', 1), ('loosens', 1), ('masks', 1), ('dance-theatre', 1), ('diaphanous', 1), ('summerspace', 1), ('neo-dadaist', 1), ('rauschenberg', 1), ('cyclorama', 1), ('self-sufficiency', 1), ('grapple', 1), ('seep', 1), ('overpowering', 1), ('irrevocably', 1), ('masterfully', 1), ('assailants', 1), ('passos', 1), ('dos', 1), ('dreiser', 1), ('validly', 1), ('make-believe', 1), ('disneyland', 1), ('subhumanity', 1), ('backwoods-and-sand-hill', 1), ('effluvium', 1), ('hogs', 1), ('razorback', 1), ('befuddles', 1), ('bewilders', 1), ('northerner', 1), ('bemoans', 1), ('autopsied', 1), ('minutely', 1), ('miasmal', 1), ('regionalism', 1), ('romanticizing', 1), ('overexploitation', 1), ('prolonging', 1), ('tara', 1), ('rabid', 1), ('keith', 1), ('non-representation', 1), ('glaringly', 1), ('beauchamps', 1), ('faulknerian', 1), ('massuh', 1), ('nufs', 1), ('sho', 1), ('yassuhs', 1), ('mutters', 1), ('woolly-headed', 1), ('socio-political', 1), ('amorphously', 1), ('subservience', 1), ('self-assertion', 1), ('unjust', 1), ('busses', 1), ('astounded', 1), ('unheard-of', 1), ('sit-ins', 1), ('white-dominated', 1), ('contenting', 1), ('testings', 1), ('hypnotically', 1), ('dreaded', 1), ('gothicism', 1), ('reveling', 1), ('capote', 1), ('city-dweller', 1), ('126000', 1), ('localisms', 1), ('buena', 1), ('mcgruder', 1), ('bankhead', 1), ('avalanche', 1), ('half-century', 1), ('47.1', 1), ('wide-sweeping', 1), ('rankest', 1), ('big-daddy', 1), ('white-suited', 1), ('eulogize', 1), ('accolades', 1), ('phantom', 1), ('overexploited', 1), ('juleps', 1), ('cornbread', 1), ('dow-jones', 1), ('georgians', 1), ('erskine', 1), ('perpetuated', 1), ('interposition', 1), ('nullifiers', 1), ('hamilton-oriented', 1), ('atune', 1), ('hamiltonian', 1), ('strenuously', 1), ('rechartering', 1), ('hamiltonians', 1), ('resolves', 1), ('nationalists', 1), ('polarizing', 1), ('fruition', 1), ('displacing', 1), ('super-imposed', 1), ('continentally', 1), ('ex-tory', 1), ('exiled', 1), ('confiscating', 1), ('forgiving', 1), ('legality', 1), ('talleyrand', 1), ('funding', 1), ('multi-million-dollar', 1), ('gridley', 1), ('mentor', 1), ('forty-two', 1), ('actuarial', 1), ('gratify', 1), ('conway', 1), ('castigated', 1), ('piddling', 1), ('dickinson', 1), ('pens', 1), ('vitriol', 1), ('controversialists', 1), ('phrasemaking', 1), ('obstinate', 1), ('rotund', 1), ('power-starved', 1), ('acumen', 1), ('two-term', 1), ('federalist', 1), ('prodigy', 1), ('precocity', 1), ('pre-revolutionary', 1), ('moderating', 1), ('colonists', 1), ('philanthropist', 1), ('printer', 1), ('transplanted', 1), ('documentation', 1), ('consequential', 1), ('indiscreet', 1), ('argonauts', 1), ('surmount', 1), ('forthrightly', 1), ('doubtingly', 1), ('uninterested', 1), ('rundfunk', 1), ('bayerische', 1), ('round-table', 1), ('unfailing', 1), ('etruscan', 1), ('stendhal', 1), ('heine', 1), ('poussin', 1), ('reminisced', 1), ('lorrain', 1), ('hals', 1), ('meinung', 1), ('keine', 1), ('aber', 1), ('amt', 1), ('ein', 1), ('habe', 1), ('ich', 1), ('introduces', 1), ('bernstein', 1), ('dimitri', 1), ('bruno', 1), ('erde', 1), ('das', 1), ('pittsburghers', 1), ('lateiner', 1), ('jacob', 1), ('concertante', 1), ('samba', 1), ('burle', 1), ('curtin', 1), ('carlisle', 1), ('accademia', 1), ('boheme', 1), ('viareggio', 1), ('marmi', 1), ('falstaff', 1), ('founder-conductor', 1), ('hubermann', 1), ('bronislaw', 1), ('feuermann', 1), ('emanuel', 1), ('erdmann', 1), ('vowing', 1), ('morgen', 1), ('auf', 1), ('heute', 1), ('kleiber', 1), ('wozzek', 1), ('berg', 1), ('breve', 1), ('vida', 1), ('falla', 1), ('lescaut', 1), ('manon', 1), ('korngold', 1), ('assented', 1), ('klemperer', 1), ('otto', 1), ('gymnasium', 1), ('escapade', 1), ('etudes', 1), ('czerny', 1), ('five-and-a-half', 1), ('volens', 1), ('nolens', 1), ('piped', 1), ('muzak', 1), ('stop-overs', 1), ('lightens', 1), ('rescinded', 1), ('directorship', 1), ('recurred', 1), ('dutchman', 1), ('jahr', 1), ('sieben', 1), ('sind', 1), ('verstrichen', 1), ('wiederum', 1), ('ist', 1), ('frist', 1), ('arabesque', 1), ('octaves', 1), ('sepulchred', 1), ('interred', 1), ('sweet-tongued', 1), ('iraj', 1), ('teddy', 1), ('fissured', 1), ('riverbanks', 1), ('mullah', 1), ('arak', 1), ('saadi', 1), ('ghazals', 1), ('prosceniums', 1), ('hawkers', 1), ('beggars', 1), ('limousines', 1), ('kajar', 1), ('rheum', 1), ('hacking', 1), ('bakhtiari', 1), ('massing', 1), ('light-flared', 1), ('descend', 1), ('understructure', 1), ('apses', 1), ('capacious', 1), ('frescoed', 1), ('bays', 1), ('spandrels', 1), ('facaded', 1), ('arcaded', 1), ('sun-baked', 1), ('1657', 1), ('pleasance', 1), ('caravans', 1), ('ghazal', 1), ('vintner', 1), ('slick-headed', 1), ('teahouses', 1), ('mustachioed', 1), ('lutihaw', 1), ('dabbling', 1), ('aesthetes', 1), ('daises', 1), ('chalk-white', 1), ('khaneh', 1), ('zur', 1), ('sotun', 1), ('chehel', 1), ('poplar', 1), ('mile-long', 1), ('bagh', 1), ('chahar', 1), ('palaces', 1), ('encroached', 1), ('safavids', 1), ('afghans', 1), ('nisf-i-jahan', 1), ('aromatick', 1), ('promenades', 1), ('terraced', 1), ('canals', 1), ('nightingales', 1), ('metalsmiths', 1), ('calligraphers', 1), ('tabac', 1), ('blindfolded', 1), ('cosmetic', 1), ('darker', 1), ('burnished', 1), ('boomerang', 1), ('spear-throwing', 1), ('woomera', 1), ('rodent', 1), ('woven-root', 1), ('rhythmical', 1), ('repellent', 1), ('eyeball', 1), ('sockets', 1), ('buggers', 1), ('malnourished', 1), ('scabbed', 1), ('sores', 1), ('dingo', 1), ('column-shaped', 1), ('camped', 1), ('speedometer', 1), ('chaps', 1), ('navigate', 1), ('flatland', 1), ('navigating', 1), ('welded', 1), ('gimbaled', 1), ('shunning', 1), ('fugitive', 1), ('seaports', 1), ('weakens', 1), ('misperceives', 1), ('falters', 1), ('unfulfilled', 1), ('twenty-mile', 1), ('mummified', 1), ('well-equipped', 1), ('grazer', 1), ('ten-by-ten-mile', 1), ('paddock', 1), ('malignancy', 1), ('bluebush', 1), ('saltbush', 1), ('moonlike', 1), ('scuttling', 1), ('ravines', 1), ('cruelest', 1), ('puddle', 1), ('discoverer', 1), ('cranelike', 1), ('capering', 1), ('gulley', 1), ('pathos', 1), ('go-to-war', 1), ('six-man', 1), ('cryptographic', 1), ('fail-safe', 1), ('authenticator', 1), ('authentication', 1), ('x-ray-proof', 1), ('klaxon', 1), ('dull-gray', 1), ('ruffles', 1), ('anchors', 1), ('beallsville', 1), ('forty-three', 1), ('floor-to-ceiling', 1), ('mans', 1), ('colonels', 1), ('h-bombs', 1), ('norfolk', 1), ('connects', 1), ('gold-phone', 1), ('ingeniously', 1), ('singlehandedly', 1), ('clobber', 1), ('authentications', 1), ('counterchallenge', 1), ('authenticate', 1), ('senders', 1), ('routings', 1), ('kc-135', 1), ('last-ditch', 1), ('teletypes', 1), ('offutt', 1), ('norad', 1), ('thule', 1), ('accidental-war', 1), ('nonprofit', 1), ('rand', 1), ('sociologist', 1), ('swiss-born', 1), ('meek-mannered', 1), ('ikle', 1), ('unthinkable', 1), ('semicircular', 1), ('arclike', 1), ('darting', 1), ('forefingers', 1), ('inhabit', 1), ('pre-emption', 1), ('hypothesize', 1), ('scenarios', 1), ('unleash', 1), ('unceasing', 1), ('farfetched', 1), ('foxholes', 1), ('compartments', 1), ('cockpits', 1), ('instrument-jammed', 1), ('pistol-packing', 1), ('sidearms', 1), ('launch-control', 1), ('supplanted', 1), ('high-level', 1), ('exemplifies', 1), ('internal-external', 1), ('indivisibility', 1), ('seminal', 1), ('complementing', 1), ('dissipating', 1), ('quirks', 1), ('cornucopia', 1), ('subduing', 1), ('civilizational', 1), ('wreak', 1), ('fervors', 1), ('worldwide', 1), ('febrile', 1), ('socal', 1), ('glorifies', 1), ('epitomizes', 1), ('time-span', 1), ('feudalism', 1), ('supranationalism', 1), ('validating', 1), ('accumulating', 1), ('non-soviet', 1), ('substantively', 1), ('redefined', 1), ('hands-off', 1), ('wallowing', 1), ('truism', 1), ('immersion', 1), ('watersheds', 1), ('court-packing', 1), ('victorious', 1), ('night-watchman', 1), ('implanted', 1), ('articulation', 1), ('unannounced', 1), ('darwinism', 1), ('britannica', 1), ('pax', 1), ('avaricious', 1), ('reexamination', 1), ('bentham', 1), ('non-western', 1), ('shietz', 1), ('clairaudiently', 1), ('clairvoyant', 1), ('eidetic', 1), ('aches', 1), ('chalked', 1), ('significants', 1), ('totted', 1), ('sitters', 1), ('z', 1), ('objectiveness', 1), ('afield', 1), ('typescript', 1), ('paranormal', 1), ('clarifying', 1), ('telepathically', 1), ('osis', 1), ('karlis', 1), ('pre-conscious', 1), ('beyond-normal', 1), ('semi-conscious', 1), ('entranced', 1), ('dissociated', 1), ('mediumship', 1), ('preferring', 1), ('prognoses', 1), ('nicknames', 1), ('prematurely', 1), ('advises', 1), ('gelatin-like', 1), ('alginates', 1), ('vulcanized', 1), ('650', 1), ('full-banded', 1), ('aligning', 1), ('healthier', 1), ('molars', 1), ('well-cemented', 1), ('soreness', 1), ('custom-make', 1), ('peridontal', 1), ('lisping', 1), ('interferes', 1), ('prolong', 1), ('jammed-together', 1), ('pyorrhea', 1), ('bad-fitting', 1), ('molar', 1), ('thumb-sucking', 1), ('thumbs', 1), ('lip-sucking', 1), ('tongue-thrusting', 1), ('finger-sucking', 1), ('predisposition', 1), ('protrude', 1), ('eyeteeth', 1), ('lowers', 1), ('protrusion', 1), ('malformations', 1), ('jawbone', 1), ('tooth-straightening', 1), ('whole-heartedly', 1), ('co-operated', 1), ('realigning', 1), ('specializes', 1), ('bunny', 1), ('nicknamed', 1), ('ten-year-old', 1), ('chromium-plated', 1), ('snazzy', 1), ('bracket', 1), ('morphine', 1), ('bolivia', 1), ('co-operating', 1), ('vesuvio', 1), ('courtesan', 1), ('comely', 1), ('unromantic', 1), ('overthrown', 1), ('gaafer', 1), ('mohammed', 1), ('badrawi', 1), ('tewfik', 1), ('egyptians', 1), ('middle-eastern', 1), ('semiramis', 1), ('servitors', 1), ('auditioning', 1), ('discreet', 1), ('swanky', 1), ('revels', 1), ('envious', 1), ('fiddling', 1), ('high-tailed', 1), ('beautifully-built', 1), ('croupier', 1), ('warfield', 1), ('ex-fighter', 1), ('wide-eyed', 1), ('brew', 1), ('chaperone', 1), ('underestimated', 1), ('sobbingly', 1), ('tycoon', 1), ('arraigning', 1), ('liebler', 1), ('swank', 1), ('masterminding', 1), ('play-girl', 1), ('minot', 1), ('oleomargarine', 1), ('ash-blonde', 1), ('trollop', 1), ('another-the', 1), ('nudism', 1), ('pornographic', 1), ('semi-nude', 1), ('crusader', 1), ('nudist', 1), ('kinsey', 1), ('arouses', 1), ('kenneth', 1), ('self-centered', 1), ('wisest', 1), ('premature', 1), ('facilitate', 1), ('inflame', 1), ('decisiveness', 1), ('virility', 1), ('prolongs', 1), ('urethra', 1), ('lubricant', 1), ('dilates', 1), ('fore-play', 1), ('prolongation', 1), ('gynecological', 1), ('involuntarily', 1), ('dilation', 1), ('dilating', 1), ('outgrowth', 1), ('incise', 1), ('foresaw', 1), ('newly-weds', 1), ('hymens', 1), ('exaggerations', 1), ('profuse', 1), ('stateroom', 1), ('newly-married', 1), ('sex-manuals', 1), ('honeymooners', 1), ('procreativity', 1), ('over-occupied', 1), ('acrobats', 1), ('blitzes', 1), ('tennyson', 1), ('verne', 1), ('jules', 1), ('specie', 1), ('non-instinctive', 1), ('noah', 1), ('dolls', 1), ('timetables', 1), ('plugging', 1), ('dejection', 1), ('carve', 1), ('hands-off-all-sweets', 1), ('cakes', 1), ('yearn', 1), ('ceramics', 1), ('braiding', 1), ('hooking', 1), ('tat', 1), ('crochet', 1), ('buttonholes', 1), ('unabridged', 1), ('bewail', 1), ('moan', 1), ('invalids', 1), ('out-moded', 1), ('fogy', 1), ('stickler', 1), ('penman', 1), ('looms', 1), ('old-timers', 1), ('slipstream', 1), ('revved', 1), ('miscalculated', 1), ('near-misses', 1), ('barnyards', 1), ('shuttled', 1), ('danville', 1), ('ottauquechee', 1), ('chandelle', 1), ('socked', 1), ('reckoning', 1), ('sleet', 1), ('hangar', 1), ('marston', 1), ('caleb', 1), ('hartwell', 1), ('ceilings', 1), ('wind-velocity', 1), ('frosty', 1), ('airman', 1), ('goggles', 1), ('helmet', 1), ('sheep-lined', 1), ('togs', 1), ('vagaries', 1), ('sub-freezing', 1), ('one-plane', 1), ('telegram', 1), ('barre-montpelier', 1), ('passable', 1), ('scouted', 1), ('mckenna', 1), ('sleight', 1), ('snow-covered', 1), ('uphill', 1), ('flat-topped', 1), ('roundabout', 1), ('unsafe', 1), ('wry-faced', 1), ('on-to-spokane', 1), ('silver-painted', 1), ('225', 1), ('aviators', 1), ('lindbergh', 1), ('winnipesaukee', 1), ('mf', 1), ('racked', 1), ('barnstormer', 1), ('empowering', 1), ('recently-passed', 1), ('hob', 1), ('hops', 1), ('millstone', 1), ('172', 1), ('quarrymen', 1), ('granite', 1), ('flood-ravaged', 1), ('two-seaters', 1), ('dehaviland', 1), ('wide-winged', 1), ('hastily-summoned', 1), ('undisrupted', 1), ('ferried', 1), ('rights-of-way', 1), ('postmasters', 1), ('girders', 1), ('roadbed', 1), ('labored', 1), ('idled', 1), ('plume', 1), ('whined', 1), ('sheen', 1), ('shampoo', 1), ('packages', 1), ('munch', 1), ('hikes', 1), ('conserves', 1), ('residues', 1), ('insecticide', 1), ('spaghetti', 1), ('brewer', 1), ('unsprayed', 1), ('sulphured', 1), ('puddings', 1), ('roosters', 1), ('suey', 1), ('home-made', 1), ('freezer', 1), ('voraciously', 1), ('buckshot', 1), ('fresh-ground', 1), ('cereals', 1), ('listens', 1), ('soy', 1), ('deteriorate', 1), ('wholewheat', 1), ('bio-dynamic', 1), ('rotenone', 1), ('beets', 1), ('rutabagas', 1), ('turnips', 1), ('fungicides', 1), ('long-keeping', 1), ('crumbly', 1), ('stooped', 1), ('irrigate', 1), ('water-holding', 1), ('mulching', 1), ('spreader', 1), ('shredder', 1), ('plowman', 1), ('conservationist', 1), ('bromfield', 1), ('reminiscing', 1), ('contouring', 1), ('ghostly', 1), ('quick-drying', 1), ('lends', 1), ('handicaps', 1), ('assimilate', 1), ('mortally', 1), ('valiantly', 1), ('gunners', 1), ('casks', 1), ('mp', 1), ('homing', 1), ('hundred-odd', 1), ('balkans', 1), ('eerily', 1), ('crewmen', 1), ('fermate', 1), ('blips', 1), ('badly-needed', 1), ('renovated', 1), ('boggled', 1), ('noncommittal', 1), ('grins', 1), ('cahill', 1), ('gangplank', 1), ('tarry', 1), ('supposing', 1), ('flammable', 1), ('foggia', 1), ('grimness', 1), ('britisher', 1), ('tracers', 1), ('co-ordinate', 1), ('handmaiden', 1), ('blitz', 1), ('peltz', 1), ('luftwaffe', 1), ('alarmist', 1), ('troopship', 1), ('bougie', 1), ('maddalena', 1), ('immemorial', 1), ('nitrogen-mustard', 1), ('incendiaries', 1), ('smokescreen', 1), ('stockpiling', 1), ('consenting', 1), ('categorically', 1), ('noxious', 1), ('warfront', 1), ('delano', 1), ('stern-to', 1), ('nuovo', 1), ('sea-horses', 1), ('durrell', 1), ('pursewarden', 1), ('soma', 1), ('neurasthenic', 1), ('stammering', 1), ('danehy', 1), ('hockett', 1), ('pittenger', 1), ('sibling', 1), ('intuitively', 1), ('psychotherapists', 1), ('unmeshed', 1), ('monumentally', 1), ('blunted', 1), ('non-scientific', 1), ('paralinguistic', 1), ('sloppily', 1), ('breathy', 1), ('congruent', 1), ('catapults', 1), ('itemization', 1), ('triad', 1), ('now-historic', 1), ('chartings', 1), ('beefed', 1), ('non-verbal', 1), ('fade-in', 1), ('disinclination', 1), ('departs', 1), ('acoustic', 1), ('redstone', 1), ('playbacks', 1), ('seven-word', 1), ('throaty', 1), ('downtalking', 1), ('well-adjusted', 1), ('kinesics', 1), ('three-part', 1), ('birdwhistell', 1), ('austerely', 1), ('talker', 1), ('attuned', 1), ('spring-joints', 1), ('blubber', 1), ('undaunted', 1), ('tandem', 1), ('gambit', 1), ('flirtation', 1), ('drawling', 1), ('oversoftness', 1), ('linguist-anthropologist', 1), ('comico-romantico', 1), ('macarthur-helen', 1), ('boy-meets-girl', 1), ('ventilator', 1), ('droves', 1), ('light-colored', 1), ('extra-thick', 1), ('double-glaze', 1), ('weatherstrip', 1), ('heat-absorbing', 1), ('obliquely', 1), ('trellises', 1), ('undersized', 1), ('thrower', 1), ('makeup', 1), ('quits', 1), ('winters', 1), ('rambling', 1), ('dehumidified', 1), ('prefab', 1), ('cooling-heating', 1), ('radiators', 1), ('diffusers', 1), ('perimeter', 1), ('mild-winter', 1), ('inaccessible', 1), ('crawlspace', 1), ('counterflow', 1), ('ductwork', 1), ('whole-house', 1), ('shade-darkened', 1), ('naps', 1), ('mildew', 1), ('repainting', 1), ('reupholstering', 1), ('godsend', 1), ('sinus', 1), ('asthma', 1), ('allergies', 1), ('overcooled', 1), ('concurs', 1), ('add-on', 1), ('prefabricated', 1), ('pool-care', 1), ('floodlight', 1), ('scooping', 1), ('furbishing', 1), ('dirt-catcher', 1), ('algaecide', 1), ('hydraulics', 1), ('bi-monthly', 1), ('pristine', 1), ('soignee', 1), ('lawsuits', 1), ('littlest', 1), ('divers', 1), ('grit-impregnated', 1), ('coco', 1), ('non-skid', 1), ('inexpert', 1), ('kapok-filled', 1), ('buckle-on', 1), ('life-preservers', 1), ('conveniences', 1), ('usher', 1), ('famille', 1), ('free-drink', 1), ('solvency', 1), ('dunk', 1), ('gabbling', 1), ('gaggle', 1), ('chaperoned', 1), ('potlatches', 1), ('invitees', 1), ('ringers', 1), ('beforehand', 1), ('telephoning', 1), ('subnormal', 1), ('unsettling', 1), ('impulsive', 1), ('handymen', 1), ('pool-owners', 1), ('lien', 1), ('quadrupled', 1), ('delectation', 1), ('home-comings', 1), ('dips', 1), ('solaced', 1), ('mud-sweat-and-tears', 1), ('transoceanic', 1), ('greensward', 1), ('wintering', 1), ('fauna', 1), ('flora', 1), ('plastic-covered', 1), ('floe', 1), ('unglamorous', 1), ('climes', 1), ('mowed', 1), ('sylvan', 1), ('out-of-mind', 1), ('out-of-sight', 1), ('make-your-house-our-club', 1), ('semi-inflated', 1), ('suntan', 1), ('fine-feathered', 1), ('mailed-fist-in-velvet-glove', 1), ('pump-priming', 1), ('hydrochemistry', 1), ('unrewarding', 1), ('barbour', 1), ('imboden', 1), ('buckhannon', 1), ('torch', 1), ('joshual', 1), ('combustibles', 1), ('burnings', 1), ('jones-imboden', 1), ('momentoes', 1), ('walk-way', 1), ('staunton', 1), ('lemuel', 1), ('1852', 1), ('vies', 1), ('parcel', 1), ('kelley', 1), ('talbott', 1), ('break-neck', 1), ('impersonated', 1), ('lander', 1), ('tygartis', 1), ('1868', 1), ('thirty-foot', 1), ('570', 1), ('superintend', 1), ('patentees', 1), ('underbracing', 1), ('1882', 1), ('ciceronian', 1), ('share-holders', 1), ('abutments', 1), ('roofed', 1), ('haverhill', 1), ('portsmouth', 1), ('spofford', 1), ('apprenticed', 1), ('boxford', 1), ('1751', 1), ('house-building', 1), ('pascataqua', 1), ('high-water', 1), ('vortex', 1), ('new-york', 1), ('new-england', 1), ('two-part', 1), ('recompense', 1), ('severally', 1), ('malden', 1), ('incorporating', 1), ('conveyance', 1), ('newbery', 1), ('petitioned', 1), ('merrimac', 1), ('hardness', 1), ('workpiece', 1), ('nicked', 1), ('sided', 1), ('exact-size', 1), ('overheating', 1), ('booklet', 1), ('step-cone', 1), ('counter-clockwise', 1), ('loosening', 1), ('unwinding', 1), ('pliers', 1), ('bolts', 1), ('dusting', 1), ('lubrication', 1), ('rusting', 1), ('rubdown', 1), ('swivels', 1), ('tilting', 1), ('shank', 1), ('multitude', 1), ('woodworking', 1), ('rabbeting', 1), ('ripping', 1), ('thicknesses', 1), ('rustproof', 1), ('wastage', 1), ('filler', 1), ('mastic', 1), ('double-strength', 1), ('asbestos-cement', 1), ('wiring', 1), ('partitions', 1), ('expandable', 1), ('informative', 1), ('swampy', 1), ('wash-outs', 1), ('l-p', 1), ('precut', 1), ('trucked', 1), ('panelization', 1), ('modular', 1), ('panelized', 1), ('hermanovski', 1), ('egils', 1), ('dimensionally', 1), ('non-absorbent', 1), ('ensolite', 1), ('padding', 1), ('bulkhead', 1), ('five-gallon', 1), ('drains', 1), ('hinged', 1), ('removable', 1), ('plexiglas', 1), ('shatterproof', 1), ('bulkheads', 1), ('firzite', 1), ('quarter-inch', 1), ('planed', 1), ('well-braced', 1), ('1605', 1), ('beaching', 1), ('centerline', 1), ('sander', 1), ('harden', 1), ('hardener', 1), ('fastenings', 1), ('saber', 1), ('bit-like', 1), ('routo-jig', 1), ('homemaster', 1), ('fastening', 1), ('inch-thick', 1), ('five-ply', 1), ('bevels', 1), ('two-inch', 1), ('beveling', 1), ('clamps', 1), ('three-inch', 1), ('spliced', 1), ('gussets', 1), ('notching', 1), ('lapped', 1), ('different-color', 1), ('resorcinal', 1), ('bridgewater', 1), ('silicon', 1), ('flathead', 1), ('mooring', 1), ('long-cruise', 1), ('six-gallon', 1), ('bumpers', 1), ('five-foot', 1), ('runabout', 1), ('three-foot', 1), ('roomy', 1), ('galley', 1), ('headroom', 1), ('helmsman', 1), ('menfolk', 1), ('underarm', 1), ('sewn', 1), ('sl', 1), ('armhole', 1), ('greenware', 1), ('breakage', 1), ('leather-hard', 1), ('spout', 1), ('splice', 1), ('design-side', 1), ('miter', 1), ('ware', 1), ('reinforcing', 1), ('unglazed', 1), ('paperweight', 1), ('undercut', 1), ('cantaloupe', 1), ('jacquelyn', 1), ('roughened', 1), ('pinholes', 1), ('paintbrush', 1), ('wood-grained', 1), ('dampness', 1), ('moistening', 1), ('pliable', 1), ('well-wedged', 1), ('modeling', 1), ('cookie', 1), ('patties', 1), ('grated', 1), ('f-inch', 1), ('floured', 1), ('knead', 1), ('drained', 1), ('criss-cross', 1), ('servings', 1), ('ketchup', 1), ('caraway', 1), ('moisten', 1), ('kraut', 1), ('toppings', 1), ('back-yard', 1), ('dipping', 1), ('toasting', 1), ('sayonara', 1), ('broil', 1), ('marinating', 1), ('chive', 1), ('tangy', 1), ('extras', 1), ('pickle', 1), ('permeate', 1), ('juices', 1), ('broiled', 1), ('toasted', 1), ('franks-in-buns', 1), ('sausage-meat', 1), ('skewer', 1), ('blutwurst', 1), ('pepperoni', 1), ('knackwurst', 1), ('bockwurst', 1), ('bratwurst', 1), ('mettwurst', 1), ('cervelat', 1), ('basics', 1), ('home-for-the-night', 1), ('earthenware', 1), ('all-purpose', 1), ('bernz-o-matic', 1), ('lobster', 1), ('kebob', 1), ('shish', 1), ('a-1', 1), ('chowders', 1), ('stews', 1), ('beer-cooling', 1), ('wall-tex', 1), ('tablecloths', 1), ('dinnerware', 1), ('platters', 1), ('saucers', 1), ('drips', 1), ('tongs', 1), ('marinade', 1), ('non-freezing', 1), ('test-run', 1), ('roasts', 1), ('allot', 1), ('halves', 1), ('puncturing', 1), ('juiciest', 1), ('barbecued', 1), ('rinse', 1), ('divans', 1), ('thrones', 1), ('divan-like', 1), ('jewelled', 1), ('portico', 1), ('floor-length', 1), ('porcelain', 1), ('arrowed', 1), ('beheading', 1), ('topkapi', 1), ('pagoda', 1), ('cistern', 1), ('red-tile', 1), ('baklava', 1), ('gazinosu', 1), ('chant', 1), ('muezzin', 1), ('cascade', 1), ('retracing', 1), ('rivalled', 1), ('delphi', 1), ('entwined', 1), ('serpentine', 1), ('lateran', 1), ('thutmose', 1), ('theodosius', 1), ('crusaders', 1), ('196', 1), ('minber', 1), ('ephesus', 1), ('artemis', 1), ('moslems', 1), ('mosaics', 1), ('buttresses', 1), ('sinan', 1), ('grander', 1), ('532', 1), ('sophias', 1), ('pandelli', 1), ('cami', 1), ('yeni', 1), ('eminonu', 1), ('slenderer', 1), ('galata', 1), ('liners', 1), ('dolmabahce', 1), ('taksim', 1), ('cadesi', 1), ('cumhuriyet', 1), ('constantinople', 1), ('megarians', 1), ('byzas', 1), ('byzantium', 1), ('highpoint', 1), ('semiarid', 1), ('bryce', 1), ('2425', 1), ('two-week', 1), ('fun-filled', 1), ('vacationers', 1), ('usga', 1), ('elgin', 1), ('exposures', 1), ('sometimes-necessary', 1), ('dioramas', 1), ('sightseers', 1), ('memo', 1), ('fill-in', 1), ('travelogue', 1), ('forts', 1), ('relives', 1), ('mackinack', 1), ('boomtown', 1), ('ex-president', 1), ('earp', 1), ('mementoes', 1), ('itasca', 1), ('vacationland', 1), ('hatched', 1), ('finn', 1), ('huck', 1), ('hannibal', 1), ('twain', 1), ('rushmore', 1), ('deadwood', 1), ('image-provoking', 1), ('badlands', 1), ('farmlands', 1), ('stopover', 1), ('fern', 1), ('dells', 1), ('waterskiing', 1), ('linville', 1), ('scenics', 1), ('long-view', 1), ('shafts', 1), ('flourishing', 1), ('natchez', 1), ('trademarks', 1), ('chattanooga', 1), ('gorges', 1), ('alamo', 1), ('photofloodlights', 1), ('caverns', 1), ('luray', 1), ('yorktown', 1), ('jamestown', 1), ('williamsburg', 1), ('wrought', 1), ('parrot', 1), ('palm-studded', 1), ('everglades', 1), ('glass-bottom', 1), ('water-ski', 1), ('unequalled', 1), ('fredericksburg', 1), ('re-enactments', 1), ('encompasses', 1), ('light-reflecting', 1), ('overexpose', 1), ('lighthouses', 1), ('tripods', 1), ('modernistic', 1), ('northeastern', 1), ('sightseeing', 1), ('mts.', 1), ('rockbound', 1), ('acadia', 1), ('completely-restored', 1), ('sturbridge', 1), ('whaling', 1), ('townships', 1), ('forge', 1), ('eye-filling', 1), ('wednesdays', 1), ('two-day', 1), ('verdant', 1), ('drama-filled', 1), ('art-filled', 1), ('smoke-filled', 1), ('sky-reaching', 1), ('yolk', 1), ('gild', 1), ('tablespoonfuls', 1), ('pastry-lined', 1), ('poach', 1), ('clove', 1), ('apricot', 1), ('peel', 1), ('billets', 1), ('thereabouts', 1), ('brimful', 1), ('creeks', 1), ('almaden', 1), ('gunflint', 1), ('venison', 1), ('panthers', 1), ('six-foot', 1), ('kegs', 1), ('kegful', 1), ('chutney', 1), ('simmered', 1), ('gherkins', 1), ('teaspoonfuls', 1), ('esteemed', 1), ('oak-log', 1), ('sweepstakes', 1), ('oaks', 1), ('acorns', 1), ('bierce', 1), ('ambrose', 1), ('sojourners', 1), ('rockers', 1), ('verandas', 1), ('copious', 1), ('disfavor', 1), ('mackintosh', 1), ('half-witted', 1), ('seersucker', 1), ('fernery', 1), ('shoulder-high', 1), ('splashes', 1), ('bakes', 1), ('sky-tapping', 1), ('indulging', 1), ('dashboard', 1), ('inns', 1), ('cantered', 1), ('surtout', 1), ('epsom', 1), ('clatter', 1), ('currant', 1), ('wellington', 1), ('gardenia', 1), ('winfield', 1), ('slash-mouthed', 1), ('rubicund', 1), ('maelstrom', 1), ('galleries', 1), ('magnate', 1), ('nob', 1), ('restaurateur', 1), ('pierpont', 1), ('fortnight', 1), ('jigger', 1), ('chives', 1), ('fry', 1), ('delawares', 1), ('coppery', 1), ('piquant', 1), ('anchovy', 1), ('buttery', 1), ('hard-boiled', 1), ('haddock', 1), ('flake', 1), ('funerals', 1), ('gloss', 1), ('greased', 1), ('axles', 1), ('french-polished', 1), ('whips', 1), ('matchless', 1), ('replica', 1), ('unadorned', 1), ('liqueur', 1), ('underbedding', 1), ('parsley', 1), ('pernod', 1), ('absinthe', 1), ('gastronomes', 1), ('consummately', 1), ('fritters', 1), ('blacking', 1), ('sarsaparilla', 1), ('liniments', 1), ('lithographs', 1), ('adorned', 1), ('adjoined', 1), ('breakfasted', 1), ('botanical', 1), ('malabar', 1), ('pastilles', 1), ('orphic', 1), ('roamed', 1), ('franciscan', 1), ('ferns', 1), ('sangaree', 1), ('sturgeon', 1), ('filets', 1), ('halts', 1), ('trenchermen', 1), ('hell-for-leather', 1), ('horsedom', 1), ('prospered', 1), ('handguns', 1), ('73.50', 1), ('flite-king', 1), ('supermatic', 1), ('valmet', 1), ('finland', 1), ('sighting', 1), ('ventilated', 1), ('barrel-wide', 1), ('beavertail', 1), ('superposed', 1), ('940', 1), ('single-barrel', 1), ('514', 1), ('full-sized', 1), ('drop-block', 1), ('ithaca', 1), ('beginners', 1), ('slide-lock', 1), ('featherweight', 1), ('short-barrel', 1), ('760', 1), ('310', 1), ('725', 1), ('pellets', 1), ('wing-shooting', 1), ('repeater', 1), ('seven-shot', 1), ('fastens', 1), ('clays', 1), ('shotshells', 1), ('smoothbore', 1), ('unscrew', 1), ('rifled', 1), ('unrifled', 1), ('rifle-shotgun', 1), ('989', 1), ('hammerless', 1), ('sport-king', 1), ('coltsman', 1), ('.270', 1), ('.308', 1), ('.243', 1), ('.222', 1), ('sako', 1), ('center-fire', 1), ('scopes', 1), ('shotgun-type', 1), ('.338', 1), ('better-than-average', 1), ('high-power', 1), ('scoped', 1), ('plinking', 1), ('small-game', 1), ('adapter', 1), ('intriguing', 1), ('crow', 1), ('squirrel', 1), ('edible', 1), ('mid-range', 1), ('flattest', 1), ('2460', 1), ('wesson', 1), ('standard-weight', 1), ('foreleg', 1), ('thicket', 1), ('rhododendron', 1), ('hop-skipped', 1), ('opening-day', 1), ('unjacketed', 1), ('upsetting', 1), ('six-inch', 1), ('inch-barrel', 1), ('wart', 1), ('kob', 1), ('reedbuck', 1), ('bagged', 1), ('grassed', 1), ('fast-firing', 1), ('quick-handling', 1), ('high-velocity', 1), ('arms-making', 1), ('strictest', 1), ('christmas-season', 1), ('05.2', 1), ('06.1', 1), ('04', 1), ('orin', 1), ('trotter', 1), ('02.2', 1), ('06.3', 1), ('claudia', 1), ('dundeen', 1), ('02', 1), ('01.3', 1), ('05.3', 1), ('tanker', 1), ('05.1', 1), ('00.3', 1), ('59.3', 1), ('braden', 1), ('03', 1), ('lottie', 1), ('00.2', 1), ('budlong', 1), ('greentree', 1), ('dauntless', 1), ('chalidale', 1), ('marilyn', 1), ('blackstone', 1), ('work-outs', 1), ('rainless', 1), ('galophone-prissy', 1), ('engle', 1), ('nipe', 1), ('hanover-mauri', 1), ('nibble', 1), ('armbro', 1), ('karet', 1), ('heel-kaola', 1), ('cathy', 1), ('hanover-bertie', 1), ('adios-rena', 1), ('jordon', 1), ('hanover-lucy', 1), ('layton', 1), ('dalzell-cousin', 1), ('riverboat', 1), ('wyn', 1), ('victor-butler', 1), ('butterwyn', 1), ('caton', 1), ('31.3', 1), ('dream-lusty', 1), ('heel-lotus', 1), ('hanover-pebble', 1), ('hanover-precious', 1), ('prudent', 1), ('gallon-loren', 1), ('lorena', 1), ('classiest', 1), ('baffled', 1), ('delvin', 1), ('bare-footed', 1), ('three-quarters', 1), ('stalling', 1), ('equines', 1), ('kid-isoletta', 1), ('iosola', 1), ('time-mynah', 1), ('boy-marquita', 1), ('florican-my', 1), ('dream-next', 1), ('knightfall', 1), ('boy-lady', 1), ('mite', 1), ('florican-inverness', 1), ('invercalt', 1), ('whippet', 1), ('hanover-sally', 1), ('mahone', 1), ('heel-betty', 1), ('bordner', 1), ('time-olivette', 1), ('lorraine', 1), ('jacky', 1), ('34.2', 1), ('dream-way', 1), ('farvel-topsy', 1), ('charmer', 1), ('rodney-the', 1), ('hanover-supermarket', 1), ('checkit', 1), ('rodney-miss', 1), ('hanover-chalidale', 1), ('harlan-marcia', 1), ('rodney-honor', 1), ('hanover-ceyway', 1), ('heel-beryl', 1), ('buxton', 1), ('harlan-hickory', 1), ('pride-venus', 1), ('hanover-misty', 1), ('abbe-scotch', 1), ('bonnie', 1), ('haughton', 1), ('rhythm-wily', 1), ('dream-sweetmite', 1), ('staley', 1), ('equine', 1), ('abbe-direct', 1), ('dailey', 1), ('grand-looking', 1), ('taraday', 1), ('underpinning', 1), ('cerise', 1), ('full-sisters', 1), ('37.3', 1), ('43.1', 1), ('hoppled', 1), ('heel-holiday', 1), ('hoopla', 1), ('32.4', 1), ('hanover-justitia', 1), ('justine', 1), ('fillies', 1), ('flyer-castle', 1), ('frisco', 1), ('pacer', 1), ('best-gaited', 1), ('torrid-adios', 1), ('fair-looking', 1), ('adios-direct', 1), ('strongheart', 1), ('strong-made', 1), ('torrid-breeze', 1), ('gaited', 1), ('rascal', 1), ('dream-torkin', 1), ('hustler', 1), ('best-tempered', 1), ('heel-terka', 1), ('gamecock', 1), ('twice-around', 1), ('line-driven', 1), ('adios-trustful', 1), ('emasculation', 1), ('33.3', 1), ('torrid-mighty', 1), ('trackdown', 1), ('upstanding', 1), ('equalled', 1), ('smoothest', 1), ('girth', 1), ('26.2', 1), ('galophone-kimberly', 1), ('adios-on', 1), ('frost-debby', 1), ('railbirds', 1), ('wis.', 1), ('kroening', 1), ('clocked', 1), ('mainliner-highland', 1), ('4.00', 1), ('168', 1), ('crankshaft', 1), ('displaced', 1), ('micrometer', 1), ('thousandths', 1), ('beakers', 1), ('overfill', 1), ('decimals', 1), ('v8', 1), ('chevy', 1), ('283', 1), ('16.38', 1), ('2.54', 1), ('3.1416', 1), ('one-quarter', 1), ('.7854', 1), ('stroking', 1), ('pave', 1), ('handbooks', 1), ('mathematician', 1), ('rotate', 1), ('standardizing', 1), ('lathe', 1), ('scribing', 1), ('marring', 1), ('barrette', 1), ('mandrel', 1), ('.020', 1), ('carborundum', 1), ('v-shaped', 1), ('.31', 1), ('dog-pin', 1), ('snug-fitting', 1), ('.6', 1), ('crosswise', 1), ('undersize', 1), ('.19', 1), ('align', 1), ('burrs', 1), ('soldered', 1), ('disassemble', 1), ('unsolder', 1), ('counter-drill', 1), ('horizontally', 1), ('soldering', 1), ('sanding', 1), ('railroader', 1), ('low-speed', 1), ('blacked-in', 1), ('derails', 1), ('track-signal', 1), ('wedge-shaped', 1), ('flange', 1), ('insures', 1), ('unlocking', 1), ('cams', 1), ('municipally', 1), ('boatels', 1), ('yachtels', 1), ('nomenclature', 1), ('pertain', 1), ('boatel', 1), ('yachtsman', 1), ('ever-increasing', 1), ('dine', 1), ('governmentally', 1), ('seamanship', 1), ('ungoverned', 1), ('aloft', 1), ('purchaser', 1), ('non-dealer', 1), ('tiller', 1), ('sizeable', 1), ('excel', 1), ('sportiest', 1), ('once-a-month', 1), ('purchasers', 1), ('galleys', 1), ('toilets', 1), ('dinghy', 1), ('laze', 1), ('accommodating', 1), ('houseboats', 1), ('canoes', 1), ('pram', 1), ('eight-foot', 1), ('waterside', 1), ('anchorage', 1), ('boatmen', 1), ('smartly', 1), ('inboards', 1), ('easy-to-operate', 1), ('1800000', 1), ('dammed', 1), ('corp', 1), ('square-mile', 1), ('havens', 1), ('multi-purpose', 1), ('troughs', 1), ('coastline', 1), ('expectedly', 1), ('heaviest', 1), ('8000000', 1), ('awash', 1), ('navigable', 1), ('germs', 1), ('canine', 1), ('veterinarians', 1), ('obedience-trained', 1), ('housebroken', 1), ('puppies', 1), ('pointers', 1), ('grande', 1), ('kcs', 1), ('topeka', 1), ('breeds', 1), ('donating', 1), ('kerry', 1), ('airedale', 1), ('overage', 1), ('7287', 1), ('keeshond', 1), ('penna.', 1), ('trapp', 1), ('marcmann', 1), ('dachshund', 1), ('hackmann', 1), ('pinscher', 1), ('doberman', 1), ('blanc', 1), ('founder-originator', 1), ('holyoke', 1), ('public-address', 1), ('announcer', 1), ('hone', 1), ('steward', 1), ('thoroughbred', 1), ('livid', 1), ('flash-bulbs', 1), ('home-bred', 1), ('noranda', 1), ('ch.', 1), ('qualifying', 1), ('chmn.', 1), ('taxi-ways', 1), ('side-looking', 1), ('one-kiloton', 1), ('overpressure', 1), ('kiloton', 1), ('pre-attack', 1), ('semiautomatic', 1), ('vertically', 1), ('takeoff', 1), ('powerplants', 1), ('vertical-takeoff-and-landing', 1), ('propulsions', 1), ('hangars', 1), ('bomb-proof', 1), ('skybolt', 1), ('survivability', 1), ('degrade', 1), ('multimegaton', 1), ('railway-based', 1), ('rail-mobile', 1), ('long-endurance', 1), ('cinders', 1), ('cataclysmic', 1), ('self-protection', 1), ('instantaneously', 1), ('ballistics', 1), ('city-trading', 1), ('appallingly', 1), ('swiftness', 1), ('fearsome', 1), ('thump', 1), ('rotogravures', 1), ('speculator', 1), ('throes', 1), ('topple', 1), ('rejoiced', 1), ('machado', 1), ('exiles', 1), ('stoned', 1), ('prado', 1), ('revolutionaries', 1), ('war-dirty', 1), ('barbudos', 1), ('hovers', 1), ('brain-wracking', 1), ('sanctimonious', 1), ('deadliest', 1), ('selflessness', 1), ('prayer-requests', 1), ('weiss', 1), ('starr', 1), ('mullendore', 1), ('idea-exchange', 1), ('varner', 1), ('kittler', 1), ('organizes', 1), ('boal', 1), ('inducements', 1), ('braille', 1), ('chaplains', 1), ('durlach', 1), ('teresa', 1), ('overwhelm', 1), ('derelict', 1), ('down-and-outers', 1), ('unstapled', 1), ('newsstand', 1), ('circulate', 1), ('brightens', 1), ('lusts', 1), ('banquetings', 1), ('revellings', 1), ('sup', 1), ('forsake', 1), ('implore', 1), ('blood-bought', 1), ('flogged', 1), ('unction', 1), ('sacraments', 1), ('zealously', 1), ('worshipful', 1), ('dost', 1), ('hearest', 1), ('colossians', 1), ('partaker', 1), ('uncircumcision', 1), ('circumcision', 1), ('gladness', 1), ('philippians', 1), ('abides', 1), ('regeneration', 1), ('incorruptible', 1), ('unbelieving', 1), ('perishing', 1), ('hebrews', 1), ('1778', 1), ('indulgences', 1), ('individuation', 1), ('anti-authoritarian', 1), ('mealtime', 1), ('carryovers', 1), ('shakya', 1), ('manjucri', 1), ('mayst', 1), ('sceneries', 1), ('salutation', 1), ('kyo-zan', 1), ('mahayanist', 1), ('arhat', 1), ('arhats', 1), ('tai', 1), ('baku', 1), ('credulous', 1), ('self-seeking', 1), ('pantheist', 1), ('anchoritism', 1), ('gobbles', 1), ('kingdom-wide', 1), ('preoccupations', 1), ('koan', 1), ('transmittable', 1), ('mysticisms', 1), ('outhouse', 1), ('cognitive', 1), ('ratiocinating', 1), ('indwelling', 1), ('zennist', 1), ('perturbations', 1), ('enjoinder', 1), ('indisputably', 1), ('dignify', 1), ('disproportionately', 1), ('nonmagical', 1), ('catered', 1), ('magic-practicing', 1), ('idolatry', 1), ('superhuman', 1), ('self-realized', 1), ('appareled', 1), ('gorgeously', 1), ('hells', 1), ('morsels', 1), ('digested', 1), ('underwent', 1), ('magicians', 1), ('thatched-roof', 1), ('constrictions', 1), ('deadweight', 1), ('comprehending', 1), ('westerners', 1), ('flouted', 1), ('unleashing', 1), ('offend', 1), ('outrages', 1), ('demoted', 1), ('alternation', 1), ('dualities', 1), ('puissant', 1), ('lineages', 1), ('newfound', 1), ('1873', 1), ('1788', 1), ('1786', 1), ('undergirding', 1), ('philanthropies', 1), ('freedmen', 1), ('lyman', 1), ('shunned', 1), ('underlay', 1), ('giddings', 1), ('oberlin', 1), ('temperance', 1), ('evangelists', 1), ('1807', 1), ('incessant', 1), ('scotian', 1), ('nova', 1), ('1805', 1), ('1839', 1), ('lundy', 1), ('methodism', 1), ('emancipate', 1), ('1693', 1), ('pietism', 1), ('evangelicalism', 1), ('transcendentalists', 1), ('endeavours', 1), ('quakers', 1), ('congregationalism', 1), ('trinitarian', 1), ('whitman', 1), ('transcendentalism', 1), ('fountain-head', 1), ('undimmed', 1), ('thine', 1), ('mend', 1), ('1893', 1), ('granddaughter', 1), ('1808', 1), ('programmes', 1), ('desuetude', 1), ('burgeoned', 1), ('cheating', 1), ('transgressed', 1), ('mould', 1), ('vineyard', 1), ('scallops', 1), ('antiphonal', 1), ('ebbs', 1), ('broglie', 1), ('agnostics', 1), ('determinism', 1), ('supermachine', 1), ('electrodynamics', 1), ('immaterial', 1), ('pinhead', 1), ('ellipses', 1), ('footballs', 1), ('stratosphere', 1), ('wonderland', 1), ('septillion', 1), ('oceans', 1), ('sextillion', 1), ('raging', 1), ('quintillion', 1), ('blanketed', 1), ('quadrillion', 1), ('trillion', 1), ('chunk', 1), ('skillfulness', 1), ('all-inclusive', 1), ('yonkers', 1), ('ethicist', 1), ('permissibility', 1), ('reformism', 1), ('unenforcible', 1), ('covenants', 1), ('kraemer', 1), ('anti-discrimination', 1), ('lobbied', 1), ('anti-discriminatory', 1), ('undermined', 1), ('evasion', 1), ('leverage', 1), ('residentially', 1), ('illumine', 1), ('obscures', 1), ('racially', 1), ('pervasively', 1), ('alumni', 1), ('professionalism', 1), ('client-service', 1), ('agitators', 1), ('non-white', 1), ('stigma', 1), ('mediating', 1), ('self-images', 1), ('ethicists', 1), ('re-evaluation', 1), ('one-sixth', 1), ('endurable', 1), ('immanent', 1), ('foreshortening', 1), ('endures', 1), ('fright', 1), ('regaining', 1), ('rebellions', 1), ('brutally', 1), ('amass', 1), ('atomisation', 1), ('whereon', 1), ('misshapen', 1), ('imprinted', 1), ('justitia', 1), ('irredeemable', 1), ('doomsday', 1), ('dehumanised', 1), ('irredeemably', 1), ('orwell', 1), ('affirms', 1), ('eventuality', 1), ('detest', 1), ('pacifism', 1), ('trammel', 1), ('cosequences', 1), ('objectively', 1), ('prudentially', 1), ('guiltiness', 1), ('foreknown', 1), ('balancing', 1), ('prudential', 1), ('feeney', 1), ('leslie', 1), ('hinduism', 1), ('fallible', 1), ('rican', 1), ('sacral', 1), ('gustave', 1), ('secularists', 1), ('penniless', 1), ('multitudes', 1), ('infusion', 1), ('sinai', 1), ('ayub', 1), ('mohammad', 1), ('islam', 1), ('dudley', 1), ('disaffection', 1), ('theocracy', 1), ('hindus', 1), ('anti-christian', 1), ('measurably', 1), ('hindu', 1), ('missionaries', 1), ('lament', 1), ('7000000', 1), ('rejoicing', 1), ('preponderantly', 1), ('sectarian', 1), ('asians', 1), ('cross-cultural', 1), ('justifications', 1), ('trans-political', 1), ('volksgeist', 1), ('aggravate', 1), ('nurture', 1), ('redeeming', 1), ('bigots', 1), ('bigoted', 1), ('paralleling', 1), ('nation-states', 1), ('minimally', 1), ('instrumentally', 1), ('eventualities', 1), ('form-creating', 1), ('massacres', 1), ('unconcern', 1), ('9910741', 1), ('7484268', 1), ('7360187', 1), ('4122354', 1), ('4622444', 1), ('4499608', 1), ('1080062', 1), ('122158', 1), ('1541991', 1), ('1419833', 1), ('spectator-type', 1), ('never-to-be-forgotten', 1), ('sweazey', 1), ('catechism', 1), ('true-false', 1), ('audibly', 1), ('filmstrips', 1), ('dramatization', 1), ('preparation-inquirers', 1), ('.78', 1), ('pp', 1), ('finder', 1), ('solicited', 1), ('packet', 1), ('refreshment', 1), ('mid-week', 1), ('devotional', 1), ('devotions', 1), ('leaflet', 1), ('unchristian', 1), ('insincere', 1), ('chi', 1), ('kiang', 1), ('huai', 1), ('anhwei', 1), ('huo-shan', 1), ('shansi', 1), ('hopei', 1), ('heng-shan', 1), ('shensi', 1), ('hwa-shan', 1), ('ai-shan', 1), ('sung-shan', 1), ('sinuous', 1), ('inactivity', 1), ('sky-god', 1), ('ien', 1), ('tsou', 1), ('pre-han', 1), ('compendium', 1), ('nonsensical', 1), ('pervaded', 1), ('numerology', 1), ('postulate', 1), ('inscriptions', 1), ('auspicious', 1), ('ti', 1), ('wu', 1), ('overshadowed', 1), ('diagonals', 1), ('numerological', 1), ('cosmological', 1), ('imaginations', 1), ('semisecret', 1), ('culminated', 1), ('202', 1), ('reuniting', 1), ('hard-won', 1), ('huang-ti', 1), ('shih', 1), ('207', 1), ('221', 1), ('warring', 1), ('longed-for', 1), ('pythagoreans', 1), ('babylonians', 1), ('901', 1), ('836', 1), ('korra', 1), ('ibn', 1), ('tabit', 1), ('desolations', 1), ('reconciles', 1), ('tribulation', 1), ('apostle', 1), ('followeth', 1), ('encamped', 1), ('infidels', 1), ('devoured', 1), ('devour', 1), ('encamp', 1), ('confessionals', 1), ('opiates', 1), ('pascal', 1), ('frivolity', 1), ('advertise', 1), ('lounges', 1), ('jittery', 1), ('pills', 1), ('escapist', 1), ('tellers', 1), ('diagnosable', 1), ('longings', 1), ('mouth-watering', 1), ('worshipping', 1), ('70000000', 1), ('spirituality', 1), ('hell-bound', 1), ('truth-packed', 1), ('all-time', 1), ('fortune-tellers', 1), ('80000', 1), ('200000000', 1), ('canaveral', 1), ('necks', 1), ('sputniks', 1), ('innermost', 1), ('isaiah', 1), ('ministering', 1), ('tendered', 1), ('beheld', 1), ('leadings', 1), ('acording', 1), ('appetites', 1), ('treatise', 1), ('concordance', 1), ('pragmatism', 1), ('inexpressibly', 1), ('modernists', 1), ('bible-emancipated', 1), ('bible-loving', 1), ('chasm', 1), ('interpolations', 1), ('redactions', 1), ('inculcated', 1), ('refute', 1), ('mycology', 1), ('herpetology', 1), ('amateu6rish', 1), ('majesterial', 1), ('historicity', 1), ('1848', 1), ('consciences', 1), ('impersonalized', 1), ('copiously', 1), ('massacre', 1), ('preachers', 1), ('mitre', 1), ('recollect', 1), ('archangels', 1), ('seraphim', 1), ('cherubim', 1), ('infraction', 1), ('vindicated', 1), ('prophesied', 1), ('evaporated', 1), ('hunkerish', 1), ('polities', 1), ('twenty-eighth', 1), ('world-at-large', 1), ('sermons', 1), ('poignantly', 1), ('abound', 1), ('bostonians', 1), ('intolerant', 1), ('rephrased', 1), ('interrogation', 1), ('theses', 1), ('poses', 1), ('ultra-liberal', 1), ('passions', 1), ('sumner', 1), ('repressions', 1), ('iconoclasm', 1), ('narrow-minded', 1), ('incontestable', 1), ('self-deprecation', 1), ('sarcasms', 1), ('cherishing', 1), ('canker', 1), ('resigning', 1), ('lick', 1), ('infidel', 1), ('shabbily', 1), ('apostates', 1), ('stratagems', 1), ('reviled', 1), ('ostracized', 1), ('convulsions', 1), ('bartol', 1), ('attest', 1), ('unforgivable', 1), ('peccavi', 1), ('insurgence', 1), ('escutcheon', 1), ('expel', 1), ('heaves', 1), ('trinitarians', 1), ('1843', 1), ('lavished', 1), ('calvinist', 1), ('pulpits', 1), ('pernicious', 1), ('excoriate', 1), ('calumniated', 1), ('sanhedrin', 1), ('stiles', 1), ('ezra', 1), ('revisionist', 1), ('exerts', 1), ('265', 1), ('ahrens', 1), ('kinsell', 1), ('laurance', 1), ('malmros', 1), ('haqvin', 1), ('scandinavia', 1), ('cholesterol-rich', 1), ('synthesizes', 1), ('suffocated', 1), ('infarct', 1), ('irritates', 1), ('narrows', 1), ('blockages', 1), ('gallstones', 1), ('sterios', 1), ('chole', 1), ('crystalline', 1), ('waxy', 1), ('yellowish', 1), ('lbs', 1), ('dieters', 1), ('dexedrine', 1), ('benzedrine', 1), ('amphetamines', 1), ('depressants', 1), ('dismisses', 1), ('gobblers', 1), ('nibblers', 1), ('eaters', 1), ('hauls', 1), ('sedative', 1), ('encephalitis', 1), ('enhances', 1), ('narcotizes', 1), ('water-balance', 1), ('adjusts', 1), ('overeat', 1), ('physiologically', 1), ('restricts', 1), ('hampers', 1), ('exertion', 1), ('overburden', 1), ('intemperance', 1), ('flagrant', 1), ('malnutrition', 1), ('internist', 1), ('growth-stunting', 1), ('kwashiorkor', 1), ('weaned', 1), ('pellagra', 1), ('scurvy', 1), ('calorie-heavy', 1), ('rejoices', 1), ('electrocardiogram', 1), ('coloreds', 1), ('capetown', 1), ('mealie-meal', 1), ('woodcutters', 1), ('finnish', 1), ('metabolism', 1), ('neapolitan', 1), ('skinfolds', 1), ('bantu', 1), ('a-year', 1), ('directs', 1), ('grey-haired', 1), ('blocky', 1), ('birch-paneled', 1), ('bestselling', 1), ('ancel', 1), ('no-cal', 1), ('cherry-flavored', 1), ('concocted', 1), ('high-protein', 1), ('tonics', 1), ('curds', 1), ('prunes', 1), ('panaceas', 1), ('fusty', 1), ('spoilage', 1), ('banish', 1), ('conspire', 1), ('inconspicuously', 1), ('imperceptible', 1), ('weight-height', 1), ('1488', 1), ('vigilant', 1), ('horse-playing', 1), ('skindiving', 1), ('theatergoing', 1), ('lurk', 1), ('4.98', 1), ('2454', 1), ('non-public', 1), ('mario', 1), ('jogs', 1), ('rambles', 1), ('incapacity', 1), ('stirrings', 1), ('inefficiency', 1), ('envisages', 1), ('communist-inspired', 1), ('wartorn', 1), ('uncourageous', 1), ('blunderings', 1), ('alamein', 1), ('undedicated', 1), ('disunited', 1), ('pub', 1), ('communize', 1), ('invincible', 1), ('leaderless', 1), ('fatalists', 1), ('machine-masters', 1), ('submariners', 1), ('road-circuit', 1), ('ultra-fast', 1), ('virtuosi', 1), ('briton', 1), ('funneled', 1), ('algebraic', 1), ('two-lane', 1), ('adhesion', 1), ('taruffi', 1), ('sha', 1), ('death-wish', 1), ('plainest', 1), ('rolls-royces', 1), ('bentleys', 1), ('sneering', 1), ('vendome', 1), ('case-hardened', 1), ('formalities', 1), ('disclaimer', 1), ('actuarially', 1), ('reportage', 1), ('explicitness', 1), ('ramblings', 1), ('modicum', 1), ('junior-philosophical', 1), ('precedes', 1), ('sanatorium', 1), ('regimen', 1), ('knife-edge', 1), ('unformed', 1), ('miglia', 1), ('alfonso', 1), ('bruited', 1), ('48500', 1), ('loops', 1), ('twisty', 1), ('creole', 1), ('year-long', 1), ('squalls', 1), ('mile-square', 1), ('arkabutla', 1), ('mckellar', 1), ('stinkpotters', 1), ('apalachicola', 1), ('pascagoula', 1), ('yachters', 1), ('barataria', 1), ('tarpon', 1), ('jacinto', 1), ('cruisers', 1), ('northers', 1), ('isabel', 1), ('aransas', 1), ('galveston-port', 1), ('tiburon', 1), ('regattas', 1), ('becalmed', 1), ('sailboat', 1), ('gusty', 1), ('speedboat', 1), ('racers', 1), ('235', 1), ('sinkhole', 1), ('once-dry', 1), ('salton', 1), ('small-boat', 1), ('sandbars', 1), ('oceanside', 1), ('dana', 1), ('ventura', 1), ('rey', 1), ('playa', 1), ('ramps', 1), ('docks', 1), ('breezes', 1), ('scooting', 1), ('mapped', 1), ('buoys', 1), ('indomitable', 1), ('boatsmen', 1), ('flotillas', 1), ('midwesterners', 1), ('overland', 1), ('hungrier', 1), ('steadier', 1), ('yachtsmen', 1), ('balmy', 1), ('pleasure-boat', 1), ('mungus', 1), ('fungus', 1), ('beriberi', 1), ('head-cold', 1), ('neuralgia', 1), ('neuritis', 1), ('hawks', 1), ('serafin', 1), ('tullio', 1), ('scala', 1), ('venomous', 1), ('norma', 1), ('two-timed', 1), ('druid', 1), ('alain', 1), ('splurge', 1), ('mamaroneck', 1), ('anniversaries', 1), ('falmouth', 1), ('archery', 1), ('boron', 1), ('iberia', 1), ('kingwood', 1), ('buckwheat', 1), ('ore.', 1), ('bandon', 1), ('cranberries', 1), ('sonoma', 1), ('festivals', 1), ('one-night', 1), ('bayanihan', 1), ('.30', 1), ('troupes', 1), ('hoosier', 1), ('almanac', 1), ('farmwife', 1), ('peden', 1), ('novelized', 1), ('zara', 1), ('retelling', 1), ('upper-middle-class', 1), ('pitilessly', 1), ('virgilia', 1), ('deft', 1), ('urn', 1), ('althea', 1), ('conceals', 1), ('best-seller', 1), ('less-indomitable', 1), ('greenhouses', 1), ('wilted', 1), ('kennett', 1), ('longwood', 1), ('stooges', 1), ('headlining', 1), ('corniest', 1), ('dak.', 1), ('cloudcroft', 1), ('alamogordo', 1), ('ruidoso', 1), ('aspencade', 1), ('salida', 1), ('ouray', 1), ('panoramas', 1), ('ozarks', 1), ('arrowhead', 1), ('marquette', 1), ('portage', 1), ('shawano', 1), ('oct', 1), ('colorama', 1), ('vilas', 1), ('smokies', 1), ('shenandoah', 1), ('appalachians', 1), ('renovo', 1), ('poconos', 1), ('alleghenies', 1), ('adirondacks', 1), ('birches', 1), ('hardwoods', 1), ('cavalcades', 1), ('haliburton', 1), ('muskoka', 1), ('ontario', 1), ('laurentian', 1), ('pilgrimages', 1), ('late-summer', 1), ('dulls', 1), ('stabs', 1), ('tints', 1), ('chile', 1), ('azerbaijan', 1), ('shepherds', 1), ('betrothal', 1), ('tsvetkov', 1), ('juggling', 1), ('kalmuk', 1), ('quadrille', 1), ('ba', 1), ('bul', 1), ('zhok', 1), ('moldavian', 1), ('polyanka', 1), ('come-uppance', 1), ('hard-to-please', 1), ('yurochka', 1), ('maidens', 1), ('all-too-brief', 1), ('whetted', 1), ('karl-birger', 1), ('yardumian', 1), ('stockhausen', 1), ('karlheinz', 1), ('toch', 1), ('melange', 1), ('wqxr', 1), ('bloops', 1), ('bleeps', 1), ('archaism', 1), ('reinvigoration', 1), ('fulfilling', 1), ('stamina', 1), ('discursiveness', 1), ('guises', 1), ('aural', 1), ('frequency-modulation', 1), ('listener-supported', 1), ('lamentations', 1), ('shallower', 1), ('architectonic', 1), ('palladian', 1), ('grey-skied', 1), ('cedar-roofed', 1), ('colonnaded', 1), ('pillared', 1), ('pedimented', 1), ('aptness', 1), ('lacquered', 1), ('shaggy', 1), ('tintoretto', 1), ('bernini', 1), ('auberge', 1), ('bonne', 1), ('tropez', 1), ('torpetius', 1), ('fiesta', 1), ('norwegian', 1), ('guidebook', 1), ('metaphorical', 1), ('astound', 1), ('labors', 1), ('overwritten', 1), ('slices', 1), ('indigestible', 1), ('multimillionaire', 1), ('sitwell', 1), ('sacheverell', 1), ('luxuriance', 1), ('formidably', 1), ('super-charged', 1), ('sinuousness', 1), ('cat-like', 1), ('seductive', 1), ('wondrously', 1), ('stepladders', 1), ('insinuating', 1), ('shep', 1), ('langhorne', 1), ('combatants', 1), ('incisiveness', 1), ('handsomely', 1), ('showpiece', 1), ('bruhn', 1), ('erik', 1), ('tallchief', 1), ('banfield', 1), ('dollar-de', 1), ('dollar-britten', 1), ('taras-tchaikovsky', 1), ('saturday-night', 1), ('8500', 1), ('wustman', 1), ('garishness', 1), ('highlights', 1), ('coy', 1), ('misleads', 1), ('mannerism', 1), ('dramatical', 1), ('garner', 1), ('lighthearted', 1), ('attractively', 1), ('trapdoors', 1), ('yea', 1), ('nostradamus', 1), ('nan', 1), ('loudspeaker', 1), ('friar', 1), ('umbrellas', 1), ('claudio', 1), ('insipid', 1), ('arragon', 1), ('masquers', 1), ('vivacity', 1), ('verges', 1), ('dogberry', 1), ('chuckles', 1), ('inured', 1), ('sallies', 1), ('resourcefully', 1), ('hifalutin', 1), ('brooked', 1), ('declamatory', 1), ('appreciating', 1), ('theatergoer', 1), ('untidiness', 1), ('dedicates', 1), ('serfs', 1), ('doltish', 1), ('aesthetics', 1), ('cloddishness', 1), ('city-bred', 1), ('boorish', 1), ('bryant', 1), ('long-sought', 1), ('bolstering', 1), ('hinders', 1), ('non-scientist', 1), ('immeasurable', 1), ('zooming', 1), ('steady-state', 1), ('expansion-contraction', 1), ('inexact', 1), ('solemnis', 1), ('missa', 1), ('gold-filled', 1), ('rundfunkchor', 1), ('rundfunk-sinfonie-orchester', 1), ('compositional', 1), ('rhenish', 1), ('gesangverein', 1), ('sweepings', 1), ('intermission', 1), ('burgomaster', 1), ('richter-haaser', 1), ('obsequies', 1), ('raggedness', 1), ('head-tossing', 1), ('choral', 1), ('subjectivity', 1), ('podium', 1), ('orchester', 1), ('volker', 1), ('unobtrusive', 1), ('bagatelles', 1), ('quasi-recitative', 1), ('arpeggios', 1), ('dynamically', 1), ('fluently', 1), ('presumptuous', 1), ('forgeries', 1), ('revelatory', 1), ('151', 1), ('extrovert', 1), ('koshare', 1), ('ash-can', 1), ('vivified', 1), ('multifigure', 1), ('bleeker', 1), ('gloucester', 1), ('clotheslines', 1), ('breezy', 1), ('mcsorley', 1), ('syndication', 1), ('genres', 1), ('pigments', 1), ('farr', 1), ('ksan', 1), ('eloquently', 1), ('hooting', 1), ('degrading', 1), ('mclendon-ebony', 1), ('mclendon', 1), ('general-appeal', 1), ('rhythm-and-blues', 1), ('keystone', 1), ('round-the-clock', 1), ('predominately', 1), ('wlib', 1), ('futhermore', 1), ('better-remembered', 1), ('3400', 1), ('20000000000', 1), ('19000000', 1), ('mushrooming', 1), ('outdistancing', 1), ('bizet', 1), ('shakily', 1), ('besmirch', 1), ('meyerbeer', 1), ('breathtaking', 1), ('vocalism', 1), ('rainbow-hued', 1), ('lily', 1), ('admires', 1), ('landon', 1), ('seeker', 1), ('introspection', 1), ('top-level', 1), ('mismanaged', 1), ('insiders', 1), ('crisply', 1), ('eyewitness', 1), ('warmed-over', 1), ('humiliatingly', 1), ('in-groups', 1), ('quadrennial', 1), ('frolicking', 1), ('fretting', 1), ('kalentiev', 1), ('vadim', 1), ('cygne', 1), ('fokine', 1), ('pavlovsky', 1), ('ter-stepanova', 1), ('xenia', 1), ('gossiping', 1), ('cinq', 1), ('kornevey', 1), ('chernishev', 1), ('osipenko', 1), ('acrobacy', 1), ('adagios', 1), ('kekisheva', 1), ('galina', 1), ('sokolev', 1), ('stunningly', 1), ('unequal', 1), ('vikulov', 1), ('komleva', 1), ('korneyeva', 1), ('alexeyeva', 1), ('ludmilla', 1), ('ballerina', 1), ('lovelorn', 1), ('petipa', 1), ('bayaderka', 1), ('korneyev', 1), ('lev', 1), ('zhitkov', 1), ('alexei', 1), ('oleg', 1), ('soloviev-sedoi', 1), ('fenster', 1), ('folk-tale', 1), ('diehards', 1), ('miscellanies', 1), ('credibility', 1), ('protracted', 1), ('bystander', 1), ('diffring', 1), ('basil', 1), ('chaffey', 1), ('glumly', 1), ('adulterous', 1), ('sues', 1), ('misguided', 1), ('longsuffering', 1), ('husky-voiced', 1), ('censorial', 1), ('low-budget', 1), ('superfluous', 1), ('insemination', 1), ('undergoes', 1), ('antonini', 1), ('alfredo', 1), ('unstuffy', 1), ('potboilers', 1), ('woodwind', 1), ('billings', 1), ('non-dissonant', 1), ('wallingford', 1), ('triptych', 1), ('mannered', 1), ('faze', 1), ('music-making', 1), ('indigo', 1), ('bas', 1), ('beale', 1), ('tootsie', 1), ('one-step', 1), ('braud', 1), ('wellman', 1), ('haywood', 1), ('clarinet', 1), ('alcorn', 1), ('two-record', 1), ('trombonist', 1), ('menilmontant', 1), ('bricktop', 1), ('grappely', 1), ('grappelly', 1), ('stephane', 1), ('rca-victor', 1), ('belgium', 1), ('baptiste', 1), ('guitarist', 1), ('revelling', 1), ('courtship', 1), ('trickster', 1), ('busiest', 1), ('life-contracts', 1), ('slyness', 1), ('perfunctory', 1), ('heavenward', 1), ('bespeak', 1), ('stares', 1), ('lustful', 1), ('buffoon', 1), ('zealot', 1), ('wife-to-be', 1), ('fernand', 1), ('humanize', 1), ('reinterpret', 1), ('well-received', 1), ('reinterpreted', 1), ('repeats', 1), ('enchant', 1), ('reviewer', 1), ('zoologist', 1), ('traveller', 1), ('rollicking', 1), ('idal', 1), ('pickaxe', 1), ('fealty', 1), ('irritation', 1), ('imponderable', 1), ('orb', 1), ('sharpening', 1), ('exhilarating', 1), ('self-discovery', 1), ('seventy-foot', 1), ('stranding', 1), ('elan', 1), ('needle-sharp', 1), ('unsuspecting', 1), ('cub', 1), ('tigris', 1), ('beach-drift', 1), ('porpoises', 1), ('dolphins', 1), ('swans', 1), ('greylag', 1), ('stags', 1), ('single-lane', 1), ('skye', 1), ('sea-village', 1), ('long-vanished', 1), ('raine', 1), ('cobblestone', 1), ('straggle', 1), ('high-up', 1), ('crouching', 1), ('stirringly', 1), ('segal', 1), ('yakov', 1), ('dilettante', 1), ('discord', 1), ('rivets', 1), ('tediously', 1), ('smitten', 1), ('conquerors', 1), ('middle-sized', 1), ('gorky', 1), ('cameo', 1), ('artkino', 1), ('block-buster', 1), ('cranes', 1), ('huskiness', 1), ('stritch', 1), ('cut-to-a-familiar-pattern', 1), ('swao', 1), ('wao', 1), ('noe', 1), ('tunefulness', 1), ('picon', 1), ('benzell', 1), ('mimi', 1), ('weede', 1), ('resourceful', 1), ('full-bodied', 1), ('sparkles', 1), ('lyriist', 1), ('yip', 1), ('anthems', 1), ('vallee', 1), ('earnestness', 1), ('plaintive', 1), ('roxy', 1), ('loudon', 1), ('505', 1), ('spruce', 1), ('revisited', 1), ('mcwhinney', 1), ('bagley', 1), ('oistrakh', 1), ('responsively', 1), ('leonore', 1), ('broodinf', 1), ('accompanist', 1), ('rondo', 1), ('filigree', 1), ('sonorities', 1), ('2800', 1), ('seven-concert', 1), ('tetrameron', 1), ('underplayed', 1), ('toccata', 1), ('sprightly', 1), ('tamiris-daniel', 1), ('spoof', 1), ('phrasings', 1), ('slavish', 1), ('modern-dance', 1), ('catalogues', 1), ('executing', 1), ('hultberg', 1), ('bastianini', 1), ('ettore', 1), ('boat-yard', 1), ('chantier', 1), ('chanter', 1), ('ensue', 1), ('shanties', 1), ('chorale', 1), ('emil', 1), ('witherspoon', 1), ('poindexter', 1), ('resounding', 1), ('konga', 1), ('olatunji', 1), ('babatunde', 1), ('batterie', 1), ('field-hands', 1), ('gospel-singer', 1), ('preacher-singer', 1), ('hour-long', 1), ('monterey', 1), ('narrated', 1), ('easy-going', 1), ('mambo', 1), ('drummer', 1), ('bongo', 1), ('vibes', 1), ('improvising', 1), ('restating', 1), ('scintillating', 1), ('categorize', 1), ('ballards', 1), ('bangles', 1), ('baubles', 1), ('frosted', 1), ('vamp', 1), ('hard-hearted', 1), ('oldies', 1), ('minns', 1), ('accompanists', 1), ('late-comers', 1), ('unenviable', 1), ('warner', 1), ('budieshein', 1), ('messengers', 1), ('brookmeyer', 1), ('aggregations', 1), ('basie', 1), ('aggregation', 1), ('peals', 1), ('nigh', 1), ('throng', 1), ('encores', 1), ('rockabye', 1), ('picayune', 1), ('shatteringly', 1), ('over-arranged', 1), ('trundling', 1), ('rescuing', 1), ('mixers', 1), ('unsheathe', 1), ('unbidden', 1), ('encroaching', 1), ('coiffure', 1), ('short-skirted', 1), ('wedged', 1), ('lindsey', 1), ('mort', 1), ('showmen', 1), ('ritz', 1), ('puttin', 1), (\"you're\", 1), ('jazzmen', 1), ('way-out', 1), ('5500', 1), ('lumbering', 1), ('ditties', 1), ('churns', 1), ('guignol', 1), ('darius', 1), ('parella', 1), ('valente', 1), ('benita', 1), ('saunders', 1), ('mawkish', 1), ('neo-classicism', 1), ('salon', 1), ('rationalist', 1), ('librettists', 1), ('boismassif', 1), ('newlywed', 1), ('uneducated', 1), ('one-act', 1), ('pleasingly', 1), ('thre', 1), ('copland', 1), ('canteloube', 1), ('dvorak', 1), ('duets', 1), ('folksongs', 1), ('ellie', 1), ('boulez', 1), ('dissonances', 1), ('vacuous', 1), ('harpsichordist', 1), ('oboist', 1), ('josef', 1), ('flutist', 1), ('brieff', 1), ('anabel', 1), ('janitsch', 1), ('dragonetti', 1), ('comenico', 1), ('sammartini', 1), ('035', 1), ('spycket', 1), ('sylvie', 1), ('telemann', 1), ('rosenmueller', 1), ('buxtehude', 1), ('pachelbel', 1), ('siecles', 1), ('allemands', 1), ('maitres', 1), ('evocative', 1), ('harpsichord', 1), ('046', 1), ('menet', 1), ('sextuor', 1), ('elegances', 1), ('mid-century', 1), ('steinkerque', 1), ('mondonville', 1), ('corrette', 1), ('beismortier', 1), ('leclair', 1), ('jean-marie', 1), ('060', 1), ('siecle', 1), ('lesser-known', 1), ('imperiale', 1), ('astree', 1), ('sultane', 1), ('nos.', 1), ('gemlike', 1), ('ld060', 1), ('ld056', 1), ('royaux', 1), ('sonates', 1), ('boite', 1), ('nonmusical', 1), ('dancelike', 1), ('look-see', 1), ('musicality', 1), ('gesualdo', 1), ('monteverdi', 1), ('marenzio', 1), ('lassus', 1), ('boom-boom-boom', 1), ('rum-tum-tum', 1), ('tarantara', 1), ('tomkins', 1), ('latter-day', 1), ('obliterate', 1), ('glees', 1), ('interregnum', 1), ('cromwellian', 1), ('continuo', 1), ('5031', 1), ('bgs', 1), ('609', 1), ('consort', 1), ('madrigaling', 1), ('cleva', 1), ('fausto', 1), ('holdovers', 1), ('enzo', 1), ('cieca', 1), ('mignon', 1), ('cesare', 1), ('regina', 1), ('legato', 1), ('colzani', 1), ('anselmo', 1), ('barnaba', 1), ('goodies', 1), ('pre-historic', 1), ('creaks', 1), ('ponchielli', 1), ('gioconda', 1), ('lopatnikoff', 1), ('nuance', 1), ('non-romantic', 1), ('ultra-efficient', 1), ('non-sentimental', 1), ('tonally', 1), ('zadel', 1), ('whine', 1), ('over-emphasize', 1), ('sweet-sounding', 1), ('franck', 1), ('sprinted', 1), ('english-dialogue', 1), ('askance', 1), ('raimu', 1), ('marseilles', 1), ('marcel', 1), ('heart-warming', 1), ('joyously', 1), ('lovable', 1), ('theatergoers', 1), ('scrim', 1), ('ter-arutunian', 1), ('rouben', 1), ('kilts', 1), ('glide', 1), ('lasses', 1), ('toomey', 1), ('nordstrom', 1), ('sez', 1), ('catchy', 1), ('brigadoon', 1), ('intimidate', 1), ('sneers', 1), ('roars', 1), ('bosco', 1), ('bowan', 1), ('sibly', 1), ('carney', 1), ('biddies', 1), ('unlamented', 1), ('fagan', 1), ('ex-prize', 1), ('graced', 1), ('impersonates', 1), ('lund', 1), ('matchmaking', 1), ('improviser', 1), ('soft-shoe', 1), ('mikeen', 1), ('knockdown', 1), ('mettlesome', 1), ('bullying', 1), ('roe', 1), ('mcenroe', 1), ('romancing', 1), ('fist-fighting', 1), ('lightened', 1), ('narrator', 1), ('soviet-western', 1), ('riddle', 1), ('misplacements', 1), ('potsdam', 1), ('rouse', 1), ('dissimulation', 1), ('amorality', 1), ('cynicism', 1), ('orations', 1), ('silences', 1), ('tirades', 1), ('truant', 1), ('moustache', 1), ('collaborator', 1), ('autocrats', 1), ('plebeian', 1), ('exemplify', 1), ('tsar', 1), ('instalments', 1), ('puerile', 1), ('anti-nazi', 1), ('unshakeable', 1), ('policed', 1), ('alger', 1), ('appeasing', 1), ('disloyal', 1), ('sweepingly', 1), ('mitigating', 1), ('uncommonly', 1), ('scrupulous', 1), ('tsarism', 1), ('remus', 1), ('laureate', 1), ('themes', 1), ('fable', 1), ('bullies', 1), ('extermination', 1), ('fifty-cent', 1), ('vegetarian', 1), ('raccoon', 1), ('despots', 1), ('lebensraum', 1), ('captions', 1), ('caricaturist', 1), ('tyrannical', 1), ('accolade', 1), ('matsu', 1), ('tensing', 1), ('hillary', 1), ('eden', 1), ('sardonic', 1), ('capably', 1), ('confucius', 1), ('stupidities', 1), ('jovian', 1), ('piecemeal', 1), ('wield', 1), ('corrosion', 1), ('tuc', 1), ('blimp', 1), ('self-deceptions', 1), ('shams', 1), ('puzzler', 1), ('humanness', 1), ('protoplasmic', 1), ('dali', 1), ('surrealist', 1), ('reassuringly', 1), ('bang-sashes', 1), ('nectareous', 1), ('glean', 1), ('epigrammatic', 1), ('shadings', 1), ('gazer', 1), ('little-known', 1), ('semi-serious', 1), ('homogenize', 1), ('announcers', 1), ('amusingly', 1), ('crumble', 1), ('kooks', 1), ('ballyhooey', 1), ('gobbledygook', 1), ('malapropism', 1), ('potions', 1), ('curative', 1), ('vocabularianism', 1), ('ear-muffs', 1), ('monographs', 1), ('asceticism', 1), ('hairshirt', 1), ('trivia', 1), ('parodies', 1), ('paraphrases', 1), ('palindromes', 1), ('hospitalized', 1), ('insomniacs', 1), ('word-games', 1), ('necklace', 1), ('graffiti', 1), ('primitive-eclogue', 1), ('displace', 1), ('truer', 1), ('impersonally', 1), ('polemic', 1), ('polemics', 1), ('imperturbable', 1), ('well-meaning', 1), ('opprobrium', 1), ('differing', 1), ('magnanimity', 1), ('unpatronizing', 1), ('grown-up', 1), ('elegantly', 1), ('felicities', 1), ('kronenberger', 1), ('editorship', 1), ('open-minded', 1), ('on-stage', 1), ('tatras', 1), ('polonaise', 1), ('dwor', 1), ('strasny', 1), ('moniuszko', 1), ('zapala', 1), ('witold', 1), ('krakowiak', 1), ('flirtatious', 1), ('ziminska-sygietynska', 1), ('mira', 1), ('gleaned', 1), ('pauses', 1), ('nonstop', 1), ('three-week', 1), ('mazowsze', 1), ('schockler', 1), ('enchantingly', 1), ('motet', 1), ('stylish', 1), ('szelenyi', 1), ('istvan', 1), ('prodigies', 1), ('bleat', 1), ('shrillness', 1), ('untrained', 1), ('well-balanced', 1), ('carols', 1), ('mater', 1), ('stabat', 1), ('pergolesi', 1), ('motets', 1), ('geroge', 1), ('high-minded', 1), ('corralling', 1), ('loped', 1), ('buckaroos', 1), ('uncomplainingly', 1), ('mutilation', 1), ('encumbered', 1), ('495', 1), ('depresses', 1), ('airstrips', 1), ('airdrops', 1), ('noncombatant', 1), ('self-critical', 1), ('praises', 1), ('well-written', 1), ('burmese', 1), ('jungles', 1), ('gurkhas', 1), ('outgeneraled', 1), ('outfought', 1), ('outmaneuvered', 1), ('ill-prepared', 1), ('counter-moves', 1), ('abridged', 1), ('technicalities', 1), ('unfailingly', 1), ('serieuses', 1), ('bravura', 1), ('songful', 1), ('preludes', 1), ('kabalevsky', 1), ('filagree', 1), ('deep-sounding', 1), ('.12', 1), ('virtuosity', 1), ('greek-born', 1), ('saint-saens', 1), ('sarasate', 1), ('paganini', 1), ('hubay', 1), ('dohnanyi', 1), ('wornout', 1), ('ravel-like', 1), ('capricious', 1), ('melodically', 1), ('vibrato', 1), ('eschews', 1), ('brahm', 1), ('526', 1), ('mozart', 1), ('drawback', 1), ('overdriving', 1), ('misgauged', 1), ('acoustics', 1), ('hungarian-born', 1), ('falsehood', 1), ('aura', 1), ('unjustifiable', 1), ('discounted', 1), ('dissembling', 1), ('tizard', 1), ('lindemanns', 1), ('impressionistic', 1), ('perverted', 1), ('incoherent', 1), ('prepublication', 1), ('incautious', 1), ('gist', 1), ('post-mortem', 1), ('autobiographical', 1), ('refresher', 1), ('instructors', 1), ('disintegrate', 1), ('webb', 1), ('re-run', 1), ('censored', 1), ('re-runs', 1), ('brinkley', 1), ('front-page', 1), ('liabilities', 1), ('journalists', 1), ('markel', 1), ('messing', 1), ('amory', 1), ('dooleys', 1), ('schweitzers', 1), ('delving', 1), ('meme', 1), ('lui', 1), ('gouverne', 1), ('roi', 1), ('deification', 1), ('monarque', 1), ('bogey-symbol', 1), ('light-hearted', 1), ('bouvier', 1), ('antoinette', 1), ('incompetent', 1), ('dust-settling', 1), ('regency', 1), ('moluccas', 1), ('celebes', 1), ('upholds', 1), ('dienbienphu', 1), ('insurgents', 1), ('indonesian', 1), ('jakarta', 1), ('stodgy', 1), ('twenty-first-century', 1), ('pitney-bowes', 1), ('vidal', 1), ('tigers', 1), ('chennault', 1), ('escadrille', 1), ('hessians', 1), ('1770', 1), ('confuses', 1), ('brigades', 1), ('deferments', 1), ('sidelight', 1), ('disruptions', 1), ('draftee', 1), ('pfc', 1), ('devens', 1), ('pegged', 1), ('peiping', 1), ('ed.', 1), ('nr', 1), ('debt-free', 1), ('mises', 1), ('hazlitt', 1), ('isolationism', 1), ('worn-out', 1), ('worlders', 1), ('self-rule', 1), ('ramifications', 1), ('amalgamated', 1), ('sacrificing', 1), ('across-the-board', 1), ('shoddy', 1), ('overpaid', 1), ('underpaid', 1), ('kirk', 1), ('rapid-fire', 1), ('camouflaged', 1), ('concealment', 1), ('creek-filled', 1), ('deactivated', 1), ('undismayed', 1), ('m-4', 1), ('collinsville', 1), ('m-1', 1), ('norborne', 1), ('bolivar', 1), ('life-and-death', 1), ('fog-enshrouded', 1), ('foggy', 1), ('anti-communists', 1), ('infernally', 1), ('crusading', 1), ('liberating', 1), ('peace-treaty', 1), ('canceling', 1), ('appease', 1), ('exalting', 1), ('malinovsky', 1), ('russo-american', 1), ('prophecies', 1), ('bombastic', 1), ('hoxa', 1), ('enver', 1), ('chinese-soviet', 1), ('abusive', 1), ('undemocratic', 1), ('dictatorial', 1), ('marxist-leninist', 1), ('epoch-making', 1), ('whipping-boys', 1), ('mikoyan', 1), ('non-stop', 1), ('voroshilov', 1), ('eighty-year-old', 1), ('kaganovich', 1), ('malenkov', 1), ('obsessive', 1), ('skate', 1), ('old-age', 1), ('kolkhozes', 1), ('thrives', 1), ('sovkhozes', 1), ('wage-earning', 1), ('democratization', 1), ('consecration', 1), ('apotheosis', 1), ('uninitiated', 1), ('blueprint', 1), ('tauntingly', 1), ('half-dressed', 1), ('contorted', 1), ('self-portraits', 1), ('morbid-minded', 1), ('moneymaking', 1), ('billet', 1), ('wangled', 1), ('scrounging', 1), ('collars', 1), ('hand-me-down', 1), ('jailed', 1), ('erotica', 1), ('klimt', 1), ('gustav', 1), ('mosaic-like', 1), ('impressionists', 1), ('defecated', 1), ('tantrums', 1), ('schoolwork', 1), ('tulln', 1), ('danubian', 1), ('drowsy', 1), ('stationmaster', 1), ('boldest', 1), ('foreshortened', 1), ('knobby-knuckled', 1), ('landau', 1), ('egon', 1), ('half-forgotten', 1), ('kokoschka', 1), ('oskar', 1), ('handkerchiefs', 1), ('circa', 1), ('ziraldo', 1), ('gloria', 1), ('cascades', 1), ('miniatures', 1), ('persianesque', 1), ('malia', 1), ('leila', 1), ('adamo', 1), ('glimmering', 1), ('patrician', 1), ('waist-length', 1), ('picnics', 1), ('gerby', 1), ('jemela', 1), ('syrians', 1), ('haflis', 1), ('somay', 1), ('murat', 1), ('black-bearded', 1), ('roadhouse', 1), ('semra', 1), ('mid-shimmy', 1), ('prohibit', 1), ('bombardment', 1), ('striptease', 1), ('bends', 1), ('karshilama', 1), ('telli', 1), ('shifte', 1), ('fingertips', 1), ('migrates', 1), ('glides', 1), ('terpers', 1), ('cooch', 1), ('progeny', 1), ('prim', 1), ('def', 1), ('roemer', 1), ('treelike', 1), ('darbuka', 1), ('lute', 1), ('oud', 1), ('violins', 1), ('guitars', 1), ('shirt-sleeved', 1), ('overeager', 1), ('hand-painted', 1), ('papier-mache', 1), ('boites', 1), ('familial', 1), ('inpost', 1), ('playwrights', 1), ('borak', 1), ('hock', 1), ('laudably', 1), ('unoriginals', 1), ('fledermaus', 1), ('lili', 1), ('reconverting', 1), ('yum-yum', 1), ('farces', 1), ('douce', 1), ('irma', 1), ('charmingly', 1), ('tenderloin', 1), ('camelot', 1), ('behan', 1), ('brendan', 1), ('anouilh', 1), ('shelagh', 1), ('laurents', 1), ('boulle', 1), ('mountainously', 1), ('hersey', 1), ('agee', 1), ('goa', 1), ('uni-directional', 1), ('five-hundred-year-old', 1), ('bleating', 1), ('supinely', 1), ('materiel', 1), ('kwame', 1), ('pro-europe', 1), ('fln', 1), ('moscow-allied', 1), ('anti-french', 1), ('apartheid', 1), ('gigenza', 1), ('tshombe-gizenga-goa-ghana', 1), ('temporally', 1), ('hungary-suez', 1), ('truth-revealing', 1), ('too-naked', 1), ('self-deceiving', 1), ('strutting', 1), ('frontiers', 1), ('crystallization', 1), ('indecisiveness', 1), ('planeload', 1), ('jocularly', 1), ('vouchsafes', 1), ('idiocies', 1), ('extirpating', 1), ('semi-independent', 1), ('calamitous', 1), ('down-and-out', 1), ('indigent', 1), ('catalytic', 1), ('exegete', 1), ('leninism-marxism', 1), ('privations', 1), ('admirals', 1), ('extirpated', 1), ('perforce', 1), ('conscripted', 1), ('formosan', 1), ('crucially', 1), ('translator', 1), ('itinerary', 1), ('smarted', 1), ('taipei', 1), ('duchess', 1), ('asinine', 1), ('bloke', 1), ('re-enter', 1), ('pointedly', 1), ('irredentism', 1), ('septuagenarian', 1), ('hypnotized', 1), ('tiniest', 1), ('give-and-take', 1), ('generality', 1), ('reassert', 1), ('going-over', 1), ('aristotelean-thomistic', 1), ('discussant', 1), ('thirty-fourth', 1), ('battle-cry', 1), ('intransigents', 1), ('mollify', 1), ('anti-recession', 1), ('eisenhhower', 1), ('penny-wise', 1), ('booby-trap', 1), ('omnipotence', 1), ('discouragement', 1), ('secretariate', 1), ('augustin', 1), ('cicognani', 1), ('revivified', 1), ('pontiff', 1), ('ecumenicists', 1), ('glossed', 1), ('deceiving', 1), ('brutalized', 1), ('sufficiency', 1), ('cogently', 1), ('cessation', 1), ('domestically', 1), ('unilaterally', 1), ('dilemmas', 1), ('moratorium', 1), ('three-power', 1), ('footwork', 1), ('halcyon', 1), ('bureaucrat', 1), ('mid-1950s', 1), ('nastier', 1), ('shies', 1), ('lauritsen', 1), ('excusable', 1), ('agreed-on', 1), ('radiation-produced', 1), ('stillbirths', 1), ('neonatal', 1), ('carbon-14', 1), ('plasm', 1), ('biologic', 1), ('linus', 1), ('hedged', 1), ('tricky', 1), ('worst-marked', 1), ('abstain', 1), ('seaborg', 1), ('above-ground', 1), ('holier-than-thou', 1), ('inveigh', 1), ('descends', 1), ('uk', 1), ('hecatomb', 1), ('gallivantin', 1), ('ruark', 1), ('tarheelia', 1), ('wont', 1), ('baptists', 1), ('hardshell', 1), ('tenacious', 1), ('socinianism', 1), ('disreputable', 1), ('home-keeping', 1), ('miniscule', 1), ('stasis', 1), ('yon', 1), ('hither', 1), ('ancillary', 1), ('grinds', 1), ('inalienable', 1), ('symbolical', 1), ('processional', 1), ('grandstand', 1), ('centralia', 1), ('thousandth', 1), ('meat-wagon', 1), ('publicizing', 1), ('fatality', 1), ('blood-lust', 1), ('satiate', 1), ('motor-car', 1), ('heathenish', 1), ('idol-worship', 1), ('corrupting', 1), ('stans', 1), ('soft-headed', 1), ('soft-heartedness', 1), ('bemoan', 1), ('chimes', 1), ('undetected', 1), ('doe', 1), ('subversives', 1), ('to-the-death', 1), ('blackbirds', 1), ('starlings', 1), ('octopus', 1), ('tentacle', 1), ('ars', 1), ('crossings', 1), ('ferries', 1), ('insignificances', 1), ('bashir', 1), ('camel', 1), ('pakistani', 1), ('tardy', 1), ('atone', 1), ('thankless', 1), ('gooey', 1), ('jagan', 1), ('cheddi', 1), ('demage', 1), ('simplicitude', 1), ('simpleton', 1), ('hogging', 1), ('hough', 1), ('hard-sell', 1), ('gentility', 1), ('impudence', 1), ('apathy', 1), ('complimented', 1), ('trumbull', 1), ('weeded', 1), ('littering', 1), ('litterbug', 1), ('dpw', 1), ('cavanagh', 1), ('mayor-elect', 1), ('miriani', 1), ('southfield', 1), ('donates', 1), ('government-controlled', 1), ('government-blessed', 1), ('person-to-person', 1), ('dialing', 1), ('automate', 1), ('saver', 1), ('fifty-ninth', 1), ('thirty-ninth', 1), ('bmt', 1), ('seventy-fourth', 1), ('tens', 1), ('flushing-main', 1), ('home-bound', 1), ('self-judging', 1), ('nonpayment', 1), ('smoldering', 1), ('terrorized', 1), ('rearmed', 1), ('resurgence', 1), ('seven-week', 1), ('fall-outs', 1), ('nullity', 1), ('murderous', 1), ('allege', 1), ('proxmire', 1), ('fountains', 1), ('memorials', 1), ('liberalizing', 1), ('landlords', 1), ('molest', 1), ('preparedness', 1), ('manmade', 1), ('civilian-groups', 1), ('920', 1), ('mistrust', 1), ('interglacial', 1), ('dinosaurs', 1), ('cretaceous', 1), ('microfossils', 1), ('entombed', 1), ('overlying', 1), ('cypress-like', 1), ('coal-like', 1), ('peep', 1), ('newarker', 1), ('taxicab', 1), ('muggers', 1), ('uplift', 1), ('speedup', 1), ('levied', 1), ('startle', 1), ('oppressors', 1), ('cohorts', 1), ('god-given', 1), ('loaders', 1), ('leased', 1), ('covert', 1), ('guzzle', 1), ('103', 1), ('congresswoman', 1), ('divest', 1), ('580', 1), ('3.22', 1), ('550', 1), ('welcomes', 1), ('archdiocese', 1), ('commendation', 1), ('innuendo', 1), ('affix', 1), ('instruct', 1), ('madeira', 1), ('fairest', 1), ('freezers', 1), ('regimented', 1), ('bettering', 1), ('unsheltered', 1), ('mcnamara', 1), ('trohan', 1), ('exhaustion', 1), ('forand', 1), ('unsurpassed', 1), ('tear-soaked', 1), ('nonservice-connected', 1), ('out-of-step', 1), ('non-service', 1), ('undivided', 1), ('switzer', 1), ('rozella', 1), ('mathewson', 1), ('dewitt', 1), ('fain', 1), ('update', 1), ('cowessett', 1), ('potowomut', 1), ('greenwich-potowomut', 1), ('cowessett-east', 1), ('metropolitanization', 1), ('absorbing', 1), ('foundering', 1), ('fallacy', 1), ('bostitch', 1), ('well-to-do', 1), ('zoned', 1), ('canoe', 1), ('paddle', 1), ('birch', 1), ('fair-sized', 1), ('attlee', 1), ('mudslinging', 1), ('ooze', 1), ('spectre', 1), ('shuddery', 1), ('debating', 1), ('pauper', 1), ('spenders', 1), ('adage', 1), ('mince', 1), ('unpartisan', 1), ('self-insurance', 1), ('allegiances', 1), ('folkston', 1), ('brasstown', 1), ('griffin-byrd', 1), ('downgrade', 1), ('smokers', 1), ('mule-drawn', 1), ('recaptured', 1), ('squirms', 1), ('goal-line', 1), ('tackles', 1), ('jolting', 1), ('kick-offs', 1), ('puffs', 1), ('by-gone', 1), ('eyeglasses', 1), ('middle-age', 1), ('slap', 1), ('hails', 1), ('persimmons', 1), ('unripe', 1), ('bifocals', 1), ('bridgework', 1), ('titter', 1), ('coed', 1), ('perpetually', 1), ('homecomings', 1), ('dodd', 1), ('restudy', 1), ('retranslated', 1), ('recopied', 1), ('novice', 1), ('beatitudes', 1), ('paragraphing', 1), ('straightway', 1), ('becometh', 1), ('comest', 1), ('forbad', 1), ('cometh', 1), ('apocrypha', 1), ('weigle', 1), ('chairmanship', 1), ('1881', 1), ('inaccuracies', 1), ('r-6th', 1), ('roswell', 1), ('fourth-class', 1), ('312', 1), ('285', 1), ('presided', 1), ('foote', 1), ('seoul', 1), ('hee', 1), ('chung', 1), ('r-5th', 1), ('luxer', 1), ('pullmans', 1), ('pullman', 1), ('590000', 1), ('750000', 1), ('2300000', 1), ('ibm', 1), ('sawed-off', 1), ('hoosegow', 1), ('escapees', 1), ('lifer', 1), ('arbitration', 1), ('hoosegows', 1), ('seafood', 1), ('low-calory', 1), ('jarvis', 1), ('berniece', 1), ('cyril', 1), ('staircases', 1), ('sashayed', 1), ('brice', 1), (\"''.\", 1), ('nile', 1), ('miscellany', 1), ('initialed', 1), ('90000', 1), ('gazettes', 1), ('politburo', 1), ('sabre', 1), ('rattles', 1), ('egged', 1), ('chestnuts', 1), ('britons', 1), ('contaminate', 1), ('proverbial', 1), ('novosti', 1), ('revenge-seeking', 1), ('besetting', 1), ('imperialist', 1), ('sabre-rattling', 1), ('clamored', 1), ('munitions', 1), ('mouthpieces', 1), ('impute', 1), ('post-reapportionment', 1), ('committeeman', 1), ('shrewdest', 1), ('close-in', 1), ('ex-gov.', 1), ('incumbents', 1), ('shunted', 1), ('eye-to-eye', 1), ('bodes', 1), ('lavishing', 1), ('to-1', 1), ('rock-ribbed', 1), ('reapportionment', 1), ('loose-knit', 1), ('contrarily', 1), ('afar', 1), ('hard-nosed', 1), ('politico', 1), ('candidate-picking', 1), ('fresno', 1), ('endorsing', 1), ('broad-scale', 1), ('officeholders', 1), ('grassroots-fueled', 1), ('dissensions', 1), ('clubrooms', 1), ('handicrafts', 1), ('reappearing', 1), ('chinese-inspired', 1), ('chippendale', 1), ('jacobean', 1), ('twirled', 1), ('sauterne', 1), ('over-stitched', 1), ('varitinted', 1), ('one-color', 1), ('multicolor', 1), ('crayons', 1), ('ingenuity', 1), ('uncomforatble', 1), ('straightens', 1), ('inborn', 1), ('nonchalant', 1), ('foiles', 1), ('offensively', 1), ('duplicate', 1), ('robby', 1), ('charge-a-plate', 1), ('threateningly', 1), ('pedal', 1), ('acquiesence', 1), ('decelerate', 1), ('lanesmanship', 1), ('accommodation', 1), ('depots', 1), ('bombings', 1), ('nonsegregated', 1), ('nonracial', 1), ('citywide', 1), ('boycotted', 1), ('stair-step', 1), ('dynamited', 1), ('biracial', 1), ('tucking', 1), ('scary', 1), ('robin', 1), ('crickets', 1), ('chirping', 1), ('fringed-wrapped', 1), ('freckled', 1), ('lyin', 1), ('sun-browned', 1), ('butterflies', 1), ('road-crossing', 1), ('singleness', 1), ('pre-history', 1), ('world-ignoring', 1), ('asters', 1), ('sunshield', 1), ('broad-brimmed', 1), ('straw-hat', 1), ('winging', 1), ('retraced', 1), ('autumn-touched', 1), ('unintelligible', 1), ('rippling', 1), ('vine-shaded', 1), ('slung', 1), ('hooks', 1), ('cross-top', 1), ('podgers', 1), ('unmindful', 1), ('saintliness', 1), ('bruise', 1), ('covet', 1), ('sneed', 1), ('mothers-in-law', 1), ('mother-in-law', 1), ('reassure', 1), ('no-o', 1), ('signposts', 1), ('intoxicating', 1), ('fevered', 1), ('pre-nuptial', 1), ('searchingly', 1), ('giggling', 1), ('cokes', 1), ('squeals', 1), ('oft', 1), ('dyke', 1), ('thoughtlessly', 1), ('employe', 1), ('booster', 1), ('lundeen', 1), ('lewellyn', 1), ('.2', 1), ('.3', 1), ('canning', 1), ('metropolitian', 1), ('decatur', 1), ('hash', 1), ('sprout', 1), ('work-weary', 1), ('beef-fat', 1), ('typewritten', 1), ('postmen', 1), ('newsletters', 1), ('selfless', 1), ('alarming', 1), ('squeamish', 1), ('dead-end', 1), ('double-talk', 1), ('avert', 1), ('unemotional', 1), ('tightest', 1), ('purge', 1), ('armageddon', 1), ('ten-year', 1), ('imbalances', 1), ('throttled', 1), ('injustices', 1), ('second-look', 1), ('approving', 1), ('now-misplaced', 1), ('budget-altering', 1), ('trusteeship', 1), ('leasing', 1), ('leases', 1), ('franchises', 1), ('lawmaking', 1), ('reorganize', 1), ('budget-making', 1), ('nonpolitical', 1), ('hobbled', 1), ('revolves', 1), ('electing', 1), ('controversies', 1), ('morass', 1), ('succumb', 1), ('1450000000', 1), ('dinh', 1), ('ngo', 1), ('ridgway', 1), ('cong', 1), ('interposed', 1), ('saigon', 1), ('cruises', 1), ('trans-atlantic', 1), ('84000000', 1), ('50400000', 1), ('q3', 1), ('prosaic', 1), ('discourses', 1), ('off-the-cuff', 1), ('ex-presidents', 1), ('dollarette', 1), ('fellowships', 1), ('ungracious', 1), ('nigeria', 1), ('postcard', 1), ('sniping', 1), ('diligently', 1), ('prerogatives', 1), ('anti-castro', 1), ('interrogator', 1), ('mariano', 1), ('donkey', 1), ('banishment', 1), ('cartoonists', 1), ('reforming', 1), ('sedition', 1), ('expunging', 1), ('balks', 1), ('sachems', 1), ('badges', 1), ('second-class', 1), ('plant-location', 1), ('politics-ridden', 1), ('frankfort', 1), ('herrin-murphysboro-west', 1), ('city-owned', 1), ('schwada', 1), ('dovetail', 1), ('nine-state', 1), ('outstate', 1), ('retarding', 1), ('mid-continent', 1), ('slow-growing', 1), ('missouri-illinois', 1), ('nil', 1), ('joyride', 1), ('corpsman', 1), ('black-crowned', 1), ('egrets', 1), ('provincetown', 1), ('shorelines', 1), ('warns', 1), ('udall', 1), ('battlefront', 1), ('parceled', 1), ('8100', 1), ('corroborating', 1), ('forecasters', 1), ('pacemaker', 1), ('prognostication', 1), ('concedes', 1), ('marauders', 1), ('harboring', 1), ('prognosticator', 1), ('hazardous', 1), ('self-criticism', 1), ('revitalize', 1), ('swindling', 1), ('growers', 1), ('over-produce', 1), ('feuds', 1), ('craft-industrial', 1), ('squabbling', 1), ('reuther', 1), ('pro-castro', 1), ('pro-trujillo', 1), ('vive', 1), ('responsive', 1), ('wracked', 1), ('expeditious', 1), ('rationalizations', 1), ('subverted', 1), ('open-meeting', 1), ('above-water', 1), ('islandia', 1), ('undeniably', 1), ('duped', 1), ('rewrite', 1), ('unsupportable', 1), ('assail', 1), ('gulled', 1), ('joiners', 1), ('bismarck', 1), ('rock-like', 1), ('konrad', 1), ('veers', 1), ('rebirth', 1), ('ascend', 1), ('moon-faced', 1), ('bundestag', 1), ('arisen', 1), ('floridians', 1), ('colee', 1), ('689', 1), ('8.5', 1), ('painstaking', 1), ('15.5', 1), ('indenture', 1), ('dissenting', 1), ('bogged', 1), ('imperiled', 1), ('outbreaks', 1), ('katangan', 1), ('machinegun', 1), ('riddled', 1), ('rhodesia', 1), ('ndola', 1), ('truckers', 1), ('felonious', 1), ('incompetence', 1), ('moralities', 1), ('caracas', 1), ('purloined', 1), ('montevideo', 1), ('edified', 1), ('guevara', 1), ('che', 1), ('mortification', 1), ('demented', 1), ('marimba', 1), ('bayed', 1), ('pacifier', 1), ('oafs', 1), ('wallop', 1), ('jumper', 1), ('imperfection', 1), ('lads', 1), ('internationalists', 1), ('discloses', 1), ('compensating', 1), ('featherbedding', 1), ('expediency', 1), ('mandated', 1), ('garrisoned', 1), ('demoralized', 1), ('wrong-headed', 1), ('subjugate', 1), ('outlawry', 1), ('pillage', 1), ('mutinies', 1), ('rapes', 1), ('nationhood', 1), ('dissident', 1), ('condoned', 1), ('atrocities', 1), ('dismembered', 1), ('bloodlust', 1), ('airmen', 1), ('sadder', 1), ('harding', 1), ('educating', 1), ('oratorical', 1), ('subside', 1), ('retraction', 1), ('loquacious', 1), ('unnumbered', 1), ('partisans', 1), ('rear-looking', 1), ('emulated', 1), ('well-ruled', 1), ('coup-proof', 1), ('guaranteed-neutral', 1), ('pro-neutralist', 1), ('ousted', 1), ('rightist', 1), ('tacitly', 1), ('bypassed', 1), ('braddock-against-the-indians', 1), ('guerrilla-th', 1), ('road-shy', 1), ('monsoon-shrouded', 1), ('combat-tested', 1), ('minh', 1), ('bog', 1), ('unprovocative', 1), ('pawn', 1), ('callable', 1), ('thai', 1), ('bangkok', 1), ('helicopter-borne', 1), ('downing', 1), ('gulling', 1), ('oopsie-cola', 1), ('enticing', 1), ('toothpaste', 1), ('soft-drinks', 1), ('pseudo-sophistication', 1), ('fatuous', 1), ('non-code', 1), ('unfairly', 1), ('subverting', 1), ('major-market', 1), ('anti-liquor', 1), ('distiller', 1), ('silo', 1), ('grasslands', 1), ('moth-eaten', 1), ('pottawatomie', 1), ('live-oak', 1), ('indelibly', 1), ('sun-bleached', 1), ('seamless', 1), ('grassland', 1), ('dusty-green', 1), ('throw-rug', 1), ('bison', 1), ('danzig', 1), ('redressed', 1), ('hooliganism', 1), ('vopos', 1), ('fusillades', 1), ('acknowledging', 1), ('quadripartite', 1), ('eisler', 1), ('gerhard', 1), ('sound-truck', 1), ('berlin-west', 1), ('illegally', 1), ('promulgating', 1), ('mitigate', 1), ('airlift', 1), ('zones', 1), ('comprising', 1), ('semi-city', 1), ('usurp', 1), ('acquiesced', 1), ('well-advised', 1), ('stolzenbach', 1), ('alluring', 1), ('brookmont', 1), ('communist-type', 1), ('coalesces', 1), ('noire', 1), ('bete', 1), ('rapprochement', 1), ('right-wing', 1), ('tarnished', 1), ('tardily', 1), ('sycophantically', 1), ('lobbies', 1), ('quashed', 1), ('jimenez', 1), ('perez', 1), ('marcos', 1), ('romulo', 1), ('galindez', 1), ('abduction', 1), ('fiefdom', 1), ('even-handed', 1), ('often-blood', 1), ('rafael', 1), ('behooves', 1), ('half-million', 1), ('1250000', 1), ('milledgeville', 1), ('1750000', 1), ('soapy', 1), ('imperialists', 1), ('zanzibar', 1), ('mennen', 1), ('brinkmanship', 1), ('junks', 1), ('gearing', 1), ('brushfire', 1), ('leeway', 1), ('deterrence', 1), ('deter', 1), ('a-bombs', 1), ('go-it-alone', 1), ('banding', 1), ('five-member', 1), ('83750', 1), ('coosa', 1), ('cons', 1), ('newspapermen', 1), ('inattentive', 1), ('windup', 1), ('banning', 1), ('penal', 1), ('crisis-to-crisis', 1), ('musts', 1), ('adjourns', 1), ('1509', 1), ('50000000', 1), ('25000000', 1), ('co-ops', 1), ('maligned', 1), ('booklists', 1), ('grassroots', 1), ('pre-school', 1), ('book-selection', 1), ('book-review', 1), ('well-planned', 1), ('nanook', 1), ('hewlett-woodmere', 1), ('levittown', 1), ('freeport', 1), ('teletype', 1), ('co-op', 1), ('well-stocked', 1), ('high-density', 1), ('bounty', 1), ('grist', 1), ('rentals', 1), ('unprofitable', 1), ('communist-led', 1), ('attactive', 1), ('2.80', 1), ('steelmaker', 1), ('steelmakers', 1), ('highest-paid', 1), ('transferring', 1), ('shrinkage', 1), ('unrestrictedly', 1), ('lancashire', 1), ('high-wage', 1), ('exporting', 1), ('less-developed', 1), ('textile-exporting', 1), ('textile-importing', 1), ('advertising-conscious', 1), ('sales-conscious', 1), ('design-conscious', 1), ('cabled', 1), ('typewriters', 1), ('defaulted', 1), ('skyway', 1), ('kans.', 1), ('wichita', 1), ('richmond-petersburg', 1), ('toll-rate', 1), ('173', 1), ('186', 1), ('blyth', 1), ('more-than-ordinary', 1), ('bucked', 1), ('payoff', 1), ('maitre', 1), ('french-born', 1), ('cuisine', 1), ('dubois', 1), ('soft-shell', 1), ('smelts', 1), ('lowliest', 1), ('poor-mouth', 1), ('foreign-aid', 1), ('5.2', 1), ('224', 1), ('754', 1), ('46.7', 1), ('prudently', 1), ('mutterers', 1), ('hold-back', 1), ('225000', 1), ('unaccustomed', 1), ('peddle', 1), ('kidnapping', 1), ('frog-marched', 1), ('besset', 1), ('toni', 1), ('stewardesses', 1), ('ambulances', 1), ('taxiing', 1), ('cody', 1), ('ex-convict', 1), ('dc-7', 1), ('propeller-driven', 1), ('swap', 1), ('fuels', 1), ('boxer', 1), ('pfc.', 1), ('recruiter', 1), ('nap', 1), ('skyjackers', 1), ('newsweek', 1), ('electra', 1), ('cuban-american', 1), ('arequipa', 1), ('tri-motor', 1), ('peruvian', 1), ('mid-flight', 1), ('night-coach', 1), ('stopovers', 1), ('four-jet', 1), ('good-will', 1), ('nepal', 1), ('emissaries', 1), ('peking', 1), ('emissary', 1), ('cheng', 1), ('uruguay', 1), ('bourguiba', 1), ('habib', 1), ('bahi', 1), ('imbroglio', 1), ('tunis', 1), ('reconvention', 1), ('eject', 1), ('flickered', 1), ('balkanize', 1), ('federalize', 1), ('exasperated', 1), ('intervene', 1), ('meddle', 1), ('kalonji', 1), ('19000', 1), ('mali', 1), ('guinea', 1), ('hammarskjo', 1), ('abstaining', 1), ('mineral-rich', 1), ('paratroops', 1), ('raping', 1), ('rioting', 1), ('cannibalistic', 1), ('well-armed', 1), ('officered', 1), ('frictions', 1), ('well-wishers', 1), ('bicameral', 1), ('western-style', 1), ('kivu', 1), ('federalism', 1), ('near-balkanization', 1), ('balkanizing', 1), ('guiltless', 1), ('pedagogue', 1), ('goutte', 1), ('unsure', 1), ('clamoring', 1), ('chatte', 1), ('dole', 1), ('envisaged', 1), ('societe', 1), ('gunther', 1), ('cartels', 1), ('manganese', 1), ('unmatched', 1), ('disparities', 1), ('trampled', 1), ('equatorial', 1), ('steamily', 1), ('animism', 1), ('mohammedanism', 1), ('900000', 1), ('avidly', 1), ('speech-making', 1), ('sixth-sense', 1), ('139.3', 1), ('typhoon', 1), ('tidying', 1), ('nine-year', 1), ('genes', 1), ('bundy', 1), ('mcgeorge', 1), ('plaintiffs', 1), ('desegregated', 1), ('roommate', 1), ('morehouse', 1), ('valedictorian', 1), ('175', 1), ('discriminate', 1), ('speculated', 1), ('rhine-westphalia', 1), ('1500000', 1), ('basel', 1), ('snubbing', 1), ('burglarproof', 1), ('giacometti', 1), ('legers', 1), ('matisses', 1), ('braques', 1), ('cezannes', 1), ('bellboys', 1), ('barr', 1), ('343', 1), ('ardor', 1), ('new-rich', 1), ('connotes', 1), ('jetliners', 1), ('transatlantic', 1), ('spooned', 1), ('self-exile', 1), ('red-prone', 1), ('enterprisingly', 1), ('izvestia', 1), ('eulogizers', 1), ('self-crimination', 1), ('crowns', 1), ('cliffhanging', 1), ('gumption', 1), ('rafer', 1), ('decathlon', 1), ('toneless', 1), ('tutors', 1), ('cacophonist', 1), ('dreamboat', 1), ('bobby-sox', 1), ('cerebrated', 1), ('swum', 1), ('ambassador-designate', 1), ('buss', 1), ('brotherly', 1), ('neuberger', 1), ('maurine', 1), ('noncommissioned', 1), ('deplored', 1), ('tilling', 1), ('hawing', 1), ('geeing', 1), ('moldboard', 1), ('leatherneck', 1), ('warless', 1), ('commandant', 1), ('couturier', 1), ('ringside', 1), ('ensconced', 1), ('fitzgerald', 1), ('ella', 1), ('glutted', 1), ('lawford', 1), ('cinemactor', 1), ('actor-crooner', 1), ('convair', 1), ('disillusioned', 1), ('dullest', 1), ('base-stealing', 1), ('aparicio', 1), ('3.1', 1), ('bunters', 1), ('.332', 1), ('stances', 1), ('right-handed', 1), ('head-and-shoulders', 1), ('railroading', 1), ('vow', 1), ('ex-yankee', 1), ('idolize', 1), ('kerby', 1), ('tulsa', 1), ('shuns', 1), ('stunk', 1), ('tropic', 1), ('halfbacks', 1), ('roommates', 1), ('sleeps', 1), ('251', 1), ('mvp', 1), ('zeroed', 1), ('foxx', 1), ('challenger', 1), ('incorrigible', 1), ('thinning', 1), ('knock-down', 1), ('pinch-hitter', 1), ('grand-slam', 1), ('ambled', 1), ('double-header', 1), ('three-wood', 1), ('one-iron', 1), ('par-3', 1), ('bunkered', 1), ('punching', 1), ('dogleg', 1), ('obliterated', 1), ('well-played', 1), ('intervening', 1), ('vocalization', 1), ('footer', 1), ('parklike', 1), ('nagle', 1), ('kel', 1), ('tidal', 1), ('hyndman', 1), ('twosome', 1), ('scoreboards', 1), ('geriatric', 1), ('treacheries', 1), ('putter', 1), ('supersensitive', 1), ('venturi', 1), ('nicklaus', 1), ('horde', 1), ('under-par', 1), ('flag-stick', 1), ('skiddy', 1), ('drizzly', 1), ('outplayed', 1), ('duels', 1), ('footnotes', 1), ('washed-out', 1), ('206', 1), ('holed', 1), ('baltimorean', 1), ('one-over-par', 1), ('topnotch', 1), ('leathery', 1), ('second-place', 1), ('281', 1), ('overshot', 1), ('putted', 1), ('last-round', 1), ('lodged', 1), ('strayed', 1), ('seven-iron', 1), ('scorecard', 1), ('over-par', 1), ('double-bogeyed', 1), ('rainstorm', 1), ('officiate', 1), ('convening', 1), ('congresses', 1), ('cloture', 1), ('hard-to-get', 1), ('saltonstall', 1), ('leverett', 1), ('filibusters', 1), ('legislation-delaying', 1), ('forma', 1), ('liberal-conservative', 1), ('coolheaded', 1), ('unworkable', 1), ('chairmanships', 1), ('costlier', 1), ('whiplash', 1), ('maverick', 1), ('mississippians', 1), ('purged', 1), ('caucuses', 1), ('cloakrooms', 1), ('vinson', 1), ('pork-barrel', 1), ('smith-colmer', 1), ('unconscionable', 1), ('anti-colmer', 1), ('unscathed', 1), ('dixiecrats', 1), ('prodigal', 1), ('anti-kennedy', 1), ('ouster', 1), ('rayburn-johnson', 1), ('democratic-sponsored', 1), ('far-out', 1), ('anti-negro', 1), ('diehard', 1), ('choppy', 1), ('gangling', 1), ('godliness', 1), ('caucusing', 1), ('meyers', 1), ('conservative-liberal', 1), ('menaced', 1), ('masquerades', 1), ('coyly', 1), ('ilyushin', 1), ('predictably', 1), ('indo-china', 1), ('cold-war', 1), ('116', 1), ('okinawa', 1), ('troopships', 1), ('precautionary', 1), ('battalions', 1), ('secretary-designate', 1), ('breakoff', 1), ('foreign-policy', 1), ('consulate', 1), ('offensives', 1), ('undermining', 1), ('alleging', 1), ('emasculated', 1), ('immunization', 1), ('loewe', 1), ('hatters', 1), ('danbury', 1), ('irrationality', 1), ('aeronautics', 1), ('injunctions', 1), ('norris-laguardia', 1), ('improper', 1), ('officious', 1), ('ten-hour', 1), ('unsupported', 1), ('collective-bargaining', 1), ('taft-hartley', 1), ('impolitic', 1), ('pretends', 1), ('fictitious', 1), ('prosecutions', 1), ('contendere', 1), ('nolo', 1), ('thurman', 1), ('scapegoats', 1), ('culpas', 1), ('mea', 1), ('enforcers', 1), ('wide-open', 1), ('self-restraint', 1), ('flex', 1), ('multi-product', 1), ('price-setting', 1), ('7500000', 1), ('machinists', 1), ('stoppages', 1), ('anatole', 1), ('fallacious', 1), ('john.', 1), ('administers', 1), ('luncheon-table', 1), ('busy-work', 1), ('pre-set', 1), ('versed', 1), ('faked', 1), ('high-sounding', 1), ('baneful', 1), ('dichotomy', 1), ('invests', 1), ('clerical-lay', 1), ('oft-repeated', 1), ('inhomogeneous', 1), ('citizenship', 1), ('acclimatized', 1), ('inapt', 1), ('teacher-employee', 1), ('decision-making', 1), ('intra-mural', 1), ('pre-academic', 1), ('co-educational', 1), ('anomalies', 1), ('family-community', 1), ('blunts', 1), ('well-springs', 1), ('arithmetical', 1), ('flattering', 1), ('mollusks', 1), ('biologist', 1), ('onus', 1), ('impotency', 1), ('tripartite', 1), ('unchecked', 1), ('stalemate', 1), ('novosibirsk', 1), ('llewellyn', 1), ('sparing', 1), ('adversary', 1), ('summitry', 1), ('one-sided', 1), ('u-2', 1), ('full-dress', 1), ('givers', 1), ('rough-housing', 1), ('preceeded', 1), ('bed-time', 1), ('ugf', 1), ('chatting', 1), ('washington-alexandria', 1), ('biennial', 1), ('crypt', 1), ('eulogized', 1), ('bustling', 1), ('1733', 1), ('sphynxes', 1), ('collonaded', 1), ('angelico', 1), ('fra', 1), ('courbet', 1), ('blue-uniformed', 1), ('gogh', 1), ('rheims', 1), ('alba', 1), ('self-portrait', 1), ('curator', 1), ('sousa', 1), ('rapt', 1), ('sharpe', 1), ('rainier', 1), ('holbrook', 1), ('sun-tanned', 1), ('england-born', 1), ('white-clad', 1), ('spangled', 1), ('cardiac', 1), ('wellknown', 1), ('jussel', 1), ('mccluskey', 1), ('lehman', 1), ('woodcarver', 1), ('mcintyre', 1), ('mantlepiece', 1), ('antiquarians', 1), ('refurbishing', 1), ('sidechairs', 1), ('authenticated', 1), ('rutherford', 1), ('heirs', 1), ('much-copied', 1), ('cadillacs', 1), ('tuck', 1), ('finned', 1), ('1.80', 1), ('clobbers', 1), ('ok', 1), ('oases', 1), ('wind-and-water', 1), ('fins', 1), ('debonair', 1), ('enriching', 1), ('chiuchow', 1), ('cantonese', 1), ('mandarin', 1), ('musica', 1), ('capello', 1), ('kqed', 1), ('ventilates', 1), ('unlinked', 1), ('knickerbocker', 1), ('paine', 1), ('detract', 1), ('dud', 1), ('shocker', 1), ('herridge', 1), ('ekberg', 1), ('lex', 1), ('unknowns', 1), ('private-eye', 1), ('ozzie', 1), ('naughtier', 1), ('naughty', 1), ('spanish-born', 1), ('munoz', 1), ('charmed', 1), ('casals', 1), ('pablo', 1), ('676', 1), ('198', 1), ('stonestown', 1), ('firehouses', 1), ('798', 1), ('busied', 1), ('1044', 1), ('erroneously', 1), ('ten-concert', 1), ('sustaining', 1), ('lumia', 1), ('concertmaster', 1), ('dubovskoi', 1), ('evegeni', 1), ('pastel-like', 1), ('virsaladze', 1), ('shatilov', 1), ('konstantin', 1), ('danseur', 1), ('semenov', 1), ('vladilen', 1), ('nijinsky', 1), ('bluebird', 1), ('sizova', 1), ('lightness', 1), ('suavity', 1), ('filial', 1), ('thestage', 1), ('impoverished', 1), ('oops', 1), ('stalingr', 1), ('pinsk', 1), ('omsk', 1), ('aya', 1), ('eva', 1), ('ova', 1), ('self-plagiarisms', 1), ('boobify', 1), ('stultifying', 1), ('infantile', 1), ('ytime', 1), ('petipa-tschaikowsky', 1), ('slenczynka', 1), ('ricci', 1), ('ruggiero', 1), ('menuhin', 1), ('yehudi', 1), ('violinists', 1), ('conductors', 1), ('bordeau', 1), ('philharmonique', 1), ('siciliana', 1), ('sinfonica', 1), ('enrique', 1), ('densmore', 1), ('nazarene', 1), ('treadwell', 1), ('lutheran', 1), ('blanton', 1), ('prayer-time', 1), ('miffed', 1), ('two-year-old', 1), ('shari', 1), ('twice-a-year', 1), ('ter.', 1), ('3181', 1), ('macwhorter', 1), ('city-wide', 1), ('braun', 1), ('four-hour', 1), ('enthralled', 1), ('communisn', 1), ('biblically', 1), ('schoolers', 1), ('brainwashing', 1), ('pompano', 1), ('stranahan', 1), ('aquinas', 1), ('orlando', 1), ('tallahassee', 1), ('librarian-board', 1), ('whelan', 1), ('2.50', 1), ('gretchen', 1), ('bolet', 1), ('espagnol', 1), ('ximenez-vargas', 1), ('milenoff', 1), ('rimini', 1), ('carlo', 1), ('smallwood', 1), ('placentia', 1), ('michaels', 1), ('fazio', 1), ('rickshaw', 1), ('moffett', 1), ('morgart', 1), ('bandish', 1), ('gill', 1), ('searles', 1), ('avon', 1), ('randy', 1), ('pualani', 1), ('chum', 1), ('playboy', 1), ('drinkhouse', 1), ('month-long', 1), ('bimini', 1), ('mackey', 1), ('buffets', 1), ('brunches', 1), ('debuts', 1), ('cornering', 1), ('sunman', 1), ('reopening', 1), ('lorain', 1), ('hubie', 1), ('tic-tac-toe', 1), ('decicco', 1), ('shrimp', 1), ('yokel', 1), ('chandeliers', 1), ('bossman', 1), ('kissak', 1), ('bouncy', 1), ('skips', 1), ('keyboarding', 1), ('kelly', 1), ('wes', 1), ('kemm', 1), ('sidemen', 1), ('repartee', 1), ('reminiscence', 1), ('ex-schoolteacher', 1), ('fike', 1), ('toppers', 1), ('marskmen', 1), ('reno-lake', 1), ('hovarter', 1), ('ringsiders', 1), ('springing', 1), ('leighton', 1), ('capers', 1), ('calypso', 1), ('bahia', 1), ('freida', 1), ('accordion', 1), ('fireside', 1), ('cumbancheros', 1), ('oceania', 1), ('bartha', 1), ('crazy-wonderful', 1), ('tuba', 1), ('grossman', 1), ('ciciulla', 1), ('spotlights', 1), ('instrumentals', 1), ('vocals', 1), ('skits', 1), ('leland', 1), ('cabinetmakers', 1), ('home-owners', 1), ('playtime', 1), ('disharmony', 1), ('whims', 1), ('althaus', 1), ('macgregors', 1), ('geddes', 1), ('carbones', 1), ('longinotti', 1), ('armisteads', 1), ('crispin', 1), ('egerton', 1), ('berteros', 1), ('chapelles', 1), ('aderholds', 1), ('olerichs', 1), ('eng.', 1), ('wangemans', 1), ('esnards', 1), ('raoul', 1), ('beesemyers', 1), ('windsor', 1), ('moultons', 1), ('moulton', 1), ('chantilly', 1), ('pauleys', 1), ('pfau', 1), ('mcalester', 1), ('haskins', 1), ('huntingtons', 1), ('huntington', 1), ('ludlow', 1), ('cynthia', 1), ('brownings', 1), ('duque', 1), ('mcalister', 1), ('valerie', 1), ('gregg', 1), ('hartley', 1), ('currys', 1), ('ellsworth', 1), ('joanne', 1), ('mcfarland', 1), ('ghormley', 1), ('worrell', 1), ('postman', 1), ('hord', 1), ('crackpots', 1), ('finger-paint', 1), ('rainy', 1), ('logistical', 1), ('tapestries', 1), ('kreisler', 1), ('schmidl-seeberg', 1), ('ilona', 1), ('examiners', 1), ('leroy', 1), ('lafe', 1), ('bricker', 1), ('niven', 1), ('cott', 1), ('three-building', 1), ('renderings', 1), ('welton', 1), ('finalist', 1), ('wellsville', 1), ('vanilla', 1), ('bake-offs', 1), ('pillsbury', 1), ('frosting', 1), ('caramel', 1), ('scrapbook', 1), ('schmalzried', 1), ('kerrville', 1), ('climaxed', 1), ('darrow', 1), ('mcelyee', 1), ('messrs', 1), ('abell', 1), ('sunbonnet', 1), ('bluebonnets', 1), ('vests', 1), ('stetsons', 1), ('calico', 1), ('ginghams', 1), ('air-conditioned', 1), ('vagabonds', 1), ('reiterate', 1), ('hand-crafted', 1), ('bronzy-green-gold', 1), ('mellow', 1), ('bookcases', 1), ('hand-screened', 1), ('shoji', 1), ('see-through', 1), ('lustrous', 1), ('spider-leg', 1), ('scotchgard', 1), ('predominating', 1), ('magenta', 1), ('chromspun', 1), ('eastman', 1), ('poster', 1), ('styling', 1), ('headboard', 1), ('canted', 1), ('easy-to-reach', 1), ('high-legged', 1), ('macassar', 1), ('inlaid', 1), ('insets', 1), ('titche', 1), ('custom-design', 1), ('pecan', 1), ('wormy', 1), ('sanger-harris', 1), ('boxy', 1), ('garde', 1), ('avant', 1), ('livability', 1), ('straight-line', 1), ('pontiac', 1), ('seedless', 1), ('slow-baked', 1), ('mushrooms', 1), ('saute', 1), ('275', 1), ('saffron', 1), ('atlee', 1), ('clement', 1), ('stoked', 1), ('cauliflower', 1), ('broccoli', 1), ('hotdogs', 1), ('condiments', 1), ('flavored', 1), ('bans', 1), ('duress', 1), ('go-go-go', 1), ('mastodons', 1), ('chow', 1), ('hockaday', 1), ('pester', 1), ('ruggedly', 1), ('mcelvaney', 1), ('moans', 1), ('groceries', 1), ('women-trodden', 1), ('dutifully', 1), ('coeds', 1), ('gander', 1), ('oilman-rancher', 1), ('afro-cuban', 1), ('kiowa', 1), ('waxworks', 1), ('tussard', 1), ('camille', 1), ('brassbound', 1), ('mame', 1), ('campobello', 1), ('miniver', 1), ('forsythe', 1), ('curie', 1), ('grenoble', 1), ('postgraduate', 1), ('orkney', 1), ('scotch-irish-scandinavian', 1), ('reminisces', 1), ('balenciaga', 1), ('ceil', 1), ('long-bodied', 1), ('chemise', 1), ('pecos', 1), ('bel-air', 1), ('fogelson', 1), ('luncheons', 1), ('revolutionized', 1), ('dior', 1), ('vivier', 1), ('casuals', 1), ('wragge', 1), ('byer-rolnick', 1), ('rolnick', 1), ('sarmi', 1), ('ferdinando', 1), ('titian-haired', 1), ('17.8', 1), ('pre-easter', 1), ('18.2', 1), ('seasonally', 1), ('divulging', 1), ('subsidiary', 1), ('wholly-owned', 1), ('briefs', 1), ('upshots', 1), ('tax-aided', 1), ('household-type', 1), ('kickbacks', 1), ('invoices', 1), ('liquidations', 1), ('tax-freedom', 1), ('disallowed', 1), ('deductibility', 1), ('revenuers', 1), ('substantiation', 1), ('clay-mining', 1), ('prior-year', 1), ('adjourning', 1), ('mid-1960', 1), ('mid-july', 1), ('237', 1), ('242', 1), ('12.7', 1), ('39.5', 1), ('marketings', 1), ('639', 1), ('1.4', 1), ('129', 1), ('cutback', 1), ('merritt', 1), ('stepped-up', 1), ('staiger', 1), ('869', 1), ('2418', 1), ('ltd.', 1), ('massey-ferguson', 1), ('2700', 1), ('picker', 1), ('uptrend', 1), ('drought-seared', 1), ('upswing', 1), ('ehlers', 1), ('tilts', 1), ('non-farm', 1), ('1257700', 1), ('polled', 1), ('2.295', 1), ('2.325', 1), ('three-way', 1), ('icc', 1), ('cross-examination', 1), ('tuohy', 1), ('shareholder', 1), ('irate', 1), ('television-electronics', 1), ('kawecki', 1), ('teleprompter', 1), ('1.58', 1), ('1.23', 1), ('1981', 1), ('1976', 1), ('1971', 1), ('1991', 1), ('subordinated', 1), ('923076', 1), ('2700877', 1), ('stockholder', 1), ('phelan', 1), ('all-automatic', 1), ('equalizers', 1), ('geometrically', 1), ('log-jam', 1), ('industrialist', 1), ('howell', 1), ('3.98', 1), ('3.28', 1), ('lows', 1), ('354', 1), ('695', 1), ('1253', 1), ('687.87', 1), ('7.19', 1), ('whopping', 1), ('streeters', 1), ('snapback', 1), ('pivotal', 1), ('sidelines', 1), ('675', 1), ('blackmail', 1), ('retrenching', 1), ('aggressively', 1), ('neo-stagnationist', 1), ('cyclical', 1), ('arouny', 1), ('gaither', 1), ('palo', 1), ('beryl', 1), ('stallard', 1), ('caron', 1), ('bert', 1), ('carolyn', 1), ('samuels', 1), ('flanagan', 1), ('wolverton', 1), ('seagoville', 1), ('rylie', 1), ('mclauchlin', 1), ('neal', 1), ('edna', 1), ('carty', 1), ('carrel', 1), ('deloris', 1), ('satterfield', 1), ('shay', 1), ('hillcrest', 1), ('kestner', 1), ('paulah', 1), ('crozier', 1), ('paschall', 1), ('tommie', 1), ('adamson', 1), ('terral', 1), ('fil', 1), ('whitney', 1), ('janice', 1), ('kaminsky', 1), ('arrington', 1), ('trigg', 1), ('pharmical', 1), ('isodine', 1), ('owens', 1), ('seniors', 1), ('lower-priced', 1), ('compacts', 1), ('april-june', 1), ('1212000', 1), ('11744', 1), ('9273', 1), ('quarter-to-quarter', 1), ('4441', 1), ('2963', 1), ('3399', 1), ('doldrums', 1), ('belting', 1), ('stacy', 1), ('piping', 1), ('separators', 1), ('extractors', 1), ('hinckley', 1), ('heaters', 1), ('lummus', 1), ('cotton-growing', 1), ('prattville', 1), ('1834', 1), ('dallas-based', 1), ('gins', 1), ('ginner', 1), ('avid', 1), ('chip-o', 1), ('second-echelon', 1), ('fittest', 1), ('run-up', 1), ('run-ups', 1), ('subscribe', 1), ('11.50', 1), ('185000', 1), ('reams', 1), ('underwriter', 1), ('eppler', 1), ('over-the-counter', 1), ('allotting', 1), ('dallas-headquartered', 1), ('28700000', 1), ('cashed', 1), ('blaber', 1), ('109', 1), ('liens', 1), ('embezzlement', 1), ('antone', 1), ('undetermined', 1), ('embezzling', 1), ('1630', 1), ('micro-microcurie', 1), ('bottling', 1), ('warehouseman', 1), ('1215', 1), ('onetime', 1), ('accardo', 1), ('teamster', 1), ('senese', 1), ('dominic', 1), ('kedzie', 1), ('3247', 1), ('543', 1), ('stevedore', 1), ('hoodlum', 1), ('allegretti', 1), ('divarco', 1), ('gangland', 1), ('3300', 1), ('reilly', 1), ('ratto', 1), ('petrini', 1), ('perasso', 1), ('calude', 1), ('moscone', 1), ('duhagon', 1), ('armond', 1), ('cervetto', 1), ('campagnoli', 1), ('frederic', 1), ('bianco', 1), ('beronio', 1), ('attilio', 1), ('anderlini', 1), ('elios', 1), ('casassa', 1), ('arata', 1), ('scampini', 1), ('massimo', 1), ('gliders', 1), ('waterline', 1), ('streamer', 1), ('fuselage', 1), ('ailerons', 1), ('pulse-jet', 1), ('signaled', 1), ('rocket-bombs', 1), ('super-secret', 1), ('aeronautical', 1), ('quiet-spoken', 1), ('airstrip', 1), ('underbelly', 1), ('rocket-bomb', 1), ('kentfield', 1), ('olney', 1), ('greenwood', 1), ('tidelands', 1), ('645', 1), ('livermore', 1), ('fonta', 1), ('co-ordination', 1), ('pesticides', 1), ('wetlands', 1), ('reyes', 1), ('blueberries', 1), ('rodents', 1), ('borer', 1), ('princeton', 1), ('prentice-hall', 1), ('newsom', 1), ('mcn.', 1), ('kkk', 1), ('jury-tampering', 1), ('hobart', 1), ('greyhound', 1), ('hartselle', 1), ('greenock', 1), ('trawler', 1), ('destroyer', 1), ('newport-based', 1), ('trichieri', 1), ('cavaliere', 1), ('mfg.', 1), ('uncas', 1), ('646', 1), ('50000', 1), ('4177.37', 1), ('simmonsville', 1), ('thornton', 1), ('hose', 1), ('nickels', 1), ('8250', 1), ('823', 1), ('claus', 1), ('hodosh', 1), ('saul', 1), ('8293', 1), ('52500', 1), ('57500', 1), ('atwells', 1), ('lovett', 1), ('rosella', 1), ('vermeersch', 1), ('tougas', 1), ('nolan', 1), ('fractured', 1), ('woonasquatucket', 1), ('fatima', 1), ('rotelli', 1), ('cochran', 1), ('255', 1), ('two-family', 1), ('jewelry', 1), ('stoppage', 1), ('nunes', 1), ('kochaneks', 1), ('intruders', 1), ('hillsdrive', 1), ('kochanek', 1), ('3675', 1), ('disimone', 1), ('desoto', 1), ('collided', 1), ('734', 1), ('centredale', 1), ('accessors', 1), ('filbert', 1), ('borland', 1), ('jaross', 1), ('jody', 1), ('verboort', 1), ('jansen', 1), ('millie', 1), ('cedar', 1), ('championships', 1), ('corneilus', 1), ('haase', 1), ('wacklin', 1), ('batchelder', 1), ('tualatin', 1), ('pumpkin', 1), ('traxel', 1), ('lorlyn', 1), ('janet', 1), ('finalists', 1), ('reedville', 1), ('nuttall', 1), ('all-county', 1), ('fairgoers', 1), ('five-day', 1), ('ffa', 1), ('shelby', 1), ('kolb', 1), ('wegener', 1), ('reifenrath', 1), ('ct.', 1), ('5847', 1), ('breuer', 1), ('full-scale', 1), ('2170', 1), ('pocket-size', 1), ('first-place', 1), ('scolatti', 1), ('ja', 1), ('top-ranking', 1), ('zebek', 1), ('neveh', 1), ('holman', 1), ('gevurtz', 1), ('dorenzo', 1), ('tearle', 1), ('sholom', 1), ('nevah', 1), ('voiture', 1), ('142', 1), ('elks', 1), ('kader', 1), ('silvers', 1), ('6124', 1), ('nlrb', 1), ('1565', 1), ('decertify', 1), ('dalles', 1), ('kiefferm', 1), ('lucy', 1), ('horstman', 1), ('macwhyte', 1), ('riverview', 1), ('forsyth', 1), ('bicycle-auto', 1), ('9329', 1), ('hillsdale', 1), ('mcneil', 1), ('2825', 1), ('bros', 1), ('woodyard', 1), ('getaway', 1), ('lavaughn', 1), ('patterson', 1), ('vice-chairman', 1), ('answerable', 1), ('keizer', 1), ('ennis', 1), ('newly-appointed', 1), ('7082', 1), ('66000', 1), ('58918', 1), ('ga', 1), ('herrington', 1), ('bester', 1), ('tractor-trailer', 1), ('skidding', 1), ('maynor', 1), ('crashes', 1), ('expressways', 1), ('cain', 1), ('north-bound', 1), ('venom', 1), ('infest', 1), ('tift', 1), ('bleckley', 1), ('37679', 1), ('bibb', 1), ('37000', 1), ('heptachlor', 1), ('granular-type', 1), ('low-flying', 1), ('entomologist', 1), ('132000', 1), ('pest', 1), ('fast-spreading', 1), ('employments', 1), ('month-old', 1), ('511', 1), ('nakoma', 1), ('1671', 1), ('subdue', 1), ('assaulting', 1), ('wansley', 1), ('stoll', 1), ('tenn.', 1), ('fergeson', 1), ('odom', 1), ('emma', 1), ('officiating', 1), ('hearn', 1), ('oakland', 1), ('101', 1), ('bessie', 1), ('pittsboro', 1), ('venable', 1), ('357', 1), ('buckhead', 1), ('nonviolent', 1), ('identically', 1), ('first-run', 1), ('lacerations', 1), ('704', 1), ('coleman', 1), ('ponce', 1), ('963', 1), ('olvey', 1), ('rain-slick', 1), ('hammons', 1), ('cir.', 1), ('1688', 1), ('waddell', 1), ('jeopardizing', 1), ('arf', 1), ('armenian', 1), ('bucharest', 1), ('pseudynom', 1), ('dragnet', 1), ('berrellez', 1), ('raymont', 1), ('boatload', 1), ('smuggling', 1), ('ex-marine', 1), ('decreeing', 1), ('southern-central', 1), ('thakhek', 1), ('winthrop', 1), ('full-fledged', 1), ('worsens', 1), ('sopsaisana', 1), ('tiao', 1), ('reconvened', 1), ('no-driving', 1), ('2433', 1), ('commandeering', 1), ('crosswalk', 1), ('belatedly', 1), ('kercheval', 1), ('vernor', 1), ('9230', 1), ('3505', 1), ('furhmann', 1), ('y-teen', 1), ('5155', 1), ('553', 1), ('480', 1), ('door-to-door', 1), ('tareytown', 1), ('2731', 1), ('22111', 1), ('serra', 1), ('2269', 1), ('split-level', 1), ('bernardine', 1), ('darlene', 1), ('ignited', 1), ('2274', 1), ('31730', 1), ('lyle', 1), ('caskets', 1), ('olivet', 1), ('31978', 1), ('viceroy', 1), ('34220', 1), ('hard-hit', 1), ('elsie', 1), ('heideman', 1), ('canvassed', 1), ('sentencing', 1), ('stepson', 1), ('court-appointed', 1), ('2544', 1), ('plee-zing', 1), ('stratton', 1), ('carpentier', 1), ('bookwalter', 1), ('lang', 1), ('skylarking', 1), ('wabash', 1), ('7026', 1), ('buaford', 1), ('maroy', 1), ('jessy', 1), ('5835', 1), ('mardis', 1), ('6934', 1), ('4700', 1), ('connelly', 1), ('jealousies', 1), ('peddlers', 1), ('enmity', 1), ('lighters', 1), ('cigaret', 1), ('nabbed', 1), ('radiomen', 1), ('asdic', 1), ('torpedoes', 1), ('albacore', 1), ('turbines', 1), ('teardrop', 1), ('propelling', 1), ('blabbed', 1), ('symonds', 1), ('paymaster', 1), ('griffith-jones', 1), ('mervin', 1), ('29000', 1), ('klaus', 1), ('baraclough', 1), ('dunlop', 1), ('bookseller', 1), ('kroger', 1), ('shadowy', 1), ('strongrooms', 1), ('whisking', 1), ('london-based', 1), ('still-building', 1), ('johns-manville', 1), ('gas-fired', 1), ('three-story', 1), ('sixty-seven', 1), ('long-life', 1), ('apartment-building', 1), ('102285000', 1), ('278877000', 1), ('253355000', 1), ('ten-month', 1), ('634517000', 1), ('9841000', 1), ('47101000', 1), ('20447000', 1), ('77389000', 1), ('countian', 1), ('swearing-in', 1), ('judgeship', 1), ('sybert', 1), ('ferdinand', 1), ('finan', 1), ('grzesiak', 1), ('shootings', 1), ('first-floor', 1), ('remanding', 1), ('michaelson', 1), ('hagner', 1), ('malone', 1), ('bay-front', 1), ('freezes', 1), ('crews', 1), ('salting', 1), ('piraro', 1), ('paralyzed', 1), ('bertorelli', 1), ('misunderstandings', 1), ('long-time', 1), ('ellwood', 1), ('severna', 1), ('darnell', 1), ('one-room', 1), ('aiken', 1), ('verstandig', 1), ('thug', 1), ('furloughed', 1), ('3325', 1), ('regrettable', 1), ('12.01', 1), ('sequins', 1), ('olive-green', 1), ('reily', 1), ('tulle', 1), ('decolletage', 1), ('filmy', 1), ('eggshell', 1), ('feringa', 1), ('fenwick', 1), ('greenish', 1), ('frock', 1), ('tomato-red', 1), ('maskers', 1), ('ballgowns', 1), ('helene', 1), ('robinsonville', 1), ('leatherman', 1), ('irwin', 1), ('muncipal', 1), ('briar', 1), ('dane', 1), ('honoree', 1), ('carre', 1), ('vieux', 1), ('waveland', 1), ('socola', 1), ('walkers', 1), ('shrove', 1), ('majesties', 1), ('epsilon', 1), ('tulane', 1), ('hayward', 1), ('stella', 1), ('mcgehee', 1), ('nell', 1), ('merner', 1), ('ashman', 1), ('newtown', 1), ('deforest', 1), ('walbridge', 1), ('usn.', 1), ('cmdr.', 1), ('clearwater', 1), ('delray', 1), ('hoaps', 1), ('brelin', 1), ('haaek', 1), ('bietnar', 1), ('dusseldorf', 1), ('dussa', 1), ('ingo', 1), ('lehner', 1), ('heinze', 1), ('brigantine', 1), ('glennon', 1), ('fairless', 1), ('coulson', 1), ('voorhees', 1), ('app', 1), ('rockhall', 1), ('kimbolton', 1), ('ludwick', 1), ('volney', 1), ('sabol', 1), ('kershbaum', 1), ('bregman', 1), ('liss', 1), ('langsdorf', 1), ('kamens', 1), ('zinman', 1), ('korman', 1), ('berton', 1), ('cushman', 1), ('fernberger', 1), ('malmud', 1), ('fund-raiser', 1), ('wissahickon', 1), ('avery', 1), ('loen', 1), ('shahn', 1), ('tyson', 1), ('preview', 1), ('felske', 1), ('cotty', 1), ('sub-zero', 1), ('camping-out', 1), ('lisle', 1), ('mrs', 1), ('wolcott', 1), ('kloman', 1), ('harrity', 1), ('meyle', 1), ('collett', 1), ('natalie', 1), ('baringer', 1), ('cauffman', 1), ('kilhour', 1), ('zeising', 1), ('moller', 1), ('harcourt', 1), ('coles', 1), ('wilkinson', 1), ('pre-fair', 1), ('admittance', 1), ('weinberg', 1), ('kaufnabb', 1), ('lichtenstein', 1), ('loeb', 1), ('newburger', 1), ('kapnek', 1), ('staffing', 1), ('840000', 1), ('fund-raisers', 1), ('blumenthal', 1), ('bernhard', 1), ('hollander', 1), ('globetrotter', 1), ('louchheim', 1), ('lanin', 1), ('gayety', 1), ('gaston', 1), ('8861', 1), ('marcile', 1), ('burgher', 1), ('lovelace', 1), ('lewelleyn', 1), ('headdress', 1), ('floresville', 1), ('fitzhugh', 1), ('2705', 1), ('arlington', 1), ('neumann', 1), ('mceachern', 1), ('groomsmen', 1), ('cecil', 1), ('reeder', 1), ('hinsdale', 1), ('dawson', 1), ('bridesmaids', 1), ('gardenias', 1), ('appliques', 1), ('court-length', 1), ('pabor', 1), ('grahamstown', 1), ('sigma', 1), ('omega', 1), ('tau', 1), ('parmer', 1), ('alton', 1), ('gamma', 1), ('semmes', 1), ('frances', 1), ('mcroberts', 1), ('branum', 1), ('sandra', 1), ('ucla', 1), ('baines', 1), ('7034', 1), ('munger', 1), ('oxnard', 1), ('pressed-paper', 1), ('tab', 1), ('8.50', 1), ('boxwood', 1), ('fast-grossing', 1), ('accommodated', 1), ('vented', 1), ('advertises', 1), ('motel-keeping', 1), ('over-night', 1), ('far-flung', 1), ('souvenir', 1), ('2809', 1), ('motel-keepers', 1), ('sweets', 1), ('denverite', 1), ('mingle', 1), ('relearns', 1), ('pert', 1), ('larimer', 1), ('esther', 1), ('kira', 1), ('welborn', 1), ('sudier', 1), ('neusteter', 1), ('myron', 1), ('willett', 1), ('magarrell', 1), ('hicks', 1), ('dobbins', 1), ('cris', 1), ('carr', 1), ('rollie', 1), ('bernet', 1), ('teter', 1), ('neusteters', 1), ('betsy', 1), ('bassis', 1), ('bassi', 1), ('emilio', 1), ('luise', 1), ('mcdermott', 1), ('brig.', 1), ('merrill', 1), ('plaza', 1), ('manzanola', 1), ('vroman', 1), ('buell', 1), ('mcintosh', 1), ('kittredge', 1), ('sheila', 1), ('luette', 1), ('hackstaff', 1), ('nightly', 1), ('uhles', 1), ('probate', 1), ('pronto', 1), ('fardulli', 1), ('ticker', 1), ('medics', 1), ('dynamo', 1), ('veeck', 1), ('masterful', 1), ('yodel', 1), ('garrulous', 1), ('glib', 1), ('weissmuller', 1), ('frothier', 1), ('hmpf', 1), ('luthuli', 1), ('contaminating', 1), ('khrush', 1), ('jotted', 1), ('brandenburg', 1), ('clashes', 1), ('kriss', 1), ('bernie', 1), ('baseballight', 1), ('genevieve', 1), ('dazzler', 1), ('darlin', 1), ('emcee', 1), ('wackers', 1), ('ex-singer', 1), ('jana', 1), ('frau', 1), ('wacker', 1), ('lenobel', 1), ('hubby', 1), ('annamorena', 1), ('thrush', 1), ('whee', 1), ('screenings', 1), ('exhibitors', 1), ('rackmil', 1), ('melcher', 1), ('producer-hubby', 1), ('gotham', 1), ('kanin', 1), ('havilland', 1), ('olivia', 1), ('solicits', 1), ('7599', 1), ('contribs', 1), ('solicit', 1), ('mag', 1), ('strafaci', 1), ('rosemary', 1), ('universal-international', 1), ('simonelli', 1), ('medico', 1), ('warbling', 1), ('sellout', 1), ('skylark', 1), ('pubs', 1), ('playboy-show-biz', 1), ('arvey', 1), ('manville', 1), ('ainsworth', 1), ('rancho', 1), ('rat-a-tat-tatty', 1), ('winchell', 1), ('crabapple', 1), ('germania', 1), ('masque', 1), ('bal', 1), ('affaire', 1), ('boothby', 1), ('holabird', 1), ('odell', 1), ('profili', 1), ('giacomo', 1), ('translates', 1), ('fiance', 1), ('kankakee', 1), ('rostagnos', 1), ('guglielmo', 1), ('rostagno', 1), ('aldo', 1), ('prentice', 1), ('abra', 1), ('racquet', 1), ('harveys', 1), ('passavant', 1), ('geraghtys', 1), ('beirut', 1), ('manila', 1), ('visa', 1), ('globe-girdling', 1), ('djakarta', 1), ('embassies', 1), ('acclaim', 1), ('tieken', 1), ('presbyterian-st.', 1), ('huzzahs', 1), ('kramer', 1), ('fete', 1), ('stevenses', 1), ('porters', 1), ('robertsons', 1), ('kenilworth', 1), ('bernadine', 1), ('winnetka', 1), ('sulcer', 1), ('belafonte', 1), ('nilsson', 1), ('birgit', 1), ('turandot', 1), ('alsop', 1), ('camilla', 1), ('mont.', 1), ('missoula', 1), ('measles', 1), ('kirkland', 1), ('sarasota', 1), ('wendells', 1), ('barrett', 1), ('deferred', 1), ('well-established', 1), ('7000', 1), ('nominating', 1), ('reelected', 1), ('exaltation', 1), ('resurrection', 1), ('substitutionary', 1), ('diety', 1), ('fundamentalism', 1), ('coliseum', 1), ('heitschmidt', 1), ('piersee', 1), ('steeves', 1), ('culbertson', 1), ('bubenik', 1), ('njust', 1), ('brod', 1), ('huffman', 1), ('salter', 1), ('schrunk', 1), ('nilsen', 1), ('ullman', 1), ('d-ore.', 1), ('a-plate', 1), ('581000', 1), ('washington-oregon', 1), ('bryson', 1), ('emerald', 1), ('reiterating', 1), ('evacuate', 1), ('mears', 1), ('maplecrest', 1), ('1409', 1), ('detriment', 1), ('ritiuality', 1), ('northwestern', 1), ('connall', 1), ('desmond', 1), ('sunay', 1), ('cedvet', 1), ('adnan', 1), ('indecisive', 1), ('cemal', 1), ('secretary-treasurer', 1), ('kas.', 1), ('nitroglycerine', 1), ('severly', 1), ('grovers', 1), ('two-and-a-half-mile', 1), ('walkways', 1), ('vehicular', 1), ('doxiadis', 1), ('constantinos', 1), ('12192865', 1), ('1311', 1), ('300000000', 1), ('redevelopers', 1), ('stansbery', 1), ('hess', 1), ('dannehower', 1), ('norristown', 1), ('gillis', 1), ('lieberman', 1), ('barnet', 1), ('indorsed', 1), ('catchers', 1), ('67000', 1), ('43000', 1), ('115000', 1), ('leary', 1), ('pedigreed', 1), ('councilwoman', 1), ('kaplan', 1), ('457000', 1), ('accomodations', 1), ('multi-family', 1), ('2330000', 1), ('740000', 1), ('172000', 1), ('37500', 1), ('3100', 1), ('2400', 1), ('belanger', 1), ('102', 1), ('indemnity', 1), ('bonding', 1), ('crumlish', 1), ('3646', 1), ('certifying', 1), ('vouchers', 1), ('172400', 1), ('rigging', 1), ('shortcuts', 1), ('impossibly', 1), ('344000', 1), ('frankford', 1), ('house-cleaning', 1), ('imprudently', 1), ('trims', 1), ('arouse', 1), ('raiser', 1), ('inflate', 1), ('consonance', 1), ('ineffectual', 1), ('politicos', 1), ('so-far', 1), ('reconvenes', 1), ('inconsistencies', 1), ('tardiness', 1), ('vexing', 1), ('jimmie', 1), ('stennis', 1), ('eastland', 1), ('sens.', 1), ('functionary', 1), ('loyalist', 1), ('reestablish', 1), ('titular', 1), ('independents', 1), ('redistricting', 1), ('agitating', 1), ('22.50', 1), ('scramble', 1), ('eight-year', 1), ('job-seekers', 1), ('builtin', 1), ('samoa', 1), ('presides', 1), ('edgar', 1), ('suffragettes', 1), ('169', 1), ('seven-stories', 1), ('oath-taking', 1), ('bleacher-type', 1), ('4911', 1), ('karol', 1), ('knecht', 1), ('audrey', 1), ('belleville', 1), ('soule', 1), ('fortier', 1), ('tims', 1), ('times-picayune', 1), ('laotians', 1), ('moune', 1), ('murville', 1), ('couve', 1), ('harriman', 1), ('averell', 1), ('fourteen-nation', 1), ('delegations', 1), ('half-brothers', 1), ('souphanouvong', 1), ('cut-off', 1), ('30000000', 1), ('400000000', 1), ('1000000000', 1), ('expansive', 1), ('jesting', 1), ('proselytizing', 1), ('forswears', 1), ('boyce', 1), ('contract-negotiation', 1), ('26000000', 1), ('clears', 1), ('public-school', 1), ('private-school', 1), ('amending', 1), ('balking', 1), ('moderate-income', 1), ('down-payments', 1), ('forty-year', 1), ('6100000000', 1), ('aid-to-education', 1), ('jockeying', 1), ('southern-republican', 1), ('8555', 1), ('chicanery', 1), ('graft', 1), ('feis', 1), ('sharkey', 1), ('welled', 1), ('retirements', 1), ('tusks', 1), ('expire', 1), ('', 1), ('125000', 1), ('alloted', 1), ('infiltrating', 1), ('piracy', 1), ('tripping', 1), ('puddingstone', 1), ('fire-fighting', 1), ('forestry', 1), ('salvatore', 1), ('freeholder', 1), ('transcended', 1), ('distasteful', 1), ('weldon', 1), ('woodland', 1), ('copeland', 1), ('r-cape', 1), ('rebound', 1), ('republican-controlled', 1), ('inject', 1), ('closeness', 1), ('adminstration', 1), ('lifeblood', 1), ('r-warren', 1), ('r-bergen', 1), ('abatuno', 1), ('sanantonio', 1), ('signers', 1), ('pretenses', 1), ('insurgent', 1), ('spearhead', 1), ('justices', 1), ('fortin', 1), ('grooming', 1), ('toolmaker', 1), ('regrouping', 1), ('dating', 1), ('special-interest', 1), ('appointing', 1), ('offenders', 1), ('ond', 1), ('ot', 1), ('hackett', 1), ('combating', 1), ('fulbright', 1), ('pricking', 1), ('detente', 1), ('detach', 1), ('recommends', 1), ('pleads', 1), ('brandeis', 1), ('thruston', 1), ('blunders', 1), ('amateurish', 1), ('understates', 1), ('gallup', 1), ('confrontations', 1), ('excuses', 1), ('erupts', 1), ('rekindling', 1), ('reiterated', 1), ('enunciate', 1), ('semipublic', 1), ('northernmost', 1), ('rumored', 1), ('conspicious', 1), ('exacerbated', 1), ('colonialist', 1), ('franker', 1), ('ore', 1), ('noes', 1), ('ayes', 1), ('aged-care', 1), ('540', 1), ('stimulatory', 1), ('5.1', 1), ('dentistry', 1), ('prepayment', 1), ('overcrowding', 1), ('outpatient', 1), ('hospital-care', 1), ('paid-for', 1), ('boosts', 1), ('6.5', 1), ('4800', 1), ('14.2', 1), ('subpoenaed', 1), ('miscount', 1), ('wrongful', 1), ('subpenas', 1), ('677', 1), ('pertained', 1), ('midmorning', 1), ('free-for-all', 1), ('all-woman', 1), ('contraptions', 1), ('ceptin', 1), ('shipshape', 1), ('highfield', 1), ('smithtown', 1), (\"mother's\", 1), ('worktable', 1), ('assortment', 1), ('disorderly', 1), ('two-by-fours', 1), ('unload', 1), ('jinny', 1), ('assorted', 1), ('sandpaper', 1), ('doweling', 1), ('babbiting', 1), ('dial', 1), ('lizards', 1), ('blissfully', 1), ('perfectionists', 1), ('fret', 1), ('yelping', 1), ('romping', 1), ('make-ready', 1), ('outfielders', 1), ('goddamit', 1), ('ramming', 1), ('pro-ball', 1), ('team-mate', 1), ('helluva', 1), ('squelched', 1), ('flat-footed', 1), ('haydon', 1), (\"batter's\", 1), ('hefty', 1), ('hander', 1), ('rotten', 1), ('nervously', 1), ('sonny', 1), ('punches', 1), ('relay', 1), ('redheaded', 1), ('smacked', 1), ('overhand', 1), ('malta', 1), ('regretfully', 1), ('encouragingly', 1), ('bobbing', 1), ('signora', 1), ('ello', 1), ('ciao', 1), ('worrying', 1), ('stair', 1), ('wearied', 1), ('sistine', 1), ('drowsily', 1), ('piazza', 1), ('farneses', 1), ('farnese', 1), ('veneto', 1), ('ruins', 1), ('loafed', 1), ('parioli', 1), ('dark-blue', 1), ('tweedy', 1), ('fawn', 1), ('soled', 1), ('dwelt', 1), ('caneli', 1), ('flatter', 1), ('kleenex', 1), ('umm', 1), ('convivial', 1), ('eyelid', 1), ('quitting', 1), ('mailman', 1), ('upshot', 1), ('apprenticeship', 1), ('fluff', 1), ('tooth-paste', 1), ('satirist', 1), ('carver', 1), ('goldsmith', 1), ('hangouts', 1), ('thoreau', 1), ('cezanne', 1), ('retrospective', 1), ('osric', 1), ('iijima', 1), ('hajime', 1), ('enameling', 1), ('photorealism', 1), ('mantegna', 1), ('durer', 1), ('miro', 1), ('modigliani', 1), ('bookshelves', 1), ('velasquez', 1), ('illustrators', 1), ('bolo', 1), ('viyella', 1), ('cashmere', 1), ('illustrator', 1), ('prussian', 1), ('sleepwalker', 1), ('nearsighted', 1), ('fauntleroy', 1), ('haircuts', 1), ('researches', 1), ('rufus', 1), ('ferreted', 1), ('magpie', 1), ('karamazov', 1), ('paperback', 1), (\"jeweler's\", 1), ('six-thirty', 1), ('whichever-the-hell', 1), ('primping', 1), ('unventilated', 1), ('factory-to-you', 1), ('droughts', 1), ('rippled', 1), ('bumps', 1), ('rehearsing', 1), ('spellbound', 1), ('whitewashed', 1), ('dawns', 1), ('chump', 1), ('houdini', 1), ('crates', 1), ('tramp', 1), ('hating', 1), ('starkey', 1), ('parachute', 1), ('yanking', 1), ('burkette', 1), ('toonker', 1), ('mattie', 1), ('overhearing', 1), ('pinging', 1), ('hopscotch', 1), ('bouts', 1), ('streetlight', 1), ('unfrosted', 1), ('ethiopians', 1), ('braving', 1), ('wardroom', 1), ('untruth', 1), ('handcuffs', 1), ('thick-skulled', 1), ('calmness', 1), ('mild-mannered', 1), ('sobbed', 1), ('sentinel', 1), ('ferocious', 1), ('omniscient', 1), ('villainous', 1), ('brig', 1), ('insolently', 1), ('morose', 1), ('questioningly', 1), ('battle-ax', 1), ('souvenirs', 1), ('holystones', 1), ('wild-eyed', 1), ('mutineer', 1), ('cold-bloodedly', 1), ('spoilables', 1), ('aired', 1), ('tarpaulins', 1), ('furled', 1), ('frizzling', 1), ('jellies', 1), ('jams', 1), ('messes', 1), ('chunky', 1), ('spokes', 1), ('despondency', 1), ('sputtered', 1), ('tailgate', 1), ('speared', 1), ('floodheads', 1), ('blurted', 1), ('renewing', 1), ('haggardly', 1), ('thinned', 1), ('frothing', 1), ('jetting', 1), ('hollows', 1), ('slopping', 1), ('pelting', 1), ('conestoga', 1), ('marrowbones', 1), ('boulders', 1), ('funnel', 1), ('limbed', 1), ('puzzlement', 1), ('sharecrop', 1), ('miserably', 1), ('sidewinder', 1), ('laudanum', 1), ('semitrance', 1), ('crudity', 1), ('pathless', 1), ('smolderingly', 1), ('kerchief', 1), ('baleful', 1), ('draught', 1), ('cleansed', 1), ('unlashed', 1), ('played-out', 1), ('balled', 1), ('saliva', 1), ('rivulets', 1), ('hoa-whup', 1), ('goad', 1), ('high-stepped', 1), ('scorched', 1), ('sapped', 1), ('singed', 1), ('stolid', 1), ('once-over-lightly', 1), ('pm', 1), (\"lloyd's\", 1), ('gunk', 1), ('filming', 1), ('antony', 1), ('dichondra', 1), ('spartan', 1), ('swarms', 1), ('doggone', 1), ('itches', 1), ('mmmm', 1), ('dandily', 1), ('upcoming', 1), ('swam', 1), ('longshot', 1), ('cavorted', 1), ('soapsuds', 1), ('repositories', 1), ('peddled', 1), ('swimsuit', 1), ('yelped', 1), ('wobbling', 1), ('disturbingly', 1), ('shrieking', 1), ('froth', 1), ('s-s-sahjunt', 1), ('screech', 1), ('unwire', 1), ('pebble', 1), ('clod', 1), ('splintery', 1), ('aye-yah-ah-ah', 1), ('harmlessly', 1), ('jabs', 1), ('hyphenated', 1), ('bobbed', 1), ('foamed', 1), ('waterproof', 1), ('geysering', 1), ('whitening', 1), ('hovering', 1), ('sideboards', 1), ('gesticulating', 1), ('bueno', 1), ('anteater', 1), ('pearly', 1), ('glassless', 1), ('slivery', 1), ('shin', 1), ('wadded', 1), ('unwired', 1), ('shards', 1), ('re-echo', 1), ('eventshah-leh', 1), ('eventshahleh', 1), ('taos', 1), ('nahce', 1), ('doa', 1), ('behahn', 1), ('ovuh', 1), ('gethuh', 1), ('tole', 1), ('majuh', 1), ('aftuh', 1), ('wohd', 1), ('uttuh', 1), ('fathuh', 1), ('gay-ess', 1), ('aw', 1), ('ansuh', 1), ('coudn', 1), ('nawt', 1), ('whah', 1), ('cai', 1), ('coahse', 1), ('cohnfidunt', 1), ('lite', 1), ('hev', 1), ('vuhranduh', 1), ('dack-rihs', 1), ('wuh', 1), ('academeh', 1), ('foh', 1), ('befoh', 1), ('lahk', 1), ('lah', 1), ('bawhs', 1), ('younguh', 1), ('smilingly', 1), ('co-cola', 1), ('howsabout', 1), ('kittenish', 1), ('overhaul', 1), ('ee-faket', 1), ('wahtahm', 1), ('wonduh', 1), ('hi-im', 1), ('diffrunce', 1), ('didn', 1), ('alreadeh', 1), ('rewt', 1), ('suhthuhn', 1), ('prefuh', 1), ('maht', 1), ('husbun', 1), ('jawn', 1), ('nawth', 1), ('ahm', 1), ('thiihng', 1), ('drahve', 1), ('darkhaired', 1), ('gunner', 1), ('yoorick', 1), ('sahjunt', 1), ('thumbed', 1), ('listlessly', 1), ('sweltering', 1), ('foregone', 1), ('yucca', 1), ('sagebrush', 1), ('perfumed', 1), ('tinted', 1), ('textured', 1), ('delicately', 1), ('enviably', 1), ('brushcut', 1), ('counterpointing', 1), ('mor-ee-air-teeeee', 1), ('emergent', 1), ('thumbing', 1), ('tootley-toot-tootled', 1), ('cravated', 1), ('conservatively', 1), ('shirted', 1), ('whizzed', 1), ('gauche', 1), ('chuffing', 1), ('mustering', 1), ('whispers', 1), ('gears', 1), ('fenders', 1), ('vertigo', 1), ('rudder', 1), ('cowling', 1), ('jap', 1), ('etched', 1), ('half-gainer', 1), ('closure', 1), ('break-away', 1), ('pinpoints', 1), ('airspeed', 1), ('deviating', 1), ('firepower', 1), ('maneuverability', 1), ('tactically', 1), ('specks', 1), ('bogies', 1), ('glide-bombed', 1), ('earphones', 1), ('cliffs', 1), ('claustrophobia', 1), ('hundred-and-eighty', 1), ('punched', 1), ('a-26', 1), ('samar', 1), ('shivered', 1), ('chocks', 1), ('taxied', 1), ('prearranged', 1), ('trade-mark', 1), ('carabao', 1), ('seton', 1), ('straps', 1), ('check-out', 1), ('revetments', 1), ('kamikaze', 1), ('cagayan', 1), ('mindanao', 1), ('shirtsleeve', 1), ('remounting', 1), ('unmolested', 1), ('besieging', 1), ('clap', 1), ('canter', 1), ('stober', 1), ('dismayed', 1), ('tartly', 1), ('glowering', 1), ('disdainful', 1), ('ridding', 1), ('pants-legs', 1), ('cowpuncher', 1), ('golly', 1), ('cache', 1), ('wads', 1), ('sweatband', 1), ('half-a-dozen', 1), ('grunting', 1), ('groan', 1), ('reeling', 1), ('jab', 1), ('nimbly', 1), ('upraised', 1), ('ell', 1), ('alertly', 1), ('barkeep', 1), ('yuh', 1), ('dozed', 1), ('revelry', 1), ('tersely', 1), ('muffling', 1), ('bowstring', 1), ('dodged', 1), ('perfunctorily', 1), ('batwings', 1), ('canyonside', 1), ('ornate', 1), ('doggedly', 1), ('plummeting', 1), ('ganado', 1), ('holdin', 1), ('busier', 1), ('worriedly', 1), ('halter', 1), ('shirtfront', 1), ('crowbait', 1), ('sneaks', 1), ('gunslinger', 1), ('outdrew', 1), ('drawin', 1), ('claw', 1), ('swarthy', 1), ('gunbarrel', 1), ('two-by-four', 1), ('trigger-happy', 1), ('gruller', 1), ('squeal', 1), ('snuffed', 1), ('dun', 1), ('sway-backed', 1), ('hoof', 1), ('unfastened', 1), ('haystack', 1), ('inkling', 1), ('moistened', 1), ('re-entered', 1), ('minstrels', 1), ('waging', 1), ('rodeos', 1), ('roundups', 1), ('cowhand', 1), ('bosler', 1), ('coble', 1), ('substantiate', 1), ('explosively', 1), ('pastures', 1), ('fallow', 1), ('half-heartedly', 1), ('killin', 1), ('lettin', 1), ('wrappin', 1), ('skulls', 1), ('spread-eagled', 1), ('apache', 1), ('sunburnt', 1), ('dry-gulchin', 1), ('scairt', 1), ('swingin', 1), (\"s'posin\", 1), ('rodeo', 1), ('straight-out', 1), ('rustlers', 1), ('bushwhacked', 1), ('exterminatin', 1), ('lawmen', 1), ('lashed', 1), ('harnessing', 1), ('haying', 1), ('hisself', 1), ('foreclosed', 1), ('soddies', 1), ('raided', 1), ('natrona', 1), (\"stockgrowers'\", 1), ('inquest', 1), ('.30-30', 1), ('ghostlike', 1), ('bushwhackin', 1), ('far-off', 1), ('shootin', 1), ('puff', 1), ('all-knowing', 1), ('ansley', 1), ('oaken', 1), ('garbed', 1), ('scarecrowish', 1), ('padlocked', 1), ('unlock', 1), ('balked', 1), ('padlock', 1), ('strap', 1), ('banded', 1), ('resignedly', 1), ('beaded', 1), ('pallor', 1), ('toter', 1), ('lawman', 1), ('claps', 1), ('sluicing', 1), ('corduroy', 1), ('gunplay', 1), ('cantles', 1), ('slickers', 1), ('glum', 1), ('vaquero', 1), ('maguires', 1), ('nagged', 1), ('cookfire', 1), ('mules', 1), ('readying', 1), ('mateo', 1), ('listless', 1), ('coosie', 1), ('remuda', 1), ('offsaddled', 1), ('laredo', 1), ('amado', 1), ('bedground', 1), ('hondo', 1), ('hoots', 1), ('maddened', 1), ('stinging', 1), ('scot-free', 1), ('unpunished', 1), ('willful', 1), ('uppercut', 1), ('volition', 1), ('storefront', 1), ('huh-uh', 1), ('knuckled', 1), ('oil-field', 1), ('well-nigh', 1), ('respite', 1), ('workin', 1), ('swindled', 1), ('reddened', 1), ('see-lective', 1), ('accosting', 1), ('coiling', 1), ('tunelessly', 1), ('mudguard', 1), ('lakewood', 1), ('maddening', 1), ('teased', 1), ('tantrum', 1), ('baited', 1), ('shrug', 1), ('anyways', 1), ('wildcatter', 1), ('derrick', 1), ('looky', 1), ('rattler', 1), ('danged', 1), ('probl', 1), ('howsomever', 1), ('seein', 1), ('drawled', 1), ('walkin', 1), ('clowning', 1), ('yokels', 1), ('wearer', 1), ('handsomer', 1), ('contemptible', 1), ('god-forsaken', 1), ('limitless', 1), ('yearningly', 1), ('teensy', 1), ('ommission', 1), ('levis', 1), ('permian', 1), ('absorber', 1), ('handmade', 1), ('mournfully', 1), ('aah', 1), ('cipher', 1), ('checkin', 1), ('pleasin', 1), ('brainy', 1), ('agreeably', 1), ('up-pp', 1), ('shu-tt', 1), ('pooched', 1), ('idiotically', 1), ('sweetest', 1), ('a-tall', 1), ('demontez', 1), ('click', 1), ('unlacing', 1), ('vetoed', 1), ('ackerly', 1), ('readjustment', 1), ('grappled', 1), ('foolproof', 1), ('distastefully', 1), ('fifty-piece', 1), ('skepticism', 1), ('double-crossed', 1), ('refinance', 1), ('79.89', 1), ('velour', 1), ('jiffy-couch-a-bed', 1), ('salesgirl', 1), ('bilingual', 1), ('ubiquitous', 1), ('espanol', 1), ('habla', 1), ('mart', 1), ('quintana', 1), ('urbano', 1), ('doughnuttery', 1), ('squinted', 1), ('pro-tem', 1), ('ulcerated', 1), ('pencil-pusher', 1), ('mid-watch', 1), ('comportment', 1), ('playback', 1), ('loren', 1), ('balling', 1), ('insubordination', 1), ('nasaled', 1), ('negligent', 1), ('trapdoor', 1), ('law-enforcement', 1), ('purportedly', 1), ('after-hours', 1), ('extralegal', 1), ('frequented', 1), ('arrogate', 1), (\"inspector's\", 1), ('sergeants', 1), ('absented', 1), ('drunk-and-disorderlies', 1), ('single-spaced', 1), ('squadroom', 1), ('beady', 1), ('wordlessly', 1), ('kneecap', 1), ('shinbone', 1), ('seepage', 1), ('stiff-backed', 1), ('washbowl', 1), ('thatches', 1), ('raked', 1), ('pomaded', 1), ('combing', 1), ('lieut', 1), ('envelopes', 1), ('fumed-oak', 1), ('scarred', 1), ('incursion', 1), ('untoward', 1), ('thirty-seven', 1), (\"policemen's\", 1), ('unsold', 1), ('unused', 1), ('buoyed', 1), ('arleigh', 1), ('retch', 1), ('lurching', 1), ('nakedly', 1), ('aromas', 1), ('facades', 1), ('guardia', 1), ('bulked', 1), ('copings', 1), ('drapes', 1), ('leaded', 1), ('sari', 1), ('muddleheaded', 1), ('p.m', 1), ('crocked', 1), ('hideously', 1), ('bonfiglio', 1), ('uncertainly', 1), ('recollected', 1), ('swallows', 1), ('placating', 1), ('encased', 1), ('red-rimmed', 1), ('undersecretary', 1), ('wrought-iron', 1), ('stock-market', 1), ('dunston', 1), ('unremarkable', 1), ('ten-thousand-dollar', 1), ('deepened', 1), ('faucet', 1), ('pecks', 1), ('great-nieces', 1), ('bequests', 1), ('pompousness', 1), ('wills', 1), ('disliking', 1), ('jaycee', 1), ('youngish', 1), ('haircut', 1), ('thrombosis', 1), ('cavities', 1), ('scrapings', 1), ('hemorrhages', 1), ('suffocation', 1), ('adulation', 1), ('uninvited', 1), ('reprehensible', 1), ('chaise', 1), ('piteous', 1), ('talkative', 1), ('lars', 1), ('corrode', 1), ('eliminations', 1), ('unreasoning', 1), ('punishes', 1), ('ambushes', 1), ('hunches', 1), ('scuffle', 1), ('uprising', 1), ('birdwood', 1), ('livingston', 1), ('hathaway', 1), ('norths', 1), ('ridgefield', 1), ('dribbled', 1), ('vitus', 1), ('collapsible', 1), ('ocelot', 1), ('bellhops', 1), ('telescopic', 1), ('fifty-four', 1), ('paynes', 1), ('airless', 1), ('icicle', 1), ('chomp', 1), ('snivelings', 1), ('jerkings', 1), ('morosely', 1), ('uprooted', 1), ('staginess', 1), ('molesting', 1), ('recreating', 1), ('prodding', 1), ('yelp', 1), ('shark', 1), ('pleats', 1), ('slimmer', 1), ('sneaking', 1), ('limped', 1), ('limps', 1), ('scraggly', 1), ('penciled', 1), ('serenely', 1), ('acapulco', 1), ('urgings', 1), ('kettle', 1), ('worksheet', 1), ('racking', 1), ('undisguised', 1), ('one-thousandth', 1), ('no-goal', 1), ('progressing', 1), ('fifty-five', 1), ('enormity', 1), ('unheeding', 1), ('blustery', 1), ('massaging', 1), ('telephone-booth', 1), ('stinking', 1), ('confidant', 1), ('schoolgirl', 1), ('cobbler', 1), ('satirically', 1), ('brad', 1), ('dusky', 1), ('rafters', 1), ('hams', 1), ('storeroom', 1), ('emptier', 1), ('doled', 1), ('curtly', 1), ('armoire', 1), ('moire', 1), ('unpleasantly', 1), ('unprocurable', 1), ('rilly', 1), ('undrinkable', 1), ('paterollers', 1), ('floes', 1), ('hiked', 1), ('carters', 1), ('vet', 1), ('spoil', 1), ('despues', 1), ('sigue', 1), ('que', 1), ('abyssinians', 1), ('daintily', 1), ('bast', 1), ('propped', 1), ('alison', 1), ('mendoza', 1), ('roslev', 1), ('superstitious', 1), ('bouvardier', 1), ('paternally', 1), ('underling', 1), ('distractedly', 1), ('worryin', 1), ('hangin', 1), ('acourse', 1), ('trustworthy', 1), ('determinate', 1), ('admiralty', 1), ('nationalize', 1), ('reshaped', 1), ('servanda', 1), ('sunt', 1), ('pacta', 1), ('anzilotti', 1), ('touchstone', 1), ('clog', 1), ('abrogated', 1), ('bourgeoisie', 1), ('emanation', 1), ('judiciary', 1), ('jellinek', 1), ('jurisprudentially', 1), ('unifications', 1), ('transcending', 1), ('unconnected', 1), ('conceptually', 1), ('ineffectively', 1), ('misconstruction', 1), ('civilizations', 1), ('europeanization', 1), ('napoleonic', 1), ('europeanized', 1), ('alignments', 1), ('opportunistic', 1), ('legislate', 1), ('disproving', 1), ('gratuitously', 1), ('exacerbates', 1), ('acceded', 1), ('encompassed', 1), ('behaves', 1), ('expository', 1), ('aptitudes', 1), ('heighten', 1), ('enrollees', 1), ('estimating', 1), ('preemployment', 1), ('semi-skilled', 1), ('740', 1), ('297', 1), ('retraining', 1), ('fiftieth', 1), ('alphabetized', 1), ('operationally', 1), ('unachievable', 1), ('lexicostatistic', 1), ('predilections', 1), ('lees', 1), ('glottochronology', 1), ('day-by-day', 1), ('anciently', 1), ('evidential', 1), ('salish', 1), ('diagrammed', 1), ('phyla', 1), ('penutian', 1), ('hokan', 1), ('kingdoms', 1), ('coalescence', 1), ('ramification', 1), ('indubitable', 1), ('cocopalm', 1), ('swan', 1), ('definable', 1), ('labile', 1), ('linguistically', 1), ('snare', 1), ('expectable', 1), ('retentiveness', 1), ('unasterisked', 1), ('weighting', 1), ('classificatory', 1), ('diachronic', 1), ('yok', 1), ('ath.', 1), ('m-k', 1), ('unvarying', 1), ('unpredictably', 1), ('137', 1), ('ijal', 1), ('mon-khmer', 1), ('eventuate', 1), ('lingually', 1), ('trans', 1), ('consistence', 1), ('durability', 1), ('2.8', 1), ('3.4', 1), ('4.0', 1), ('4.7', 1), ('3.9', 1), ('2.7', 1), ('253', 1), ('proportionally', 1), ('demonstratives', 1), ('interrogatives', 1), ('manzanita', 1), ('salmon', 1), ('genera', 1), ('omit', 1), ('joaquin', 1), ('informants', 1), ('unambiguity', 1), ('diverging', 1), ('stopping-point', 1), ('jointed', 1), ('item-categories', 1), ('whiteley', 1), ('prosodic', 1), ('prosodies', 1), ('restates', 1), ('carnochan', 1), ('hesitates', 1), ('superficiality', 1), ('examines', 1), ('vowel-length', 1), ('typographic', 1), ('abstrusenesses', 1), ('broadest', 1), ('transcription', 1), ('grammatically', 1), ('confusing', 1), ('multidimensional', 1), ('morphemic', 1), ('sukuma', 1), ('ewe', 1), ('accentual', 1), ('glottal', 1), ('intermeshed', 1), ('rowlands', 1), ('articulations', 1), ('co-occurring', 1), ('knowledgeable', 1), ('uninitiate', 1), ('divert', 1), ('welmers', 1), ('analytically', 1), ('equip', 1), ('familar', 1), ('over-simple', 1), ('monosyllable', 1), ('ity', 1), ('suffix', 1), ('vocalic', 1), ('syntactically', 1), ('steiners', 1), ('noun', 1), ('adverb', 1), ('martinique', 1), ('silliest', 1), ('declarative', 1), ('italics', 1), ('italicized', 1), ('accompanies', 1), ('adjuncts', 1), ('adverbial', 1), ('friendlier', 1), ('syntactic', 1), ('fy', 1), ('boylston', 1), ('summarizing', 1), ('summarization', 1), ('inflection', 1), ('paradigms', 1), ('outputting', 1), ('y-regions', 1), ('pre-determined', 1), ('y-cells', 1), ('target-language', 1), ('sentence-structure', 1), ('compile', 1), ('alphabetic', 1), ('data-processing', 1), ('voume', 1), ('suffixes', 1), ('prefixes', 1), ('docked', 1), ('tangibly', 1), ('expounding', 1), ('simile', 1), ('peeking', 1), ('surreptitiously', 1), ('intrusive', 1), ('philosophizing', 1), ('prototypical', 1), ('mcghie', 1), ('cameron', 1), ('intimating', 1), ('mulling', 1), ('belching', 1), ('scorned', 1), ('dedifferentiated', 1), ('undifferentiated', 1), ('dearie', 1), ('delineated', 1), ('indistinct', 1), ('babel', 1), ('grooved', 1), ('spread-out', 1), ('terse', 1), ('vociferous', 1), ('arrogantly', 1), ('succor', 1), ('consoling', 1), ('personifying', 1), ('steoreotyped', 1), ('manifesting', 1), ('seclude', 1), ('vocalize', 1), ('passerby', 1), ('introjects', 1), ('introjected', 1), ('unmanageably', 1), ('disconcertingly', 1), ('despises', 1), ('condemnatory', 1), ('scathingly', 1), ('day-after-day', 1), ('demarcated', 1), ('wracking', 1), ('axiom', 1), ('timeworn', 1), ('parroting', 1), ('parrotlike', 1), ('veridical', 1), ('totalistic', 1), ('evaluative', 1), ('graphed', 1), ('roleplayed', 1), ('condensing', 1), ('tailor-make', 1), ('abruptness', 1), ('curtness', 1), ('supermarket', 1), ('diagnosing', 1), ('criticizing', 1), ('antagonize', 1), ('comer', 1), ('supplanting', 1), ('aplomb', 1), ('mousy', 1), ('clerking', 1), ('hesitating', 1), ('questionnaires', 1), ('resignations', 1), ('possiblities', 1), ('subparts', 1), ('disadvantage', 1), ('replication', 1), ('sarason', 1), ('panicked', 1), ('memorizing', 1), ('memorization', 1), ('.01', 1), ('accentuates', 1), ('phonic', 1), ('systemization', 1), ('whole-word', 1), ('sub-group', 1), ('3.0', 1), ('over-achievement', 1), ('4.8', 1), ('wechsler', 1), ('median', 1), ('sub-tests', 1), ('stanford', 1), ('permeates', 1), ('obsessive-compulsive', 1), ('.04', 1), ('validation', 1), ('differentiating', 1), ('multiphastic', 1), ('cleans', 1), ('emotionality', 1), ('behaviors', 1), ('categorizing', 1), ('perusing', 1), ('interviewers', 1), ('punctuality', 1), ('orderliness', 1), ('perfectionism', 1), ('multiple-choice', 1), ('open-ended', 1), ('under-achievers', 1), ('underachievers', 1), ('upper-lower', 1), ('upper-middle', 1), ('w-2', 1), ('720', 1), ('devisee', 1), ('legatee', 1), ('reimburses', 1), ('royalties', 1), ('refunds', 1), ('refunded', 1), ('elapses', 1), ('uncertified', 1), ('remitted', 1), ('2688', 1), ('1310', 1), ('waived', 1), ('air-to-surface', 1), ('equipping', 1), ('b-58', 1), ('turbofan', 1), ('air-frame', 1), ('reinforcement', 1), ('underscore', 1), ('curtailed', 1), ('interceptor', 1), ('surfaced', 1), ('aerodynamic', 1), ('overtaken', 1), ('redirect', 1), ('reevaluation', 1), ('break-through', 1), ('obsolescent', 1), ('reenact', 1), ('581', 1), ('3825', 1), ('1390', 1), ('4753', 1), ('obligational', 1), ('19.3', 1), ('transactions', 1), ('365', 1), ('601', 1), ('184', 1), ('94', 1), ('dependents', 1), ('longevity', 1), ('12.1', 1), ('270000', 1), ('360000', 1), ('400000', 1), ('reexamine', 1), ('825000', 1), ('91', 1), ('175000', 1), ('619000', 1), ('817', 1), ('870000', 1), ('2489000', 1), ('year-end', 1), ('contending', 1), ('hounds', 1), ('public-opinion', 1), ('undigested', 1), ('desks', 1), ('multilateral', 1), ('inflammation', 1), ('imperceptibly', 1), ('merges', 1), ('guidelines', 1), ('merciful', 1), ('underlies', 1), ('appreciative', 1), ('explores', 1), ('departmental', 1), ('remedial', 1), ('affliction', 1), ('inadvertence', 1), ('interdepartmental', 1), ('objectors', 1), ('intradepartmental', 1), ('thereon', 1), ('evensen', 1), ('tecum', 1), ('duces', 1), ('subpoena', 1), ('contentions', 1), ('413', 1), ('327', 1), ('estep', 1), ('renders', 1), ('attributing', 1), ('concurred', 1), ('veracity', 1), ('385', 1), ('sicurella', 1), ('reopened', 1), ('reclassification', 1), ('.1', 1), ('899', 1), ('certiorari', 1), ('613', 1), ('269', 1), ('462', 1), ('app.', 1), ('622', 1), ('604', 1), ('rosenberg', 1), ('wilkey', 1), ('friedman', 1), ('covington', 1), ('depose', 1), ('unreality', 1), ('enthrone', 1), ('asserts', 1), ('525', 1), ('362', 1), ('pronouncement', 1), ('confidentiality', 1), ('endanger', 1), ('unnourished', 1), ('quirk', 1), ('disenfranchised', 1), ('depress', 1), ('alia', 1), ('counterproposal', 1), ('2.09', 1), ('taxpaying', 1), ('63000000', 1), ('antitrust', 1), ('deeming', 1), ('pont-general', 1), ('pretrial', 1), ('608', 1), ('401', 1), ('392', 1), ('332', 1), ('endangered', 1), ('pre-eminent', 1), ('589', 1), ('monopolization', 1), ('proscribe', 1), ('.235', 1), ('supp', 1), ('606', 1), ('outstripping', 1), ('climates', 1), ('advisable', 1), ('blowers', 1), ('decays', 1), ('tornado', 1), ('milliampere', 1), ('low-level', 1), ('scatters', 1), ('right-angle', 1), ('pre-cast', 1), ('waterproofing', 1), ('overlaid', 1), ('aboveground', 1), ('inset', 1), ('mortaring', 1), ('reductions', 1), ('recouped', 1), ('5.4865771', 1), ('computations', 1), ('disruption', 1), ('vocationally', 1), ('traineeships', 1), ('homebound', 1), ('remunerative', 1), ('rehabilitating', 1), ('backlog', 1), ('gainful', 1), ('236', 1), ('foodstuffs', 1), ('contraband', 1), ('confiscated', 1), ('shangri-la', 1), ('americas', 1), ('cockier', 1), ('migs', 1), ('strafing', 1), ('mig', 1), ('heartiest', 1), ('emeritus', 1), ('two-way', 1), ('advocated', 1), ('on-again-off-again', 1), ('southbound', 1), ('b.+o.', 1), ('c.+o.', 1), ('47.6', 1), ('commutation', 1), ('implemented', 1), ('discontinuance', 1), ('adjudication', 1), ('ratable', 1), ('17000000', 1), ('disbursed', 1), ('states-yugoslav', 1), ('submissions', 1), ('provisons', 1), ('deferring', 1), ('mandamus', 1), ('therefor', 1), ('misdemeanor', 1), ('unlawful', 1), ('deducting', 1), ('apportion', 1), ('1001', 1), ('d-c', 1), ('matrix', 1), ('dissemination', 1), ('indexing', 1), ('astrophysics', 1), ('astin', 1), ('herzfeld', 1), ('wildhack', 1), ('logarithm', 1), ('intermolecular', 1), ('integrals', 1), ('prandtl', 1), ('atm', 1), ('electrically', 1), ('capacitance', 1), ('displaces', 1), ('unbalance', 1), ('hydrostatic', 1), ('dewars', 1), ('reproducibilities', 1), ('2.16', 1), ('4.21', 1), ('calibrations', 1), ('resistances', 1), ('cycled', 1), ('thermally', 1), ('doped', 1), ('2.1', 1), ('thermometric', 1), ('acoustical', 1), ('144', 1), ('0.10', 1), ('1667.36', 1), ('1665.32', 1), ('low-frequency', 1), ('foreknowledge', 1), ('bandwidth', 1), ('telescopes', 1), ('sch', 1), ('sih', 1), ('aperture', 1), ('blackening', 1), ('edgerton', 1), ('ohmic', 1), ('calorimetric', 1), ('beryllium', 1), ('substantiates', 1), ('non-volatile', 1), ('fluorine', 1), ('3500000', 1), ('4000000', 1), ('assay', 1), ('bidder', 1), ('1967', 1), ('75000000', 1), ('dispositions', 1), ('thereunder', 1), ('deprive', 1), ('cosponsored', 1), ('on-site', 1), ('bibliographical', 1), ('subsections', 1), ('mineralized', 1), ('328', 1), ('caveat', 1), ('empedocles', 1), ('unfit', 1), ('tragedians', 1), ('plundering', 1), ('coleridge', 1), ('dialogues', 1), ('montaigne', 1), ('plutarch', 1), ('familarity', 1), ('enlightenment', 1), ('reformation', 1), ('ipso', 1), ('re-thinking', 1), ('rethink', 1), ('conceptual', 1), ('thematic', 1), ('sonnet', 1), ('aurelius', 1), ('invictus', 1), ('syndrome', 1), ('atypical', 1), ('estranging', 1), ('unplumbed', 1), ('plumed', 1), ('thunder-purple', 1), ('literatures', 1), ('perfectibility', 1), ('sensuous', 1), ('immediacies', 1), ('interpenetrate', 1), ('stylistic', 1), ('confine', 1), ('inexhaustible', 1), ('colour', 1), ('cavemen', 1), ('titian', 1), ('cimabue', 1), ('chaucer', 1), ('picture-palace', 1), ('music-hall', 1), ('anaesthesia', 1), ('shallowness', 1), ('triviality', 1), ('obverse', 1), ('transcultural', 1), ('asch', 1), ('researchable', 1), ('subtlety', 1), ('legitimized', 1), ('undereducated', 1), ('spinley', 1), ('imaginatively', 1), ('mastering', 1), ('fireman', 1), ('devious', 1), ('stratagem', 1), ('tensional', 1), ('reconciling', 1), ('compounding', 1), ('cleanth', 1), ('wimsatt', 1), ('earth-bound', 1), ('enriched', 1), ('ineffable', 1), ('deflated', 1), ('northrop', 1), ('beautify', 1), ('housman', 1), ('beardsley', 1), ('purging', 1), ('aristotelian', 1), ('cognate', 1), ('seldes', 1), ('prurient', 1), ('pre-literate', 1), ('psychotherapeutic', 1), ('buber', 1), ('ranyard', 1), ('flugel', 1), ('idiosyncratic', 1), ('fromm', 1), ('hallelujahs', 1), ('judgement', 1), ('folk-music', 1), ('characterizes', 1), ('negroid', 1), ('jot', 1), ('retentive', 1), ('absentia', 1), ('colloquial', 1), ('puckish', 1), ('creepers', 1), ('jeepers', 1), ('dervish', 1), ('tenderfoot', 1), ('hooray', 1), ('woodin', 1), ('donaldson', 1), ('heusen', 1), ('ziggy', 1), ('benny', 1), ('relyriced', 1), ('hoagy', 1), ('li', 1), ('misplacing', 1), ('mercers', 1), ('meehan', 1), ('stellar', 1), ('gershwin', 1), ('ira', 1), ('holloway', 1), ('guild', 1), ('malfeasant', 1), ('imprint', 1), ('aspiring', 1), ('apocryphal', 1), ('washbasin', 1), ('walk-up', 1), ('hearted', 1), ('entertainer', 1), ('encumbrances', 1), ('half-brother', 1), ('expressivness', 1), ('gullah', 1), ('playmates', 1), ('jazzy', 1), ('woodberry', 1), ('evidencing', 1), ('jasper', 1), ('1747', 1), ('emigrated', 1), ('tug-of-war', 1), ('mouthed', 1), ('bracken', 1), ('craze', 1), ('bobby-soxer', 1), ('lobl', 1), ('suitors', 1), ('lovering', 1), ('laurie', 1), ('prettiest', 1), ('movingly', 1), ('andromache', 1), ('recited', 1), ('guthrie', 1), ('musicale', 1), ('soiree', 1), ('dummkopf', 1), ('schoolmarm', 1), ('personages', 1), ('incapacitated', 1), ('rheumatic', 1), ('confidante', 1), ('hoydenish', 1), ('sophie', 1), ('marmee', 1), ('alcott', 1), ('louisa', 1), ('lombard', 1), ('corbin', 1), ('familiarly', 1), ('promulgated', 1), ('sulamith', 1), ('shalom', 1), ('rodeph', 1), ('temerity', 1), ('racie', 1), ('chignon', 1), ('eclipsed', 1), ('patronize', 1), ('dazzle', 1), ('punster', 1), ('round-faced', 1), ('assyriology', 1), ('mothered', 1), ('disciple', 1), ('hanukkah', 1), ('maccabeus', 1), ('judas', 1), ('oratorio', 1), ('anglo', 1), ('biographical', 1), ('overstraining', 1), ('avenge', 1), ('overconfident', 1), ('importunities', 1), ('unwomanly', 1), ('exasperating', 1), ('exacted', 1), ('demander', 1), ('giver', 1), ('sulamite', 1), ('contemplates', 1), ('tall-tale', 1), ('hardscrabble', 1), ('abounded', 1), ('subtler', 1), ('unmalicious', 1), ('lovingood', 1), ('sut', 1), ('habitually', 1), ('sharpness', 1), ('suggs', 1), ('bee-hunter', 1), ('unliterary', 1), ('horse-trading', 1), ('sniffle', 1), ('ransy', 1), ('baldwin', 1), ('emanating', 1), ('vivify', 1), ('elizabethans', 1), ('robustness', 1), ('realist', 1), ('gilmore', 1), ('indelicate', 1), ('addison', 1), ('narratives', 1), ('lubberlanders', 1), ('1728', 1), ('glasgow', 1), ('dynasties', 1), ('tangential', 1), ('sentimentalize', 1), ('best-selling', 1), ('idealization', 1), ('meriwether', 1), ('swallow-barn', 1), ('deviated', 1), ('testifies', 1), ('novelists', 1), ('stream-of-consciousness', 1), ('symbolists', 1), ('romancers', 1), ('gothic', 1), ('orally', 1), ('regimentation', 1), ('intolerance', 1), ('unquestioningly', 1), ('apologist', 1), ('hoffman', 1), ('moralist', 1), ('untraditional', 1), ('crassness', 1), ('commercialism', 1), ('barn-burner', 1), ('disintegrating', 1), ('sutpen', 1), ('nathaniel', 1), ('besets', 1), ('stimulations', 1), ('stereotypes', 1), ('beplastered', 1), ('winnow', 1), ('barnsful', 1), ('vaccine', 1), ('polio', 1), ('salk', 1), ('worthless', 1), ('deprecatory', 1), ('434', 1), ('vol.', 1), ('deutsch', 1), ('eminently', 1), ('stepchild', 1), ('ogress', 1), ('steprelationship', 1), ('surfeit', 1), ('consigned', 1), ('sociologists', 1), ('biologists', 1), ('half-moons', 1), ('tell-tale', 1), ('overworked', 1), ('short-story', 1), ('unchangeable', 1), ('leopard', 1), ('californians', 1), ('palomar', 1), ('resifted', 1), ('prefaced', 1), ('besmirching', 1), ('cold-blooded', 1), ('inquisitor-general', 1), ('torquemada', 1), ('non-jew', 1), ('abhorrent', 1), ('misrepresentation', 1), ('fiendish', 1), ('crafty', 1), ('shylockian', 1), ('aberrant', 1), ('tikopia', 1), ('scotchman', 1), ('216', 1), ('griston', 1), ('1558', 1), ('pecorone', 1), ('first-hand', 1), ('market-place', 1), ('1655', 1), ('1290', 1), ('scour', 1), ('einsteinian', 1), ('pilfering', 1), ('inmate', 1), ('salable', 1), ('repress', 1), ('demagogues', 1), ('traitorous', 1), ('pilloried', 1), ('burleson', 1), ('irrationally', 1), ('self-locking', 1), ('pin-curl', 1), ('abler', 1), ('disagreements', 1), ('legacies', 1), ('accruing', 1), ('short-range', 1), ('unluckily', 1), ('sham', 1), ('pretense', 1), ('capitalistic', 1), ('set-up', 1), ('ballyhoo', 1), ('milquetoast', 1), ('contrive', 1), ('entrepreneurs', 1), ('montage', 1), ('reading-rooms', 1), ('overrode', 1), ('porgy', 1), ('steppes', 1), ('cutting-edge', 1), ('counter-offensive', 1), ('augment', 1), ('amplify', 1), ('sedentary', 1), ('determinable', 1), ('cancers', 1), ('panoramic', 1), ('secularist', 1), ('preface', 1), ('shibboleth', 1), ('incantation', 1), ('forefathers', 1), ('evangelist', 1), ('columnists', 1), ('preferment', 1), ('gyrations', 1), ('assailing', 1), ('nascent', 1), ('clamorous', 1), ('assiduity', 1), ('disillusionment', 1), ('enforceable', 1), ('containment', 1), ('undeclared', 1), ('exemplar', 1), ('classless', 1), ('rousseauan', 1), ('voegelin', 1), ('heresy', 1), ('newcastle', 1), ('locke', 1), ('gatsby', 1), ('face-lifting', 1), ('industrialism', 1), ('charisma', 1), ('mythic', 1), ('reposed', 1), ('scrapped', 1), ('utopianism', 1), ('naturalism', 1), ('millenarianism', 1), ('incipience', 1), ('generalist', 1), ('contrasted', 1), ('andean', 1), ('montmorillonites', 1), ('crystallography', 1), ('mineralogy', 1), ('geochemistry', 1), ('finns', 1), ('bottlenecks', 1), ('channeled', 1), ('55987', 1), ('indoctrinating', 1), ('combinable', 1), ('projectiles', 1), ('target-hunting', 1), ('hookup', 1), ('monitored', 1), ('theorists', 1), ('distresses', 1), ('distortable', 1), ('arable', 1), ('configuration', 1), ('half-life', 1), ('1225', 1), ('intonations', 1), ('complimentary', 1), ('inadequately', 1), ('timepiece', 1), ('enumerated', 1), ('pleases', 1), ('spillane', 1), ('exonerate', 1), ('cramer', 1), ('burger', 1), ('adventurers', 1), ('joins', 1), ('ambler', 1), ('thrillers', 1), ('despised', 1), ('demi-monde', 1), ('outcast', 1), ('self-imposed', 1), ('descendents', 1), ('sayers', 1), ('christie', 1), ('agatha', 1), ('whimsey', 1), ('hercule', 1), ('whodunnit', 1), ('lurks', 1), ('alter-ego', 1), ('misogynist', 1), ('vioiln', 1), ('catatonic', 1), ('stimulants', 1), ('cocaine', 1), ('deepening', 1), ('enforces', 1), ('compensates', 1), ('disguises', 1), ('balzac', 1), ('1880', 1), ('anarchist', 1), ('hindmost', 1), ('self-reliance', 1), ('free-lance', 1), ('self-employed', 1), ('unpromising', 1), ('adolphus', 1), ('gustavus', 1), ('conqueror', 1), ('gustaf', 1), ('teems', 1), ('birgitta', 1), ('convent', 1), ('lagerlo', 1), ('vdingar', 1), ('ho', 1), ('deras', 1), ('svenskarna', 1), ('chieftains', 1), ('detain', 1), ('tombs', 1), ('madman', 1), ('thirty-six', 1), ('fredrikshall', 1), ('regains', 1), ('inertia', 1), ('petulance', 1), ('cheerfulness', 1), ('losers', 1), ('degenerated', 1), ('1709', 1), ('aspired', 1), ('julius', 1), ('macedon', 1), ('fervor', 1), ('idolized', 1), ('concise', 1), ('tolstoy', 1), ('karolinerna', 1), ('mediocrity', 1), ('re-assumed', 1), ('tiveden', 1), ('sardanapalus', 1), ('faustus', 1), ('storied', 1), ('alienus', 1), ('incite', 1), ('desultory', 1), ('tortures', 1), ('dwells', 1), ('revelations', 1), ('naxos', 1), ('parthenon', 1), ('paestum', 1), ('sombre', 1), ('wander-years', 1), ('hedonism', 1), ('indolence', 1), ('care-free', 1), ('bazaars', 1), ('acclaims', 1), ('fredrik', 1), ('childe', 1), ('vandringsar', 1), ('vallfart', 1), ('unceasingly', 1), ('swart', 1), ('gerome', 1), ('ttern', 1), ('vadstena', 1), ('recreates', 1), ('verner', 1), ('segregate', 1), ('adorns', 1), ('forty-eight', 1), ('perchance', 1), ('agitated', 1), ('northampton', 1), ('1889', 1), ('desensitized', 1), ('censures', 1), ('importation', 1), ('complaisance', 1), ('enslaving', 1), ('reprobating', 1), ('unrealism', 1), ('abstractionism', 1), ('thundering', 1), ('paternalistic', 1), ('taint', 1), ('manipulations', 1), ('toil', 1), ('unrequited', 1), ('redemption', 1), ('segregating', 1), ('nilly', 1), ('professes', 1), ('tokenish', 1), ('fugitives', 1), ('insouciance', 1), ('not-involved', 1), ('thank-heaven-we', 1), ('aloofness', 1), ('jeffersonian', 1), ('disquisition', 1), ('talismanic', 1), ('1857', 1), ('dred', 1), ('taney', 1), ('irrevocable', 1), ('appellant', 1), ('pacem', 1), ('faciunt', 1), ('solitudinem', 1), ('tacitus', 1), ('instancy', 1), ('socialize', 1), ('counter-attack', 1), ('humanely', 1), ('hattiesburg', 1), ('statisticians', 1), ('melioration', 1), ('non-interference', 1), ('scepticism', 1), ('interconnectedness', 1), ('presentational', 1), ('presupposition', 1), ('epistemology', 1), ('unities', 1), ('abstractive', 1), ('efficacious', 1), ('causally', 1), ('presuppose', 1), ('environing', 1), ('empiricism', 1), ('uninvolved', 1), ('presuppositions', 1), ('compels', 1), ('clamors', 1), ('imitates', 1), ('carven', 1), ('conventionalized', 1), ('connote', 1), ('vividness', 1), ('literalism', 1), ('inextricable', 1), ('relatedness', 1), ('recovers', 1), ('imagining', 1), ('re-living', 1), ('designations', 1), ('rarified', 1), ('overtones', 1), ('auerbach', 1), ('imitated', 1), ('unimpassioned', 1), ('stratify', 1), ('presupposed', 1), ('solipsism', 1), ('uncaused', 1), ('sub-human', 1), ('disintegrative', 1), ('unreason', 1), ('powerfulness', 1), ('cowhide', 1), ('thwack', 1), ('coaxing', 1), ('hoofmarks', 1), ('bucolic', 1), ('steeply', 1), ('unpaved', 1), ('edgewise', 1), ('sunshiny', 1), ('slant-wise', 1), ('heeded', 1), ('bumble-bee', 1), ('sing-song', 1), ('ni', 1), ('forearms', 1), ('gutter', 1), ('palpable', 1), ('drowsed', 1), ('unintentionally', 1), ('latched', 1), ('poor-white-trash', 1), ('misinterpretation', 1), ('solitudes', 1), ('crocketed', 1), ('rapunzel', 1), ('gate-post', 1), ('embowered', 1), ('unselfconsciousness', 1), ('passers-by', 1), ('exteriors', 1), ('pocketed', 1), ('creamy', 1), ('faery', 1), ('stabled', 1), ('snails', 1), ('caterpillars', 1), ('waggling', 1), ('blown-up', 1), ('morning-glory', 1), ('columbines', 1), ('fire-crackers', 1), ('balsams', 1), ('seed-pods', 1), ('snapdragons', 1), ('minutiae', 1), ('larkspur', 1), ('petticoated', 1), ('hollyhock', 1), ('prodigally', 1), ('myrtle', 1), ('poppy', 1), ('poppies', 1), ('longer-lived', 1), ('lilies', 1), ('plantain', 1), ('woodshed', 1), ('heliotrope', 1), ('wintered', 1), ('wall-flowers', 1), ('tubs', 1), ('oleanders', 1), ('gourd', 1), ('dining-room', 1), ('slippered', 1), ('pears', 1), ('chrysanthemums', 1), ('remonstrate', 1), ('mill-pond', 1), ('mill-wheel', 1), ('queerest', 1), ('queerer', 1), ('apple-tree', 1), ('garments', 1), ('clothesline', 1), ('balm-of-gilead', 1), ('rose-of-sharon', 1), ('syringa', 1), ('grandfathers', 1), ('greenness', 1), ('clang', 1), ('squeak', 1), ('pinnacle', 1), ('cast-iron', 1), ('open-work', 1), ('creeper', 1), ('hollyhocks', 1), ('systematization', 1), ('disarray', 1), ('orphans', 1), ('irksome', 1), ('jansenist', 1), ('inscrutability', 1), ('clov', 1), ('gogo', 1), ('didi', 1), ('unexplainable', 1), ('chartres', 1), ('royale', 1), ('malesherbes', 1), ('krapp', 1), ('endgame', 1), ('formalized', 1), ('invades', 1), ('heidegger', 1), ('renovation', 1), ('inflections', 1), ('unruly', 1), ('unsharpened', 1), ('rough-hewn', 1), ('jesuit', 1), ('nihilism', 1), ('astute', 1), ('nihilistic', 1), ('reviewers', 1), ('imprisons', 1), ('illuminate', 1), ('rubric', 1), ('keynotes', 1), ('stabilities', 1), ('ricans', 1), ('rearguard', 1), ('countervailing', 1), ('stratification', 1), ('counteracting', 1), ('crystallize', 1), ('schism', 1), ('cross-purposes', 1), ('illumines', 1), ('balances', 1), ('statuses', 1), ('propitious', 1), ('suitability', 1), ('fraternize', 1), ('17.3', 1), ('insignificance', 1), ('11.2', 1), ('co-opting', 1), ('perishes', 1), ('blight', 1), ('survives', 1), ('repairing', 1), ('vandalism', 1), ('typewriting', 1), ('majored', 1), ('stenography', 1), ('falter', 1), ('disappears', 1), ('learners', 1), ('inequality', 1), ('tamp', 1), ('anti-intellectual', 1), ('out-of-school', 1), ('furthering', 1), ('work-study', 1), ('remuneration', 1), ('half-time', 1), ('sheet-metal', 1), ('hairdos', 1), ('mascara', 1), ('flamboyantly', 1), ('foppish', 1), ('fife', 1), ('erwin', 1), ('witt', 1), ('scrupulously', 1), ('ringings', 1), ('pinnings', 1), ('watchings', 1), ('marts', 1), ('sororities', 1), ('fraternities', 1), ('jubilant', 1), ('prodded', 1), ('nubile', 1), ('morningstar', 1), ('marjorie', 1), ('acculturation', 1), ('homogeneously', 1), ('westhampton', 1), ('sallying', 1), ('hapless', 1), ('co-ordinates', 1), ('sorority', 1), ('overprotection', 1), ('overprotective', 1), ('certitudes', 1), ('unavailing', 1), ('unimpeachably', 1), ('detribalize', 1), ('cozy', 1), ('inconsiderable', 1), ('congratulation', 1), ('midwood', 1), ('ambiance', 1), ('expansively', 1), ('buttressed', 1), ('contradistinction', 1), ('best-sellers', 1), ('exertions', 1), ('45.6', 1), ('nonobservant', 1), ('kosher', 1), ('outing', 1), ('inconveniently', 1), ('intermarriage', 1), ('inhabiting', 1), ('querulously', 1), ('spinrad', 1), ('maier', 1), ('accords', 1), ('weakening', 1), ('salve', 1), ('maggots', 1), ('festering', 1), ('villagers', 1), ('notables', 1), ('bamboo', 1), ('261', 1), ('baci', 1), ('soukhouma', 1), ('plateau', 1), ('bolovens', 1), ('stumping', 1), ('villager', 1), ('soldiery', 1), ('joked', 1), ('coconuts', 1), ('infirmary', 1), ('usom', 1), ('doctorate', 1), ('anthropologist', 1), ('coatings', 1), ('beaver', 1), ('viphakone', 1), ('dispensary', 1), ('cicadas', 1), ('silkworms', 1), ('kok', 1), ('keng', 1), ('luger', 1), ('ten-gallon', 1), ('mien', 1), ('churchillian', 1), ('land-rover', 1), ('highness', 1), ('spurned', 1), ('escorts', 1), ('garrett', 1), ('overloaded', 1), ('rickety', 1), ('muong', 1), ('attopeu', 1), ('1.60', 1), ('tranquil', 1), ('colonized', 1), ('frangipani', 1), ('slender-waisted', 1), ('majestically', 1), ('pirogues', 1), ('phis', 1), ('patagonians', 1), ('oregonians', 1), ('buffaloes', 1), ('terrorists', 1), ('hit-and-run', 1), ('rubble', 1), ('peppered', 1), ('thoroughfares', 1), ('din', 1), ('eclipse', 1), ('newspaperman', 1), ('bicycles', 1), ('unshaven', 1), ('guatemalan', 1), ('purposively', 1), ('espousing', 1), ('unqualifiedly', 1), ('americanism', 1), ('bridgehead', 1), ('plunging', 1), ('swerving', 1), ('wilsonian', 1), ('kikiyus', 1), ('adamantly', 1), ('kassem', 1), ('nasser', 1), ('pretensions', 1), ('avowed', 1), ('besieged', 1), ('troubie', 1), ('adherent', 1), ('neutralize', 1), ('undercover', 1), ('clandestine', 1), ('parliaments', 1), ('skirmishes', 1), ('conquests', 1), ('cominform', 1), ('campaigne', 1), ('jameson', 1), ('policy-makers', 1), ('consisently', 1), ('sino-soviet', 1), ('defer', 1), ('antithetical', 1), ('doctrinally', 1), ('approachable', 1), ('imperfectability', 1), ('reckons', 1), ('supposes', 1), ('herblock', 1), ('mesa', 1), ('patton', 1), ('brevet', 1), ('pistol-whipped', 1), ('profusely', 1), ('paddies', 1), ('counterattack', 1), ('withering', 1), ('diversionary', 1), ('stragglers', 1), ('imbued', 1), ('faring', 1), ('cavalrymen', 1), ('regrouped', 1), ('machine-gun', 1), ('overran', 1), ('fodder', 1), ('luzon', 1), ('non-commissioned', 1), ('ra', 1), ('rotc', 1), ('margarito', 1), ('bugler', 1), ('ould', 1), ('tearfully', 1), ('gouldings', 1), ('non-com', 1), ('soldiering', 1), ('blind-folded', 1), ('steed', 1), ('splattered', 1), ('melbourne', 1), ('pancho', 1), ('banditos', 1), ('valor', 1), ('shannon', 1), ('limerick', 1), ('tremor', 1), ('leet', 1), ('overemphasized', 1), ('marooned', 1), ('longitude', 1), ('seismic', 1), ('seismograph', 1), ('07', 1), ('kamchatka', 1), ('alerts', 1), ('seismographs', 1), ('attu', 1), ('notifying', 1), ('disregarded', 1), ('geodetic', 1), ('sagami', 1), ('diatoms', 1), ('miliaris', 1), ('noctiluca', 1), ('luminescent', 1), ('luminosity', 1), ('pololu', 1), ('seaquake', 1), ('steepest', 1), ('oceanography', 1), ('lulled', 1), ('landslides', 1), ('scurried', 1), ('tugaru', 1), ('denuded', 1), ('reefs', 1), ('salvo', 1), ('bathers', 1), ('lagrange', 1), ('27000', 1), ('ponoluu', 1), ('1869', 1), ('osaka', 1), ('1596', 1), ('1755', 1), ('lisbon', 1), ('archaeologists', 1), ('atlantis', 1), ('inundations', 1), ('catastrophic', 1), ('sumatra', 1), ('krakatoa', 1), ('volcanic', 1), ('carted', 1), ('1750', 1), ('brazenness', 1), ('sibley', 1), ('coups', 1), ('freight-car', 1), ('marshalling', 1), ('recklessness', 1), ('brash', 1), ('druggan-lake', 1), ('saltis-mcerlane', 1), ('speak-easy', 1), ('amity', 1), ('double-crossing', 1), ('irishman', 1), ('dionie', 1), ('braggadocio', 1), ('unhurt', 1), ('ricocheted', 1), ('wounding', 1), ('nighters', 1), ('tuxedoed', 1), ('gowned', 1), ('salle', 1), ('hirschey', 1), ('referee', 1), ('prize-fight', 1), ('bodyguard', 1), ('blandness', 1), ('enraged', 1), ('vulpine', 1), ('truculence', 1), ('swaggering', 1), ('aggrandisement', 1), ('euphoric', 1), ('ballooning', 1), ('forging', 1), ('bribers', 1), ('marshalled', 1), ('tributes', 1), ('fraternized', 1), ('feasts', 1), ('belshazzar', 1), ('blatancy', 1), ('rubies', 1), ('pestering', 1), ('stickpin', 1), ('honoured', 1), ('recognised', 1), ('fixers', 1), ('felons', 1), ('dishonouring', 1), ('dever', 1), ('sold-out', 1), ('heelers', 1), ('fraternisation', 1), ('organised', 1), ('conferring', 1), ('wooed', 1), ('forty-third', 1), ('forty-second', 1), ('bullyboys', 1), ('knuckle-duster', 1), ('pistoleers', 1), ('holdups', 1), ('bootlegging', 1), ('bribes', 1), ('acquitted', 1), ('prossed', 1), ('nolle', 1), ('alderman', 1), ('bridewell', 1), ('dion', 1), ('misted', 1), ('homicidal', 1), ('asylum', 1), ('geary', 1), ('neanderthal', 1), ('highwayman', 1), ('breaker', 1), ('herald-examiner', 1), ('befuddled', 1), ('notoriously', 1), (\"mcgovern's\", 1), ('scarface', 1), ('gimpy', 1), ('housebreaking', 1), ('dodging', 1), ('pressure-cooker', 1), ('neighbourhood', 1), ('honkytonks', 1), ('acolyte', 1), ('plasterer', 1), ('roughneck', 1), ('interwoven', 1), ('casebook', 1), ('risking', 1), ('nerveless', 1), ('plugugly', 1), ('landesco', 1), ('quickness', 1), ('lurch', 1), ('wreaths', 1), ('bouquets', 1), ('armpit', 1), ('jovial', 1), ('creased', 1), ('candour', 1), ('inadvisable', 1), ('skunks', 1), ('thievin', 1), ('staid', 1), ('wus', 1), ('recooned', 1), ('alabamans', 1), ('shavings', 1), ('takeing', 1), ('homefolk', 1), ('offersey', 1), ('ters', 1), ('filde', 1), ('conte', 1), ('docters', 1), ('slinging', 1), ('rascals', 1), ('mauldin', 1), ('shucks', 1), ('puke', 1), ('pemberton', 1), ('louisianan', 1), ('fay', 1), ('tote', 1), ('floridian', 1), ('ignoramus', 1), ('alabamian', 1), ('stuck-up', 1), ('reub', 1), ('disparagement', 1), ('choicest', 1), ('godamit', 1), ('thay', 1), ('biches', 1), ('holored', 1), ('brok', 1), ('skouting', 1), ('infantryman', 1), ('shute', 1), ('hel', 1), ('helion', 1), ('tode', 1), ('pigen', 1), ('yeard', 1), ('lop', 1), ('theaf', 1), ('com', 1), ('bich', 1), ('thefin', 1), ('feler', 1), ('nise', 1), ('chouise', 1), ('yuse', 1), ('doo', 1), ('mor', 1), ('wod', 1), ('runing', 1), ('pungently', 1), ('eyd', 1), ('recond', 1), ('wold', 1), ('pappies', 1), ('thout', 1), ('belles', 1), ('boastfully', 1), ('printable', 1), ('amorous', 1), ('sweethearts', 1), ('laundering', 1), ('menial', 1), ('whizzing', 1), ('hubbub', 1), ('thease', 1), ('dyerear', 1), ('stomack', 1), ('sowered', 1), ('poark', 1), ('diorah', 1), ('shitts', 1), ('knott', 1), ('sh-ts', 1), ('bowels', 1), ('looseness', 1), ('thiot', 1), ('er', 1), ('gray-backs', 1), ('parodied', 1), ('corpulence', 1), ('forgitful', 1), ('enny', 1), ('sofar', 1), ('maryed', 1), ('georgian', 1), ('stillwell', 1), ('halda', 1), ('geered', 1), ('twister', 1), ('one-horse', 1), ('maget', 1), ('jist', 1), ('missive', 1), ('leaches', 1), ('stirups', 1), ('rawhide', 1), ('poring', 1), ('ornraier', 1), ('lise', 1), ('1841', 1), ('smuggled', 1), ('pemmican', 1), ('forwarding', 1), ('prohibiton', 1), ('4369', 1), ('1831', 1), ('2417', 1), ('selkirkers', 1), ('platted', 1), ('plympton', 1), ('bottineau', 1), ('uninterruptedly', 1), ('157', 1), ('1837', 1), ('vevay', 1), ('443', 1), ('1826', 1), ('1823', 1), ('rafts', 1), ('halkett', 1), ('mcdonnell', 1), ('michilimackinac', 1), ('discontented', 1), ('sieux', 1), ('drovers', 1), ('labothe', 1), ('hercules', 1), ('outposts', 1), ('leavenworth', 1), ('lieutenant-colonel', 1), ('northerly', 1), ('tho', 1), ('thills', 1), ('ox', 1), ('withes', 1), ('pegs', 1), ('1802', 1), ('renville', 1), ('rolette', 1), ('1816', 1), ('barony', 1), ('metis', 1), ('dispersal', 1), ('ravages', 1), ('hoes', 1), ('regiments', 1), ('meurons', 1), ('winnipeg', 1), ('tippecanoe', 1), ('116000', 1), ('crofters', 1), ('scot', 1), ('capstan', 1), ('adame', 1), ('criss-crossing', 1), ('bylot', 1), ('homeward', 1), ('mathues', 1), ('bennett', 1), ('tacking', 1), ('angered', 1), ('land-locked', 1), ('blackest', 1), ('westwards', 1), ('deltas', 1), ('wolstenholme', 1), ('digges', 1), ('precipice', 1), ('starboard', 1), ('gateways', 1), ('mists', 1), ('headlands', 1), ('wordy', 1), ('lopped', 1), ('captains', 1), ('quelling', 1), ('ungava', 1), ('bergs', 1), ('nearness', 1), ('protege', 1), ('two-weeks', 1), ('lousie', 1), ('skirted', 1), ('gravesend', 1), ('whores', 1), ('panders', 1), ('pimps', 1), ('unsuited', 1), ('voyager', 1), ('navigator', 1), ('hendrik', 1), ('londoner', 1), ('seafaring', 1), ('perse', 1), ('zemlya', 1), ('novaya', 1), ('voyages', 1), ('qualms', 1), ('waymouth', 1), ('1602', 1), ('labrador', 1), ('baffin', 1), ('provisioned', 1), ('forbade', 1), ('dartmouth', 1), ('geographers', 1), ('1608', 1), ('1607', 1), ('persisting', 1), ('second-hand', 1), ('galway', 1), ('limping', 1), (\"katherine's\", 1), ('masted', 1), ('social-welfare', 1), ('continence', 1), ('self-control', 1), ('steadfastly', 1), ('emphatic', 1), ('tumultuous', 1), ('inglorious', 1), ('creedal', 1), ('supplant', 1), ('propositions', 1), ('natural-law', 1), ('birth-prevention', 1), ('infertile', 1), ('eugenic', 1), ('beget', 1), ('jibes', 1), ('roughshod', 1), ('commonweal', 1), ('gara', 1), ('dispassionate', 1), ('sloganeering', 1), ('recrimination', 1), ('polemical', 1), ('nettlesome', 1), ('faiths', 1), ('smolders', 1), ('rumbles', 1), ('erupting', 1), ('rancor', 1), ('dramatize', 1), ('embroiled', 1), ('contraceptive', 1), ('reinstated', 1), ('poughkeepsie', 1), ('memoirs', 1), ('highlighting', 1), ('compatriots', 1), ('bulgaria', 1), ('haters', 1), ('convict', 1), ('megalomania', 1), ('opportunism', 1), ('neighborliness', 1), ('demoralization', 1), ('pulverizing', 1), ('meanest', 1), ('terrorizing', 1), ('patriots', 1), ('gassings', 1), ('bashings', 1), ('edifying', 1), ('madness', 1), ('concentration-camp', 1), ('accomplices', 1), ('exterminating', 1), ('promulgators', 1), ('emigration', 1), ('strangulation', 1), ('goering', 1), ('phraseology', 1), ('wansee', 1), ('outrageous', 1), ('mindedness', 1), ('giddiness', 1), ('disobeying', 1), ('virulent', 1), ('falsifying', 1), ('refining', 1), ('repentant', 1), ('rebuked', 1), ('servatius', 1), ('awfulness', 1), ('delicti', 1), ('admissible', 1), ('lunatic', 1), ('auschwitz', 1), ('gassed', 1), ('machine-gunned', 1), ('adolescents', 1), ('graybeards', 1), ('mains', 1), ('binder', 1), ('secondhand', 1), ('small-scale', 1), ('cultivating', 1), ('disking', 1), ('plantings', 1), ('white-collar', 1), ('threshing', 1), ('labor-saving', 1), ('routinely', 1), ('confining', 1), ('courted', 1), ('assertive', 1), ('butting', 1), ('passivity', 1), ('extramarital', 1), ('flurried', 1), ('tradesmen', 1), ('postwar', 1), ('flapper', 1), ('shamefacedly', 1), ('gynecologist', 1), ('hilliard', 1), ('roost', 1), ('reik', 1), ('theodor', 1), ('threshhold', 1), ('milquetoasts', 1), ('shrewish', 1), ('henpecked', 1), ('topsy-turvy', 1), ('demandingly', 1), ('overtures', 1), ('ironing', 1), ('custody', 1), ('embezzle', 1), ('luxuries', 1), ('maleness', 1), ('masculinity', 1), ('robs', 1), ('saps', 1), ('demeans', 1), ('wifely', 1), ('bestial', 1), ('heedless', 1), ('steichen', 1), ('meekest', 1), ('aye', 1), ('unselfish', 1), ('mattresses', 1), ('logger', 1), ('tow', 1), ('resorts', 1), ('splits', 1), ('aaa', 1), ('campsites', 1), ('windbreaks', 1), ('parachutes', 1), ('pup', 1), ('bluefish', 1), ('seagulls', 1), ('hatteras', 1), ('sammy', 1), ('man-hours', 1), ('grass-roots', 1), ('assists', 1), ('appreciations', 1), ('thc', 1), ('jennings', 1), ('oep', 1), ('carryover', 1), ('kick-off', 1), (\"sportsmen's\", 1), ('harvested', 1), ('reaped', 1), ('expendable', 1), ('small-arms', 1), ('autoloaders', 1), ('loader', 1), ('studebaker', 1), ('replacements', 1), ('widest', 1), ('dishwater', 1), ('absentee', 1), ('startups', 1), ('layoffs', 1), ('illnesses', 1), ('deadheads', 1), ('drinkers', 1), ('dispensers', 1), ('deductable', 1), ('227.72', 1), ('blue-collar', 1), ('facsimile', 1), ('dietetic', 1), ('distributes', 1), ('bafflers', 1), ('hourly', 1), ('revamping', 1), ('indiscriminantly', 1), ('first-aid', 1), ('make-work', 1), ('non-productive', 1), ('unneeded', 1), ('re-scheduled', 1), ('weed', 1), ('audited', 1), ('custodial', 1), ('subcontracting', 1), ('prepackaged', 1), ('wash-up', 1), ('midweek', 1), ('profit-sharing', 1), ('fancier', 1), ('absenteeism', 1), ('yr', 1), ('short-changing', 1), ('hip-pocket', 1), ('top-notch', 1), ('shelved', 1), ('commercialization', 1), ('obsoleting', 1), ('beats', 1), ('influencing', 1), ('mos.', 1), ('higher-priced', 1), ('niceties', 1), ('slants', 1), ('fast-growing', 1), ('researching', 1), ('warehousing', 1), ('discretionary', 1), ('follow-through', 1), ('assertions', 1), ('wittingly', 1), ('upgraded', 1), ('efficiencies', 1), ('all-weather', 1), ('.75', 1), ('vaccinating', 1), ('tranquilizer', 1), ('rumen', 1), ('coccidiosis', 1), ('dysentery', 1), ('legume', 1), ('feeder', 1), ('droppings', 1), ('nodular', 1), ('hookworm', 1), ('grubs', 1), ('flavus', 1), ('orzae', 1), ('apergillus', 1), ('fermentation', 1), ('tags', 1), ('fungal', 1), ('butterfat', 1), ('elevates', 1), ('fattening', 1), ('consumes', 1), ('.0044', 1), ('vibrionic', 1), ('enterotoxemia', 1), ('anaplasmosis', 1), ('vaccination', 1), ('hydrochloride', 1), ('parentheses', 1), ('processors', 1), ('unimpressive', 1), ('romagnosi', 1), ('transversally', 1), ('leyden', 1), ('marum', 1), ('lauritz', 1), ('bornholm', 1), ('detonating', 1), ('1814', 1), ('coulomb', 1), ('bruckmann', 1), ('electriques', 1), ('chimiques', 1), ('identite', 1), ('recherches', 1), ('thoroughness', 1), ('1842', 1), ('1769', 1), ('ordinarius', 1), ('professorship', 1), ('1806', 1), ('condenser', 1), ('1782', 1), ('wilcke', 1), ('electrophorus', 1), ('1764', 1), ('kleist', 1), ('leiden', 1), ('corresponded', 1), ('1745', 1), ('remodeled', 1), ('stormed', 1), ('jena', 1), ('galvanism', 1), ('ttingen', 1), ('elector', 1), ('woburn,', 1), ('tieck', 1), ('fichte', 1), ('wanderjahr', 1), ('ferment', 1), ('1799', 1), ('onward', 1), ('1479', 1), ('soeren', 1), ('1777', 1), ('langeland', 1), ('rudkoebing', 1), ('blood-filled', 1), ('submerging', 1), ('howry', 1), ('epoxy', 1), ('mc.', 1), ('sonogram', 1), ('ultrasonically', 1), ('glaucoma', 1), ('retina', 1), ('gratifying', 1), ('bursts', 1), ('kc.', 1), ('farrar', 1), ('oscillator', 1), ('transistor', 1), ('multichannel', 1), ('analogue', 1), ('outputs', 1), ('thermistor', 1), ('doppler', 1), ('time-delay', 1), ('msec.', 1), ('pulsed', 1), ('undisturbed', 1), ('medically', 1), ('treadmill', 1), ('inhalation', 1), ('dioxide', 1), ('lobar', 1), ('perfecting', 1), ('tricolor', 1), ('amplifiers', 1), ('sequential', 1), ('circuitry', 1), ('commutator', 1), ('leakage', 1), ('one-twentieth', 1), ('sequenced', 1), ('synchronism', 1), ('quartz', 1), ('xenon', 1), ('biophysicist', 1), ('aterman', 1), ('replaces', 1), ('disrupts', 1), ('bio-medical', 1), ('timers', 1), ('paging', 1), ('closed-circuit', 1), ('bursitis', 1), ('contusions', 1), ('diathermy', 1), ('evenutally', 1), ('academicianship', 1), ('rockport', 1), ('chautauqua', 1), ('blair', 1), ('pennell', 1), ('pisces', 1), ('interpretor', 1), ('vicarious', 1), ('universalize', 1), (\"mind's\", 1), ('foiled', 1), ('decorativeness', 1), (\"davy's\", 1), (\"payne's\", 1), ('ochre', 1), (\"hooker's\", 1), ('winsor', 1), ('ultramarine', 1), ('cerulean', 1), ('sepia', 1), ('umber', 1), ('alizarin', 1), ('fitch', 1), ('riggers', 1), ('sables', 1), ('sable', 1), ('absorbency', 1), ('mop', 1), ('nubbins', 1), ('flaws', 1), ('inspecting', 1), ('hand-made', 1), ('heavy-weight', 1), ('unfixed', 1), ('tilt-top', 1), ('accenting', 1), ('reorder', 1), ('imparts', 1), ('clicking', 1), ('darkest', 1), ('lightest', 1), ('duplicable', 1), ('rigger', 1), ('flicks', 1), ('stylemark', 1), ('imitative', 1), ('ryder', 1), ('nina', 1), ('discerning', 1), ('commends', 1), ('engraver', 1), ('effortless', 1), ('cotman', 1), ('practising', 1), ('fermentations', 1), ('flitting', 1), ('polka', 1), ('idiomatic', 1), ('star-spangled', 1), ('anthem', 1), ('reharmonization', 1), ('maladroit', 1), ('protagonist', 1), ('renunciations', 1), ('serialism', 1), ('ecclesiasticism', 1), ('classicism', 1), ('postulates', 1), ('firma', 1), ('terra', 1), ('predisposed', 1), ('noces', 1), ('les', 1), ('printemps', 1), ('sacre', 1), ('petruchka', 1), ('inspirations', 1), ('miscalculations', 1), ('refashion', 1), ('fruitfulness', 1), ('fecundity', 1), ('experimentations', 1), ('experimentalism', 1), ('florid', 1), ('heaviness', 1), ('evading', 1), ('adroitness', 1), ('modulations', 1), ('polytonal', 1), ('adroit', 1), ('forsakes', 1), ('torrents', 1), ('defection', 1), ('striven', 1), ('fluent', 1), ('truculent', 1), ('disciplines', 1), ('fascist', 1), ('conscription', 1), ('coagulating', 1), ('motherland', 1), ('enthusiasms', 1), ('sympathique', 1), ('ultramodern', 1), ('dadaism', 1), ('diaghileff', 1), ('gavottes', 1), ('extravaganzas', 1), ('opulent', 1), ('unreservedly', 1), ('life-long', 1), ('dieu', 1), ('classicists', 1), ('traditionalists', 1), ('monde', 1), ('bonheur', 1), ('pranks', 1), ('mercurial', 1), ('muzyka', 1), ('sovietskaya', 1), ('stupefying', 1), ('boucle', 1), ('cheekbones', 1), ('blue-black', 1), ('aviary', 1), ('exhaling', 1), ('perelman', 1), ('hex', 1), ('bilharziasis', 1), ('fluke', 1), ('yaws', 1), ('hors', 1), ('bodhisattva', 1), ('sidle', 1), ('horoscope', 1), ('pityingly', 1), ('extremis', 1), ('besmirched', 1), ('bathos', 1), ('plumbed', 1), ('hubris', 1), ('beggary', 1), ('masterly', 1), ('incubi', 1), ('speckled', 1), ('roylott', 1), ('grimesby', 1), ('server', 1), ('spector', 1), ('quavering', 1), ('crisscrossed', 1), ('tallow', 1), ('contentedly', 1), ('stubbed', 1), ('retaliate', 1), ('chivying', 1), ('odious', 1), ('arboreal', 1), ('mio', 1), ('donning', 1), (\"paglieri's\", 1), ('enrico', 1), ('exasperate', 1), ('areaways', 1), ('scarify', 1), ('yapping', 1), ('cartons', 1), ('garlanded', 1), ('bombay', 1), ('joss', 1), ('wisenheimer', 1), ('befell', 1), ('ubermenschen', 1), ('pinball', 1), ('gorging', 1), ('gage', 1), ('pap', 1), ('forty-fifth', 1), ('naught', 1), ('vandals', 1), ('fishmongers', 1), ('cocu', 1), ('rooftree', 1), ('agoeng', 1), ('tjokorda', 1), ('balinese', 1), ('rajah', 1), ('mem', 1), ('housebreakers', 1), ('amulet', 1), ('nuf', 1), ('thuggee', 1), ('worshiped', 1), ('goddess', 1), ('kali', 1), ('subcontinent', 1), ('travancore', 1), ('krishna', 1), ('siva', 1), ('ganessa', 1), ('deities', 1), ('applejack', 1), ('provenance', 1), ('khartoum', 1), ('livers', 1), ('juju', 1), ('sudanese', 1), ('desecration', 1), ('imploring', 1), ('fantods', 1), ('chaulmoogra', 1), ('leprosy', 1), ('salpetriere', 1), ('guimet', 1), ('musee', 1), ('jokers', 1), ('retribution', 1), ('maltreat', 1), ('fess', 1), ('allah', 1), ('jehovah', 1), ('teakwood', 1), ('statuette', 1), ('obsidian', 1), ('heisted', 1), ('meted', 1), ('affronted', 1), ('delimit', 1), ('occidental', 1), ('ensues', 1), ('curtain-raiser', 1), ('spasm', 1), ('clonic', 1), (\"king's\", 1), ('frambesia', 1), ('effloresce', 1), ('wither', 1), ('posses', 1), ('gird', 1), ('javert', 1), ('constables', 1), ('lammed', 1), ('kodaks', 1), ('chess', 1), ('unearthed', 1), ('snuffboxes', 1), ('glommed', 1), ('doble', 1), ('tangos', 1), ('victrola', 1), ('fumed', 1), ('eludes', 1), ('khaki', 1), ('coverlet', 1), ('hastening', 1), ('jimmied', 1), (\"'orso\", 1), ('dell', 1), ('hostaria', 1), ('22nd', 1), ('recapitulate', 1), ('malign', 1), ('rectitude', 1), (\"d'art\", 1), ('objets', 1), ('whimper', 1), ('rifling', 1), ('etymological', 1), ('taunting', 1), ('prowlers', 1), ('argot', 1), ('reliably', 1), ('jocose', 1), ('sirs', 1), ('chiding', 1), ('entitle', 1), ('counterbalance', 1), ('unwavering', 1), ('unpaintable', 1), ('inexpressible', 1), ('kline', 1), ('kooning', 1), ('blossomed', 1), ('kandinsky', 1), ('guggenheim', 1), ('sophisticates', 1), ('drib-drool', 1), ('curvaceously', 1), ('brighetti', 1), ('margo', 1), ('crackles', 1), ('mailer', 1), ('rossilini', 1), ('fredrico', 1), ('new-waver', 1), ('tasti-freeze', 1), ('sadistic', 1), ('bogartian', 1), ('jean-pierre', 1), ('pug-nosed', 1), ('filles', 1), ('jeunes', 1), ('beat-up', 1), ('elysees', 1), ('rosalie', 1), ('fascinatingly', 1), ('opalescent', 1), ('chipping', 1), ('volare', 1), ('mudugno', 1), ('leitmotiv', 1), ('bout-de-souffle', 1), ('nabisco', 1), ('rediscovery', 1), ('hardwicke', 1), ('mah-jongg', 1), (\"parkinson's\", 1), ('tragically', 1), ('quizzical', 1), ('understated', 1), ('bambi', 1), ('engagingly', 1), ('chadroe', 1), ('petite', 1), ('existentialist', 1), ('mlle', 1), ('hollowness', 1), ('pithy', 1), ('trip-hammer', 1), ('lascivious', 1), ('scenario', 1), ('sexy', 1), ('francoisette', 1), ('enfant', 1), ('precocious', 1), ('unpretentious', 1), ('rilke', 1), ('muffins', 1), ('lemon-meringue', 1), ('intruding', 1), ('waitress', 1), ('offbeat', 1), ('ceaseless', 1), ('amateurishness', 1), ('entwhistle', 1), ('haiku', 1), ('basho', 1), ('theatregoer', 1), ('bittersweet', 1), ('inspirational', 1), ('heavy-handed', 1), ('trite', 1), ('fingerings', 1), ('phrasing', 1), ('tschilwyk', 1), ('rattzhenfuut', 1), ('skolkau', 1), ('neurenschatz', 1), ('purgatory', 1), ('brest-silevniov', 1), ('63711', 1), ('bini', 1), ('movie-goer', 1), ('mute', 1), ('shatters', 1), ('punishing', 1), ('dunkirk', 1), ('pangs', 1), ('expunge', 1), ('reichstag', 1), ('derivations', 1), ('gaelic', 1), ('epileptic', 1), ('flashback', 1), ('meinckian', 1), ('jungian', 1), ('melodrama', 1), ('pockmanster', 1), ('spouting', 1), ('bathar-on-walli', 1), ('nnuolapertar-it-vuh-karti-biri-pitknoumen', 1), ('tongue-twister', 1), ('sweathruna', 1), ('pratakku', 1), ('salivate', 1), ('bouanahsha', 1), ('bantered', 1), ('visrhanik', 1), ('proto-senility', 1), ('eurasian', 1), ('dharma', 1), ('ad-lib', 1), ('gooshey', 1), ('sidesteps', 1), ('shuz', 1), ('vanishes', 1), ('prudence', 1), ('gorshek', 1), ('phineoppus', 1), ('invocation', 1), ('serbantian', 1), ('grunnfeu', 1), ('atonally', 1), ('ranavan', 1), ('yalagaloo', 1), ('conduit', 1), ('prometheus', 1), ('sforzt', 1), ('hattie', 1), ('contralto', 1), ('spegititgninino', 1), ('sevigli', 1), ('spumoni', 1), ('oxcart', 1), ('stumbles', 1), ('scimitar', 1), ('buckling', 1), ('cancels', 1), ('affianced', 1), ('silesia', 1), ('saracens', 1), ('fifty-third', 1), ('marcellus', 1), ('punic', 1), ('vignette', 1), ('portant', 1), ('agricolas', 1), ('silvas', 1), ('aquam', 1), ('pueri', 1), ('eye-beamings', 1), ('rollickingly', 1), ('intrigued', 1), ('rakishly', 1), ('perpetration', 1), ('swig', 1), ('maneuvered', 1), ('wheezes', 1), ('convulsed', 1), ('balkiness', 1), ('ceremonially', 1), ('laughingly', 1), ('middles', 1), ('pamper', 1), ('somersaulting', 1), ('ladylike', 1), ('ish', 1), ('chorused', 1), (\"ma'am\", 1), ('minks', 1), ('bumped', 1), ('funnier', 1), ('wiggling', 1), ('gaspingly', 1), ('backwards', 1), ('oatmeal', 1), ('warm-up', 1), ('twirlingly', 1), ('unco-operative', 1), ('tumbles', 1), ('nooks', 1), ('corrupts', 1), ('manic-depressive', 1), ('paranoiac', 1), ('ideologist', 1), ('carthage', 1), ('deus', 1), ('est', 1), ('delenda', 1), ('carthago', 1), ('angleterre', 1), ('gott', 1), ('frenchmen', 1), ('eddies', 1), ('disbelieves', 1), ('tube-nosed', 1), ('screw-loose', 1), ('fancy-free', 1), ('restively', 1), ('wynn', 1), ('mockery', 1), ('ba-a-a', 1), ('unison', 1), ('alps', 1), ('demonstrable', 1), ('saner', 1), ('mehitabel', 1), ('gai', 1), ('toujours', 1), ('clinked', 1), ('living-room', 1), ('tawdry', 1), ('dustbin', 1), ('brothel', 1), ('tragicomic', 1), ('anglo-americans', 1), ('drawing-rooms', 1), ('antic', 1), ('re-explore', 1), ('theatres', 1), ('co-existence', 1), ('knightly', 1), ('galahad', 1), ('daffodils', 1), ('rapture', 1), ('beholds', 1), ('dilys', 1), ('retrogressive', 1), ('insanity', 1), ('exterminate', 1), ('noisier', 1), ('sit-down', 1), ('nonism', 1), ('commoners', 1), ('dooms', 1), ('walrus', 1), ('paraphrasing', 1), ('zeitgeist', 1), ('comics', 1), ('careerism', 1), ('gagarin', 1), ('upson', 1), ('fairy-tale', 1), ('misnomer', 1), ('equivocal', 1), ('petted', 1), ('soulfully', 1), ('moonlit', 1), ('undertaker', 1), ('maxim', 1), ('indefinity', 1), ('demurred', 1), ('anatomicals', 1), ('misconstructions', 1), ('lumbar', 1), ('rumpus', 1), ('escorting', 1), ('reappearance', 1), ('caterer', 1), ('schooldays', 1), ('headlinese', 1), ('bathtubs', 1), ('misrelated', 1), ('chockfull', 1), ('snapshots', 1), ('gagline', 1), ('gagwriters', 1), ('wooden-leg', 1), ('quatrain', 1), ('grammarians', 1), ('interviewer', 1), ('biter', 1), ('explanatory', 1), ('stumped', 1), ('misquoted', 1), ('girl-friend', 1), ('sours', 1), ('jest', 1), ('interweaving', 1), ('baffle', 1), ('misdirectors', 1), ('misunderstanders', 1), ('misinterpreters', 1), ('parlance', 1), ('ologies', 1), ('parisology', 1), ('amphibology', 1), ('rhetoricians', 1), ('sheridan', 1), ('brinsley', 1), ('ridiculed', 1), ('disfigured', 1), ('rotundity', 1), ('neatest', 1), ('niobe', 1), ('ocher', 1), ('soutane', 1), ('delighting', 1), ('bagpipe', 1), ('squirted', 1), ('undulated', 1), ('whiskered', 1), ('unfalteringly', 1), ('marbleized', 1), ('encrusted', 1), ('time-cast', 1), ('sallow', 1), ('feasting', 1), ('claret', 1), ('lapping', 1), ('wetness', 1), ('daydreaming', 1), ('downcast', 1), ('harshness', 1), ('artfully', 1), ('tanned', 1), ('pales', 1), ('gloved', 1), ('eight-thirty', 1), ('columned', 1), ('coolness', 1), ('courtyards', 1), ('tunneled', 1), ('alleyways', 1), ('showroom', 1), ('bartoli', 1), ('grating', 1), ('reeked', 1), ('rusted', 1), ('ginkgo', 1), ('aloneness', 1), ('chieti', 1), ('withered', 1), ('variegated', 1), ('sundials', 1), ('shooing', 1), ('suppleness', 1), ('puttana', 1), ('sweeter', 1), ('tweezed', 1), ('rosaries', 1), ('henh', 1), ('dante', 1), ('airs', 1), ('streetcars', 1), ('strutted', 1), ('buttocks', 1), ('fur-piece', 1), ('signore', 1), ('filippo', 1), ('surging', 1), ('cheesecloth', 1), ('repetitive', 1), ('sunbaked', 1), ('false-fronted', 1), ('kelseyville', 1), ('red-tailed', 1), ('graze', 1), ('awry', 1), ('livable', 1), ('bulls', 1), ('broken-down', 1), ('scrubbed', 1), ('coyote', 1), ('browbeaten', 1), ('prettiness', 1), ('side-stepped', 1), ('thong', 1), ('sanchez', 1), ('flinching', 1), ('glared', 1), ('dark-skinned', 1), ('sternly', 1), ('cud', 1), ('aback', 1), ('dangle', 1), ('conjunctions', 1), ('nouns', 1), ('inanimate', 1), ('neuter', 1), ('genders', 1), ('tenses', 1), (\"mai'teipa\", 1), (\"ksu'u'peli'afo\", 1), (\"dabhumaksanigalu'ahai\", 1), ('infinitive', 1), ('animate', 1), ('unattached', 1), ('inflecting', 1), ('ozagenians', 1), ('wrongly', 1), ('unthaw', 1), ('actuate', 1), ('photon', 1), ('99.1', 1), ('lopsidedly', 1), ('jowled', 1), ('welling', 1), ('cremated', 1), ('unrealistically', 1), ('french-canadians', 1), ('resettling', 1), ('disputed', 1), ('sahara', 1), ('swahili', 1), ('visualized', 1), ('malay', 1), ('necklaces', 1), ('megalopolises', 1), ('israelites', 1), ('couched', 1), ('urielites', 1), ('pardons', 1), ('lamechian', 1), ('lamechians', 1), ('m.r.', 1), ('creche', 1), ('impresser', 1), ('573', 1), ('barometric', 1), ('personae', 1), ('rock-steady', 1), ('tiptoeing', 1), ('cb', 1), ('bcd', 1), ('clinches', 1), ('ethereal', 1), ('gripes', 1), ('requisition', 1), ('popes', 1), ('fosterites', 1), ('romano', 1), (\"l'osservatore\", 1), ('denunciations', 1), ('hoy', 1), (\"l'unita\", 1), ('huey', 1), ('with-but-after', 1), ('spot-promoted', 1), ('fosterite', 1), ('price-cutting', 1), ('purses', 1), ('guru', 1), ('rig-veda', 1), ('diapers', 1), ('matsyendra', 1), ('chelas', 1), ('pranha', 1), ('yoga', 1), ('sicily', 1), ('swami', 1), ('serviettes', 1), ('meditations', 1), ('merged', 1), ('breathlessly', 1), ('discorporated', 1), ('nests', 1), ('nymphs', 1), ('antares', 1), ('picnicked', 1), ('night-sight', 1), ('stinky', 1), ('chipper', 1), ('puppyish', 1), ('clear-headed', 1), ('uncurled', 1), ('nirvana', 1), ('warily', 1), ('tabernacle', 1), ('threes-fulfilled', 1), ('morgue', 1), ('dumpty', 1), ('humpty', 1), ('mended', 1), ('jerks', 1), ('off-stage', 1), ('goodnight', 1), ('discordantly', 1), ('perspiring', 1), ('gravestone', 1), ('upbeat', 1), ('lucks', 1), ('call-backs', 1), ('sippers', 1), ('natch', 1), ('constrained', 1), ('kidnappers', 1), ('duvol', 1), ('hero-worshippers', 1), ('prying', 1), ('brush-fire', 1), ('eluding', 1), ('hustled', 1), ('nosing', 1), ('cancelling', 1), ('confer', 1), ('befitting', 1), ('revising', 1), ('comforted', 1), ('cant', 1), ('kidnapped', 1), ('crutch', 1), ('shrouded', 1), ('tarpaulin', 1), ('wacky', 1), ('more-than', 1), ('unerringly', 1), ('skylight', 1), ('fingerprinting', 1), ('foursome', 1), ('agile', 1), ('edmund', 1), ('shh', 1), ('fingerprints', 1), ('whorls', 1), ('blokes', 1), ('whiff', 1), ('receded', 1), ('dentures', 1), ('heavy-armed', 1), ('big-shouldered', 1), ('chested', 1), ('cavort', 1), ('flute', 1), ('apparition', 1), ('handiwork', 1), ('unaccountable', 1), ('hatted', 1), ('unsuitably', 1), ('craggy', 1), ('sobriety', 1), ('householder', 1), ('onlookers', 1), ('goings', 1), ('comings', 1), ('on-the-spot', 1), ('pantomimed', 1), ('top-grade', 1), ('visored', 1), ('spic', 1), ('epaulets', 1), ('entranceway', 1), ('haberdashery', 1), ('saw-horse', 1), ('signpost', 1), ('forays', 1), ('kissings', 1), ('huggings', 1), ('curdling', 1), ('twinge', 1), ('merrymaking', 1), ('beach-head', 1), ('gallants', 1), ('camaraderie', 1), ('cheered', 1), ('bleats', 1), ('rasps', 1), ('serenaded', 1), ('hawked', 1), ('marquees', 1), ('revellers', 1), ('impassable', 1), ('hatless', 1), ('herringbone', 1), ('worsted', 1), ('waffles', 1), ('toffenetti', 1), ('etiquette', 1), ('expectant', 1), ('corsage', 1), ('impending', 1), ('pompously', 1), ('lovingly', 1), ('timidity', 1), ('premonitions', 1), ('fleetest', 1), ('flustered', 1), ('fantasist', 1), ('schoolgirlish', 1), ('braids', 1), ('bunkmates', 1), ('jubilantly', 1), ('mum', 1), ('unbounded', 1), ('irresolution', 1), ('unimaginable', 1), ('bunkmate', 1), ('imitating', 1), ('communiques', 1), ('epistolatory', 1), ('studious', 1), ('configurations', 1), ('unsloped', 1), ('boroughs', 1), ('mess-hall', 1), ('footbridge', 1), ('intruded', 1), ('woeful', 1), ('severing', 1), ('spatter', 1), ('dresser', 1), ('lovie', 1), ('cockatoo', 1), ('breakables', 1), ('sheaf', 1), ('cherries', 1), ('dogwood', 1), ('hyacinths', 1), ('periwinkles', 1), ('jonquils', 1), ('citron', 1), ('polishes', 1), ('hinge', 1), ('swiped', 1), ('good-by', 1), ('unworn', 1), ('corduroys', 1), ('shoelace', 1), ('fleck', 1), ('pigskin', 1), ('clothesbrush', 1), ('thinness', 1), ('flounced', 1), ('cockeyed', 1), ('undid', 1), ('impudently', 1), ('jeannie', 1), ('bashful', 1), ('flops', 1), ('vulturidae', 1), ('tanganika', 1), ('fellers', 1), ('highboard', 1), ('showerhead', 1), ('sixty-eight', 1), ('cackly', 1), ('barnyard', 1), ('bustle', 1), ('tip-toe', 1), ('unnoticed', 1), ('beckon', 1), ('feller', 1), ('displeased', 1), ('pricked', 1), ('emanations', 1), ('coughing', 1), ('attentions', 1), ('shanked', 1), ('sforzando', 1), ('stair-well', 1), ('enquired', 1), ('alors', 1), ('tout', 1), ('dejeuners', 1), ('petits', 1), ('vos', 1), ('voulez', 1), ('protuberance', 1), ('matinals', 1), ('etes', 1), ('messieurs', 1), ('bonjour', 1), ('perturbation', 1), ('perceptible', 1), ('sequestration', 1), ('abed', 1), ('seven-thirty', 1), ('fowl', 1), ('lappets', 1), ('justness', 1), ('hackles', 1), ('excellences', 1), ('revery', 1), ('quacked', 1), ('turkeys', 1), ('gobbled', 1), ('hallways', 1), ('sure-enough', 1), ('medecine', 1), ('ecole', 1), ('gammas', 1), ('beta', 1), ('squawk', 1), ('scapulars', 1), ('eighty-three', 1), ('flumenophobe', 1), ('eared', 1), ('specimentalia', 1), ('unimposing', 1), ('undertakings', 1), ('smuggle', 1), ('oil-well', 1), ('farnworth', 1), ('full-of-the-moon', 1), ('well-rounded', 1), ('caliche-topped', 1), ('bye', 1), ('drouth', 1), ('windbag', 1), ('lucked', 1), ('odessa', 1), ('swingy', 1), ('smothering', 1), ('booming', 1), ('lura', 1), ('embracing', 1), ('unwrinkled', 1), ('grayed', 1), ('carload', 1), ('clucking', 1), ('evaporative', 1), ('albrights', 1), ('linoleum', 1), ('unpack', 1), ('reprieve', 1), ('sisters-in-law', 1), ('unready', 1), ('thankfulness', 1), ('smoothing', 1), ('crook', 1), ('perch', 1), ('harp', 1), ('cha-chas', 1), ('improvise', 1), ('parakeets', 1), ('realest', 1), ('partings', 1), ('protectively', 1), ('tate', 1), ('nicotine', 1), ('uncombable', 1), ('impaled', 1), ('toot-toot', 1), ('ferociously', 1), ('breaths', 1), ('peasanthood', 1), ('gardened', 1), ('money-making', 1), ('rutted', 1), ('defrost', 1), ('rumanian', 1), ('cleota', 1), ('mackinaw', 1), ('mistook', 1), ('disengagement', 1), ('caretaker', 1), ('wrestler', 1), ('nosed', 1), ('moralistic', 1), ('grunt', 1), ('skates', 1), ('cycly', 1), ('camden', 1), ('gear-sets', 1), ('broken-backed', 1), ('windfall', 1), ('monochromes', 1), ('gratings', 1), ('inventing', 1), ('cantilevers', 1), ('spidery', 1), ('bower', 1), ('high-topped', 1), ('believably', 1), ('childishness', 1), ('crafter', 1), ('rummel', 1), ('disputable', 1), ('unqualified', 1), ('o.k.', 1), ('privy', 1), ('pawing', 1), ('cleat', 1), ('sassing', 1), ('nightshirt', 1), ('cuff', 1), ('mother-naked', 1), ('pap-pap-pap-hey', 1), ('dandelion', 1), ('fuzzed', 1), ('sails', 1), ('cumulus', 1), ('mutuality', 1), ('knitted', 1), ('sloop', 1), ('headland', 1), ('clambering', 1), ('crags', 1), ('bride-gift', 1), ('fieldstone', 1), ('seaweed', 1), ('farmland', 1), ('fecund', 1), ('briefest', 1), ('uh-uh', 1), ('crotchety', 1), ('categorized', 1), ('covetousness', 1), ('contrition', 1), ('reigning', 1), ('selfishness', 1), ('impervious', 1), ('familiarness', 1), ('tilled', 1), ('greenly', 1), ('unendurable', 1), ('paling', 1), ('unreeling', 1), ('bassinet', 1), ('malignancies', 1), ('quirking', 1), ('dined', 1), ('densest', 1), ('mashing', 1), ('populate', 1), ('packards', 1), ('belligerently', 1), ('oblivion', 1), ('impaling', 1), ('dourly', 1), ('unself-conscious', 1), ('indefinable', 1), ('omissions', 1), ('blowfish', 1), ('repose', 1), ('uncousinly', 1), ('paled', 1), ('speculatively', 1), ('nibbed', 1), ('thwarting', 1), ('quaver', 1), ('authoritatively', 1), ('vellum', 1), ('lemons', 1), ('notification', 1), ('shun', 1), ('unashamedly', 1), ('scuff', 1), ('pari-mutuel', 1), ('starlight', 1), ('harried', 1), ('window-washing', 1), ('truthfulness', 1), ('depressors', 1), ('sighs', 1), ('riffle', 1), ('instantaneous', 1), ('cozier', 1), ('dyed', 1), ('scotch-and-soda', 1), ('surcliffes', 1), ('encyclopedias', 1), ('unwed', 1), ('gout', 1), ('littleton', 1), ('ryerson', 1), ('birthcontrol', 1), ('hewlitt', 1), ('gilkson', 1), ('surcliffe', 1), ('trempler', 1), ('eyke', 1), ('balcolm', 1), ('zenith', 1), ('acidity', 1), ('ammoniac', 1), ('fineness', 1), ('brae', 1), ('threadbare', 1), ('bewilderingly', 1), ('ungrateful', 1), ('trumps', 1), ('delancy', 1), ('mosquitoes', 1), ('physicalness', 1), ('bulks', 1), ('adjoins', 1), ('pasterns', 1), ('horse-chestnut', 1), ('mobcaps', 1), ('gnomes', 1), ('birdbath', 1), ('plaster-of-paris', 1), ('thackeray', 1), ('chekhov', 1), ('chafe', 1), ('parcels', 1), ('bade', 1), ('prie-dieu', 1), ('grovel', 1), ('accusingly', 1), ('pine-knot', 1), ('flecked', 1), ('bewilderedly', 1), ('mewed', 1), ('wheezed', 1), ('secesh', 1), ('bein', 1), ('fellas', 1), ('nighted', 1), ('gummy', 1), ('clotted', 1), ('cadaverous', 1), ('gesticulated', 1), ('incertain', 1), ('swamping', 1), ('haughtily', 1), ('supercilious', 1), ('unsteadily', 1), ('flounder', 1), ('elbowing', 1), ('cawing', 1), ('shambled', 1), ('clean-shaven', 1), ('stocky', 1), ('dented', 1), ('scuse', 1), ('belched', 1), ('skulk', 1), ('enervation', 1), ('dank', 1), ('exorcise', 1), ('safe-conduct', 1), ('pouch', 1), ('slimed', 1), ('urine', 1), ('rotting', 1), ('drumlin', 1), ('low-ceilinged', 1), ('thumbnail', 1), ('folding', 1), ('milbankes', 1), ('smallish', 1), ('languishing', 1), ('far-famed', 1), ('low-water', 1), ('byronism', 1), ('corinth', 1), ('caliphs', 1), ('thynnes', 1), ('raptures', 1), ('reprovingly', 1), ('southey', 1), ('contemptuously', 1), ('musings', 1), ('disowned', 1), ('pardonable', 1), ('detractor', 1), ('pensioner', 1), ('bonaparte', 1), ('scimitars', 1), ('sonorous', 1), ('parisina', 1), ('kindled', 1), ('undo', 1), ('buttoned', 1), ('untied', 1), ('poplin', 1), ('catechize', 1), ('unfaithful', 1), ('tis', 1), ('nymph', 1), ('io', 1), ('bacchus', 1), ('overpriced', 1), ('philosophized', 1), ('hostelries', 1), ('elba', 1), ('illicit', 1), ('modesty', 1), ('adonis', 1), ('palpably', 1), ('bluestocking', 1), ('seduction', 1), ('beadsman', 1), ('dashwood', 1), ('blasphemous', 1), ('conjured', 1), ('amorist', 1), ('depravities', 1), ('chancel', 1), ('self-flagellation', 1), ('scourge', 1), ('monkish', 1), ('dodington', 1), ('firsthand', 1), ('bloods', 1), ('cassocked', 1), ('regaled', 1), ('medmenham', 1), ('harpy', 1), ('jackdaws', 1), ('magpies', 1), ('doves', 1), ('cooing', 1), ('rosabelle', 1), ('forte-pianos', 1), ('daunt', 1), ('manservant', 1), ('entanglement', 1), ('bait', 1), ('dappled', 1), ('attired', 1), ('altercation', 1), ('ito', 1), ('deceive', 1), ('tableau', 1), ('effortlessly', 1), ('cuttings', 1), ('sushi', 1), ('yamata', 1), ('misinterpreted', 1), ('gosaimasu', 1), ('arigato', 1), ('kayabashi-san', 1), ('imagnation', 1), ('embellished', 1), ('gusto', 1), ('chiba', 1), ('indirection', 1), ('truthful', 1), ('guileless', 1), ('point-blank', 1), ('attentively', 1), ('pachinko', 1), ('stiffness', 1), ('indefatigable', 1), ('bishopry', 1), ('extinguish', 1), ('weatherbeaten', 1), ('redhook', 1), ('musclemen', 1), ('wharves', 1), ('watchmen', 1), ('towboats', 1), ('seafarers', 1), ('muscled', 1), ('layette', 1), ('christening', 1), ('apparel', 1), ('clannishness', 1), ('plug-ugly', 1), ('lecher', 1), ('beefy', 1), ('poker-faced', 1), ('hocking', 1), ('kale', 1), ('wheedled', 1), ('screechy', 1), ('self-effacing', 1), ('twotiming', 1), ('needled', 1), ('advisedly', 1), ('shacked', 1), ('postscript', 1), ('coffee-cup', 1), ('lowdown', 1), ('fellow-feeling', 1), ('nastiest', 1), ('exhusband', 1), ('exboyfriend', 1), ('olivefaced', 1), ('bleary', 1), ('percolator', 1), ('hairtonic', 1), ('sickish', 1), ('coffeepot', 1), ('hangovers', 1), ('remorseful', 1), ('lotion', 1), ('hummed', 1), ('wring', 1), ('dramatics', 1), ('highschool', 1), ('gabler', 1), ('hedda', 1), ('clumsily', 1), ('petrified', 1), ('one-thousand-zloty', 1), ('slurped', 1), ('barrack', 1), ('lentils', 1), ('bystrzyca', 1), ('dishonored', 1), ('shred', 1), ('zlotys', 1), ('bricklayers', 1), ('complains', 1), ('vociferously', 1), ('mustached', 1), ('brownish', 1), ('krakow', 1), ('litowski', 1), ('umschlagplatz', 1), ('refilled', 1), ('majdan-tartarski', 1), ('maniacs', 1), ('knee-deep', 1), ('einsatzkommandos', 1), ('crushers', 1), ('lashings', 1), ('krasnik', 1), ('budzyn', 1), ('krzywy-rog', 1), ('belzec', 1), ('poltawa', 1), ('chelmno', 1), ('sobibor', 1), ('lipowa', 1), ('madagascar', 1), ('lagers', 1), ('interlacing', 1), ('fountainhead', 1), ('funk', 1), ('himmler', 1), ('gauleiter', 1), ('odilo', 1), ('ana', 1), ('rumanians', 1), ('marshaling', 1), ('inched', 1), ('gnawed', 1), ('rak', 1), ('flirted', 1), ('aviv', 1), ('tel', 1), ('birthright', 1), ('zionism', 1), ('judea', 1), ('berated', 1), ('zionists', 1), ('unfertile', 1), ('irrigating', 1), ('alterman', 1), ('tolek', 1), ('bathyran', 1), ('leathered', 1), ('squires', 1), ('manors', 1), ('plenitude', 1), ('patriarchal', 1), ('wide-cut', 1), ('colonials', 1), ('wig', 1), ('retied', 1), ('meditate', 1), ('tenebrous', 1), ('perfectability', 1), ('wretch', 1), ('tarred', 1), ('hancock', 1), ('ingratitude', 1), ('manderscheid', 1), ('ledgers', 1), ('stropped', 1), ('intuitions', 1), ('tories', 1), ('calumny', 1), ('delirium', 1), ('bedpost', 1), ('knob', 1), ('stropping', 1), ('tepid', 1), ('mosquito', 1), ('pensive', 1), ('odyssey', 1), ('unshaved', 1), ('cutlass', 1), ('kentuck', 1), ('duyvil', 1), ('spuyten', 1), ('lobster-backed', 1), ('rockaways', 1), ('crusted', 1), ('verplanck', 1), ('fishkill', 1), ('dutchess', 1), ('wappinger', 1), ('gritty', 1), ('palisades', 1), ('frise', 1), ('chevaux', 1), ('gig', 1), ('men-of-war', 1), ('sterns', 1), ('glided', 1), ('ketches', 1), ('yachts', 1), ('herding', 1), ('paulus', 1), ('inlets', 1), ('digestible', 1), ('killable', 1), ('eatable', 1), ('mooncursers', 1), ('fishers', 1), ('snake-rail', 1), ('husbandry', 1), ('hayfields', 1), ('landowners', 1), ('bleaching', 1), ('crowing', 1), ('croaking', 1), ('bewhiskered', 1), ('blending', 1), ('weirs', 1), ('purling', 1), ('electrifying', 1), ('pothole', 1), ('trolls', 1), ('horseback', 1), ('minuet', 1), ('rensselaerwyck', 1), ('upstate', 1), ('lummox', 1), ('lace-drawn', 1), ('silver-gray', 1), ('sugared', 1), ('seahorse', 1), ('marvelously', 1), ('candlewick', 1), ('snuffer', 1), ('unsaid', 1), ('cove', 1), ('manumission', 1), ('enunciated', 1), ('gentians', 1), ('iced', 1), ('potomac', 1), ('insulted', 1), ('victoriously', 1), ('rejoice', 1), ('dere', 1), ('garbled', 1), ('grassfire', 1), ('maj.', 1), ('breckenridge', 1), ('federals', 1), (\"out'n\", 1), ('trinkets', 1), ('wares', 1), ('bawling', 1), ('restive', 1), ('brigade', 1), ('blackberry', 1), ('broadside', 1), ('raucously', 1), ('strapped', 1), ('moccasin', 1), ('cronies', 1), ('annie', 1), ('replanted', 1), ('portended', 1), ('postmark', 1), ('fitzroy', 1), ('drooped', 1), ('steeled', 1), ('crooning', 1), ('convulsively', 1), ('gush', 1), ('pigeons', 1), ('lippi', 1), ('chisels', 1), ('anvil', 1), ('campagna', 1), ('unteach', 1), ('jesuits', 1), ('rigorously', 1), ('plastically', 1), ('scratchiness', 1), ('translucence', 1), ('tuscany', 1), ('mid-fifties', 1), ('thirty-three', 1), ('roughed', 1), ('bolting', 1), ('toweling', 1), ('disrobe', 1), ('trestle', 1), ('dionigi', 1), ('carrara', 1), ('tenets', 1), ('graven', 1), ('gabardine', 1), ('robed', 1), ('1492', 1), ('ripa', 1), ('francesco', 1), ('hebraic', 1), ('substantive', 1), ('drapery', 1), ('life-size', 1), ('foreheads', 1), ('sweet-faced', 1), ('remotest', 1), ('full-grown', 1), ('resurrected', 1), ('halos', 1), ('pontius', 1), ('usurped', 1), ('grief-stricken', 1), ('lamentation', 1), (\"dell'arca\", 1), ('magdalene', 1), ('winding-clothes', 1), ('concorde', 1), ('hot-water', 1), ('eighties', 1), ('irelands', 1), ('vermouth', 1), ('blois', 1), ('coupons', 1), ('open-collared', 1), ('unpicturesque', 1), ('shoestrings', 1), ('aprons', 1), ('vouillemont', 1), ('scandalized', 1), ('astral', 1), ('da-da-da-dum', 1), ('velours', 1), ('dark-brown', 1), ('daybed', 1), ('lancret', 1), ('russet', 1), ('upholstered', 1), ('contradicted', 1), ('vienot', 1), ('bonenfant', 1), ('important-looking', 1), ('ornately', 1), ('berlitz', 1), ('ex-cuse', 1), ('black-market', 1), ('marmalade', 1), ('rudeness', 1), ('fauteuil', 1), ('spoonful', 1), ('breakfast-table', 1), ('dejeuner', 1), ('petit', 1), ('pantry', 1), ('teakettle', 1), ('flamed', 1), ('ki-yi-ing', 1), ('firecracker', 1), ('firecrackers', 1), ('barging', 1), ('dried-out', 1), ('sedate', 1), ('rimless', 1), ('fortifications', 1), ('fledglings', 1), ('insularity', 1), ('nods', 1), ('monosyllables', 1), ('inquisitor', 1), ('quilted', 1), ('matriarch', 1), ('herded', 1), ('brocaded', 1), ('unrevealing', 1), ('boatloads', 1), ('olives', 1), ('resiny', 1), ('skirting', 1), ('suppers', 1), ('lunchroom', 1), ('ringel', 1), ('degroot', 1), ('munching', 1), ('andruses', 1), ('buncha', 1), ('duane', 1), ('spurns', 1), ('luisa', 1), ('play-acting', 1), ('uselessness', 1), ('crank', 1), ('groggy', 1), ('drugging', 1), ('mug', 1), ('notebook', 1), ('blinkers', 1), ('deadened', 1), ('unservile', 1), ('overcurious', 1), ('westwood', 1), ('gauged', 1), ('southernisms', 1), ('crudities', 1), ('thanking', 1), ('irv', 1), ('irvin', 1), ('106', 1), ('nother', 1), ('swathings', 1), ('consoled', 1), ('flaunting', 1), ('essayed', 1), ('terry-cloth', 1), ('wrack', 1), ('spume', 1), ('easthampton', 1), ('lobscouse', 1), ('hoo-pig', 1), ('corkscrew', 1), ('lak', 1), (\"gre't\", 1), ('blaustein', 1), ('veining', 1), ('flail', 1), ('maniacal', 1), ('cornfield', 1), ('lice', 1), ('skirmishing', 1), ('hutments', 1), ('yonder', 1), ('thickening', 1), ('riven', 1), ('hawksworth', 1), ('jed', 1), ('hasps', 1), ('bhoy', 1), ('perilously', 1), ('swathed', 1), ('emptiness', 1), ('grayer', 1), ('slacking', 1), ('rubberized', 1), ('campmate', 1), ('armful', 1), ('untellable', 1), ('lemme', 1), ('trustfully', 1), ('emit', 1), ('bestubbled', 1), ('covertly', 1), ('chaffing', 1), ('shaven', 1), ('lairs', 1), ('sopping', 1), ('sluggishly', 1), ('cranky', 1), ('tenting', 1), ('doorways', 1), ('chinked', 1), ('hutment', 1), ('loblolly', 1), ('befogged', 1), ('torpid', 1), ('expiating', 1), ('pfennig', 1), ('aimlessly', 1), ('bitters', 1), ('toffee', 1), ('hardbake', 1), ('bristling', 1), ('growling', 1), ('pummeled', 1), ('dizzily', 1), ('heretic', 1), ('arianist', 1), ('gaspard', 1), ('premonition', 1), ('molard', 1), ('syndic', 1), ('leavened', 1), (\"lord's\", 1), ('anabaptist', 1), ('unmasked', 1), ('arianists', 1), ('arianism', 1), ('benoit', 1), ('anabaptists', 1), ('tiredly', 1), ('ashen', 1), ('gospelers', 1), ('near-blind', 1), ('corault', 1), ('reverie', 1), ('meditated', 1), ('blasphemed', 1), ('stabbed', 1), ('plied', 1), ('smashing', 1), ('waldensian', 1), ('tillet', 1), ('bucer', 1), ('glittered', 1), ('insurmountable', 1), ('clemence', 1), ('parchment', 1), ('crunched', 1), ('rooftops', 1), ('specters', 1), ('rumbling', 1), ('raftered', 1), ('lilt', 1), ('noyon-la-sainte', 1), ('varnessa', 1), ('mommor', 1), ('eloi', 1), ('gibbet', 1), ('evildoers', 1), ('throttling', 1), ('berthelier', 1), ('philibert', 1), ('brazenly', 1), ('poupin', 1), ('high-backed', 1), ('rudely', 1), ('dishonor', 1), ('brazen', 1), ('blasphemy', 1), ('reprobate', 1), ('breeches', 1), ('braver', 1), ('pimples', 1), ('mattathias', 1), ('narrowness', 1), ('brisker', 1), ('slow-moving', 1), ('sympathizing', 1), ('handfuls', 1), ('thirst', 1), ('mooed', 1), ('low-lying', 1), ('viselike', 1), ('sobbing', 1), ('pipers', 1), ('drummers', 1), ('crazed', 1), ('booted', 1), ('showy', 1), ('priming', 1), ('flint', 1), ('deplorably', 1), ('storekeepers', 1), ('spurring', 1), ('inane', 1), ('obeys', 1), ('slovenliness', 1), ('pompadour', 1), ('raynal', 1), ('confessions', 1), ('perspiration', 1), ('titillating', 1), ('unperformed', 1), ('soothsayer', 1), (\"d'aumont\", 1), ('self-effacement', 1), ('austerity', 1), ('fontainebleau', 1), ('anonymity', 1), ('fabricius', 1), ('prosopopoeia', 1), ('armide', 1), ('rehearse', 1), ('bah', 1), ('craved', 1), ('nothings', 1), ('replying', 1), ('stoutly', 1), ('muses', 1), ('subterfuges', 1), ('misanthrope', 1), ('timon', 1), ('souci', 1), ('sans', 1), ('depraved', 1), ('bedraggled', 1), ('perseveres', 1), ('pricks', 1), ('breakin', 1), ('christsake', 1), ('dreamin', 1), ('nut-house', 1), ('caved', 1), ('shrank', 1), ('nailing', 1), ('fucks', 1), ('croaked', 1), ('asses', 1), ('stupidest', 1), ('bullshit', 1), ('willya', 1), ('testily', 1), ('stirrin', 1), ('waitin', 1), ('keeeerist', 1), ('cavin', 1), ('glob-flakes', 1), ('wised', 1), ('goofed', 1), ('thorn', 1), ('soft-spoken', 1), ('sleepy-eyed', 1), ('mutilated', 1), ('bumpin', 1), ('warmongering', 1), ('lackeys', 1), ('pow', 1), ('culprits', 1), ('jiving', 1), ('squashing', 1), ('twinges', 1), ('keerist', 1), ('croakin', 1), ('wanta', 1), ('redheader', 1), ('thum', 1), ('kaboom', 1), ('sonuvabitch', 1), ('yooee', 1), ('sus', 1), ('jee', 1), ('lovin', 1), ('shack', 1), ('haint', 1), ('krist', 1), ('boardinghouses', 1), ('p.j.', 1), ('tinkled', 1), ('fiddles', 1), ('haughty', 1), ('insolent', 1), ('verandah', 1), ('mustaches', 1), ('boaters', 1), ('meandered', 1), ('doghouse', 1), ('pinafores', 1), ('christophers', 1), ('jingled', 1), ('shivery', 1), ('ice-chest', 1), ('overheated', 1), ('yankton', 1), ('chased', 1), ('shooters', 1), ('slingshot', 1), ('mite-box', 1), ('brimmed', 1), ('sweet-smelling', 1), ('aghast', 1), ('twigged', 1), ('mountainsides', 1), ('wrathful', 1), ('hackettstown', 1), ('burt', 1), ('townley', 1), ('indentations', 1), ('lipped', 1), ('deathly', 1), ('luminescence', 1), ('wreathed', 1), ('coattails', 1), ('curtained', 1), ('pews', 1), ('wainscoted', 1), ('shuffled', 1), ('peaked', 1), ('howe', 1), ('paterson', 1), (\"he'll\", 1), ('chugging', 1), ('idols', 1), ('cuddleback', 1), ('rove', 1), ('excursions', 1), ('tri-state', 1), ('underbrush', 1), ('matamoras', 1), ('tollhouse', 1), ('erie', 1), ('journeyed', 1), ('sunday-school', 1), ('tollgate', 1), ('hulking', 1), ('belfry', 1), ('sussex', 1), ('foothills', 1), ('jervis', 1), ('broome', 1), ('cupboards', 1), ('alligatored', 1), ('pendulum', 1), ('vibrated', 1), ('trainman', 1), (\"we're\", 1), ('mangled', 1), ('nudging', 1), ('hooted', 1), ('clamshell', 1), ('chortling', 1), ('slavered', 1), ('gloated', 1), ('iron-shod', 1), ('wickedly', 1), ('agilely', 1), ('silky', 1), ('ferocity', 1), ('toppling', 1), ('bridle', 1), ('seizing', 1), ('nimbler', 1), ('midair', 1), ('sneer', 1), ('leale', 1), ('hoist', 1), ('taft', 1), ('beehive', 1), ('self-indulgence', 1), ('mistaking', 1), ('maimed', 1), ('octoroon', 1), ('faltered', 1), ('leapt', 1), ('billowed', 1), ('tyrannis', 1), ('semper', 1), ('soundproof', 1), ('mantrap', 1), ('sockdologizing', 1), ('boo', 1), ('practised', 1), ('edwina', 1), ('giles', 1), ('soothed', 1), ('surfeited', 1), ('tousled', 1), ('wakes', 1), ('nightdress', 1), ('hacked', 1), ('punish', 1), ('nightmares', 1), ('exultantly', 1), ('misfired', 1), ('pantomime', 1), ('clodhoppers', 1), ('gaiters', 1), ('lumbered', 1), ('banisters', 1), ('synchronize', 1), ('doorbell', 1), ('clomped', 1), ('gentry', 1), ('chemist', 1), ('rut', 1), ('business-like', 1), ('privies', 1), ('dumps', 1), ('cosily', 1), ('pliant', 1), ('deacons', 1), ('avenging', 1), ('dissenter', 1), ('rat-holes', 1), ('parsonage', 1), ('sympathized', 1), ('man-to-man', 1), ('disgust', 1), ('re-enacted', 1), ('death-like', 1), ('contortion', 1), ('re-enacting', 1), ('conversational', 1), ('worshippers', 1), ('orgy', 1), ('loud-voiced', 1), ('calamities', 1), ('tallahoosa', 1), ('seventy-five', 1), ('annisberg', 1), ('piss', 1), ('werther', 1), ('krautheads', 1), ('crucifying', 1), ('bluster', 1), ('discourteous', 1), ('wilkes-barre', 1), ('cut-glass', 1), ('well-bound', 1), ('renoir', 1), ('florentine', 1), ('distrusted', 1), ('furtive', 1), ('underhanded', 1), ('lorelei', 1), ('cripple', 1), ('vernal', 1), ('deliciously', 1), ('pharmacist', 1), ('chastity', 1), ('citations', 1), ('dsm', 1), ('nigras', 1), ('davao', 1), ('paralyzes', 1), ('rank-and-file', 1), ('concussion', 1), ('inscrutable', 1), ('altruism', 1), ('sorting', 1), ('hideaway', 1), ('shopkeepers', 1), ('moonan', 1), ('eloise', 1), ('elfin', 1), ('black-haired', 1), ('whisky-on-the-rocks', 1), ('protestations', 1), ('solesmes', 1), ('healthiest', 1), ('infirmity', 1), ('merveilleux', 1), ('oui', 1), ('handless', 1), ('foreigner', 1), ('vouching', 1), ('brest', 1), ('shipyards', 1), ('handlebars', 1), ('stone-gray', 1), ('exultation', 1), ('damnation', 1), ('grotesques', 1), ('pallid', 1), ('beatings', 1), ('snugly', 1), ('armpits', 1), ('overheat', 1), ('bandoleers', 1), ('furtively', 1), ('radiance', 1), ('diffused', 1), ('malevolencies', 1), ('gnaw', 1), ('enchained', 1), ('nocturnal', 1), ('pant-legs', 1), ('stealthily', 1), ('overhang', 1), ('2230', 1), ('searchlights', 1), ('betties', 1), ('kinder', 1), ('2130', 1), ('0600', 1), ('briefed', 1), ('unlovely', 1), ('spill', 1), ('lulls', 1), ('weirdly', 1), ('concertina', 1), ('womb', 1), ('reigned', 1), ('hulk', 1), ('gouge', 1), ('glacier', 1), ('invariable', 1), ('annoys', 1), ('estherson', 1), ('irritability', 1), ('disinterest', 1), ('fussily', 1), ('unsmilingly', 1), ('moth', 1), ('veined', 1), ('teasing', 1), ('slim-waisted', 1), ('draughty', 1), ('rediscover', 1), ('store-front', 1), ('querulous', 1), ('overindulged', 1), ('whitely', 1), (\"he's\", 1), ('sectioned', 1), ('crested', 1), ('grizzled', 1), ('blueberry', 1), ('banners', 1), ('baronial', 1), ('stainless-steel', 1), ('lengthily', 1), ('gpd', 1), ('147000', 1), ('nuisances', 1), ('9.3', 1), ('determinations', 1), ('predomination', 1), ('ciliates', 1), ('protozoan', 1), ('predominated', 1), ('flagellated', 1), ('mckinney', 1), ('microbial', 1), ('resuspension', 1), ('1.2', 1), ('14.5', 1), ('mlss', 1), ('metabolized', 1), ('grindings', 1), ('6.4', 1), ('volumetric', 1), ('cu', 1), ('slippage', 1), ('710', 1), ('composites', 1), ('metered', 1), ('314', 1), ('contributor', 1), ('121000', 1), ('anaerobic', 1), ('aerobic', 1), ('1230', 1), ('4.77', 1), ('yrs.', 1), ('weston', 1), ('effluents', 1), ('aegis', 1), ('householders', 1), ('lower-middle-class', 1), ('cheap-money', 1), ('superhighways', 1), ('suburbanites', 1), ('tunnard', 1), ('diagnosticians', 1), ('accountants', 1), ('big-ticket', 1), ('gadgetry', 1), ('shopper', 1), ('inducement', 1), ('46000', 1), ('indiscriminate', 1), ('lazarus', 1), ('suburbanized', 1), ('profitability', 1), ('recalculated', 1), ('shopping-center', 1), ('hotelman', 1), ('retailer', 1), ('converged', 1), ('congregated', 1), ('haberdasheries', 1), ('drugstores', 1), ('central-city', 1), ('hotel-motel', 1), ('outskirt', 1), ('cost-plus', 1), ('non-competitive', 1), ('polaroid', 1), ('by-pass', 1), ('thruways', 1), ('syracuse', 1), ('walk-to', 1), ('trucking', 1), ('long-haul', 1), ('akron', 1), ('slighter', 1), ('roadways', 1), ('subways', 1), ('ruinous', 1), ('accesses', 1), ('grade-constructed', 1), ('rapid-transit', 1), ('skyscraper', 1), ('extruded', 1), ('legibility', 1), ('exhaustively', 1), ('colles', 1), ('papiers', 1), ('re-emerged', 1), ('chain-reaction', 1), ('atom-like', 1), ('coalesce', 1), ('plumped', 1), ('verge', 1), ('hermetic', 1), ('unrecognizable', 1), ('obliterating', 1), ('expropriated', 1), ('disembodied', 1), ('imaging', 1), ('reemerged', 1), ('re-created', 1), ('re-creates', 1), ('underpins', 1), ('transforms', 1), ('reacts', 1), ('fictive', 1), ('pictorially', 1), ('optically', 1), ('eye-deceiving', 1), ('woodgraining', 1), ('corporeality', 1), ('charcoaled', 1), ('flatnesses', 1), (\"trompe-l'oeil\", 1), ('conventionally', 1), ('surfaceness', 1), ('boomerangs', 1), ('overshoots', 1), ('extraneousness', 1), ('corporeal', 1), ('caning', 1), ('woodgrain', 1), ('pasting', 1), ('fusing', 1), ('telescoping', 1), ('shuttling', 1), ('marbleizing', 1), ('graining', 1), ('contrivances', 1), (\"arm's\", 1), ('facet-plane', 1), ('bereavements', 1), ('risked', 1), ('impropriety', 1), ('servile', 1), ('free-will', 1), ('garrisonian', 1), ('ex-mayor', 1), ('tolled', 1), ('fanatics', 1), ('pluck', 1), ('quakeress', 1), ('bedford', 1), ('anemated', 1), ('non-resistants', 1), ('reprinted', 1), ('elisha', 1), ('know-nothing', 1), ('remnant', 1), ('override', 1), ('extenuating', 1), ('advertiser', 1), ('instigate', 1), ('actuated', 1), ('philantropists', 1), ('misnamed', 1), ('butchered', 1), ('fairer', 1), ('inciting', 1), ('misrepresenting', 1), ('magistrates', 1), ('refectories', 1), ('infirm', 1), ('1516', 1), ('elaborates', 1), ('atreus', 1), ('aeschylus', 1), ('agamemnon', 1), ('ineptly', 1), ('sieve', 1), ('bottomless', 1), ('unwisely', 1), ('safeguards', 1), ('unalterable', 1), ('severalty', 1), ('stoics', 1), ('athleticism', 1), ('novitiate', 1), ('statu', 1), ('reipublicae', 1), ('optimo', 1), ('lumpish', 1), ('ruling-class', 1), ('excursus', 1), ('janissaries', 1), ('anachronistically', 1), ('communistic', 1), ('sharpen', 1), ('1515', 1), ('full-clad', 1), ('monasteries', 1), ('truest', 1), ('perennially', 1), ('inconceivable', 1), ('machiavelli', 1), ('niccolo', 1), ('tenuously', 1), ('philological', 1), ('erasmus', 1), ('papal', 1), ('regius', 1), ('imbecile', 1), ('callousness', 1), ('dispossessed', 1), ('brutalities', 1), ('solemnity', 1), ('sedulously', 1), ('quam', 1), ('salutaris', 1), ('nec', 1), ('overflow', 1), ('phantasy', 1), ('tie-in', 1), ('transformers', 1), ('sub-station', 1), ('hydro-electric', 1), ('1904', 1), ('intending', 1), ('creamery', 1), ('dellwood', 1), ('ormsby', 1), ('isham', 1), ('gristmill', 1), ('colvin', 1), ('2490', 1), ('briggs', 1), ('erecting', 1), ('1918', 1), ('troubleshooter', 1), ('hemenway', 1), ('switchboard', 1), ('carleton', 1), ('eber', 1), ('bourn', 1), ('mercier', 1), ('goyette', 1), ('heckman', 1), ('ellamae', 1), ('simplex', 1), ('basked', 1), ('telegraphed', 1), ('ekwanok', 1), ('flocked', 1), ('cambridgeport', 1), ('lowell', 1), ('sirloin', 1), ('porterhouse', 1), ('peremptory', 1), ('koop', 1), ('pettibone', 1), ('flimsy', 1), ('holley', 1), ('1878', 1), ('editorially', 1), ('1871', 1), ('watchmaker', 1), ('1846', 1), ('wickham', 1), ('telegraphy', 1), ('230000', 1), ('selectmen', 1), ('connell', 1), ('gun-shot', 1), ('posseman', 1), ('celso', 1), ('prowling', 1), ('a.m.', 1), ('asher', 1), ('litigants', 1), ('docketed', 1), ('colfax', 1), ('self-defense', 1), ('ambuscade', 1), ('lavato', 1), ('bonito', 1), ('underrated', 1), ('possemen', 1), ('chaves', 1), ('assassins', 1), ('garnett', 1), ('suspecting', 1), ('horse-trail', 1), ('archuleta', 1), ('flor', 1), ('pena', 1), ('julio', 1), ('daybreak', 1), ('affidavits', 1), ('exporters', 1), ('cyclades', 1), ('syrian', 1), ('frieze', 1), ('rosettes', 1), ('all-over', 1), ('ornaments', 1), ('eschewed', 1), ('sunder', 1), ('archaized', 1), ('anthropomorphic', 1), ('basileis', 1), ('janus-faced', 1), ('premonitory', 1), ('presage', 1), ('figurines', 1), ('broadens', 1), ('excavations', 1), ('turnings', 1), ('self-awareness', 1), ('crystallized', 1), ('enduringly', 1), ('survivals', 1), ('boeotian', 1), ('argive', 1), ('ascertainable', 1), ('attica', 1), ('excepting', 1), ('south-eastern', 1), ('irruptions', 1), ('mycenaean', 1), ('minoan', 1), ('embryo', 1), ('argos', 1), ('deducing', 1), ('hexameter', 1), ('epics', 1), ('homeric', 1), ('9b', 1), ('6a', 1), ('tactually', 1), ('kinesthetically', 1), ('readapting', 1), ('merest', 1), ('surmise', 1), ('figural', 1), ('memory-pictures', 1), ('corroborate', 1), ('hand-written', 1), ('hasher', 1), ('concretely', 1), ('subfigures', 1), ('discerned', 1), ('long-familiar', 1), ('every-day', 1), ('eyesight', 1), ('undamaged', 1), ('abnormalities', 1), ('passively', 1), ('skin-perceptiveness', 1), ('third-dimensionality', 1), ('spatiality', 1), ('memory-picture', 1), ('conjure', 1), ('cerebellum', 1), ('miner', 1), ('needlessly', 1), ('repulsion', 1), ('siberian', 1), ('subjectivists', 1), ('nonoccurrence', 1), ('groundless', 1), ('repugnance', 1), ('passer-by', 1), ('whit', 1), ('excruciating', 1), ('commoner', 1), ('fiddlesticks', 1), ('squeaky', 1), ('protectorate', 1), ('disqualified', 1), ('dispensation', 1), ('inescapably', 1), ('mellal', 1), ('bani', 1), ('qua', 1), ('u.m.t.', 1), ('populaires', 1), ('artisans', 1), ('industrialistes', 1), ('commercants', 1), ('marocaine', 1), ('rabat', 1), ('maximize', 1), ('unearth', 1), ('duverger', 1), ('liste', 1), ('uninominal', 1), ('self-interest', 1), ('repudiate', 1), ('procrastinate', 1), ('clamor', 1), ('labyrinth', 1), ('titre', 1), ('abdallah', 1), ('let-down', 1), ('populaire', 1), ('mouvement', 1), ('ifni', 1), ('maroc', 1), ('predominance', 1), (\"l'independance\", 1), ('democratique', 1), ('parti', 1), ('/5', 1), ('muhammad', 1), ('bekkai', 1), ('mubarak', 1), ('si', 1), ('regionally', 1), ('procrastination', 1), ('prescriptions', 1), ('embody', 1), ('crusades', 1), ('energizes', 1), ('yinger', 1), ('sociability', 1), ('integrating', 1), ('semi-public', 1), ('denominationally', 1), ('reasserting', 1), ('sanctified', 1), ('socializes', 1), ('dogmas', 1), ('creeds', 1), ('totemic', 1), ('interpretable', 1), ('tampering', 1), ('law-breaking', 1), ('sacrament', 1), ('intermediary', 1), ('religionists', 1), ('freewheelers', 1), ('universalistic', 1), ('atheistic', 1), ('reaffirms', 1), ('re-enforces', 1), ('value-system', 1), ('father-god', 1), ('all-victorious', 1), ('failures', 1), ('humilation', 1), ('repentance', 1), ('tormenting', 1), ('sinning', 1), ('redress', 1), ('anomie', 1), ('widowhood', 1), ('humanistic', 1), ('theistic', 1), ('creativeness', 1), ('sociality', 1), ('incitements', 1), ('clarifies', 1), ('moderns', 1), ('epitomize', 1), ('pacification', 1), ('pertinence', 1), ('anomic', 1), ('dominantly', 1), ('preliterate', 1), ('marginally', 1), ('free-world', 1), ('pluralistic', 1), ('constraining', 1), ('upper-level', 1), ('deficient', 1), ('decentralizing', 1), ('interrelationships', 1), ('advisor', 1), ('modernize', 1), ('self-discipline', 1), ('erratically', 1), ('forward-moving', 1), ('disrupting', 1), ('recreated', 1), ('oblique', 1), ('ordinates', 1), ('**f-values', 1), ('s-values', 1), ('pq', 1), ('analyticity', 1), ('extrema', 1), ('cartesian', 1), ('lemmas', 1), ('abscissa', 1), ('endpoints', 1), ('convexity', 1), ('cairns', 1), ('yujobo', 1), ('yamabe', 1), ('convex', 1), ('cube', 1), ('kakutani', 1), ('baseline', 1), ('constancy', 1), ('n-trial', 1), ('0.70', 1), ('0.52', 1), ('0.16', 1), ('0.36', 1), ('dazzles', 1), ('hairless', 1), ('nondriver', 1), ('solves', 1), ('exponential', 1), ('expressible', 1), ('n-dimensional', 1), ('subspaces', 1), ('integers', 1), ('irreducible', 1), ('decomposing', 1), ('imbalance', 1), ('psychotic', 1), ('psychopharmacological', 1), ('incompatibility', 1), ('catecholamines', 1), ('excretion', 1), ('ergotropic', 1), ('tropho', 1), ('assertiveness', 1), ('salivary', 1), ('reversibility', 1), ('pavlov', 1), ('neuronal', 1), ('psychosomatic', 1), ('pharmacological', 1), ('disjointed', 1), ('desynchronizing', 1), ('elicit', 1), ('altering', 1), ('metrazol', 1), ('electroshocks', 1), ('comas', 1), ('behavioral', 1), ('elicits', 1), ('reversal', 1), ('elucidated', 1), ('clinically', 1), ('cardiovascular', 1), ('noradrenalin', 1), ('impairment', 1), ('remissions', 1), ('hypo', 1), ('secretions', 1), ('hypophyseal', 1), ('hypothalamically', 1), ('therapies', 1), ('maniclike', 1), ('chlorpromazine', 1), ('reserpine', 1), ('baroreceptor', 1), ('barbiturate', 1), ('facilitatory', 1), ('paleocortical', 1), ('limbic', 1), ('maclean', 1), ('mirsky', 1), ('primates', 1), ('paleo', 1), ('extinguished', 1), ('cortically', 1), ('vertebrates', 1), ('infect', 1), ('phloem', 1), ('brakke', 1), ('transmissible', 1), ('leafhopper', 1), ('isocyanate', 1), ('littau', 1), ('pith', 1), ('bluish', 1), ('whitcomb', 1), ('precipitin', 1), ('incited', 1), ('conjugating', 1), ('sweet-clover', 1), ('rinsing', 1), ('schott', 1), ('residual', 1), ('wratten', 1), ('eyepiece', 1), ('corning', 1), ('hbo', 1), ('osram', 1), ('wolcyrz', 1), ('undiluted', 1), ('layered', 1), ('johansen', 1), ('haupts', 1), ('cryostat', 1), ('quick-frozen', 1), ('ade', 1), ('dineen', 1), ('lyophilized', 1), ('ammonium', 1), ('precipitate', 1), ('conn', 1), ('townsend', 1), ('tumefaciens', 1), ('agrobacterium', 1), ('trichrome', 1), ('regenerating', 1), ('vesicular', 1), ('inflammatory', 1), ('phagocytes', 1), ('flocculated', 1), ('protoplasm', 1), ('myofibrils', 1), ('eosinophilic', 1), ('necrotic', 1), ('brachii', 1), ('abdominis', 1), ('extremities', 1), ('megakaryocytic', 1), ('myeloid', 1), ('erythroid', 1), ('hypocellularity', 1), ('alternating', 1), ('hypercellularity', 1), ('sternum', 1), ('adenomas', 1), ('papillary', 1), ('afferent', 1), ('hyalinization', 1), ('admixed', 1), ('hyaline', 1), ('tubules', 1), ('lymphocytes', 1), ('punctuated', 1), ('coarsely', 1), ('anhemolyticus', 1), ('streptococcus', 1), ('aerogenes', 1), ('aerobacter', 1), ('pyocanea', 1), ('pseudomonas', 1), ('albicans', 1), ('monilia', 1), ('ulcerations', 1), ('thrombi', 1), ('edematous', 1), ('ileum', 1), ('focally', 1), ('gram-negative', 1), ('cytolysis', 1), ('mesenteric', 1), ('sanguineous', 1), ('intestine', 1), ('intestines', 1), ('calculi', 1), ('dark-green', 1), ('gallbladder', 1), ('vacuolated', 1), ('2090', 1), ('granulocytic', 1), ('nucleated', 1), ('endothelial', 1), ('macrophages', 1), ('nodules', 1), ('fibrocalcific', 1), ('blebs', 1), ('emphysematous', 1), ('950', 1), ('iliac', 1), ('calcified', 1), ('celiac', 1), ('renal', 1), ('yellow-brown', 1), ('confluent', 1), ('intimal', 1), ('mononuclear', 1), ('clefts', 1), ('fusiform', 1), ('hypertrophied', 1), ('mitral', 1), ('myocardium', 1), ('plaque', 1), ('atheromatous', 1), ('diffusely', 1), ('sclerotic', 1), ('ventricles', 1), ('outflow', 1), ('510', 1), ('edentulous', 1), ('senilis', 1), ('arcus', 1), ('pterygia', 1), ('lb.', 1), ('debilitated', 1), ('distension', 1), ('demineralization', 1), ('hemorrhoids', 1), ('thrombosed', 1), ('urinary', 1), ('norethandrolone', 1), ('lactate', 1), ('d8', 1), ('osteoporosis', 1), ('hypoadrenocorticism', 1), ('anorexia', 1), ('propylthiouracil', 1), ('intramuscularly', 1), ('gel', 1), ('acth', 1), ('corticotropin', 1), ('polymyositis', 1), ('min.', 1), ('ml.', 1), ('transaminase', 1), ('oxaloacetic', 1), ('glutamic', 1), ('shrunken', 1), ('sarcolemmal', 1), ('schilling', 1), ('6.6', 1), ('neuron', 1), ('electromyography', 1), ('fasciculations', 1), ('tendon', 1), ('hypoactive', 1), ('girdle', 1), ('neuromuscular', 1), ('quadriceps', 1), ('13.9', 1), ('meq.', 1), ('3.8', 1), ('musculature', 1), ('caving', 1), ('13.8', 1), ('hemolytic', 1), ('congestive', 1), ('anticoagulation', 1), ('digitalization', 1), ('11.6', 1), ('cholelithiasis', 1), ('obliterans', 1), ('arteriosclerosis', 1), ('cardiomegaly', 1), ('infarction', 1), ('myelofibrosis', 1), ('foci', 1), ('sternal', 1), ('splenomegaly', 1), ('accountant', 1), ('refractory', 1), ('necropsy', 1), ('biopsies', 1), ('corticosteroids', 1), ('equipotent', 1), ('mussett', 1), ('re-introduction', 1), ('re-emphasise', 1), ('pharmacopoeia', 1), ('thyrotoxic', 1), ('long-acting', 1), ('abnormally', 1), ('synthesised', 1), ('wynston', 1), ('carsten', 1), ('condliffe', 1), ('sonenberg', 1), ('solvents', 1), ('trichloroacetic', 1), ('loeser', 1), ('tadpoles', 1), ('hypophysectomised', 1), ('thyroids', 1), ('atrophied', 1), ('re-activate', 1), ('niepce', 1), ('assaying', 1), ('thyroidal', 1), ('follicular', 1), ('thyrotrophic', 1), ('thyrotrophin', 1), ('thyroid-stimulating', 1), ('iodothyronines', 1), ('de-iodinated', 1), ('re-use', 1), ('castillo', 1), ('itoiz', 1), ('perinetti', 1), ('riggs', 1), ('brownell', 1), ('hyperplasia', 1), ('secreted', 1), ('wishart', 1), ('brassica', 1), ('rutabaga', 1), ('oxazolidone', 1), ('thio', 1), ('vinyl', 1), ('antagonised', 1), ('counteracted', 1), ('hypothyroidism', 1), ('astwood', 1), ('iodinate', 1), ('inhibits', 1), ('fluoroboride', 1), ('perchlorate', 1), ('thiocyanate', 1), ('anion', 1), ('univalent', 1), ('freinkel', 1), ('ingbar', 1), ('de-iodination', 1), ('re-incorporated', 1), ('iodotyrosines', 1), ('de-iodinate', 1), ('triphosphopyridine', 1), ('de-iodinase', 1), ('microsomal', 1), ('proteolytic', 1), ('petermann', 1), ('macromolecular', 1), ('degradation', 1), ('protease', 1), ('trikojus', 1), ('mcquillan', 1), ('5.7', 1), ('3.7', 1), ('peptidases', 1), ('amino', 1), ('congenital', 1), ('tumours', 1), ('transplantable', 1), ('seq.', 1), ('iodocompounds', 1), ('enzymatic', 1), ('pitt-rivers', 1), ('analogues', 1), ('non-enzymatic', 1), ('thyronine', 1), ('iodoamino', 1), ('iodoprotein', 1), ('carvalho', 1), ('groot', 1), ('serif', 1), ('tong', 1), ('fawcett', 1), ('glycosides', 1), ('digitalis', 1), ('menarches', 1), ('counter-balanced', 1), ('.50', 1), ('25.3', 1), ('arrayed', 1), ('monograph', 1), ('prepubescent', 1), ('juxtaposition', 1), ('adulthood', 1), ('necessitates', 1), ('calcification', 1), ('ossify', 1), ('terminates', 1), ('lobularity', 1), ('tabulation', 1), ('interspecies', 1), ('histology', 1), ('anatomic', 1), ('grindlay', 1), ('uninjectable', 1), ('inoperable', 1), ('daly', 1), ('brailsford', 1), ('perfusion', 1), ('nonfunctional', 1), ('hayek', 1), ('gilroy', 1), ('marchand', 1), ('ruysch', 1), ('1721', 1), ('degeneration', 1), ('occlusive', 1), ('alveolus', 1), ('nutritive', 1), ('comroe', 1), ('intrapulmonary', 1), ('loosli', 1), ('pathologic', 1), ('cudkowicz', 1), ('1858', 1), ('birnbaum', 1), ('lobular', 1), ('bronchiolitis', 1), ('monkeys', 1), ('morphology', 1), ('lindskog', 1), ('morphologic', 1), ('airflow', 1), ('inter-species', 1), ('bronchiolar', 1), ('anastomosis', 1), ('net-like', 1), ('anastomotic', 1), ('distally', 1), ('lobule', 1), ('septation', 1), ('haphazardly', 1), ('terminating', 1), ('duct', 1), ('snout', 1), ('kauffeld', 1), ('hoge', 1), ('alphonse', 1), ('collated', 1), ('constrictors', 1), ('petroleum', 1), ('lamon', 1), ('roberto', 1), ('colombia', 1), ('herpetologist', 1), ('amaral', 1), ('afranio', 1), ('quelch', 1), ('schweizer', 1), ('seventy-two', 1), ('estuaries', 1), ('orinoco', 1), ('urich', 1), ('senile', 1), ('amplification', 1), ('thirteenth', 1), ('leans', 1), ('err', 1), ('ointment', 1), ('pitfalls', 1), ('monsters', 1), ('ancistrodon', 1), ('cottonmouth', 1), ('storeria', 1), ('red-bellied', 1), ('tropidoclonion', 1), ('rattlers', 1), ('paucity', 1), ('captives', 1), ('quadrupling', 1), ('kopstein', 1), ('thamnophis', 1), ('laurence', 1), ('fine-grained', 1), ('inhospitable', 1), ('prosser', 1), ('yakima', 1), ('prepupal', 1), ('bohart', 1), ('melanderi', 1), ('nomia', 1), ('larval', 1), ('pupated', 1), ('digs', 1), ('mounds', 1), ('intruder', 1), ('amiss', 1), ('unobtrusively', 1), ('parasite', 1), ('idler', 1), ('victimize', 1), ('deceptively', 1), ('cuckoo', 1), ('onslaughts', 1), ('hardworking', 1), ('idlers', 1), ('beetles', 1), ('scavenging', 1), ('unfertilized', 1), ('pupates', 1), ('papery', 1), ('incubating', 1), ('waxen', 1), ('woodpecker', 1), ('choosy', 1), ('befits', 1), ('hideout', 1), ('plath', 1), ('hairier', 1), ('nectaries', 1), ('stamens', 1), ('blooms', 1), ('sanguineum', 1), ('currants', 1), ('perished', 1), ('unmated', 1), ('lumps', 1), ('sods', 1), ('torpor', 1), ('chromatogram', 1), ('eluate', 1), ('citrated', 1), ('agglutinating', 1), ('2a', 1), ('1a', 1), ('syringe', 1), ('hypodermic', 1), ('preparative', 1), ('schlieren', 1), ('1.00', 1), ('59780', 1), ('0.154', 1), ('7.2', 1), ('eluates', 1), ('eluted', 1), ('pooled', 1), ('transversely', 1), ('analytrol', 1), ('densitometry', 1), ('bromophenol', 1), ('milliamperes', 1), ('whatman', 1), ('0.075', 1), ('barbital', 1), ('gentler', 1), ('dilute', 1), ('pervaporation', 1), ('spectrophotometer', 1), ('beckman', 1), ('0.50', 1), ('round-bottom', 1), ('erlenmeyer', 1), ('varigrad', 1), ('meq', 1), ('0.78', 1), ('supernatant', 1), ('aminomethane', 1), ('hydroxymethyl', 1), ('0.039', 1), ('0.005', 1), ('volumetrically', 1), ('centrifuging', 1), ('deglycerolized', 1), ('glycerolized', 1), ('immunoelectrophoresis', 1), ('incubated', 1), ('conciseness', 1), ('macroscopically', 1), ('1024', 1), ('2048', 1), ('serological', 1), ('g-globulin', 1), ('preisolated', 1), ('fahey', 1), ('speer', 1), ('carboxymethyl', 1), ('abelson', 1), ('celluloses', 1), ('ethanol', 1), ('predigested', 1), ('precooked', 1), ('ventilating', 1), ('disseminating', 1), ('lousiness', 1), ('prowazwki', 1), ('rickettsia', 1), ('causative', 1), ('contradictorily', 1), ('mutants', 1), ('antibiotic', 1), ('mutational', 1), ('lethality', 1), ('microorganism', 1), ('logistic', 1), ('coccidioidomycosis', 1), ('glanders', 1), ('brucellosis', 1), ('os', 1), ('thousand-fold', 1), ('toxin', 1), ('botulinal', 1), ('four-fold', 1), ('562', 1), ('samplers', 1), ('on-shore', 1), ('off-shore', 1), ('globigii', 1), ('var.', 1), ('34000', 1), ('fluoresces', 1), ('sulfide', 1), ('diffuses', 1), ('inversion', 1), ('cilia', 1), ('turbinates', 1), ('respiration', 1), ('anesthetized', 1), ('instillation', 1), ('intensively', 1), ('pathogenesis', 1), ('unsuitable', 1), ('dusts', 1), ('ablated', 1), ('spherules', 1), (\"earth's\", 1), ('pettersson', 1), ('corpuscular-radiation', 1), ('electromagnetic', 1), ('observational', 1), ('twenty-fifth', 1), ('cubed', 1), ('thirtieth', 1), ('eshleman', 1), ('0.15', 1), ('jacchia', 1), ('unshielded', 1), ('next-to-last', 1), ('gegenschein', 1), ('densities', 1), ('fluffy', 1), ('u.s.s.r.', 1), ('sensor', 1), ('hypervelocity', 1), ('vaporization', 1), ('4.5', 1), ('lagow', 1), ('nazarova', 1), ('contradictory', 1), ('dubin', 1), ('gages', 1), ('cores', 1), ('corona', 1), ('kilometers', 1), ('asteroidal', 1), ('spiraling', 1), ('cometary', 1), ('replenishment', 1), ('jager', 1), ('km', 1), ('semi-minor', 1), ('diminish', 1), ('diminution', 1), ('sputter', 1), ('aberration', 1), ('retardation', 1), ('robertson', 1), ('proportionality', 1), ('phosgene', 1), ('actinometer', 1), ('0.7', 1), ('eutectic', 1), ('electrolysis', 1), ('emptying', 1), ('geiger', 1), ('aliquots', 1), ('titration', 1), ('gaseous', 1), ('potentiometer', 1), ('thermopile', 1), ('ah6', 1), ('thermostated', 1), ('positioned', 1), ('reproducibly', 1), ('pre-cooled', 1), ('distill', 1), ('resealed', 1), ('degassed', 1), ('vigreux', 1), ('reagent', 1), ('sulfur', 1), ('mallinckrodt', 1), ('sublimed', 1), ('tagging', 1), ('resublimed', 1), ('matheson', 1), ('reproducibility', 1), ('scavenger', 1), ('prechlorination', 1), ('chlorides', 1), ('halogen', 1), ('tetrahalides', 1), ('halogens', 1), ('isotopic', 1), ('bimolecular', 1), ('isomers', 1), ('antiredeposition', 1), ('synergistic', 1), ('flocculation', 1), ('1748', 1), ('1746', 1), ('desorption', 1), ('polyphosphate', 1), ('oleophobic', 1), ('1678', 1), ('oil-water', 1), ('polyelectrolytes', 1), ('contiguous', 1), ('disengage', 1), ('emulsified', 1), ('surfactant', 1), ('congregate', 1), ('technologically', 1), ('imbibe', 1), ('assemblages', 1), ('anionics', 1), ('dimers', 1), ('monomers', 1), ('anions', 1), ('soaps', 1), ('physicochemical', 1), ('solvating', 1), ('dissolving', 1), ('waal', 1), ('evaporate', 1), ('nonparticulate', 1), ('esters', 1), ('hydrocarbons', 1), ('peptizing', 1), ('silicates', 1), ('carbonates', 1), ('borates', 1), ('orthophosphates', 1), ('hydroxides', 1), ('wetting', 1), ('reflectance', 1), ('terg-o-tometer', 1), ('launder-ometer', 1), ('tattle-tale', 1), ('washings', 1), ('absorptive', 1), ('coupon', 1), ('phosphates', 1), ('orthophosphate', 1), ('trisodium', 1), ('general-purpose', 1), ('dishwashers', 1), ('granules', 1), ('light-duty', 1), ('nonionic', 1), ('low-sudsing', 1), ('pyrophosphate', 1), ('tetrasodium', 1), ('alkylbenzenesulfonates', 1), ('high-sudsing', 1), ('spray-dried', 1), ('heavy-duty', 1), ('synergism', 1), ('alundum', 1), ('anhydrous', 1), ('hemispherical', 1), ('wt', 1), ('eades', 1), ('294', 1), ('california,berkeley', 1), ('signal-to-noise', 1), ('rf', 1), ('bridged-t', 1), ('electromagnet', 1), ('crystallites', 1), ('benesi', 1), ('3.10', 1), ('meisenheimer', 1), ('cukla', 1), ('adsorbs', 1), ('61.2', 1), ('58.8', 1), ('hydrous', 1), ('nitrates', 1), ('oxides', 1), ('spectrometric', 1), ('463', 1), ('10.8', 1), ('thermogravimetric', 1), ('water-washed', 1), ('magnetically', 1), ('chromic', 1), ('symmetrically', 1), ('randomization', 1), ('equivalence', 1), ('geometrical', 1), ('2.58', 1), ('2.55', 1), ('nonequivalence', 1), ('nonequivalent', 1), ('rooh', 1), ('octahedron', 1), ('piezoelectricity', 1), ('laue', 1), ('trigonal', 1), ('semiempirical', 1), ('2.44', 1), ('2.26', 1), ('dipoles', 1), ('paramagnet', 1), ('curie-weiss', 1), ('|j', 1), ('hyperfine', 1), ('asymmetry', 1), ('isothermal', 1), ('\\\\q', 1), ('compressing', 1), ('rubber-like', 1), ('2lc', 1), ('cosec', 1), ('bartok', 1), ('phthalate', 1), ('cyclohexanol', 1), ('ellipsoid', 1), ('rumscheidt', 1), ('|g', 1), ('asymptotic', 1), ('|c', 1), ('recoverable', 1), ('asymptotically', 1), ('infer', 1), ('deformational', 1), ('thermostatics', 1), ('derivative', 1), ('|r', 1), ('spinnability', 1), ('shortness', 1), ('adhesives', 1), ('inks', 1), ('pastes', 1), ('magnitudes', 1), ('disassembly', 1), ('suction', 1), ('polybutenes', 1), ('polybutene', 1), ('hr.', 1), ('silicone', 1), ('0.002', 1), ('shims', 1), ('viscometer', 1), ('analogously', 1), ('|e', 1), ('specular', 1), ('halfways', 1), ('voltmeter', 1), ('millivoltmeter', 1), ('shunt', 1), ('mv', 1), ('resistive', 1), ('rator', 1), ('regulator', 1), ('1/16', 1), ('pyrometers', 1), ('porosity', 1), ('nc', 1), ('coaxial', 1), ('axially', 1), ('thoriated', 1), ('sintered', 1), ('anodes', 1), ('stagnation', 1), ('maecker', 1), ('transpirating', 1), ('gaussian', 1), ('observatory', 1), ('84', 1), ('|qt', 1), ('directivity', 1), ('graphical', 1), ('subtended', 1), ('high-resolution', 1), ('salomonovich', 1), ('noskova', 1), ('amenitskii', 1), ('falloff', 1), ('imbrium', 1), ('calibrating', 1), ('sinton', 1), ('decimeter', 1), ('quiescent', 1), ('emitting', 1), ('radiates', 1), ('subtends', 1), ('960', 1), ('radhakrishnan', 1), ('azimuth', 1), ('nrl', 1), ('interferometers', 1), ('10.2', 1), ('ewen', 1), ('3.75', 1), ('9.4', 1), ('gallet', 1), ('nicholson', 1), ('sinusoidal', 1), ('beringer', 1), ('dicke', 1), ('amplifying', 1), ('radiator', 1), ('subsurface', 1), ('garstung', 1), ('eclipses', 1), ('certifies', 1), ('provdied', 1), ('350000', 1), ('repayment', 1), ('wholesalers', 1), ('authorizes', 1), ('urgently', 1), ('diversification', 1), ('adaptable', 1), ('semi-processed', 1), ('one-day', 1), ('cosponsors', 1), ('obe', 1), ('velociter', 1), ('cito', 1), ('terram', 1), ('vanities', 1), ('envisions', 1), ('bluthenzweig', 1), ('savonarola', 1), ('characterizing', 1), ('bruegel', 1), ('du^rer', 1), ('unthematic', 1), ('expressiveness', 1), ('naphta', 1), ('germinal', 1), ('raving', 1), ('unproblematic', 1), ('unreflective', 1), ('capitulated', 1), ('wrestlings', 1), ('dialectically', 1), ('religiousness', 1), ('fox-terrier', 1), ('cur', 1), ('doom', 1), ('imprecates', 1), ('wretchedness', 1), ('impotent', 1), ('psychopomp', 1), ('cadaver', 1), ('widower', 1), ('footpath', 1), ('platitudinous', 1), ('expressionistic', 1), ('punishable', 1), ('masquerading', 1), ('accumulates', 1), ('cipolla', 1), ('singularity', 1), ('transgression', 1), ('aschenbach', 1), ('kro^ger', 1), ('tonio', 1), ('resonances', 1), ('miraculous', 1), ('horrifying', 1), ('enciphered', 1), ('constatation', 1), ('collapses', 1), ('perceives', 1), ('abjection', 1), ('hackwork', 1), ('artifice', 1), ('banal', 1), ('horrifyingly', 1), ('transvestitism', 1), ('abasement', 1), ('unredeemed', 1), ('decently', 1), ('poseurs', 1), ('epithets', 1), ('amra', 1), ('obscurely', 1), ('unanswered', 1), ('hallucinations', 1), ('imminence', 1), ('acquires', 1), ('bio', 1), ('exhortations', 1), ('compulsions', 1), ('voodoo', 1), ('toto', 1), ('unwitting', 1), ('clench', 1), ('staved', 1), ('planetoid', 1), ('instituting', 1), ('periodicity', 1), ('ptolemaic', 1), ('solstice', 1), ('reiterates', 1), ('ritualized', 1), ('comets', 1), ('remembrances', 1), ('discernable', 1), ('breakwaters', 1), ('coexist', 1), ('standstill', 1), ('archimedes', 1), ('lavoisier', 1), ('nucleic', 1), ('coalesced', 1), ('gastronomy', 1), ('reaping', 1), ('racists', 1), ('levelled', 1), ('britannic', 1), ('celtic', 1), ('sharers', 1), ('veiling', 1), ('delude', 1), ('miscegenation', 1), ('carolinas', 1), ('arrogant', 1), ('humbled', 1), ('anglophilia', 1), ('lowlands', 1), ('enclaves', 1), ('tenaciously', 1), ('carolinians', 1), ('virginians', 1), ('unpatriotic', 1), ('souths', 1), ('leavening', 1), ('state-supported', 1), ('roomful', 1), ('womb-to-tomb', 1), ('anachronisms', 1), ('shibboleths', 1), ('left-of-center', 1), ('egghead', 1), ('non-discrimination', 1), ('purveyors', 1), ('stereophonic', 1), ('unthinking', 1), ('d.w.', 1), ('footage', 1), ('geniuses', 1), ('outlaws', 1), ('appended', 1), ('honky-tonk', 1), ('overpowers', 1), (\"1950's\", 1), ('1903', 1), ('incalculable', 1), ('endows', 1), ('climaxes', 1), ('illusionary', 1), ('georges', 1), ('cinerama', 1), ('travelogues', 1), ('menlo', 1), ('headsman', 1), ('scotts', 1), ('snips', 1), ('sandburgs', 1), ('steinbecks', 1), ('benets', 1), ('longs', 1), ('publically', 1), ('people,', 1), ('steinbeck', 1), (\"brown's\", 1), ('tamper', 1), ('money-maker', 1), ('potpourri', 1), ('probings', 1), ('progandist', 1), ('uncritical', 1), ('hunts', 1), ('footnote', 1), ('acculturated', 1), ('heritages', 1), ('dramatists', 1), ('sentimentalists', 1), ('teutonic', 1), ('subliterary', 1), ('literate', 1), ('rhymes', 1), ('proverbs', 1), ('myths', 1), ('recreate', 1), ('crockett', 1), ('uniting', 1), ('weems', 1), ('rewriting', 1), ('isolationistic', 1), ('egocentric', 1), ('curricula', 1), (\"1880's\", 1), ('spanish-american', 1), ('justifying', 1), ('superimposes', 1), ('rewrites', 1), ('avarice', 1), ('sufferers', 1), ('jannsen', 1), ('stephens', 1), ('reconditioning', 1), ('ghoul', 1), ('35823', 1), ('t.b.', 1), ('knobs', 1), ('radionic', 1), ('healer', 1), ('drugless', 1), ('306', 1), ('vrilium', 1), ('barium', 1), ('arsenic', 1), ('hepker', 1), ('bilked', 1), ('townsman', 1), ('callously', 1), ('preying', 1), ('acs', 1), ('charlatans', 1), ('610', 1), ('ama', 1), ('conned', 1), ('diagnometer', 1), ('radioclast', 1), ('4200', 1), ('abrams', 1), ('ghadiali', 1), ('hawker', 1), ('gallus', 1), ('letterhead', 1), ('naturopath', 1), ('electrotherapist', 1), ('physiotherapist', 1), ('naprapath', 1), ('faker', 1), ('capitalizing', 1), ('rube', 1), ('luring', 1), ('fatten', 1), ('misbranded', 1), ('convicting', 1), ('sage', 1), ('mumbo-jumbo', 1), ('diseased', 1), ('applicator', 1), ('bakersfield', 1), ('orator', 1), ('clinched', 1), ('nominate', 1), ('withstands', 1), ('sleeper', 1), ('nippur', 1), ('substitution', 1), ('fadeout', 1), ('ostensibly', 1), ('cassite', 1), ('1300', 1), ('kurigalzu', 1), ('babylonian', 1), ('photographically', 1), ('intactible', 1), ('coexistent', 1), ('pulsation', 1), ('ramsperger', 1), ('philosophies', 1), ('psycho-physiology', 1), ('subconsciously', 1), ('dreamer', 1), ('hodge-podge', 1), ('life-like', 1), ('retrovision', 1), ('clairvoyance', 1), ('mantic', 1), ('ponder', 1), ('unreleased', 1), ('rudyard', 1), ('mystified', 1), ('maeterlinck', 1), ('grope', 1), ('side-step', 1), ('strangest', 1), ('offences', 1), ('mitigation', 1), ('repute', 1), ('ring-around-a', 1), ('confreres', 1), ('irresponsibility', 1), ('jack-of-all-trades', 1), ('disservice', 1), ('institutes', 1), ('anomalous', 1), ('catalog', 1), ('scrutinized', 1), ('extant', 1), ('curricular', 1), ('a.i.d.', 1), ('lengthen', 1), ('crux', 1), ('militated', 1), ('pelvis', 1), ('copying', 1), ('walkover', 1), ('handstand', 1), ('supine', 1), ('acrobatics', 1), ('backbend', 1), ('fours', 1), ('chinning', 1), ('chin-ups', 1), ('ballerinas', 1), ('headstand', 1), ('demonstrators', 1), (\"wives'\", 1), ('sustains', 1), ('infants', 1), ('gymnast', 1), ('volleyball', 1), ('flips', 1), ('backbends', 1), ('headstands', 1), ('useable', 1), ('landscaping', 1), ('grading', 1), ('subsoil', 1), ('topsoil', 1), ('outcrops', 1), ('fisherman', 1), ('artifacts', 1), ('archeological', 1), ('semi-precious', 1), ('agates', 1), ('crust', 1), ('migratory', 1), ('flyways', 1), ('stocking', 1), ('waterfalls', 1), ('watershed', 1), ('nourishes', 1), ('surf', 1), ('polluted', 1), ('ownerships', 1), ('topographic', 1), ('sd', 1), ('monophonic', 1), ('abridgment', 1), ('penultimate', 1), ('sentimentality', 1), ('vehement', 1), ('ultra', 1), ('fistoulari', 1), ('horrid', 1), ('four-sided', 1), ('feyer', 1), ('allegro', 1), ('scherzo', 1), ('assai', 1), ('undertow', 1), ('discounting', 1), ('intrudes', 1), ('sonority', 1), ('reverberation', 1), ('acoustically', 1), ('clicks', 1), ('scrapes', 1), ('peaky', 1), ('obtrudes', 1), ('scheherazade', 1), ('fractional', 1), ('spotting', 1), ('rehearing', 1), ('disillusioning', 1), ('tenfold', 1), ('caruso', 1), ('re-creation', 1), ('verisimilitude', 1), ('milestones', 1), ('magnificence', 1), ('2.98', 1), ('bargain-priced', 1), ('telefunken', 1), ('roloff', 1), ('helmut', 1), ('tensionless', 1), ('toned', 1), ('grammophon', 1), ('deutsche', 1), ('demus-schubert', 1), ('konzerthaus', 1), ('badura-skoda-vienna', 1), ('unimaginative', 1), ('babin-festival', 1), ('menuhin-amadeus', 1), ('hephzibah', 1), ('lucidity', 1), ('concert-disc', 1), ('glazer-fine', 1), ('hilarity', 1), ('tottering', 1), ('krumpp', 1), ('johann', 1), ('octet', 1), ('finicky', 1), ('gossamer', 1), ('viennese', 1), ('landler', 1), ('sps', 1), ('splicing', 1), ('forellen', 1), ('interpretative', 1), ('superlatives', 1), ('markings', 1), ('pianism', 1), ('strait-laced', 1), ('schnabelian', 1), ('pianistic', 1), ('pedagogical', 1), ('adrian', 1), ('schubert-beethoven-mozart', 1), ('artur', 1), ('colh', 1), ('schnabel-pro', 1), ('marathon', 1), ('contrabass', 1), ('serenade', 1), ('quintets', 1), ('classifiers', 1), ('phosphorus', 1), ('riboflavin', 1), ('thiamin', 1), ('versatility', 1), ('sprays', 1), ('ripening', 1), ('gassing', 1), ('waxing', 1), ('dyeing', 1), ('delays', 1), ('refrigerated', 1), ('eatings', 1), ('pulp', 1), ('meaty', 1), ('prolific', 1), ('sickly', 1), ('grower', 1), ('cut-down', 1), ('pegged-down', 1), ('pegging', 1), ('tall-growing', 1), ('leggy', 1), ('budded', 1), ('greenhouse', 1), ('unheated', 1), ('seedlings', 1), ('feedings', 1), ('overfeed', 1), ('pulverized', 1), ('oftener', 1), ('sowing', 1), ('lustily', 1), ('tilth', 1), ('harrowed', 1), ('unimproved', 1), ('nutshell', 1), ('one-leg', 1), ('breather', 1), ('squats', 1), ('razor-sharp', 1), ('reps', 1), ('extensor', 1), ('curling', 1), ('hipline', 1), ('thigh-bone', 1), ('reacquainted', 1), ('rediscovers', 1), ('limbo', 1), ('rarer', 1), ('deltoid', 1), ('lat', 1), ('stretcher', 1), ('lateral', 1), ('bent-arm', 1), ('classically', 1), ('pectorals', 1), ('dumbbells', 1), ('gladiator', 1), ('reeves-type', 1), ('collar-to-collar', 1), ('widens', 1), ('straight-arm', 1), ('tanny', 1), ('wonder-working', 1), ('super-protein', 1), ('quick-wate', 1), ('testimonials', 1), ('yesiree', 1), ('harve', 1), ('boissoneault', 1), ('senesac', 1), (\"d'amours\", 1), ('gaetan', 1), ('anticus', 1), ('tibialis', 1), ('mastoideus', 1), ('sterno-cleido', 1), ('professeur', 1), ('bodybuilding', 1), ('admonishing', 1), ('unkind', 1), ('whaddya', 1), ('stunt', 1), ('sonny-boy', 1), ('alters', 1), ('naturalness', 1), ('transience', 1), ('deliverance', 1), ('incorruptibility', 1), ('cyprian', 1), ('tatian', 1), ('dissolution', 1), ('interposing', 1), ('irremediable', 1), ('pitied', 1), ('punitive', 1), ('providential', 1), ('conformed', 1), ('extenuate', 1), ('potentiality', 1), ('betrothed', 1), ('imprecise', 1), ('arrogance', 1), ('self-conceited', 1), ('overstepping', 1), ('pre-existent', 1), ('pre-existence', 1), ('recurrence', 1), ('crucifixion', 1), ('aeon', 1), ('votive', 1), ('lords', 1), ('leamington', 1), ('14th', 1), ('primate', 1), ('heenan', 1), ('superficially', 1), ('cherwell', 1), ('tutorials', 1), ('seminarians', 1), ('1854', 1), ('irishmen', 1), ('imprecations', 1), ('hyperbolically', 1), ('martyrs', 1), ('venerated', 1), ('vicar', 1), ('intercede', 1), ('benediction', 1), ('reciting', 1), ('centenary', 1), ('ascendancy', 1), ('ironies', 1), ('breakwater', 1), ('anglicanism', 1), ('secularism', 1), ('nonchurchgoing', 1), ('nonconformists', 1), ('764', 1), ('demolition', 1), ('790', 1), ('archbishops', 1), ('2887671', 1), ('9748000', 1), ('evensong', 1), ('churchgoers', 1), ('oratory', 1), ('keenest', 1), ('apologia', 1), ('disapprobation', 1), ('tractarians', 1), ('bonfires', 1), ('anti-catholicism', 1), ('cornwall', 1), ('devonshire', 1), ('cleric', 1), ('transcribe', 1), ('unpublished', 1), ('unacceptable', 1), ('hermeneutics', 1), ('unconditioned', 1), ('self-consistent', 1), ('invalidated', 1), ('indefensible', 1), ('untenable', 1), ('demythologizing', 1), ('philosophically', 1), ('neoliberal', 1), ('tillich', 1), ('macintosh', 1), ('rauschenbusch', 1), ('clarke', 1), ('bushnell', 1), ('troeltsch', 1), ('harnack', 1), ('herrmann', 1), ('ritschl', 1), ('schleiermacher', 1), ('aligned', 1), ('irreversible', 1), ('estrangement', 1), ('bonhoeffer', 1), ('intellectus', 1), ('corporis', 1), ('fortiori', 1), ('alienate', 1), ('castigation', 1), ('fulminate', 1), ('pundits', 1), ('mythologies', 1), ('estranged', 1), ('admittedly', 1), ('stumbling-block', 1), ('overestimates', 1), ('responsibly', 1), ('mythology', 1), ('misrepresents', 1), ('expurgation', 1), ('understanded', 1), ('givenness', 1), ('prospers', 1), ('cohere', 1), ('nazism', 1), ('cohesiveness', 1), ('presentness', 1), ('abounding', 1), ('wickedness', 1), ('redeemed', 1), ('worthlessness', 1), ('inculcation', 1), ('diametrically', 1), ('1692', 1), ('combatted', 1), ('proctor', 1), ('dreadfully', 1), ('engulfs', 1), ('crucible', 1), ('apprehend', 1), ('excesses', 1), ('conceptualization', 1), ('unmixed', 1), ('misconceptions', 1), ('peopled', 1), ('understandings', 1), ('rejections', 1), ('user', 1), ('agreed-upon', 1), ('fracases', 1), ('despoilers', 1), ('mimieux', 1), ('gorshin', 1), ('hutton', 1), ('unstilted', 1), ('prentiss', 1), ('paula', 1), ('believable', 1), ('dolores', 1), ('mermaid', 1), ('hilariously', 1), ('vexes', 1), ('collegians', 1), ('disqualify', 1), ('yalies', 1), ('screenplay', 1), ('levin', 1), ('pasternak', 1), ('mgm', 1), ('loew', 1), ('hereabouts', 1), ('obtrusiveness', 1), ('road-show', 1), ('stager', 1), ('folk-dance', 1), ('lingual', 1), ('frolic', 1), ('penthouse', 1), ('ward-heelers', 1), ('tuneful', 1), ('fugual', 1), ('zeme', 1), ('thea', 1), ('lipson', 1), ('distraught', 1), (\"one's\", 1), ('bosley', 1), ('pulitzer', 1), ('eckart', 1), ('gennaro', 1), ('harnick', 1), ('bock', 1), ('weidman', 1), ('knill', 1), ('congdon', 1), ('melisande', 1), ('sparrow', 1), ('monologist', 1), ('sultry', 1), ('ashmolean', 1), (\"charley's\", 1), ('hamming', 1), ('ambling', 1), ('tantalizingly', 1), ('matlowsky', 1), ('conlow', 1), ('hewett', 1), ('weissman', 1), ('hildy', 1), ('scratchy', 1), ('spider', 1), ('talky', 1), ('finger-tips', 1), ('scoundrel', 1), ('embittered', 1), ('angriest', 1), ('coletta', 1), ('century-fox', 1), ('head-in-the-clouds', 1), ('heffernan', 1), ('hires', 1), ('adopts', 1), ('arty', 1), ('macaulay', 1), ('gibbon', 1), ('future-day', 1), ('storylines', 1), ('unauthentic', 1), ('murrow', 1), ('intrigues', 1), ('paraphernalia', 1), ('unimpeachable', 1), ('masking', 1), ('gratifyingly', 1), ('44007', 1), ('pianos', 1), ('brassy', 1), ('44002', 1), ('44005', 1), ('kombo', 1), ('keating', 1), ('44006', 1), ('castanets', 1), ('xylophones', 1), ('microphoning', 1), ('monaural', 1), ('directionality', 1), ('44001', 1), ('ping-pong', 1), ('sonambula', 1), ('tenda', 1), ('canto', 1), ('edgardo', 1), ('varviso', 1), ('silvio', 1), ('spell-binding', 1), ('blemishes', 1), ('sopranos', 1), ('outburst', 1), ('operagoers', 1), ('salvos', 1), ('donizetti', 1), ('bygone', 1), ('inquisitive', 1), ('trumpeter', 1), ('beiderbecke', 1), ('bix', 1), ('closeup', 1), ('zoomed', 1), ('seeley', 1), ('lil', 1), ('cyr', 1), ('krupa', 1), ('teagarden', 1), ('in-person', 1), ('faulted', 1), ('luminaries', 1), ('rudderless', 1), ('hearer', 1), ('free-wheeling', 1), ('slotted', 1), ('costumed', 1), ('wonderfulness', 1), ('windmill', 1), ('thenceforth', 1), ('poignancy', 1), ('wearisome', 1), ('facetiously', 1), ('buffoons', 1), ('oftentimes', 1), ('tolubeyev', 1), ('stilted', 1), ('studiously', 1), ('kozintsev', 1), ('grigory', 1), ('crackpot', 1), ('deep-eyed', 1), ('caricature', 1), ('knight-errantry', 1), ('chivalrous', 1), ('addle-brained', 1), ('nevsky', 1), ('affectingly', 1), ('chivalry', 1), ('abbreviated', 1), ('tragi-comic', 1), ('visualization', 1), ('playhouses', 1), ('sixty-eighth', 1), ('dines', 1), ('potting', 1), ('nourishment', 1), ('poaches', 1), ('restock', 1), ('larkins', 1), ('oneupmanship', 1), ('capital-gains', 1), ('manse', 1), ('mendacious', 1), ('table-tennis', 1), ('patinas', 1), ('unpremeditated', 1), ('stained-glass', 1), ('junior-grade', 1), ('atrociously', 1), ('pinkie', 1), ('humaine', 1), ('chronicled', 1), ('boisterous', 1), ('stockbroker', 1), ('eccentrics', 1), ('lark', 1), ('scribbled', 1), ('zeffirelli', 1), ('bauer-ecsy', 1), ('leni', 1), ('mcnear', 1), ('828', 1), ('cibula', 1), ('mondays', 1), ('reopen', 1), ('bookings', 1), ('bookers', 1), ('balletomane', 1), ('maryinsky', 1), ('leningrad-kirov', 1), ('bolshoi', 1), ('bumbry', 1), ('lehmann', 1), ('lotte', 1), ('kempe', 1), ('rudolf', 1), ('meistersinger', 1), ('knappertsbusch', 1), ('sawalisch', 1), ('sawallisch', 1), ('wolfgang', 1), ('wieland', 1), ('coarsened', 1), ('astringent', 1), ('joust', 1), ('hindemith', 1), ('byronic', 1), ('manfred', 1), (\"schumann's\", 1), ('alchemy', 1), ('flounders', 1), ('shredding', 1), ('surpass', 1), ('unlocks', 1), ('demon-ridden', 1), ('bouffe', 1), ('launcher', 1), ('snook', 1), ('foley', 1), ('paramilitary', 1), ('vigilantism', 1), ('372', 1), ('engh', 1), ('salsich', 1), ('mentalities', 1), ('staple', 1), ('pessimists', 1), ('troika', 1), ('compromises', 1), ('weltanschauung', 1), ('unshakable', 1), ('augurs', 1), ('in-fighting', 1), ('waylaid', 1), ('boland', 1), ('mongi', 1), (\"u.n.'s\", 1), ('dispossession', 1), ('rehabilitations', 1), ('exhumations', 1), ('musing', 1), ('morticians', 1), ('seventy-eight', 1), ('macmillan', 1), ('deplores', 1), ('whitehall', 1), ('gallows', 1), ('tyburn', 1), ('disinterred', 1), ('/4', 1), ('haestier', 1), ('chastisement', 1), ('367', 1), ('commentators', 1), ('reunite', 1), ('resilience', 1), (\"employers'\", 1), ('arnold-foster', 1), ('counterbalanced', 1), ('12.8', 1), ('2200000', 1), ('migrating', 1), ('berliners', 1), ('publicists', 1), ('paeans', 1), ('statesmanlike', 1), ('emulate', 1), ('animosity', 1), ('miscarried', 1), ('lob', 1), ('neutron', 1), ('hue', 1), ('b-52s', 1), ('nos', 1), ('knick-knacks', 1), ('clothe', 1), ('frowningly', 1), ('clings', 1), ('promoter', 1), ('suckers', 1), ('dabbles', 1), ('2000000', 1), ('parlayed', 1), ('complexes', 1), ('roughest', 1), ('leggett', 1), ('bodenheim', 1), ('peal', 1), ('muir', 1), ('wheelock', 1), ('ciardi', 1), ('basler', 1), ('buffs', 1), ('fillip', 1), ('bertrand', 1), ('ben-gurion', 1), (\"o'casey\", 1), ('lipchitz', 1), ('jawaharlal', 1), ('sages', 1), ('turntable', 1), ('histrionics', 1), ('phonetics', 1), ('eye-strain', 1), ('sophocles', 1), ('bookshelf', 1), ('overactive', 1), ('cramp', 1), ('neurological', 1), ('awakens', 1), ('numbness', 1), ('enjoyable', 1), ('bedfast', 1), ('enamel', 1), ('anteriors', 1), ('malposed', 1), ('crevices', 1), ('detachable', 1), ('sterilized', 1), ('braided', 1), ('luster', 1), ('ile', 1), ('pastels', 1), ('afoot', 1), ('citrus', 1), ('cushioning', 1), ('lustre', 1), ('semi-heights', 1), ('perforations', 1), ('durocher', 1), ('walloping', 1), ('wrigley', 1), ('pun', 1), ('inheriting', 1), ('base-runner', 1), ('bunter', 1), ('homerun', 1), ('joplin', 1), ('rizzuto', 1), ('prod', 1), ('.345', 1), ('rbis', 1), ('.365', 1), ('triple-crown', 1), ('switch-hitter', 1), ('bull-necked', 1), ('doubleheader', 1), ('3:30', 1), ('ligget', 1), ('boehmer', 1), ('defeats', 1), ('doesn', 1), ('latinovich', 1), ('luechtefeld', 1), ('reid', 1), ('hambric', 1), ('lettermen', 1), ('globe-democrat', 1), ('burnes', 1), ('ball-hawking', 1), ('all-round', 1), ('post-dispatch', 1), ('broeg', 1), ('most-valuable', 1), ('pepping', 1), ('tipoff', 1), (\"'51\", 1), ('dodger', 1), (\"'52\", 1), (\"'49\", 1), ('.500', 1), ('fall-off', 1), ('plunkers', 1), ('unhappiest', 1), ('.143', 1), ('.179', 1), ('.267', 1), ('skinner', 1), ('hoak', 1), ('.306', 1), ('.323', 1), ('groat', 1), ('clemente', 1), ('.340', 1), ('.389', 1), ('cimoli', 1), ('gino', 1), ('.455', 1), ('bucs', 1), ('lindy', 1), ('lineup', 1), ('vern', 1), ('cubs', 1), ('disheartening', 1), ('earned-run', 1), ('won-lost', 1), ('shantz', 1), ('outclass', 1), ('rozelle', 1), ('god-like', 1), ('golfing', 1), ('burrowed', 1), ('yarder', 1), ('fiercest', 1), ('jangling', 1), ('playable', 1), ('countin', 1), ('nae', 1), ('ainsley', 1), ('hackers', 1), ('perturbed', 1), ('out-of-bounds', 1), ('508', 1), ('banshees', 1), ('zombies', 1), ('pixies', 1), ('boomed', 1), ('crusher', 1), ('aggravates', 1), ('self-sacrifice', 1), ('paragon', 1), ('meditating', 1), ('flubbed', 1), ('duffer', 1), ('hickok', 1), ('horton', 1), ('title-holder', 1), ('beman', 1), ('deane', 1), ('dublin', 1), ('hamey', 1), ('most-valuable-player', 1), ('nori', 1), ('flushing', 1), ('big-league', 1), ('payson', 1), ('shipman', 1), ('rickey', 1), ('blume', 1), ('farley', 1), ('skit', 1), ('lampoon', 1), ('1400', 1), ('sid', 1), ('slocum', 1), ('meritorious', 1), ('epstein', 1), ('journal-american', 1), ('thirty-eighth', 1), ('cufflinks', 1), ('dilworth', 1), ('auspiciously', 1), ('rejoining', 1), ('polytechnic', 1), ('jock', 1), ('lineman', 1), ('aerials', 1), ('bucky', 1), ('daley', 1), ('wally', 1), ('fizzled', 1), ('32589', 1), ('subbing', 1), ('loser', 1), ('routed', 1), ('outclassed', 1), ('romp', 1), ('cbs', 1), ('denver-area', 1), ('candlestick', 1), ('anemic', 1), (\"mickey's\", 1), ('.318', 1), ('boils', 1), ('colavito', 1), ('seerey', 1), ('adcock', 1), ('klein', 1), ('delahanty', 1), ('ebbetts', 1), ('gil', 1), ('walloped', 1), ('enos', 1), ('spahnie', 1), ('18792', 1), ('beardown', 1), ('gentlemanly', 1), ('nehf', 1), ('pennock', 1), ('hubbell', 1), ('lefthanders', 1), ('laurels', 1), ('stimulant', 1), ('hitless', 1), ('embossed', 1), ('retaliating', 1), ('wagging', 1), ('double-crosser', 1), ('streamliner', 1), ('olsen', 1), ('zoe', 1), ('nev.', 1), ('.130', 1), ('at-bats', 1), ('walkout', 1), ('25th', 1), ('newsman', 1), ('baser', 1), ('killebrew', 1), ('harmon', 1), ('380', 1), ('camilo', 1), ('sievers', 1), ('lenny', 1), ('chopper', 1), ('bertoia', 1), ('lown', 1), ('5777', 1), ('minoso', 1), ('eluded', 1), ('randall', 1), ('muskegon', 1), ('donnelly', 1), ('tsitouris', 1), ('wyman', 1), ('waggin', 1), ('patti', 1), ('dobbs', 1), ('refocusing', 1), ('grounder', 1), ('ruiz', 1), ('infielder', 1), ('pavletich', 1), ('shartzer', 1), ('leftfield', 1), ('putout', 1), ('grizzlies', 1), ('949', 1), ('205', 1), ('baseballs', 1), ('liveliness', 1), ('34.7', 1), ('189', 1), ('187.5', 1), ('174', 1), ('swc', 1), ('1512', 1), ('545', 1), ('dent', 1), ('quipping', 1), ('grayson', 1), ('haynes', 1), ('abner', 1), ('touchdowns', 1), ('linebackers', 1), ('fullbacking', 1), ('mutter', 1), ('oilers', 1), ('quarterbacks', 1), ('reckonings', 1), ('pre-season', 1), ('broncos', 1), ('priddy', 1), ('hargett', 1), ('idleness', 1), ('nichols', 1), ('lsu', 1), ('raesz', 1), ('stafford', 1), ('scrimmage', 1), ('scrimmaged', 1), ('injuring', 1), ('ligament', 1), (\"force's\", 1), ('isaacson', 1), ('mustang', 1), ('falcons', 1), ('arshinkoff', 1), ('fumble', 1), ('cudmore', 1), ('richey', 1), ('mustangs', 1), ('wingback', 1), ('uncorked', 1), ('second-half', 1), ('273', 1), ('271', 1), ('netted', 1), ('tailback', 1), ('469', 1), ('scholastically', 1), ('punted', 1), ('anson', 1), ('208', 1), ('kicker', 1), ('darrell', 1), ('lettered', 1), ('unearned', 1), ('kubek', 1), ('49ers', 1), ('a.a.u.', 1), ('wellsley', 1), ('shipley', 1), ('tenths', 1), ('2.21.6', 1), ('chardon', 1), ('butcher', 1), ('1.10.4', 1), ('whitfield', 1), ('mal', 1), ('1.10.8', 1), ('1.09.3', 1), ('clocking', 1), ('1.10.1', 1), ('purdue', 1), ('jamaican', 1), ('verrone', 1), ('842617', 1), ('patty', 1), ('8280', 1), ('milties', 1), ('hallowell', 1), ('paget', 1), ('furlongs', 1), ('toying', 1), ('7.20', 1), ('scrapiron', 1), ('shouldda', 1), ('courtney', 1), ('iglehart', 1), ('macphail', 1), ('hurlers', 1), ('connie', 1), ('centerfield', 1), ('sacker', 1), ('contingent', 1), ('wintertime', 1), ('clipper', 1), ('ditmar', 1), ('pappas', 1), ('york-pennsylvania', 1), ('auburn', 1), ('duren', 1), ('ryne', 1), ('knuckleball', 1), ('cal.', 1), ('.255', 1), ('belated', 1), ('415', 1), ('romped', 1), ('batter', 1), ('fouling', 1), ('fielded', 1), ('herzog', 1), ('safeties', 1), ('pounder', 1), ('767', 1), ('powderpuff', 1), ('cipriani', 1), ('batters', 1), ('hurler', 1), ('to-o', 1), ('coasted', 1), ('illegitimacy', 1), ('breakups', 1), ('pirie', 1), ('virgil', 1), ('4.4', 1), ('desertion', 1), ('strickland', 1), ('raymondville', 1), ('letterman', 1), ('a+i', 1), ('mclemore', 1), ('regents', 1), ('co-signers', 1), ('fifty-three', 1), (\"master's\", 1), ('sulphur', 1), ('garza', 1), ('kika', 1), ('eligio', 1), ('dumas', 1), ('5000000', 1), ('hollowell', 1), ('seminole', 1), ('referendum', 1), ('plainview', 1), ('/3', 1), ('aikin', 1), ('notarized', 1), ('saba', 1), ('crump', 1), ('validated', 1), ('sledding', 1), ('parimutuels', 1), ('scholastics', 1), ('182', 1), ('88000', 1), ('157460', 1), ('451500', 1), ('tarrant', 1), ('bexar', 1), ('harlingen', 1), ('brady', 1), ('gaynor', 1), ('depositors', 1), ('erase', 1), ('tabb', 1), ('callan', 1), ('colquitt', 1), ('calmest', 1), ('402', 1), ('1119', 1), ('13th', 1), ('mac', 1), ('schley', 1), ('gainesville', 1), ('ledford', 1), ('dorsey', 1), ('expires', 1), ('637', 1), ('opelika', 1), ('amicable', 1), ('cheshire', 1), ('alpharetta', 1), ('bellwood', 1), ('extern', 1), ('intern', 1), ('concessionaires', 1), ('unmeritorious', 1), ('juries', 1), ('awarding', 1), ('appraisers', 1), ('disable', 1), ('swipe', 1), ('re-set', 1), ('mayor-nominate', 1), ('hard-fought', 1), ('pye', 1), ('durwood', 1), ('presentments', 1), ('momma', 2), ('belletch', 2), ('chateau', 2), ('baby-dear', 2), ('traitor', 2), ('availed', 2), ('stung', 2), ('metronome', 2), ('cantor', 2), ('mistrusted', 2), ('zounds', 2), ('knee-length', 2), ('honeymooned', 2), ('parvenu', 2), ('digger', 2), ('blackjack', 2), ('flowerpot', 2), ('highball', 2), ('eskimos', 2), ('toodle', 2), ('sierras', 2), ('subic', 2), ('murdering', 2), ('humiliated', 2), ('tinkling', 2), ('yokosuka', 2), ('miyagi', 2), ('grand-daughter', 2), ('titus', 2), ('dryin', 2), ('dew', 2), ('one-two-three', 2), ('lonesome', 2), ('oystchers', 2), ('spa', 2), ('laments', 2), ('foal', 2), ('whipsnade', 2), ('absolution', 2), ('fairbrothers', 2), ('abernathy', 2), ('bled', 2), ('steeper', 2), ('atonement', 2), ('great-grandfather', 2), ('culver', 2), ('whistle', 2), ('pits', 2), ('monitors', 2), ('mitch', 2), ('haskell', 2), ('white-topped', 2), ('baldness', 2), ('slam', 2), ('circling', 2), ('spine-chilling', 2), ('lances', 2), ('rees', 2), ('blackfeet', 2), ('canister', 2), ('durkin', 2), ('leaping', 2), ('streamed', 2), ('manes', 2), ('pettigrew', 2), ('watchful', 2), ('rustle', 2), ('drunkards', 2), ('strays', 2), ('ditches', 2), ('resembling', 2), ('bawled', 2), ('torsos', 2), ('screams', 2), ('wisecracked', 2), ('tanner', 2), ('scouts', 2), ('diaphragmic', 2), ('digesting', 2), ('irritating', 2), ('crooned', 2), ('scowled', 2), ('shipmate', 2), ('mucking', 2), ('spaceship', 2), ('curl', 2), ('critters', 2), ('nudged', 2), ('coverall', 2), ('sonic', 2), ('hugged', 2), ('paw', 2), ('fuses', 2), ('nernst', 2), ('elation', 2), ('natures', 2), ('lila', 2), ('gaylor', 2), ('carmody', 2), ('poodle', 2), ('snowed', 2), ('hunched', 2), ('feint', 2), ('paunchy', 2), ('biscayne', 2), ('thundered', 2), ('nerve-shattering', 2), ('helplessly', 2), ('ruse', 2), ('bordered', 2), ('red-clay', 2), ('sanford', 2), ('foolishly', 2), ('graying', 2), ('coke', 2), ('twitch', 2), ('cate', 2), ('paunch', 2), ('spilled', 2), ('wycoff', 2), ('rumdum', 2), ('perceptions', 2), ('arm-levitation', 2), ('nonreactors', 2), ('guilford-martin', 2), ('freshmen', 2), ('strata', 2), ('belge', 2), ('out-migrants', 2), ('age-and-sex', 2), ('indigenes', 2), ('deviance', 2), ('exogamy', 2), ('linkage', 2), ('systemic', 2), ('hypothesized', 2), ('consanguinity', 2), ('regulative', 2), ('weddings', 2), ('short-contact', 2), ('reactivated', 2), ('time-honored', 2), ('suppression', 2), ('counteract', 2), ('psychoanalytic', 2), ('transference', 2), ('referral', 2), ('homemaker', 2), ('dissipated', 2), ('stressful', 2), ('conic', 2), ('quadratic', 2), ('triservice', 2), ('macropathological', 2), ('squibb', 2), ('refurbished', 2), ('loaned', 2), ('morphological', 2), ('opthalmic', 2), ('reine', 2), ('eighty-fifth', 2), ('kingstown', 2), ('disbursements', 2), ('mailings', 2), ('expansions', 2), ('barrington', 2), ('debated', 2), ('cost-data', 2), ('reimburseable', 2), ('reimbursements', 2), ('change-over', 2), ('three-year', 2), ('lieu', 2), ('.027', 2), ('regimes', 2), ('favoritism', 2), ('deviants', 2), ('composes', 2), ('instinctual', 2), ('wholeness', 2), ('dionysian', 2), ('legalized', 2), ('barbarians', 2), ('orgiastic', 2), ('eros', 2), ('hemingway', 2), ('liberty-and-union', 2), ('seceding', 2), ('ordain', 2), ('constitutions', 2), ('centralizing', 2), ('89', 2), ('freeing', 2), ('uninhibited', 2), ('jumps', 2), ('litz', 2), ('projective', 2), ('parasol', 2), ('metamorphosed', 2), ('creators', 2), ('glimmer', 2), ('yoknapatawpha', 2), ('westbrook', 2), ('blissful', 2), ('urbanism', 2), ('styron', 2), ('yankeefication', 2), ('thorp', 2), ('antiquated', 2), ('forsaken', 2), ('post-bellum', 2), ('jeffersonians', 2), ('1783', 2), ('single-handedly', 2), ('preside', 2), ('mitropoulos', 2), ('synagogues', 2), ('repertoire', 2), ('advancement', 2), ('zemlinsky', 2), ('prague', 2), ('twinkle', 2), ('alphabet', 2), ('wanderings', 2), ('und', 2), ('herrick', 2), ('sluices', 2), ('hafiz', 2), ('maw', 2), ('shah', 2), ('samovar', 2), ('arcades', 2), ('pavilions', 2), ('spooky', 2), ('coating', 2), ('ageless', 2), ('wispy', 2), ('lubra', 2), ('corroborees', 2), ('peeping', 2), ('tree-clumps', 2), ('hummocks', 2), ('lope', 2), ('activate', 2), ('beige', 2), ('preprepared', 2), ('omaha', 2), ('revere', 2), ('thinkers', 2), ('prowl', 2), ('thermonuclear', 2), ('anarchical', 2), ('externally', 2), ('signify', 2), ('apprehended', 2), ('sittings', 2), ('extra-sensory', 2), ('sensitives', 2), ('clinics', 2), ('ill-conceived', 2), ('deformity', 2), ('hereditary', 2), ('knowingly', 2), ('neon-lit', 2), ('overcrowded', 2), ('teamed', 2), ('financier', 2), ('audition', 2), ('deauville', 2), ('diana', 2), ('nudity', 2), ('dishearten', 2), ('dilatation', 2), ('childbirth', 2), ('dilate', 2), ('folk-lore', 2), ('gynecologists', 2), ('remake', 2), ('forbears', 2), ('puzzles', 2), ('dandy', 2), ('amaze', 2), ('puttering', 2), ('barracks', 2), ('rackety', 2), ('old-style', 2), ('pouches', 2), ('countered', 2), ('curtiss', 2), ('landings', 2), ('takeoffs', 2), ('easing', 2), ('ruptured', 2), ('northfield', 2), ('biplane', 2), ('buffeted', 2), ('hiking', 2), ('kelp', 2), ('wheat-germ', 2), ('pours', 2), ('menus', 2), ('squash', 2), ('sniffing', 2), ('insecticides', 2), ('erupt', 2), ('junkers', 2), ('keening', 2), ('tinsel', 2), ('schooner', 2), ('sorrentine', 2), ('rochford', 2), ('anti-aircraft', 2), ('naples', 2), ('me-210', 2), ('701', 2), ('poisonous', 2), ('blauberman', 2), ('articulated', 2), ('therapists', 2), ('facial', 2), ('paralanguage', 2), ('regrettably', 2), ('junctures', 2), ('oversoft', 2), ('macarthur', 2), ('real-life', 2), ('overhangs', 2), ('well-designed', 2), ('compressor', 2), ('releasing', 2), ('oversize', 2), ('conditioners', 2), ('square-foot', 2), ('glass-fiber', 2), ('vacuuming', 2), ('horseplay', 2), ('lashes', 2), ('sharks', 2), ('pool-side', 2), ('restful', 2), ('trek', 2), ('corder', 2), ('inclement', 2), ('139', 2), ('fairmont', 2), ('confederates', 2), ('1827', 2), ('finley', 2), ('templeman', 2), ('oration', 2), ('herewith', 2), ('engraving', 2), ('patented', 2), ('subscribing', 2), ('ble', 2), ('1791', 2), ('cutter', 2), ('adjustable', 2), ('drills', 2), ('pulleys', 2), ('louvers', 2), ('weatherproof', 2), ('carport', 2), ('accessibility', 2), ('decking', 2), ('sanded', 2), ('trimming', 2), ('laminated', 2), ('resin-saturated', 2), ('misalignment', 2), ('bilge', 2), ('notched', 2), ('weldwood', 2), ('gator', 2), ('skiis', 2), ('cruiser', 2), ('merc', 2), ('dowel', 2), ('stopper', 2), ('shaker', 2), ('sponged', 2), ('08', 2), ('bevel', 2), ('jars', 2), ('eraser', 2), ('unfired', 2), ('craters', 2), ('cupped', 2), ('cones', 2), ('one-stroke', 2), ('glazing', 2), ('gashes', 2), ('onions', 2), ('sweet-sour', 2), ('paprika', 2), ('tasty', 2), ('styled', 2), ('horse-radish', 2), ('sedately', 2), ('grilled', 2), ('feuchtwanger', 2), ('mushroom', 2), ('skillet', 2), ('relishes', 2), ('mugs', 2), ('barbecues', 2), ('melamine', 2), ('desserts', 2), ('diagonally', 2), ('sear', 2), ('basting', 2), ('prisons', 2), ('flaky', 2), ('bayezit', 2), ('octagonal', 2), ('heliopolis', 2), ('stubby', 2), ('temples', 2), ('ottoman', 2), ('turks', 2), ('1453', 2), ('mosques', 2), ('spires', 2), ('boulevards', 2), ('haphazard', 2), ('world-renowned', 2), ('carriages', 2), ('abilene', 2), ('unfold', 2), ('synchronized', 2), ('gatlinburg', 2), ('seaquarium', 2), ('weekday', 2), ('adirondack', 2), ('battlefields', 2), ('photogenic', 2), ('bakery', 2), ('cloves', 2), ('cured', 2), ('redwoods', 2), ('tilt', 2), ('moorish', 2), ('celery', 2), ('arbogast', 2), ('omelet', 2), ('cayenne', 2), ('seasoning', 2), ('kirkpatrick', 2), ('coachmen', 2), ('napkins', 2), ('fir', 2), ('botanists', 2), ('hostler', 2), ('redwood', 2), ('optional', 2), ('scattergun', 2), ('pump-action', 2), ('.410', 2), ('top-tang', 2), ('deluxe', 2), ('742', 2), ('tr', 2), ('mossberg', 2), ('.458', 2), ('.375', 2), ('.264', 2), ('fn', 2), ('varmint', 2), ('fps', 2), ('sapling', 2), ('deadliness', 2), ('whitetail', 2), ('lookout', 2), ('02.3', 2), ('04.2', 2), ('lass', 2), ('lullwater', 2), ('comet', 2), ('34.3', 2), ('gene-princess', 2), ('last-named', 2), ('grattan', 2), ('valentine', 2), ('dream-miss', 2), ('sampson', 2), ('33.2', 2), ('torrid', 2), ('blistered', 2), ('32.2', 2), ('thrived', 2), ('mon-goddess', 2), ('mon-columbia', 2), ('mon-fay', 2), ('pride-starlette', 2), ('stardel', 2), ('work-out', 2), ('conformation', 2), ('heel-miracle', 2), ('kimberly', 2), ('raceway', 2), ('domed', 2), ('pistons', 2), ('beaker', 2), ('cc', 2), ('blanks', 2), ('remotely', 2), ('figs', 2), ('underside', 2), ('chamfer', 2), ('spacer', 2), ('center-punch', 2), ('compress', 2), ('snag', 2), ('turnouts', 2), ('turnout', 2), ('boatyards', 2), ('yachtel', 2), ('coined', 2), ('piloting', 2), ('squadrons', 2), ('booklets', 2), ('naebm', 2), ('reorganized', 2), ('foreseeing', 2), ('owning', 2), ('wherein', 2), ('phenomenal', 2), ('outboards', 2), ('texoma', 2), ('pointer', 2), ('trophies', 2), ('superintendents', 2), ('brumby', 2), ('handlers', 2), ('campaigners', 2), ('betsey', 2), ('forty-six', 2), ('samos', 2), ('to-one', 2), ('vtol', 2), ('one-shot', 2), ('imprecisely', 2), ('trajectory', 2), ('defenseless', 2), ('pulsating', 2), ('millionaire', 2), ('diario', 2), ('catherine', 2), ('sherrill', 2), ('mailing', 2), ('galatians', 2), ('blemish', 2), ('zendo', 2), ('appeased', 2), ('torrent', 2), ('credulity', 2), ('seclusion', 2), ('magically', 2), ('anchorite', 2), ('patriarch', 2), ('exponents', 2), ('quietism', 2), ('proponents', 2), ('practicality', 2), ('confucianism', 2), ('bonzes', 2), ('unchanging', 2), ('quietist', 2), ('taoists', 2), ('constraint', 2), ('otherworldly', 2), ('awesome', 2), ('tappan', 2), ('beecher', 2), ('greenleaf', 2), ('alleviation', 2), ('hopkinsian', 2), ('parentage', 2), ('revivalism', 2), ('malicious', 2), ('subscribed', 2), ('connexion', 2), ('predetermined', 2), ('milky', 2), ('snowing', 2), ('octillion', 2), ('wanton', 2), ('ambivalence', 2), ('forthrightness', 2), ('colloquium', 2), ('wesleyan', 2), ('preconditioned', 2), ('eighty-four', 2), ('incur', 2), ('capitulation', 2), ('devastation', 2), ('problematic', 2), ('efficaciously', 2), ('risks', 2), ('finality', 2), ('absoluteness', 2), ('newbiggin', 2), ('weigel', 2), ('khan', 2), ('muslims', 2), ('ironically', 2), ('adventists', 2), ('buddhists', 2), ('non-christians', 2), ('compensate', 2), ('forcibly', 2), ('participant', 2), ('memorized', 2), ('refreshments', 2), ('79', 2), ('discipleship', 2), ('outlining', 2), ('visitation', 2), ('yin-yang', 2), ('fives', 2), ('five-elements', 2), ('dynastic', 2), ('erased', 2), ('wei', 2), ('famine', 2), ('threefold', 2), ('unfounded', 2), ('confessional', 2), ('suicides', 2), ('perish', 2), ('believeth', 2), ('trusteth', 2), ('giveth', 2), ('dearest', 2), ('arraigned', 2), ('genteel', 2), ('hyperbole', 2), ('exquisitely', 2), ('mobs', 2), ('veneration', 2), ('contagion', 2), ('naming', 2), ('liberality', 2), ('excommunicated', 2), ('unitarians', 2), ('frothingham', 2), ('unitarianism', 2), ('judiciously', 2), ('oz', 2), ('poly-unsaturated', 2), ('mono-unsaturated', 2), ('fatalities', 2), ('calorie', 2), ('insecurity', 2), ('drinker', 2), ('insidious', 2), ('2300', 2), ('physiologist', 2), ('spinach', 2), ('automated', 2), ('consume', 2), ('lbs.', 2), ('lanza', 2), ('militarist', 2), ('monty', 2), ('poverty-stricken', 2), ('ably', 2), ('mystics', 2), ('nobleman', 2), ('pontchartrain', 2), ('brazos', 2), ('launches', 2), ('undependable', 2), ('laps', 2), ('shingles', 2), ('loveliest', 2), ('delon', 2), ('niagara', 2), ('depict', 2), ('mccullers', 2), ('rye', 2), ('aspencades', 2), ('hiawatha', 2), ('shawnee', 2), ('mid-october', 2), ('berkshires', 2), ('scarlet', 2), ('maples', 2), ('aspen', 2), ('keyed', 2), ('canadians', 2), ('platter', 2), ('hilarious', 2), ('moiseyev', 2), ('blomdahl', 2), ('programed', 2), ('julep', 2), ('vicenza', 2), ('palladio', 2), ('andrea', 2), ('invigoration', 2), ('astonishment', 2), ('sniff', 2), ('lifts', 2), ('lavallade', 2), ('enthusiasts', 2), ('wolf', 2), ('lieder', 2), ('grieving', 2), ('leonato', 2), ('papp', 2), ('rink', 2), ('skating', 2), ('jilted', 2), ('brand-new', 2), ('telescope', 2), ('gravitation', 2), ('relativity', 2), ('whitrow', 2), ('moderator', 2), ('cosmology', 2), ('cosmologists', 2), ('tortoise', 2), ('dtisches', 2), ('sta', 2), ('wangenheim', 2), ('chronology', 2), ('quotes', 2), ('wwrl', 2), ('boasts', 2), ('upgrade', 2), ('carmen', 2), ('verreau', 2), ('cites', 2), ('zealous', 2), ('chronological', 2), ('sergei', 2), ('moiseyeva', 2), ('petipa-minkus', 2), ('sokolov', 2), ('bulba', 2), ('taras', 2), ('livshitz', 2), ('alexandre', 2), ('unresolved', 2), ('artless', 2), ('adultery', 2), ('potboiler', 2), ('romanza', 2), ('riegger', 2), ('schuman', 2), ('creston', 2), ('mischa', 2), ('ramble', 2), ('djangology', 2), ('reinhardt', 2), ('bourgeois', 2), ('impersonation', 2), ('deluded', 2), ('clowns', 2), ('ludicrous', 2), ('solitude', 2), ('idyll', 2), ('nip', 2), ('recounts', 2), ('fjords', 2), ('dotting', 2), ('persuasively', 2), ('cruise', 2), ('1643', 2), ('lso', 2), ('1066', 2), ('loc', 2), ('blush', 2), ('gems', 2), ('gershwins', 2), ('wallenstein', 2), ('tchaikovsky', 2), ('toobin', 2), ('menacing', 2), ('refreshingly', 2), ('tamiris', 2), ('alwin', 2), ('agreeable', 2), ('french-canadian', 2), ('chantey', 2), ('gilels', 2), ('getz', 2), ('hannah', 2), ('julie', 2), ('vocalists', 2), ('mellowed', 2), ('timid', 2), ('glimpses', 2), ('blakey', 2), ('shine', 2), ('chubby', 2), ('milhaud', 2), ('gontran', 2), ('essentials', 2), ('light-weight', 2), ('giuseppe', 2), ('anton', 2), ('corelli', 2), ('shakes', 2), ('bodin', 2), ('out-of-the-way', 2), ('musique', 2), ('elizabethan', 2), ('chansons', 2), ('masterpieces', 2), ('deller', 2), ('alvise', 2), ('siepi', 2), ('resnik', 2), ('cloying', 2), ('chromatic', 2), ('paray', 2), ('cole', 2), ('limber', 2), ('authentically', 2), ('malevolence', 2), ('mettle', 2), ('foy', 2), ('matchmaker', 2), ('danaher', 2), ('innesfree', 2), ('wistful', 2), ('purges', 2), ('hiss', 2), ('yalta', 2), ('fables', 2), ('wharf', 2), ('catfish', 2), ('puny', 2), ('lunchtime', 2), ('viscera', 2), ('essences', 2), ('quotation', 2), ('virginian', 2), ('wister', 2), ('sneaky', 2), ('exaggerating', 2), ('paean', 2), ('vistas', 2), ('slumber', 2), ('alphabetical', 2), ('cunningly', 2), ('belaboring', 2), ('fronting', 2), ('hardwick', 2), ('mazurka', 2), ('selectively', 2), ('britten', 2), ('bragg', 2), ('remnants', 2), ('viscount', 2), ('rachmaninoff', 2), ('bella', 2), ('directness', 2), ('jenni', 2), ('unclear', 2), ('falsehoods', 2), ('marred', 2), ('rebuttal', 2), ('formality', 2), ('submits', 2), ('commits', 2), ('estimation', 2), ('transcripts', 2), ('fifteen-minute', 2), ('dogmatism', 2), ('lucas', 2), ('khrushchevs', 2), ('mar.', 2), ('capet', 2), ('clemency', 2), ('flier', 2), ('steuben', 2), ('hessian', 2), ('equitably', 2), ('enviable', 2), ('anticipating', 2), ('many-sided', 2), ('libertarians', 2), ('rub', 2), ('sellers', 2), ('dearth', 2), ('recoilless', 2), ('contretemps', 2), ('shiloh', 2), ('helmets', 2), ('albanians', 2), ('albanian', 2), ('albania', 2), ('twenty-year', 2), ('en-lai', 2), ('chou', 2), ('soviet-chinese', 2), ('harping', 2), ('kolkhoz', 2), ('rehash', 2), ('twelve-hour', 2), ('nudes', 2), ('spittle', 2), ('somber', 2), ('cityscapes', 2), ('expressionist', 2), ('turtleneck', 2), ('seamen', 2), ('divorcee', 2), ('intriguingly', 2), ('voluble', 2), ('cosmopolitan', 2), ('crass', 2), ('crawls', 2), ('improvisations', 2), ('burlesque', 2), ('adapters', 2), ('conquering', 2), ('mi', 2), ('hostage', 2), ('owes', 2), ('bestseller', 2), ('nowadays', 2), ('tito', 2), ('suez-hungary', 2), ('nkrumah', 2), ('castros', 2), ('suez', 2), ('strategically', 2), ('hurriedly', 2), ('quemoy', 2), ('gladly', 2), ('heightening', 2), ('algeria', 2), ('bleed', 2), ('despot', 2), ('depersonalization', 2), ('450000', 2), ('liberate', 2), ('self-delusion', 2), ('ethically', 2), ('lebanese', 2), ('unbalanced', 2), ('apologetic', 2), ('6.9', 2), ('reverses', 2), ('ecumenical', 2), ('holiness', 2), ('evaded', 2), ('broom', 2), ('resuming', 2), ('embryonic', 2), ('long-lived', 2), ('phs', 2), ('balloons', 2), ('glenn', 2), ('poisoning', 2), ('invisibly', 2), ('sect', 2), ('awnings', 2), ('bigotry', 2), ('fanatical', 2), ('moloch', 2), ('inflicting', 2), ('thugs', 2), ('delinquents', 2), ('dislikes', 2), ('fairmount', 2), ('dictators', 2), ('nagasaki', 2), ('arsenal', 2), ('ghost', 2), ('trimmer', 2), ('ordinances', 2), ('woodward', 2), ('servicing', 2), ('eighty-seventh', 2), ('militarism', 2), ('fossilized', 2), ('biscuit', 2), ('freeholders', 2), ('burdens', 2), ('katangans', 2), ('gizenga', 2), ('plus-one', 2), ('reek', 2), ('192', 2), ('unskilled', 2), ('liberace', 2), ('depaul', 2), ('packaged', 2), ('week-ends', 2), ('vitriolic', 2), ('hospitalization', 2), ('irving', 2), ('gabrielle', 2), ('migrant', 2), ('olson', 2), ('preston', 2), ('exemptions', 2), ('migrants', 2), ('endorsement', 2), ('recess', 2), ('oaths', 2), ('pre-legislative', 2), ('underscored', 2), ('mundt', 2), ('rasp', 2), ('strolling', 2), ('unaccountably', 2), ('tethered', 2), ('lilting', 2), ('wanders', 2), ('grad', 2), ('blest', 2), ('alight', 2), ('galilee', 2), ('baptism', 2), ('archaic', 2), ('translations', 2), ('autograph', 2), ('managerial', 2), ('1884', 2), ('grandson', 2), ('lucius', 2), ('ziegfeld', 2), ('baron', 2), ('sochi', 2), ('non-military', 2), ('lawful', 2), ('painstakingly', 2), ('espoused', 2), ('ziffren', 2), ('hopefuls', 2), ('staked', 2), ('participates', 2), ('pyramid', 2), ('pre-primary', 2), ('top-drawer', 2), ('naturalistic', 2), ('upholstery', 2), ('crewel', 2), ('outgrow', 2), ('uncover', 2), ('stiffens', 2), ('autism', 2), ('oncoming', 2), ('injustice', 2), ('soggy', 2), ('invading', 2), ('incipient', 2), ('four-lane', 2), ('resorting', 2), ('rivaled', 2), ('purring', 2), ('alacrity', 2), ('bidders', 2), ('auctioneer', 2), ('ministered', 2), ('bestow', 2), ('sacrificial', 2), ('vainly', 2), ('riches', 2), ('ruthlessly', 2), ('toughest', 2), ('saith', 2), ('22000', 2), ('loads', 2), ('accuses', 2), ('permissive', 2), ('reformer', 2), ('consolidating', 2), ('speculation', 2), ('expediting', 2), ('appropriating', 2), ('watchdog', 2), ('nonpartisan', 2), ('lyndon', 2), ('all-powerful', 2), ('reformers', 2), ('clair', 2), ('carbondale', 2), ('desirability', 2), ('herons', 2), ('jobless', 2), ('sihanouk', 2), ('basing', 2), ('shortening', 2), ('secession', 2), ('eradicate', 2), ('trujillos', 2), ('warships', 2), ('anti-secrecy', 2), ('developers', 2), ('offshore', 2), ('einstein', 2), ('confusions', 2), ('capitalize', 2), ('blaming', 2), ('disagrees', 2), ('subversive', 2), ('unification', 2), ('shortest', 2), ('cooperated', 2), ('long-awaited', 2), ('goodbody', 2), ('precariously', 2), ('hangs', 2), ('shockwave', 2), ('half-hearted', 2), ('protecting', 2), ('demurrer', 2), ('gunman', 2), ('admirer', 2), ('covenant', 2), ('fantastically', 2), ('savages', 2), ('etv', 2), ('unreasonable', 2), ('casualties', 2), ('mercilessly', 2), ('shortcomings', 2), ('livelier', 2), ('broadcasters', 2), ('hard-liquor', 2), ('clinch', 2), ('ecological', 2), ('unfenced', 2), ('salami', 2), ('ulbricht', 2), ('dismemberment', 2), ('acquiesce', 2), ('authoritarianism', 2), ('tacit', 2), ('censure', 2), ('overflowing', 2), ('venezuelan', 2), ('demise', 2), ('betancourt', 2), ('hunk', 2), ('emmerich', 2), ('extremity', 2), ('delusion', 2), ('area-wide', 2), ('undertaking', 2), ('wolves', 2), ('spate', 2), ('reappraisal', 2), ('brochures', 2), ('bookkeeping', 2), ('discounts', 2), ('interlibrary', 2), ('microfilm', 2), ('startlingly', 2), ('five-cent', 2), ('nationalized', 2), ('chafing', 2), ('pakistanis', 2), ('textile-producing', 2), ('turin', 2), ('toured', 2), ('break-even', 2), ('investor', 2), ('per-year', 2), ('bean', 2), ('idaho', 2), ('enlivened', 2), ('160000', 2), ('peacetime', 2), ('transporting', 2), ('distracted', 2), ('mullen', 2), ('mccauley', 2), ('refuel', 2), ('radioed', 2), ('hijacked', 2), ('carnegey', 2), ('stewardess', 2), ('mongolia', 2), ('kai-shek', 2), ('picks', 2), ('ladgham', 2), ('thorny', 2), ('unify', 2), ('directive', 2), ('obstructionist', 2), ('mobutu', 2), ('three-month', 2), ('eire', 2), ('secretary-general', 2), ('seceded', 2), ('tribesmen', 2), ('publique', 2), ('kasai', 2), ('detested', 2), ('une', 2), ('gale', 2), ('colossus', 2), ('brussels', 2), ('imagines', 2), ('paternalism', 2), ('temperate', 2), ('1885', 2), ('leopold', 2), ('excite', 2), ('heady', 2), ('endowment', 2), ('maynard', 2), ('caltech', 2), ('grads', 2), ('teahouse', 2), ('pretexts', 2), ('beyeler', 2), ('ernst', 2), ('klees', 2), ('sseldorf', 2), ('prix', 2), ('zealand', 2), ('93', 2), ('hearty', 2), ('hitched', 2), ('spills', 2), ('armory', 2), ('fielders', 2), ('sportswriter', 2), ('benched', 2), ('dark-haired', 2), ('minors', 2), ('fargo', 2), ('oldsmobile', 2), ('greenberg', 2), ('spurt', 2), ('home-run', 2), ('shrinking', 2), ('chipped', 2), ('four-wood', 2), ('mar', 2), ('fairways', 2), ('thunderous', 2), ('birdies', 2), ('contender', 2), ('cloudless', 2), ('winnings', 2), ('mano', 2), ('213', 2), ('three-round', 2), ('jitters', 2), ('agonizing', 2), ('mishap', 2), ('bogeyed', 2), ('pros', 2), ('ante', 2), ('upped', 2), ('three-fifths', 2), ('filibuster', 2), ('wilbur', 2), ('caucus', 2), ('internationalist', 2), ('dour', 2), ('breaching', 2), ('bottleneck', 2), ('acknowledgment', 2), ('appeasement', 2), ('battleground', 2), ('closed-door', 2), ('guise', 2), ('amend', 2), ('hoffa', 2), ('monopolistic', 2), ('hypocrisies', 2), ('subsidy', 2), ('palmed', 2), ('landrum-griffin', 2), ('ineptness', 2), ('managements', 2), ('govern', 2), ('allocate', 2), ('heavy-electrical-goods', 2), ('undefined', 2), ('jurisdictional', 2), ('underestimate', 2), ('coveted', 2), ('declines', 2), ('low-key', 2), ('pitifully', 2), ('staffed', 2), ('comradeship', 2), ('disunity', 2), ('dangerously', 2), ('three-man', 2), ('deteriorating', 2), ('lull', 2), ('blacks', 2), ('antagonisms', 2), ('ignoring', 2), ('alexandria', 2), ('nw.', 2), ('bouton', 2), ('letitia', 2), ('music-loving', 2), ('transylvania', 2), ('lenygon', 2), ('competed', 2), ('rarity', 2), ('unveiled', 2), ('redecoration', 2), ('andover', 2), ('fair-weather', 2), ('nozzle', 2), ('ha', 2), ('heartbreaking', 2), ('four-letter', 2), ('fellini', 2), ('seaside', 2), ('nymphomaniacs', 2), ('decadence', 2), ('watchers', 2), ('three-hour', 2), ('immorality', 2), ('cellist', 2), ('franciscans', 2), ('sponsoring', 2), ('solos', 2), ('courtly', 2), ('zubkovskaya', 2), ('soloviev', 2), ('alla', 2), ('incomparable', 2), ('kolpakova', 2), ('irina', 2), ('undistinguished', 2), ('incomparably', 2), ('renowned', 2), ('cecilia', 2), ('orchestre', 2), ('five-month', 2), ('ordained', 2), ('henderson', 2), ('riviera', 2), ('rae', 2), ('lois', 2), ('jon', 2), ('antidote', 2), ('jacksonville', 2), ('schenk', 2), ('morley', 2), ('bea', 2), ('gould', 2), ('plotting', 2), ('airline', 2), ('heilman', 2), ('remodeling', 2), ('galt', 2), ('rum', 2), ('judson', 2), ('lasalle', 2), ('flip', 2), ('chalk', 2), ('augmenting', 2), ('tambourine', 2), ('bonanza', 2), ('alden', 2), ('tricked', 2), ('antiques', 2), ('merry-go-round', 2), ('fixture', 2), ('lockies', 2), ('chases', 2), ('arden', 2), ('todd', 2), ('curry', 2), ('coopers', 2), ('updated', 2), ('subtitled', 2), ('grammar', 2), ('raincoats', 2), ('wilshire', 2), ('mmes.', 2), ('becket', 2), ('bolker', 2), ('bake-off', 2), ('cooky', 2), ('jamaica', 2), ('fun-loving', 2), ('roquemore', 2), ('get-together', 2), ('fronted', 2), ('dressers', 2), ('decorate', 2), ('recessed', 2), ('paneled', 2), ('burl', 2), ('chestnut', 2), ('perennian', 2), ('mayonnaise', 2), ('195', 2), ('snacks', 2), ('ogled', 2), ('starring', 2), ('pinks', 2), ('irene', 2), ('norell', 2), ('timeless', 2), ('showings', 2), ('non-profit', 2), ('discriminatory', 2), ('pitfall', 2), ('tax-free', 2), ('mid-september', 2), ('year-earlier', 2), ('keeler', 2), ('houtz', 2), ('shareholders', 2), ('programmed', 2), ('1986', 2), ('holdings', 2), ('hoped-for', 2), ('erasing', 2), ('abortive', 2), ('conferees', 2), ('gauntlet', 2), ('assn.', 2), ('hammond', 2), ('eaton', 2), ('tech.', 2), ('sheraton-dallas', 2), ('year-to-year', 2), ('registrations', 2), ('saws', 2), ('harvesting', 2), ('cen-tennial', 2), ('hardwicke-etter', 2), ('price-earnings', 2), ('frito', 2), ('guerin', 2), ('12.50', 2), ('lucrative', 2), ('detonation', 2), ('deodorant', 2), ('pesce', 2), ('prosecutors', 2), ('grisly', 2), ('figone', 2), ('steer', 2), ('stave', 2), ('warhead', 2), ('reichenberg', 2), ('heinkel', 2), ('lenient', 2), ('excused', 2), ('grooms', 2), ('kretchmer', 2), ('aurora', 2), ('journal-bulletin', 2), ('55000', 2), ('democratic-endorsed', 2), ('bumper', 2), ('incinerator', 2), ('picketed', 2), ('pawtucket', 2), ('eddy', 2), ('earrings', 2), ('jewels', 2), ('uninjured', 2), ('grenier', 2), ('tigard', 2), ('nyberg', 2), ('swine', 2), ('carol', 2), ('phyllis', 2), ('zurcher', 2), ('stephanie', 2), ('horsemanship', 2), ('kathleen', 2), ('stephenson', 2), ('georgia-pacific', 2), ('interment', 2), ('af', 2), ('durante', 2), ('67', 2), ('cio', 2), ('afl', 2), ('gateway', 2), ('logan', 2), ('holdup', 2), ('robber', 2), ('juras', 2), ('adapting', 2), ('renew', 2), ('slackening', 2), ('budgeted', 2), ('lawrenceville', 2), ('calvary', 2), ('snellville', 2), ('allergic', 2), ('65000', 2), ('bulloch', 2), ('wistfully', 2), ('melee', 2), ('ronald', 2), ('crawford', 2), ('marietta', 2), ('gettysburg', 2), ('kililngsworth', 2), ('three-day', 2), ('picketing', 2), ('aforementioned', 2), ('tax-exemption', 2), ('by-laws', 2), ('kegham', 2), ('disbanded', 2), ('pinar', 2), ('executions', 2), ('sarkees', 2), ('belvidere', 2), ('grader', 2), ('sisk', 2), ('motorist', 2), ('pohly', 2), ('fuhrmann', 2), ('dequindre', 2), ('sister-in-law', 2), ('pankowski', 2), ('bottled', 2), ('homeowners', 2), ('aftermath', 2), ('deliberation', 2), ('arson', 2), ('westphalia', 2), ('skidded', 2), ('speeding', 2), ('slaying', 2), ('reformatory', 2), ('dunkel', 2), ('accosted', 2), ('paycheck', 2), ('pullings', 2), ('jeremiah', 2), ('sears', 2), ('heroin', 2), ('narcotic', 2), ('indictments', 2), ('cooperman', 2), ('malice', 2), ('70000', 2), ('westinghouse', 2), ('bedridden', 2), ('maiden', 2), ('lola', 2), ('anti-submarine', 2), ('nautilus', 2), ('subs', 2), ('balconies', 2), ('trouble-free', 2), ('pantas', 2), ('nonresidential', 2), ('somerset', 2), ('tawes', 2), ('edgewater', 2), ('dresbachs', 2), ('elmer', 2), ('detention', 2), ('inefficient', 2), ('banned', 2), ('229', 2), ('second-degree', 2), ('somerville', 2), ('assailant', 2), ('beads', 2), ('edging', 2), ('trimmed', 2), ('tiers', 2), ('taffeta', 2), ('rowley', 2), ('nairne', 2), ('pierson', 2), ('achaeans', 2), ('pl.', 2), ('feted', 2), ('comus', 2), ('wellesley', 2), ('emmert', 2), ('orcutt', 2), ('marella', 2), ('rosen', 2), ('co-chairmen', 2), ('schultz', 2), ('blum', 2), ('shoettle', 2), ('honorary', 2), ('newbold', 2), ('clyde', 2), ('1213', 2), ('cohen', 2), ('grillwork', 2), ('reproductions', 2), ('specialties', 2), ('grinsfelder', 2), ('ervin', 2), ('glison', 2), ('pampa', 2), ('glenda', 2), ('christi', 2), ('newlyweds', 2), ('mayfair', 2), ('conn.', 2), ('hartford', 2), ('stephanotis', 2), ('accented', 2), ('princesse', 2), ('neckline', 2), ('bateau', 2), ('organdy', 2), ('elvis', 2), ('sequoia', 2), ('perkins', 2), ('monica', 2), ('coronado', 2), ('brocade', 2), ('carpeting', 2), ('wall-to-wall', 2), ('boasting', 2), ('heather', 2), ('tucson', 2), ('safari', 2), ('all-american', 2), ('readjust', 2), ('skid', 2), ('parolees', 2), ('scarsdale', 2), ('rickenbaugh', 2), ('butler', 2), ('bradford', 2), ('pate', 2), ('mead', 2), ('bldg.', 2), ('cocktails', 2), ('piero', 2), ('mullenax', 2), ('patio', 2), ('lorenz', 2), ('sidled', 2), ('struggles', 2), ('mets', 2), ('trager', 2), ('biz', 2), ('jude', 2), ('gals', 2), ('wed', 2), ('exec', 2), ('debuting', 2), ('lucille', 2), ('ex-mrs.', 2), ('lyon', 2), ('sethness', 2), ('lambert', 2), ('balkan', 2), ('cotillion', 2), ('arab', 2), ('bridal', 2), ('uncles', 2), ('beadles', 2), ('vero', 2), ('parichy', 2), ('off-beat', 2), ('starred', 2), ('armour', 2), ('defraud', 2), ('schwab', 2), ('acquittal', 2), ('mistrial', 2), ('sexton', 2), ('five-year', 2), ('re-election', 2), ('blueprints', 2), ('swearing', 2), ('kiwanis', 2), ('hatfield', 2), ('exported', 2), ('extraordinarily', 2), ('pardoned', 2), ('pledges', 2), ('protocol', 2), ('menderes', 2), ('by-passing', 2), ('shiflett', 2), ('fractures', 2), ('stanton', 2), ('dicks', 2), ('pedestrians', 2), ('reprimanded', 2), ('hit-run', 2), ('davenport', 2), ('collects', 2), ('regulate', 2), ('knauer', 2), ('varani', 2), ('erection', 2), ('stab', 2), ('grant-in-aid', 2), ('bypass', 2), ('withstand', 2), ('diem', 2), ('re-enactment', 2), ('shrines', 2), ('ceremonial', 2), ('six-point', 2), ('malcolm', 2), ('zurich', 2), ('150000000', 2), ('ninety-nine', 2), ('uncommitted', 2), ('under-developed', 2), ('40000000', 2), ('neill', 2), ('dormitories', 2), ('carmine', 2), ('last-minute', 2), ('mayoral', 2), ('anti-organization', 2), ('beame', 2), ('screvane', 2), ('geraldine', 2), ('four-year', 2), ('underwrite', 2), ('wardens', 2), ('bontempo', 2), ('seidel', 2), ('duffy', 2), ('macdonald', 2), ('roos', 2), ('ballots', 2), ('committeewoman', 2), ('greenfield', 2), ('r-n.', 2), ('nominee', 2), ('barbs', 2), ('decried', 2), ('mediocre', 2), ('congealed', 2), ('trenton', 2), ('boos', 2), ('fines', 2), ('scheduling', 2), ('canvassers', 2), ('seekonk', 2), ('sirens', 2), ('laughlin', 2), ('defray', 2), ('larceny', 2), ('revamped', 2), ('shipped', 2), ('cornerstone', 2), ('inconclusive', 2), ('locomotive', 2), ('candor', 2), ('tex', 2), ('ind', 2), ('halleck', 2), ('92', 2), ('stays', 2), ('advisement', 2), ('coercion', 2), ('.8', 2), ('nov', 2), ('hyannis', 2), ('drafts', 2), ('courtroom', 2), ('disclosure', 2), ('summerdale', 2), ('pegboards', 2), ('treacherous', 2), ('complicate', 2), ('polishing', 2), ('breakdowns', 2), ('atta', 2), ('shaky', 2), ('undressing', 2), ('sweatshirt', 2), ('bum', 2), ('powerfully', 2), ('uproar', 2), ('hop', 2), ('signor', 2), ('approvingly', 2), ('enchantment', 2), ('boxcars', 2), ('ferraro', 2), ('wearying', 2), ('atheists', 2), ('dogmatic', 2), ('englishman', 2), ('alberto', 2), ('lancaster', 2), ('illustrating', 2), ('craftsmanship', 2), ('artisan', 2), ('multitudinous', 2), ('brush-off', 2), ('smack', 2), ('freshness', 2), ('reflections', 2), ('shields', 2), ('crammed', 2), ('pen-and-ink', 2), ('saturdays', 2), ('scrubbing', 2), ('malingering', 2), ('furrowed', 2), ('swelled', 2), ('delivers', 2), ('underwear', 2), ('leak', 2), ('feelers', 2), ('cockroaches', 2), ('poling', 2), ('chariot', 2), ('hazel', 2), ('undoing', 2), ('shackles', 2), ('averted', 2), ('midshipmen', 2), ('self-confident', 2), ('staunch', 2), ('tillotson', 2), ('midshipman', 2), ('reasoned', 2), ('deslonde', 2), ('adrien', 2), ('shackled', 2), ('topgallant', 2), ('mysteriously', 2), ('heavers', 2), ('andrews', 2), ('chide', 2), ('vehemence', 2), ('rimmed', 2), ('wade', 2), ('sluice', 2), ('beasts', 2), ('smoldered', 2), ('hubs', 2), ('cloudburst', 2), ('goaded', 2), ('crests', 2), ('sparked', 2), ('stale', 2), ('featureless', 2), ('plain-clothesmen', 2), ('monstrosity', 2), ('relaxes', 2), ('salacious', 2), ('grits', 2), ('oatnut', 2), ('fervently', 2), ('shrubbery', 2), ('mawr', 2), ('bryn', 2), ('clutches', 2), ('scooted', 2), ('stills', 2), ('caller', 2), ('high-powered', 2), ('unstrung', 2), ('muffler', 2), ('low-pitched', 2), ('teetotaler', 2), ('protruding', 2), ('flipped', 2), ('cotter', 2), ('loosened', 2), ('unoccupied', 2), ('deluge', 2), ('zigzagging', 2), ('luckily', 2), ('tee-wah', 2), ('purest', 2), ('veering', 2), ('hollered', 2), ('amigo', 2), ('taped', 2), ('senor', 2), ('pick-up', 2), ('uh', 2), ('huhmun', 2), ('bawh', 2), ('wiles', 2), ('mah', 2), ('blinding', 2), ('taunt', 2), ('treble', 2), ('supplicating', 2), ('ovals', 2), ('moderation', 2), ('gracias', 2), ('giggles', 2), ('inverted', 2), ('propeller', 2), ('veer', 2), ('wingman', 2), ('camouflage', 2), ('muddied', 2), ('tacloban', 2), ('ridiculously', 2), ('rumbled', 2), ('walters', 2), ('belton', 2), ('five-hundred', 2), ('ormoc', 2), ('fleischman', 2), ('straits', 2), ('intersecting', 2), ('recklessly', 2), ('madly', 2), ('clipped', 2), ('buzzed', 2), ('brushy', 2), ('twinkling', 2), ('mused', 2), ('leisurely', 2), ('awhile', 2), ('unspoken', 2), ('crip', 2), ('stetson', 2), ('waning', 2), ('complying', 2), ('fangs', 2), ('kneeling', 2), ('shuddering', 2), ('halting', 2), ('sleek', 2), ('tipsy', 2), ('hilt', 2), ('affording', 2), ('tramped', 2), ('rigs', 2), ('dabbing', 2), ('swaying', 2), ('catapulted', 2), ('tines', 2), ('pitchfork', 2), ('bubbled', 2), ('snort', 2), ('sourly', 2), ('curses', 2), ('thrashed', 2), ('rump', 2), ('spineless', 2), ('stacey', 2), ('crunch', 2), ('haltingly', 2), ('molinari', 2), ('carelessly', 2), ('foresee', 2), ('patrolled', 2), ('outdated', 2), ('tacked', 2), ('keane', 2), ('brother-in-law', 2), ('cattlemen', 2), ('nester', 2), ('shoot-down', 2), ('buckboard', 2), ('rustler', 2), ('defiant', 2), ('unplowed', 2), ('cheyenne', 2), ('alibi', 2), ('face-to-face', 2), ('settler', 2), ('campfire', 2), ('arturo', 2), ('dismounting', 2), ('lockup', 2), ('puffing', 2), ('slicker', 2), ('jesse', 2), ('reined', 2), ('ramirez', 2), ('donned', 2), ('rumble', 2), ('lurid', 2), ('senora', 2), ('unhappiness', 2), ('midday', 2), ('sourdough', 2), ('garcia', 2), ('slash-b', 2), ('flailing', 2), ('leaden', 2), ('withdrawn', 2), ('derision', 2), ('numbing', 2), ('punch', 2), ('inadvertently', 2), ('mis-ter', 2), ('gangster', 2), ('payday', 2), ('banging', 2), ('proffered', 2), ('mincing', 2), ('conceding', 2), ('hunkered', 2), ('pursed', 2), ('somethin', 2), ('miraculously', 2), ('sedan', 2), ('blackmailer', 2), ('outsmarted', 2), ('glint', 2), ('sodden', 2), ('wastebasket', 2), ('freddie', 2), ('confessor', 2), ('thirty-two', 2), ('muse', 2), ('clientele', 2), ('gonzalez', 2), ('clods', 2), ('diligence', 2), ('gunnar', 2), ('eying', 2), ('patrolmen', 2), ('thinly', 2), ('vaughn', 2), ('rinker', 2), ('day-watch', 2), ('chopping', 2), ('gut', 2), ('clamping', 2), ('about-faced', 2), ('schaeffer', 2), ('torrence', 2), ('stuffing', 2), ('hiram', 2), ('ingleside', 2), ('fumbled', 2), ('fussing', 2), ('vestibule', 2), ('patrolling', 2), ('legation', 2), ('maroon', 2), ('wraps', 2), ('fuzz', 2), ('midge', 2), ('unbelievable', 2), ('armchairs', 2), ('landscaped', 2), ('flicker', 2), ('hostesses', 2), ('prized', 2), ('doubting', 2), ('harbored', 2), ('handclasp', 2), ('boyish', 2), ('high-priced', 2), ('one-thirty', 2), ('pathologist', 2), ('herring', 2), ('meditative', 2), ('unlucky', 2), ('too-large', 2), ('blaine', 2), ('grudges', 2), ('dereliction', 2), ('centrifuge', 2), ('lab', 2), ('pearson', 2), ('shrugs', 2), ('lodgings', 2), ('busboy', 2), ('macready', 2), ('coldness', 2), ('seeping', 2), ('pictured', 2), ('outlying', 2), ('wobbled', 2), ('wilfully', 2), ('cringed', 2), ('scheming', 2), ('blatant', 2), ('squinting', 2), ('flaring', 2), ('spying', 2), ('dazed', 2), ('unpredictable', 2), ('unblinkingly', 2), ('jacobs', 2), ('refuted', 2), ('dismally', 2), ('lamplight', 2), ('steadied', 2), ('drizzling', 2), ('commissary', 2), ('cornmeal', 2), ('despairingly', 2), ('dosed', 2), ('moccasins', 2), ('floorboards', 2), ('horribly', 2), ('swished', 2), ('stowe', 2), ('satiric', 2), ('smokehouse', 2), ('strung', 2), ('celie', 2), ('overrun', 2), ('fatter', 2), ('smarter', 2), ('mopping', 2), ('domokous', 2), ('prettyman', 2), ('ounce', 2), ('spaniel', 2), ('crooks', 2), ('litigation', 2), ('lent', 2), ('rationalization', 2), ('harnessed', 2), ('hobbes', 2), ('origins', 2), ('neutralization', 2), ('neutrality', 2), ('resisting', 2), ('discusses', 2), ('spells', 2), ('bargains', 2), ('unenthusiastic', 2), ('hoc', 2), ('groundwork', 2), ('enrollments', 2), ('exceeded', 2), ('swerve', 2), ('step-by-step', 2), ('by-product', 2), ('cloudy', 2), ('uto-aztecan', 2), ('banana', 2), ('elephant', 2), ('lexical', 2), ('tact', 2), ('adjectival', 2), ('asterisks', 2), ('121', 2), ('i-e', 2), ('2.0', 2), ('concordant', 2), ('1.07', 2), ('2.75', 2), ('3.46', 2), ('divergence', 2), ('proto', 2), ('iraqw', 2), ('briefer', 2), ('weighs', 2), ('syllabicity', 2), ('purport', 2), ('tenuous', 2), ('esthetics', 2), ('pedantic', 2), ('orthographies', 2), ('succinctly', 2), ('subsystem', 2), ('phonemes', 2), ('phonemics', 2), ('murmur', 2), ('phonetic', 2), ('interact', 2), ('systematized', 2), ('disentangle', 2), ('nonlinguistic', 2), ('insufficiently', 2), ('pondering', 2), ('simplistic', 2), ('analysed', 2), ('consonant', 2), ('wide-ranging', 2), ('rhyme', 2), ('formative', 2), ('gerundial', 2), ('unambiguously', 2), ('subordinator', 2), ('insulting', 2), ('semantically', 2), ('preposition', 2), ('complements', 2), ('predicator', 2), ('glorify', 2), ('i-th', 2), ('initiates', 2), ('inspected', 2), ('y-region', 2), ('compiling', 2), ('borderline', 2), ('burnham', 2), ('particularistic', 2), ('deplorable', 2), ('flatus', 2), ('welter', 2), ('conveys', 2), ('determinants', 2), ('grooves', 2), ('communicational', 2), ('shutting', 2), ('uncomfortably', 2), ('paranoid', 2), ('morrow', 2), ('good-bye', 2), ('condescension', 2), ('condescending', 2), ('annoy', 2), ('traceable', 2), ('scolding', 2), ('fragmented', 2), ('misconstrued', 2), ('investigative', 2), ('sobs', 2), ('duplicated', 2), ('blackboard', 2), ('defends', 2), ('laxness', 2), ('merciless', 2), ('outstandingly', 2), ('queries', 2), ('successively', 2), ('unabated', 2), ('decrement', 2), ('conjecture', 2), ('graphically', 2), ('descriptive', 2), ('98', 2), ('validate', 2), ('castaneda', 2), ('messy', 2), ('over-achievers', 2), ('stratified', 2), ('socioeconomic', 2), ('tenement', 2), ('earns', 2), ('beneficiary', 2), ('computes', 2), ('decedent', 2), ('aliens', 2), ('nonresident', 2), ('b-47', 2), ('tankers', 2), ('refueling', 2), ('reliability', 2), ('fueled', 2), ('minuteman', 2), ('retaliatory', 2), ('evaluations', 2), ('deployed', 2), ('f-108', 2), ('bidding', 2), ('shipbuilding', 2), ('18.9', 2), ('outweigh', 2), ('proficiency', 2), ('187', 2), ('strengths', 2), ('sorted', 2), ('ambassadors', 2), ('charters', 2), ('alerted', 2), ('delegate', 2), ('intentionally', 2), ('timeliness', 2), ('inaccuracy', 2), ('longhand', 2), ('overturned', 2), ('412', 2), ('memorandum', 2), ('combatant', 2), ('reclassified', 2), ('pioneering', 2), ('ministerial', 2), (\"jehovah's\", 2), ('346', 2), ('objector', 2), ('waver', 2), ('households', 2), ('comprehensively', 2), ('equity', 2), ('vested', 2), ('realty', 2), ('disenfranchisement', 2), ('exigencies', 2), ('discharging', 2), ('remanded', 2), ('furthered', 2), ('finishes', 2), ('incipiency', 2), ('conspiracies', 2), ('605', 2), ('blocking', 2), ('diaries', 2), ('monotony', 2), ('radioactivity', 2), ('belowground', 2), ('conelrad', 2), ('hatchway', 2), ('mounded', 2), ('dearborn', 2), ('bricks', 2), ('mortared', 2), ('pivot', 2), ('apportioned', 2), ('23000000', 2), ('excludes', 2), ('sparsely', 2), ('resides', 2), ('maximums', 2), ('stipulates', 2), ('565', 2), ('83', 2), ('disabilities', 2), ('grants-in-aid', 2), ('chemicals', 2), ('short-of', 2), ('reaffirm', 2), ('rulings', 2), ('blockading', 2), ('bolder', 2), ('embargo', 2), ('buildup', 2), ('bipartisan', 2), ('enlist', 2), ('t-34', 2), ('merz', 2), ('orvil', 2), ('harmful', 2), ('3500', 2), ('raiding', 2), ('124', 2), (\"people's\", 2), ('assignee', 2), ('executor', 2), ('reimbursement', 2), ('accrued', 2), ('nationals', 2), ('39000', 2), ('profiles', 2), ('stabilized', 2), ('exhaustive', 2), ('bibliographies', 2), ('reorientation', 2), ('straddling', 2), ('0.001', 2), ('corrosive', 2), ('3.3', 2), ('thermometry', 2), ('insensitive', 2), ('microwave', 2), ('sh', 2), ('diatomic', 2), ('fluoride', 2), ('calorimeter', 2), ('1964', 2), ('4500000', 2), ('right-of-entry', 2), ('embodying', 2), ('expiration', 2), ('theretofore', 2), ('moneys', 2), ('fullest', 2), ('publish', 2), ('correlate', 2), ('effectuate', 2), ('physicists', 2), ('byproducts', 2), ('authorization', 2), ('aforesaid', 2), ('converting', 2), ('low-cost', 2), ('hegel', 2), ('wordsworth', 2), ('woefully', 2), ('henley', 2), ('ism', 2), ('commentaries', 2), ('characterizations', 2), ('similarities', 2), ('snobbish', 2), ('collingwood', 2), ('wholes', 2), ('inferential', 2), ('metaphors', 2), ('uttering', 2), ('indulged', 2), ('common-sense', 2), ('utilitarian', 2), ('enrichment', 2), ('indecision', 2), ('viable', 2), ('instructs', 2), ('grounding', 2), ('spirituals', 2), ('dreamlike', 2), ('unerring', 2), ('castles', 2), ('whiting', 2), ('countrywide', 2), ('vocalist', 2), ('goodman', 2), ('lazybones', 2), ('satan', 2), ('garrick', 2), ('lyricists', 2), ('trait', 2), ('femininity', 2), ('strumming', 2), ('rebellious', 2), ('adele', 2), ('entertainments', 2), ('meg', 2), ('tempers', 2), ('unwillingness', 2), ('follies', 2), ('opinionated', 2), ('friedenwald', 2), ('darwin', 2), ('huxley', 2), ('aspiration', 2), ('libretto', 2), ('isaacs', 2), ('confiding', 2), ('foolhardy', 2), ('captivated', 2), ('delights', 2), ('hardships', 2), ('humorists', 2), ('unintended', 2), ('perpetrated', 2), ('hooper', 2), ('longstreet', 2), ('horace', 2), ('clan', 2), ('low-class', 2), ('dramatizes', 2), ('portraying', 2), ('romanticize', 2), ('1832', 2), ('notwithstanding', 2), ('basso', 2), ('charlottesville', 2), ('steeped', 2), ('hyperbolic', 2), ('flem', 2), ('melville', 2), ('cowley', 2), ('unfettered', 2), ('distinguishing', 2), ('dross', 2), ('stepmothers', 2), ('stepmother', 2), ('coal-black', 2), ('marries', 2), ('falsity', 2), ('instinctive', 2), ('kyne', 2), ('treasured', 2), ('dramatist', 2), ('senatorial', 2), ('boycott', 2), ('delineation', 2), ('ballads', 2), ('thirty-nine', 2), ('infallible', 2), ('calibre', 2), ('expounded', 2), ('defensible', 2), ('bogeys', 2), ('raids', 2), ('scare', 2), ('humane', 2), ('dams', 2), ('cumbersome', 2), ('swallowing', 2), ('consultations', 2), ('campbell', 2), ('diplomats', 2), ('bess', 2), ('promoters', 2), ('individualists', 2), ('destinies', 2), ('uncontrollable', 2), ('testaments', 2), ('taboo', 2), ('invoke', 2), ('non-partisan', 2), ('ordeal', 2), ('summation', 2), ('phrased', 2), ('lubell', 2), ('proletariat', 2), ('percy', 2), ('dislocations', 2), ('jacksonian', 2), ('progressivism', 2), ('generalists', 2), ('re-examine', 2), ('transmitting', 2), ('undersea', 2), ('materially', 2), ('unaccompanied', 2), ('maneuver', 2), ('waterfall', 2), ('habitable', 2), ('slowest', 2), ('dweller', 2), ('relayed', 2), ('assemblage', 2), ('oneness', 2), ('exclamations', 2), ('decorum', 2), ('endeavors', 2), ('questioner', 2), ('phillip', 2), ('maltese', 2), ('eric', 2), ('pervades', 2), ('elusive', 2), ('bruised', 2), ('rex', 2), ('hardboiled', 2), ('creations', 2), ('poirot', 2), ('grappling', 2), ('egotism', 2), ('deductive', 2), ('bores', 2), ('commonplaces', 2), ('recluse', 2), ('addicted', 2), ('conan', 2), ('advent', 2), ('1890', 2), ('poe', 2), ('benevolent', 2), ('virtuous', 2), ('catches', 2), ('selma', 2), ('vault', 2), ('tyrant', 2), ('norway', 2), ('plunges', 2), ('danes', 2), ('rallying', 2), ('adversity', 2), ('swedes', 2), ('pitiable', 2), ('ill-fated', 2), ('glorified', 2), ('worshipped', 2), ('world-shaking', 2), ('idyllic', 2), ('poltava', 2), ('1897', 2), ('provincialism', 2), ('strindberg', 2), ('wintry', 2), ('commemorate', 2), ('grecian', 2), ('celebrates', 2), ('racy', 2), ('och', 2), ('beggar', 2), ('eminence', 2), ('surmises', 2), ('autobiography', 2), ('mocked', 2), ('brokerage', 2), ('transaction', 2), ('indulge', 2), ('doctrinaire', 2), ('platonist', 2), ('beneficiaries', 2), ('bondsman', 2), ('dragons', 2), ('stagger', 2), ('whittier', 2), ('rejecting', 2), ('prep', 2), ('unequally', 2), ('specializing', 2), ('inseparable', 2), ('vagueness', 2), ('imputed', 2), ('defender', 2), ('constellations', 2), ('rasa', 2), ('tabula', 2), ('preconceived', 2), ('picturing', 2), ('mimetic', 2), ('truths', 2), ('poetics', 2), ('transcends', 2), ('rationalism', 2), ('thoroughgoing', 2), ('bastion', 2), ('compensatory', 2), ('mechanistic', 2), ('realms', 2), ('formalism', 2), ('shod', 2), ('ankle-deep', 2), ('hitching', 2), ('paving', 2), ('plodded', 2), ('rhu-beb', 2), ('squeaked', 2), ('unacquainted', 2), ('gaping', 2), ('locust', 2), ('nakedness', 2), ('squashed', 2), ('pinching', 2), ('snowballs', 2), ('cross-legged', 2), ('harmed', 2), ('cautiously', 2), ('brittle', 2), ('frost-bitten', 2), ('wind-blown', 2), ('shadowed', 2), ('flutter', 2), ('gingham', 2), ('snowball', 2), ('bough', 2), ('gable', 2), ('spiked', 2), ('kneel', 2), ('racine', 2), ('pondered', 2), ('gestured', 2), ('accommodates', 2), ('admits', 2), ('visage', 2), ('permeated', 2), ('clurman', 2), ('pessimism', 2), ('likeness', 2), ('dictating', 2), ('presupposes', 2), ('exclusion', 2), ('contradicts', 2), ('stabilize', 2), ('insulate', 2), ('exclusiveness', 2), ('ceases', 2), ('prosper', 2), ('pastoral', 2), ('like-minded', 2), ('disrupt', 2), ('healing', 2), ('exodus', 2), ('poorer', 2), ('worshiping', 2), ('confidentially', 2), ('roadblock', 2), ('classmate', 2), ('retrospect', 2), ('distributive', 2), ('tool-and-die', 2), ('encampment', 2), ('bouffant', 2), ('button-down', 2), ('collegiate', 2), ('dogmatically', 2), ('graduating', 2), ('hordes', 2), ('beckons', 2), ('playground', 2), ('catskills', 2), ('tentacles', 2), ('brightest', 2), ('outnumber', 2), ('vigilance', 2), ('lower-middle', 2), ('differentiate', 2), ('compensations', 2), ('marginality', 2), ('pursuits', 2), ('judaism', 2), ('professing', 2), ('teen-ager', 2), ('reside', 2), ('worthiest', 2), ('delicacies', 2), ('incense', 2), ('endearing', 2), ('pak', 2), ('shirts', 2), ('corrugated', 2), ('constructively', 2), ('notebooks', 2), ('105', 2), ('champassak', 2), ('oum', 2), ('lethargy', 2), ('prabang', 2), ('luang', 2), ('savannakhet', 2), ('uselessly', 2), ('ruts', 2), ('submachine', 2), ('ignite', 2), ('wayside', 2), ('loom', 2), ('meandering', 2), ('dryness', 2), ('frans', 2), ('mortars', 2), ('crackle', 2), ('etat', 2), ('decisively', 2), ('guatemala', 2), ('castroism', 2), ('grabs', 2), ('syria', 2), ('cambodia', 2), ('teetering', 2), ('overtly', 2), ('indochina', 2), ('masquerade', 2), ('takeover', 2), ('uprisings', 2), ('insidiously', 2), ('incurably', 2), ('nightmarish', 2), ('abreast', 2), ('foreseeable', 2), ('second-rate', 2), ('demonstrably', 2), ('rata', 2), ('sokolsky', 2), ('1876', 2), ('bellow', 2), ('whacked', 2), ('attackers', 2), ('piles', 2), ('ram', 2), ('battering', 2), ('civilians', 2), ('naktong', 2), ('bitterest', 2), ('beachhead', 2), ('martini', 2), ('good-natured', 2), ('syllable', 2), ('commissioned', 2), ('epitome', 2), ('cav', 2), ('anachronism', 2), ('untold', 2), ('restlessness', 2), ('geology', 2), ('freighter', 2), ('hurled', 2), ('gratified', 2), ('fishes', 2), ('stomachs', 2), ('turbulence', 2), ('scripps', 2), ('shepard', 2), ('ebbing', 2), ('suck', 2), ('wreckage', 2), ('fateful', 2), ('reckoned', 2), ('320', 2), ('forlorn', 2), ('swamped', 2), ('1707', 2), ('geologists', 2), ('arabian', 2), ('concession', 2), ('brothels', 2), ('takings', 2), ('torrio-capone', 2), ('runner', 2), ('hijacking', 2), ('squads', 2), ('despatched', 2), ('bums', 2), ('convoy', 2), ('incompatible', 2), ('offended', 2), ('landslide', 2), ('bludgeon', 2), ('energetically', 2), ('ostentatious', 2), ('pasley', 2), ('proprieter', 2), ('consorting', 2), ('allegiance', 2), ('grapevine', 2), ('robberies', 2), ('sicilians', 2), ('interludes', 2), ('1909', 2), ('syrupy', 2), ('trespassed', 2), ('waiters', 2), ('waiter', 2), ('nickname', 2), ('newsboy', 2), ('congested', 2), ('brien', 2), ('psychopath', 2), ('tenderly', 2), ('dispassionately', 2), ('uns', 2), ('greenest', 2), ('madmen', 2), ('friendliness', 2), ('1862', 2), ('suns', 2), ('skirmish', 2), ('damed', 2), ('orney', 2), ('gust', 2), ('alf', 2), ('boon', 2), ('foraging', 2), ('planters', 2), ('reb', 2), ('quickstep', 2), ('maladies', 2), ('fall-in', 2), ('pups', 2), ('bedtime', 2), ('forgit', 2), ('crupper', 2), ('roasted', 2), ('yore', 2), ('slowness', 2), ('dilapidated', 2), ('adept', 2), ('semi-literate', 2), ('1835', 2), ('assiniboia', 2), ('1845', 2), ('1847', 2), ('galtier', 2), ('galena', 2), ('arduous', 2), ('francois', 2), ('dousman', 2), ('josiah', 2), ('renamed', 2), ('1822', 2), ('mackinac', 2), ('alexis', 2), (\"selkirk's\", 2), ('pacify', 2), ('1811', 2), ('headwaters', 2), ('assiniboine', 2), (\"company's\", 2), ('humanitarian', 2), ('clemens', 2), ('deposed', 2), ('bloodshed', 2), ('swords', 2), ('feverishly', 2), ('marshes', 2), ('inlet', 2), ('rejoin', 2), ('quarrelsome', 2), ('ruffian', 2), ('lodley', 2), ('meekly', 2), ('waterway', 2), ('openings', 2), ('1609', 2), ('prejudiced', 2), ('preclude', 2), ('denouncing', 2), ('unparalleled', 2), ('hijackers', 2), ('racketeers', 2), ('bootleggers', 2), ('irreconcilable', 2), ('frustrate', 2), ('fostering', 2), ('abstention', 2), ('legitimately', 2), ('pius', 2), ('volcano', 2), ('resign', 2), ('tribunals', 2), ('arousing', 2), ('implicated', 2), ('exposes', 2), ('infamous', 2), ('hungary', 2), ('exemplified', 2), ('rightness', 2), ('jew-baiter', 2), ('scuttled', 2), ('anti-semite', 2), ('gurion', 2), ('bolsheviks', 2), ('emotionalism', 2), ('calming', 2), ('shrewdly', 2), ('gratuitous', 2), ('subtract', 2), ('redecorating', 2), ('tavern', 2), ('harrowing', 2), ('yardstick', 2), ('coaxed', 2), ('undisputed', 2), ('bathtub', 2), ('marketplace', 2), ('marion', 2), ('dominating', 2), ('primly', 2), ('emboldened', 2), ('domineering', 2), ('compel', 2), ('hemmed', 2), ('sacrificed', 2), ('counselor', 2), ('unworthy', 2), ('self-assertive', 2), ('emancipated', 2), ('nay', 2), ('pare', 2), ('9.50', 2), ('10.50', 2), ('binoculars', 2), ('guesses', 2), ('campgrounds', 2), ('lanterns', 2), ('stoves', 2), ('sunshades', 2), ('primed', 2), ('1926', 2), ('skeet', 2), ('acquaint', 2), ('babylon', 2), ('dennis', 2), ('cognizance', 2), ('upland', 2), ('diligent', 2), ('rap', 2), ('concessionaire', 2), ('cafeterias', 2), ('absences', 2), ('containers', 2), ('supplemental', 2), ('itemizing', 2), ('seniority', 2), ('shutdowns', 2), ('fill-ins', 2), ('taxis', 2), ('underwriting', 2), ('delegating', 2), ('subsidies', 2), ('overtime', 2), ('boiler', 2), ('premiums', 2), ('air-conditioning', 2), ('turnover', 2), ('provoke', 2), ('geared', 2), ('qualitatively', 2), ('tuned', 2), ('frills', 2), ('computers', 2), ('branded', 2), ('brands', 2), ('acquisitions', 2), ('distributors', 2), ('intensification', 2), ('snowfall', 2), ('conveyor', 2), ('mechanized', 2), ('additive', 2), ('.05', 2), ('lactating', 2), ('metabolic', 2), ('discontinue', 2), ('consuming', 2), ('overeating', 2), ('rhinotracheitis', 2), ('pneumonia', 2), ('feed-lot', 2), ('oxytetracycline', 2), ('infective', 2), ('marketed', 2), ('sanctioned', 2), ('lengthwise', 2), ('beccaria', 2), ('magnetized', 2), ('electrostatic', 2), ('esmarch', 2), ('galvanic', 2), ('repulsions', 2), ('sur', 2), ('1813', 2), ('galvanizing', 2), ('faculties', 2), ('pharmaceutical', 2), ('1817', 2), ('institut', 2), ('profusion', 2), ('rumford', 2), ('schelling', 2), ('volta', 2), ('nationalisms', 2), ('alkalis', 2), ('1797', 2), ('economizing', 2), ('tutoring', 2), ('matriculate', 2), ('oldenburg', 2), ('wigmaker', 2), ('anders', 2), ('millimeter', 2), ('baum', 2), ('transmit', 2), ('cartilage', 2), ('pulsing', 2), ('gastrointestinal', 2), ('fm', 2), ('capacitor', 2), ('catheter', 2), ('transducers', 2), ('heartbeat', 2), ('breathes', 2), ('pioneered', 2), ('amplified', 2), ('orthicon', 2), ('avenues', 2), ('zworykin', 2), ('berkely', 2), ('microscopy', 2), ('audio', 2), ('bruises', 2), ('electrocardiograph', 2), ('bio-medicine', 2), ('betterment', 2), ('laguna', 2), ('ranger', 2), ('natal', 2), ('1886', 2), ('gilbert', 2), ('locale', 2), ('avoids', 2), ('silhouetted', 2), ('foreground', 2), ('elaboration', 2), ('connotation', 2), ('cobalt', 2), ('burnt', 2), ('sienna', 2), ('top-quality', 2), ('bristle', 2), ('watercolorist', 2), ('workmanlike', 2), ('crispness', 2), ('finer', 2), ('instructive', 2), ('backdrop', 2), ('realizes', 2), ('watercolorists', 2), ('mastered', 2), ('ensembles', 2), ('choruses', 2), ('circumspect', 2), ('unfolded', 2), ('by-products', 2), ('proclamations', 2), ('patchwork', 2), ('popularism', 2), ('paganism', 2), ('admirers', 2), ('presuming', 2), ('stylist', 2), ('forged', 2), ('dwindled', 2), ('cultivate', 2), ('dialectics', 2), ('orchestrations', 2), ('harmonic', 2), ('captivating', 2), ('slavic', 2), ('craftsman', 2), ('signature', 2), ('traditionalism', 2), ('roving', 2), ('age-old', 2), ('treaties', 2), ('cringing', 2), ('crystallizing', 2), ('freedoms', 2), ('cocteau', 2), ('migrated', 2), ('symphonies', 2), ('broadcastings', 2), ('mon', 2), ('bloch', 2), ('modernism', 2), ('haute', 2), ('cherokee', 2), ('compassionately', 2), ('vocation', 2), ('granville', 2), ('sprue', 2), ('cigars', 2), ('specter', 2), ('ape', 2), ('nemesis', 2), ('overreached', 2), ('backyard', 2), ('replenished', 2), ('taverns', 2), ('pizza', 2), ('remorseless', 2), ('violates', 2), ('interlaced', 2), ('bali', 2), ('sed', 2), ('honan', 2), ('carvings', 2), ('interne', 2), ('indescribable', 2), ('khmer', 2), ('hoods', 2), ('overtake', 2), ('compassionate', 2), ('pitiless', 2), ('tenacity', 2), ('withhold', 2), ('tiresome', 2), ('customarily', 2), ('sandalwood', 2), ('rummaging', 2), ('magnifying', 2), ('jade', 2), ('bureaus', 2), ('curio', 2), ('milieu', 2), ('rackets', 2), ('ransack', 2), ('bucks', 2), ('candidly', 2), ('vindictive', 2), ('disabuse', 2), ('audacity', 2), ('burglars', 2), ('patronizing', 2), ('misconception', 2), ('tongue-in-cheek', 2), ('completeness', 2), ('relentlessness', 2), ('tick', 2), ('franz', 2), ('monet', 2), ('creditable', 2), ('starlet', 2), ('beguiling', 2), ('luscious', 2), ('stardom', 2), ('decadent', 2), ('mille', 2), ('amoral', 2), ('balding', 2), ('prostrate', 2), ('callas', 2), ('chiseled', 2), ('pulova', 2), ('fing', 2), ('burbank', 2), ('exquisite', 2), ('salamander', 2), ('readable', 2), ('sartre', 2), ('hot-shot', 2), ('parable', 2), ('nymphomaniac', 2), ('feline', 2), ('aging', 2), ('atkinson', 2), ('tutor', 2), ('fruitless', 2), ('indelible', 2), ('nebulous', 2), ('407', 2), ('skipping', 2), ('haumd', 2), ('flautist', 2), ('baslot', 2), ('schlek', 2), ('marc', 2), ('bach', 2), ('titanic', 2), ('salfininistas', 2), ('repressed', 2), ('redeem', 2), ('venetian', 2), ('slat', 2), ('governess', 2), ('wilhelmina', 2), ('freudian', 2), ('belvedere', 2), ('woo', 2), ('synonyms', 2), ('reappears', 2), ('symbolizing', 2), ('arapacis', 2), ('armadillo', 2), ('hubba', 2), ('il', 2), ('collapsing', 2), ('grind', 2), ('nettled', 2), ('insinuation', 2), ('demeanor', 2), ('irreverence', 2), ('shiver', 2), ('stringy', 2), ('cowardice', 2), ('omen', 2), ('martinis', 2), ('insinuations', 2), ('somersaults', 2), ('echoing', 2), ('unpredictability', 2), ('boosting', 2), ('crannies', 2), ('hates', 2), ('strafe', 2), ('inveterate', 2), ('foot-loose', 2), ('nasty', 2), ('non-god', 2), ('rhinos', 2), ('rhinoceros', 2), ('salubrious', 2), ('homosexual', 2), ('furiouser', 2), ('somnolent', 2), ('noel', 2), ('parishioners', 2), ('longfellow', 2), ('jumpy', 2), ('deranged', 2), ('angst', 2), ('waldo', 2), ('chanting', 2), ('gulp', 2), ('paraphrase', 2), ('manic', 2), ('hare', 2), ('loon', 2), ('hive', 2), ('anglo-american', 2), ('bearer', 2), ('petting', 2), ('repent', 2), ('baffling', 2), ('alligator', 2), ('madam', 2), ('double-entendre', 2), ('epicure', 2), ('gags', 2), ('vera', 2), ('journalese', 2), ('passionately', 2), ('modifiers', 2), ('cartoon', 2), ('blunder', 2), ('cryptic', 2), ('tripped', 2), ('kindred', 2), ('idiot', 2), ('romeo', 2), ('laced', 2), ('expectantly', 2), ('teats', 2), ('soothing', 2), ('childlike', 2), ('straddled', 2), ('lithe', 2), ('gilded', 2), ('forked', 2), ('fortresses', 2), ('hedge', 2), ('swings', 2), ('porches', 2), ('fleas', 2), ('fleshy', 2), ('fig', 2), ('mauve', 2), ('chins', 2), ('puckered', 2), ('calloused', 2), ('torino', 2), ('rossi', 2), ('trays', 2), ('stir', 2), ('amelia', 2), ('pans', 2), ('self-will', 2), ('expressionless', 2), ('slanted', 2), ('whiteface', 2), ('trappings', 2), ('gelding', 2), ('advising', 2), ('adverbs', 2), ('gender', 2), ('approximations', 2), ('dissimilar', 2), ('instructing', 2), ('deceleration', 2), ('hurl', 2), ('unfrozen', 2), ('animation', 2), ('suspensor', 2), ('gadfly', 2), ('navel', 2), ('conceiving', 2), ('rend', 2), ('sturch', 2), ('tahiti', 2), ('pidgin', 2), ('lingo', 2), ('unrecognized', 2), ('israeli', 2), ('icelandic', 2), ('haijac', 2), ('blazed', 2), ('horrified', 2), ('dormitory', 2), ('scriptural', 2), ('sentient', 2), ('abc', 2), ('salted', 2), ('punk', 2), ('halo', 2), ('recriminations', 2), ('angelic', 2), ('jackass', 2), ('conclave', 2), ('indicted', 2), ('grandmothers', 2), ('hand-woven', 2), ('palermo', 2), ('punctuation', 2), ('millennia', 2), ('long-distance', 2), ('equator', 2), ('colder', 2), ('everest', 2), ('speeded', 2), ('lotus', 2), ('jewel', 2), ('inevitability', 2), ('mahmoud', 2), ('totality', 2), ('knotty', 2), ('boone', 2), ('cusp', 2), ('trance', 2), ('discorporate', 2), ('selves', 2), ('disperse', 2), ('congratulatory', 2), ('clapped', 2), ('gasp', 2), ('salvaging', 2), ('mouthing', 2), ('plowed', 2), ('irresolute', 2), ('macabre', 2), ('louse', 2), ('loudspeakers', 2), ('stomped', 2), ('backstage', 2), ('overflowed', 2), ('rocco', 2), ('patter', 2), ('contacting', 2), ('lissa', 2), ('alertness', 2), ('dozing', 2), ('bins', 2), ('workman', 2), ('skylights', 2), ('credible', 2), ('obligingly', 2), ('prancing', 2), ('merrily', 2), ('freshly', 2), ('necktie', 2), ('emphatically', 2), ('home-grown', 2), ('glowered', 2), ('bounding', 2), ('autopsy', 2), ('cavorting', 2), ('cinch', 2), ('cleanly', 2), ('grasping', 2), ('swooping', 2), ('mallory', 2), ('broadly', 2), ('barricade', 2), ('platoons', 2), ('fiend', 2), ('clogging', 2), ('bugle', 2), ('noisemakers', 2), ('cardboard', 2), ('curbside', 2), ('astride', 2), ('rationed', 2), ('bundled', 2), ('travellers', 2), ('lapels', 2), ('double-breasted', 2), ('astor', 2), ('implored', 2), ('good-night', 2), ('bragged', 2), ('outraged', 2), ('jessie', 2), ('reunited', 2), ('halloween', 2), ('adolescent', 2), ('warmer', 2), ('kisses', 2), ('exploits', 2), ('tango', 2), ('quoting', 2), ('furlough', 2), ('wrinkle', 2), ('compliment', 2), ('overshoes', 2), ('clotheshorse', 2), ('snail', 2), ('alfresco', 2), ('peonies', 2), ('tulips', 2), ('knuckle', 2), ('apologized', 2), ('bellowing', 2), ('aspirin', 2), ('untie', 2), ('wails', 2), ('doorknob', 2), ('lavatory', 2), ('halls', 2), ('remarking', 2), ('muted', 2), ('drown', 2), ('denouement', 2), ('connoisseur', 2), ('ejaculated', 2), ('coughed', 2), ('swerved', 2), ('cluck', 2), ('breakfasts', 2), ('stroll', 2), ('vous', 2), ('gingerly', 2), ('garment', 2), ('chambermaid', 2), ('nestling', 2), ('maternal', 2), ('broody', 2), ('ministrations', 2), ('cackled', 2), ('clucks', 2), ('roused', 2), ('lineage', 2), ('scrawled', 2), ('wattles', 2), ('chicks', 2), ('primaries', 2), ('stalking', 2), ('confirming', 2), ('bing', 2), ('darn', 2), ('teenager', 2), ('debora', 2), ('bothers', 2), ('gosh', 2), ('shyly', 2), ('roundly', 2), ('stuffy', 2), ('parched', 2), ('loft', 2), ('denting', 2), ('brides', 2), ('weaning', 2), ('parting', 2), ('inwardly', 2), ('writhe', 2), ('enveloping', 2), ('lucretia', 2), ('whirring', 2), ('suddenness', 2), ('stump', 2), ('colds', 2), ('funniest', 2), ('shawl', 2), ('cuffs', 2), ('trouser', 2), ('reminders', 2), ('mittens', 2), ('sheepskin', 2), ('peeked', 2), ('disapproved', 2), ('constructions', 2), ('cages', 2), ('inventive', 2), ('internationally', 2), ('fanciful', 2), ('lionized', 2), ('shove', 2), ('frostbite', 2), ('fooling', 2), ('unscrewed', 2), ('insides', 2), ('spattered', 2), ('cagey', 2), ('pig-drunk', 2), ('shoveled', 2), ('waked', 2), ('dung', 2), ('lumped', 2), ('drafty', 2), ('ascended', 2), ('shameful', 2), ('receipt', 2), ('no-nonsense', 2), ('silos', 2), ('clearness', 2), ('plush', 2), ('intensifying', 2), ('obeying', 2), ('suspiciously', 2), ('sicilian', 2), ('flick', 2), ('resolutely', 2), ('wicker', 2), ('regal', 2), ('escritoire', 2), ('tasting', 2), ('elm', 2), ('belmont', 2), ('gutters', 2), ('procreative', 2), ('coyness', 2), ('travelled', 2), ('wo', 2), ('pane', 2), ('broiler', 2), ('kit', 2), ('smallpox', 2), ('thoughtless', 2), ('craven', 2), ('horowitz', 2), ('signified', 2), ('canvass', 2), ('boundless', 2), ('locker-room', 2), ('grassy', 2), ('soften', 2), ('statuary', 2), ('beech', 2), ('gogol', 2), ('exclaiming', 2), ('stupidly', 2), ('schoolmaster', 2), ('chute', 2), ('self-conscious', 2), ('thwart', 2), ('fetid', 2), ('weakly', 2), ('mucus', 2), ('awkwardly', 2), ('scrambling', 2), ('groping', 2), ('unclean', 2), ('drunkard', 2), ('shrilly', 2), ('postures', 2), ('eagerness', 2), ('frayed', 2), ('eruption', 2), ('reclaimed', 2), ('timbered', 2), ('rampart', 2), ('truce', 2), ('floundering', 2), ('slits', 2), ('torches', 2), ('requisitioned', 2), ('spies', 2), ('flaunted', 2), ('offender', 2), ('diverting', 2), ('gaily', 2), ('lordly', 2), ('rebelled', 2), ('disrepute', 2), ('harem', 2), ('bewitched', 2), ('thynne', 2), ('cadence', 2), ('tidings', 2), ('vintage', 2), ('admiring', 2), ('unhurriedly', 2), ('bodice', 2), ('dextrous', 2), (\"man's\", 2), ('overdone', 2), ('flattery', 2), ('minerva', 2), ('rebutted', 2), ('war-ridden', 2), ('wines', 2), ('milord', 2), ('crudely', 2), ('satiety', 2), ('girlishly', 2), ('lime', 2), ('bishopsgate', 2), ('jaded', 2), ('orgies', 2), ('vitals', 2), ('peacock', 2), ('lordship', 2), ('inconvenient', 2), ('default', 2), ('konishi', 2), ('dampen', 2), ('mavis', 2), ('pamphlets', 2), ('fujimoto', 2), ('hesitancy', 2), ('dignitaries', 2), ('morsel', 2), ('unasked', 2), ('storyteller', 2), ('occupations', 2), ('supplementing', 2), ('elated', 2), ('improperly', 2), ('gouged', 2), ('longshoremen', 2), ('demure', 2), ('hath', 2), (\"o'dwyers\", 2), ('curly', 2), (\"o'dwyer\", 2), ('valet', 2), ('underlined', 2), ('xavier', 2), ('fedora', 2), ('kitchenette', 2), ('forefinger', 2), ('jabbing', 2), ('pokes', 2), ('ballestre', 2), ('understandingly', 2), ('ginmill', 2), ('ornery', 2), ('gem', 2), ('bricklaying', 2), ('son-of-a-bitch', 2), ('belch', 2), ('deep-seated', 2), ('swarmed', 2), ('shanty', 2), ('betrays', 2), ('granary', 2), ('sniffed', 2), ('haggard', 2), ('pumped', 2), ('draining', 2), ('reinhard', 2), ('dope', 2), ('baltic', 2), ('ukrainian', 2), ('spouted', 2), (\"death's-head\", 2), ('bathyrans', 2), ('deportees', 2), ('railhead', 2), ('goddamned', 2), ('betrayal', 2), ('chills', 2), ('activism', 2), ('rostrum', 2), ('brink', 2), ('swamps', 2), ('feudal', 2), ('burly', 2), ('well-made', 2), ('sensual', 2), ('nuances', 2), ('aridity', 2), ('whigs', 2), ('introspective', 2), ('muskets', 2), ('thickets', 2), ('clam', 2), ('dwellers', 2), ('neptune', 2), ('rowed', 2), ('h.m.s.', 2), ('seeped', 2), ('loyalists', 2), ('hulks', 2), ('majesty', 2), ('tidbits', 2), ('churning', 2), ('smugglers', 2), ('grazing', 2), ('infested', 2), ('triangular', 2), ('tormented', 2), ('shied', 2), ('dispatches', 2), ('jolt', 2), ('silvery', 2), ('stately', 2), ('sweating', 2), ('buckles', 2), ('jeweled', 2), ('scudding', 2), ('bedside', 2), ('anita', 2), ('lemonade', 2), ('manassas', 2), ('woolen', 2), ('sumter', 2), ('crowed', 2), ('git', 2), ('wheeling', 2), ('beau', 2), ('reprisals', 2), ('perplexed', 2), ('jug', 2), ('trails', 2), ('hush', 2), ('rangers', 2), ('foreboding', 2), ('remembrance', 2), ('shriveled', 2), ('bewilderment', 2), ('threes', 2), ('rocking', 2), ('jerking', 2), ('dipped', 2), ('contadini', 2), ('grumbled', 2), ('stolidly', 2), ('scoured', 2), ('laundry', 2), ('robes', 2), ('santo', 2), ('sketched', 2), ('jacopo', 2), ('loins', 2), ('sangallo', 2), ('sinewy', 2), ('talmud', 2), ('synagogue', 2), ('sketching', 2), ('inquisition', 2), ('trastevere', 2), ('tactile', 2), ('sluiced', 2), ('wryly', 2), ('tiber', 2), ('limb', 2), ('ungainly', 2), ('anguished', 2), ('pieta', 2), ('mourn', 2), ('pilate', 2), ('bologna', 2), ('arimathea', 2), ('spices', 2), ('aloes', 2), ('myrrh', 2), ('high-ceilinged', 2), ('loaves', 2), ('sneakers', 2), ('metro', 2), ('overlooking', 2), ('flea', 2), ('sight-seeing', 2), ('unclaimed', 2), ('clogged', 2), ('concierge', 2), ('ticked', 2), ('panes', 2), ('criss-crossed', 2), ('bookcase', 2), ('boucher', 2), ('drawing-room', 2), ('gilt', 2), ('schoolboy', 2), ('cestre', 2), ('sabine', 2), ('bathe', 2), ('pajamas', 2), ('fling', 2), ('alarmingly', 2), ('teaspoonful', 2), ('peace-loving', 2), ('teacart', 2), ('cupboard', 2), ('icebox', 2), ('burners', 2), ('intimidated', 2), ('hausman', 2), ('pearls', 2), ('strands', 2), ('ushered', 2), ('shrub', 2), ('impacted', 2), ('romances', 2), ('restlessly', 2), ('wrapper', 2), ('posing', 2), ('urns', 2), ('hoarse', 2), ('assurances', 2), ('rheinholdt', 2), ('bosch', 2), ('wan', 2), ('intrusions', 2), ('glassy', 2), ('redder', 2), ('bloated', 2), ('doubly', 2), ('housework', 2), ('repairmen', 2), ('recollections', 2), ('quotations', 2), ('matron', 2), ('constricted', 2), ('sparling', 2), ('pique', 2), ('nuff', 2), ('confounded', 2), ('enervating', 2), ('deceit', 2), ('jabbed', 2), ('reap', 2), ('euphoria', 2), ('wisp', 2), ('liar', 2), ('parading', 2), ('wanna', 2), ('wobbly', 2), ('crumbled', 2), ('lob-scuse', 2), ('fer', 2), ('skippers', 2), ('sowbelly', 2), ('fooled', 2), ('giggled', 2), ('slop', 2), ('squealed', 2), ('tits', 2), ('buckra', 2), ('sweetness', 2), ('swirl', 2), ('clubbed', 2), ('sizzled', 2), ('nameless', 2), ('darkly', 2), ('crazily', 2), ('dislodge', 2), ('twitching', 2), ('turban', 2), ('antietam', 2), ('freckles', 2), ('sorrel', 2), ('watery', 2), ('obscene', 2), ('banter', 2), ('obscenities', 2), ('exchanging', 2), ('hairy', 2), ('surmounted', 2), ('yellowing', 2), ('vendors', 2), ('stationery', 2), ('sardines', 2), ('barley', 2), ('drumming', 2), ('snarling', 2), ('blob', 2), ('rowdy', 2), ('rabble', 2), ('co-operate', 2), ('firelight', 2), ('unleavened', 2), ('sept', 2), ('persecuted', 2), ('libertines', 2), ('prostitutes', 2), ('disregarding', 2), ('godless', 2), ('courting', 2), ('confide', 2), ('nerien', 2), ('indigestion', 2), ('pigeon', 2), ('quickening', 2), ('graver', 2), ('whisked', 2), ('neared', 2), ('trudged', 2), ('hallowed', 2), ('abbot', 2), ('reconciled', 2), ('beware', 2), ('adulterers', 2), ('rotunda', 2), ('corne', 2), ('ablard', 2), ('ungodly', 2), ('smirk', 2), ('plunking', 2), ('chinless', 2), ('drunkenness', 2), ('bordel', 2), ('gaming-card', 2), ('ameaux', 2), ('outface', 2), (\"god's\", 2), ('pasty', 2), ('slackened', 2), ('outrun', 2), ('reloaded', 2), ('gunpowder', 2), ('pitt', 2), ('scooped', 2), ('waded', 2), ('crescendo', 2), ('mule', 2), ('disorganized', 2), ('stirrup', 2), ('scouting', 2), ('nauseated', 2), ('misjudged', 2), ('a-coming', 2), ('boldness', 2), ('squirmed', 2), ('infuriating', 2), ('incensed', 2), ('cury', 2), ('unimpressed', 2), ('striving', 2), ('amusements', 2), ('hypocrite', 2), ('first-rate', 2), ('parisian', 2), ('decry', 2), ('genre', 2), ('piercing', 2), ('furor', 2), ('knocks', 2), ('bandits', 2), ('persuasive', 2), ('snuggled', 2), ('rots', 2), (\"c'mon\", 2), ('prick', 2), ('finnegan', 2), ('supremely', 2), ('jerk', 2), ('yehhh', 2), ('tien', 2), ('gnashing', 2), ('magnet', 2), ('oughta', 2), ('stroked', 2), ('bout', 2), ('stifle', 2), ('haranguing', 2), ('capitalists', 2), ('tryin', 2), ('juke', 2), ('boogie', 2), ('prickly', 2), ('doin', 2), ('goddammit', 2), ('sayin', 2), ('crummy', 2), ('ruffled', 2), ('swaggered', 2), ('jaunty', 2), ('roofer', 2), ('crows', 2), ('rooftop', 2), ('kingston', 2), ('straggling', 2), ('glistened', 2), ('industrious', 2), ('fragrant', 2), ('drenched', 2), ('crooked', 2), ('aggie', 2), ('unafraid', 2), ('summon', 2), ('spectacles', 2), ('cleft', 2), ('monticello', 2), ('inflamed', 2), ('splashing', 2), ('purled', 2), ('laurel', 2), ('greening', 2), ('overgrown', 2), ('canal', 2), ('roundhouse', 2), ('germantown', 2), ('idling', 2), ('hellfire', 2), ('consign', 2), ('resided', 2), ('yawning', 2), ('basking', 2), ('headless', 2), ('sixty-two', 2), ('monster', 2), ('scaled', 2), ('rattled', 2), ('windowpanes', 2), ('trembled', 2), ('bulged', 2), ('chavis', 2), ('hooves', 2), ('tugged', 2), ('obstruct', 2), ('whinnied', 2), ('rathbone', 2), ('involuntary', 2), ('blundered', 2), ('theatrically', 2), ('celebrations', 2), ('trenchard', 2), ('monologue', 2), ('wilkes', 2), ('honour', 2), ('declaimed', 2), ('unhitched', 2), ('clammy', 2), ('reversing', 2), ('stoop', 2), ('loomed', 2), ('patronized', 2), ('grocers', 2), ('trash', 2), ('jowl', 2), ('cottages', 2), ('ornamented', 2), ('dives', 2), ('disrepair', 2), ('ill-equipped', 2), ('typhoid', 2), ('trances', 2), ('snickered', 2), ('conciliatory', 2), ('obsequious', 2), ('mourned', 2), ('calamity', 2), ('landmark', 2), ('disarm', 2), ('politic', 2), ('deceptive', 2), ('chris', 2), ('prosecuting', 2), ('graciously', 2), ('tasteful', 2), ('regrets', 2), ('stamping', 2), ('blinds', 2), ('violets', 2), ('threading', 2), ('serpent', 2), ('filipino', 2), ('devilish', 2), ('sniper', 2), ('drawl', 2), ('christiansen', 2), ('romantics', 2), ('receptive', 2), ('corcoran', 2), ('sprouting', 2), ('mischievous', 2), ('mais', 2), (\"c'est\", 2), ('brittany', 2), ('speechlessness', 2), ('mutely', 2), ('armored', 2), ('knoll', 2), ('amidst', 2), ('softer', 2), ('searchlight', 2), ('leered', 2), ('wraith-like', 2), ('unsung', 2), ('dirge', 2), ('mourners', 2), ('unprotected', 2), ('jumble', 2), ('testicle', 2), ('clips', 2), ('rok', 2), ('unsettled', 2), ('quixotic', 2), ('coils', 2), ('raped', 2), ('briefing', 2), ('defying', 2), ('accusation', 2), ('irritated', 2), ('satirical', 2), ('sally', 2), ('irritably', 2), ('glinted', 2), ('wagged', 2), ('stethoscope', 2), ('unsmiling', 2), ('lifelike', 2), ('tiring', 2), ('candies', 2), ('tempt', 2), ('bathrobe', 2), ('peeling', 2), ('craig', 2), ('cricket', 2), ('lipstick', 2), ('checkup', 2), ('conferred', 2), ('polyethylene', 2), ('runoff', 2), ('weir', 2), ('270', 2), ('influent', 2), ('asphalt', 2), ('matting', 2), ('diam', 2), ('unattractive', 2), ('blue-green', 2), ('emitted', 2), ('lagoons', 2), ('eckenfelder', 2), (\"o'connor\", 2), ('wastewater', 2), ('loadings', 2), ('ironical', 2), ('gloomily', 2), ('paree', 2), ('quicksilver', 2), ('uneconomical', 2), ('prejudicial', 2), ('advertisement', 2), ('suburbanite', 2), ('northland', 2), ('inflated', 2), ('hurts', 2), ('relying', 2), ('shipment', 2), ('lower-class', 2), ('trolley', 2), ('blighted', 2), ('chrysler', 2), ('leapfrog', 2), ('catastrophically', 2), ('mitigates', 2), ('interchanges', 2), ('one-eighth', 2), ('vestige', 2), ('constricting', 2), ('identities', 2), ('conspicuous', 2), ('smallness', 2), ('planar', 2), ('synthesized', 2), ('juxtaposed', 2), ('representational', 2), ('opted', 2), ('interchangeable', 2), ('three-dimensionality', 2), ('reinforces', 2), ('encompass', 2), ('oscillation', 2), ('expands', 2), ('grape', 2), ('sculptural', 2), ('collages', 2), ('specifying', 2), ('eked', 2), ('inexorable', 2), ('simulation', 2), ('eye-undeceiving', 2), ('milder', 2), ('resolute', 2), ('propagation', 2), ('endeavoring', 2), ('allusion', 2), ('amos', 2), ('disgrace', 2), ('rebuke', 2), ('heroism', 2), ('deserving', 2), ('fanaticism', 2), ('insurrection', 2), ('unresponsive', 2), ('lieutenant-governor', 2), ('commuted', 2), ('outwardly', 2), ('wheaton', 2), ('defied', 2), ('accusations', 2), ('heaped', 2), ('calmer', 2), ('falsify', 2), ('antiquity', 2), ('shirking', 2), ('custodian', 2), ('gregory', 2), ('patristic', 2), ('aptitude', 2), ('canonist', 2), ('platonic', 2), ('genus', 2), ('acknowledges', 2), ('humanist', 2), ('doings', 2), ('lucian', 2), ('epigrams', 2), ('proponent', 2), ('fathered', 2), ('academics', 2), ('lexicon', 2), ('festivus', 2), ('revel', 2), ('surveying', 2), ('reuben', 2), ('envision', 2), ('fleming', 2), ('edith', 2), ('hitchcock', 2), ('gleason', 2), ('rte.', 2), ('woodcock', 2), ('1906', 2), ('dufresne', 2), ('wilcox', 2), ('boosted', 2), ('yorkers', 2), ('towsley', 2), ('windham', 2), ('londonderry', 2), ('hapgood', 2), ('fowler', 2), ('1887', 2), ('toppled', 2), ('gusts', 2), ('1879', 2), ('telegraphic', 2), ('telegrams', 2), ('equinox', 2), ('jeweler', 2), ('goodwin', 2), ('1844', 2), ('wiley', 2), ('residences', 2), ('empties', 2), ('214', 2), ('roundup', 2), ('loopholes', 2), ('entrenched', 2), ('lifeless', 2), ('besiegers', 2), ('befall', 2), ('kerosene', 2), ('jose', 2), ('transact', 2), ('adjourned', 2), ('122', 2), ('convened', 2), ('sheriffs', 2), ('perplexing', 2), ('1891', 2), ('prosecute', 2), ('overbearing', 2), ('adobe', 2), ('bloodhounds', 2), ('surmised', 2), ('felled', 2), ('beall', 2), ('ranches', 2), ('corral', 2), ('friezes', 2), ('stylized', 2), ('confidently', 2), ('hesitantly', 2), ('curving', 2), ('refine', 2), ('antecedents', 2), ('orient', 2), ('apogee', 2), ('determinedly', 2), ('tokens', 2), ('dipylon', 2), ('defect', 2), ('pantheon', 2), ('lofty', 2), ('conjoined', 2), ('pillars', 2), ('hallmarks', 2), ('corinthian', 2), ('minimizing', 2), ('inheritance', 2), ('cursory', 2), ('testimonial', 2), ('freest', 2), ('self-satisfaction', 2), ('oblivious', 2), ('declarations', 2), ('recount', 2), ('triangle', 2), ('unimpaired', 2), ('portfolio', 2), ('third-dimensional', 2), ('memory-images', 2), ('occipital', 2), ('shrapnel', 2), ('onlooker', 2), ('infliction', 2), ('subjectivist', 2), ('childishly', 2), ('companions', 2), ('dostoevsky', 2), ('untrue', 2), ('mistakenly', 2), ('troubling', 2), ('revise', 2), ('demarcation', 2), ('non-party', 2), ('recurring', 2), ('administer', 2), ('sine', 2), (\"l'union\", 2), ('deterioration', 2), ('scrutin', 2), ('resolving', 2), ('debacle', 2), ('quarreled', 2), ('harvests', 2), ('non-political', 2), ('rudimentary', 2), ('identifications', 2), ('self-government', 2), ('reproach', 2), ('motivating', 2), ('insuperable', 2), ('lured', 2), ('perpetuation', 2), ('longstanding', 2), ('nationality', 2), ('spatially', 2), ('devotees', 2), ('durkheim', 2), ('memberships', 2), ('sects', 2), ('integrates', 2), ('fulfills', 2), ('sinful', 2), ('transcendent', 2), ('legitimacy', 2), ('internalized', 2), ('ethic', 2), ('vis-a-vis', 2), ('self-sufficient', 2), ('wrongdoing', 2), ('repressive', 2), ('colossal', 2), ('equanimity', 2), ('fortitude', 2), ('plausible', 2), ('recurrent', 2), ('unassisted', 2), ('mundane', 2), ('mobilizing', 2), ('lippman', 2), ('beckoning', 2), ('yearnings', 2), ('self-preservation', 2), ('instrumentalities', 2), ('implementing', 2), ('enhancing', 2), ('formulating', 2), ('diversity', 2), ('trademark', 2), ('appraise', 2), ('inflexible', 2), ('skillfully', 2), ('mobilize', 2), ('concerted', 2), ('lastly', 2), ('tenancy', 2), ('underline', 2), ('underlining', 2), ('appraisals', 2), ('fates', 2), ('democratize', 2), ('equate', 2), ('competently', 2), ('modernized', 2), ('iran', 2), ('reacting', 2), ('intractable', 2), ('diversions', 2), ('disruptive', 2), ('statesmanship', 2), ('aspirants', 2), ('gaps', 2), ('b-plane', 2), ('parametric', 2), ('circumscribing', 2), ('bernoulli', 2), ('0.6', 2), ('usages', 2), ('recur', 2), ('zeros', 2), ('algebra', 2), ('nth', 2), ('commutes', 2), ('primes', 2), ('decomposes', 2), ('spanned', 2), ('scalar', 2), ('initiating', 2), ('underlie', 2), ('convincingly', 2), ('wolpe', 2), ('abreaction', 2), ('reliving', 2), ('reversible', 2), ('inhibitory', 2), ('abolished', 2), ('reappear', 2), ('vomiting', 2), ('nausea', 2), ('correlating', 2), ('neuropsychiatric', 2), ('synchrony', 2), ('psychoactive', 2), ('analeptic', 2), ('reflexly', 2), ('asynchrony', 2), ('synchronous', 2), ('electroshock', 2), ('feedback', 2), ('convulsive', 2), ('summate', 2), ('cortico-fugal', 2), ('cortico-hypothalamic', 2), ('neocortical', 2), ('nociceptive', 2), ('multiplies', 2), ('inclusion', 2), ('epidermis', 2), ('localization', 2), ('milliliter', 2), ('layering', 2), ('absorptions', 2), ('ocular', 2), ('bg', 2), ('zeiss', 2), ('blotting', 2), ('rottger', 2), ('schramm', 2), ('adhesive', 2), ('smeared', 2), ('fluorescein', 2), ('myofibrillae', 2), ('nucleoli', 2), ('striations', 2), ('pyknotic', 2), ('vacuolization', 2), ('transversus', 2), ('pectoralis', 2), ('arterioles', 2), ('glomerular', 2), ('interstitial', 2), ('fibrin', 2), ('submucosa', 2), ('occlusion', 2), ('foul-smelling', 2), ('colon', 2), ('circumference', 2), ('dilated', 2), ('cc.', 2), ('hyperemia', 2), ('arteriolosclerosis', 2), ('hemosiderin', 2), ('sinusoids', 2), ('lining', 2), ('hyperemic', 2), ('orifices', 2), ('narrowing', 2), ('friable', 2), ('basophilic', 2), ('infiltrated', 2), ('leaflets', 2), ('bilateral', 2), ('progression', 2), ('dexamethasone', 2), ('reclining', 2), ('chlorothiazide', 2), ('edema', 2), ('medication', 2), ('tapering', 2), ('biopsy', 2), ('transfusions', 2), ('debility', 2), ('steroids', 2), ('adrenal', 2), ('steroid', 2), ('redefinition', 2), ('alternatively', 2), ('abnormal', 2), ('soluble', 2), ('bio-assay', 2), ('trapping', 2), ('correspondingly', 2), ('labelled', 2), ('accumulate', 2), ('hypertrophy', 2), ('goitrogen', 2), ('tasmania', 2), ('goitrogens', 2), ('resorcinol', 2), ('inhibit', 2), ('binds', 2), ('diffuse', 2), ('proteolysis', 2), ('oxidised', 2), ('stanbury', 2), ('nucleotide', 2), ('de-iodinating', 2), ('preferentially', 2), ('alpers', 2), ('cf.', 2), ('hormones', 2), ('mono', 2), ('iodination', 2), ('peroxide', 2), ('chaikoff', 2), ('taurog', 2), ('kirkwood', 2), ('homogenate', 2), ('organically', 2), ('interestingly', 2), ('.10', 2), ('deviations', 2), ('interpreting', 2), ('diaphyseal', 2), ('epiphyseal', 2), ('governs', 2), ('variability', 2), ('osseous', 2), ('expectancy', 2), ('chronologically', 2), ('summarize', 2), ('modal', 2), ('peripherally', 2), ('imperfectly', 2), ('subgross', 2), ('physiology', 2), ('tobin', 2), ('lesion', 2), ('karsner', 2), ('ghoreyeb', 2), ('proximal', 2), ('nutrient', 2), ('1907', 2), ('staunchest', 2), ('anatomically', 2), ('segmental', 2), ('physiologic', 2), ('vasorum', 2), ('lobules', 2), ('incompletely', 2), ('nodes', 2), ('lymph', 2), ('generalization', 2), ('nicaragua', 2), ('colombian', 2), ('geologist', 2), ('9.8', 2), ('guiana', 2), ('emaciated', 2), ('mole', 2), ('ditmars', 2), ('brookfield', 2), ('serpents', 2), ('freaks', 2), ('heuvelmans', 2), ('graveyards', 2), ('noticeably', 2), ('oversized', 2), ('ascertained', 2), ('herpetologists', 2), ('overestimation', 2), ('captivity', 2), ('maximal', 2), ('gravid', 2), ('garter', 2), ('klauber', 2), ('evaporation', 2), ('vegetation', 2), ('yearbook', 2), ('nomias', 2), ('branched', 2), ('burrows', 2), ('emergence', 2), ('uncanny', 2), ('tunnels', 2), ('duller', 2), ('turf', 2), ('armata', 2), ('gruesome', 2), ('rightful', 2), ('baskets', 2), ('moths', 2), ('drones', 2), ('retires', 2), ('sip', 2), ('woolly', 2), ('ready-made', 2), ('nesting', 2), ('snug', 2), ('catkin', 2), ('staminate', 2), ('sloe', 2), ('ribes', 2), ('hibernate', 2), ('honeybee', 2), ('coefficients', 2), ('sedimentation', 2), ('4.1', 2), ('chambered', 2), ('equilibrated', 2), ('antisera', 2), ('rabbits', 2), ('heterozygous', 2), ('bovine', 2), ('donation', 2), ('512', 2), ('sensitized', 2), ('agglutinins', 2), ('coworkers', 2), ('diethylaminoethyl', 2), ('stepwise', 2), ('rawson', 2), ('sabotage', 2), ('prerequisite', 2), ('outbreak', 2), ('epidemics', 2), ('explosives', 2), ('debilitating', 2), ('low-grade', 2), ('aggressor', 2), ('improbable', 2), ('fastidious', 2), ('tularemia', 2), ('gallons', 2), ('bacillus', 2), ('niger', 2), ('subtilis', 2), ('dosages', 2), ('isopleths', 2), ('156', 2), ('facilitates', 2), ('cadmium', 2), ('travelling', 2), ('beverage', 2), ('inoculation', 2), ('trachea', 2), ('hand-to-hand', 2), ('secondarily', 2), ('influx', 2), ('meteorites', 2), ('decreases', 2), ('2.512', 2), ('spheres', 2), ('ejection', 2), ('detectors', 2), ('detector', 2), ('153', 2), ('inadequacies', 2), ('micrometeoritic', 2), ('corpuscular', 2), ('relativistic', 2), ('orbital', 2), ('29.2', 2), ('14.7', 2), ('oxalate', 2), ('uranyl', 2), ('0.2', 2), ('irreproducibility', 2), ('hydride', 2), ('210', 2), ('liberated', 2), ('ensuring', 2), ('thermostat', 2), ('shatter', 2), ('5.5', 2), ('withstood', 2), ('redistributed', 2), ('watt', 2), ('fused', 2), ('relevancy', 2), ('reagents', 2), ('interrelated', 2), ('negatively', 2), ('sorption', 2), ('two-fold', 2), ('oils', 2), ('hydrophobic', 2), ('ionized', 2), ('hydrocarbon', 2), ('agglomeration', 2), ('hydrophilic', 2), ('float', 2), ('loosen', 2), ('agglomerate', 2), ('der', 2), ('mechanically', 2), ('colorless', 2), ('glycerol', 2), ('typified', 2), ('colloidal', 2), ('classed', 2), ('redeposition', 2), ('whiteness', 2), ('analyzer', 2), ('substrate', 2), ('scouring', 2), ('expressly', 2), ('alkaline', 2), ('entrant', 2), ('flakes', 2), ('tripolyphosphate', 2), ('surfactants', 2), ('evacuated', 2), ('low-temperature', 2), ('corrections', 2), ('blumberg', 2), ('dispersion', 2), ('distortions', 2), ('spectrometer', 2), ('varian', 2), ('lm', 2), ('coefficient', 2), ('susceptibility', 2), ('410', 2), ('10.6', 2), ('337', 2), ('470', 2), ('endothermic', 2), ('centrifugation', 2), ('ferromagnetic', 2), ('ups', 2), ('randomly', 2), ('asymmetrically', 2), ('interlayer', 2), ('compounds', 2), ('2.4', 2), ('dimethylglyoxime', 2), ('motional', 2), ('predicts', 2), ('gauss', 2), ('asymmetric', 2), ('polycrystalline', 2), ('conformational', 2), ('poises', 2), ('suspensions', 2), ('extinction', 2), ('exerting', 2), ('philippoff', 2), ('thermodynamically', 2), ('thermodynamics', 2), ('thermodynamic', 2), ('molal', 2), ('3.25', 2), ('viscoelastic', 2), ('520', 2), ('770', 2), ('12500', 2), ('radiated', 2), ('enthalpy', 2), ('rectifier', 2), ('coolant', 2), ('pore', 2), ('inflow', 2), ('ejected', 2), ('axial', 2), ('tungsten', 2), ('1/4', 2), ('modifies', 2), ('co-workers', 2), ('voltages', 2), ('conduction', 2), ('convection', 2), ('ablation', 2), ('half-intensity', 2), ('smoother', 2), ('coates', 2), ('meter', 2), ('observable', 2), ('3.03', 2), ('0.8', 2), ('drake', 2), ('originates', 2), ('rocklike', 2), ('pettit', 2), ('lunation', 2), ('e.g.', 2), ('conductivity', 2), ('ome', 2), ('pooling', 2), ('1/2', 2), ('installments', 2), ('repayable', 2), ('borrower', 2), ('stipulate', 2), ('minn.', 2), ('colo.', 2), ('budgetary', 2), ('registrants', 2), ('flyers', 2), ('competitively', 2), ('personalized', 2), ('analyzes', 2), ('prophetically', 2), ('namesake', 2), ('hieronymus', 2), ('modeled', 2), ('1902', 2), ('gladius', 2), ('anticipates', 2), ('self-destructive', 2), ('blithe', 2), ('blue-eyed', 2), ('bitten', 2), ('puppy', 2), ('amiable', 2), ('antithesis', 2), ('light-headed', 2), ('abject', 2), ('quarrels', 2), ('enigmatic', 2), ('physiognomy', 2), ('announces', 2), ('meaningfulness', 2), ('catastrophes', 2), ('disguise', 2), ('commandment', 2), ('sufferings', 2), ('whore', 2), ('infidelity', 2), ('coquette', 2), ('lizzy', 2), ('cunning', 2), ('incarnate', 2), ('riddling', 2), ('analogies', 2), ('prowess', 2), ('warranted', 2), ('parental', 2), ('predictive', 2), ('espionage', 2), ('stubbornness', 2), ('newtonian', 2), ('built-in', 2), ('dwindle', 2), ('amenable', 2), ('mortals', 2), ('lucretius', 2), ('socialized', 2), ('copernicus', 2), ('applicability', 2), ('hawkins', 2), ('quieter', 2), ('scandinavian', 2), ('egalitarianism', 2), ('reactionaries', 2), ('charleston', 2), ('piedmont', 2), ('tidewater', 2), ('adjective', 2), ('reconstructed', 2), ('fascism', 2), ('conceal', 2), ('scornful', 2), ('attaches', 2), ('enmeshed', 2), ('uncooperative', 2), ('coerce', 2), ('scornfully', 2), ('herein', 2), ('bernhardt', 2), ('staggeringly', 2), ('slapstick', 2), ('chasing', 2), ('pursuer', 2), ('presumes', 2), ('looted', 2), ('declivity', 2), ('hide-out', 2), ('whooping', 2), ('pursues', 2), ('1915', 2), ('photographing', 2), ('fade', 2), ('inept', 2), ('fashioning', 2), ('documentaries', 2), ('simple-minded', 2), ('scaffold', 2), ('parades', 2), ('engraved', 2), ('ersatz', 2), ('hillbilly', 2), ('propagandist', 2), ('shudder', 2), ('amateurs', 2), ('anthropologists', 2), ('undergraduates', 2), ('wavers', 2), ('bunyan', 2), ('transcribed', 2), ('riddles', 2), ('davy', 2), ('patrick', 2), ('paralleled', 2), ('incarnation', 2), ('self-deception', 2), ('scans', 2), ('waits', 2), ('outlived', 2), ('microcosm', 2), ('imperialism', 2), ('oldsters', 2), ('cures', 2), ('prescription', 2), ('diagnosed', 2), ('spokane', 2), ('otis', 2), ('spike', 2), ('relies', 2), ('diabetic', 2), ('incurable', 2), ('practitioner', 2), ('ghouls', 2), ('sufferer', 2), ('racketeer', 2), ('chiropractor', 2), ('1020', 2), ('distributing', 2), ('clique', 2), ('plunder', 2), ('cultist', 2), ('sanipractor', 2), ('impotence', 2), ('translating', 2), ('milks', 2), ('buzzes', 2), ('ticks', 2), ('gullible', 2), ('robbing', 2), ('miseries', 2), ('rewarded', 2), ('ailment', 2), ('97', 2), ('neon', 2), ('disorder', 2), ('one-time', 2), ('chauncey', 2), ('level-headed', 2), ('obliteration', 2), ('corroborated', 2), ('treasure', 2), ('assyrian', 2), ('inaudible', 2), ('journeys', 2), ('immensity', 2), ('existent', 2), ('prehistoric', 2), ('perceptive', 2), ('theorize', 2), ('impressing', 2), ('psychic', 2), ('composing', 2), ('continuities', 2), ('embraces', 2), ('telepathy', 2), ('prophetic', 2), ('overwhelmed', 2), ('clasping', 2), ('obstructed', 2), ('jargon', 2), ('scorn', 2), ('unscientific', 2), ('coincidences', 2), ('previsions', 2), ('merriment', 2), ('rushes', 2), ('admissions', 2), ('molding', 2), ('tolerate', 2), ('inexcusable', 2), ('dissection', 2), ('exhibitions', 2), ('supervises', 2), ('coverings', 2), ('accredited', 2), ('catalogs', 2), ('tumbler', 2), ('beginner', 2), ('palms', 2), ('dashes', 2), ('push-ups', 2), ('kindergarten', 2), ('mats', 2), ('springboard', 2), ('gyms', 2), ('culminate', 2), ('cartwheels', 2), ('handstands', 2), ('stunts', 2), ('somersault', 2), ('tumbling', 2), ('olympics', 2), ('rainfall', 2), ('logged', 2), ('irrigation', 2), ('caves', 2), ('shipwreck', 2), ('coastal', 2), ('crabs', 2), ('clams', 2), ('seacoast', 2), ('canyons', 2), ('flooding', 2), ('cools', 2), ('investigator', 2), ('planner', 2), ('orienting', 2), ('overpowered', 2), ('brilliance', 2), ('earsplitting', 2), ('suave', 2), ('brute', 2), ('melodramatic', 2), ('charms', 2), ('lp', 2), ('presto', 2), ('brahmsian', 2), ('unclouded', 2), ('timbre', 2), ('valve', 2), ('beefed-up', 2), ('highs', 2), ('reproduces', 2), ('muck', 2), ('superlative', 2), ('fleisher', 2), ('expertise', 2), ('tempos', 2), ('indulgent', 2), ('collaborate', 2), ('radiant', 2), ('impetuous', 2), ('vibrancy', 2), ('individuality', 2), ('sheds', 2), ('babin', 2), ('aeschbacher', 2), ('glazer', 2), ('reissue', 2), ('discreetly', 2), ('renditions', 2), ('divertimento', 2), ('one-tenth', 2), ('circulatory', 2), ('unsaturated', 2), ('nutrients', 2), ('nutritional', 2), ('poisons', 2), ('graded', 2), ('bland', 2), ('melon', 2), ('solicitude', 2), ('regularity', 2), ('stub', 2), ('assures', 2), ('strawberries', 2), ('thawing', 2), ('decayed', 2), ('transplant', 2), ('sawdust', 2), ('rooting', 2), ('coddled', 2), ('seedbed', 2), ('germinate', 2), ('riotous', 2), ('wobble', 2), ('writhing', 2), ('cables', 2), ('facet', 2), ('spectacularly', 2), ('bodybuilders', 2), ('high-rep', 2), ('high-set', 2), ('hallmark', 2), ('herculean', 2), ('pectoral', 2), ('pushup', 2), ('affords', 2), ('serratus', 2), ('pumped-up', 2), ('deltoids', 2), ('pullover', 2), ('vic', 2), ('gym', 2), ('symmetrical', 2), ('dissatisfied', 2), ('shapely', 2), ('jean-paul', 2), ('physique', 2), ('pupil', 2), ('entrusted', 2), ('gotta', 2), ('schoolmates', 2), ('taunts', 2), ('divinely', 2), ('ceasing', 2), ('interminable', 2), ('sabbath', 2), ('wherefore', 2), ('nadir', 2), ('woe', 2), ('parallels', 2), ('prompts', 2), ('carelessness', 2), ('disobedient', 2), ('obedience', 2), ('pretext', 2), ('beguiled', 2), ('systematizing', 2), ('carnal', 2), ('whence', 2), ('interprets', 2), ('swoops', 2), ('slough', 2), ('nun', 2), ('crowning', 2), (\"mary's\", 2), ('liverpool', 2), ('footing', 2), ('parson', 2), ('b.b.c.', 2), ('nonconformist', 2), ('ferris', 2), ('canonized', 2), ('shepherd', 2), ('dowry', 2), ('recite', 2), ('reclaim', 2), ('lapsed', 2), ('anglicans', 2), ('chapels', 2), ('recounted', 2), ('cathedrals', 2), ('marveled', 2), ('churchgoing', 2), ('disloyalty', 2), ('garb', 2), ('implying', 2), ('preconceptions', 2), ('engender', 2), ('enthusiastically', 2), ('octave', 2), ('unauthorized', 2), ('frees', 2), ('qualifies', 2), ('fritz', 2), ('unconditionally', 2), ('affirming', 2), ('niebuhr', 2), ('distinctively', 2), ('richly', 2), ('sacrificium', 2), ('self-destruction', 2), ('foolishness', 2), ('demythologized', 2), ('infatuation', 2), ('demythologize', 2), ('insubstantial', 2), ('profundity', 2), ('attested', 2), ('communicated', 2), ('pronouncements', 2), ('unconvincing', 2), ('argues', 2), ('ciphers', 2), ('conceptuality', 2), ('separable', 2), ('permanence', 2), ('numinous', 2), ('church-state', 2), ('absolutes', 2), ('hale', 2), ('discredit', 2), ('underworld', 2), ('formulae', 2), ('designate', 2), ('unavoidably', 2), ('inexorably', 2), ('unfolds', 2), ('parris', 2), ('abigail', 2), ('devils', 2), ('debunking', 2), ('superstitions', 2), ('undesirable', 2), ('illusory', 2), ('extraneous', 2), ('objectification', 2), ('fairies', 2), ('yvette', 2), ('impromptu', 2), ('profess', 2), ('healthily', 2), ('objectivity', 2), ('rapists', 2), ('virtual', 2), ('routines', 2), ('hackneyed', 2), ('poker', 2), ('novelties', 2), ('dora', 2), ('fairchild', 2), ('hurrying', 2), ('chorines', 2), ('abbott', 2), ('tahse', 2), ('monumental', 2), ('perky', 2), ('fantasia', 2), ('gowns', 2), ('evocations', 2), ('bolger', 2), ('outdo', 2), ('sifted', 2), ('lawless', 2), ('shriek', 2), ('lingers', 2), ('chap', 2), ('osborne', 2), ('hedison', 2), ('flawless', 2), ('edgy', 2), ('daisies', 2), ('candid', 2), ('brooke', 2), ('theatre-by-the-sea', 2), ('prides', 2), ('boaz', 2), ('naomi', 2), ('unrealistic', 2), ('storyline', 2), ('cadre', 2), ('studios', 2), ('bric-a-brac', 2), ('impeccably', 2), ('imprimatur', 2), ('interruptions', 2), ('covent', 2), ('bel', 2), ('injected', 2), ('aurally', 2), ('nervousness', 2), ('immersed', 2), ('coloratura', 2), ('unfolding', 2), ('sextet', 2), ('resourcefulness', 2), ('stylization', 2), ('ovation', 2), ('newcomer', 2), ('perusal', 2), ('memorabilia', 2), ('cleverly', 2), ('wee', 2), ('pee', 2), ('considerately', 2), ('closeups', 2), ('dixieland', 2), ('dukes', 2), ('lionel', 2), ('timex', 2), ('portentous', 2), ('haunts', 2), ('deathbed', 2), ('comically', 2), ('comedians', 2), ('artistry', 2), ('dubbed', 2), ('complexities', 2), ('impious', 2), ('rogues', 2), ('hypocrites', 2), ('armor', 2), ('lanky', 2), ('nikolai', 2), ('knight-errant', 2), ('escapades', 2), ('illustrious', 2), ('fifty-fifth', 2), ('cervantes', 2), ('miguel', 2), ('sustenance', 2), ('quart', 2), ('piccadilly', 2), ('butlers', 2), ('spaciousness', 2), ('dungeon', 2), ('embodies', 2), ('conjures', 2), ('wasteland', 2), ('pheasants', 2), ('simplicities', 2), ('stirs', 2), ('blandly', 2), ('countryman', 2), ('wily', 2), ('jerebohm', 2), ('collisions', 2), ('franco', 2), ('giovanni', 2), ('lammermoor', 2), ('everett', 2), ('3211', 2), ('cancellation', 2), ('impasse', 2), ('horne', 2), ('budge', 2), ('marlene', 2), ('absurdities', 2), ('parsifal', 2), ('operas', 2), ('tannhaeuser', 2), ('bayreuth', 2), ('buoyant', 2), ('translucent', 2), ('weber', 2), ('incandescent', 2), ('recitals', 2), ('nathan', 2), ('carbines', 2), ('fetching', 2), ('/2', 2), ('commando', 2), ('swarm', 2), ('invaders', 2), ('chevrolet', 2), ('messrs.', 2), ('crave', 2), ('u.n.', 2), ('structurally', 2), ('precedents', 2), ('squabbles', 2), ('neutralists', 2), ('applauding', 2), ('rake', 2), ('presentable', 2), ('1899', 2), ('punishments', 2), ('posthumous', 2), ('mausoleum', 2), ('intransigence', 2), ('lippmann', 2), ('front-line', 2), ('m.p.', 2), ('crossman', 2), ('sputnik', 2), ('inspire', 2), ('miscalculation', 2), ('mccone', 2), ('risky', 2), ('cornell', 2), ('infinitum', 2), ('apiece', 2), ('soothsayers', 2), ('caroline', 2), ('playmate', 2), ('bites', 2), ('daddy', 2), ('non-existent', 2), ('helper', 2), ('considerate', 2), ('mommy', 2), ('motivates', 2), ('ballast', 2), ('unmoved', 2), ('westerner', 2), ('acrobatic', 2), ('irreparable', 2), ('phonies', 2), ('quiz', 2), ('upsets', 2), ('unforeseen', 2), ('fortify', 2), ('instructional', 2), ('benet', 2), ('hillyer', 2), ('bonus', 2), ('vocabularies', 2), ('albums', 2), ('sean', 2), ('modestly', 2), ('alva', 2), ('sluggish', 2), ('sciatica', 2), ('sclerosis', 2), ('tendons', 2), ('shimmy', 2), ('dystrophy', 2), ('palsy', 2), ('gums', 2), ('massage', 2), ('dentists', 2), ('brake', 2), ('plugged', 2), ('broxodent', 2), ('scalloped', 2), ('flats', 2), ('highlight', 2), ('taffy', 2), ('nautical', 2), ('padded', 2), ('cork', 2), ('weaves', 2), ('overlook', 2), ('shantung', 2), ('tintable', 2), ('hues', 2), ('barest', 2), ('dressy', 2), ('legged', 2), ('weightlessness', 2), ('leathers', 2), ('invest', 2), ('pavements', 2), ('sizzling', 2), ('commies', 2), ('162', 2), ('reserving', 2), ('127', 2), ('belted', 2), ('scherer', 2), ('runner-up', 2), ('billiken', 2), ('clutch', 2), (\"'em\", 2), ('halftime', 2), ('bevo', 2), ('kieffer', 2), ('lavish', 2), ('billikens', 2), (\"'55\", 2), ('88', 2), ('96', 2), ('blasting', 2), ('.280', 2), ('virdon', 2), ('burgess', 2), ('.300', 2), ('quieted', 2), ('groove', 2), ('taussig', 2), ('nieman', 2), ('busch', 2), ('boyer', 2), ('haddix', 2), ('solly', 2), ('mauch', 2), ('spongy', 2), ('155', 2), ('head-on', 2), ('banjo', 2), ('relieves', 2), ('nicer', 2), ('dey', 2), ('loophole', 2), ('gully', 2), ('duffers', 2), ('wayward', 2), ('ruefully', 2), ('victimized', 2), ('downtrodden', 2), ('sacrilege', 2), ('frustrations', 2), ('incompetents', 2), ('rochester', 2), ('heralded', 2), ('80738', 2), ('symington', 2), ('comeback', 2), ('plainfield', 2), ('saluted', 2), ('snead', 2), ('georgetown', 2), ('disappointments', 2), ('gimbel', 2), ('imminent', 2), ('dais', 2), ('waldorf-astoria', 2), ('engrossed', 2), ('packers', 2), ('troy', 2), ('rensselaer', 2), ('steelers', 2), ('gauer', 2), ('dyer', 2), ('fouled', 2), ('lopez', 2), ('hector', 2), ('joey', 2), ('champs', 2), ('yogi', 2), ('video', 2), ('howsam', 2), ('windy', 2), ('gehrig', 2), ('lowe', 2), ('sluggers', 2), ('gomez', 2), ('milestone', 2), ('pastime', 2), ('no-hit', 2), ('heroics', 2), ('pops', 2), ('keyhole', 2), ('ogden', 2), ('allison', 2), ('carreon', 2), ('turk', 2), ('batted', 2), ('minnie', 2), ('ranked', 2), ('kenny', 2), ('chico', 2), ('hammered', 2), ('outfield', 2), ('hitter', 2), ('mcdaniel', 2), ('paschal', 2), ('lefty', 2), ('lagged', 2), ('lefthander', 2), ('149', 2), ('355', 2), ('361', 2), ('tosses', 2), ('speedy', 2), ('jarred', 2), ('carmichael', 2), ('145', 2), ('davidson', 2), ('rabb', 2), ('leaguers', 2), ('buster', 2), ('tcu', 2), ('sprained', 2), ('aggies', 2), ('raiders', 2), ('lubbock', 2), ('owls', 2), ('taper', 2), ('mcnaughton', 2), ('crucified', 2), ('fullback', 2), ('kickoff', 2), ('surpassed', 2), ('447', 2), ('yardage', 2), ('kicks', 2), ('ineligible', 2), ('ailing', 2), ('hampered', 2), ('playoff', 2), ('roster', 2), ('astray', 2), ('longhorn', 2), ('eldon', 2), ('donated', 2), ('eleventh', 2), ('sylvania', 2), ('bespectacled', 2), ('straightaway', 2), ('quarter-mile', 2), ('striding', 2), ('stewards', 2), ('celebrants', 2), ('forbes', 2), ('1.24', 2), ('grimm', 2), (\"patrick's\", 2), ('festive', 2), ('celebrate', 2), ('milt', 2), ('slated', 2), ('hoyt', 2), ('fielding', 2), ('whiz', 2), ('slugging', 2), ('rangy', 2), ('ky.', 2), ('melt', 2), ('setback', 2), ('ripened', 2), ('390', 2), ('scoreboard', 2), ('blasted', 2), ('tallies', 2), ('snyder', 2), ('barker', 2), ('bunt', 2), ('hitters', 2), ('158', 2), ('howser', 2), ('baseman', 2), ('stepanovich', 2), ('heywood', 2), ('nab', 2), ('siebern', 2), ('scoreless', 2), ('righthander', 2), ('winless', 2), ('carson', 2), ('culminating', 2), ('supt.', 2), ('re-elected', 2), ('southwestern', 2), ('newton', 2), ('buchanan', 2), ('defenders', 2), ('15000000', 2), ('hamlet', 2), ('weatherford', 2), ('wesley', 2), ('appointee', 2), ('vacancies', 2), ('formby', 2), ('correctness', 2), ('donations', 2), ('galveston', 2), ('dissent', 2), ('beaumont', 2), ('option', 2), ('gambler', 2), ('reps.', 2), ('outlay', 2), ('county-wide', 2), ('impair', 2), ('unconstitutional', 2), ('tyler', 2), ('dewey', 2), ('pipeline', 2), ('escheat', 2), ('taunted', 2), ('legislatures', 2), ('hopper', 2), ('quickie', 2), ('rescind', 2), ('opposes', 2), ('hurdle', 2), ('dissents', 2), ('snodgrass', 2), ('reelection', 2), ('bowden', 2), ('surveillance', 2), ('wards', 2), ('disproportionate', 2), ('inure', 2), ('feeley', 3), ('bookies', 3), ('pioneers', 3), ('ghettos', 3), ('rapping', 3), ('yiddish', 3), ('paot', 3), ('hurrays', 3), ('sparky', 3), ('doolittle', 3), ('momoyama', 3), ('hetty', 3), ('kiz', 3), ('triplets', 3), ('tillie', 3), ('evadna', 3), ('melissa', 3), ('mclish', 3), ('stampede', 3), ('leavin', 3), ('fiercely', 3), ('murmuring', 3), ('buckets', 3), ('babes', 3), ('neural', 3), ('insomnia', 3), ('langer', 3), ('streaks', 3), ('ferrell', 3), ('tracking', 3), ('courthouse', 3), ('stake-out', 3), ('alvarez', 3), ('burch', 3), ('acey', 3), ('beeps', 3), ('bugging', 3), ('shadowing', 3), ('bug', 3), ('brennan', 3), ('nonreactivity', 3), ('suggestibility', 3), ('censuses', 3), ('demography', 3), ('jure', 3), ('endogamy', 3), ('socialization', 3), ('core-negro', 3), ('f-fold', 3), ('tangency', 3), ('nonsingular', 3), ('involutorial', 3), ('involutions', 3), ('clinico-pathologic', 3), ('fascicles', 3), ('medico-military', 3), ('histochemistry', 3), ('jaycees', 3), ('state-local', 3), ('middletown', 3), ('.07', 3), ('personally-owned', 3), ('forty-seven', 3), ('gruff', 3), ('homosexuals', 3), ('preambles', 3), ('1787', 3), ('segments', 3), ('choreographers', 3), ('schaack', 3), ('amazingly', 3), ('confederation', 3), ('puccini', 3), ('nberg', 3), ('scho', 3), ('khaju', 3), ('promenade', 3), ('abbas', 3), ('idje', 3), ('rover', 3), ('outback', 3), ('guarded', 3), ('bmews', 3), ('pandora', 3), ('pushers', 3), ('consoles', 3), ('windowless', 3), ('mediumistic', 3), ('parapsychology', 3), ('orthodontists', 3), ('orthodontics', 3), ('caresses', 3), ('hobbies', 3), ('inaugurated', 3), ('aviator', 3), ('sprayed', 3), ('salads', 3), ('colman', 3), ('fertilizers', 3), ('chattered', 3), ('radar-controlled', 3), ('bascom', 3), ('beckstrom', 3), ('porto', 3), ('adriatic', 3), ('stammered', 3), ('giveaways', 3), ('cues', 3), ('psychiatry', 3), ('socio-economic', 3), ('charting', 3), ('eskimo', 3), ('peanuts', 3), ('fha', 3), ('fenced', 3), ('swimmers', 3), ('chenoweth', 3), ('supervised', 3), ('newbury', 3), ('batten', 3), ('planer', 3), ('fairing', 3), ('three-inch-wide', 3), ('butted', 3), ('half-inch', 3), ('backstitch', 3), ('shakers', 3), ('creamer', 3), ('beveled', 3), ('turquoise', 3), ('matt', 3), ('toner', 3), ('overlapped', 3), ('glazes', 3), ('stoneware', 3), ('molds', 3), ('chop', 3), ('coney', 3), ('carne', 3), ('teaspoons', 3), ('spiced', 3), ('threaded', 3), ('meats', 3), ('veered', 3), ('ahmet', 3), ('sultan', 3), ('emperors', 3), ('justinian', 3), ('marmara', 3), ('panorama', 3), ('yosemite', 3), ('whirlwind', 3), ('champlain', 3), ('catsup', 3), ('worcestershire', 3), ('garlic', 3), ('mashed', 3), ('saucepan', 3), ('nutmeg', 3), ('tablespoonful', 3), ('cupful', 3), ('kedgeree', 3), ('pickled', 3), ('lever-action', 3), ('scabbard', 3), ('140', 3), ('targo', 3), ('autoloader', 3), ('kodiak', 3), ('recoil', 3), ('magnums', 3), ('bolt-action', 3), ('calibers', 3), ('rim-fire', 3), ('rim-fires', 3), ('defunct', 3), ('handgun', 3), ('06', 3), ('01.1', 3), ('rodney', 3), ('36.1', 3), ('pacers', 3), ('year-olds', 3), ('monel', 3), ('laguerre', 3), ('debonnie', 3), ('mph', 3), ('decimal', 3), ('rodder', 3), ('accessible', 3), ('scribe', 3), ('roundhead', 3), ('boatman', 3), ('sailboats', 3), ('upsurge', 3), ('pets', 3), ('kennel', 3), ('thrust-to-weight', 3), ('spacecraft', 3), ('icbms', 3), ('braces', 3), ('lesourd', 3), ('righteous', 3), ('amongst', 3), ('shan', 3), ('metaphysic', 3), ('taoist', 3), ('taoism', 3), ('weld', 3), ('1789', 3), ('benevolence', 3), ('walt', 3), ('agitation', 3), ('detrimental', 3), ('nareb', 3), ('pax-ordo', 3), ('contingencies', 3), ('watches', 3), ('jurists', 3), ('cairo', 3), ('indigenous', 3), ('separates', 3), ('centrality', 3), ('functionally', 3), ('proscription', 3), ('confucian', 3), ('divination', 3), ('profanity', 3), ('promotes', 3), ('bliss', 3), ('precepts', 3), ('textbook', 3), ('reverent', 3), ('norton', 3), ('suffused', 3), ('respecting', 3), ('hydrogens', 3), ('metrecal', 3), ('caloric', 3), ('oz.', 3), ('faulty', 3), ('race-driver', 3), ('waterways', 3), ('pitiful', 3), ('weighty', 3), ('week-long', 3), ('rockies', 3), ('maritime', 3), ('relentless', 3), ('reavey', 3), ('wbai', 3), ('addiction', 3), ('elisabeth', 3), ('benedick', 3), ('happenings', 3), ('charge-excess', 3), ('bondi', 3), ('riefling', 3), ('vista', 3), ('half-dozen', 3), ('intelligently', 3), ('nutcracker', 3), ('adagio', 3), ('hesitation', 3), ('truthfully', 3), ('ory', 3), ('toughs', 3), ('agility', 3), ('hirsch', 3), ('excessively', 3), ('implicitly', 3), ('mij', 3), ('mystic', 3), ('cliburn', 3), ('hendricks', 3), ('carrots', 3), ('photographer', 3), ('evidences', 3), ('rococo', 3), ('francaise', 3), ('jannequin', 3), ('consummate', 3), ('decaying', 3), ('salute', 3), ('stint', 3), ('pagnol', 3), ('flynn', 3), ('scraps', 3), ('portray', 3), ('obsession', 3), ('negotiated', 3), ('aggrieved', 3), ('burman', 3), ('adorable', 3), ('penned', 3), ('trenchant', 3), ('ingratiating', 3), ('madrigals', 3), ('hygiene', 3), ('enlightening', 3), ('mendelssohn', 3), ('lindemann', 3), ('watson-watt', 3), ('rust', 3), ('transcript', 3), ('substituting', 3), ('wounds', 3), ('dummy', 3), ('depugh', 3), ('unrelieved', 3), ('unabashed', 3), ('austrian', 3), ('gypsy', 3), ('surname', 3), ('bristol', 3), ('provokes', 3), ('sideways', 3), ('casbah', 3), ('originals', 3), ('paralysis', 3), ('cultivated', 3), ('islamic', 3), ('moslem', 3), ('justifiable', 3), ('aec', 3), ('ornament', 3), ('butchery', 3), ('calisthenics', 3), ('ahmad', 3), ('donate', 3), ('woodside', 3), ('affirmative', 3), ('austria', 3), ('disarmed', 3), ('cafes', 3), ('polling', 3), ('masaryk', 3), ('service-connected', 3), ('non-service-connected', 3), ('snowstorm', 3), ('praying', 3), ('makings', 3), ('woodsmoke', 3), ('aroma', 3), ('copied', 3), ('blessings', 3), ('dissuade', 3), ('verses', 3), ('weakest', 3), ('triandos', 3), ('all-white', 3), ('breath-taking', 3), ('woven', 3), ('pod', 3), ('satisfactions', 3), ('enchanting', 3), ('visualize', 3), ('disciples', 3), ('trespasses', 3), ('shines', 3), ('twenty-second', 3), ('pocketbook', 3), ('fares', 3), ('1936', 3), ('accountability', 3), ('salvage', 3), ('dalton', 3), ('snowy', 3), ('chatham', 3), ('shoreline', 3), ('reluctance', 3), ('oas', 3), ('balaguer', 3), ('extremists', 3), ('mosk', 3), ('joiner', 3), ('erhart', 3), ('courageously', 3), ('fdr', 3), ('flamboyant', 3), ('public-spirited', 3), ('glamour', 3), ('roam', 3), ('ncta', 3), ('totalitarianism', 3), ('ciudad', 3), ('assassination', 3), ('aggressions', 3), ('congratulate', 3), ('shuffle', 3), ('inadequacy', 3), ('billing', 3), ('saves', 3), ('mechanization', 3), ('welsh', 3), ('quotas', 3), ('low-wage', 3), ('underwood', 3), ('tolls', 3), ('citizenry', 3), ('coolidge', 3), ('gilman', 3), ('hostages', 3), ('.38', 3), ('salvador', 3), ('chiang', 3), ('chen', 3), ('nationalist', 3), ('tunisian', 3), ('bizerte', 3), ('mccloy', 3), ('nonwhite', 3), ('looting', 3), ('leopoldville', 3), ('generale', 3), ('colonialism', 3), ('geography', 3), ('enrollment', 3), ('bootle', 3), ('chaplin', 3), ('stirling', 3), ('undergraduate', 3), ('stitch', 3), ('loper', 3), ('sweater', 3), ('1919', 3), ('left-handed', 3), ('vowed', 3), ('photographers', 3), ('overdeveloped', 3), ('understandably', 3), ('teammate', 3), ('pars', 3), ('threesome', 3), ('hubert', 3), ('truncated', 3), ('smelling', 3), ('oust', 3), ('unheard', 3), ('confront', 3), ('intrigue', 3), ('seize', 3), ('dulles', 3), ('ike', 3), ('fronts', 3), ('herter', 3), ('enacting', 3), ('outlawed', 3), ('uncontrolled', 3), ('disputes', 3), ('allegedly', 3), ('idealism', 3), ('salaries', 3), ('gamble', 3), ('loath', 3), ('awakening', 3), ('rembrandt', 3), ('pfohl', 3), ('1792', 3), ('mansion', 3), ('billed', 3), ('off-duty', 3), ('inna', 3), ('goldwater', 3), ('frankness', 3), ('winners', 3), ('leningrad', 3), ('jorda', 3), ('dade', 3), ('doorstep', 3), ('peppery', 3), ('pal', 3), ('redhead', 3), ('specialize', 3), ('format', 3), ('tahoe', 3), ('nightclubs', 3), ('socket', 3), ('execute', 3), ('gloriana', 3), ('ludwig', 3), ('yeast', 3), ('hilton', 3), ('reese', 3), ('chartered', 3), ('mmes', 3), ('stagecoach', 3), ('saledo', 3), ('acacia', 3), ('decorating', 3), ('canned', 3), ('breasts', 3), ('baking', 3), ('cabot', 3), ('32000', 3), ('auntie', 3), ('sunrise', 3), ('ebony', 3), ('invoking', 3), ('haggling', 3), ('pickers', 3), ('perlman', 3), ('far-reaching', 3), ('1970', 3), ('dow', 3), ('alto', 3), ('sprinkel', 3), ('sharon', 3), ('gerald', 3), ('buick', 3), ('extraction', 3), ('gordin', 3), ('southeastern', 3), ('driers', 3), ('hottest', 3), ('curtis', 3), ('connect', 3), ('pier', 3), ('arger', 3), ('gus', 3), ('complacency', 3), ('ghastly', 3), ('world-famous', 3), ('mana', 3), ('420', 3), ('sunnyvale', 3), ('runway', 3), ('v-1', 3), ('wrecked', 3), ('hester', 3), ('nyu', 3), ('masked', 3), ('perjury', 3), ('sorrentino', 3), ('parrillo', 3), ('damages', 3), ('vernava', 3), ('smithfield', 3), ('giorgio', 3), ('pezza', 3), ('sherwood', 3), ('hog', 3), ('karen', 3), ('advisors', 3), ('counseled', 3), ('spice-nice', 3), ('entertainers', 3), ('brett', 3), ('elaine', 3), ('peck', 3), ('blasingame', 3), ('bryan', 3), ('troup', 3), ('eradication', 3), ('transfers', 3), ('greenville', 3), ('killingsworth', 3), ('pledged', 3), ('stand-ins', 3), ('rio', 3), ('mcnair', 3), ('60000', 3), ('murphy', 3), ('mall', 3), ('sidney', 3), ('vicky', 3), ('christine', 3), ('township', 3), ('wilmette', 3), ('boarded', 3), ('rivalries', 3), ('fuchs', 3), ('bailey', 3), ('magistrate', 3), ('reactor', 3), ('dresbach', 3), ('dispatched', 3), ('2100', 3), ('jordan', 3), ('eustis', 3), ('vieth', 3), ('marsicano', 3), ('monte', 3), ('clifton', 3), ('spurdle', 3), ('allan', 3), ('walnut', 3), ('featuring', 3), ('pi', 3), ('cater', 3), ('shreveport', 3), ('kappa', 3), ('officiated', 3), ('summertime', 3), ('chat', 3), ('alcoholics', 3), ('mom', 3), ('dept.', 3), ('showman', 3), ('leukemia', 3), ('maureen', 3), ('clinton', 3), ('consul', 3), ('burkes', 3), ('bruce', 3), ('sims', 3), ('weinstein', 3), ('dist.', 3), ('laymen', 3), ('12000', 3), ('sinless', 3), ('verbally', 3), ('clarification', 3), ('editing', 3), ('bulwark', 3), ('zimmerman', 3), ('two-year', 3), ('vacated', 3), ('masonic', 3), ('willamette', 3), ('melvin', 3), ('sw', 3), ('molvar', 3), ('ierulli', 3), ('junta', 3), ('contested', 3), ('gursel', 3), ('esplanade', 3), ('manslaughter', 3), ('mcconnell', 3), ('rooming', 3), ('overhauling', 3), ('violations', 3), ('casualty', 3), ('ptc', 3), ('sued', 3), ('contracting', 3), ('economize', 3), ('normalcy', 3), ('lawmakers', 3), ('marines', 3), ('thoroughfare', 3), ('wholesale', 3), ('princes', 3), ('sargent', 3), ('delaney', 3), ('trimble', 3), ('incumbent', 3), ('sapio', 3), ('conquer', 3), ('hoodlums', 3), ('courageous', 3), ('slogans', 3), ('pledge', 3), ('neil', 3), ('sheeran', 3), ('330', 3), ('harriet', 3), ('campaigning', 3), ('bourcier', 3), ('sr.', 3), ('dividing', 3), ('sheraton-biltmore', 3), ('labor-management', 3), ('supermarkets', 3), ('erred', 3), ('trusting', 3), ('coordinating', 3), ('angola', 3), ('dirksen', 3), ('clinic', 3), ('salinger', 3), ('parsons', 3), ('circuits', 3), ('fluorescent', 3), ('carpenters', 3), ('handyman', 3), ('crumb', 3), ('springfield', 3), ('unhurried', 3), ('ballplayers', 3), ('rounding', 3), ('fielder', 3), ('italians', 3), ('portugal', 3), ('boxcar', 3), ('joking', 3), ('ferraros', 3), ('indignities', 3), ('dervishes', 3), ('impressionist', 3), ('gorgeous', 3), ('mckenzie', 3), ('reprints', 3), ('yorker', 3), ('virtuoso', 3), ('apprentices', 3), ('hasty', 3), ('mckee', 3), ('muster', 3), ('handspikes', 3), ('arrests', 3), ('sobering', 3), ('streaked', 3), ('trunk', 3), ('tomatoes', 3), ('cheery', 3), ('roiling', 3), ('splash', 3), ('walnuts', 3), ('shimmering', 3), ('winced', 3), ('inviolate', 3), ('foul', 3), ('rawlins', 3), ('soak', 3), ('quebec', 3), ('suds', 3), ('hazy', 3), ('sx-21', 3), ('blur', 3), ('gleaming', 3), ('doubling', 3), ('fencing', 3), ('hurtling', 3), ('hevin', 3), ('onleh', 3), ('duffel', 3), ('sweetly', 3), ('leering', 3), ('fragrance', 3), ('roadside', 3), ('slick', 3), ('identifiable', 3), ('rammed', 3), ('bust', 3), ('sweeneys', 3), ('visibility', 3), ('sesame', 3), ('canceled', 3), ('sidewise', 3), ('snarled', 3), ('antler', 3), ('bronc', 3), ('colcord', 3), ('ablaze', 3), ('coolly', 3), ('curbing', 3), ('holstered', 3), ('retreated', 3), ('smothered', 3), ('banged', 3), ('livery', 3), ('personification', 3), ('ledge', 3), ('ax', 3), ('homesteaders', 3), ('slumped', 3), ('scoffed', 3), ('tracked', 3), ('puncher', 3), ('ducking', 3), ('rockfork', 3), ('elena', 3), ('billie', 3), ('lounged', 3), ('blinded', 3), ('gasping', 3), ('fella', 3), ('hoarsely', 3), ('lurched', 3), ('make-up', 3), ('figger', 3), ('darned', 3), ('sagging', 3), ('stink', 3), ('plumb', 3), ('dialed', 3), ('fussy', 3), ('unloaded', 3), ('barry', 3), ('groomed', 3), ('prop.', 3), ('oiled', 3), ('commanders', 3), ('showers', 3), ('futile', 3), ('frustrating', 3), ('keeper', 3), ('cabinets', 3), ('bitch', 3), ('batteries', 3), ('dismissing', 3), ('faintly', 3), ('faintest', 3), ('leigh', 3), ('bequest', 3), ('conditional', 3), ('proviso', 3), ('digestive', 3), ('benson', 3), ('collusion', 3), ('briskly', 3), ('dinnertime', 3), ('stilts', 3), ('masons', 3), ('intangibles', 3), ('combo', 3), ('psychopathic', 3), ('verification', 3), ('overnighters', 3), ('pounding', 3), ('yoke', 3), ('dronk', 3), ('brows', 3), ('stupor', 3), ('matrimony', 3), ('thirty-one', 3), ('flapping', 3), ('ruthlessness', 3), ('banked', 3), ('constriction', 3), ('homemade', 3), ('storehouse', 3), ('dismaying', 3), ('katya', 3), ('dreamy', 3), ('good-looking', 3), ('denny', 3), ('needing', 3), ('nuisance', 3), ('explicitly', 3), ('subservient', 3), ('positivism', 3), ('delegated', 3), ('codification', 3), ('jurisprudence', 3), ('hegelian', 3), ('sovereigns', 3), ('collectively', 3), ('epitomized', 3), ('presumption', 3), ('setter', 3), ('contradict', 3), ('cost-of-living', 3), ('manifestly', 3), ('abstracting', 3), ('nation-wide', 3), ('tuition', 3), ('poorest', 3), ('george-barden', 3), ('irrespective', 3), ('slots', 3), ('awaits', 3), ('grouping', 3), ('tabulated', 3), ('glottochronological', 3), ('lax', 3), ('igbo', 3), ('orthographic', 3), ('kikuyu', 3), ('prejudices', 3), ('overlap', 3), ('overlapping', 3), ('mack', 3), ('prepositional', 3), ('irregularity', 3), ('endings', 3), ('modifying', 3), ('skip', 3), ('y-cell', 3), ('semantic', 3), ('steamship', 3), ('concretistic', 3), ('unconventional', 3), ('nonverbal', 3), ('dispense', 3), ('annoying', 3), ('learns', 3), ('utilized', 3), ('sparkle', 3), ('attrition', 3), ('under-achievement', 3), ('psychologically', 3), ('deviant', 3), ('exchanges', 3), ('allowable', 3), ('tenant', 3), ('rents', 3), ('md.', 3), ('itemized', 3), ('complementary', 3), ('effecting', 3), ('endangering', 3), ('contingency', 3), ('unilateral', 3), ('precedence', 3), ('factual', 3), ('conflicting', 3), ('appointees', 3), ('bureaucratic', 3), ('repudiated', 3), ('relinquished', 3), ('haydn', 3), ('violating', 3), ('inroads', 3), ('pleas', 3), ('preferential', 3), ('acquiring', 3), ('enjoined', 3), ('allocable', 3), ('securities', 3), ('decree', 3), ('curiae', 3), ('amici', 3), ('automotive', 3), ('supplier', 3), ('allegations', 3), ('outweighed', 3), ('607', 3), ('honorably', 3), ('utensils', 3), ('rationing', 3), ('radios', 3), ('powered', 3), ('broadcasts', 3), ('contractors', 3), ('pit-run', 3), ('impractical', 3), ('bracing', 3), ('subtracting', 3), ('percentages', 3), ('authorizations', 3), ('demonstrations', 3), ('113', 3), ('jets', 3), ('squadron', 3), ('destroyers', 3), ('reprisal', 3), ('newsletter', 3), ('oakes', 3), ('dryfoos', 3), ('commence', 3), ('underway', 3), ('potentially', 3), ('paragraphs', 3), ('compliance', 3), ('comptroller', 3), ('hereinafter', 3), ('prescribe', 3), ('fined', 3), ('twenty-six', 3), ('devise', 3), ('psi', 3), ('insulated', 3), ('in.', 3), ('prototype', 3), ('discrepancies', 3), ('jacketed', 3), ('millidegree', 3), ('millidegrees', 3), ('vapor-pressure', 3), ('germanium', 3), ('spectroscopy', 3), ('hydrides', 3), ('extraterrestrial', 3), ('6000', 3), ('mined', 3), ('ores', 3), ('stabilization', 3), ('inspections', 3), ('consumptive', 3), ('large-scale', 3), ('practicable', 3), ('contemporaries', 3), ('inclusive', 3), ('heightened', 3), ('metaphor', 3), ('interpersonal', 3), ('sensibility', 3), ('unborn', 3), ('glossary', 3), ('americanegro', 3), ('koehler', 3), ('versatile', 3), ('burgeoning', 3), ('harburg', 3), ('unsigned', 3), ('dialects', 3), ('lyricist', 3), ('nocturne', 3), ('steamboat', 3), ('hospitality', 3), ('chopin', 3), ('happiest', 3), ('vivacious', 3), ('eldest', 3), ('indeterminate', 3), ('high-spirited', 3), ('edited', 3), ('jolly', 3), ('adler', 3), ('sympathies', 3), ('intuitive', 3), ('sullam', 3), ('exaggeration', 3), ('individualized', 3), ('shockingly', 3), ('undiminished', 3), ('reappeared', 3), ('astonishingly', 3), ('pedigree', 3), ('vickery', 3), ('olga', 3), ('sartoris', 3), ('censorship', 3), ('liquidated', 3), ('invaluable', 3), ('untrammeled', 3), ('aristocratic', 3), ('dixon', 3), ('synonymous', 3), ('insults', 3), ('expulsion', 3), ('suppress', 3), ('jails', 3), ('10000000', 3), ('proprietorships', 3), ('vying', 3), ('harvester', 3), ('organizers', 3), ('contributors', 3), ('marxist', 3), ('materialism', 3), ('supernaturalism', 3), ('evangelical', 3), ('worded', 3), ('farthest', 3), ('advantageous', 3), ('incoming', 3), ('royce', 3), ('exclamation', 3), ('executioner', 3), ('condemning', 3), ('clash', 3), ('dashiell', 3), ('condemns', 3), ('orchids', 3), ('nero', 3), ('alienation', 3), ('zest', 3), ('dorothy', 3), ('mentality', 3), ('egotist', 3), ('idiosyncrasies', 3), ('individualist', 3), ('embodiment', 3), ('self-reliant', 3), ('unending', 3), ('1892', 3), ('damascus', 3), ('sojourn', 3), ('galaxy', 3), ('clause', 3), ('sordid', 3), ('brim', 3), ('idealist', 3), ('englanders', 3), ('penn', 3), ('academies', 3), ('impunity', 3), ('jurist', 3), ('adversaries', 3), ('vices', 3), ('hume', 3), ('apprehensions', 3), ('oneself', 3), ('incitement', 3), ('therewith', 3), ('aiming', 3), ('sublime', 3), ('unrelated', 3), ('emphasizes', 3), ('individualistic', 3), ('imitations', 3), ('drone', 3), ('sleepily', 3), ('tulip', 3), ('claws', 3), ('flags', 3), ('spurs', 3), ('intrinsic', 3), ('vermilion', 3), ('petals', 3), ('tending', 3), ('verbenas', 3), ('half-way', 3), ('grape-arbor', 3), ('honeysuckle', 3), ('lilacs', 3), ('propel', 3), ('flurry', 3), ('phedre', 3), ('augustine', 3), ('invade', 3), ('jeopardize', 3), ('madeleine', 3), ('disarming', 3), ('humility', 3), ('sharpened', 3), ('reconcile', 3), ('commentator', 3), ('informing', 3), ('introductory', 3), ('prevalence', 3), ('transmutation', 3), ('environs', 3), ('vacancy', 3), ('stressing', 3), ('folksy', 3), ('believers', 3), ('peer', 3), ('stratum', 3), ('secretarial', 3), ('keenly', 3), ('dropouts', 3), ('professions', 3), ('crafts', 3), ('smith-hughes', 3), ('boxed', 3), ('advertisements', 3), ('anthropology', 3), ('in-group', 3), ('motivations', 3), ('forego', 3), ('interfered', 3), ('assent', 3), ('orthodoxy', 3), ('raft', 3), ('shovels', 3), ('daytime', 3), ('nominally', 3), ('delightfully', 3), ('mekong', 3), ('monsoon', 3), ('coup', 3), ('venezuela', 3), ('panama', 3), ('vietnam', 3), ('conspirators', 3), ('bets', 3), ('reputed', 3), ('bantus', 3), ('proximate', 3), ('diminishes', 3), ('cartoons', 3), ('believer', 3), ('rape', 3), ('detonated', 3), ('hollering', 3), ('reinforcements', 3), ('bucking', 3), ('shamrock', 3), ('battalion', 3), ('reassemble', 3), ('wielded', 3), ('old-time', 3), ('villa', 3), ('apaches', 3), ('cheyennes', 3), ('deeds', 3), ('dynamite', 3), ('unsolved', 3), ('epicenter', 3), ('forwarded', 3), ('fearing', 3), ('quake', 3), ('drowning', 3), ('travels', 3), ('inland', 3), ('damaging', 3), ('devastated', 3), ('stead', 3), ('1000000', 3), ('booze', 3), ('snubbed', 3), ('cocky', 3), ('feast', 3), ('henceforth', 3), ('loyalties', 3), ('sorely', 3), ('pervasive', 3), ('administering', 3), ('hostility', 3), ('florist', 3), ('booty', 3), ('strolled', 3), ('insignificant', 3), ('secessionist', 3), ('sis', 3), ('kitten', 3), ('1863', 3), ('vicksburg', 3), ('scarcity', 3), ('ink', 3), ('diarrhoea', 3), ('armies', 3), ('tease', 3), ('figurative', 3), ('expelled', 3), ('clustered', 3), ('1825', 3), ('shortages', 3), ('bushels', 3), ('settlements', 3), ('dickson', 3), ('bailly', 3), ('intrusion', 3), ('transported', 3), ('sod', 3), ('harrison', 3), ('sever', 3), ('inboard', 3), ('boatswain', 3), ('capes', 3), ('dissension', 3), ('passageway', 3), ('turbulent', 3), ('mid-june', 3), ('desolation', 3), ('forties', 3), ('mutiny', 3), ('overfall', 3), ('unexplored', 3), ('recruited', 3), ('amsterdam', 3), ('muscovy', 3), ('enigma', 3), ('1611', 3), ('thames', 3), ('1610', 3), ('endorsed', 3), ('lambeth', 3), ('succumbed', 3), ('conjugal', 3), ('self-evident', 3), ('non-catholics', 3), ('orthopedic', 3), ('ultimatum', 3), ('outrage', 3), ('holland', 3), ('dishonest', 3), ('splitting', 3), ('exposing', 3), ('collaborators', 3), ('germ', 3), ('anti-semites', 3), ('exhausting', 3), ('corpses', 3), ('horrors', 3), ('dulled', 3), ('rig', 3), ('attachments', 3), ('year-round', 3), ('profitably', 3), ('setbacks', 3), ('conquered', 3), ('researcher', 3), ('rearing', 3), ('motto', 3), ('well-educated', 3), ('pta', 3), ('counselors', 3), ('vacationing', 3), ('bedding', 3), ('coolers', 3), ('camper', 3), ('campground', 3), ('horizons', 3), ('benefited', 3), ('hempstead', 3), ('weeklies', 3), ('contributory', 3), ('craftsmen', 3), ('insured', 3), ('disability', 3), ('on-the-job', 3), ('periodically', 3), ('do-it-yourself', 3), ('posters', 3), ('shutdown', 3), ('sandwiches', 3), ('entitles', 3), ('burdened', 3), ('redoubled', 3), ('packaging', 3), ('mergers', 3), ('throws', 3), ('sophistication', 3), ('fence-line', 3), ('stimulates', 3), ('calving', 3), ('acetonemia', 3), ('75000', 3), ('phenothiazine', 3), ('foamy', 3), ('hides', 3), ('diethylstilbestrol', 3), ('premix', 3), ('dynafac', 3), ('severity', 3), ('abscesses', 3), ('rations', 3), ('additives', 3), ('trough', 3), ('esteem', 3), ('1812', 3), ('manthey', 3), ('prof.', 3), ('periodicals', 3), ('1820', 3), ('francs', 3), ('1801', 3), ('physicist', 3), ('netherlands', 3), ('utterance', 3), ('apothecary', 3), ('cross-section', 3), ('submerged', 3), ('resonant', 3), ('refinement', 3), ('dimensioning', 3), ('hitherto', 3), ('mouthpiece', 3), ('affectionately', 3), ('advancing', 3), ('filters', 3), ('perfected', 3), ('vibration', 3), ('interrelation', 3), ('cleansing', 3), ('watercolors', 3), ('thriving', 3), ('batavia', 3), ('seals', 3), ('hunters', 3), ('imparted', 3), ('tang', 3), ('kinship', 3), ('wove', 3), ('recapture', 3), ('incisive', 3), ('disparate', 3), ('igor', 3), ('idioms', 3), ('cinema', 3), ('tenderness', 3), ('lucid', 3), ('melodious', 3), ('vineyards', 3), ('subjugation', 3), ('submission', 3), ('challenged', 3), ('salons', 3), ('suites', 3), ('personifies', 3), ('carping', 3), ('doll', 3), ('wilt', 3), ('sadism', 3), ('slash', 3), (\"peter's\", 3), ('paws', 3), ('grimace', 3), ('pails', 3), ('pavement', 3), ('tooling', 3), ('pebbles', 3), ('whosoever', 3), ('comprehend', 3), ('divinities', 3), ('afghan', 3), ('inflict', 3), ('gravest', 3), ('defines', 3), ('expressionism', 3), ('felicity', 3), ('slob', 3), ('littered', 3), ('reminiscent', 3), ('cedric', 3), ('staging', 3), ('off-broadway', 3), ('musicals', 3), ('weighted', 3), ('eccentricity', 3), ('flaw', 3), ('erudite', 3), ('1916', 3), ('assaults', 3), ('lash', 3), ('plastered', 3), ('apollo', 3), ('whereupon', 3), ('occupant', 3), ('pip', 3), ('manhood', 3), ('illegitimate', 3), ('diverted', 3), ('loathsome', 3), ('snatch', 3), ('worm', 3), ('sweaters', 3), ('sagged', 3), ('cordial', 3), ('admirably', 3), ('obsessed', 3), ('attracts', 3), ('frog', 3), ('cabbage', 3), ('caesar', 3), ('darkened', 3), ('veritable', 3), ('quarter-century', 3), ('non-fiction', 3), ('alleviate', 3), ('peacocks', 3), ('twofold', 3), ('berth', 3), ('launching', 3), ('comprises', 3), ('saleslady', 3), ('gourmet', 3), ('typed', 3), ('brevity', 3), ('digest', 3), ('handbag', 3), ('habitat', 3), ('standby', 3), ('breach', 3), ('retracted', 3), ('misunderstood', 3), ('misses', 3), ('concetta', 3), ('jowls', 3), ('clouded', 3), ('belied', 3), ('railing', 3), ('bowing', 3), ('pact', 3), ('backyards', 3), ('intimacy', 3), ('slant', 3), ('facade', 3), ('squatted', 3), ('dregs', 3), ('flown', 3), ('sprouted', 3), ('caressed', 3), ('wiggled', 3), ('amber', 3), ('sour', 3), ('orchard', 3), ('absent-mindedly', 3), ('meanness', 3), ('regained', 3), ('carwood', 3), ('pronouns', 3), ('inflected', 3), ('natives', 3), ('torture', 3), ('greenland', 3), ('philippine', 3), ('pornsen', 3), ('sandalphon', 3), ('memorize', 3), ('absent-minded', 3), ('quicker', 3), ('muslim', 3), ('jealousy', 3), ('monitor', 3), ('ranking', 3), ('tibetan', 3), ('hindered', 3), ('homesick', 3), ('martians', 3), ('archangel', 3), ('dully', 3), ('growled', 3), ('lullaby', 3), ('thud', 3), ('fervent', 3), ('clear-cut', 3), ('stalled', 3), ('checklist', 3), ('rigged', 3), ('efficiently', 3), ('shirl', 3), ('troupe', 3), ('procured', 3), ('dorado', 3), ('casino', 3), ('dignified', 3), ('procession', 3), ('omission', 3), ('broth', 3), ('grubb', 3), ('chortled', 3), ('pompous', 3), ('intoned', 3), ('blithely', 3), ('dryly', 3), ('subsided', 3), ('esquire', 3), ('freak', 3), ('dwarf', 3), ('ruddy', 3), ('noisy', 3), ('sobered', 3), ('staccato', 3), ('scraped', 3), ('doormen', 3), ('hectic', 3), ('materialize', 3), ('rattle', 3), ('spilling', 3), ('swarming', 3), ('tantalizing', 3), ('stitches', 3), ('mayflower', 3), ('relented', 3), (\"year's\", 3), ('overcoming', 3), ('lust', 3), ('kissing', 3), ('adventurous', 3), ('unbearable', 3), ('tossing', 3), ('dispatching', 3), ('grandparents', 3), ('catalogued', 3), ('reread', 3), ('cruelly', 3), ('mania', 3), ('wrapping', 3), ('lavender', 3), ('gardening', 3), ('planting', 3), ('movers', 3), ('jerky', 3), ('noisily', 3), ('fuss', 3), ('ebullient', 3), ('savoring', 3), ('mourning', 3), ('assailed', 3), ('unwarranted', 3), ('scraping', 3), ('attentive', 3), ('audible', 3), ('cradled', 3), ('geese', 3), ('rue', 3), ('particulars', 3), ('anticipations', 3), ('retorted', 3), ('blushing', 3), ('homemakers', 3), ('fondly', 3), ('twirler', 3), ('thirsty', 3), ('powdery', 3), ('quietness', 3), ('coop', 3), ('rugs', 3), ('lamb', 3), ('suspend', 3), ('registering', 3), ('accelerator', 3), ('toot', 3), ('sunk', 3), ('sloppy', 3), ('eyebrows', 3), ('repetitious', 3), ('ransacked', 3), ('jutting', 3), ('geneticist', 3), ('playful', 3), ('lecturing', 3), ('sworn', 3), ('knack', 3), ('busted', 3), ('sticking', 3), ('growl', 3), ('chests', 3), ('chopped', 3), ('banister', 3), ('cough', 3), ('ducked', 3), ('sonofabitch', 3), ('bully', 3), ('whistling', 3), ('grandiose', 3), ('recede', 3), ('crashing', 3), ('brackish', 3), ('roaming', 3), ('packard', 3), ('raphael', 3), ('myra', 3), ('regards', 3), ('amuse', 3), ('eastward', 3), ('safer', 3), ('exasperation', 3), ('graces', 3), ('fading', 3), ('chops', 3), ('pork', 3), ('blevins', 3), ('ethel', 3), ('dimes', 3), ('hepatitis', 3), ('self-esteem', 3), ('dickens', 3), ('slaughtered', 3), ('sickened', 3), ('bleakly', 3), ('pounded', 3), ('aloof', 3), ('bewildered', 3), ('strut', 3), ('tattered', 3), ('bows', 3), ('snorted', 3), ('hillman', 3), ('languid', 3), ('brandishing', 3), ('stooping', 3), ('bombproof', 3), ('tensely', 3), ('riverbank', 3), ('fetch', 3), ('discontent', 3), ('resentful', 3), ('pervading', 3), ('fanny', 3), ('loveliness', 3), ('aflame', 3), ('withdrawing', 3), ('ariadne', 3), ('tragedies', 3), ('bellowed', 3), ('grate', 3), ('haunt', 3), ('deference', 3), ('inexperience', 3), ('tame', 3), ('goose', 3), ('chattering', 3), ('nightingale', 3), ('drury', 3), ('rebuff', 3), ('first-class', 3), ('expanse', 3), ('inquire', 3), ('telephones', 3), ('liberally', 3), ('nets', 3), ('infrequent', 3), ('joyous', 3), ('rooted', 3), ('barges', 3), ('portwatchers', 3), ('bubbling', 3), ('reddish', 3), ('disconnected', 3), ('procurer', 3), ('racket', 3), ('sock', 3), ('bowman', 3), ('mustache', 3), ('eyebrow', 3), ('smelt', 3), ('derby', 3), ('goddam', 3), ('mopped', 3), ('androfski', 3), ('auxiliaries', 3), ('depravity', 3), ('heydrich', 3), ('ss', 3), ('1939', 3), ('rendezvous', 3), ('ulanys', 3), ('abuses', 3), ('unspeakable', 3), ('ideologies', 3), ('brandel', 3), ('uplands', 3), ('fund-raising', 3), ('exalted', 3), ('well-fed', 3), ('combed', 3), ('lather', 3), ('lusty', 3), ('bankrupt', 3), ('mattered', 3), ('ached', 3), ('protruded', 3), ('estates', 3), ('bravely', 3), ('thickly', 3), ('rooster', 3), ('nostrils', 3), ('feathered', 3), ('apocalyptic', 3), ('saddlebags', 3), ('merging', 3), ('jelly', 3), ('cortlandt', 3), ('mynheer', 3), ('niece', 3), ('fearfully', 3), ('recruiting', 3), ('sly', 3), ('sired', 3), ('schoolroom', 3), ('ruler', 3), ('fathom', 3), ('harpers', 3), ('schoolhouse', 3), ('uneasily', 3), ('packs', 3), ('averting', 3), ('dictum', 3), ('stubbornly', 3), ('rebelliously', 3), ('scant', 3), ('strangled', 3), ('afflicted', 3), ('courtyard', 3), ('enlarging', 3), ('discern', 3), ('galli', 3), ('wrap', 3), ('infinitely', 3), ('workmen', 3), ('skullcap', 3), ('folds', 3), ('veils', 3), ('nuns', 3), ('stalls', 3), ('probed', 3), ('securely', 3), ('nicodemus', 3), ('unhesitatingly', 3), ('trunks', 3), ('booths', 3), ('foyer', 3), ('mantel', 3), ('pillows', 3), ('redoute', 3), ('sofas', 3), ('gray-haired', 3), ('alix', 3), ('mme', 3), ('lathered', 3), ('plodding', 3), ('cropped', 3), ('immaculate', 3), ('penalized', 3), ('shuffling', 3), ('alabaster', 3), ('imported', 3), ('litter', 3), ('caravan', 3), ('celebrities', 3), ('kidnapper', 3), ('kidnaped', 3), ('technician', 3), ('iowa', 3), ('vowels', 3), ('barren', 3), ('contrived', 3), ('drier', 3), ('herbs', 3), ('prop', 3), ('short-lived', 3), ('reborn', 3), (\"y'all\", 3), ('purposeful', 3), (\"po'k\", 3), ('huh', 3), ('fearless', 3), ('undershirt', 3), ('huddling', 3), ('trapped', 3), ('guttural', 3), ('huddle', 3), ('gallantry', 3), ('humbly', 3), ('poncho', 3), ('oath', 3), ('mask', 3), ('chimneys', 3), ('diminutive', 3), ('bavaria', 3), ('rearrange', 3), ('improvised', 3), ('bevy', 3), ('outskirts', 3), ('inconsequential', 3), ('caroli', 3), ('compromising', 3), ('nicholas', 3), ('blinking', 3), ('splashed', 3), ('niche', 3), ('canons', 3), ('lewd', 3), ('jeopardy', 3), ('disagreed', 3), ('deep-set', 3), ('sunken', 3), ('baggage', 3), ('brow', 3), ('outdistanced', 3), ('plucked', 3), ('implacable', 3), ('torment', 3), ('bayonets', 3), ('retreating', 3), ('grinning', 3), ('bolster', 3), ('punctured', 3), ('perched', 3), ('solomon', 3), ('itch', 3), ('slovenly', 3), ('abbe', 3), ('aristocracy', 3), ('stables', 3), ('authorship', 3), ('betray', 3), ('paradoxical', 3), ('enchanted', 3), ('forbid', 3), ('predicament', 3), ('bandit', 3), (\"christ's\", 3), ('infuriated', 3), ('chatter', 3), ('loathed', 3), ('isle', 3), ('hafta', 3), ('unleashed', 3), ('patting', 3), ('whirl', 3), ('thinkin', 3), ('brandon', 3), ('shit', 3), ('niggers', 3), ('yearned', 3), ('newfoundland', 3), ('gulped', 3), ('marbles', 3), ('shone', 3), ('downpour', 3), ('clenched', 3), ('hateful', 3), ('illumined', 3), ('lurked', 3), ('whistled', 3), ('neversink', 3), ('steeples', 3), ('reformed', 3), ('ivy', 3), ('sash', 3), ('yanked', 3), ('po', 3), ('knuckles', 3), ('trample', 3), ('uttered', 3), ('balustrade', 3), ('clara', 3), ('hopping', 3), ('wits', 3), ('keene', 3), ('overreach', 3), ('spurred', 3), ('carpeted', 3), ('idiotic', 3), ('gleamed', 3), ('wasting', 3), ('pretence', 3), ('tenements', 3), ('nestled', 3), ('malaria', 3), ('rebuilt', 3), ('soared', 3), ('perpetual', 3), ('spotless', 3), ('macon', 3), ('handkerchief', 3), ('beset', 3), ('carlson', 3), ('sojourner', 3), ('chandelier', 3), ('walsh', 3), ('dainty', 3), ('dalloway', 3), ('medals', 3), ('crucifix', 3), ('quarreling', 3), ('outpost', 3), ('snaked', 3), ('week-end', 3), ('sends', 3), ('jeff', 3), ('clippings', 3), ('low-down', 3), ('mingled', 3), ('seekers', 3), ('ache', 3), ('imprisoned', 3), ('blasts', 3), ('warped', 3), ('footstep', 3), ('whir', 3), ('grenade', 3), ('tripod', 3), ('intermittent', 3), ('hoops', 3), ('booby', 3), ('ponderous', 3), ('immobility', 3), ('solidity', 3), ('scarf', 3), ('throbbing', 3), ('phoned', 3), ('self-consciousness', 3), ('darkening', 3), ('unnecessarily', 3), ('leash', 3), ('throbbed', 3), ('spoon', 3), ('tiled', 3), ('spoiled', 3), ('fluttering', 3), ('thicker', 3), ('focusing', 3), ('puffed', 3), ('160', 3), ('ciliated', 3), ('floc', 3), ('volatile', 3), ('skimming', 3), ('2.6', 3), ('sewers', 3), ('overload', 3), ('erosion', 3), ('gal', 3), ('nitrate', 3), ('obnoxious', 3), ('septic', 3), ('fayette', 3), ('mortgages', 3), ('morgenthau', 3), ('reed', 3), ('ya', 3), ('geographically', 3), ('controllers', 3), ('shiny', 3), ('painless', 3), ('boeing', 3), ('prophets', 3), ('occupies', 3), ('interchange', 3), ('abstracted', 3), ('literalness', 3), ('capitals', 3), ('imbedded', 3), ('establishes', 3), ('bas-relief', 3), ('facet-planes', 3), ('broaden', 3), ('oilcloth', 3), ('wallpaper', 3), ('flattening', 3), ('typography', 3), ('1911', 3), ('speedily', 3), ('reverence', 3), ('occasioned', 3), ('preamble', 3), ('upholding', 3), ('applauded', 3), ('peaceable', 3), ('vaughan', 3), ('woodbury', 3), ('augustus', 3), ('uncompromising', 3), ('barstow', 3), ('bravery', 3), ('radicalism', 3), ('savored', 3), ('inappropriate', 3), ('oppression', 3), ('philanthropic', 3), ('nominated', 3), ('sic', 3), ('foss', 3), ('cowardly', 3), ('indecent', 3), ('abolitionists', 3), ('dorr', 3), ('manual', 3), ('shreds', 3), ('obligated', 3), ('adjectives', 3), ('impetus', 3), ('humanism', 3), ('bawdy', 3), ('canon', 3), ('insolence', 3), ('salutary', 3), ('vail', 3), ('ascertain', 3), ('installing', 3), ('seventy', 3), ('1932', 3), ('blackmer', 3), ('thirty-four', 3), ('winged', 3), ('250000', 3), ('vogue', 3), ('1888', 3), ('peru', 3), ('dime', 3), ('payable', 3), ('lag', 3), ('seminary', 3), ('headmaster', 3), ('bonnet', 3), ('unwise', 3), ('desiring', 3), ('belongings', 3), ('horsemen', 3), ('raton', 3), ('slugs', 3), ('whereabouts', 3), ('vacant', 3), ('depredations', 3), ('inconvenience', 3), ('arresting', 3), ('cowboys', 3), ('laramie', 3), ('pedro', 3), ('plows', 3), ('impudent', 3), ('wiser', 3), ('macpherson', 3), ('comrade', 3), ('arroyo', 3), ('trapper', 3), ('salyer', 3), ('renting', 3), ('whirled', 3), ('martinez', 3), ('writ', 3), ('bowls', 3), ('singly', 3), ('floral', 3), ('well-defined', 3), ('embodied', 3), ('freehand', 3), ('rebuilding', 3), ('athens', 3), ('unmistakably', 3), ('slanting', 3), ('consolidation', 3), ('interplay', 3), ('sharper', 3), ('protogeometric', 3), ('deduce', 3), ('mammoth', 3), ('disturb', 3), ('upheaval', 3), ('users', 3), ('molded', 3), ('undeniable', 3), ('jumbled', 3), ('blots', 3), ('unaffected', 3), ('psychically', 3), ('unfitting', 3), ('vanishing', 3), ('fatigued', 3), ('precede', 3), ('distort', 3), ('frivolous', 3), ('asserting', 3), ('brutal', 3), ('positivists', 3), ('hurrah', 3), ('electors', 3), ('naturalized', 3), ('bulletins', 3), ('voter', 3), ('displeasure', 3), ('monarch', 3), ('impartial', 3), ('campaigned', 3), ('u.m.c.i.a.', 3), ('bickering', 3), ('confidential', 3), ('dictated', 3), ('tortuous', 3), ('intervened', 3), ('p.d.i.', 3), ('moroccan', 3), ('pessimistic', 3), ('feasibility', 3), ('long-run', 3), ('uncertainties', 3), ('rewards', 3), ('admonitions', 3), ('beacon', 3), ('functioned', 3), ('cultivation', 3), ('reliance', 3), ('conserving', 3), ('stabilizing', 3), ('unifying', 3), ('ethos', 3), ('bind', 3), ('rites', 3), ('attaching', 3), ('fosters', 3), ('unifies', 3), ('transcendental', 3), ('religiously', 3), ('primacy', 3), ('pragmatic', 3), ('subordinate', 3), ('undertakes', 3), ('compensated', 3), ('consolation', 3), ('expansiveness', 3), ('conserve', 3), ('abyss', 3), ('viewpoints', 3), ('generate', 3), ('reassured', 3), ('creatively', 3), ('flows', 3), ('supplemented', 3), ('philippines', 3), ('illusions', 3), ('bureaucracies', 3), ('symbolically', 3), ('inhibitions', 3), ('impeded', 3), ('iraq', 3), ('sub-interval', 3), ('lemma', 3), ('monotone', 3), ('denote', 3), ('clockwise', 3), ('constituting', 3), ('labels', 3), ('fridays', 3), ('narrowly', 3), ('illustrative', 3), ('aces', 3), ('wavy', 3), ('litters', 3), ('repetitions', 3), ('satisfies', 3), ('constants', 3), ('differentiable', 3), ('notation', 3), ('|a', 3), ('monic', 3), ('vectors', 3), ('disturbances', 3), ('shocks', 3), ('reflex', 3), ('alerting', 3), ('tuning', 3), ('depressions', 3), ('tranquilizers', 3), ('eeg', 3), ('restoring', 3), ('ascending', 3), ('arousal', 3), ('nonspecifically', 3), ('walled', 3), ('autofluorescence', 3), ('globulin', 3), ('fitc', 3), ('diluting', 3), ('yellow-green', 3), ('yellow-dwarf', 3), ('extract', 3), ('coons', 3), ('proliferation', 3), ('fiber', 3), ('biceps', 3), ('tubular', 3), ('granular', 3), ('kidneys', 3), ('hemorrhage', 3), ('rods', 3), ('jejunum', 3), ('blackened', 3), ('atrophic', 3), ('bile', 3), ('discrete', 3), ('mottled', 3), ('spleen', 3), ('apex', 3), ('aorta', 3), ('intima', 3), ('necrosis', 3), ('fibrous', 3), ('ventricle', 3), ('tracts', 3), ('vertebral', 3), ('intensify', 3), ('serial', 3), ('unaided', 3), ('curbs', 3), ('pelvic', 3), ('myocardial', 3), ('prednisone', 3), ('disabling', 3), ('13.5', 3), ('usp', 3), ('critically', 3), ('chemically', 3), ('accentuated', 3), ('rationally', 3), ('ingested', 3), ('clements', 3), ('owing', 3), ('goitre', 3), ('thiouracil', 3), ('secretion', 3), ('iodinating', 3), ('vivo', 3), ('tyrosine', 3), ('vitro', 3), ('mono-iodotyrosine', 3), ('pubescent', 3), ('menarche', 3), ('markedly', 3), ('alignment', 3), ('utilizes', 3), ('confirms', 3), ('connective', 3), ('grouped', 3), ('inferred', 3), ('rats', 3), ('antagonist', 3), ('verloop', 3), ('nakamura', 3), ('extracting', 3), ('diffusing', 3), ('mammalian', 3), ('reaffirmed', 3), ('nonexistent', 3), ('dynamics', 3), ('pathways', 3), ('one-fifth', 3), ('one-fourth', 3), ('derivation', 3), ('vasa', 3), ('mammals', 3), ('vascular', 3), ('localities', 3), ('subspecies', 3), ('ounces', 3), ('twenty-eight', 3), ('prodigious', 3), ('hoop', 3), ('explorers', 3), ('unscrupulous', 3), ('skins', 3), ('rattlesnake', 3), ('maturing', 3), ('scanty', 3), ('captive', 3), ('reticulate', 3), ('transports', 3), ('sacramento', 3), ('hosts', 3), ('villain', 3), ('fertilized', 3), ('broods', 3), ('cocoon', 3), ('hatch', 3), ('pots', 3), ('loaf', 3), ('fills', 3), ('bumblebee', 3), ('nectar', 3), ('warts', 3), ('scrutinizing', 3), ('buzzing', 3), ('ultracentrifuge', 3), ('unstained', 3), ('chromatographic', 3), ('concave', 3), ('mesh', 3), ('230', 3), ('tris', 3), ('clot', 3), ('thawed', 3), ('resuspended', 3), ('donor', 3), ('256', 3), ('deae', 3), ('fractionated', 3), ('electrophoresis', 3), ('processed', 3), ('imposes', 3), ('typhus', 3), ('overriding', 3), ('biochemical', 3), ('militarily', 3), ('viability', 3), ('portal', 3), ('nozzles', 3), ('spores', 3), ('pathogenic', 3), ('downwind', 3), ('optimal', 3), ('bronchi', 3), ('aerosolized', 3), ('nasal', 3), ('aerosols', 3), ('toxic', 3), ('accretion', 3), ('satellite', 3), ('scales', 3), ('extrapolation', 3), ('orbiting', 3), ('calibrated', 3), ('day-to-day', 3), ('diurnal', 3), ('vanguard', 3), ('explorer', 3), ('statistically', 3), ('probes', 3), ('zodiacal', 3), ('unreliable', 3), ('impacts', 3), ('interplanetary', 3), ('ecliptic', 3), ('protons', 3), ('wyatt', 3), ('erratic', 3), ('mixtures', 3), ('fillings', 3), ('i.d.', 3), ('reactants', 3), ('chips', 3), ('radiochlorine', 3), ('purification', 3), ('distillation', 3), ('yields', 3), ('constituent', 3), ('repelled', 3), ('detergency', 3), ('oleophilic', 3), ('polymerization', 3), ('moderately', 3), ('greases', 3), ('intensified', 3), ('particulate', 3), ('up-to-date', 3), ('interrelations', 3), ('compositions', 3), ('swatches', 3), ('oversimplified', 3), ('incorporation', 3), ('detergents', 3), ('adsorbed', 3), ('spin', 3), ('commensurate', 3), ('sec', 3), ('1.8', 3), ('contaminated', 3), ('impurity', 3), ('325', 3), ('piezoelectric', 3), ('interactions', 3), ('bonded', 3), ('shorten', 3), ('oxygens', 3), ('cr', 3), ('isotropic', 3), ('proton', 3), ('ab', 3), ('interfacial', 3), ('conforms', 3), ('curvature', 3), ('radii', 3), ('breakup', 3), ('droplets', 3), ('calculate', 3), ('deformation', 3), ('birefringence', 3), ('equating', 3), ('cross-sectional', 3), ('chemists', 3), ('osmotic', 3), ('plastics', 3), ('molten', 3), ('paints', 3), ('parameter', 3), ('elasticity', 3), ('exploratory', 3), ('cps', 3), ('clearance', 3), ('dotted', 3), ('rim', 3), ('starter', 3), ('terminals', 3), ('resistor', 3), ('originating', 3), ('thermocouples', 3), ('pyrometer', 3), ('thermocouple', 3), ('schematic', 3), ('comparisons', 3), ('geometry', 3), ('transpiration', 3), ('input', 3), ('electrode', 3), ('lobe', 3), ('0.85', 3), ('10.3', 3), ('latitude', 3), ('surround', 3), ('antennae', 3), ('4.3', 3), ('neglecting', 3), ('centimeter', 3), ('hypothetical', 3), ('interferometer', 3), ('polarized', 3), ('wave-length', 3), ('mccullough', 3), ('chap.', 3), ('minnett', 3), ('piddington', 3), ('reflectors', 3), ('diameters', 3), ('saturn', 3), ('unobtainable', 3), ('probe', 3), ('repaid', 3), ('furnishing', 3), ('coordinates', 3), ('annum', 3), ('contacted', 3), ('identifying', 3), ('utilization', 3), ('know-how', 3), ('short-run', 3), ('negation', 3), ('dei', 3), ('proverb', 3), ('allegory', 3), ('strivings', 3), ('howls', 3), ('sinfulness', 3), ('praisegod', 3), ('unawareness', 3), ('1901', 3), ('parody', 3), ('perversely', 3), ('disasters', 3), ('leverku^hn', 3), ('characteristically', 3), ('revert', 3), ('cleverness', 3), ('mindless', 3), ('emblematic', 3), ('frightful', 3), ('humiliation', 3), ('epiphany', 3), ('prophecy', 3), ('wretched', 3), ('la^utner', 3), ('voluptuous', 3), ('savagely', 3), ('generates', 3), ('aggravated', 3), ('x-rays', 3), ('persist', 3), ('domains', 3), ('heredity', 3), ('cosmos', 3), ('cheat', 3), ('induces', 3), ('uneasiness', 3), ('drunks', 3), ('meteor', 3), ('celestial', 3), ('postulated', 3), ('harbors', 3), ('quell', 3), ('inventions', 3), ('gravity', 3), ('adapt', 3), ('antipathy', 3), ('socialistic', 3), ('inferences', 3), ('1898', 3), ('grievances', 3), ('anglo-saxon', 3), ('meddling', 3), ('tory', 3), ('ante-bellum', 3), ('gatherings', 3), ('segregationist', 3), ('friendships', 3), ('understatement', 3), ('unsympathetic', 3), ('favoring', 3), ('patron', 3), ('outsider', 3), ('phonograph', 3), ('downgraded', 3), ('actresses', 3), ('enthralling', 3), ('catering', 3), ('interrupt', 3), ('escapes', 3), ('reel', 3), ('cinematic', 3), ('instrumentalists', 3), ('unbreakable', 3), ('artistically', 3), ('motion-picture', 3), ('nineties', 3), ('bias', 3), ('labeling', 3), ('classifications', 3), ('romanticism', 3), ('confuse', 3), ('sown', 3), ('scholarly', 3), ('industrialization', 3), ('abe', 3), ('bogus', 3), ('patriotism', 3), ('rebelling', 3), ('abraham', 3), ('oversimplification', 3), ('warlike', 3), ('lags', 3), ('currency', 3), ('cohesive', 3), ('searches', 3), ('underprivileged', 3), ('scrape', 3), ('diabetes', 3), ('185', 3), ('starvation', 3), ('compresses', 3), ('twirling', 3), ('insulin', 3), ('extracts', 3), ('loot', 3), ('policing', 3), ('rheumatism', 3), ('arthritis', 3), ('bbb', 3), ('yesteryear', 3), ('masseur', 3), ('huckster', 3), ('metals', 3), ('amply', 3), ('capsules', 3), ('cysts', 3), ('shrieked', 3), ('ozone', 3), ('diagnose', 3), ('saratoga', 3), ('prevalent', 3), ('forgetfulness', 3), ('misty', 3), ('uninterrupted', 3), ('incorrect', 3), ('progressions', 3), ('invisible', 3), ('ultra-violet', 3), ('retinal', 3), ('unexplained', 3), ('skeptics', 3), ('glibly', 3), ('confessing', 3), ('prevision', 3), ('confesses', 3), ('open-mouthed', 3), ('accompaniments', 3), ('circulated', 3), ('suffice', 3), ('hack', 3), ('undeveloped', 3), ('initials', 3), ('denies', 3), ('fashions', 3), ('bulbs', 3), ('enhance', 3), ('carpentry', 3), ('supervising', 3), ('correlated', 3), ('fixtures', 3), ('institutional', 3), ('educators', 3), ('layout', 3), ('esthetic', 3), ('certification', 3), ('tighten', 3), ('slipper', 3), ('pushes', 3), ('bulging', 3), ('wedded', 3), ('rigorous', 3), ('competitor', 3), ('europeans', 3), ('elevation', 3), ('topography', 3), ('rectangle', 3), ('logging', 3), ('unrestricted', 3), ('shrubs', 3), ('overlooks', 3), ('formations', 3), ('overall', 3), ('potentials', 3), ('assessor', 3), ('geological', 3), ('tolerable', 3), ('doctored', 3), ('vanish', 3), ('orchestration', 3), ('invites', 3), ('manages', 3), ('spirito', 3), ('faithfully', 3), ('noises', 3), ('informally', 3), ('environments', 3), ('weaknesses', 3), ('innovations', 3), ('toscanini', 3), ('indistinguishable', 3), ('purported', 3), ('accorded', 3), ('pianists', 3), ('dated', 3), ('compliments', 3), ('delicious', 3), ('keyboard', 3), ('innate', 3), ('clifford', 3), ('arte', 3), ('divergent', 3), ('clown', 3), ('rein', 3), ('opus', 3), ('would-be', 3), ('quintet', 3), ('diets', 3), ('grocer', 3), ('softening', 3), ('lapses', 3), ('bartlett', 3), ('pear', 3), ('assets', 3), ('healthful', 3), ('tug', 3), ('dampened', 3), ('midsummer', 3), ('heaving', 3), ('fertilizer', 3), ('gluttons', 3), ('encourages', 3), ('scoop', 3), ('thrifty', 3), ('protects', 3), ('adequacy', 3), ('gardener', 3), ('velvety', 3), ('uppermost', 3), ('unforgettable', 3), ('chisel', 3), ('workouts', 3), ('terrific', 3), ('flare', 3), ('dumbbell', 3), ('elbows', 3), ('super-sets', 3), ('frontal', 3), ('lats', 3), ('rib', 3), ('skiing', 3), ('astounding', 3), ('histories', 3), ('discouraging', 3), ('courcy', 3), ('lookit', 3), ('sting', 3), ('symbolizes', 3), ('prepares', 3), ('disobeyed', 3), ('forfeit', 3), ('parallelism', 3), ('imperfect', 3), ('portrays', 3), ('origen', 3), ('concurrence', 3), ('universality', 3), ('periodical', 3), ('converts', 3), ('vatican', 3), ('canterbury', 3), ('respectful', 3), ('laity', 3), ('proclaims', 3), ('nationalistic', 3), ('doctrinal', 3), ('decreasing', 3), ('demolished', 3), ('redundant', 3), ('professedly', 3), ('bonfire', 3), ('1864', 3), ('christendom', 3), ('tenable', 3), ('mutually', 3), ('buri', 3), ('self-consciously', 3), ('maturation', 3), ('unambiguous', 3), ('follower', 3), ('depriving', 3), ('accomplishing', 3), ('greeks', 3), ('corinthians', 3), ('churchmen', 3), ('cultured', 3), ('fundamentalist', 3), ('encounters', 3), ('rapidity', 3), ('secularized', 3), ('existential', 3), ('kerygma', 3), ('klan', 3), ('klux', 3), ('ku', 3), ('lieutenants', 3), ('discredited', 3), ('filthy', 3), ('disintegration', 3), ('virulence', 3), ('sinner', 3), ('ominously', 3), ('foibles', 3), ('pleasures', 3), ('witches', 3), ('puritan', 3), ('witch', 3), ('powerless', 3), ('inquiring', 3), ('blessing', 3), ('axiomatic', 3), ('nightclub', 3), ('plunge', 3), ('hasten', 3), ('distraction', 3), ('touring', 3), ('rallies', 3), ('multi', 3), ('choreographic', 3), ('splendidly', 3), ('floyd', 3), ('shirley', 3), ('chieftain', 3), ('rudy', 3), ('lance', 3), ('suitably', 3), ('brazilian', 3), ('conservatory', 3), ('voluminous', 3), ('whispering', 3), ('choreography', 3), ('christopher', 3), (\"where's\", 3), ('spouse', 3), ('belligerent', 3), ('proficient', 3), ('irritations', 3), ('cliches', 3), ('creighton', 3), ('dizzy', 3), ('fledgling', 3), ('specialty', 3), ('cartoonist', 3), ('matunuck', 3), ('recounting', 3), ('arenas', 3), ('bellini', 3), ('tucker', 3), ('fullness', 3), ('topped', 3), ('trill', 3), ('questionable', 3), ('musicianship', 3), ('waxed', 3), ('disconcerting', 3), ('showcase', 3), ('blotted', 3), ('hampton', 3), ('photographed', 3), ('concludes', 3), ('firmness', 3), ('subtleties', 3), ('roughness', 3), ('excellently', 3), ('abetted', 3), ('tempo', 3), ('cynics', 3), ('soberly', 3), ('cherkasov', 3), ('exposition', 3), ('spain', 3), ('panza', 3), ('sancho', 3), ('callers', 3), ('tangled', 3), ('havoc', 3), ('saddled', 3), ('rolls-royce', 3), ('jerebohms', 3), ('courtiers', 3), ('manor', 3), ('rustic', 3), ('shenanigans', 3), ('lurking', 3), ('hark', 3), ('farce', 3), ('evelyn', 3), ('richest', 3), ('queried', 3), ('lena', 3), ('booker', 3), ('sol', 3), ('howl', 3), ('barring', 3), ('orchestral', 3), ('sprawl', 3), ('lets', 3), ('hendl', 3), ('cadenza', 3), ('20th', 3), ('wizard', 3), ('dump', 3), ('connotations', 3), ('dogma', 3), ('sanctity', 3), ('buddhist', 3), ('tunisia', 3), ('instability', 3), ('karl', 3), ('gallant', 3), ('arrivals', 3), ('imitate', 3), ('chagrin', 3), ('strives', 3), ('compulsively', 3), ('ranges', 3), ('exacerbation', 3), ('strauss', 3), ('proving', 3), ('contestants', 3), ('predictions', 3), ('toy', 3), ('snatches', 3), ('misbehavior', 3), ('marksmanship', 3), ('feverish', 3), ('portuguese', 3), ('publishes', 3), ('narrower', 3), ('sculptor', 3), ('sandburg', 3), ('decca', 3), ('eclectic', 3), ('buyer', 3), ('sewing', 3), ('pores', 3), ('baths', 3), ('toothbrush', 3), ('weave', 3), ('crush', 3), ('straws', 3), ('pastel', 3), ('elongated', 3), ('gamut', 3), ('softness', 3), ('unlined', 3), ('bestowed', 3), ('sow', 3), ('possessive', 3), ('thrilling', 3), ('quincy', 3), ('len', 3), ('healed', 3), ('congratulated', 3), ('mankowski', 3), ('battling', 3), ('overcame', 3), ('recovering', 3), ('triumphs', 3), ('musial', 3), ('stan', 3), ('murtaugh', 3), ('flu', 3), ('broglio', 3), ('ernie', 3), ('mizell', 3), ('misled', 3), ('lengthening', 3), ('bunker', 3), ('twelfth', 3), ('confessed', 3), ('brook', 3), ('excavation', 3), ('chisholm', 3), ('heyday', 3), ('sliced', 3), ('wailed', 3), ('golfer', 3), ('yen', 3), ('endeared', 3), ('acclaimed', 3), ('charity', 3), ('frick', 3), ('majors', 3), ('franchise', 3), ('convince', 3), ('mazeroski', 3), ('citation', 3), ('reconsider', 3), ('vikings', 3), ('brocklin', 3), ('edwards', 3), ('blanchard', 3), ('berra', 3), ('humiliating', 3), ('reds', 3), ('terminated', 3), ('dissatisfaction', 3), ('purposely', 3), ('nationwide', 3), ('blackout', 3), ('blacked', 3), ('phillies', 3), ('herb', 3), ('leaguer', 3), ('rookies', 3), ('rightfully', 3), ('feats', 3), ('tongues', 3), ('hurting', 3), ('speculating', 3), ('340', 3), ('mich.', 3), ('tribe', 3), ('roller', 3), ('gaines', 3), ('rightfield', 3), ('wert', 3), ('alusik', 3), ('cooke', 3), ('rudolph', 3), ('hinton', 3), ('viewers', 3), ('husky', 3), ('unofficial', 3), ('126', 3), ('bulge', 3), ('1065', 3), ('flashy', 3), ('spikes', 3), ('broncs', 3), ('mending', 3), ('myers', 3), ('baylor', 3), ('intercepted', 3), ('nick', 3), ('gratification', 3), ('saxton', 3), ('place-kicking', 3), ('stamford', 3), ('indoor', 3), ('twenty-first', 3), ('knights', 3), ('jockey', 3), ('4500', 3), ('downed', 3), ('boarding', 3), ('nightfall', 3), ('expired', 3), ('teammates', 3), ('hitch', 3), ('steve', 3), ('helm', 3), ('houk', 3), ('n.y.', 3), ('roland', 3), ('wilhelm', 3), ('knox', 3), ('inducted', 3), ('homers', 3), ('slugged', 3), ('grapefruit', 3), ('rapped', 3), ('rundown', 3), ('lumpe', 3), ('escaping', 3), ('merited', 3), ('keegan', 3), ('offerings', 3), ('adair', 3), ('tally', 3), ('marv', 3), ('major-league', 3), ('preserving', 3), ('dependency', 3), ('denton', 3), ('principals', 3), ('okla.', 3), ('kan.', 3), ('math', 3), ('peanut', 3), ('majorities', 3), ('81', 3), ('reservoirs', 3), ('lamar', 3), ('advocacy', 3), ('betting', 3), ('ratcliff', 3), ('authorizing', 3), ('drafted', 3), ('adamant', 3), ('coolest', 3), ('delegation', 3), ('emphasizing', 3), ('reconsideration', 3), ('repealed', 3), ('issuance', 3), ('revolving', 3), ('adjournment', 3), ('rob', 3), ('1923', 3), ('interlude', 3), ('rd.', 3), ('administrators', 3), ('modernizing', 3), ('outmoded', 3), ('cabrini', 4), ('grazie', 4), ('jennie', 4), ('lay-sisters', 4), ('gertrude', 4), ('diego', 4), ('rosa', 4), ('blackwell', 4), ('dunne', 4), ('quinzaine', 4), ('laban', 4), ('faro', 4), ('bale', 4), ('purvis', 4), ('budd', 4), ('shayol', 4), ('super-condamine', 4), ('lisa', 4), ('peralta', 4), ('admassy', 4), ('guardino', 4), ('beep', 4), ('pregnancy', 4), ('auditors', 4), ('irsac', 4), ('loomis', 4), ('pencils', 4), ('registries', 4), ('fiscal-tax', 4), ('follow-up', 4), ('situs', 4), ('beatniks', 4), ('lipton', 4), ('kulturbund', 4), ('pavilion', 4), ('persia', 4), ('isfahan', 4), ('communicator', 4), ('esp', 4), ('mediums', 4), ('harrington', 4), ('consummation', 4), ('sew', 4), ('hon', 4), ('merrimack', 4), ('teaspoon', 4), ('sauerkraut', 4), ('spear', 4), ('skinless', 4), ('hamburgers', 4), ('hibachi', 4), ('pagan', 4), ('minarets', 4), ('winooski', 4), ('ethan', 4), ('peerless', 4), ('simmer', 4), ('pint', 4), ('orchards', 4), ('single-shot', 4), ('marlin', 4), ('.44', 4), ('35.3', 4), ('hickory', 4), ('hopples', 4), ('compression', 4), ('rodding', 4), ('dia.', 4), ('sq.', 4), ('widths', 4), ('trailer', 4), ('barcus', 4), ('kc', 4), ('obsolete', 4), ('runways', 4), ('paredon', 4), ('marina', 4), ('indulgence', 4), ('pah', 4), ('hwang', 4), ('manipulation', 4), ('respectability', 4), ('reconsidered', 4), ('repudiation', 4), ('afro-asian', 4), ('tao', 4), ('behold', 4), ('refuge', 4), ('stronghold', 4), ('psalm', 4), ('begotten', 4), ('reminding', 4), ('gannett', 4), ('jolliffe', 4), ('obesity', 4), ('race-drivers', 4), ('love-making', 4), ('yacht', 4), ('routes', 4), ('mansions', 4), ('pastry', 4), ('ailey', 4), ('wollman', 4), ('ado', 4), ('wesker', 4), ('emancipation', 4), ('beatie', 4), ('bonnor', 4), ('herr', 4), ('pons', 4), ('platforms', 4), ('deux', 4), ('scapin', 4), ('tartuffe', 4), ('ledoux', 4), ('jouvet', 4), ('camusfearna', 4), ('otter', 4), ('nikolais', 4), ('chabrier', 4), ('twentieth-century', 4), ('workmanship', 4), ('bam', 4), ('texts', 4), ('evenly', 4), ('enright', 4), ('donnybrook', 4), ('dexter', 4), ('santayana', 4), ('tireless', 4), ('lewisohn', 4), ('godkin', 4), ('practitioners', 4), ('tapes', 4), ('chooses', 4), ('sexuality', 4), ('arabic', 4), ('egyptian', 4), ('unsinkable', 4), ('fission', 4), ('corruptible', 4), ('hiroshima', 4), ('converse', 4), ('swamp', 4), ('antoine', 4), ('omitting', 4), ('cutters', 4), ('miranda', 4), ('agony', 4), ('homecoming', 4), ('manuscripts', 4), ('dwyer', 4), ('carpets', 4), ('datelined', 4), ('tass', 4), ('excerpts', 4), ('stalwart', 4), ('assembling', 4), ('embroidery', 4), ('lanes', 4), ('sprung', 4), ('auction', 4), ('obscured', 4), ('poise', 4), ('cans', 4), ('stew', 4), ('man-made', 4), ('screening', 4), ('compilation', 4), ('interama', 4), ('seminar', 4), ('surrendering', 4), ('persuasion', 4), ('issuing', 4), ('adenauer', 4), ('wartime', 4), ('parkway', 4), ('oppressive', 4), ('uncovered', 4), ('benefactor', 4), ('africans', 4), ('governors', 4), ('industrialized', 4), ('olivetti', 4), ('bearden', 4), ('rickards', 4), ('707', 4), ('ld', 4), ('patrice', 4), ('moise', 4), ('kimpton', 4), ('lied', 4), ('charlayne', 4), ('classmates', 4), ('fabian', 4), ('entourage', 4), ('154', 4), ('thwarted', 4), ('bogey', 4), ('birdied', 4), ('rosburg', 4), ('pensacola', 4), ('73', 4), ('eighteenth-century', 4), ('1776', 4), ('empires', 4), ('anti-monopoly', 4), ('aptly', 4), ('directorate', 4), ('negotiation', 4), ('churchill', 4), ('baldrige', 4), ('stripes', 4), ('jacqueline', 4), ('phyfe', 4), ('duncan', 4), ('unhappily', 4), ('exploring', 4), ('auspices', 4), ('altar', 4), ('vows', 4), ('ballets', 4), ('steaks', 4), ('props', 4), ('hamburger', 4), ('wrangler', 4), ('archaeology', 4), ('isles', 4), ('neiman-marcus', 4), ('cadet', 4), ('suspects', 4), ('upturn', 4), ('monetary', 4), ('sunset', 4), ('hayes', 4), ('proximity', 4), ('gregorio', 4), ('probing', 4), ('chiefs', 4), ('glimco', 4), ('marin', 4), ('ratification', 4), ('juror', 4), ('one-story', 4), ('audio-visual', 4), ('fender', 4), ('rental', 4), ('dumping', 4), ('theft', 4), ('jossy', 4), ('wick', 4), ('blvd.', 4), ('alice', 4), ('kaiser', 4), ('willard', 4), ('legion', 4), ('tribunal', 4), ('laotian', 4), ('kimmell', 4), ('pall', 4), ('addicts', 4), ('sokol', 4), ('reputedly', 4), ('krogers', 4), ('lonsdale', 4), ('chains', 4), ('werner', 4), ('schaefer', 4), ('annapolis', 4), ('margaret', 4), ('katherine', 4), ('miss.', 4), ('lynn', 4), ('son-in-law', 4), ('meyer', 4), ('boyd', 4), ('wheeler', 4), ('moody', 4), ('philmont', 4), ('carter', 4), ('lace', 4), ('down-to-earth', 4), ('shoup', 4), ('tarzan', 4), ('mink', 4), ('conspired', 4), ('cooperating', 4), ('congenial', 4), ('goodis', 4), ('reorganization', 4), ('16000', 4), ('lafayette', 4), ('1600', 4), ('pfaff', 4), ('two-hour', 4), ('overly', 4), ('plenary', 4), ('pro-communist', 4), ('secretariat', 4), ('shriver', 4), ('gerosa', 4), ('proposing', 4), ('levitt', 4), ('warden', 4), ('meyner', 4), ('westfield', 4), ('republicanism', 4), ('sanitary', 4), ('regulating', 4), ('atty.', 4), ('fiasco', 4), ('attachment', 4), ('tactical', 4), ('oslo', 4), ('weaver', 4), ('unspecified', 4), ('drain', 4), ('altho', 4), ('undone', 4), ('unconsciously', 4), ('quota', 4), ('unconditional', 4), ('ricco', 4), ('devout', 4), ('mystical', 4), ('countrymen', 4), ('agnese', 4), ('courteous', 4), ('tranquility', 4), ('obelisk', 4), ('soles', 4), ('uhhu', 4), ('ugliness', 4), ('fragment', 4), ('tiles', 4), ('gravy', 4), ('villains', 4), ('sleeves', 4), ('journals', 4), ('predicting', 4), ('bugs', 4), ('towering', 4), ('aft', 4), ('receding', 4), ('engulfed', 4), ('rouge', 4), ('cabana', 4), ('robe', 4), ('filmed', 4), ('glistening', 4), ('buddies', 4), ('thet', 4), ('chrome', 4), ('grossly', 4), ('herry', 4), ('autos', 4), ('marker', 4), ('switches', 4), ('japs', 4), ('flicked', 4), ('throttle', 4), ('take-off', 4), ('bivouac', 4), ('sweeney', 4), ('cries', 4), ('sensibly', 4), ('yell', 4), ('unarmed', 4), ('bosses', 4), ('ranchers', 4), ('lay-offs', 4), ('downfall', 4), ('shrink', 4), ('sportin', 4), ('chilling', 4), ('baird', 4), ('veranda', 4), ('luke', 4), ('whichever', 4), ('tomas', 4), ('donna', 4), ('face-saving', 4), ('grudge', 4), ('axle', 4), ('trousers', 4), ('honorable', 4), ('betty', 4), ('negligence', 4), ('accacia', 4), ('orville', 4), ('stamps', 4), ('mailboxes', 4), ('unwilling', 4), ('audit', 4), ('enlargement', 4), ('skimmed', 4), ('professed', 4), ('medfield', 4), ('uh-huh', 4), ('smythe', 4), ('sane', 4), ('weigand', 4), ('clerks', 4), ('pad', 4), ('drifted', 4), ('groves', 4), ('darted', 4), ('maze', 4), ('crosson', 4), ('overalls', 4), ('oven', 4), ('companionship', 4), ('lone', 4), ('lain', 4), ('tack', 4), ('rampant', 4), ('honotassa', 4), ('inherit', 4), ('kittens', 4), ('crumpled', 4), ('expedient', 4), ('spades', 4), ('grinding', 4), ('inflation', 4), ('preferences', 4), ('projecting', 4), ('subsidize', 4), ('distressed', 4), ('aggregate', 4), ('lexicostatistics', 4), ('listing', 4), ('slot', 4), ('advocating', 4), ('59', 4), ('spans', 4), ('consonants', 4), ('unstressed', 4), ('skipped', 4), ('x-region', 4), ('bales', 4), ('global', 4), ('streaming', 4), ('introject', 4), ('freeze', 4), ('supervisors', 4), ('antagonists', 4), ('compulsives', 4), ('spelling', 4), ('rapport', 4), ('classrooms', 4), ('deductible', 4), ('overpayment', 4), ('installment', 4), ('supersonic', 4), ('mobilization', 4), ('parliamentary', 4), ('bearings', 4), ('procedural', 4), ('348', 4), ('solicitor', 4), ('trusts', 4), ('divestiture', 4), ('dealings', 4), ('restraints', 4), ('lessen', 4), ('dismissal', 4), ('maximizing', 4), ('gallon', 4), ('install', 4), ('vents', 4), ('insuring', 4), ('aviation', 4), ('re', 4), ('attracting', 4), ('weaken', 4), ('armaments', 4), ('priced', 4), ('backbone', 4), ('chesapeake', 4), ('idly', 4), ('liability', 4), ('deducted', 4), ('void', 4), ('heretofore', 4), ('penalties', 4), ('nbs', 4), ('erroneous', 4), ('4.2', 4), ('1965', 4), ('lignite', 4), ('nonmetallic', 4), ('licenses', 4), ('stat.', 4), ('evolutionary', 4), ('adjunct', 4), ('platonism', 4), ('rehearsal', 4), ('magnification', 4), ('troublesome', 4), ('salient', 4), ('aunts', 4), ('ephemeral', 4), ('forte', 4), ('whiteman', 4), ('gaieties', 4), ('wears', 4), ('sinatra', 4), ('calculating', 4), ('hospitable', 4), ('nephew', 4), ('cyrus', 4), ('johns', 4), ('affections', 4), ('thorpe', 4), ('bangs', 4), ('protesting', 4), ('habitual', 4), ('1934', 4), ('snopes', 4), ('compson', 4), ('wasteful', 4), ('antagonistic', 4), ('safest', 4), ('fasten', 4), ('un-american', 4), ('repression', 4), ('disclose', 4), ('1200', 4), ('quarterly', 4), ('airports', 4), ('disadvantages', 4), ('disregard', 4), ('directives', 4), ('east-west', 4), ('moderates', 4), ('irrational', 4), ('ussr', 4), ('centralization', 4), ('woodrow', 4), ('logistics', 4), ('noses', 4), ('continuum', 4), ('predecessors', 4), ('hammett', 4), ('marlowe', 4), ('wolfe', 4), ('verified', 4), ('observes', 4), ('fortress', 4), ('uneven', 4), ('wreath', 4), ('acquiescence', 4), ('pilgrim', 4), ('homeland', 4), ('legendary', 4), ('rewarding', 4), ('clothed', 4), ('complicity', 4), ('willy', 4), ('thailand', 4), ('enroll', 4), ('judicial', 4), ('apologies', 4), ('arena', 4), ('erich', 4), ('intellect', 4), ('dialectic', 4), ('hereafter', 4), ('fragmentation', 4), ('prettier', 4), ('flaming', 4), ('grandchildren', 4), ('metallic', 4), ('roses', 4), ('mirrors', 4), ('partition', 4), ('perverse', 4), ('hamm', 4), ('viewer', 4), ('confronts', 4), ('chaotic', 4), ('shattering', 4), ('engrossing', 4), ('baggy', 4), ('charities', 4), ('psychiatric', 4), ('defeating', 4), ('locales', 4), ('redevelopment', 4), ('dunbar', 4), ('plumber', 4), ('typing', 4), ('chore', 4), ('marketable', 4), ('nondescript', 4), ('timetable', 4), ('nantucket', 4), ('badge', 4), ('academically', 4), ('disrupted', 4), ('envisioned', 4), ('piety', 4), ('antiseptic', 4), ('4000', 4), ('keo', 4), ('traversed', 4), ('atop', 4), ('grotesquely', 4), ('ghana', 4), ('nominal', 4), ('backwoods', 4), ('intimidation', 4), ('deteriorated', 4), ('unrest', 4), ('dwell', 4), ('algerian', 4), ('pinned', 4), ('assaulted', 4), ('rifleman', 4), ('chuckle', 4), ('surprises', 4), ('swivel', 4), ('organizational', 4), ('battered', 4), ('hilo', 4), ('self-confidence', 4), ('stealth', 4), ('diamonds', 4), ('platinum', 4), ('gunmen', 4), ('convicts', 4), ('webster', 4), ('banquet', 4), ('forestall', 4), ('labour', 4), ('burglary', 4), ('dive', 4), ('birthplace', 4), ('immigrant', 4), ('hawthorne', 4), ('corporal', 4), ('denunciation', 4), ('correspondents', 4), ('bin', 4), ('stationed', 4), ('modes', 4), ('wildcat', 4), ('refined', 4), ('richer', 4), ('furs', 4), ('violated', 4), ('onslaught', 4), ('trader', 4), ('pembina', 4), ('1818', 4), ('traders', 4), ('numbered', 4), ('valleys', 4), ('earl', 4), ('coasts', 4), ('backers', 4), ('sailor', 4), ('fatally', 4), ('lukewarm', 4), ('staffe', 4), ('strait', 4), ('furious', 4), ('tides', 4), ('arctic', 4), ('imposition', 4), ('ratified', 4), ('morally', 4), ('contraception', 4), ('gangsters', 4), ('enforce', 4), ('intrinsically', 4), ('implement', 4), ('spouses', 4), ('teachings', 4), ('contraceptives', 4), ('unduly', 4), (\"o'\", 4), ('birth-control', 4), ('criminality', 4), ('anti-semitic', 4), ('liquidation', 4), ('fairness', 4), ('achieves', 4), ('corpus', 4), ('legally', 4), ('strategists', 4), ('starved', 4), ('wholesome', 4), ('triggered', 4), ('manuals', 4), ('suffrage', 4), ('summed', 4), ('psychiatrist', 4), ('confided', 4), ('schillinger', 4), ('ridicule', 4), ('self-respect', 4), ('unhealthy', 4), ('submissive', 4), ('spice', 4), ('migration', 4), ('1966', 4), ('seashore', 4), ('shooter', 4), ('affiliated', 4), ('teen-age', 4), ('assuredly', 4), ('overlooked', 4), ('subsidized', 4), ('prefers', 4), ('menu', 4), ('restricting', 4), ('giveaway', 4), ('investments', 4), ('scarce', 4), ('forecasts', 4), ('consumers', 4), ('flourishes', 4), ('salesmanship', 4), ('yr.', 4), ('unloading', 4), ('discarded', 4), ('sterile', 4), ('worms', 4), ('aureomycin', 4), ('regulatory', 4), ('veterinary', 4), ('polarity', 4), ('charted', 4), ('lion', 4), ('1810', 4), ('reckon', 4), ('1803', 4), ('lodging', 4), ('astronomy', 4), ('1793', 4), ('denmark', 4), ('detachment', 4), ('displaying', 4), ('scanning', 4), ('transmitter', 4), ('bloodstream', 4), ('researchers', 4), ('wavelength', 4), ('lenses', 4), ('haven', 4), ('landscapes', 4), ('decorative', 4), ('easel', 4), ('indoors', 4), ('spontaneity', 4), ('palette', 4), ('expeditions', 4), ('out-of-doors', 4), ('endowments', 4), ('supra', 4), ('warping', 4), ('traditionalist', 4), ('archives', 4), ('harmonies', 4), ('counterpoint', 4), ('melodic', 4), ('instrumentation', 4), ('idiom', 4), ('world-wide', 4), ('premieres', 4), ('speculations', 4), ('post-war', 4), ('koussevitzky', 4), ('headache', 4), ('superseded', 4), ('lions', 4), ('savory', 4), ('dispose', 4), ('priceless', 4), ('specifies', 4), ('siamese', 4), ('prelude', 4), ('limbs', 4), ('drawers', 4), ('inhumane', 4), ('unwittingly', 4), ('layman', 4), ('pollock', 4), ('one-man', 4), ('disgusting', 4), ('gaulle', 4), ('engages', 4), ('alicia', 4), ('pet', 4), ('wry', 4), ('motif', 4), ('sumptuous', 4), ('rebuffed', 4), ('outspoken', 4), ('catharsis', 4), ('terrifying', 4), ('neitzbohr', 4), ('forthright', 4), ('poking', 4), ('coconut', 4), ('juncture', 4), ('eyelids', 4), ('bottoms', 4), ('statues', 4), ('towers', 4), ('dove', 4), ('falcon', 4), ('questionnaire', 4), ('undergone', 4), ('marquis', 4), ('rainbow', 4), ('swallow', 4), ('diminishing', 4), ('pronoun', 4), ('hauling', 4), ('gushed', 4), ('reluctantly', 4), ('jocular', 4), ('rubbish', 4), ('doorman', 4), ('gag', 4), ('modifier', 4), ('ecstatic', 4), ('swirled', 4), ('blended', 4), ('hinges', 4), ('sameness', 4), ('stucco', 4), ('dived', 4), ('judith', 4), ('softened', 4), ('mountainside', 4), ('verb', 4), ('grammatical', 4), ('ozagen', 4), ('descendants', 4), ('caribbean', 4), ('iceland', 4), ('mediterranean', 4), ('ceylon', 4), ('yarrow', 4), ('sigmen', 4), ('inhabited', 4), ('interstellar', 4), ('ill-starred', 4), ('vs', 4), ('poisoned', 4), ('militant', 4), ('heavenly', 4), ('snack', 4), ('grokking', 4), ('equated', 4), ('grokked', 4), ('cherish', 4), ('shouldered', 4), ('exit', 4), ('contemptuous', 4), ('microphone', 4), ('clapping', 4), ('complaining', 4), ('helplessness', 4), ('battlefield', 4), ('bouquet', 4), ('cetera', 4), ('jammed', 4), ('supervise', 4), ('vegas', 4), ('las', 4), ('advisability', 4), ('aides', 4), ('capsule', 4), ('connor', 4), ('flannel', 4), ('oppressed', 4), ('murdered', 4), ('twined', 4), ('bucket', 4), ('caps', 4), ('makeshift', 4), ('subway', 4), ('strangely', 4), ('wallet', 4), ('boasted', 4), ('overheard', 4), ('consummated', 4), ('suffocating', 4), ('glamor', 4), ('withdrawal', 4), ('unwanted', 4), ('welcoming', 4), ('contemplation', 4), ('tag', 4), ('lint', 4), ('tightening', 4), ('embarrassed', 4), ('fumbling', 4), ('vulture', 4), ('prevail', 4), ('suppressed', 4), ('persuading', 4), ('unwelcome', 4), ('witnessing', 4), ('leaps', 4), ('stairway', 4), ('comb', 4), ('patronne', 4), ('knocking', 4), ('1908', 4), ('hens', 4), ('initiate', 4), ('possum', 4), ('ernest', 4), ('wishing', 4), ('choked', 4), ('calves', 4), ('forty-nine', 4), ('ignition', 4), ('maniac', 4), ('underfoot', 4), ('sill', 4), ('vine', 4), ('gazette', 4), ('flopped', 4), ('poked', 4), ('hunted', 4), ('cheated', 4), ('popping', 4), ('jorge', 4), ('steaming', 4), ('cock', 4), ('hid', 4), ('watering', 4), ('brotherhood', 4), ('accompany', 4), ('starbird', 4), ('hugging', 4), ('drawer', 4), ('affectionate', 4), ('angelina', 4), ('glare', 4), ('widowed', 4), ('births', 4), ('stance', 4), ('comforts', 4), ('plump', 4), ('boring', 4), ('flannagans', 4), ('yugoslavia', 4), ('czechoslovakia', 4), ('bereavement', 4), ('ducks', 4), ('spat', 4), ('gouging', 4), ('slamming', 4), ('milling', 4), ('shocking', 4), ('skiffs', 4), ('groped', 4), ('coherent', 4), ('slippery', 4), ('sag', 4), ('rigidly', 4), ('flat-bottomed', 4), ('fertile', 4), ('lump', 4), ('timbers', 4), ('beckworth', 4), ('disclosures', 4), ('echoed', 4), ('alastor', 4), ('godwin', 4), ('sultans', 4), ('pausing', 4), ('striped', 4), ('knotted', 4), ('fabled', 4), ('virginity', 4), ('eagle', 4), ('abandoning', 4), ('surveyor', 4), ('graphic', 4), ('travelers', 4), ('oyabun', 4), ('livelihood', 4), ('outlines', 4), ('thieving', 4), ('sposato', 4), ('swell', 4), ('skull', 4), ('begging', 4), ('parted', 4), ('handing', 4), ('overcoat', 4), ('jealous', 4), ('pimp', 4), ('fights', 4), ('exile', 4), ('jan', 4), ('drunken', 4), ('globocnik', 4), ('coffin', 4), ('flourish', 4), ('drab', 4), ('refreshed', 4), ('peg', 4), ('buckle', 4), ('sword', 4), ('nested', 4), ('swells', 4), ('stakes', 4), ('ports', 4), ('sandy', 4), ('westchester', 4), ('groin', 4), ('flapped', 4), ('sulky', 4), ('bridegroom', 4), ('schuyler', 4), ('candles', 4), ('misgivings', 4), ('flushed', 4), ('dangling', 4), ('drunkenly', 4), ('ridges', 4), ('lattimer', 4), ('parkersburg', 4), ('haunted', 4), ('tussle', 4), ('stiffening', 4), ('twitched', 4), ('gasps', 4), ('blink', 4), ('splinter', 4), ('subtracted', 4), ('forbids', 4), ('luminous', 4), ('melzi', 4), ('pose', 4), ('draper', 4), ('draperies', 4), ('storing', 4), ('tweed', 4), ('towel', 4), ('velvet', 4), ('accusing', 4), ('armchair', 4), ('creaking', 4), ('rude', 4), ('terrier', 4), ('volunteered', 4), ('staircase', 4), ('tribal', 4), ('consented', 4), ('skopas', 4), ('headline', 4), ('sofa', 4), ('invalid', 4), ('minorities', 4), ('selena', 4), ('lush', 4), ('engendered', 4), ('hike', 4), ('mumbled', 4), ('glitter', 4), ('twilight', 4), ('gleam', 4), ('pullen', 4), ('choking', 4), ('fumes', 4), ('hardtack', 4), ('boughs', 4), ('cabins', 4), ('caressing', 4), ('heaved', 4), ('comply', 4), ('revenge', 4), ('hearth', 4), ('eli', 4), ('curtail', 4), ('signing', 4), ('shoving', 4), ('filtering', 4), ('knelt', 4), ('murderers', 4), ('proclaiming', 4), ('beadle', 4), ('mocking', 4), ('frenchman', 4), ('populace', 4), ('calvin', 4), ('denounce', 4), ('camaret', 4), ('fanning', 4), ('joshua', 4), ('callous', 4), ('pasture', 4), ('sanity', 4), ('vile', 4), ('committeemen', 4), ('recollection', 4), ('dashing', 4), ('beards', 4), ('madame', 4), ('shave', 4), ('carriage', 4), ('inform', 4), ('rehearsals', 4), ('hum', 4), ('manuscript', 4), ('shouts', 4), ('laughs', 4), ('contradictions', 4), ('um', 4), ('eyeing', 4), ('alarmed', 4), ('gnawing', 4), ('bump', 4), ('revulsion', 4), ('nagging', 4), ('fuck', 4), ('blizzard', 4), ('grownups', 4), ('chewed', 4), ('grasshoppers', 4), ('screeched', 4), ('bury', 4), ('strove', 4), ('shuddered', 4), ('slipping', 4), ('northward', 4), ('westerly', 4), ('buggy', 4), ('parish', 4), ('sinners', 4), ('awe', 4), ('loudest', 4), ('corpse', 4), ('triumphantly', 4), ('hem', 4), ('dingy', 4), ('dashed', 4), ('toad', 4), ('pungent', 4), ('commotion', 4), ('yelling', 4), ('knives', 4), ('appalling', 4), ('dismay', 4), ('bedrooms', 4), ('verdi', 4), ('herold', 4), ('subscription', 4), ('queer', 4), ('repository', 4), ('fierce', 4), ('catt', 4), ('stemmed', 4), ('shrill', 4), ('knot', 4), ('deacon', 4), ('episcopal', 4), ('laborers', 4), ('decorated', 4), ('sympathize', 4), ('boxell', 4), ('rosebuds', 4), ('bald', 4), ('prosperous', 4), ('greetings', 4), ('lunged', 4), ('subdued', 4), ('cave', 4), ('sentry', 4), ('mickie', 4), ('steered', 4), ('wrists', 4), ('barns', 4), ('fascinated', 4), ('vest', 4), ('sneaked', 4), ('clump', 4), ('sweaty', 4), ('chilled', 4), ('tremble', 4), ('sighing', 4), ('tread', 4), ('chunks', 4), ('mercifully', 4), ('ammo', 4), ('barricades', 4), ('abortion', 4), ('apologetically', 4), ('swooped', 4), ('fuzzy', 4), ('awakened', 4), ('bandaged', 4), ('hover', 4), ('sprawling', 4), ('motionless', 4), ('lids', 4), ('blurred', 4), ('plumpness', 4), ('appointments', 4), ('1.0', 4), ('membrane', 4), ('bacteria', 4), ('sludge', 4), ('240', 4), ('extensively', 4), ('warehouse', 4), ('bicycle', 4), ('retailing', 4), ('patents', 4), ('128', 4), ('lockheed', 4), ('grille', 4), ('siding', 4), ('turbine', 4), ('intertwined', 4), ('clusters', 4), ('plasticity', 4), ('assimilated', 4), ('monopolize', 4), ('shaded', 4), ('ambivalent', 4), ('lettering', 4), ('undepicted', 4), ('assigns', 4), ('simulate', 4), ('rescued', 4), ('charitable', 4), ('cheerfully', 4), ('hissing', 4), ('countenance', 4), ('trafton', 4), ('lingering', 4), ('imprisonment', 4), ('woonsocket', 4), ('informs', 4), ('originality', 4), ('misuse', 4), ('compassion', 4), ('rigors', 4), ('quest', 4), ('warrior', 4), ('stoic', 4), ('utopians', 4), ('denials', 4), ('onrush', 4), ('penetrate', 4), ('evoked', 4), ('dreary', 4), ('houghton', 4), ('diary', 4), ('1905', 4), ('barnumville', 4), ('manley', 4), ('dividends', 4), ('bennington', 4), ('matthew', 4), ('inventor', 4), ('battenkill', 4), ('disappearing', 4), ('sighted', 4), ('hillside', 4), ('cartridges', 4), ('comrades', 4), ('appoint', 4), ('chavez', 4), ('warrants', 4), ('fortified', 4), ('foreman', 4), ('noticing', 4), ('grabbing', 4), ('bluffs', 4), ('thence', 4), ('sundown', 4), ('syntax', 4), ('revolved', 4), ('culmination', 4), ('swirling', 4), ('indicative', 4), ('hellenic', 4), ('motifs', 4), ('vase', 4), ('novelty', 4), ('millennium', 4), ('transmuted', 4), ('consolidated', 4), ('pins', 4), ('serenity', 4), ('storms', 4), ('prohibiting', 4), ('recourse', 4), ('unseen', 4), ('manifest', 4), ('exceedingly', 4), ('blunt', 4), ('kinesthetic', 4), ('impaired', 4), ('decidedly', 4), ('greet', 4), ('cheer', 4), ('condemn', 4), ('murders', 4), ('entirety', 4), ('struggled', 4), ('accomplishment', 4), ('disinterested', 4), ('communal', 4), ('stimulate', 4), ('transposed', 4), ('faction', 4), ('prominence', 4), ('maneuvering', 4), ('ibrahim', 4), ('harassed', 4), ('consultants', 4), ('rumors', 4), ('affiliation', 4), ('vindication', 4), ('inter', 4), ('adherents', 4), ('2500', 4), ('allusions', 4), ('standardized', 4), ('cults', 4), ('regulation', 4), ('societal', 4), ('penance', 4), ('self-contained', 4), ('triumphant', 4), ('experiencing', 4), ('relate', 4), ('harmonious', 4), ('perpetuating', 4), ('intellectuals', 4), ('alienated', 4), ('surpluses', 4), ('programming', 4), ('incentives', 4), ('inducing', 4), ('murky', 4), ('dearly', 4), ('foresight', 4), ('diagonal', 4), ('cubes', 4), ('generalize', 4), ('high-school', 4), ('integer', 4), ('divides', 4), ('divisible', 4), ('algebraically', 4), ('beast', 4), ('neuroses', 4), ('neurosis', 4), ('stimuli', 4), ('mecholyl', 4), ('excitatory', 4), ('somatic', 4), ('wakefulness', 4), ('excitability', 4), ('responsiveness', 4), ('topical', 4), ('mosaic', 4), ('xylem', 4), ('photography', 4), ('distinguishable', 4), ('designation', 4), ('antiserum', 4), ('glycerine', 4), ('ethyl', 4), ('clumps', 4), ('irregularly', 4), ('cytoplasm', 4), ('pigment', 4), ('laden', 4), ('visceral', 4), ('plaques', 4), ('7.5', 4), ('crutches', 4), ('gastrocnemius', 4), ('atrophy', 4), ('triamcinolone', 4), ('hemoglobin', 4), ('marrow', 4), ('complication', 4), ('acetone', 4), ('janssen', 4), ('1851', 4), ('doses', 4), ('affinity', 4), ('enzyme', 4), ('proteases', 4), ('circulating', 4), ('enzymes', 4), ('coupling', 4), ('tri-iodothyronine', 4), ('potter', 4), ('cell-free', 4), ('organification', 4), ('crosses', 4), ('forecasting', 4), ('predominantly', 4), ('elbow', 4), ('denotes', 4), ('denoting', 4), ('transverse', 4), ('adolescence', 4), ('periphery', 4), ('pig', 4), ('valves', 4), ('thickened', 4), ('sized', 4), ('emphysema', 4), ('arteriolar', 4), ('parenchyma', 4), ('hilar', 4), ('bronchiole', 4), ('bronchus', 4), ('brazil', 4), ('emmett', 4), ('anacondas', 4), ('piling', 4), ('ghosts', 4), ('weigh', 4), ('amethystine', 4), ('java', 4), ('rattlesnakes', 4), ('sparse', 4), ('salty', 4), ('plead', 4), ('200000', 4), ('gregarious', 4), ('well-kept', 4), ('burrow', 4), ('andrenas', 4), ('abode', 4), ('bombus', 4), ('parasites', 4), ('honeybees', 4), ('mated', 4), ('flattened', 4), ('spinco', 4), ('165', 4), ('isotonic', 4), ('dialyzed', 4), ('injecting', 4), ('agglutination', 4), ('titers', 4), ('titer', 4), ('gradients', 4), ('elution', 4), ('modifications', 4), ('ultracentrifugation', 4), ('fractionation', 4), ('cohn', 4), ('resistant', 4), ('ulcer', 4), ('1980', 4), ('00', 4), ('dosage', 4), ('inert', 4), ('meteorological', 4), ('alveoli', 4), ('intra', 4), ('incubation', 4), ('microorganisms', 4), ('intentional', 4), ('microns', 4), ('deriving', 4), ('experimenters', 4), ('dubious', 4), ('eta', 4), ('microphones', 4), ('sediments', 4), ('extrapolated', 4), ('meteors', 4), ('prediction', 4), ('demonstrates', 4), ('replenish', 4), ('continual', 4), ('astronomical', 4), ('radial', 4), ('repulsive', 4), ('inversely', 4), ('spectral', 4), ('0.4', 4), ('correction', 4), ('minimized', 4), ('sealing', 4), ('alkali', 4), ('radicals', 4), ('intermediates', 4), ('quantum', 4), ('idealized', 4), ('ionic', 4), ('accelerate', 4), ('tails', 4), ('exhibiting', 4), ('versa', 4), ('uncharged', 4), ('theoretically', 4), ('residue', 4), ('salts', 4), ('smoothness', 4), ('ingredient', 4), ('genesis', 4), ('woodwork', 4), ('dwindling', 4), ('exploited', 4), ('microseconds', 4), ('0.3', 4), ('occluded', 4), ('accord', 4), ('ion', 4), ('diffraction', 4), ('peculiarities', 4), ('chromium', 4), ('unpaired', 4), ('intercept', 4), ('syrup', 4), ('ellipsoids', 4), ('gibbs', 4), ('terminology', 4), ('gravitational', 4), ('build-up', 4), ('modification', 4), ('acetate', 4), ('environmental', 4), ('approximated', 4), ('parameters', 4), ('holders', 4), ('shielded', 4), ('contamination', 4), ('disks', 4), ('dissociation', 4), ('ref.', 4), ('enhanced', 4), ('sheath', 4), ('fluxes', 4), ('velocities', 4), ('high-speed', 4), ('amp', 4), ('transpiring', 4), ('8.6', 4), ('approximation', 4), ('.7', 4), ('optical', 4), ('mc', 4), ('linearly', 4), ('intensities', 4), ('polarization', 4), ('sporadic', 4), ('opaque', 4), ('1.25', 4), ('unavailable', 4), ('wash.', 4), ('installations', 4), ('exploitation', 4), ('economists', 4), ('florence', 4), ('holocaust', 4), ('mistress', 4), ('madonna', 4), ('munich', 4), ('tendencies', 4), ('intimately', 4), ('devoid', 4), ('carefree', 4), ('prophet', 4), ('professionally', 4), ('liaison', 4), ('modulation', 4), ('sinister', 4), ('untouched', 4), ('mischief', 4), ('indolent', 4), ('sensuality', 4), ('ambiguities', 4), ('malformed', 4), ('visions', 4), ('commune', 4), ('suggestive', 4), ('rituals', 4), ('terrestrial', 4), ('harmless', 4), ('reconstruct', 4), ('attribute', 4), ('dispel', 4), ('sociological', 4), ('restraining', 4), ('councils', 4), ('unnatural', 4), ('organisms', 4), ('disapprove', 4), ('therefrom', 4), ('docile', 4), ('reversed', 4), ('conquest', 4), ('wrongs', 4), ('wishful', 4), ('centering', 4), ('discount', 4), ('northerners', 4), ('prejudice', 4), ('ruined', 4), ('outbursts', 4), ('authoritarian', 4), ('laissez-faire', 4), ('bureaucracy', 4), ('totalitarian', 4), ('liberties', 4), ('to-day', 4), ('cynical', 4), ('conservatives', 4), ('supporters', 4), ('instinctively', 4), ('sequences', 4), ('pail', 4), ('telegrapher', 4), ('close-up', 4), ('wooded', 4), ('ensued', 4), ('photo', 4), ('lens', 4), ('registers', 4), ('complications', 4), ('fantasies', 4), ('visually', 4), ('instincts', 4), ('melies', 4), ('nonfiction', 4), ('arcade', 4), ('silenced', 4), ('proceeding', 4), ('acutely', 4), ('hobby', 4), ('fondness', 4), ('analysts', 4), ('propagandists', 4), ('willy-nilly', 4), ('ascribed', 4), ('americana', 4), ('culturally', 4), ('fuse', 4), ('anecdotes', 4), ('definitions', 4), ('propagandistic', 4), ('mindful', 4), ('heterogeneous', 4), ('plight', 4), ('rationalize', 4), ('prosecuted', 4), ('108', 4), ('wreck', 4), ('strychnine', 4), ('machinist', 4), ('recovered', 4), ('institutionalized', 4), ('complaints', 4), ('postmaster', 4), ('fda', 4), ('medicines', 4), ('cure-all', 4), ('360', 4), ('wrinkles', 4), ('rectangular', 4), ('squeezing', 4), ('depew', 4), ('affecting', 4), ('escorted', 4), ('hilprecht', 4), ('bizarre', 4), ('subconscious', 4), ('challenges', 4), ('slab', 4), ('irregular', 4), ('stout', 4), ('psychical', 4), ('ensuing', 4), ('recognizes', 4), ('abused', 4), ('decorators', 4), ('clauses', 4), ('shortsighted', 4), ('dares', 4), ('refuses', 4), ('inhibition', 4), ('fairy', 4), ('wording', 4), ('manufacture', 4), ('schemes', 4), ('furnishes', 4), ('fundamentals', 4), ('adhere', 4), ('dismiss', 4), ('politeness', 4), ('upwards', 4), ('push-up', 4), ('abdominal', 4), ('virile', 4), ('clumsy', 4), ('fitness', 4), ('enterprising', 4), ('gymnastic', 4), ('coordination', 4), ('rings', 4), ('gymnasts', 4), ('sheltered', 4), ('stumps', 4), ('deserts', 4), ('pollution', 4), ('stagnant', 4), ('wolff', 4), ('chilly', 4), ('fascination', 4), ('giselle', 4), ('quasi', 4), ('incidental', 4), ('eliminates', 4), ('quantitatively', 4), ('distortion', 4), ('alteration', 4), ('scrawny', 4), ('shading', 4), ('pinched', 4), ('minded', 4), ('traits', 4), ('curzon', 4), ('anew', 4), ('trout', 4), ('schubert', 4), ('consumption', 4), ('dietary', 4), ('gables', 4), ('refrigeration', 4), ('vitamin', 4), ('appreciable', 4), ('asset', 4), ('excelsior', 4), ('tart', 4), ('tomato', 4), ('reputable', 4), ('ignores', 4), ('bloomed', 4), ('steamed', 4), ('sprinkling', 4), ('coldest', 4), ('glaring', 4), ('lowering', 4), ('straightening', 4), ('lifters', 4), ('thighs', 4), ('lunge', 4), ('selects', 4), ('incline', 4), ('pecs', 4), ('widen', 4), ('exercising', 4), ('mt.', 4), ('montreal', 4), ('lad', 4), ('secretly', 4), ('bestowal', 4), ('culminates', 4), ('envied', 4), ('grandeur', 4), ('affirmation', 4), ('rained', 4), ('primeval', 4), ('identifies', 4), ('concur', 4), ('symbolize', 4), ('sickness', 4), ('pulpit', 4), ('victorian', 4), ('portrayed', 4), ('ecclesiastical', 4), ('embarrassment', 4), ('fold', 4), ('redundancy', 4), ('warehouses', 4), ('tenth', 4), ('800000', 4), ('1850', 4), ('/1', 4), ('fawkes', 4), ('longest', 4), ('variant', 4), ('clergy', 4), ('englishmen', 4), ('intellectually', 4), ('accepts', 4), ('thesis', 4), ('unimportant', 4), ('inconsistent', 4), ('variously', 4), ('criticize', 4), ('apostolic', 4), ('schweitzer', 4), ('restatement', 4), ('scripture', 4), ('venerable', 4), ('peale', 4), ('revolutions', 4), ('profoundly', 4), ('adhered', 4), ('occupying', 4), ('potency', 4), ('methodical', 4), ('ever-changing', 4), ('attributes', 4), ('ken', 4), ('commentary', 4), ('detecting', 4), ('lucifer', 4), ('infected', 4), ('subtly', 4), ('characterize', 4), ('rightly', 4), ('experiential', 4), ('demons', 4), ('disbelief', 4), ('revisions', 4), ('transitional', 4), ('springtime', 4), ('lauderdale', 4), ('verve', 4), ('abiding', 4), ('laguardia', 4), ('evoke', 4), ('elliott', 4), ('fiorello', 4), ('sparkling', 4), ('chords', 4), ('loesser', 4), ('vibrant', 4), ('groom', 4), ('overcomes', 4), ('eroded', 4), ('wallace', 4), ('epitaph', 4), ('playhouse', 4), ('gospels', 4), ('traced', 4), ('lavishly', 4), ('complied', 4), ('architectural', 4), ('interiors', 4), ('decor', 4), ('percussion', 4), ('serviceable', 4), ('technically', 4), ('breathless', 4), ('composure', 4), ('cheers', 4), ('amounted', 4), ('teens', 4), ('buff', 4), ('trimmings', 4), ('magnificently', 4), ('finely', 4), ('threads', 4), ('peasant', 4), ('toughness', 4), ('helpfully', 4), ('brightly', 4), ('nobility', 4), ('performs', 4), ('quixote', 4), ('kipling', 4), ('ventures', 4), ('flyer', 4), ('preposterous', 4), ('kitchens', 4), ('tudor', 4), ('glories', 4), ('eliot', 4), ('impress', 4), ('affluence', 4), ('devastating', 4), ('cushion', 4), ('operatic', 4), ('shrine', 4), ('notified', 4), ('dietrich', 4), ('hurok', 4), ('conducts', 4), ('lacks', 4), ('orchestras', 4), ('sparks', 4), ('violinist', 4), ('milstein', 4), ('traitors', 4), ('frenzy', 4), ('pistols', 4), ('mobilized', 4), ('showdown', 4), ('neutralism', 4), ('dormant', 4), ('candidacy', 4), ('thant', 4), ('resolutions', 4), ('predecessor', 4), ('misdeeds', 4), ('occupancy', 4), ('contemplating', 4), ('graveyard', 4), ('avail', 4), ('handwriting', 4), ('dispatch', 4), ('departures', 4), ('unfavorable', 4), ('satellites', 4), ('intercontinental', 4), ('teller', 4), ('urbanized', 4), ('discontinuity', 4), ('morrison', 4), ('embark', 4), ('overwhelmingly', 4), ('temptations', 4), ('seller', 4), ('suffers', 4), ('well-informed', 4), ('arizona', 4), ('guides', 4), ('impart', 4), ('dover', 4), ('downs', 4), ('playwright', 4), ('esoteric', 4), ('edison', 4), ('numb', 4), ('gadget', 4), ('experimented', 4), ('bristles', 4), ('brushes', 4), ('underwriters', 4), ('tan', 4), ('dip', 4), ('lilac', 4), ('foam', 4), ('sandals', 4), ('wedge', 4), ('teenage', 4), ('silhouette', 4), ('tapered', 4), ('polo', 4), ('glamorous', 4), ('gum', 4), ('behaving', 4), ('slugger', 4), ('contented', 4), ('donnell', 4), ('compiled', 4), ('faults', 4), ('commended', 4), ('nordmann', 4), ('runaway', 4), ('so-so', 4), ('smoky', 4), ('imposing', 4), ('pirate', 4), ('redbirds', 4), ('vinegar', 4), ('embedded', 4), ('rains', 4), ('embankment', 4), ('flowed', 4), ('heartening', 4), ('diamond', 4), ('sportsman', 4), ('blazing', 4), ('golfers', 4), ('tournaments', 4), ('sponsorship', 4), ('kathy', 4), ('lease', 4), ('relentlessly', 4), ('babe', 4), ('trailing', 4), ('bleachers', 4), ('applaud', 4), ('barrage', 4), ('19th', 4), ('abide', 4), ('televised', 4), ('distressing', 4), ('all-out', 4), ('tying', 4), ('anymore', 4), ('examiner', 4), ('ritchie', 4), ('ensign', 4), ('awaited', 4), ('newsmen', 4), ('jensen', 4), ('outfielder', 4), ('landis', 4), ('liner', 4), ('diving', 4), ('tripled', 4), ('bunched', 4), ('smash', 4), ('grounded', 4), ('mcauliffe', 4), ('innings', 4), ('louisville', 4), ('nischwitz', 4), ('280', 4), ('spree', 4), ('tactic', 4), ('trinity', 4), ('owl', 4), ('a+m', 4), ('reserves', 4), ('thrusts', 4), ('longhorns', 4), ('conversions', 4), ('housewife', 4), ('thirds', 4), ('fingered', 4), ('crowding', 4), ('someplace', 4), ('tokyo', 4), ('clint', 4), ('inflicted', 4), ('ramp', 4), ('dunn', 4), ('streamlined', 4), ('bulky', 4), ('petersburg', 4), ('yanks', 4), ('skinny', 4), ('15000', 4), ('completes', 4), ('ron', 4), ('braves', 4), ('hartman', 4), ('kunkel', 4), ('blows', 4), ('fanned', 4), ('athletics', 4), ('soaring', 4), ('bachelor', 4), ('hays', 4), ('grover', 4), ('small-town', 4), ('114', 4), ('texan', 4), ('licensing', 4), ('brokers', 4), ('excise', 4), ('retailers', 4), ('17000', 4), ('fare', 4), ('meager', 4), ('authorize', 4), ('schooling', 4), ('cox', 4), ('contractual', 4), ('violate', 4), ('keynote', 4), ('watered', 4), ('carey', 4), ('unanimous', 4), ('74', 4), ('guardians', 4), ('populous', 4), ('jurors', 4), ('ivan', 4), ('poitrine', 5), ('kafka', 5), ('reuveni', 5), ('adelia', 5), ('kizzie', 5), ('aricaras', 5), ('fiske', 5), ('stallion', 5), ('dromozoa', 5), ('felice', 5), ('aimo', 5), ('pilgrims', 5), ('eighty-sixth', 5), ('choreographer', 5), ('alcoves', 5), ('proxy', 5), ('appliance', 5), ('gamblers', 5), ('farouk', 5), ('prostitute', 5), ('waco', 5), ('barre', 5), ('musmanno', 5), ('vesole', 5), ('hideous', 5), ('philippi', 5), ('newburyport', 5), ('chines', 5), ('hotei', 5), ('coil', 5), ('creek-turn', 5), ('frankfurters', 5), ('tablespoon', 5), ('flares', 5), ('hippodrome', 5), ('bosphorus', 5), ('istanbul', 5), ('remington', 5), ('ruger', 5), ('caper', 5), ('gasket', 5), ('spacers', 5), ('horsepower', 5), ('ephesians', 5), ('finney', 5), ('dynasty', 5), ('psalmist', 5), ('almighty', 5), ('posterity', 5), ('appestat', 5), ('portago', 5), ('lakes', 5), ('pageants', 5), ('byzantine', 5), ('balcony', 5), ('billions', 5), ('lyttleton', 5), ('advertisers', 5), ('forty-five', 5), ('seigner', 5), ('arnolphe', 5), ('mijbil', 5), ('django', 5), ('sax', 5), ('mulligan', 5), ('throne', 5), ('baritone', 5), ('couperin', 5), ('revivals', 5), ('madrigal', 5), ('skolovsky', 5), ('choreographed', 5), ('lauchli', 5), ('minutemen', 5), ('anti-party', 5), ('subjectively', 5), ('formosa', 5), ('post-attack', 5), ('frelinghuysen', 5), ('communese', 5), ('carvey', 5), ('hammock', 5), ('safeguard', 5), ('faget', 5), ('tammany', 5), ('keel', 5), ('rivalry', 5), ('dag', 5), ('chanted', 5), ('budgeting', 5), ('budgets', 5), ('unanimity', 5), ('beardens', 5), ('kasavubu', 5), ('ruthless', 5), ('tribes', 5), ('aching', 5), ('farrell', 5), ('cerv', 5), ('coe', 5), ('president-elect', 5), ('airlines', 5), ('intangible', 5), ('diocesan', 5), ('brevard', 5), ('chronicle', 5), ('librarian', 5), ('appraisal', 5), ('puppets', 5), ('yarn', 5), ('recipe', 5), ('buses', 5), ('sprinkle', 5), ('seasoned', 5), ('traded', 5), ('bluntly', 5), ('ronnie', 5), ('ginning', 5), ('janitors', 5), ('dread', 5), ('airfield', 5), ('sydney', 5), ('hutchins', 5), ('nevada', 5), ('birdie', 5), ('99', 5), ('huntley', 5), ('scratches', 5), ('latch', 5), ('wilmington', 5), ('nw', 5), ('coahr', 5), ('cubans', 5), ('hunter-killer', 5), ('fastest', 5), ('reactors', 5), ('adviser', 5), ('passport', 5), ('skipjack', 5), ('two-story', 5), ('capt.', 5), ('councilman', 5), ('arundel', 5), ('.45', 5), ('embroidered', 5), ('fraternity', 5), ('louise', 5), ('evans', 5), ('bundles', 5), ('thrift', 5), ('la.', 5), ('tourists', 5), ('accommodations', 5), ('parole', 5), ('carruthers', 5), ('stag', 5), ('vita', 5), ('dolce', 5), ('ariz.', 5), ('towne', 5), ('surgery', 5), ('debutante', 5), ('8000', 5), ('beaverton', 5), ('firemen', 5), ('tnt', 5), ('gladden', 5), ('pedestrian', 5), ('eastwick', 5), ('bids', 5), ('finances', 5), ('foes', 5), ('viewing', 5), ('allocated', 5), ('sandman', 5), ('scotch', 5), ('offenses', 5), ('reama', 5), ('responding', 5), ('drive-in', 5), ('narragansett', 5), ('phouma', 5), ('freer', 5), ('totaling', 5), ('needy', 5), ('cod', 5), ('figuring', 5), ('ballplayer', 5), ('thanked', 5), ('gestures', 5), ('vanity', 5), ('monmouth', 5), ('bandstand', 5), ('begged', 5), ('cracks', 5), ('gripping', 5), ('prisoner', 5), ('glances', 5), ('smells', 5), ('starving', 5), ('hettie', 5), ('grudgingly', 5), ('haze', 5), ('mentioning', 5), ('roadway', 5), ('fe', 5), ('sante', 5), ('fools', 5), ('attacker', 5), ('tightened', 5), ('roulette', 5), ('widened', 5), ('miners', 5), ('sack', 5), ('harshly', 5), ('thief', 5), ('cartridge', 5), ('hoofs', 5), ('ventured', 5), ('conchita', 5), ('maguire', 5), ('batch', 5), ('voiced', 5), ('blake', 5), ('calenda', 5), ('divan', 5), ('swear', 5), ('cypress', 5), ('homicide', 5), ('sucked', 5), ('ripped', 5), ('generously', 5), ('brian', 5), ('coroner', 5), ('constable', 5), ('vantage', 5), ('twenty-two', 5), ('nightmare', 5), ('sinking', 5), ('right-hand', 5), ('left-hand', 5), ('switzerland', 5), ('entail', 5), ('provoked', 5), ('unemployed', 5), ('founders', 5), ('genetic', 5), ('securing', 5), ('phonology', 5), ('importantly', 5), ('linguistics', 5), ('deprived', 5), ('snows', 5), ('w-region', 5), ('grammatic', 5), ('articulate', 5), ('sounding', 5), ('commenting', 5), ('commendable', 5), ('stupidity', 5), ('compares', 5), ('3.5', 5), ('sub', 5), ('depletion', 5), ('extensions', 5), ('icbm', 5), ('deterrent', 5), ('totals', 5), ('appropriation', 5), ('inaction', 5), ('withholding', 5), ('prohibited', 5), ('framing', 5), ('monopolies', 5), ('chill', 5), ('confines', 5), ('authoritative', 5), ('congratulations', 5), ('attributable', 5), ('certify', 5), ('claimants', 5), ('notify', 5), ('claimant', 5), ('thermometers', 5), ('shutter', 5), ('enactment', 5), ('surveys', 5), ('66', 5), ('milton', 5), ('thinker', 5), ('evaluate', 5), ('elman', 5), ('monocle', 5), ('sadie', 5), ('bertha', 5), ('sulzberger', 5), ('hopkins', 5), ('tapestry', 5), ('sara', 5), ('simon', 5), ('refinements', 5), ('genial', 5), ('planter', 5), ('experimenter', 5), ('jason', 5), ('heir', 5), ('43', 5), ('all-important', 5), ('mccarthy', 5), ('limitation', 5), ('exceeding', 5), ('inhuman', 5), ('fore', 5), ('dividend', 5), ('mandatory', 5), ('salisbury', 5), ('invoked', 5), ('slogan', 5), ('pertaining', 5), ('subordinates', 5), ('signaling', 5), ('compulsion', 5), ('unorthodox', 5), ('doyle', 5), ('premise', 5), ('ancestor', 5), ('entrepreneur', 5), ('ancestors', 5), ('hymns', 5), ('bo', 5), ('crane', 5), ('mores', 5), ('cliche', 5), ('etc', 5), ('implements', 5), ('compelling', 5), ('invent', 5), ('documented', 5), ('inexplicable', 5), ('godot', 5), ('1.1', 5), ('outreach', 5), ('peers', 5), ('motivation', 5), ('attends', 5), ('preparatory', 5), ('announcements', 5), ('monks', 5), ('boun', 5), ('nebraska', 5), ('sukarno', 5), ('waged', 5), ('koreans', 5), ('honolulu', 5), ('closes', 5), ('rattling', 5), ('terrified', 5), ('stickney', 5), ('distrust', 5), ('denounced', 5), ('pumping', 5), ('cicero', 5), ('col.', 5), ('nashville', 5), ('stereotyped', 5), ('unmarried', 5), ('garrison', 5), ('yank', 5), ('raining', 5), ('tariff', 5), ('cart', 5), ('daer', 5), ('scots', 5), ('talented', 5), ('aimless', 5), ('leaked', 5), ('westward', 5), ('digging', 5), ('evils', 5), ('reign', 5), ('disagree', 5), ('exempt', 5), ('offspring', 5), ('sensibilities', 5), ('envy', 5), ('workings', 5), ('annihilation', 5), ('weakened', 5), ('insisting', 5), ('dock', 5), ('nazis', 5), ('drilled', 5), ('hiring', 5), ('pigs', 5), ('disgusted', 5), ('contends', 5), ('contend', 5), ('dominates', 5), ('worldly', 5), ('pensions', 5), ('extravagant', 5), ('costing', 5), ('utilizing', 5), ('privileges', 5), ('assess', 5), ('automation', 5), ('progressively', 5), ('outlet', 5), ('outlets', 5), ('allocation', 5), ('geographic', 5), ('assessed', 5), ('distributor', 5), ('reproduction', 5), ('registry', 5), ('lambs', 5), ('reduces', 5), ('scours', 5), ('1800', 5), ('assisted', 5), ('experimenting', 5), ('educate', 5), ('spine', 5), ('traverse', 5), ('drs.', 5), ('counters', 5), ('staggering', 5), ('audubon', 5), ('blower', 5), ('umbrella', 5), ('washes', 5), ('simplified', 5), ('patterned', 5), ('fortunes', 5), ('engagements', 5), ('transform', 5), ('lure', 5), ('imaginative', 5), ('capitalist', 5), ('avant-garde', 5), ('chic', 5), ('premiere', 5), ('hailed', 5), ('greedy', 5), ('midwestern', 5), ('additionally', 5), ('butts', 5), ('elimination', 5), ('pennies', 5), ('troopers', 5), ('haul', 5), ('premises', 5), ('skillful', 5), ('quasimodo', 5), ('mechanic', 5), ('sponge', 5), ('provocative', 5), ('philosophic', 5), ('impeccable', 5), ('anna', 5), ('retaliation', 5), ('fink', 5), ('hopelessly', 5), ('intuition', 5), ('concertos', 5), ('revival', 5), ('thereupon', 5), ('delhi', 5), ('epoch', 5), ('coincided', 5), ('jokes', 5), ('cute', 5), ('dinners', 5), ('vaudeville', 5), ('evasive', 5), ('paved', 5), ('schuylkill', 5), ('eh', 5), ('satin', 5), ('obeyed', 5), ('half-breed', 5), ('mister', 5), ('gee', 5), ('whining', 5), ('ashes', 5), ('eyed', 5), ('republics', 5), ('drives', 5), ('fleeting', 5), ('ripples', 5), ('hi', 5), ('martian', 5), ('grok', 5), ('skolman', 5), ('rehearsed', 5), ('pedestal', 5), ('nancy', 5), ('demonstrating', 5), ('shaved', 5), ('solidly', 5), ('fringed', 5), ('borough', 5), ('preferable', 5), ('dapper', 5), ('descriptions', 5), ('commencing', 5), ('residing', 5), ('barefoot', 5), ('nail', 5), ('speck', 5), ('fine-looking', 5), ('gloves', 5), ('bending', 5), ('leona', 5), ('peacefully', 5), ('astonished', 5), ('wearily', 5), ('varieties', 5), ('scientifically', 5), ('blushed', 5), ('graceful', 5), ('linger', 5), ('cousins', 5), ('albright', 5), ('awaken', 5), ('austere', 5), ('canvases', 5), ('masonry', 5), ('stowey', 5), ('dripping', 5), ('shovel', 5), ('steal', 5), ('froze', 5), ('crib', 5), ('bargain', 5), ('bordering', 5), ('divorced', 5), ('procreation', 5), ('conveniently', 5), ('nephews', 5), ('links', 5), ('irons', 5), ('stockings', 5), ('checkbook', 5), ('heartily', 5), ('hallway', 5), ('slapping', 5), ('confess', 5), ('stricken', 5), ('tolerance', 5), ('generosity', 5), ('siege', 5), ('heroine', 5), ('handicap', 5), ('fabulous', 5), ('serge', 5), ('battles', 5), ('immensely', 5), ('rented', 5), ('nodding', 5), ('uptown', 5), ('disappear', 5), ('sausages', 5), ('peeled', 5), ('grunted', 5), ('shabby', 5), ('web', 5), ('unchanged', 5), ('animated', 5), ('infantry', 5), ('hook', 5), ('wary', 5), ('bloody', 5), ('haunches', 5), ('boyhood', 5), ('scented', 5), ('stuffed', 5), ('aide', 5), ('marsh', 5), ('rumor', 5), ('sorrow', 5), ('organizing', 5), ('rebs', 5), ('gaudy', 5), ('desperation', 5), ('grief', 5), ('awoke', 5), ('beth', 5), ('grumble', 5), ('senseless', 5), ('abdomen', 5), ('linen', 5), ('scrap', 5), ('carving', 5), ('physicians', 5), ('pies', 5), ('basin', 5), ('discovering', 5), ('rhodes', 5), ('wool', 5), ('stillness', 5), ('peddler', 5), ('cheese', 5), ('treasures', 5), ('elevator', 5), ('portraits', 5), ('curtains', 5), ('elapsed', 5), ('cautioned', 5), ('creaked', 5), ('suitcases', 5), ('glazed', 5), ('cadillac', 5), ('sandwich', 5), ('flanked', 5), ('nourished', 5), ('discoveries', 5), ('ransom', 5), ('moll', 5), ('gasped', 5), ('ole', 5), ('greatcoat', 5), ('clinging', 5), ('hamper', 5), ('snoring', 5), ('gaiety', 5), ('sadness', 5), ('drizzle', 5), ('chimney', 5), ('roofs', 5), ('ruin', 5), ('dripped', 5), ('duck', 5), ('bern', 5), ('revealing', 5), ('raged', 5), ('banished', 5), ('tapping', 5), ('righteousness', 5), ('refugees', 5), ('headaches', 5), ('greeting', 5), ('patched', 5), ('penetrated', 5), ('glinting', 5), ('aisle', 5), ('defiance', 5), ('tolerated', 5), ('carts', 5), ('hurling', 5), ('bolted', 5), ('glancing', 5), ('unreal', 5), ('initiation', 5), ('soaking', 5), ('redcoats', 5), ('bathed', 5), ('lovers', 5), ('obscurity', 5), ('tender', 5), ('reject', 5), ('sits', 5), ('nuts', 5), ('thumping', 5), ('takin', 5), ('braced', 5), ('ching', 5), ('humming', 5), ('blinked', 5), ('chuckled', 5), ('nothin', 5), ('bosom', 5), ('cocked', 5), ('hopped', 5), ('landlord', 5), ('tucked', 5), ('flared', 5), ('choir', 5), ('centennial', 5), ('spire', 5), ('shapeless', 5), ('echo', 5), ('retaining', 5), ('assassin', 5), ('blamed', 5), ('drowned', 5), ('mildly', 5), ('clambered', 5), ('clattered', 5), ('rebuild', 5), ('upkeep', 5), ('janitor', 5), ('shutters', 5), ('arrears', 5), ('wailing', 5), ('hysteria', 5), ('sidewalks', 5), ('brandy', 5), ('patiently', 5), ('gangs', 5), ('harlem', 5), ('wiry', 5), ('mint', 5), ('severed', 5), ('monuments', 5), ('insistent', 5), ('eased', 5), ('blackness', 5), ('tear', 5), ('lugged', 5), ('jagged', 5), ('slit', 5), ('pregnant', 5), ('insult', 5), ('gracefully', 5), ('elaborately', 5), ('drugged', 5), ('accidentally', 5), ('biscuits', 5), ('slippers', 5), ('fuller', 5), ('sauces', 5), ('polite', 5), ('smoking', 5), ('melted', 5), ('stalked', 5), ('examinations', 5), ('activated', 5), ('aeration', 5), ('fiberglas', 5), ('ft', 5), ('developer', 5), ('stack', 5), ('skyline', 5), ('foreseen', 5), ('economist', 5), ('merchandise', 5), ('contemplated', 5), ('piers', 5), ('freeway', 5), ('garages', 5), ('freeways', 5), ('taut', 5), ('glimpsed', 5), ('relinquish', 5), ('unmistakable', 5), ('silhouettes', 5), ('pry', 5), ('cooper', 5), ('reinforce', 5), ('deceived', 5), ('despotism', 5), ('brutality', 5), ('doomed', 5), ('commenced', 5), ('deed', 5), ('abolition', 5), ('honoring', 5), ('quaker', 5), ('vengeance', 5), ('riot', 5), ('zeal', 5), ('islanders', 5), ('interfere', 5), ('overthrow', 5), ('liberation', 5), ('stoicism', 5), ('conceptions', 5), ('restore', 5), ('sinned', 5), ('psyche', 5), ('commonwealth', 5), ('supremacy', 5), ('anguish', 5), ('secondly', 5), ('amused', 5), ('diversion', 5), ('marsden', 5), ('1925', 5), ('1895', 5), ('dale', 5), ('pharmacy', 5), ('1929', 5), ('1914', 5), ('1896', 5), ('grafton', 5), ('connecting', 5), ('proprietors', 5), ('1883', 5), ('telegraphers', 5), ('declare', 5), ('drugstore', 5), ('leon', 5), ('locality', 5), ('grenades', 5), ('consumed', 5), ('methodically', 5), ('stealing', 5), ('robbed', 5), ('twenty-three', 5), ('dismounted', 5), ('scrub', 5), ('catskill', 5), ('insufficient', 5), ('solemn', 5), ('indefinitely', 5), ('ancestral', 5), ('postpone', 5), ('countryside', 5), ('definitive', 5), ('enrich', 5), ('iliad', 5), ('manifested', 5), ('guessing', 5), ('recognizable', 5), ('amorphous', 5), ('astonishing', 5), ('inference', 5), ('whatsoever', 5), ('constitutes', 5), ('complexion', 5), ('condemnation', 5), ('implication', 5), ('removes', 5), ('criminals', 5), ('affiliations', 5), ('homogeneity', 5), ('balafrej', 5), ('affirmed', 5), ('differentiated', 5), ('sacrifices', 5), ('irresistible', 5), ('sentiments', 5), ('directing', 5), ('firmer', 5), ('doctrines', 5), ('integrate', 5), ('reflective', 5), ('deficiencies', 5), ('transitions', 5), ('coordinate', 5), ('self-sustaining', 5), ('credits', 5), ('promoting', 5), ('decrees', 5), ('mystique', 5), ('priorities', 5), ('pertains', 5), ('guarantee', 5), ('rotation', 5), ('rotated', 5), ('chord', 5), ('expressive', 5), ('haired', 5), ('equations', 5), ('illustrates', 5), ('sympathetically', 5), ('perceptual', 5), ('psychotherapy', 5), ('preservation', 5), ('neocortex', 5), ('stain', 5), ('conjugated', 5), ('al.', 5), ('alterations', 5), ('infiltration', 5), ('mucosa', 5), ('cord', 5), ('veins', 5), ('neutrophils', 5), ('scar', 5), ('discontinued', 5), ('hips', 5), ('downhill', 5), ('restriction', 5), ('peripheral', 5), ('anemia', 5), ('evaluating', 5), ('fragmentary', 5), ('isolating', 5), ('isolate', 5), ('uptake', 5), ('anterior', 5), ('rall', 5), ('di-iodotyrosine', 5), ('potassium', 5), ('inhibited', 5), ('133', 5), ('phalanx', 5), ('analyzing', 5), ('epiphysis', 5), ('developmental', 5), ('classify', 5), ('onsets', 5), ('infancy', 5), ('shunts', 5), ('relied', 5), ('54', 5), ('ducts', 5), ('drifts', 5), ('supplying', 5), ('hilum', 5), ('tentatively', 5), ('hatching', 5), ('staten', 5), ('skeptical', 5), ('j', 5), ('beebe', 5), ('foregoing', 5), ('responds', 5), ('speculate', 5), ('constrictor', 5), ('generalizations', 5), ('omitted', 5), ('sloping', 5), ('dense', 5), ('mentions', 5), ('hairs', 5), ('possesses', 5), ('coincides', 5), ('rusty', 5), ('lawns', 5), ('hind', 5), ('psithyrus', 5), ('builds', 5), ('constructing', 5), ('tipped', 5), ('catkins', 5), ('pussy', 5), ('prey', 5), ('125', 5), ('buffered', 5), ('homozygous', 5), ('donors', 5), ('abo', 5), ('liable', 5), ('overt', 5), ('neutralized', 5), ('sampled', 5), ('multiplication', 5), ('infection', 5), ('susceptible', 5), ('infections', 5), ('render', 5), ('lethal', 5), ('bw', 5), ('shielding', 5), ('inverse', 5), ('ninety', 5), ('micrometeorites', 5), ('consequent', 5), ('poynting-robertson', 5), ('exchanged', 5), ('220', 5), ('tubing', 5), ('liter', 5), ('flask', 5), ('inactive', 5), ('pyrex', 5), ('interfering', 5), ('photochemical', 5), ('measurable', 5), ('coated', 5), ('molecule', 5), ('interfaces', 5), ('unequivocally', 5), ('averaging', 5), ('micelles', 5), ('polar', 5), ('debris', 5), ('arbitrarily', 5), ('perfume', 5), ('powders', 5), ('polyphosphates', 5), ('precautions', 5), ('corresponds', 5), ('evacuation', 5), ('saturation', 5), ('170', 5), ('reproducible', 5), ('angles', 5), ('111', 5), ('calculations', 5), ('2.5', 5), ('nickel', 5), ('dipole', 5), ('axes', 5), ('curved', 5), ('mathematically', 5), ('distorted', 5), ('shearing', 5), ('combines', 5), ('generated', 5), ('denoted', 5), ('systematically', 5), ('ripple', 5), ('cylindrical', 5), ('upstream', 5), ('ensure', 5), ('blown', 5), ('rod', 5), ('usable', 5), ('injection', 5), ('impinging', 5), ('condensation', 5), ('necessitate', 5), ('qualitative', 5), ('currents', 5), ('graphite', 5), ('uniformly', 5), ('.5', 5), ('plotted', 5), ('scan', 5), ('drift', 5), ('lobes', 5), ('mountainous', 5), ('diagrams', 5), ('contour', 5), ('receivers', 5), ('specify', 5), ('altitude', 5), ('reflector', 5), ('angular', 5), ('sloanaker', 5), ('mayer', 5), ('3.15', 5), ('deduced', 5), ('black-body', 5), ('atmospheres', 5), ('royalty', 5), ('progresses', 5), ('facility', 5), ('commodity', 5), ('criteria', 5), ('jointly', 5), ('lending', 5), ('directory', 5), ('specifications', 5), ('strangers', 5), ('seizure', 5), ('pictorial', 5), ('cosmetics', 5), ('erotic', 5), ('luxurious', 5), ('centrally', 5), ('secrecy', 5), ('collision', 5), ('illuminating', 5), ('empirically', 5), ('communes', 5), ('entropy', 5), ('submitting', 5), ('1865', 5), ('regretted', 5), ('indies', 5), ('flowering', 5), ('unreconstructed', 5), ('impose', 5), ('provocation', 5), ('wrecking', 5), ('waist', 5), ('immoral', 5), ('commuting', 5), ('englander', 5), ('southerner', 5), ('divisive', 5), ('vulgar', 5), ('arrives', 5), ('robbers', 5), ('linking', 5), ('straightforward', 5), ('dissolve', 5), ('justly', 5), ('magnified', 5), ('backgrounds', 5), ('housewives', 5), ('lore', 5), ('assumes', 5), ('aggressiveness', 5), ('deaths', 5), ('postal', 5), ('testify', 5), ('doris', 5), ('chloride', 5), ('committing', 5), ('justifiably', 5), ('laborer', 5), ('recorder', 5), ('superimposed', 5), ('ailments', 5), ('gazing', 5), ('compose', 5), ('relic', 5), ('perpetuate', 5), ('fantasy', 5), ('momentary', 5), ('paragraph', 5), ('concurrent', 5), ('avoidance', 5), ('bombing', 5), ('mysteries', 5), ('wakeful', 5), ('awed', 5), ('psychiatrists', 5), ('decorator', 5), ('breadth', 5), ('continuance', 5), ('fabric', 5), ('consultation', 5), ('frowned', 5), ('assertion', 5), ('obtainable', 5), ('examining', 5), ('lifting', 5), ('overweight', 5), ('arches', 5), ('straighten', 5), ('unprepared', 5), ('masculine', 5), ('plague', 5), ('newborn', 5), ('checking', 5), ('encroachment', 5), ('dam', 5), ('deposits', 5), ('forests', 5), ('wildlife', 5), ('bathing', 5), ('relaxing', 5), ('desolate', 5), ('inexperienced', 5), ('verify', 5), ('accompaniment', 5), ('reproduce', 5), ('accumulation', 5), ('crippled', 5), ('slides', 5), ('delicacy', 5), ('comprised', 5), ('coral', 5), ('worthwhile', 5), ('avocados', 5), ('greens', 5), ('repay', 5), ('frigid', 5), ('buds', 5), ('mat', 5), ('thaw', 5), ('tops', 5), ('weeds', 5), ('spade', 5), ('ant', 5), ('beauties', 5), ('dakota', 5), ('prizes', 5), ('defining', 5), ('sculptured', 5), ('accents', 5), ('1821', 5), ('barbell', 5), ('temporal', 5), ('inescapable', 5), ('inception', 5), ('fashioned', 5), ('savior', 5), ('uniqueness', 5), ('archbishop', 5), ('depicting', 5), ('saints', 5), ('brethren', 5), ('non-catholic', 5), ('indignant', 5), ('1840', 5), ('inaccurate', 5), ('fireworks', 5), ('celebrating', 5), ('courtesy', 5), ('1861', 5), ('popularly', 5), ('participants', 5), ('treason', 5), ('indebted', 5), ('barth', 5), ('despise', 5), ('concluding', 5), ('ever-present', 5), ('unavoidable', 5), ('entails', 5), ('perennial', 5), ('operative', 5), ('fruitful', 5), ('universally', 5), ('horns', 5), ('superficial', 5), ('evokes', 5), ('defective', 5), ('biting', 5), ('refreshing', 5), ('teenagers', 5), ('visibly', 5), ('nostalgic', 5), ('exuberant', 5), ('charlotte', 5), ('jerome', 5), ('comedian', 5), ('cheerful', 5), ('stunning', 5), ('cherry', 5), ('explode', 5), ('blaze', 5), ('crippling', 5), ('tortured', 5), ('gary', 5), ('intimated', 5), ('twists', 5), ('potentialities', 5), ('tingling', 5), ('volley', 5), ('spirited', 5), ('directional', 5), ('jackets', 5), ('sundry', 5), ('reviewing', 5), ('uncommon', 5), ('actress', 5), ('girlish', 5), ('ecstasy', 5), ('wink', 5), ('clip', 5), ('auxiliary', 5), ('reinforced', 5), ('documentary', 5), ('yuri', 5), ('richness', 5), ('appropriately', 5), ('gravely', 5), ('sincerely', 5), ('gaunt', 5), ('poignant', 5), ('brigadier', 5), ('maids', 5), ('planks', 5), ('paneling', 5), ('splendor', 5), ('herds', 5), ('urges', 5), ('di', 5), ('marie', 5), ('minus', 5), ('cancel', 5), ('juicy', 5), ('repertory', 5), ('cradle', 5), ('cycles', 5), ('overture', 5), ('spitting', 5), ('noblest', 5), ('slashing', 5), ('accessories', 5), ('qualification', 5), ('diplomat', 5), ('secretaries', 5), ('buys', 5), ('revered', 5), ('marx', 5), ('statue', 5), ('restoration', 5), ('turmoil', 5), ('alan', 5), ('risen', 5), ('guardian', 5), ('threatens', 5), ('substitutes', 5), ('reassurance', 5), ('understands', 5), ('magician', 5), ('frauds', 5), ('inferiority', 5), ('depressing', 5), ('banker', 5), ('rca', 5), ('poets', 5), ('lecturer', 5), ('hugh', 5), ('nehru', 5), ('manifestation', 5), ('symptom', 5), ('disorders', 5), ('crowned', 5), ('shaving', 5), ('lacy', 5), ('throats', 5), ('pumps', 5), ('squared', 5), ('airy', 5), ('leo', 5), ('alvin', 5), ('inviting', 5), ('preached', 5), ('ol', 5), ('resented', 5), ('130', 5), ('blond', 5), ('pitched', 5), ('precedent', 5), ('inscription', 5), ('bradley', 5), ('hartweger', 5), ('finishing', 5), ('sore', 5), ('hemus', 5), ('amendments', 5), ('agenda', 5), ('guarding', 5), ('downstream', 5), ('idol', 5), ('fairway', 5), ('studded', 5), ('fla.', 5), ('tee', 5), ('matches', 5), ('switching', 5), ('sands', 5), ('dodgers', 5), ('columnist', 5), ('eagles', 5), ('feat', 5), ('cardinals', 5), ('momentarily', 5), ('crushing', 5), ('irritable', 5), ('revived', 5), ('clubhouse', 5), ('utah', 5), ('tex.', 5), ('rip', 5), ('lightweight', 5), ('accounted', 5), ('cliff', 5), ('indianapolis', 5), ('pinpoint', 5), ('averages', 5), ('reynolds', 5), ('stram', 5), ('ankle', 5), ('44', 5), ('gannon', 5), ('sophomore', 5), ('kinda', 5), ('77', 5), ('pads', 5), ('swelling', 5), ('quarterback', 5), ('ga.', 5), ('thrill', 5), ('duel', 5), ('brisk', 5), ('catching', 5), ('coaches', 5), ('assisting', 5), ('famed', 5), ('dimaggio', 5), ('twenty-one', 5), ('triple', 5), ('runners', 5), ('jackie', 5), ('pete', 5), ('pinch', 5), ('doubles', 5), ('pitchers', 5), ('shortstop', 5), ('southpaw', 5), ('throneberry', 5), ('tuttle', 5), ('solo', 5), ('hyde', 5), ('fisher', 5), ('drought', 5), ('recipients', 5), ('consulting', 5), ('sway', 5), ('construed', 5), ('cotten', 5), ('alleged', 5), ('domain', 5), ('certificate', 5), ('schwartz', 5), ('navigation', 5), ('antonio', 5), ('scholastic', 5), ('parkhouse', 5), ('undermine', 5), ('enforcing', 5), ('63', 5), ('subcommittee', 5), ('congressmen', 5), ('barber', 5), ('coordinator', 5), ('caldwell', 5), ('signatures', 5), ('precincts', 5), ('pelham', 5), ('griffin', 5), ('hartsfield', 5), ('grady', 5), ('distribute', 5), ('gunny', 6), ('julia', 6), ('jarrodsville', 6), ('roberta', 6), ('arm-elevation', 6), ('subgroups', 6), ('tangents', 6), ('out-of-state', 6), ('vaults', 6), ('aborigine', 6), ('nation-state', 6), ('malocclusion', 6), ('bey', 6), ('vaginal', 6), ('whole-wheat', 6), ('spindle', 6), ('one-inch', 6), ('bisque', 6), ('chili', 6), ('emeralds', 6), ('constantine', 6), ('apples', 6), ('minced', 6), ('deerstalker', 6), ('subtraction', 6), ('solder', 6), ('levers', 6), ('notches', 6), ('handler', 6), ('propulsion', 6), ('airfields', 6), ('realtor', 6), ('channing', 6), ('calories', 6), ('schwarzkopf', 6), ('negro-appeal', 6), ('nagrin', 6), ('hint', 6), ('recital', 6), ('xydis', 6), ('excerpt', 6), ('sr', 6), ('molotov', 6), ('adaptations', 6), ('youngster', 6), ('pineapple', 6), ('earthly', 6), ('cunard', 6), ('500000', 6), ('forceful', 6), ('nurses', 6), ('dekalb', 6), ('pas', 6), ('uranium', 6), ('socks', 6), ('humphrey', 6), ('pious', 6), ('presidents', 6), ('puppet', 6), ('judy', 6), ('pasadena', 6), ('continents', 6), ('debentures', 6), ('buyers', 6), ('chip', 6), ('rocket', 6), ('wilderness', 6), ('buchheister', 6), ('larson', 6), ('scottish', 6), ('vietnamese', 6), ('youthful', 6), ('jenks', 6), ('narcotics', 6), ('bail', 6), ('dreadnought', 6), ('simpkins', 6), ('carnival', 6), ('gala', 6), ('bayonet', 6), ('carnegie', 6), ('molly', 6), ('pastors', 6), ('multnomah', 6), ('hood', 6), ('barnard', 6), ('princess', 6), ('motorists', 6), ('delinquency', 6), ('souvanna', 6), ('seato', 6), ('asian', 6), ('compulsory', 6), ('wexler', 6), ('blank', 6), ('pegboard', 6), ('rossoff', 6), ('temperament', 6), ('askington', 6), ('scholarships', 6), ('insect', 6), ('shed', 6), ('wept', 6), ('instinct', 6), ('gansevoort', 6), ('sunshine', 6), ('dipper', 6), ('strand', 6), ('adios', 6), ('windshield', 6), ('carbine', 6), ('bartender', 6), ('arbuckle', 6), ('hernandez', 6), ('mounts', 6), ('needham', 6), ('tax-exempt', 6), ('grease', 6), ('brakes', 6), ('serene', 6), ('dismal', 6), ('resisted', 6), ('decks', 6), ('agreeing', 6), ('supplementary', 6), ('hoijer', 6), ('incredibly', 6), ('orthography', 6), ('coping', 6), ('schizophrenic', 6), ('totaled', 6), ('receptionist', 6), ('regression', 6), ('exemption', 6), ('earning', 6), ('compute', 6), ('deadline', 6), ('forgiven', 6), ('titan', 6), ('b-70', 6), ('repeal', 6), ('offset', 6), ('posed', 6), ('colleague', 6), ('registrant', 6), ('upheld', 6), ('nugent', 6), ('rebut', 6), ('mandate', 6), ('recommending', 6), ('hearings', 6), ('353', 6), ('aiding', 6), ('statute', 6), ('statutory', 6), ('export', 6), ('halt', 6), ('inter-american', 6), ('deliberations', 6), ('certified', 6), ('resistors', 6), ('ch', 6), ('centum', 6), ('facto', 6), ('taxing', 6), ('recover', 6), ('susie', 6), ('lillian', 6), ('1941', 6), ('jo', 6), ('szolds', 6), ('stark', 6), ('pendleton', 6), ('endowed', 6), ('editorials', 6), ('debates', 6), ('accelerating', 6), ('adlai', 6), ('publisher', 6), ('buckley', 6), ('presidency', 6), ('communicative', 6), ('hears', 6), ('misunderstanding', 6), ('restrictive', 6), ('broadcasting', 6), ('moriarty', 6), ('hinted', 6), ('conventions', 6), ('sherlock', 6), ('morals', 6), ('discomfort', 6), ('mounting', 6), ('accumulated', 6), ('cargo', 6), ('interdependent', 6), ('penetrating', 6), ('aristotle', 6), ('causal', 6), ('rationale', 6), ('bubbles', 6), ('newcomers', 6), ('insulation', 6), ('interdependence', 6), ('assimilation', 6), ('recruitment', 6), ('mobility', 6), ('cautious', 6), ('fran', 6), ('out-of-town', 6), ('paradigm', 6), ('immature', 6), ('wander', 6), ('hungarian', 6), ('conflicts', 6), ('self-determination', 6), ('leyte', 6), ('custer', 6), ('villages', 6), ('concede', 6), ('1928', 6), ('cracking', 6), ('tenor', 6), ('fighter', 6), ('capone', 6), ('foe', 6), ('plantation', 6), ('bite', 6), ('wheat', 6), ('1815', 6), ('highlands', 6), ('cable', 6), ('destined', 6), ('syndicate', 6), ('anarchy', 6), ('paramount', 6), ('managing', 6), ('phrases', 6), ('commissions', 6), ('zoning', 6), ('tractor', 6), ('deciding', 6), ('toronto', 6), ('roaring', 6), ('restrained', 6), ('selfish', 6), ('sexually', 6), ('parenthood', 6), ('calderone', 6), ('tiger', 6), ('commanding', 6), ('expenditure', 6), ('promotional', 6), ('teen', 6), ('assigning', 6), ('concessions', 6), ('recreational', 6), ('vending', 6), ('negotiating', 6), ('premium', 6), ('continuation', 6), ('ketosis', 6), ('merchandising', 6), ('founder', 6), ('milligram', 6), ('references', 6), ('1819', 6), ('copenhagen', 6), ('arithmetic', 6), ('specially', 6), ('sonar', 6), ('wavelengths', 6), ('logs', 6), ('inspiring', 6), ('withdrew', 6), ('weekends', 6), ('sportsmen', 6), ('fishermen', 6), ('strengthened', 6), ('landmarks', 6), ('stretches', 6), ('sonatas', 6), ('divinity', 6), ('suspicions', 6), ('dialect', 6), ('innumerable', 6), ('socially', 6), ('expectation', 6), ('endlessly', 6), ('raucous', 6), ('pre-war', 6), ('wandering', 6), ('dessert', 6), ('upside', 6), ('ideology', 6), ('spotlight', 6), ('dramas', 6), ('co', 6), ('uniformed', 6), ('observance', 6), ('journalist', 6), ('pretended', 6), ('pompeii', 6), ('vines', 6), ('surveyed', 6), ('streetcar', 6), ('thinner', 6), ('elders', 6), ('leveled', 6), ('harness', 6), ('complain', 6), ('feminine', 6), ('earthmen', 6), ('surviving', 6), ('bazaar', 6), ('siberia', 6), ('setup', 6), ('bishops', 6), ('verse', 6), ('domes', 6), ('hello', 6), ('kidding', 6), ('bonner', 6), ('outsiders', 6), ('screens', 6), ('forgetting', 6), ('hardy', 6), ('fingerprint', 6), ('apron', 6), ('alley', 6), ('fried', 6), ('chambre', 6), ('fille', 6), ('clocks', 6), ('turkey', 6), ('ledger', 6), ('middle-aged', 6), ('hotter', 6), ('granny', 6), ('floods', 6), ('drafting', 6), ('tribune', 6), ('herald', 6), ('smoked', 6), ('dammit', 6), ('mast', 6), ('casually', 6), ('ribbons', 6), ('twin', 6), ('ominous', 6), ('album', 6), ('olive', 6), ('izaak', 6), ('maple', 6), ('cling', 6), ('receipts', 6), ('admire', 6), ('veil', 6), ('frail', 6), ('swayed', 6), ('rope', 6), ('sucking', 6), ('blindly', 6), ('banner', 6), ('yearning', 6), ('careless', 6), ('challenging', 6), ('worlds', 6), ('danced', 6), ('beckoned', 6), ('arrange', 6), ('seasonal', 6), ('tedious', 6), ('fletcher', 6), ('hound', 6), ('stumbling', 6), ('clamped', 6), ('grabski', 6), ('excitedly', 6), ('romans', 6), ('zion', 6), ('colonies', 6), ('stranded', 6), ('drilling', 6), ('plank', 6), ('overboard', 6), ('martha', 6), ('high-pitched', 6), ('goodbye', 6), ('flames', 6), ('maestro', 6), ('announcing', 6), ('thirties', 6), ('accidental', 6), ('anchored', 6), ('old-fashioned', 6), ('shorts', 6), ('junk', 6), ('duplication', 6), ('buffet', 6), ('mahogany', 6), ('likelihood', 6), ('unlocked', 6), ('scandal', 6), ('betrayed', 6), ('fireplace', 6), ('warming', 6), ('sipping', 6), ('shoved', 6), ('mose', 6), ('mollie', 6), ('rails', 6), ('affirm', 6), ('needles', 6), ('guiding', 6), ('flourished', 6), ('longed', 6), ('favre', 6), ('jake', 6), ('soaked', 6), ('heavens', 6), ('lexington', 6), ('militia', 6), ('pants', 6), ('paces', 6), ('musket', 6), ('redcoat', 6), ('gunfire', 6), ('regulars', 6), ('pretend', 6), ('chocolate', 6), ('duclos', 6), ('rameau', 6), ('pleading', 6), ('operetta', 6), ('annoyed', 6), ('surged', 6), ('comin', 6), ('slater', 6), ('fucken', 6), ('trailed', 6), ('tenants', 6), ('bolt', 6), ('taller', 6), ('outdoors', 6), ('wiping', 6), ('boom', 6), ('bong', 6), ('winked', 6), ('frantically', 6), ('weeping', 6), ('stunned', 6), ('debts', 6), ('notch', 6), ('sleepy', 6), ('bothering', 6), ('flour', 6), ('errand', 6), ('lamps', 6), ('eventual', 6), ('flatly', 6), ('huts', 6), ('saloons', 6), ('declining', 6), ('coldly', 6), ('disliked', 6), ('defy', 6), ('joys', 6), ('placid', 6), ('accent', 6), ('medal', 6), ('booth', 6), ('scent', 6), ('calmed', 6), ('wandered', 6), ('perilous', 6), ('peninsula', 6), ('guts', 6), ('pilgrimage', 6), ('glowed', 6), ('beaming', 6), ('peering', 6), ('flattered', 6), ('tangle', 6), ('awaiting', 6), ('smoothed', 6), ('exhaust', 6), ('absently', 6), ('pardon', 6), ('distaste', 6), ('mock', 6), ('bleak', 6), ('cathedral', 6), ('anxiously', 6), ('cookies', 6), ('jumping', 6), ('gazed', 6), ('damaged', 6), ('rotor', 6), ('needless', 6), ('straining', 6), ('discernible', 6), ('pipes', 6), ('odors', 6), ('wastes', 6), ('hp', 6), ('120', 6), ('midwest', 6), ('integrity', 6), ('detached', 6), ('bodily', 6), ('pasted', 6), ('cubist', 6), ('1912', 6), ('commend', 6), ('propriety', 6), ('admitting', 6), ('enclosure', 6), ('turner', 6), ('sentenced', 6), ('misleading', 6), ('successors', 6), ('separating', 6), ('monastic', 6), ('possessions', 6), ('preoccupation', 6), ('sixteenth', 6), ('co-operative', 6), ('phones', 6), ('assistants', 6), ('supervisor', 6), ('bacon', 6), ('oranges', 6), ('vice-president', 6), ('aaron', 6), ('orvis', 6), ('junction', 6), ('thirty-five', 6), ('manuel', 6), ('interpreter', 6), ('winding', 6), ('bluff', 6), ('ambush', 6), ('marcus', 6), ('suspense', 6), ('pels', 6), ('feather', 6), ('creep', 6), ('decoration', 6), ('abundant', 6), ('plagued', 6), ('unlimited', 6), ('shores', 6), ('appreciated', 6), ('spiritually', 6), ('makers', 6), ('blot', 6), ('attained', 6), ('invested', 6), ('merry', 6), ('inmates', 6), ('contended', 6), ('pathetic', 6), ('traps', 6), ('backing', 6), ('u.n.f.p.', 6), ('des', 6), ('morocco', 6), ('strife', 6), ('busily', 6), ('fostered', 6), ('empirical', 6), ('sanction', 6), ('consensus', 6), ('denominational', 6), ('genuinely', 6), ('economies', 6), ('boldly', 6), ('introducing', 6), ('inscribed', 6), ('choices', 6), ('coin', 6), (\"bull's-eyes\", 6), ('augmented', 6), ('lessened', 6), ('topic', 6), ('creativity', 6), ('elicited', 6), ('removing', 6), ('dilution', 6), ('pseudophloem', 6), ('dowex-2-chloride', 6), ('invaded', 6), ('scars', 6), ('congestion', 6), ('microscopically', 6), ('posterior', 6), ('stepping', 6), ('fibrosis', 6), ('depart', 6), ('pierce', 6), ('potent', 6), ('1922', 6), ('greer', 6), ('antithyroid', 6), ('robbins', 6), ('simulated', 6), ('coupled', 6), ('generating', 6), ('iodinated', 6), ('appendix', 6), ('simplify', 6), ('shortened', 6), ('clarified', 6), ('ossification', 6), ('slowing', 6), ('arrows', 6), ('assessments', 6), ('sexes', 6), ('comprise', 6), ('incidence', 6), ('conclusively', 6), ('1931', 6), ('airways', 6), ('anastomoses', 6), ('pleural', 6), ('pleura', 6), ('septa', 6), ('carcass', 6), ('boa', 6), ('attaining', 6), ('kills', 6), ('deposit', 6), ('larvae', 6), ('deposited', 6), ('hollow', 6), ('agglutinin', 6), ('mixing', 6), ('alternately', 6), ('min', 6), ('rh', 6), ('chromatography', 6), ('artificially', 6), ('450', 6), ('disseminated', 6), ('organism', 6), ('lapse', 6), ('airborne', 6), ('manning', 6), ('meteorite', 6), ('intersect', 6), ('calibration', 6), ('sensors', 6), ('micrometeorite', 6), ('meteoritic', 6), ('vicinity', 6), ('captured', 6), ('illumination', 6), ('endeavor', 6), ('scratched', 6), ('filtered', 6), ('extracted', 6), ('78', 6), ('proportional', 6), ('activation', 6), ('dispersed', 6), ('ions', 6), ('outward', 6), ('micelle', 6), ('liquids', 6), ('sticky', 6), ('inorganic', 6), ('soiled', 6), ('grey', 6), ('advertised', 6), ('induction', 6), ('relaxation', 6), ('gases', 6), ('unsatisfactory', 6), ('broadening', 6), ('spherical', 6), ('appreciably', 6), ('elastic', 6), ('characterization', 6), ('manometer', 6), ('calculation', 6), ('decreased', 6), ('95', 6), ('spacing', 6), ('summarized', 6), ('68', 6), ('meters', 6), ('burke', 6), ('originate', 6), ('amplitude', 6), ('detection', 6), ('distances', 6), ('outlined', 6), ('establishments', 6), ('seattle', 6), ('inventories', 6), ('voluntarily', 6), ('publicized', 6), ('undertook', 6), ('gossip', 6), ('melancholy', 6), ('ambulance', 6), ('addressing', 6), ('venice', 6), ('marched', 6), ('highroad', 6), ('anecdote', 6), ('breakthrough', 6), ('shrewd', 6), ('quivering', 6), ('amusement', 6), ('compound', 6), ('insofar', 6), ('prevails', 6), ('modify', 6), ('manipulate', 6), ('fond', 6), ('resemble', 6), ('innovation', 6), ('induce', 6), ('unaware', 6), ('strides', 6), ('immunity', 6), ('internally', 6), ('leisure', 6), ('inferior', 6), ('therein', 6), ('marking', 6), ('arising', 6), ('favors', 6), ('hypocrisy', 6), ('simpler', 6), ('puzzling', 6), ('bourbons', 6), ('employing', 6), ('succeeding', 6), ('axe', 6), ('unpopular', 6), ('analyst', 6), ('esprit', 6), ('illiterate', 6), ('cohesion', 6), ('focal', 6), ('disguised', 6), ('hastened', 6), ('contracted', 6), ('licensed', 6), ('intake', 6), ('tuberculosis', 6), ('hesitate', 6), ('notorious', 6), ('reich', 6), ('patent', 6), ('wonders', 6), ('flashing', 6), ('quackery', 6), ('confinement', 6), ('kidney', 6), ('counterpart', 6), ('metaphysical', 6), ('rays', 6), ('recalling', 6), ('flooring', 6), ('abbey', 6), ('amazement', 6), ('uphold', 6), ('enlarge', 6), ('designing', 6), ('decorations', 6), ('versus', 6), ('workshops', 6), ('acquaintance', 6), ('architects', 6), ('extremes', 6), ('beginnings', 6), ('tricks', 6), ('lessening', 6), ('disappointing', 6), ('eighty', 6), ('accidents', 6), ('proven', 6), ('horizontal', 6), ('athletes', 6), ('slopes', 6), ('preference', 6), ('reservoir', 6), ('vastly', 6), ('photos', 6), ('selections', 6), ('cleaner', 6), ('frantic', 6), ('pacing', 6), ('classics', 6), ('multiplied', 6), ('lyrical', 6), ('cite', 6), ('regret', 6), ('attire', 6), ('interpretations', 6), ('dual', 6), ('acids', 6), ('abundance', 6), ('oily', 6), ('blossoms', 6), ('frost', 6), ('diluted', 6), ('mulch', 6), ('ventilation', 6), ('strains', 6), ('pansy', 6), ('enormously', 6), ('squat', 6), ('contraction', 6), ('symmetry', 6), ('wins', 6), ('benches', 6), ('weider', 6), ('bodybuilder', 6), ('theologian', 6), ('borne', 6), ('obey', 6), ('dominion', 6), ('mortal', 6), ('oyster', 6), ('similitude', 6), ('eternity', 6), ('descent', 6), ('willed', 6), ('immigrants', 6), ('clergymen', 6), ('kindly', 6), ('cambridge', 6), ('myriad', 6), ('persecution', 6), ('mapping', 6), ('260', 6), ('mornings', 6), ('segment', 6), ('reminder', 6), ('utmost', 6), ('tide', 6), ('urging', 6), ('exclude', 6), ('formulate', 6), ('strive', 6), ('modernity', 6), ('squarely', 6), ('preach', 6), ('smug', 6), ('solace', 6), ('demythologization', 6), ('recruits', 6), ('integral', 6), ('analyze', 6), ('accounting', 6), ('elemental', 6), ('marvel', 6), ('expresses', 6), ('entity', 6), ('seriousness', 6), ('enlightened', 6), ('dispelled', 6), ('sterling', 6), ('tin', 6), ('rides', 6), ('bounce', 6), ('rousing', 6), ('berman', 6), ('unsuccessful', 6), ('jam', 6), ('portrayal', 6), ('stamped', 6), ('kings', 6), ('meticulously', 6), ('alas', 6), ('librarians', 6), ('guarantees', 6), ('moods', 6), ('tennis', 6), ('reproduced', 6), ('co-operation', 6), ('channels', 6), ('introduce', 6), ('discriminating', 6), ('essays', 6), ('glimpse', 6), ('prolonged', 6), ('armstrong', 6), ('soloists', 6), ('episodes', 6), ('grotesque', 6), ('conveyed', 6), ('bony', 6), ('gracious', 6), ('relegated', 6), ('ironic', 6), ('relish', 6), ('pageant', 6), ('castle', 6), ('longing', 6), ('irresponsible', 6), ('trades', 6), ('semi', 6), ('abstractions', 6), ('booking', 6), ('soprano', 6), ('casts', 6), ('tunes', 6), ('dazzling', 6), ('glittering', 6), ('ashore', 6), ('nikita', 6), ('parliament', 6), ('hanged', 6), ('lenin', 6), ('escort', 6), ('refusing', 6), ('volunteer', 6), ('1700', 6), ('sixty-five', 6), ('footsteps', 6), ('chairmen', 6), ('angrily', 6), ('obstacles', 6), ('circus', 6), ('paired', 6), ('inexpensive', 6), ('presentations', 6), ('productions', 6), ('interviewing', 6), ('glands', 6), ('steam', 6), ('brushing', 6), ('margins', 6), ('brighter', 6), ('crisp', 6), ('oval', 6), ('blend', 6), ('heel', 6), ('stacked', 6), ('textures', 6), ('oats', 6), ('possessing', 6), ('spelled', 6), ('professionals', 6), ('51', 6), ('sensational', 6), ('notre', 6), ('bats', 6), ('heed', 6), ('provisional', 6), ('floated', 6), ('echoes', 6), ('strewn', 6), ('hooked', 6), ('winner', 6), ('bernard', 6), ('graham', 6), ('sutherland', 6), ('buck', 6), ('succeeds', 6), ('finale', 6), ('rulers', 6), ('rocky', 6), ('spahn', 6), ('traveler', 6), ('liston', 6), ('olympic', 6), ('reflexes', 6), ('pop', 6), ('victories', 6), ('tagged', 6), ('exotic', 6), ('infield', 6), ('clicked', 6), ('leagues', 6), ('offense', 6), ('comforting', 6), ('collectors', 6), ('opener', 6), ('kelsey', 6), ('stops', 6), ('coaching', 6), ('prevailed', 6), ('touchdown', 6), ('39', 6), ('135', 6), ('undergo', 6), ('kerr', 6), ('glen', 6), ('colts', 6), ('workout', 6), ('49', 6), ('freshman', 6), ('86', 6), ('scoring', 6), ('pitches', 6), ('popped', 6), ('whitey', 6), ('375', 6), ('milwaukee', 6), ('breeding', 6), ('sullivan', 6), ('oriole', 6), ('62', 6), ('clarence', 6), ('chapman', 6), ('collins', 6), ('pending', 6), ('revision', 6), ('retarded', 6), ('enlarged', 6), ('ponies', 6), ('stake', 6), ('con', 6), ('permitting', 6), ('300000', 6), ('contention', 6), ('enact', 6), ('protests', 6), ('veiled', 6), ('expended', 6), ('endorse', 6), ('87', 6), ('intends', 6), ('reconstruction', 6), ('vandiver', 6), ('resignation', 6), ('resigned', 6), ('requesting', 6), ('1937', 6), ('ne', 6), ('ala.', 6), ('1913', 6), ('criticisms', 6), ('proportionate', 6), ('outgoing', 6), ('implementation', 6), ('remedy', 6), ('catatonia', 7), ('kodyke', 7), ('kruger', 7), ('hirey', 7), ('perrin', 7), ('brandywine', 7), ('quadric', 7), ('sixty-one', 7), ('hereunto', 7), ('whereof', 7), ('plantations', 7), ('cunningham', 7), ('agrarian', 7), ('bruckner', 7), ('mahler', 7), ('frankfurt', 7), ('squall', 7), ('jelke', 7), ('orgasm', 7), ('montpelier', 7), ('burlington', 7), ('jig', 7), ('franks', 7), ('sophia', 7), ('tablespoons', 7), ('resin', 7), ('tallyho', 7), ('30.3', 7), ('faber', 7), ('piston', 7), ('cylinders', 7), ('reconnaissance', 7), ('yin', 7), ('clerfayt', 7), ('marinas', 7), ('galaxies', 7), ('rodgers', 7), ('schiele', 7), ('mao', 7), ('connally', 7), ('terraces', 7), ('bless', 7), ('subscribers', 7), ('coloring', 7), ('exports', 7), ('tshombe', 7), ('augusta', 7), ('gait', 7), ('colmer', 7), ('staffs', 7), ('dictator', 7), ('anti-communist', 7), ('lounge', 7), ('appliances', 7), ('leavitt', 7), ('tim', 7), ('desegregation', 7), ('fidel', 7), ('05', 7), ('cta', 7), ('stewart', 7), ('simpson', 7), ('bermuda', 7), ('putt', 7), ('chef', 7), ('motels', 7), ('marr', 7), ('en', 7), ('geraghty', 7), ('wendell', 7), ('engaging', 7), ('plea', 7), ('probation', 7), ('berger', 7), ('hoover', 7), ('petty', 7), ('forum', 7), ('martinelli', 7), ('recipient', 7), ('cease-fire', 7), ('levy', 7), ('dugout', 7), ('shafer', 7), ('boast', 7), ('heiser', 7), ('somers', 7), ('warmly', 7), ('inauguration', 7), ('turtle', 7), ('donovan', 7), ('jungle', 7), ('gyp', 7), ('teamsters', 7), ('carpet', 7), ('holster', 7), ('fleeing', 7), ('mullins', 7), ('willings', 7), ('precinct', 7), ('dad', 7), ('momentous', 7), ('typewriter', 7), ('waving', 7), ('hysterical', 7), ('emile', 7), ('katharine', 7), ('earnestly', 7), ('1917', 7), ('morphophonemic', 7), ('vowel', 7), ('luggage', 7), ('hebephrenic', 7), ('intensive', 7), ('classroom', 7), ('rated', 7), ('69', 7), ('computation', 7), ('housekeeping', 7), ('appropriations', 7), ('handles', 7), ('yugoslav', 7), ('discretion', 7), ('symposium', 7), ('inspiration', 7), ('kern', 7), ('collaborated', 7), ('mailed', 7), ('coarse', 7), ('ellen', 7), ('bankruptcy', 7), ('forensic', 7), ('shylock', 7), ('mails', 7), ('partnership', 7), ('abolish', 7), ('assuring', 7), ('statutes', 7), ('logically', 7), ('replacing', 7), ('drifting', 7), ('solving', 7), ('warriors', 7), ('revive', 7)]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "little script on semcor_lexicon to see where we should cut off most and least frequent\n",
    "\"\"\"\n",
    "\n",
    "print(semcor_lexicon.most_common(200))\n",
    "n = 30000\n",
    "print(semcor_lexicon.most_common()[:-n-1:-1])\n",
    "\n",
    "# we want to keep words with a count < 600\n",
    "\n",
    "# and with a count greater than > 10 (which is knocking off the l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of sentences:\n",
      "37176\n",
      "number of tokens:\n",
      "820411\n",
      "number of types:\n",
      "38642\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "get basic semcor stats\n",
    "\"\"\"\n",
    "print(\"number of sentences:\")\n",
    "print(len(sents))\n",
    "print(\"number of tokens:\")\n",
    "print(len(words))\n",
    "print(\"number of types:\")\n",
    "print(len(semcor_lexicon))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Create Token Index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Next step is to create an index of all of the tokens of a single lemma. \n",
    "So, we build a data structure with all of the word forms found in semcor. With each word form,\n",
    "we store a list of all of the sentences containing it.\n",
    "\"\"\"\n",
    "word_index = {}\n",
    "sense_index = {}\n",
    "\n",
    "semcor_indices = list(range(0,len(sents)))\n",
    "#print(semcor_indices)\n",
    "random.shuffle(semcor_indices)\n",
    "#print(semcor_indices)\n",
    "\n",
    "\n",
    "# go through the dataset sentence by sentence\n",
    "for random_index in semcor_indices:\n",
    "    sent = tagged_sents[random_index]\n",
    "    #sentence_id = int(sent.num)\n",
    "    sentence_id = random_index\n",
    "    \n",
    "    # go through each sentence word by word\n",
    "    for word in sent:\n",
    "        senses = get_senses_in_tagged_sentence(tagged_sents[1])\n",
    "        for sense in senses:\n",
    "            # if this is our first time seeing this word, add it to the index and put the sentence id in the entry\n",
    "            if sense not in word_index:\n",
    "                word_index[sense] = {sentence_id}\n",
    "            # otherwise, add the sentence id to the entry for the word\n",
    "            else:\n",
    "                word_index[sense].add(sentence_id)\n",
    "        \n",
    "#     # we need to make sure we are collecting only those tokens which have semcor senses, or we make note of which ones do\n",
    "    \n",
    "#         # if this is our first time seeing this word, add it to the index and put the sentence id in the entry\n",
    "#         if word not in word_index:\n",
    "#             word = word.lower()\n",
    "#             word_index[word] = {sentence_id}\n",
    "#         # otherwise, add the sentence id to the entry for the word\n",
    "#         else:\n",
    "#             word_index[word].add(sentence_id)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(Lemma('jury.n.01.jury'), {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19}), (Lemma('far.r.02.far'), {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19}), (Lemma('state.v.01.say'), {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19}), (Lemma('term.n.02.term'), {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19}), (Lemma('end.n.02.end'), {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19}), (Lemma('presentment.n.01.presentment'), {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19}), (Lemma('group.n.01.group'), {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19}), (Lemma('own.v.01.have'), {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19}), (Lemma('overall.s.02.overall'), {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19}), (Lemma('mission.n.03.charge'), {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19}), (Lemma('election.n.01.election'), {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19}), (Lemma('deserve.v.01.deserve'), {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19}), (Lemma('praise.n.01.praise'), {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19}), (Lemma('thanks.n.01.thanks'), {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19}), (Lemma('location.n.01.location'), {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19}), (Lemma('manner.n.01.manner'), {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19}), (Lemma('conduct.v.01.conduct'), {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19})]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "let's take a look at it\n",
    "\"\"\"\n",
    "print(list(word_index.items())[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['v']"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "render1 = wn.lemma('render.v.07.return')\n",
    "# render2 = wn.lemma('return.v.01.return')\n",
    "\n",
    "# \"\"\"\n",
    "# importnt point about nltk wordnet lemmas. their representation is confusing so be careful. i think equals or differentequals are implmementd in\n",
    "# unsuspected ways, because you get issues where they dont act like their display name\n",
    "# \"\"\"\n",
    "\n",
    "# dixt = {str(render1): \"foo\"}\n",
    "# dixt[str(render2)] = \"bar\"\n",
    "# print(dixt)\n",
    "\n",
    "\n",
    "# dixt = {str(render1): \"foo\"}\n",
    "# dixt[str(render2)] = \"bar\"\n",
    "# print(dixt)\n",
    "\n",
    "re.findall(r\"\\.(.*?)\\.\", 'render.v.07.return')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collecting tokens for  performances\n",
      "indices:    {25991, 31625, 15755, 26635, 31631, 1042, 2458, 1056, 32674, 301, 1722, 26301, 1726, 25663, 11198, 26559, 22092, 26317, 26335, 26976, 26344, 26473, 26352, 22385, 37116}\n",
      "dict_items([(\"Lemma('performance.n.02.performance')\", 3), (\"Lemma('performance.n.03.performance')\", 1), (\"Lemma('performance.n.01.performance')\", 3)])\n",
      "collecting tokens for  assured\n",
      "indices:    {23296, 36224, 16898, 910, 20370, 31763, 31764, 2199, 26009, 22042, 24091, 25759, 2594, 30758, 15148, 14263, 9144, 31320, 25051, 25447, 26473, 7403, 26352, 18547, 20085, 11127}\n",
      "dict_items([(\"Lemma('assure.v.03.assure')\", 5), (\"Lemma('guarantee.v.02.assure')\", 5), (\"Lemma('assure.v.02.assure')\", 5), (\"Lemma('reassure.v.01.assure')\", 1), (\"Lemma('assured.s.01.assured')\", 2), (\"Lemma('promise.v.01.assure')\", 1), (\"Lemma('assured.s.02.assured')\", 1), (\"Lemma('see.v.10.assure')\", 1)])\n",
      "collecting tokens for  informal\n",
      "indices:    {22598, 11432, 22729, 25418, 14059, 13356, 13357, 27852, 26352, 34260, 22612, 22645, 26391, 32951}\n",
      "dict_items([(\"Lemma('informal.a.01.informal')\", 3), (\"Lemma('informal.s.02.informal')\", 1)])\n",
      "collecting tokens for  board\n",
      "indices:    {6042}\n",
      "dict_items([])\n",
      "collecting tokens for  inquiry\n",
      "indices:    {27264, 33091, 16195, 33060, 14633, 12908, 5214, 19356, 16222}\n",
      "dict_items([(\"Lemma('inquiry.n.01.inquiry')\", 4), (\"Lemma('inquiry.n.03.inquiry')\", 2)])\n",
      "collecting tokens for  called\n",
      "indices:    {26631, 8745, 30253, 33838, 28725, 3637, 12355, 12362, 7758, 12370, 17491, 11877, 12396, 3205, 17543, 26247, 14477, 37012, 25237, 12441, 29339, 27295, 24223, 14505, 169, 31916, 25774, 22702, 36531, 29386, 21194, 17612, 5326, 36561, 22738, 17620, 27350, 26330, 35550, 2282, 25834, 10487, 21753, 20222, 7425, 28419, 24327, 6919, 14089, 25356, 18713, 10522, 21789, 36128, 37160, 20777, 4394, 25915, 13124, 10565, 7494, 24903, 35161, 5979, 26979, 26980, 27492, 7012, 6505, 29034, 36215, 4472, 9599, 19840, 28544, 20356, 36229, 1925, 11145, 4496, 33686, 19864, 27560, 26027, 30637, 17331, 21434, 11707, 4549, 20430, 26071, 8156, 7654, 7655, 10219, 7661, 10744, 29178, 32764}\n",
      "dict_items([(\"Lemma('shout.v.02.call')\", 8), (\"Lemma('name.v.01.call')\", 17), (\"Lemma('call.v.05.call')\", 8), (\"Lemma('call.v.03.call')\", 9), (\"Lemma('visit.v.03.call')\", 3), (\"Lemma('call.v.08.call')\", 1), (\"Lemma('call.v.02.call')\", 3), (\"Lemma('call.v.07.call')\", 1)])\n",
      "collecting tokens for  look\n",
      "indices:    {6023, 31920, 17043, 14646, 19066, 7738, 26975}\n",
      "dict_items([(\"Lemma('expression.n.01.look')\", 1), (\"Lemma('look.n.02.look')\", 1), (\"Lemma('look.v.01.look')\", 1), (\"Lemma('look.v.02.look')\", 1)])\n",
      "collecting tokens for  charges\n",
      "indices:    {15107, 12934, 15114, 21260, 32529, 12439, 1955, 21412, 21539, 32553, 21676, 21688, 23353, 23927, 30911, 25923, 25924, 20677, 26829, 26830, 23895, 21347, 2787, 12643, 22760, 28010, 12908, 2542, 2543, 20724, 37110, 2551, 3193}\n",
      "dict_items([(\"Lemma('charge.n.03.charge')\", 3), (\"Lemma('charge.v.02.charge')\", 1), (\"Lemma('charge.n.02.charge')\", 7), (\"Lemma('charge.n.07.charge')\", 1), (\"Lemma('charge.n.04.charge')\", 1)])\n",
      "collecting tokens for  against\n",
      "indices:    {11648, 640, 25858, 21635, 33796, 35204, 33668, 27782, 20746, 26636, 34316, 31502, 18703, 17423, 34061, 25613, 23311, 2709, 14230, 28053, 21657, 3226, 32027, 27804, 22812, 17948, 14242, 25763, 12962, 5287, 10536, 27946, 17578, 28076, 4784, 15281, 36018, 2483, 21692, 28093, 25790, 33852, 24896, 30785, 2496, 20291, 12609, 12229, 31172, 14973, 24259, 3402, 339, 30804, 597, 18134, 35926, 33493, 601, 24281, 27739, 5852, 21346, 2661, 14950, 13929, 13930, 27753, 18796, 28398, 22640, 21752, 18428, 27261, 11134}\n",
      "dict_items([])\n",
      "collecting tokens for  men\n",
      "indices:    {35137, 865, 15465}\n",
      "dict_items([(\"Lemma('man.n.01.man')\", 1)])\n",
      "collecting tokens for  seen\n",
      "indices:    {7693, 13, 7700, 30741, 3609, 13342, 33851, 8252, 16444, 31805, 1603, 8773, 8774, 16455, 8268, 28748, 14426, 32860, 11362, 30834, 6263, 29308, 640, 12422, 30351, 23698, 14999, 36507, 11422, 4278, 5818, 30908, 3783, 3784, 3818, 26859, 24572, 14060, 29934, 33526, 6912, 7430, 9995, 17685, 3862, 26914, 28963, 25893, 24360, 24366, 15662, 22321, 1338, 19771, 33603, 33611, 9548, 26959, 4948, 4949, 29018, 27997, 15712, 1376, 30567, 3434, 13674, 18285, 30575, 22385, 36722, 891, 3452, 35709, 35198, 2431, 4992, 18309, 1416, 17800, 8074, 15763, 28053, 27033, 16285, 10142, 27564, 11698, 32195, 32196, 7119, 7120, 26588, 9697, 2020, 7145, 36842, 33258, 13808, 19441, 12784, 1018, 25595, 3580, 8703}\n",
      "dict_items([(\"Lemma('watch.v.03.see')\", 4), (\"Lemma('see.v.01.see')\", 26), (\"Lemma('learn.v.02.see')\", 5), (\"Lemma('visualize.v.01.see')\", 2), (\"Lemma('witness.v.02.see')\", 22), (\"Lemma('see.v.05.see')\", 6), (\"Lemma('determine.v.08.see')\", 4), (\"Lemma('understand.v.02.see')\", 3), (\"Lemma('meet.v.01.see')\", 5), (\"Lemma('see.v.11.see')\", 1), (\"Lemma('visit.v.01.see')\", 2)])\n",
      "collecting tokens for  leave\n",
      "indices:    {27266, 34277, 34939, 15191, 35183, 35248, 18065, 16497, 8590, 5111, 3189, 21206, 17591, 2363, 17626, 17595, 36734, 14943}\n",
      "dict_items([(\"Lemma('leave.v.02.leave')\", 4), (\"Lemma('leave.v.08.leave')\", 1), (\"Lemma('leave.v.03.leave')\", 1), (\"Lemma('leave.v.01.leave')\", 5), (\"Lemma('leave.n.02.leave')\", 1), (\"Lemma('exit.v.01.leave')\", 1), (\"Lemma('leave_behind.v.01.leave_behind')\", 1), (\"Lemma('leave.v.04.leave')\", 2)])\n",
      "collecting tokens for  officer\n",
      "indices:    {15336, 32366, 30291, 24148, 15414}\n",
      "dict_items([(\"Lemma('officeholder.n.01.officer')\", 1)])\n",
      "collecting tokens for  heard\n",
      "indices:    {26626, 26627, 19460, 34309, 12804, 7685, 18952, 22537, 22539, 7693, 34319, 33808, 25105, 17945, 34331, 7203, 7207, 1065, 7215, 10803, 8249, 35903, 24643, 17989, 33862, 8266, 2123, 8782, 6739, 35925, 33885, 21606, 12908, 9844, 118, 30330, 26749, 6279, 9352, 19595, 21645, 11918, 12441, 36509, 24225, 26280, 18093, 21680, 21681, 30390, 6841, 19137, 6339, 20169, 13003, 14540, 4815, 7376, 34511, 14044, 9951, 22754, 24291, 18660, 17638, 6888, 6890, 747, 33516, 6383, 6896, 7409, 755, 9459, 19702, 37112, 763, 20225, 34059, 9995, 13073, 36628, 28437, 6420, 4887, 5914, 22301, 26397, 35615, 8485, 6442, 12587, 6445, 17709, 26417, 9011, 21300, 21301, 7479, 19259, 24384, 10055, 10056, 9547, 18252, 9549, 10573, 11087, 18770, 26968, 20832, 17769, 17770, 18287, 18288, 12661, 11131, 34174, 36223, 26496, 26497, 1412, 26502, 35213, 914, 17303, 20378, 12188, 17820, 6566, 18860, 6579, 11191, 33727, 31168, 8642, 32195, 18373, 19913, 2506, 8138, 10701, 6606, 15825, 5081, 24538, 7648, 7147, 26605, 1520, 5109, 2552, 36345, 18429}\n",
      "dict_items([(\"Lemma('hear.v.03.hear')\", 7), (\"Lemma('hear.v.01.hear')\", 26), (\"Lemma('learn.v.02.hear')\", 26), (\"Lemma('hear.v.04.hear')\", 3)])\n",
      "collecting tokens for  suggest\n",
      "indices:    {12933, 21905, 26777, 24104, 5032, 3760, 15664, 25144, 7611, 24893, 11721, 14156, 16079, 14415, 23805, 27105, 2147, 3837, 12010, 9718, 24574, 24568, 25725, 25854}\n",
      "dict_items([(\"Lemma('indicate.v.05.suggest')\", 5), (\"Lemma('propose.v.01.suggest')\", 8), (\"Lemma('suggest.v.05.suggest')\", 4), (\"Lemma('suggest.v.03.suggest')\", 4), (\"Lemma('hint.v.01.suggest')\", 3)])\n",
      "collecting tokens for  wounded\n",
      "indices:    {8512, 6913, 35587, 5798, 4903, 12870, 12871, 5068, 12908, 9582, 5936, 30385, 5938, 35603, 30388, 35637, 30390, 35636}\n",
      "dict_items([(\"Lemma('injure.v.01.wound')\", 4), (\"Lemma('hurt.s.01.wounded')\", 9)])\n",
      "collecting tokens for  left\n",
      "indices:    {25730, 12872, 36296, 25613, 32366, 19793, 23348, 33462, 21046, 11036}\n",
      "dict_items([(\"Lemma('left.a.01.left')\", 1), (\"Lemma('leave.v.02.leave')\", 1), (\"Lemma('leave.v.04.leave')\", 1), (\"Lemma('leave.v.11.leave')\", 1), (\"Lemma('bequeath.v.01.leave')\", 1), (\"Lemma('leave.v.01.leave')\", 1)])\n",
      "collecting tokens for  sioux\n",
      "indices:    {35494}\n",
      "dict_items([])\n",
      "collecting tokens for  refused\n",
      "indices:    {10625, 34434, 32003, 26885, 22925, 24851, 21270, 8476, 11037, 7070, 7074, 36899, 15780, 16932, 15778, 15781, 15783, 18220, 6829, 9650, 23731, 14534, 31815, 15305, 28620, 5069, 7380, 15575, 11992, 9177, 471, 11999, 12255, 12385, 5088, 5094, 12649, 12907, 12908, 36978}\n",
      "dict_items([(\"Lemma('refuse.v.01.refuse')\", 26), (\"Lemma('deny.v.04.refuse')\", 1), (\"Lemma('refuse.v.02.refuse')\", 7), (\"Lemma('defy.v.02.refuse')\", 2)])\n",
      "collecting tokens for  say\n",
      "indices:    {13688, 7685, 11015, 14988, 5646, 8590, 25105, 1306, 12059, 29212, 12064, 6056, 28202, 18603, 13228, 17842, 31155, 14645, 17847, 14398, 1216, 1728, 23749, 15814, 19911, 19912, 28102, 27461, 17227, 17485, 14671, 26447, 27089, 1497, 5721, 22239, 24290, 28261, 14182, 21991, 28265, 33400, 4845, 16749, 17263, 10352, 4336, 2546, 4852, 30709, 8693, 30711, 36216, 37117, 4858, 4859, 636, 36605, 19327}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('allege.v.01.say')\", 15), (\"Lemma('state.v.01.say')\", 26), (\"Lemma('suppose.v.01.say')\", 3)])\n",
      "collecting tokens for  harsh\n",
      "indices:    {20234, 12267, 12908, 27088, 18642, 36051, 2551, 28411}\n",
      "dict_items([(\"Lemma('harsh.s.02.harsh')\", 2), (\"Lemma('harsh.s.01.harsh')\", 2)])\n",
      "collecting tokens for  word\n",
      "indices:    {10633, 23851, 26448, 17847, 28380}\n",
      "dict_items([(\"Lemma('word.n.01.word')\", 2)])\n",
      "collecting tokens for  showed\n",
      "indices:    {4097, 3586, 3588, 4103, 17928, 4108, 4111, 4117, 4118, 3100, 3102, 1055, 3114, 3115, 4152, 26170, 4155, 24125, 3137, 8259, 14407, 584, 10315, 32845, 4182, 35928, 3164, 34911, 4199, 27249, 3713, 651, 19089, 27288, 17562, 5283, 4261, 14503, 37031, 26791, 4268, 37037, 9903, 19635, 10932, 6846, 25280, 31457, 6888, 21231, 31472, 37107, 33526, 28407, 13579, 18715, 36644, 19253, 6966, 4921, 17723, 27975, 18760, 13131, 10573, 2388, 18786, 28003, 26477, 21871, 5493, 375, 887, 30590, 2947, 36239, 2971, 3996, 12699, 35746, 12196, 15786, 7595, 4021, 33208, 3514, 29115, 15296, 34761, 4044, 16846, 17358, 4058, 5594, 35294, 4065, 9707, 3566, 4088, 4090, 3070}\n",
      "dict_items([(\"Lemma('testify.v.02.show')\", 13), (\"Lemma('show.v.01.show')\", 26), (\"Lemma('show.v.08.show')\", 5), (\"Lemma('express.v.01.show')\", 9), (\"Lemma('show.v.04.show')\", 10), (\"Lemma('indicate.v.02.show')\", 7), (\"Lemma('prove.v.02.show')\", 7), (\"Lemma('read.v.08.show')\", 4), (\"Lemma('show.v.10.show')\", 1)])\n",
      "collecting tokens for  shower\n",
      "indices:    {19114, 9388, 9389, 19116, 19087, 8752, 30289, 19089, 9393, 26933, 30199, 734}\n",
      "dict_items([(\"Lemma('shower.n.01.shower')\", 3), (\"Lemma('shower.n.02.shower')\", 4), (\"Lemma('shower.v.03.shower')\", 1), (\"Lemma('shower.v.02.shower')\", 1)])\n",
      "collecting tokens for  tub\n",
      "indices:    {35072, 14529, 11424, 7489, 7492, 19089, 7422}\n",
      "dict_items([(\"Lemma('bathtub.n.01.tub')\", 6)])\n",
      "collecting tokens for  smiling\n",
      "indices:    {8453, 36613, 5767, 10248, 7691, 10905, 10907, 9246, 17694, 19748, 12841, 6582, 10937, 6475, 36704, 33507, 7785, 28395, 1521, 5626}\n",
      "dict_items([(\"Lemma('smile.v.01.smile')\", 16), (\"Lemma('beamish.s.01.smiling')\", 2), (\"Lemma('smile.n.01.smiling')\", 1)])\n",
      "collecting tokens for  really\n",
      "indices:    {16481, 17733, 30665, 20620, 11729, 34962, 9204, 2587}\n",
      "dict_items([(\"Lemma('truly.r.01.really')\", 5)])\n",
      "collecting tokens for  mind\n",
      "indices:    {35200, 28165, 30215, 31111, 20107, 17023, 10000, 35870, 34339, 22563, 34725, 24357, 17701, 33708, 30253, 33711, 11698, 12980, 1335, 33340, 9538, 30659, 14408, 17754, 9186, 10340, 9575, 13676, 10348, 19823, 34799, 14452, 1269, 7542, 13558, 10618, 35967}\n",
      "dict_items([(\"Lemma('mind.n.02.mind')\", 2), (\"Lemma('take_care.v.02.mind')\", 1), (\"Lemma('mind.v.01.mind')\", 2), (\"Lemma('mind.n.01.mind')\", 13), (\"Lemma('judgment.n.01.mind')\", 1)])\n",
      "collecting tokens for  think\n",
      "indices:    {27392, 24322, 9604, 14596, 16774, 16775, 19596, 31120, 16785, 9491, 34964, 15382, 31767, 19734, 33945, 35482, 33179, 15391, 23457, 31909, 34854, 27816, 297, 33708, 10413, 4915, 22451, 5687, 33340, 19907, 19524, 9668, 19959, 25542, 31688, 853, 8663, 8024, 25816, 16856, 220, 27102, 34655, 1120, 13282, 11241, 36076, 10608, 31223, 7800, 8317}\n",
      "dict_items([(\"Lemma('think.v.01.think')\", 14), (\"Lemma('think.v.03.think')\", 6), (\"Lemma('think.v.02.think')\", 17), (\"Lemma('think.v.05.think')\", 1), (\"Lemma('think.v.06.think')\", 1)])\n",
      "collecting tokens for  'll\n",
      "indices:    {19456, 13313, 33282, 13316, 19973, 6662, 23047, 19975, 18441, 7691, 10764, 5647, 6672, 1556, 19476, 17940, 23064, 35869, 35358, 33313, 20011, 17963, 36909, 20013, 20015, 11821, 561, 35378, 35379, 17460, 36405, 1589, 8760, 5689, 569, 35899, 33337, 18493, 1598, 5693, 1600, 6721, 33346, 29250, 5700, 580, 33350, 33351, 6728, 19016, 28744, 18505, 18508, 29254, 11851, 29263, 16979, 29268, 16981, 34006, 16473, 20062, 5728, 9313, 22115, 10345, 18028, 29292, 34417, 1652, 19572, 33398, 6775, 15992, 8314, 636, 33918, 642, 16519, 16520, 33929, 33415, 8327, 18567, 18061, 7309, 9870, 19089, 1684, 20117, 1685, 19096, 19097, 35484, 17056, 5793, 10401, 18596, 16037, 19109, 20135, 10407, 18089, 33450, 30889, 18602, 10415, 16559, 33457, 18607, 36537, 21184, 33985, 35521, 14529, 10434, 33989, 9922, 33991, 35522, 29890, 8393, 19149, 35027, 35030, 35031, 16599, 8409, 218, 34011, 18140, 8413, 35550, 35551, 19680, 28897, 35554, 25826, 18148, 31465, 14570, 16620, 36086, 19191, 9976, 19195, 33534, 34047, 35584, 19710, 9984, 35075, 19711, 36606, 35078, 9985, 29448, 27401, 266, 35076, 33548, 35085, 29454, 36623, 35087, 31502, 35093, 18712, 19736, 291, 10019, 8998, 18216, 18217, 10025, 10027, 16689, 10034, 29491, 36147, 10035, 29496, 17725, 318, 36670, 17729, 34627, 18687, 36165, 326, 35143, 323, 325, 34122, 35148, 18766, 35073, 36180, 6484, 12118, 12119, 36694, 36186, 9052, 36701, 350, 9567, 36192, 36704, 36702, 36190, 10085, 13157, 12134, 9065, 18794, 11113, 33642, 19821, 12653, 19820, 35184, 12141, 33652, 11126, 10614, 36221, 11136, 10112, 21384, 10121, 16782, 35900, 6546, 10131, 6547, 405, 13206, 24470, 6550, 34201, 6554, 18500, 36253, 30110, 24479, 22433, 9124, 31653, 35239, 9128, 19880, 24489, 34216, 9127, 17837, 9137, 8113, 29105, 8116, 34229, 20920, 36281, 30136, 36280, 6587, 35773, 24505, 9658, 20928, 20931, 36292, 6601, 34252, 20942, 30159, 30673, 30161, 35285, 30166, 35287, 34265, 27101, 9694, 20448, 20961, 20451, 20452, 19941, 35301, 20453, 34280, 34279, 17900, 6125, 1518, 30191, 20469, 19446, 30199, 36351}\n",
      "dict_items([])\n",
      "collecting tokens for  get\n",
      "indices:    {8071, 10892, 20237, 37138, 405, 27034, 8228, 11943, 6570, 27434, 10413, 5687, 25144, 10937, 16571, 17729, 30659, 9029, 20041, 30540, 16718, 17749, 35286, 9052, 19299, 33893, 20069, 36071, 27881, 33641, 17010, 19066, 34428}\n",
      "dict_items([(\"Lemma('become.v.01.get')\", 3), (\"Lemma('receive.v.02.get')\", 1), (\"Lemma('lower.v.01.get_down')\", 1), (\"Lemma('arrive.v.01.get')\", 3), (\"Lemma('catch_sight.v.01.get_a_look')\", 1), (\"Lemma('get.v.01.get')\", 8), (\"Lemma('get.v.03.get')\", 3), (\"Lemma('bring.v.04.get')\", 3)])\n",
      "collecting tokens for  clean\n",
      "indices:    {28624, 5116, 29663}\n",
      "dict_items([(\"Lemma('clean.v.01.clean')\", 1)])\n",
      "collecting tokens for  few\n",
      "indices:    {11880, 2057, 31027, 28513}\n",
      "dict_items([(\"Lemma('few.a.01.few')\", 1)])\n",
      "collecting tokens for  minutes\n",
      "indices:    {27653, 23301, 22921, 33418, 8590, 36884, 25237, 28571, 34462, 23328, 31394, 31266, 29221, 30248, 4137, 36649, 24619, 4139, 4144, 23345, 37049, 21180, 24381, 21183, 29890, 324, 34117, 17736, 29520, 20054, 29536, 28521, 21754, 34171, 26876}\n",
      "dict_items([(\"Lemma('minute.n.01.minute')\", 4), (\"Lemma('moment.n.02.minute')\", 1)])\n",
      "collecting tokens for  expressed\n",
      "indices:    {15456, 25441, 8898, 25893, 4872, 14632, 1465, 301, 5137, 16020, 4854, 1335, 31993, 31578}\n",
      "dict_items([(\"Lemma('carry.v.04.express')\", 3), (\"Lemma('expressed.s.01.expressed')\", 3), (\"Lemma('express.v.02.express')\", 4), (\"Lemma('express.v.01.express')\", 4)])\n",
      "collecting tokens for  interest\n",
      "indices:    {23432, 15242, 14224, 32277, 1430, 14455, 12186, 4773, 15275, 23098, 24896, 9668, 12358, 20432, 1878, 11478, 6104, 11482, 15582, 5215, 2785, 24164, 5606, 1772, 3054, 17012, 37108, 28663, 30718, 20991}\n",
      "dict_items([(\"Lemma('interest.n.01.interest')\", 12), (\"Lemma('interest.n.04.interest')\", 3), (\"Lemma('sake.n.01.interest')\", 4), (\"Lemma('interest.n.03.interest')\", 1)])\n",
      "collecting tokens for  world\n",
      "indices:    {31920, 20771, 34574}\n",
      "dict_items([])\n",
      "collecting tokens for  affairs\n",
      "indices:    {20771}\n",
      "dict_items([])\n",
      "collecting tokens for  offered\n",
      "indices:    {16898, 17413, 1031, 30475, 33676, 9359, 26640, 20754, 20755, 9240, 30233, 1439, 21024, 35746, 2042, 36899, 21282, 24740, 21928, 6825, 19753, 9389, 22831, 2735, 23986, 36022, 12343, 30520, 7357, 19774, 66, 28355, 7364, 24775, 5068, 26956, 28110, 31695, 27214, 36346, 15739, 26965, 35290, 12124, 33246, 28384, 2784, 3682, 23394, 13154, 17122, 26464, 5479, 22889, 1770, 4715, 23147, 23152, 14962, 7414, 35962, 23803, 27900}\n",
      "dict_items([(\"Lemma('offer.v.01.offer')\", 26), (\"Lemma('offer.v.06.offer')\", 2), (\"Lemma('volunteer.v.02.offer')\", 8), (\"Lemma('offer.v.07.offer')\", 1), (\"Lemma('offer.v.02.offer')\", 13), (\"Lemma('offer.v.05.offer')\", 1), (\"Lemma('offer.v.04.offer')\", 3), (\"Lemma('offer.v.08.offer')\", 1)])\n",
      "collecting tokens for  make\n",
      "indices:    {10633, 25266, 29523, 19639, 34079}\n",
      "dict_items([(\"Lemma('make.v.19.make')\", 1), (\"Lemma('make.v.03.make')\", 1), (\"Lemma('induce.v.02.make')\", 1), (\"Lemma('do.v.08.make')\", 1), (\"Lemma('make.v.01.make')\", 1)])\n",
      "collecting tokens for  satisfy\n",
      "indices:    {14629, 4616, 23532, 27244, 4364, 4655, 31695, 27406, 4661, 22614, 11703, 6811, 19391}\n",
      "dict_items([(\"Lemma('meet.v.04.satisfy')\", 6), (\"Lemma('satisfy.v.01.satisfy')\", 6), (\"Lemma('satisfy.v.02.satisfy')\", 1)])\n",
      "collecting tokens for  therefore\n",
      "indices:    {10192}\n",
      "dict_items([(\"Lemma('therefore.r.01.therefore')\", 1)])\n",
      "collecting tokens for  wardrobe\n",
      "indices:    {23104, 2698, 694, 22459, 22076, 22077, 17599}\n",
      "dict_items([(\"Lemma('wardrobe.n.01.wardrobe')\", 2), (\"Lemma('wardrobe.n.02.wardrobe')\", 1)])\n",
      "collecting tokens for  largely\n",
      "indices:    {21378, 25732, 20615, 22664, 24073, 33032, 15499, 11660, 5389, 27150, 27534, 5392, 5393, 22284, 281, 16154, 27420, 12197, 27316, 15479, 22076, 15735, 33089, 28101, 15179, 26188, 16075, 16464, 27856, 28663, 33111, 17369, 29146, 473, 25561, 21865, 31850, 15853, 13165, 6255, 27888, 2035, 2036, 13175, 26360, 15484, 6141, 25726}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('largely.r.01.largely')\", 23)])\n",
      "collecting tokens for  mobile\n",
      "indices:    {23693, 13351, 28458, 28459, 28463, 28470, 13367, 28473, 22076, 28477, 28478, 28480, 34762, 28509, 31596, 28525, 34671, 26742, 32380}\n",
      "dict_items([(\"Lemma('mobile.s.01.mobile')\", 2)])\n",
      "collecting tokens for  packed\n",
      "indices:    {1698, 33378, 3077, 21358, 9326, 34127, 27921, 30899, 30419, 4120, 22076, 1534, 17535}\n",
      "dict_items([(\"Lemma('pack.v.01.pack')\", 6), (\"Lemma('pack.v.03.pack')\", 2), (\"Lemma('pack_on.v.01.pack_on')\", 1), (\"Lemma('jammed.s.01.packed')\", 1), (\"Lemma('pack.v.02.pack')\", 1)])\n",
      "collecting tokens for  moment\n",
      "indices:    {25603, 25604, 35847, 10764, 18449, 35347, 36888, 6170, 21531, 35870, 6177, 24098, 1058, 31267, 5672, 1576, 23096, 33850, 3131, 22076, 8253, 33359, 33363, 2132, 2645, 36952, 26713, 2652, 33373, 34404, 25700, 26215, 17000, 7273, 2664, 2160, 35444, 18037, 17013, 33912, 30330, 10368, 1155, 20100, 34438, 13447, 18569, 11916, 5773, 31886, 8847, 25747, 29335, 17048, 5271, 20120, 8348, 17053, 16030, 17572, 8362, 29355, 34988, 27825, 6322, 8884, 24758, 23741, 36030, 13506, 14535, 35015, 35529, 17100, 5837, 31440, 18640, 24795, 8412, 5858, 34019, 18659, 24805, 9970, 34036, 17655, 5369, 18171, 7420, 19200, 13057, 26882, 24328, 7946, 6923, 6922, 34061, 34065, 28434, 6931, 36628, 26389, 34069, 17171, 22809, 34074, 8473, 17184, 5409, 35622, 21802, 27434, 23852, 24376, 16703, 32068, 14154, 11090, 14676, 7519, 2399, 35679, 7525, 7526, 7529, 19306, 32108, 14702, 7537, 11126, 11641, 18810, 19326, 9598, 11140, 9617, 19361, 35745, 33701, 7592, 7598, 19888, 9651, 10677, 31674, 17855, 9152, 9162, 9676, 1486, 34767, 36310, 12762, 33760, 33251, 36323, 9189, 17382, 9191, 3046, 12262, 10730, 25578, 15851, 3048, 3052, 5612, 7147, 25588, 25592, 27644}\n",
      "dict_items([(\"Lemma('moment.n.01.moment')\", 26), (\"Lemma('moment.n.02.moment')\", 26), (\"Lemma('here_and_now.n.01.moment')\", 1)])\n",
      "collecting tokens for  notice\n",
      "indices:    {901, 26891, 3603, 6166, 5663, 12076, 20270, 33967, 17334, 2745, 36287, 19660, 7503, 33494, 9177, 24538, 19679, 27489, 22115, 29923, 30565, 17133, 17011, 14969}\n",
      "dict_items([(\"Lemma('detect.v.01.notice')\", 7), (\"Lemma('notice.n.06.notice')\", 1), (\"Lemma('notice.n.04.notice')\", 1), (\"Lemma('notice.v.02.notice')\", 8), (\"Lemma('notification.n.03.notice')\", 1), (\"Lemma('notice.n.01.notice')\", 2)])\n",
      "collecting tokens for  shake\n",
      "indices:    {12064, 19235, 10916, 8106, 24458, 28140, 9008, 10931, 22516, 5813, 19413, 22076}\n",
      "dict_items([(\"Lemma('shake.v.05.shake')\", 2), (\"Lemma('rock.v.01.shake')\", 2), (\"Lemma('judder.v.01.shake')\", 1), (\"Lemma('shake.v.01.shake')\", 2), (\"Lemma('shake.v.07.shake')\", 1), (\"Lemma('shake.v.02.shake')\", 2)])\n",
      "collecting tokens for  without\n",
      "indices:    {11388, 22563, 34428, 5606}\n",
      "dict_items([])\n",
      "collecting tokens for  thoroughly\n",
      "indices:    {16130, 11148, 25361, 25752, 11294, 11296, 28582, 551, 11313, 14386, 29492, 29636, 17748, 29782, 26072, 29410, 14821, 29545, 6639, 14959}\n",
      "dict_items([(\"Lemma('thoroughly.r.01.thoroughly')\", 7), (\"Lemma('thoroughly.r.02.thoroughly')\", 4)])\n",
      "collecting tokens for  modern\n",
      "indices:    {27266, 31240, 12940, 17165, 23442, 25370, 1316, 26566, 14027, 1745, 20823, 19555, 14691, 23139, 5225, 31853, 15470, 13040, 17407}\n",
      "dict_items([(\"Lemma('modern.a.01.modern')\", 7), (\"Lemma('advanced.s.03.modern')\", 1), (\"Lemma('modern.n.01.modern')\", 1), (\"Lemma('mod.s.01.modern')\", 1)])\n",
      "collecting tokens for  treatment\n",
      "indices:    {24960, 30979, 4164, 32904, 11529, 32714, 2218, 11596, 30989, 26219, 2220, 5489, 2228, 24408, 32890, 30427, 31068, 23640}\n",
      "dict_items([(\"Lemma('treatment.n.01.treatment')\", 5), (\"Lemma('treatment.n.02.treatment')\", 2)])\n",
      "collecting tokens for  same\n",
      "indices:    {20545, 12641, 12615, 15022, 2158, 33232, 5744, 21937, 12915, 25430, 5367, 4950, 7738, 6012}\n",
      "dict_items([(\"Lemma('same.a.02.same')\", 4), (\"Lemma('same.a.01.same')\", 3), (\"Lemma('like.a.02.same')\", 1)])\n",
      "collecting tokens for  full\n",
      "indices:    {21893, 21253, 11143, 19335, 23435, 34061, 23950, 13587, 12826, 9628, 2076, 12574, 9759, 3490, 11301, 3877, 29866, 14891, 34481, 30513, 17588, 11325, 15554, 22978, 15171, 29128, 585, 28619, 11468, 23379, 30804, 26325, 20186, 20059, 23009, 21991, 13676, 16374, 8311, 28543}\n",
      "dict_items([(\"Lemma('entire.s.01.full')\", 7), (\"Lemma('full.a.01.full')\", 8), (\"Lemma('full.s.03.full')\", 3)])\n",
      "collecting tokens for  simple\n",
      "indices:    {32259, 32771, 32775, 2060, 21011, 25621, 26136, 11291, 14369, 2593, 26661, 4646, 29753, 22074, 30779, 27201, 13899, 32843, 34384, 11349, 13397, 14435, 6763, 5230, 14959, 31856, 2675, 11382, 35966, 29823, 35967, 23169, 2690, 29827, 11395, 25221, 35974, 26247, 20108, 22677, 28312, 22680, 27808, 11433, 3244, 14522, 28860, 28862, 7361, 16066, 24262, 4810, 31449, 16098, 16100, 14574, 17135, 29426, 26362, 4867, 779, 28428, 29454, 16144, 5397, 13622, 16188, 25412, 15174, 4939, 4940, 36179, 8023, 4966, 15720, 15721, 2428, 4990, 7039, 2432, 4481, 5001, 27531, 5008, 2448, 29074, 24465, 15763, 18327, 5023, 17825, 5026, 1958, 2987, 18352, 30147, 15825, 12756, 32222, 28640, 15847, 16363, 10219, 7149, 12781, 1007, 3054, 28660, 25078}\n",
      "dict_items([(\"Lemma('simple.a.01.simple')\", 26), (\"Lemma('bare.s.06.simple')\", 3), (\"Lemma('elementary.s.01.simple')\", 8)])\n",
      "collecting tokens for  sincerity\n",
      "indices:    {15329, 27138, 16355, 28385, 1188, 27269, 28329, 14574, 26639, 26586}\n",
      "dict_items([(\"Lemma('sincerity.n.02.sincerity')\", 2), (\"Lemma('sincerity.n.03.sincerity')\", 1), (\"Lemma('earnestness.n.01.sincerity')\", 1)])\n",
      "collecting tokens for  invariably\n",
      "indices:    {10880, 36233, 37130, 18316, 13969, 3221, 1564, 29212, 6045, 28063, 34598, 26920, 24624, 25649, 31281, 26179, 37073, 2392, 27877, 32358, 2661, 14574, 6769, 17909, 13180}\n",
      "dict_items([(\"Lemma('constantly.r.01.invariably')\", 12)])\n",
      "collecting tokens for  genuine\n",
      "indices:    {20231, 14215, 25744, 27289, 14368, 33184, 16045, 2350, 9145, 20668, 2371, 33219, 22602, 33358, 27733, 2647, 32216, 13657, 26849, 4580, 1766, 27110, 14574, 1520, 26099, 23669}\n",
      "dict_items([(\"Lemma('genuine.a.01.genuine')\", 6), (\"Lemma('genuine.s.02.genuine')\", 4), (\"Lemma('actual.s.03.genuine')\", 2)])\n",
      "collecting tokens for  negro\n",
      "indices:    {13739}\n",
      "dict_items([(\"Lemma('negro.s.01.negro')\", 1)])\n",
      "collecting tokens for  means\n",
      "indices:    {36992, 14721, 25475, 3974, 4487, 905, 30089, 27788, 27789, 12306, 28178, 15382, 2327, 2326, 1306, 1307, 24220, 14365, 5411, 20645, 1318, 27560, 32936, 14763, 14638, 27439, 16432, 177, 3889, 2227, 15415, 27832, 10811, 13117, 16446, 18367, 32967, 712, 25039, 3664, 11217, 22738, 13138, 24567, 26197, 23382, 5336, 601, 1243, 2651, 12765, 28509, 3678, 14176, 23904, 25057, 32236, 13040, 25331, 28532, 24182, 26231, 20216, 5245}\n",
      "dict_items([(\"Lemma('entail.v.01.mean')\", 10), (\"Lemma('means.n.02.means')\", 5), (\"Lemma('means.n.01.means')\", 14), (\"Lemma('mean.v.03.mean')\", 10), (\"Lemma('intend.v.01.mean')\", 1), (\"Lemma('mean.v.05.mean')\", 1), (\"Lemma('mean.v.01.mean')\", 1)])\n",
      "collecting tokens for  confused\n",
      "indices:    {32993, 1505, 2018, 25123, 15724, 14156, 5837, 13136, 13650, 10870, 14042, 6170, 4156, 8573}\n",
      "dict_items([(\"Lemma('broken.s.08.confused')\", 2), (\"Lemma('confuse.v.01.confuse')\", 5), (\"Lemma('confused.a.05.confused')\", 1), (\"Lemma('baffled.s.01.confused')\", 2), (\"Lemma('confused.s.03.confused')\", 1), (\"Lemma('confuse.v.02.confuse')\", 1), (\"Lemma('confused.s.02.confused')\", 1)])\n",
      "collecting tokens for  average\n",
      "indices:    {3345, 12178, 3738, 22428, 17182, 27168, 11936, 14242, 32294, 15017, 5550, 15022, 439, 30160, 15059, 11880, 19949, 11633, 16372}\n",
      "dict_items([(\"Lemma('average.s.01.average')\", 9), (\"Lemma('average.n.01.average')\", 1), (\"Lemma('average.s.02.average')\", 2), (\"Lemma('average.s.03.average')\", 1)])\n",
      "collecting tokens for  broadway\n",
      "indices:    {33369}\n",
      "dict_items([])\n",
      "collecting tokens for  depend\n",
      "indices:    {28675, 32016, 2974, 12962, 29859, 36136, 173, 12469, 12092, 32192, 30153, 15179, 29133, 11858, 23508, 23380, 13536, 25575, 25576, 25578, 4203, 14574, 17909, 30969, 12027}\n",
      "dict_items([(\"Lemma('depend.v.01.depend')\", 4), (\"Lemma('depend_on.v.01.depend_upon')\", 1), (\"Lemma('depend_on.v.01.depend_on')\", 1)])\n",
      "collecting tokens for  racial\n",
      "indices:    {27904, 27872, 27843, 32963, 13735, 27880, 169, 24426, 171, 4718, 27886, 24436, 24437, 24406, 2519, 27896, 2522, 31806}\n",
      "dict_items([(\"Lemma('racial.a.01.racial')\", 5), (\"Lemma('racial.a.02.racial')\", 1)])\n",
      "collecting tokens for  flavor\n",
      "indices:    {29479, 22155, 14574, 29487, 31538, 29266, 212, 26322, 1721, 21818, 1692, 1693}\n",
      "dict_items([(\"Lemma('spirit.n.02.flavor')\", 3), (\"Lemma('relish.n.03.flavor')\", 2)])\n",
      "collecting tokens for  upon\n",
      "indices:    {6336, 27841, 25890, 24899, 30596, 24742, 14855, 27848, 4490, 24970, 36013, 2158, 27343, 14224, 12689, 14643, 25238, 25081}\n",
      "dict_items([])\n",
      "collecting tokens for  amen\n",
      "indices:    {6042}\n",
      "dict_items([])\n",
      "collecting tokens for  corner\n",
      "indices:    {4487, 1289, 4489, 4496, 31121, 4498, 8339, 10388, 4500, 4502, 4499, 9369, 17818, 6042, 33564, 15134, 6047, 24352, 9632, 6046, 17827, 37028, 18469, 13606, 33960, 33961, 1196, 15152, 5176, 1977, 8505, 31547, 9151, 33728, 6082, 9414, 33737, 457, 35404, 29389, 7889, 35410, 31187, 8532, 35413, 34902, 4569, 12634, 4571, 20447, 18272, 13539, 10596, 13541, 15206, 19555, 20071, 14187, 17772, 34798, 31599, 369, 371, 28789, 12537, 33018}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('corner.n.02.corner')\", 9), (\"Lemma('corner.n.05.corner')\", 2), (\"Lemma('corner.n.01.corner')\", 10), (\"Lemma('corner.n.03.corner')\", 8), (\"Lemma('corner.n.04.corner')\", 6), (\"Lemma('recess.n.02.corner')\", 2), (\"Lemma('corner.n.07.corner')\", 1), (\"Lemma('corner_post.n.01.corner_post')\", 1), (\"Lemma('cut_corners.v.01.cut_corners')\", 1)])\n",
      "collecting tokens for  day\n",
      "indices:    {36961, 35939, 27461, 17926, 24777, 23536, 14615}\n",
      "dict_items([(\"Lemma('day.n.03.day')\", 1), (\"Lemma('day.n.01.day')\", 1)])\n",
      "collecting tokens for  gabriel\n",
      "indices:    {34339}\n",
      "dict_items([])\n",
      "collecting tokens for  horn\n",
      "indices:    {26618, 18244}\n",
      "dict_items([])\n",
      "collecting tokens for  devil\n",
      "indices:    {1273, 36236, 28287}\n",
      "dict_items([(\"Lemma('satan.n.01.Devil')\", 1)])\n",
      "collecting tokens for  random\n",
      "indices:    {15905, 4456, 22095, 16181, 5530, 4476}\n",
      "dict_items([(\"Lemma('random.a.01.random')\", 1), (\"Lemma('random-access_memory.n.01.random-access_memory')\", 1)])\n",
      "collecting tokens for  thrown\n",
      "indices:    {8577, 17674, 19346, 2710, 12453, 10536, 29105, 2358, 30903, 37047, 28736, 28738, 28739, 26053, 31176, 24779, 18002, 28371, 12639, 5859, 37101, 14574, 12663, 18943}\n",
      "dict_items([(\"Lemma('throw.v.01.throw')\", 8), (\"Lemma('throw.v.06.throw')\", 3), (\"Lemma('throw.v.04.throw')\", 2), (\"Lemma('bewilder.v.02.throw')\", 1), (\"Lemma('shed.v.01.throw')\", 1)])\n",
      "collecting tokens for  good\n",
      "indices:    {28675, 10629, 27782, 24837, 27786, 27789, 14484, 1813, 29205, 27801, 23193, 32028, 14364, 24865, 28961, 17700, 24742, 28968, 1087, 17472, 13759, 27073, 325, 25801, 21069, 15738, 6612, 30686, 25439, 26091, 2423, 19066, 27901}\n",
      "dict_items([(\"Lemma('good.a.01.good')\", 7), (\"Lemma('full.s.06.good')\", 1), (\"Lemma('well.r.01.good')\", 1), (\"Lemma('estimable.s.02.good')\", 1), (\"Lemma('good.s.09.good')\", 1)])\n",
      "collecting tokens for  measure\n",
      "indices:    {3329, 15266, 21797, 13256, 29673, 25322, 35692, 11726, 11388, 4722, 12917, 2422, 26102, 26361, 27545, 23420}\n",
      "dict_items([(\"Lemma('measure.v.04.measure')\", 1), (\"Lemma('measure.n.02.measure')\", 1), (\"Lemma('quantify.v.02.measure')\", 2), (\"Lemma('measure.v.01.measure')\", 2)])\n",
      "collecting tokens for  spoken\n",
      "indices:    {10209, 8173, 10606, 36369, 8884, 5656, 761, 32671}\n",
      "dict_items([(\"Lemma('talk.v.02.speak')\", 2), (\"Lemma('talk.v.01.speak')\", 2), (\"Lemma('spoken.a.01.spoken')\", 1), (\"Lemma('speak.v.03.speak')\", 1)])\n",
      "collecting tokens for  apparent\n",
      "indices:    {32897, 20485, 2825, 12297, 2827, 2828, 1806, 23567, 20247, 2970, 17307, 20256, 31521, 11426, 672, 16802, 2981, 22694, 30241, 20392, 30248, 28450, 16300, 18868, 2877, 20033, 27330, 16323, 9155, 31942, 2641, 12629, 36950, 26077, 16224, 33763, 9960, 26730, 24042, 4202, 31598}\n",
      "dict_items([(\"Lemma('apparent.s.02.apparent')\", 6), (\"Lemma('apparent.s.01.apparent')\", 14)])\n",
      "collecting tokens for  signal\n",
      "indices:    {17568, 9921, 260, 28745, 19343, 3125}\n",
      "dict_items([(\"Lemma('signal.n.01.signal')\", 3), (\"Lemma('sign.v.05.signal')\", 1)])\n",
      "collecting tokens for  given\n",
      "indices:    {4481, 15242, 20491, 3729, 3730, 3482, 33193, 28078, 4020, 13494, 34359, 27840, 20167, 25801, 1359, 1104, 13649, 18395, 24028, 33246, 27999, 14314, 16383}\n",
      "dict_items([(\"Lemma('impart.v.01.give')\", 1), (\"Lemma('give.v.04.give')\", 4), (\"Lemma('give.v.05.give')\", 2), (\"Lemma('give.v.01.give')\", 4), (\"Lemma('give.v.18.give')\", 1), (\"Lemma('give.v.20.give')\", 1), (\"Lemma('give.v.03.give')\", 2), (\"Lemma('yield.v.01.give')\", 1)])\n",
      "collecting tokens for  accident\n",
      "indices:    {21507, 21637, 21639, 34443, 26640, 2452, 31255, 27800, 21657, 27801, 27812, 14756, 23336, 10669, 25139, 18623, 19148, 21611, 4845, 10225, 10229, 20726, 2303}\n",
      "dict_items([(\"Lemma('accident.n.02.accident')\", 4), (\"Lemma('accident.n.01.accident')\", 5)])\n",
      "collecting tokens for  murder\n",
      "indices:    {13976, 19026, 17419, 36917}\n",
      "dict_items([(\"Lemma('murder.n.01.murder')\", 2)])\n",
      "collecting tokens for  suicide\n",
      "indices:    {27812, 13476, 36902, 28453, 21736, 36906, 19148, 24851, 27480, 2266, 23836}\n",
      "dict_items([(\"Lemma('suicide.n.01.suicide')\", 3)])\n",
      "collecting tokens for  take\n",
      "indices:    {17176, 19990}\n",
      "dict_items([(\"Lemma('consider.v.03.take')\", 1)])\n",
      "collecting tokens for  pick\n",
      "indices:    {13601, 9186, 20998, 29000, 20491, 25132, 19149, 28395, 17648, 9874, 28626, 33396, 28601}\n",
      "dict_items([(\"Lemma('pick.v.01.pick')\", 3), (\"Lemma('pick_up.v.02.pick_up')\", 2), (\"Lemma('pick_up.v.03.pick_up')\", 1), (\"Lemma('elate.v.01.pick_up')\", 1)])\n",
      "collecting tokens for  brought\n",
      "indices:    {28164, 29190, 11271, 12815, 26644, 10774, 10266, 20508, 27676, 1054, 13860, 2084, 1060, 41, 14381, 8242, 13875, 7732, 30777, 36421, 2632, 35914, 16459, 9296, 9297, 593, 36947, 5204, 22615, 14947, 11876, 4715, 4716, 14446, 8814, 10354, 6259, 26739, 25209, 8827, 25727, 10368, 8833, 27266, 3714, 24708, 27276, 9359, 22674, 2709, 32918, 2711, 1698, 674, 10416, 34992, 26803, 26804, 25784, 32440, 12474, 23224, 6332, 20159, 27839, 20673, 7361, 29383, 14544, 37074, 35539, 5332, 32468, 23256, 34012, 1246, 22752, 10981, 1254, 12520, 237, 10991, 13047, 7418, 35071, 24831, 26371, 35081, 25354, 20233, 18194, 14102, 8471, 30488, 14104, 34071, 22812, 34079, 16673, 36641, 4899, 16676, 9513, 17199, 3889, 315, 20796, 26429, 21308, 10052, 26951, 12626, 17749, 21336, 18264, 22874, 19803, 18268, 19807, 26977, 7522, 31587, 13155, 18277, 1382, 26476, 23405, 7029, 28533, 14713, 31097, 19324, 7551, 16273, 19349, 33174, 30102, 35230, 35234, 12195, 34210, 36265, 13739, 36269, 9646, 10672, 9147, 15804, 35772, 10684, 26557, 17344, 1482, 22988, 1997, 7629, 13776, 2002, 12754, 26580, 7636, 5081, 12250, 35808, 28643, 25061, 35815, 26087, 31723, 2031, 32252}\n",
      "dict_items([(\"Lemma('bring_up.v.05.bring_up')\", 1), (\"Lemma('bring.v.03.bring')\", 19), (\"Lemma('bring.v.01.bring')\", 26), (\"Lemma('bring.v.02.bring')\", 19), (\"Lemma('bring_oneself.v.01.bring_oneself')\", 1), (\"Lemma('bring.v.04.bring')\", 10), (\"Lemma('return.v.05.bring_back')\", 1), (\"Lemma('join.v.02.bring_together')\", 1), (\"Lemma('institute.v.02.bring')\", 3), (\"Lemma('bring.v.05.bring')\", 4), (\"Lemma('bring.v.06.bring')\", 2), (\"Lemma('raise.v.07.bring_up')\", 1), (\"Lemma('advance.v.05.bring_forward')\", 1), (\"Lemma('lower.v.01.bring_down')\", 1), (\"Lemma('fetch.v.02.bring_in')\", 1)])\n",
      "collecting tokens for  bed\n",
      "indices:    {19460, 18948, 26129, 5652, 5658, 27163, 16930, 5673, 5676, 5690, 5695, 1603, 6214, 35914, 35920, 5712, 7771, 8798, 5729, 8804, 36968, 1641, 8809, 5740, 5743, 25722, 22150, 2193, 11958, 3772, 13502, 11972, 9415, 19664, 3793, 29406, 16610, 24292, 30954, 19183, 12027, 3849, 35082, 3850, 20746, 35085, 12054, 12056, 35099, 9215, 10013, 36139, 36149, 31548, 3410, 17238, 17246, 30562, 9588, 10640, 17306, 30109, 26542, 34223, 8119, 8135, 16846, 16848, 16849, 7636, 16852, 36310, 5598, 36323, 7652, 7653, 29163, 5102, 5103, 7668, 5629, 5630, 18943}\n",
      "dict_items([(\"Lemma('bed.n.01.bed')\", 26), (\"Lemma('bed.n.03.bed')\", 1), (\"Lemma('bed.n.02.bed')\", 2)])\n",
      "collecting tokens for  sent\n",
      "indices:    {18447, 5141, 33305, 556, 8245, 35905, 12353, 36440, 28261, 28272, 119, 18560, 36481, 23683, 14987, 36494, 11408, 32403, 8339, 24222, 7845, 17576, 13994, 17579, 7852, 5308, 28352, 197, 21207, 10457, 23260, 12512, 15586, 14056, 14057, 32488, 18668, 11505, 8948, 25849, 23291, 8448, 33024, 23299, 20747, 36633, 29979, 23841, 23851, 5948, 22848, 23365, 840, 30551, 31580, 20331, 10614, 13187, 21398, 13722, 931, 10149, 36265, 14251, 7596, 6575, 17330, 22962, 6097, 5076, 5077, 21462, 22489, 13795, 7652, 14312, 35818, 36849, 14834}\n",
      "dict_items([(\"Lemma('send.v.01.send')\", 26), (\"Lemma('station.v.01.send')\", 3), (\"Lemma('mail.v.02.send')\", 11), (\"Lemma('commit.v.03.send')\", 3), (\"Lemma('send.v.02.send')\", 13), (\"Lemma('transport.v.04.send')\", 4), (\"Lemma('send.v.06.send')\", 2), (\"Lemma('air.v.03.send')\", 1)])\n",
      "collecting tokens for  hurried\n",
      "indices:    {9360, 18455, 35480, 9243, 33439, 9506, 7587, 27299, 16933, 5159, 2219, 5935, 7730, 33461, 7735, 35914, 34257, 18647, 35810, 31601, 9465}\n",
      "dict_items([(\"Lemma('travel_rapidly.v.01.hurry')\", 16), (\"Lemma('rush.v.04.hurry')\", 1), (\"Lemma('rush.v.03.hurry')\", 1), (\"Lemma('hurried.a.01.hurried')\", 1)])\n",
      "collecting tokens for  conferences\n",
      "indices:    {32730, 16124}\n",
      "dict_items([(\"Lemma('conference.n.01.conference')\", 1)])\n",
      "collecting tokens for  history\n",
      "indices:    {11264, 2309, 4988, 24843, 24703, 13464, 1436, 22685, 1454, 26671, 12206, 13874, 14392, 7227, 21693, 20415, 21570, 2244, 25159, 8395, 24018, 13782, 8414, 31711, 14691, 15462, 27499, 751, 21495, 20597, 32246, 23542, 2300, 32255}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('history.n.01.history')\", 8), (\"Lemma('history.n.04.history')\", 4), (\"Lemma('history.n.02.history')\", 3), (\"Lemma('history.n.05.history')\", 1), (\"Lemma('history.n.03.history')\", 2)])\n",
      "collecting tokens for  usefulness\n",
      "indices:    {2304, 31234, 16134, 16135, 16137, 24172, 12236, 22774}\n",
      "dict_items([(\"Lemma('utility.n.02.usefulness')\", 5)])\n",
      "collecting tokens for  nationalism\n",
      "indices:    {2296, 31235, 31236, 16420, 31224, 4632, 27753, 31245, 16430, 27731, 2294, 31222, 27736, 31227}\n",
      "dict_items([(\"Lemma('nationalism.n.02.nationalism')\", 2), (\"Lemma('patriotism.n.01.nationalism')\", 3)])\n",
      "collecting tokens for  territorial\n",
      "indices:    {16161, 27015, 31719, 31180, 31182, 31224}\n",
      "dict_items([(\"Lemma('territorial.a.01.territorial')\", 1)])\n",
      "collecting tokens for  rapidly\n",
      "indices:    {31234, 37125, 17545, 25737, 18833, 2837, 13334, 15515, 1533, 18467, 18855, 5544, 3500, 31025, 16434, 3634, 13108, 13365, 15158, 27954, 32313, 22714, 4793, 16316, 5568, 23621, 2631, 20553, 8907, 14164, 3415, 23513, 16354, 36067, 12518, 16489, 3307, 4593, 20466, 241, 37107, 34420, 22909, 3711}\n",
      "dict_items([(\"Lemma('quickly.r.01.rapidly')\", 26)])\n",
      "collecting tokens for  precisely\n",
      "indices:    {28003, 32838, 13735, 7304, 2634, 2123, 32876, 1325, 24625, 3922, 13046, 16383}\n",
      "dict_items([(\"Lemma('precisely.r.01.precisely')\", 5), (\"Lemma('precisely.r.02.precisely')\", 2)])\n",
      "collecting tokens for  highest\n",
      "indices:    {31234, 2818, 22018, 14468, 13319, 29328, 27537, 26907, 21276, 30750, 14751, 12965, 16425, 23081, 5418, 3245, 22704, 22707, 4664, 4665, 28604, 21436, 24636, 6847, 1213, 2244, 25030, 31433, 12746, 12749, 4689, 14034, 14038, 22877, 4577, 37097, 877, 31223, 12281}\n",
      "dict_items([(\"Lemma('eminent.s.01.high')\", 1), (\"Lemma('high.a.02.high')\", 2), (\"Lemma('high.a.01.high')\", 3)])\n",
      "collecting tokens for  number\n",
      "indices:    {11780, 16396, 17556, 15919, 22722, 4549, 3655, 25801, 21066, 27852, 20561, 33493, 4442, 9949, 27748, 4456, 2158, 32625, 15478, 3065, 16251, 4476}\n",
      "dict_items([(\"Lemma('number.n.01.number')\", 9), (\"Lemma('act.n.04.number')\", 1), (\"Lemma('number.n.08.number')\", 1), (\"Lemma('number.n.02.number')\", 2)])\n",
      "collecting tokens for  approximately\n",
      "indices:    {32480, 3264, 3139, 15465, 2858, 24970, 3439}\n",
      "dict_items([(\"Lemma('approximately.r.01.approximately')\", 5)])\n",
      "collecting tokens for  100\n",
      "indices:    {31234, 30742, 27167, 23090, 4149, 55, 23103, 4159, 30273, 21578, 27210, 1113, 21109, 14977, 15003, 12461, 15027, 22199, 32446, 12486, 32460, 15070, 32480, 21229, 11524, 15116, 20748, 29464, 23834, 21787, 21789, 21794, 21795, 21796, 16167, 23848, 2860, 11568, 821, 16183, 25399, 16189, 11584, 21327, 20836, 20839, 2919, 2926, 26991, 28528, 28527, 28526, 3443, 22901, 3452, 21884, 29059, 27019, 3982, 29073, 29078, 3999, 12706, 20389, 21419, 21931, 12719, 14776, 12728, 5066, 15314, 5076, 15317, 5077, 15319, 3541, 15327, 28640, 15334, 23538, 32761, 23034}\n",
      "dict_items([(\"Lemma('hundred.s.01.100')\", 26), (\"Lemma('hundred.n.01.100')\", 5)])\n",
      "collecting tokens for  because\n",
      "indices:    {3714, 23780, 36839, 13447, 3911, 10633, 174, 6738, 11411, 11508, 15478, 31386, 15704, 21210, 2587}\n",
      "dict_items([])\n",
      "collecting tokens for  children\n",
      "indices:    {30497, 25220, 15652, 9668, 7432, 15662, 36400, 24913, 30450, 23217, 23027, 3862, 8311, 33016, 20922, 10299, 12189}\n",
      "dict_items([(\"Lemma('child.n.01.child')\", 7), (\"Lemma('child.n.02.child')\", 1)])\n",
      "collecting tokens for  intensely\n",
      "indices:    {1155, 26405, 27112, 36239, 7536, 36436, 31607, 4188}\n",
      "dict_items([(\"Lemma('intensely.r.01.intensely')\", 3)])\n",
      "collecting tokens for  practicing\n",
      "indices:    {20768, 1602, 23300, 2280, 270, 2224, 272, 34355, 18870, 31607, 22202, 26234, 16060}\n",
      "dict_items([(\"Lemma('drill.v.03.practice')\", 3), (\"Lemma('rehearse.v.01.practice')\", 3), (\"Lemma('practice.v.01.practice')\", 4), (\"Lemma('practice.v.04.practice')\", 1)])\n",
      "collecting tokens for  composed\n",
      "indices:    {2178, 133, 20734, 32017, 3601, 27540, 11285, 4383, 6050, 4651, 3115, 26284, 4400, 4402, 4403, 26933, 3776, 26693, 12870, 8903, 4939, 2771, 5332, 2646, 2393, 4443, 31998, 27235, 13674, 31607, 2558}\n",
      "dict_items([(\"Lemma('compose.v.04.compose')\", 2), (\"Lemma('compose.v.01.compose')\", 14), (\"Lemma('composed.a.01.composed')\", 2), (\"Lemma('compose.v.02.compose')\", 3)])\n",
      "collecting tokens for  own\n",
      "indices:    {20480, 18437, 18440, 34827, 36879, 30735, 8210, 30741, 28698, 30749, 16415, 14368, 36897, 30752, 18467, 8237, 14391, 34878, 26687, 26686, 34881, 14406, 6215, 10314, 16463, 10320, 22613, 6230, 32853, 12376, 34905, 34907, 14428, 26715, 32870, 22632, 16492, 2158, 2159, 32883, 36979, 2166, 14454, 22649, 36986, 14459, 26750, 30850, 130, 26785, 2222, 2231, 18617, 6337, 22727, 8398, 22736, 30929, 22741, 12502, 37099, 14577, 14580, 6389, 6406, 37131, 16654, 20765, 8478, 20773, 37158, 24878, 313, 26940, 6462, 12608, 22853, 33101, 26964, 26966, 24918, 14688, 2401, 357, 22886, 10609, 22897, 31094, 29050, 31114, 31116, 33167, 31119, 33169, 35224, 31139, 31141, 24998, 29101, 16827, 33219, 20946, 27099, 20965, 4585, 8682, 27114, 35309, 2552, 4603, 27132, 33276, 25087, 27137, 18955, 23053, 23065, 4633, 4635, 21022, 2601, 25139, 4669, 4671, 6720, 12867, 12880, 23122, 2650, 23133, 23137, 17009, 4721, 8817, 2679, 4734, 2687, 14985, 23183, 12951, 6807, 17048, 27287, 17056, 17057, 23202, 33452, 27320, 25273, 8905, 715, 6873, 4832, 2785, 2787, 27365, 10989, 25339, 27388, 763, 4864, 4866, 6925, 27409, 19217, 25364, 793, 801, 802, 807, 11048, 29490, 29497, 15166, 23362, 838, 4937, 4944, 11089, 13143, 31582, 25442, 19303, 13160, 25451, 27504, 27507, 11125, 885, 11126, 31607, 4983, 15225, 35713, 15235, 13199, 912, 916, 25504, 15270, 33712, 25523, 35764, 25524, 949, 21439, 7113, 31692, 7116, 975, 7122, 19417, 19424, 13281, 23522, 19427, 9188, 25575, 11241, 11245, 7149, 11247, 9200, 9201, 31734, 31736, 11263, 7176, 23566, 21525, 11285, 25623, 31768, 11289, 1053, 5149, 13346, 25650, 23606, 7224, 15417, 19514, 23611, 29756, 5182, 15422, 25663, 19533, 13402, 23650, 13414, 1127, 23658, 17515, 25712, 25714, 13428, 9337, 25723, 29822, 31873, 29831, 27783, 7305, 13454, 33938, 13463, 1176, 31897, 36005, 23718, 19625, 17590, 27839, 36062, 27872, 31972, 17646, 7408, 23793, 25842, 11508, 23797, 13560, 36097, 17666, 15629, 15631, 15643, 1310, 27940, 29989, 23844, 34096, 13617, 32055, 36153, 19771, 30015, 32067, 25926, 25927, 23881, 30026, 13648, 23892, 32088, 15706, 11611, 1373, 34143, 13668, 30053, 36201, 5486, 19823, 11635, 36211, 9591, 1401, 11644, 32125, 23943, 36237, 34190, 32145, 21906, 7571, 34197, 28057, 13723, 15771, 15774, 13728, 1445, 1447, 1448, 32169, 36272, 19894, 32182, 30136, 32184, 1465, 32192, 36290, 26053, 32205, 28116, 21975, 5598, 32225, 32228, 15844, 36326, 15846, 21999, 26096, 30201, 36346, 32253, 26109, 7679, 36352, 7681, 30221, 5646, 32273, 7708, 34333, 36383, 11809, 26146, 22051, 28200, 5673, 13868, 30255, 30256, 17970, 36408, 30271, 34379, 1613, 34383, 7766, 26199, 9819, 9835, 7789, 32367, 32372, 32375, 5762, 13959, 13964, 24205, 13967, 18064, 5788, 13980, 13984, 24228, 11940, 5800, 13997, 28340, 7862, 32447, 1733, 7882, 5838, 7896, 7902, 30431, 20196, 36582, 28400, 32497, 3826, 36596, 32502, 12027, 3836, 5898, 14090, 26381, 32526, 24336, 18194, 5911, 12061, 12068, 28452, 18219, 26416, 12081, 12091, 36668, 26432, 18251, 10061, 1874, 1876, 22357, 16219, 14171, 14175, 16223, 12130, 8040, 18286, 14203, 16252, 26493, 14204, 6015, 32638, 6018, 34695, 20360, 10122, 32657, 14233, 14237, 14238, 14239, 18348, 1966, 34741, 14262, 26551, 36791, 26550, 34747, 8123, 26569, 12236, 34766, 24530, 30675, 12245, 26600, 10218, 6125, 18421, 16374, 10233, 16380}\n",
      "dict_items([(\"Lemma('own.s.01.own')\", 26), (\"Lemma('own.v.01.own')\", 14)])\n",
      "collecting tokens for  studies\n",
      "indices:    {14849, 14721, 16289, 14725, 3239, 14920, 2986, 4108, 3823, 3824, 33199, 30831, 14803, 32345, 33050, 32891, 14748, 3006}\n",
      "dict_items([(\"Lemma('survey.n.01.study')\", 12), (\"Lemma('study.n.02.study')\", 1)])\n",
      "collecting tokens for  perhaps\n",
      "indices:    {36208, 23666}\n",
      "dict_items([])\n",
      "collecting tokens for  child\n",
      "indices:    {13824, 21511, 12, 8744, 8745, 8248, 34876, 35901, 2634, 13388, 19534, 27215, 32857, 31836, 7261, 18020, 2661, 2665, 24546, 7275, 17016, 35962, 32892, 32893, 32894, 16003, 5763, 32907, 32908, 26773, 35993, 13476, 23207, 30400, 20173, 9439, 2276, 21222, 8423, 9456, 36082, 20211, 20210, 13557, 33014, 36087, 22267, 8445, 8446, 22275, 30980, 30981, 12037, 781, 782, 15631, 15632, 30989, 30997, 30999, 3864, 31002, 15643, 15642, 31006, 3870, 3872, 800, 14627, 31013, 17705, 811, 15663, 15664, 31026, 15668, 3892, 3894, 3893, 13119, 3907, 32067, 15687, 15691, 15692, 15693, 15694, 31063, 31065, 31066, 15707, 12636, 15708, 31071, 31073, 15715, 15717, 15718, 31077, 7529, 29034, 15723, 15724, 15725, 35182, 15728, 7544, 2438, 2439, 22414, 1934, 1941, 9622, 31150, 8630, 1467, 24519, 24520, 1992, 24526, 23504, 24529, 24530, 24533, 2007, 36825, 15840, 24544, 7650, 7651, 24548, 2019, 7654, 2018, 2024, 2025, 36327, 24549, 7660, 2020, 30702, 7663, 14320, 26091, 14324, 24565, 36341, 24569}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('child.n.01.child')\", 26), (\"Lemma('child.n.02.child')\", 26), (\"Lemma('location.n.01.location')\", 1)])\n",
      "collecting tokens for  recent\n",
      "indices:    {21893, 12934, 2823, 23432, 1417, 1173, 1434, 3749, 12971, 28717, 31790, 23983, 15281, 14772, 32439, 21559, 26425, 18620, 25024, 16323, 17219, 20421, 11104, 31588, 11626, 31088, 27767, 2301}\n",
      "dict_items([(\"Lemma('recent.s.01.recent')\", 10), (\"Lemma('late.s.03.recent')\", 1)])\n",
      "collecting tokens for  traveled\n",
      "indices:    {12483, 13059, 32311, 5861, 5864, 3433, 759, 26669, 36759, 5047, 21332, 12789, 29237, 31639, 25112, 57, 32346, 14525}\n",
      "dict_items([(\"Lemma('traveled.a.01.traveled')\", 1), (\"Lemma('travel.v.01.travel')\", 12), (\"Lemma('traveled.s.02.traveled')\", 1), (\"Lemma('travel.v.04.travel')\", 2), (\"Lemma('travel.v.02.travel')\", 1)])\n",
      "collecting tokens for  widely\n",
      "indices:    {1282, 4998, 1414, 32903, 33033, 26505, 33032, 16141, 28174, 5391, 30991, 31639, 25497, 20505, 33050, 32543, 2339, 3878, 25532, 16061, 28355, 23877, 3150, 4700, 25695, 5215, 5216, 3171, 18276, 32620, 17133, 32111, 12786, 13300, 28021, 21237, 28025, 23675}\n",
      "dict_items([(\"Lemma('widely.r.01.widely')\", 15), (\"Lemma('widely.r.03.widely')\", 1)])\n",
      "collecting tokens for  europe\n",
      "indices:    {13534}\n",
      "dict_items([(\"Lemma('europe.n.01.Europe')\", 1)])\n",
      "collecting tokens for  conducting\n",
      "indices:    {928, 27617, 24837, 22379, 25261, 6062, 11508, 11510, 31639}\n",
      "dict_items([(\"Lemma('conduct.v.01.conduct')\", 4), (\"Lemma('conduct.v.02.conduct')\", 2)])\n",
      "collecting tokens for  italy\n",
      "indices:    {30268}\n",
      "dict_items([])\n",
      "collecting tokens for  france\n",
      "indices:    {27975}\n",
      "dict_items([])\n",
      "collecting tokens for  several\n",
      "indices:    {26701, 7345, 5169, 8179, 21209, 14809, 1434, 20317, 31294, 21375}\n",
      "dict_items([(\"Lemma('several.s.03.several')\", 1)])\n",
      "collecting tokens for  sections\n",
      "indices:    {4160, 4139, 4192}\n",
      "dict_items([(\"Lemma('section.n.02.section')\", 2), (\"Lemma('section.n.04.section')\", 1)])\n",
      "collecting tokens for  dark\n",
      "indices:    {4996, 35204, 18182, 18186, 10380, 9624, 33578, 7213, 35249, 11315, 36023, 5957, 36685, 30418, 25686, 6745, 4186, 35806, 9187, 9190, 17641, 17258, 378, 9596, 8829}\n",
      "dict_items([(\"Lemma('dark.a.02.dark')\", 4), (\"Lemma('darkness.n.02.dark')\", 1), (\"Lemma('night.n.01.dark')\", 2), (\"Lemma('dark.s.03.dark')\", 2), (\"Lemma('dark.a.01.dark')\", 6), (\"Lemma('dark.n.01.dark')\", 1)])\n",
      "collecting tokens for  bread\n",
      "indices:    {36103, 30476, 30222, 19470, 7078, 22182, 7080, 2988, 7485, 27347, 35542, 30429, 7391, 30432, 30433, 30431, 30436, 7400, 30443, 30445, 24686, 30446, 25326, 29425, 29427, 8052, 7412, 30461}\n",
      "dict_items([(\"Lemma('bread.n.01.bread')\", 2)])\n",
      "collecting tokens for  butter\n",
      "indices:    {29218, 29187, 29540, 7400, 29585, 8850, 22129, 29588, 7412, 22134, 27191, 29592, 9405, 29236, 9404, 30493, 29534, 7391}\n",
      "dict_items([(\"Lemma('butter.n.01.butter')\", 3)])\n",
      "collecting tokens for  tiny\n",
      "indices:    {10496, 31489, 34692, 36747, 10510, 31375, 3603, 19348, 26260, 18842, 8094, 10527, 5669, 31401, 31021, 10031, 30769, 29106, 36408, 22201, 27960, 36416, 16717, 33743, 22992, 29012, 1620, 17108, 24036, 25327, 9200, 34420}\n",
      "dict_items([(\"Lemma('bantam.s.01.tiny')\", 13)])\n",
      "collecting tokens for  cake\n",
      "indices:    {24006, 29387, 26926, 30734, 26418, 27219, 19033, 37082, 37085, 7391}\n",
      "dict_items([(\"Lemma('cake.n.01.cake')\", 2)])\n",
      "collecting tokens for  ice\n",
      "indices:    {19460, 12421, 12423, 9229, 8210, 13594, 9243, 29467, 5538, 4132, 28711, 36138, 29489, 30004, 12486, 5584, 30163, 12374, 29536, 7009, 36451, 16625, 12410}\n",
      "dict_items([(\"Lemma('ice.n.01.ice')\", 11)])\n",
      "collecting tokens for  suddenly\n",
      "indices:    {36328, 31397, 6879}\n",
      "dict_items([(\"Lemma('abruptly.r.01.suddenly')\", 1)])\n",
      "collecting tokens for  cold\n",
      "indices:    {33682, 19862, 6429, 25763, 10019, 19116, 26415, 35248, 11313, 22849, 35150, 15193, 1115, 2273, 2535, 36463, 1654, 1659, 34046, 24831}\n",
      "dict_items([(\"Lemma('cold_war.n.01.cold_war')\", 1), (\"Lemma('cold.a.02.cold')\", 2), (\"Lemma('cold.a.01.cold')\", 6)])\n",
      "collecting tokens for  lobby\n",
      "indices:    {33410, 18339, 22538, 13395, 36565, 34103, 33401, 16827, 34135, 25759}\n",
      "dict_items([(\"Lemma('anteroom.n.01.lobby')\", 3)])\n",
      "collecting tokens for  last\n",
      "indices:    {10628, 21769, 1436, 10269, 24478, 26284, 444, 19014, 23751, 23752, 14023, 9423, 20307, 31967, 25700, 18149, 21369, 10618, 10621}\n",
      "dict_items([(\"Lemma('last.a.02.last')\", 3), (\"Lemma('last.s.01.last')\", 5), (\"Lemma('last.r.01.last')\", 1)])\n",
      "collecting tokens for  essential\n",
      "indices:    {16258, 32647, 32135, 32137, 32016, 2704, 32018, 14224, 2069, 2586, 2714, 33179, 32158, 15391, 15139, 15526, 15528, 4648, 28849, 34355, 2614, 1336, 4793, 1978, 11323, 15162, 28861, 11326, 14400, 21441, 14912, 13891, 23619, 7877, 13261, 20343, 32504, 21205, 2390, 31705, 13275, 20059, 15197, 31966, 2017, 27233, 31969, 20193, 24170, 9579, 2414, 2030, 13294, 15475, 34675, 32887, 760, 20346, 25083, 15485, 32895}\n",
      "dict_items([(\"Lemma('essential.a.02.essential')\", 11), (\"Lemma('essential.s.01.essential')\", 13), (\"Lemma('all-important.s.01.essential')\", 7), (\"Lemma('necessity.n.02.essential')\", 1)])\n",
      "collecting tokens for  program\n",
      "indices:    {25730, 4620, 13, 147, 30420, 1816, 21529, 21882, 32509}\n",
      "dict_items([(\"Lemma('plan.n.01.program')\", 3)])\n",
      "collecting tokens for  forward\n",
      "indices:    {10368, 17665, 5762, 8576, 33154, 29702, 6278, 30987, 16895, 4622, 36239, 5008, 24848, 8850, 12434, 4500, 4498, 4502, 12442, 29695, 25727, 1695, 32161, 5410, 5411, 31397, 16422, 15528, 32169, 34090, 36267, 29736, 10031, 35764, 32182, 32183, 1591, 1337, 35130, 31674, 1980, 1983, 32192, 1984, 19906, 12867, 7108, 24261, 27080, 19273, 18890, 12881, 18770, 18648, 12890, 31323, 36061, 19934, 17632, 2017, 11745, 2019, 20451, 2018, 18662, 7777, 496, 17528, 29691, 18556, 27645, 31487}\n",
      "dict_items([(\"Lemma('forward.r.01.forward')\", 21), (\"Lemma('forward.a.01.forward')\", 6), (\"Lemma('forth.r.02.forward')\", 5), (\"Lemma('ahead.r.02.forward')\", 3)])\n",
      "collecting tokens for  roll\n",
      "indices:    {21275, 29619, 34148, 19191}\n",
      "dict_items([(\"Lemma('roll.v.01.roll')\", 1), (\"Lemma('wheel.v.03.roll')\", 1), (\"Lemma('roll_out.v.01.roll')\", 1)])\n",
      "collecting tokens for  columns\n",
      "indices:    {30851, 25924, 24675, 26951, 34215, 34220, 16175, 27536, 16177, 12915, 29364, 29365, 29206, 9148, 25662, 34303}\n",
      "dict_items([(\"Lemma('column.n.05.column')\", 1), (\"Lemma('column.n.03.column')\", 2), (\"Lemma('column.n.07.column')\", 1)])\n",
      "collecting tokens for  around\n",
      "indices:    {13053, 34029, 7822, 36335, 14484, 18714, 30013}\n",
      "dict_items([])\n",
      "collecting tokens for  dome\n",
      "indices:    {31523, 29379, 23694, 29358, 29232, 29361, 29364, 29366, 10233, 29373, 34205, 10207}\n",
      "dict_items([])\n",
      "collecting tokens for  round\n",
      "indices:    {22915, 1668, 8325, 13572, 13577, 27020, 35214, 530, 22930, 22932, 4119, 22938, 14748, 16541, 540, 3874, 35490, 3875, 7461, 35237, 30118, 33578, 22955, 29228, 36269, 22445, 30124, 28848, 4401, 4402, 35378, 22969, 36415, 3267, 29380, 21959, 12490, 6733, 24398, 1360, 4437, 20574, 28642, 7011, 36071, 8051, 13559, 504, 29563, 33404}\n",
      "dict_items([(\"Lemma('round.a.01.round')\", 7), (\"Lemma('round_of_golf.n.01.round')\", 1), (\"Lemma('round.r.01.round')\", 3), (\"Lemma('cycle.n.01.round')\", 2), (\"Lemma('round.s.03.round')\", 1), (\"Lemma('round.n.01.round')\", 2)])\n",
      "collecting tokens for  writing\n",
      "indices:    {22789, 32071, 30828, 16016, 13779, 8468, 12563, 14453, 20150, 12915, 12572}\n",
      "dict_items([(\"Lemma('write.v.01.write')\", 3), (\"Lemma('write.v.02.write')\", 2), (\"Lemma('writing.n.01.writing')\", 3)])\n",
      "collecting tokens for  indication\n",
      "indices:    {4803, 23402, 11626, 8285, 32925, 15959, 5372, 28733, 11391}\n",
      "dict_items([(\"Lemma('indication.n.01.indication')\", 6)])\n",
      "collecting tokens for  personalities\n",
      "indices:    {26753, 26755, 12683, 11244, 491, 37070, 27728, 31157, 37014, 1013, 23065}\n",
      "dict_items([(\"Lemma('personality.n.02.personality')\", 1), (\"Lemma('personality.n.01.personality')\", 3)])\n",
      "collecting tokens for  reacted\n",
      "indices:    {28033, 33221, 14950, 14249, 30233, 22834, 33235, 23065, 1438}\n",
      "dict_items([(\"Lemma('react.v.01.react')\", 9)])\n",
      "collecting tokens for  meeting\n",
      "indices:    {24195, 32132, 22666, 37002, 28051, 37012, 9623, 32791, 37025, 36132, 20772, 22828, 32441, 21180, 22593, 22338, 5323, 22603, 21709, 5326, 27087, 32209, 22614, 20700, 20448, 11875, 22629, 36967, 12655, 22641, 22644, 22648, 30204}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('meeting.n.01.meeting')\", 3), (\"Lemma('meet.v.02.meet')\", 2), (\"Lemma('meet.v.05.meet')\", 1), (\"Lemma('converge.v.01.meet')\", 1), (\"Lemma('meeting.n.02.meeting')\", 1), (\"Lemma('meet.v.06.meet')\", 1), (\"Lemma('meet.v.07.meet')\", 1)])\n",
      "collecting tokens for  heroes\n",
      "indices:    {2656, 27108, 2309, 30535, 2312, 32044, 26704, 23065, 11257, 5949}\n",
      "dict_items([(\"Lemma('hero.n.01.hero')\", 4), (\"Lemma('hero.n.02.hero')\", 1)])\n",
      "collecting tokens for  wish\n",
      "indices:    {1155, 19463, 25490, 33172, 36116, 31778, 4771, 423, 23728, 34228, 10933, 9142, 36791, 7742, 12609, 17225, 36297, 31433, 14925, 13397, 4312, 20192, 24290, 36964, 13288, 8299, 6511, 12143, 22897, 15859, 26359, 35706, 32254}\n",
      "dict_items([(\"Lemma('wish.v.01.wish')\", 8), (\"Lemma('wish.n.02.wish')\", 1), (\"Lemma('wish.n.01.wish')\", 3), (\"Lemma('wish.v.02.wish')\", 5), (\"Lemma('wish.v.06.wish')\", 1), (\"Lemma('wish.v.03.wish')\", 2), (\"Lemma('wish.v.04.wish')\", 1)])\n",
      "collecting tokens for  henry\n",
      "indices:    {22501}\n",
      "dict_items([])\n",
      "collecting tokens for  buy\n",
      "indices:    {29440, 30083, 37123, 12552, 9229, 11789, 29455, 21904, 15505, 29713, 11796, 21909, 29466, 27168, 21792, 21794, 2212, 2213, 9639, 2215, 30124, 2735, 24887, 22586, 29756, 20937, 23503, 23504, 1615, 8183, 7895, 20057, 12122, 12125, 992, 29409, 995, 21988, 30181, 12135, 12141, 29422, 21999, 12143, 27124, 6135, 33403, 29439}\n",
      "dict_items([(\"Lemma('buy.v.01.buy')\", 26), (\"Lemma('take_over.v.05.buy_out')\", 1), (\"Lemma('bribe.v.01.buy')\", 1)])\n",
      "collecting tokens for  bottle\n",
      "indices:    {2698, 18955, 33676, 16652, 33678, 6158, 18959, 18957, 33679, 33681, 18964, 34046, 36133, 16704, 8396, 30035, 10712, 33625, 18905, 18907, 29665, 9186, 18924, 9069, 9070, 18929, 10739, 18932, 9460, 34039, 18936, 18939, 18556, 18941, 16638, 18943}\n",
      "dict_items([(\"Lemma('bottle.n.02.bottle')\", 2), (\"Lemma('bottle.n.01.bottle')\", 22)])\n",
      "collecting tokens for  whiskey\n",
      "indices:    {36613, 36614, 29159, 33928, 33294, 33744, 8785, 10740, 9629}\n",
      "dict_items([(\"Lemma('whiskey.n.01.whiskey')\", 3)])\n",
      "collecting tokens for  within\n",
      "indices:    {13490}\n",
      "dict_items([])\n",
      "collecting tokens for  hours\n",
      "indices:    {21507, 23557, 11273, 5642, 21522, 5654, 3098, 2590, 16927, 30760, 2092, 19512, 23102, 21068, 11857, 23633, 34899, 35924, 1621, 36441, 36443, 31327, 21087, 27748, 27749, 20074, 26736, 25207, 32892, 34946, 11399, 36495, 36496, 153, 154, 155, 5275, 33437, 19615, 31392, 5793, 29345, 5799, 3253, 5815, 33476, 9935, 23251, 3286, 29406, 234, 29423, 28406, 6912, 23301, 23823, 3347, 13078, 20760, 28447, 23328, 19746, 23337, 22827, 11563, 12077, 12079, 27439, 15159, 31036, 18754, 17737, 8010, 25936, 24916, 27988, 30037, 11607, 25943, 30039, 12129, 21351, 8039, 30057, 21356, 19311, 3447, 3448, 30073, 10631, 32654, 36239, 15762, 13213, 17314, 21411, 33705, 7596, 26544, 26545, 12741, 4042, 15314, 15317, 15319, 27609, 15327, 15328, 27620, 15334, 17895, 15853, 36851, 17909, 21503}\n",
      "dict_items([(\"Lemma('hour.n.02.hour')\", 7), (\"Lemma('hours.n.01.hours')\", 7), (\"Lemma('hour.n.01.hour')\", 26), (\"Lemma('hours.n.02.hours')\", 2)])\n",
      "collecting tokens for  gone\n",
      "indices:    {25600, 8194, 36871, 33290, 8206, 34321, 16915, 34324, 5653, 28186, 7716, 10788, 12840, 12337, 16947, 12854, 16952, 7225, 5694, 9279, 8769, 16962, 36930, 17484, 26709, 19542, 30297, 2654, 27745, 36962, 20067, 18529, 24685, 33902, 19056, 34428, 10367, 30341, 2698, 7818, 19087, 2704, 25241, 35995, 8871, 6319, 17079, 16569, 10425, 26307, 36549, 12486, 18642, 1234, 28372, 8929, 24809, 25846, 6902, 16632, 30972, 1797, 7944, 271, 13592, 17186, 16674, 28968, 7466, 9008, 18738, 20796, 34621, 27966, 35137, 29009, 29015, 13665, 9572, 29029, 7530, 9068, 6522, 7039, 33673, 396, 13716, 407, 10137, 10143, 20393, 36267, 9649, 21938, 33723, 14274, 19394, 36306, 36308, 33749, 35805, 7650, 34282, 23029, 34805, 9208, 30207}\n",
      "dict_items([(\"Lemma('go.v.02.go')\", 10), (\"Lemma('run.v.05.go')\", 1), (\"Lemma('done_for.s.01.gone')\", 3), (\"Lemma('go.v.03.go')\", 13), (\"Lemma('travel.v.01.go')\", 16), (\"Lemma('run_low.v.01.go')\", 2), (\"Lemma('go.v.09.go')\", 4), (\"Lemma('become.v.01.go')\", 4), (\"Lemma('recur.v.02.go_back')\", 1), (\"Lemma('asleep.s.03.gone')\", 1), (\"Lemma('go.v.16.go')\", 1), (\"Lemma('fail.v.02.go_wrong')\", 1)])\n",
      "collecting tokens for  remarkable\n",
      "indices:    {25216, 27906, 24452, 22927, 27153, 4118, 5015, 14103, 8351, 420, 1189, 14503, 14506, 26673, 28339, 30782, 30145, 11460, 8910, 23000, 14428, 27236, 29936, 26487, 22395, 25471}\n",
      "dict_items([(\"Lemma('remarkable.s.01.remarkable')\", 10), (\"Lemma('noteworthy.s.02.remarkable')\", 1)])\n",
      "collecting tokens for  book\n",
      "indices:    {865, 27095, 22249, 26219, 1137, 25972, 25975, 2489, 1179}\n",
      "dict_items([(\"Lemma('book.n.01.book')\", 4)])\n",
      "collecting tokens for  interesting\n",
      "indices:    {2628, 9284, 26566, 4741, 36584, 14663, 26436, 30253, 4782, 2991, 2703, 26029, 12658, 13940, 2998, 28537, 30906, 1310}\n",
      "dict_items([(\"Lemma('interesting.a.01.interesting')\", 11)])\n",
      "collecting tokens for  questions\n",
      "indices:    {5744, 14059, 7520, 15662}\n",
      "dict_items([(\"Lemma('question.n.03.question')\", 1), (\"Lemma('question.n.01.question')\", 3)])\n",
      "collecting tokens for  answered\n",
      "indices:    {7304, 15373, 24724, 34196, 32414, 5281, 14499, 10026, 15787, 15788, 4397, 15789, 25520, 22960, 4914, 34994, 33719, 33591, 36408, 7355, 34494, 15422, 28230, 35655, 35400, 7370, 8527, 10066, 31319, 20055, 25049, 13147, 24796, 33755, 23646, 34782, 10720, 7520, 7397, 10726, 28518, 33387, 10870, 8439}\n",
      "dict_items([(\"Lemma('answer.v.02.answer')\", 6), (\"Lemma('answer.v.01.answer')\", 26), (\"Lemma('answer.v.03.answer')\", 2), (\"Lemma('answer.v.05.answer')\", 2), (\"Lemma('answer.v.04.answer')\", 2)])\n",
      "collecting tokens for  successes\n",
      "indices:    {4480, 4479, 32157, 12971, 4396, 23983, 12989, 13534, 4459, 4461, 8432, 4467, 27380, 4469, 4470, 4471, 4476, 4478, 24703}\n",
      "dict_items([(\"Lemma('success.n.01.success')\", 11), (\"Lemma('success.n.02.success')\", 4)])\n",
      "collecting tokens for  x\n",
      "indices:    {4476}\n",
      "dict_items([])\n",
      "collecting tokens for  probability\n",
      "indices:    {15238, 21896, 33033, 27795, 27802, 20634, 4384, 24608, 4385, 27815, 4392, 4393, 4396, 28461, 28462, 33070, 4410, 4435, 27349, 4438, 4439, 3037, 32997, 4457, 28521, 4466, 4469, 4470, 15231}\n",
      "dict_items([(\"Lemma('probability.n.01.probability')\", 15), (\"Lemma('probability.n.02.probability')\", 1)])\n",
      "collecting tokens for  occurrence\n",
      "indices:    {15872, 15878, 15890, 15892, 15896, 15897, 15898, 15902, 15903, 11552, 15905, 15914, 4394, 15923, 4534, 15930, 15934, 15935, 15944, 3402, 16203, 10736, 23281, 4470}\n",
      "dict_items([(\"Lemma('happening.n.01.occurrence')\", 20), (\"Lemma('occurrence.n.02.occurrence')\", 3)])\n",
      "collecting tokens for  set\n",
      "indices:    {37120, 11108, 11110, 31111, 30888, 1545, 22154, 36974, 21206, 7738}\n",
      "dict_items([(\"Lemma('set.v.05.set')\", 1), (\"Lemma('set.v.08.set')\", 1)])\n",
      "collecting tokens for  pairs\n",
      "indices:    {3602, 27539, 27540, 4470, 36598, 3702, 14009, 16187, 16092}\n",
      "dict_items([(\"Lemma('pair.n.01.pair')\", 2), (\"Lemma('couple.n.04.pair')\", 3), (\"Lemma('pair.n.03.pair')\", 1)])\n",
      "collecting tokens for  function\n",
      "indices:    {14599, 22792, 5256, 9864, 30736, 5265, 4504, 4505, 4379, 4382, 4515, 4516, 15400, 4522, 4523, 4527, 2993, 14514, 2869, 4533, 4535, 3000, 32953, 32694, 2998, 4540, 4541, 32702, 3006, 4544, 13889, 4547, 20165, 4549, 34759, 32453, 4041, 13645, 16081, 4051, 1492, 4692, 16343, 4568, 4569, 3802, 16349, 32990, 4959, 26592, 3042, 16357, 32998, 16358, 25064, 13417, 4457, 2155, 4718, 4719, 27886, 16113, 15858, 31926, 16372, 4470, 32502, 5243, 26493}\n",
      "dict_items([(\"Lemma('function.n.01.function')\", 26), (\"Lemma('function.n.02.function')\", 12), (\"Lemma('function.n.03.function')\", 5), (\"Lemma('function.v.01.function')\", 4)])\n",
      "collecting tokens for  binomial\n",
      "indices:    {4384, 4385, 4419, 4420, 4428, 4431, 4436, 4438, 4443, 4444, 4456, 4459, 4465, 4466, 4471, 4472, 4473, 4474, 4475, 4476}\n",
      "dict_items([(\"Lemma('binomial.a.01.binomial')\", 16), (\"Lemma('binomial_distribution.n.01.binomial_distribution')\", 1), (\"Lemma('binomial.n.01.binomial')\", 1)])\n",
      "collecting tokens for  distribution\n",
      "indices:    {15489, 2948, 2955, 11661, 14, 3345, 3987, 2835, 2836, 11672, 11677, 4384, 15265, 4385, 11683, 2848, 15654, 15657, 3757, 14894, 21809, 3378, 30513, 21811, 16179, 16180, 3385, 3386, 3387, 21827, 17351, 3276, 3021, 845, 4185, 32730, 5083, 3293, 2910, 11485, 4985, 4200, 4471, 4472, 3577, 3325, 3326}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('distribution.n.01.distribution')\", 20), (\"Lemma('distribution.n.03.distribution')\", 5), (\"Lemma('distribution.n.04.distribution')\", 3), (\"Lemma('distribution.n.02.distribution')\", 8)])\n",
      "collecting tokens for  traveling\n",
      "indices:    {26775}\n",
      "dict_items([])\n",
      "collecting tokens for  south\n",
      "indices:    {31852}\n",
      "dict_items([])\n",
      "collecting tokens for  miles\n",
      "indices:    {30080, 9217, 20100, 12036, 27017, 28954, 24864, 12706, 12460, 27180, 33582, 21294, 25774, 30515, 35005, 26945, 18250, 12491, 7630, 27983, 20816, 30543, 12371, 35925, 31448, 21212, 27103, 30560, 28640, 24034, 35813, 12390, 3431, 3434, 19055, 28661, 36598, 12791, 33784, 12793, 3451, 3452, 31358}\n",
      "dict_items([(\"Lemma('mile.n.01.mile')\", 13), (\"Lemma('nautical_mile.n.02.mile')\", 1)])\n",
      "collecting tokens for  great\n",
      "indices:    {640, 10848, 27141, 23430, 23666, 36436, 26102, 31800, 16251, 26908, 24831}\n",
      "dict_items([(\"Lemma('great.s.01.great')\", 1), (\"Lemma('bang-up.s.01.great')\", 1)])\n",
      "collecting tokens for  persian\n",
      "indices:    {31508}\n",
      "dict_items([])\n",
      "collecting tokens for  've\n",
      "indices:    {22530, 9732, 29700, 21003, 33291, 23051, 22539, 35856, 1556, 33300, 33303, 23063, 33304, 17948, 36389, 7718, 33319, 24617, 36908, 34863, 35888, 16945, 33331, 36404, 18998, 19000, 17981, 36925, 16962, 19522, 35908, 8773, 8774, 1603, 21064, 5705, 8780, 21070, 8783, 8784, 8785, 19538, 8786, 8787, 21074, 16483, 7784, 17001, 19564, 33902, 14461, 8318, 8317, 640, 33923, 18565, 10373, 19595, 11918, 18063, 10386, 18581, 34453, 663, 17057, 10402, 20134, 10407, 18600, 18089, 10410, 10411, 17071, 28341, 17079, 9401, 35002, 25274, 36538, 8893, 19137, 16579, 33990, 17101, 34004, 35028, 16598, 16599, 22233, 34013, 35037, 34528, 16609, 9446, 9448, 18167, 9466, 18684, 9469, 9984, 9988, 17671, 36625, 283, 298, 16682, 17713, 22323, 17716, 17222, 9033, 7498, 21834, 34637, 24398, 34639, 34641, 16736, 11104, 10084, 8041, 21866, 36203, 11117, 29045, 29047, 16761, 24446, 26499, 6021, 30603, 10124, 395, 30606, 24461, 22419, 17300, 13722, 24475, 11174, 17834, 17842, 36279, 8123, 30651, 34240, 30658, 30661, 28616, 28620, 10701, 9678, 28623, 35789, 35286, 34775, 19927, 18395, 21982, 30179, 10724, 17382, 19944, 10729, 35827, 26613, 19962}\n",
      "dict_items([(\"Lemma('have.v.01.have_got')\", 1)])\n",
      "collecting tokens for  worked\n",
      "indices:    {24579, 24580, 31236, 9224, 21001, 8713, 8715, 11278, 35855, 1552, 11282, 33300, 26164, 64, 21576, 11857, 11858, 35926, 34393, 113, 22644, 28819, 25250, 7339, 14509, 27320, 19129, 27325, 32449, 195, 29892, 16067, 10954, 27339, 36557, 206, 14542, 34004, 26329, 14555, 16101, 14566, 14567, 14568, 5861, 13561, 268, 23823, 31509, 5401, 28960, 28965, 17706, 21307, 329, 29007, 29008, 33620, 30039, 16217, 25954, 29028, 24422, 29036, 34157, 24429, 21369, 15739, 3969, 18305, 32134, 34694, 906, 35214, 27023, 16276, 24473, 11163, 6045, 7596, 35259, 9152, 28616, 9182, 36838, 493, 14832, 7677, 16894}\n",
      "dict_items([(\"Lemma('work.v.01.work')\", 11), (\"Lemma('work.v.03.work')\", 5), (\"Lemma('work.v.02.work')\", 13), (\"Lemma('work.v.10.work')\", 2), (\"Lemma('work.v.05.work')\", 4), (\"Lemma('bring.v.03.work')\", 3), (\"Lemma('exercise.v.03.work')\", 5), (\"Lemma('work.v.08.work')\", 3), (\"Lemma('cultivate.v.02.work')\", 2), (\"Lemma('function.v.01.work')\", 4), (\"Lemma('make.v.36.work')\", 1), (\"Lemma('work_out.v.01.work_out')\", 1), (\"Lemma('work.v.09.work')\", 1)])\n",
      "collecting tokens for  regular\n",
      "indices:    {9949, 12900, 20445}\n",
      "dict_items([(\"Lemma('regular.a.01.regular')\", 1)])\n",
      "collecting tokens for  routine\n",
      "indices:    {9155, 23301, 13894, 5560, 22361, 8093}\n",
      "dict_items([(\"Lemma('routine.n.01.routine')\", 3)])\n",
      "collecting tokens for  acceptance\n",
      "indices:    {4610, 16133, 32390, 22789, 20489, 16411, 3229, 23590, 6825, 15793, 12219, 21820, 32956, 27840, 14407, 28616, 27342, 34390, 32854, 22745, 24409, 31195, 13415, 31208, 31219, 32501, 27895, 16120}\n",
      "dict_items([(\"Lemma('credence.n.01.acceptance')\", 4), (\"Lemma('acceptance.n.04.acceptance')\", 1), (\"Lemma('adoption.n.01.acceptance')\", 3), (\"Lemma('acceptance.n.03.acceptance')\", 1)])\n",
      "collecting tokens for  walls\n",
      "indices:    {22144, 35587, 19460, 20108, 36759, 35351, 29977, 13084, 29853, 7836, 11426, 3236, 19240, 29867, 31531, 15154, 15156, 9147, 29381, 3153, 3155, 30810, 2908, 36321, 34274, 7778, 27236, 30181, 29158, 30184, 13033, 33514, 30955, 15209, 6376, 30186, 35439, 30064, 15091, 30195, 23156, 30074, 15100, 15102}\n",
      "dict_items([(\"Lemma('wall.n.01.wall')\", 18), (\"Lemma('wall.n.03.wall')\", 1), (\"Lemma('wall.n.02.wall')\", 1)])\n",
      "collecting tokens for  floor\n",
      "indices:    {2048, 2060, 22544, 17424, 18451, 29717, 3615, 18465, 20519, 5676, 18476, 9780, 25663, 5695, 25671, 33870, 35413, 18520, 5721, 25691, 7263, 7268, 29805, 29808, 17523, 17524, 20086, 29832, 35471, 30869, 17560, 29853, 21663, 15010, 15011, 9380, 17577, 17579, 22189, 9394, 29366, 29879, 29381, 9415, 29386, 19660, 19664, 21200, 17108, 21212, 29405, 6366, 21213, 23780, 13550, 21242, 20224, 36098, 20227, 21260, 34065, 34579, 18195, 30485, 29975, 26910, 34099, 5427, 5428, 8502, 8499, 22850, 23367, 35663, 27475, 8533, 33624, 35160, 22878, 11618, 15203, 15204, 11108, 15210, 35696, 34169, 36730, 34176, 7554, 24457, 2441, 34191, 35733, 25496, 9113, 35739, 6049, 35765, 18359, 25017, 9148, 1980, 9662, 30143, 9672, 1993, 18891, 1997, 2007, 8159, 34274, 5095, 17406}\n",
      "dict_items([(\"Lemma('floor.n.02.floor')\", 13), (\"Lemma('floor.n.01.floor')\", 26), (\"Lemma('floor.n.04.floor')\", 1), (\"Lemma('floor.n.03.floor')\", 2)])\n",
      "collecting tokens for  example\n",
      "indices:    {25353, 22667, 16016, 30229, 13973, 2201, 16410, 11808, 14634, 20536, 31805, 29247, 28867, 4422, 2630, 29128, 25289, 3914, 3911, 13774, 14418, 31699, 3923, 30167, 4439, 4445, 14046, 31199, 3425, 14050, 26083, 29288, 14954, 23403, 4464, 32117, 12150, 22006, 3065, 12027, 30204}\n",
      "dict_items([(\"Lemma('example.n.01.example')\", 9), (\"Lemma('model.n.07.example')\", 2)])\n",
      "collecting tokens for  probably\n",
      "indices:    {31547, 325, 18111}\n",
      "dict_items([(\"Lemma('probably.r.01.probably')\", 2)])\n",
      "collecting tokens for  very\n",
      "indices:    {23240, 1385, 19307, 16587, 2158, 17846}\n",
      "dict_items([(\"Lemma('very.r.01.very')\", 2), (\"Lemma('identical.s.02.very')\", 1)])\n",
      "collecting tokens for  know\n",
      "indices:    {11801, 29212, 17948, 18972, 12831, 9767, 34857, 2607, 33330, 28212, 7223, 1600, 17477, 19525, 2123, 8779, 21073, 23127, 13404, 5215, 27232, 2158, 19064, 20098, 27789, 11921, 20116, 37012, 2200, 37025, 10413, 18607, 9405, 24259, 27341, 8407, 13529, 220, 34015, 30945, 24293, 24299, 6897, 33521, 16626, 30969, 17659, 27920, 10514, 1815, 10520, 28963, 25908, 31541, 323, 26436, 34636, 31056, 16723, 8019, 34644, 24405, 25941, 36186, 17243, 4442, 33631, 20319, 10081, 31588, 9067, 12141, 6000, 9073, 25460, 33673, 13749, 30146, 10701, 19406, 33749, 36827, 6621, 996, 25575, 6129}\n",
      "dict_items([(\"Lemma('know.v.03.know')\", 7), (\"Lemma('know.v.04.know')\", 10), (\"Lemma('know.v.01.know')\", 26), (\"Lemma('know.v.02.know')\", 4)])\n",
      "collecting tokens for  today\n",
      "indices:    {28667, 27196}\n",
      "dict_items([])\n",
      "collecting tokens for  stems\n",
      "indices:    {4192, 24577, 16194, 16196, 935, 16157, 14189, 25294, 16175, 32624, 16191, 22745, 16155, 16188, 4125, 4126, 13343}\n",
      "dict_items([(\"Lemma('root.n.03.stem')\", 7), (\"Lemma('stem.v.01.stem')\", 6), (\"Lemma('stalk.n.02.stem')\", 3)])\n",
      "collecting tokens for  core\n",
      "indices:    {21889, 22403, 34436, 31244, 20245, 918, 13336, 13337, 32923, 13853, 32926, 32929, 13349, 32935, 5415, 25897, 10543, 29232, 32948, 32949, 32953, 6715, 23745, 14591, 33003, 12790, 24056, 22655}\n",
      "dict_items([(\"Lemma('core.n.02.core')\", 4), (\"Lemma('core.n.01.core')\", 3), (\"Lemma('kernel.n.03.core')\", 2), (\"Lemma('core.v.01.core')\", 1), (\"Lemma('core.n.03.core')\", 1)])\n",
      "collecting tokens for  nato\n",
      "indices:    {20237}\n",
      "dict_items([])\n",
      "collecting tokens for  concerned\n",
      "indices:    {16897, 33802, 23565, 13840, 14869, 15387, 4640, 31780, 12327, 12330, 31275, 31800, 24122, 14921, 14922, 32844, 31825, 32339, 6743, 22621, 22625, 4208, 5237, 5238, 5239, 23676, 24193, 19077, 2183, 31883, 3726, 16016, 26778, 8350, 31909, 6822, 12455, 15530, 31929, 22731, 8400, 28904, 33011, 23284, 33016, 30973, 25859, 12040, 20232, 20245, 2345, 2348, 31028, 32066, 1346, 838, 25929, 20297, 14671, 24914, 14677, 4960, 1377, 14692, 14701, 20336, 14708, 15225, 22396, 17796, 31109, 2950, 33169, 32147, 14740, 1428, 3480, 28056, 15773, 3493, 2486, 21439, 25037, 16334, 16338, 7637, 30680, 17381, 28142, 29171, 23035, 25598}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('concern.v.02.concern')\", 17), (\"Lemma('refer.v.02.concern')\", 19), (\"Lemma('concerned.s.02.concerned')\", 11), (\"Lemma('concerned.a.01.concerned')\", 15)])\n",
      "collecting tokens for  secretary\n",
      "indices:    {14887}\n",
      "dict_items([])\n",
      "collecting tokens for  united\n",
      "indices:    {23752}\n",
      "dict_items([])\n",
      "collecting tokens for  states\n",
      "indices:    {20212, 15012, 16396, 29239}\n",
      "dict_items([(\"Lemma('state.n.01.state')\", 1), (\"Lemma('state.n.04.state')\", 1)])\n",
      "collecting tokens for  profound\n",
      "indices:    {12327, 13960, 9576, 25895, 14280, 1497, 31757, 14926, 36303, 10609, 4241, 34898, 25523, 20245, 19607, 11064, 889, 14716}\n",
      "dict_items([(\"Lemma('profound.a.01.profound')\", 9), (\"Lemma('profound.s.02.profound')\", 3)])\n",
      "collecting tokens for  alliance\n",
      "indices:    {31713, 23749, 27127}\n",
      "dict_items([])\n",
      "collecting tokens for  foreign\n",
      "indices:    {20771, 32149, 28039}\n",
      "dict_items([])\n",
      "collecting tokens for  policy\n",
      "indices:    {14721, 4610, 12929, 25604, 28675, 22789, 22666, 25740, 32404, 15381, 25495, 20251, 14748, 27807, 20258, 4645, 27814, 15400, 16432, 12978, 15414, 15417, 31290, 32317, 23749, 26566, 16331, 27852, 13265, 14293, 33127, 5486, 23284, 12917, 16374, 25589, 32509}\n",
      "dict_items([(\"Lemma('policy.n.01.policy')\", 7), (\"Lemma('policy.n.02.policy')\", 6)])\n",
      "collecting tokens for  announced\n",
      "indices:    {21377, 14978, 22407, 22030, 9743, 21395, 4756, 20245, 21397, 10136, 28569, 21274, 16921, 20766, 21790, 15263, 21153, 24099, 21411, 21926, 39, 936, 9386, 36655, 21423, 22961, 18277, 22587, 21693, 8254, 22502, 6399, 25415, 331, 588, 20301, 23117, 20428, 465, 23123, 26475, 23255, 31320, 16217, 23265, 37093, 14949, 20581, 21352, 20966, 21221, 22379, 26476, 21741, 29166, 26479, 14319, 24191, 22383, 243, 4595, 11885, 22901, 10103, 20982, 10099, 12411, 26876, 27774, 33535}\n",
      "dict_items([(\"Lemma('announce.v.01.announce')\", 26), (\"Lemma('announce.v.02.announce')\", 9), (\"Lemma('announce.v.03.announce')\", 2), (\"Lemma('announce.v.04.announce')\", 1)])\n",
      "collecting tokens for  five\n",
      "indices:    {36673, 18817, 20612, 6023, 21769, 24970, 34462, 33229, 8590, 16181, 3701, 5047, 9624, 37049, 32412, 32510}\n",
      "dict_items([(\"Lemma('five.s.01.five')\", 7)])\n",
      "collecting tokens for  nuclear\n",
      "indices:    {23617, 28449, 28483, 27801, 31301, 25446, 25159, 27816, 907, 25166, 31278, 24656, 28465, 28529, 25269, 21752, 28441}\n",
      "dict_items([(\"Lemma('nuclear.a.01.nuclear')\", 1)])\n",
      "collecting tokens for  submarines\n",
      "indices:    {14980, 3495, 21287, 28458, 15532, 21295, 11409, 21297, 20245, 15513, 31260}\n",
      "dict_items([(\"Lemma('submarine.n.01.submarine')\", 5)])\n",
      "collecting tokens for  eventually\n",
      "indices:    {33059, 21206}\n",
      "dict_items([])\n",
      "collecting tokens for  disposal\n",
      "indices:    {31872, 5124, 10277, 5126, 14699, 24911, 11471, 2737, 21460, 25525, 20245, 2453, 32628, 15189, 5498}\n",
      "dict_items([(\"Lemma('disposal.n.01.disposal')\", 4), (\"Lemma('disposal.n.03.disposal')\", 1), (\"Lemma('administration.n.01.disposal')\", 1)])\n",
      "collecting tokens for  european\n",
      "indices:    {3637}\n",
      "dict_items([])\n",
      "collecting tokens for  waters\n",
      "indices:    {19241, 27051, 12334, 32434, 12374, 255}\n",
      "dict_items([(\"Lemma('water.n.01.water')\", 1), (\"Lemma('body_of_water.n.01.water')\", 2)])\n",
      "collecting tokens for  walking\n",
      "indices:    {33603, 8740, 8774, 24360, 14443, 9548, 5963, 19886, 25230, 11377, 28154, 19541, 6393, 34010, 7548}\n",
      "dict_items([(\"Lemma('walk.v.01.walk')\", 11), (\"Lemma('walk-to.s.01.walking')\", 1), (\"Lemma('walk.v.04.walk')\", 1)])\n",
      "collecting tokens for  home\n",
      "indices:    {17733, 28039, 22995, 437, 24566, 21369}\n",
      "dict_items([(\"Lemma('home.n.01.home')\", 1)])\n",
      "collecting tokens for  school\n",
      "indices:    {121, 22212, 13252, 27559}\n",
      "dict_items([(\"Lemma('school.n.01.school')\", 2)])\n",
      "collecting tokens for  seemed\n",
      "indices:    {1026, 33795, 17922, 1539, 5640, 18446, 33303, 2583, 26650, 29212, 8733, 6173, 11299, 8744, 36912, 20023, 17977, 6203, 30267, 36928, 33345, 36419, 20036, 1606, 1096, 9800, 8779, 33359, 32848, 35408, 10834, 18515, 33874, 20052, 5715, 13401, 90, 18523, 16478, 6241, 8802, 36963, 9316, 9315, 33382, 34405, 8808, 16489, 8810, 33379, 17004, 7281, 23154, 20081, 30839, 34427, 5756, 17021, 9343, 641, 30340, 36484, 10376, 25738, 20108, 37004, 8334, 12431, 12432, 10388, 30870, 14488, 8857, 10396, 30877, 35998, 26790, 3239, 28328, 7849, 19111, 37036, 26797, 14513, 34482, 9395, 28338, 8885, 8373, 7353, 27321, 7359, 27330, 36035, 8394, 17100, 37070, 23246, 8912, 30926, 8402, 18131, 16594, 23250, 23767, 35544, 5851, 3292, 7899, 36063, 5856, 3297, 18658, 13025, 1252, 23785, 37103, 9455, 241, 5362, 6387, 6901, 28410, 18170, 31485, 14086, 26379, 13070, 28430, 7440, 7441, 7443, 18198, 19735, 31510, 26394, 10523, 13596, 18718, 37156, 33574, 36135, 26412, 35632, 28977, 11058, 20786, 8498, 25911, 30520, 26425, 20794, 4921, 30015, 30530, 36163, 34116, 25410, 22854, 36678, 2381, 17748, 17239, 18264, 30554, 22880, 18276, 22886, 7015, 35688, 26473, 19310, 7541, 9594, 15739, 9598, 12899, 22917, 25990, 26501, 30608, 36243, 13717, 19351, 15768, 35736, 15770, 19866, 36249, 33690, 6047, 10144, 12193, 27554, 28579, 19888, 31678, 35775, 24510, 9154, 6083, 33223, 17352, 26570, 12746, 26575, 9169, 33233, 9174, 9185, 6114, 36322, 33255, 8173, 8177, 5620, 33270, 8695, 8189, 16895}\n",
      "dict_items([(\"Lemma('look.v.02.seem')\", 26), (\"Lemma('appear.v.04.seem')\", 18)])\n",
      "collecting tokens for  foliage\n",
      "indices:    {26987}\n",
      "dict_items([])\n",
      "collecting tokens for  york\n",
      "indices:    {498}\n",
      "dict_items([])\n",
      "collecting tokens for  lay\n",
      "indices:    {24323, 34567, 13586, 14483, 7830, 35870, 33704, 3625, 29236, 27575, 9529, 21433, 314, 23612, 31420, 17216, 26709, 29787, 7653, 36711, 28781, 36337, 36339, 15092, 3575, 35577, 9468, 26622, 9215}\n",
      "dict_items([(\"Lemma('lie.v.02.lie')\", 6), (\"Lemma('lie.v.01.lie')\", 8), (\"Lemma('dwell.v.02.lie')\", 2), (\"Lemma('put.v.01.lay')\", 2), (\"Lemma('lie.v.06.lie')\", 2), (\"Lemma('lay.v.04.lay')\", 1), (\"Lemma('lay.v.03.lay')\", 1), (\"Lemma('lay.v.02.lay')\", 1)])\n",
      "collecting tokens for  summer\n",
      "indices:    {13568, 27016, 21007, 21009, 30098, 20883, 24097, 10024, 6825, 20150, 31674, 1858, 1861, 3657, 31562, 9808, 27985, 26980, 9575, 6505, 22509, 30198}\n",
      "dict_items([(\"Lemma('summer.n.01.summer')\", 8)])\n",
      "collecting tokens for  sun\n",
      "indices:    {26945, 36039, 31466, 30186, 16814, 34574, 36018, 29365, 35989}\n",
      "dict_items([(\"Lemma('sun.n.03.sun')\", 1)])\n",
      "collecting tokens for  morning\n",
      "indices:    {9408, 32483, 35588, 18215, 9837, 34574, 7830, 30013}\n",
      "dict_items([(\"Lemma('morning.n.01.morning')\", 3)])\n",
      "collecting tokens for  fish\n",
      "indices:    {30467, 8343, 7835, 16164, 7844, 27051, 10680, 10684, 36413, 12733, 37056, 8769, 1865, 1871, 36432, 1872, 29160, 10232, 7802}\n",
      "dict_items([(\"Lemma('fish.n.01.fish')\", 7), (\"Lemma('fish.n.02.fish')\", 3), (\"Lemma('pisces.n.02.Fish')\", 1)])\n",
      "collecting tokens for  hawk\n",
      "indices:    {6266, 7830}\n",
      "dict_items([(\"Lemma('hawk.n.01.hawk')\", 1)])\n",
      "collecting tokens for  flying\n",
      "indices:    {30562, 27746, 30534, 18891, 30540, 26773, 27061, 29015, 28157}\n",
      "dict_items([(\"Lemma('fly.v.01.fly')\", 2)])\n",
      "collecting tokens for  heated\n",
      "indices:    {30177, 3106, 24609, 7821, 14318, 35917, 29492, 8920, 3098, 2909, 29150}\n",
      "dict_items([(\"Lemma('heat.v.01.heat')\", 6), (\"Lemma('heated.s.01.heated')\", 2), (\"Lemma('heated.s.02.heated')\", 1)])\n",
      "collecting tokens for  air\n",
      "indices:    {35588, 23981}\n",
      "dict_items([])\n",
      "collecting tokens for  saw\n",
      "indices:    {6274, 11908, 1541, 34954, 6410, 35213, 31374, 23311, 7184, 35731, 23700, 10003, 1950, 18850, 28835, 18723, 8871, 34983, 35885, 14126, 24369, 9649, 7738, 22844, 10694, 4937, 74, 29395, 12886, 8920, 11480, 20059, 31452, 5481, 34922, 7531, 9835, 26614, 34040, 28157, 34046}\n",
      "dict_items([(\"Lemma('see.v.01.see')\", 24), (\"Lemma('visualize.v.01.see')\", 3), (\"Lemma('understand.v.02.see')\", 6), (\"Lemma('see.v.10.see')\", 1), (\"Lemma('witness.v.02.see')\", 4), (\"Lemma('meet.v.01.see')\", 1)])\n",
      "collecting tokens for  below\n",
      "indices:    {29729, 4421, 4741, 5051, 3944, 27049, 6405, 7021, 2900, 12793, 32315, 4220, 31199}\n",
      "dict_items([(\"Lemma('below.r.02.below')\", 2), (\"Lemma('below.r.01.below')\", 2)])\n",
      "collecting tokens for  long\n",
      "indices:    {508, 3911}\n",
      "dict_items([(\"Lemma('long_bone.n.01.long_bone')\", 1)])\n",
      "collecting tokens for  manhattan\n",
      "indices:    {22502}\n",
      "dict_items([])\n",
      "collecting tokens for  island\n",
      "indices:    {508}\n",
      "dict_items([])\n",
      "collecting tokens for  though\n",
      "indices:    {32876}\n",
      "dict_items([])\n",
      "collecting tokens for  incomplete\n",
      "indices:    {3585, 3586, 3777, 3589, 14705, 4561, 308, 3514, 3515, 33087}\n",
      "dict_items([(\"Lemma('incomplete.a.01.incomplete')\", 9)])\n",
      "collecting tokens for  record\n",
      "indices:    {20224, 22017, 13570, 23168, 1667, 29317, 20487, 15239, 649, 521, 28043, 22539, 24722, 8082, 24083, 30229, 278, 3730, 2462, 9759, 8225, 23203, 23718, 12710, 680, 23595, 15664, 10677, 15290, 32443, 13886, 1089, 23618, 23625, 27081, 24009, 15180, 26189, 23676, 22995, 12757, 597, 23001, 601, 247, 23004, 223, 355, 23012, 613, 2406, 23014, 20455, 12912, 10097, 23027, 15220, 246, 32247, 24956, 1782, 11382, 252, 32254, 22015}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('record.n.01.record')\", 7), (\"Lemma('record.n.06.record')\", 2), (\"Lemma('record.n.04.record')\", 3), (\"Lemma('record.n.03.record')\", 6), (\"Lemma('record.v.01.record')\", 4), (\"Lemma('phonograph_record.n.01.record')\", 4), (\"Lemma('read.v.08.record')\", 1), (\"Lemma('record.n.05.record')\", 1)])\n",
      "collecting tokens for  persons\n",
      "indices:    {33026, 33023, 21509, 5515, 9356, 14738, 14997, 14999, 14877, 27690, 20155, 33212, 27583, 21441, 12228, 12103, 27591, 2123, 21709, 16247, 20303, 4945, 6993, 15839, 2144, 29921, 20838, 21607, 26087, 20598, 14070, 27257, 5503}\n",
      "dict_items([(\"Lemma('person.n.01.person')\", 15)])\n",
      "collecting tokens for  present\n",
      "indices:    {31240, 24593, 15390, 30751, 10783, 26143, 15391, 14371, 2600, 30250, 9783, 11325, 30281, 24653, 26709, 2135, 32353, 2664, 15465, 3180, 11372, 3184, 23680, 15493, 3206, 12938, 26765, 32406, 25754, 161, 13479, 1706, 32427, 25799, 1238, 4835, 27882, 4854, 23810, 33035, 12561, 1301, 280, 31519, 31520, 24867, 9010, 9536, 32066, 13128, 15696, 1873, 3934, 20319, 11620, 7527, 35694, 15726, 21365, 28536, 28543, 14721, 21890, 2951, 28554, 14220, 29072, 5013, 3480, 20377, 14241, 20386, 14245, 27563, 2987, 31674, 22462, 27591, 31176, 14791, 25038, 20942, 32209, 26583, 13788, 23009, 23536}\n",
      "dict_items([(\"Lemma('present.a.01.present')\", 18), (\"Lemma('present.n.01.present')\", 5), (\"Lemma('stage.v.01.present')\", 1), (\"Lemma('show.v.01.present')\", 5), (\"Lemma('present.v.04.present')\", 1), (\"Lemma('present.a.02.present')\", 10), (\"Lemma('present.v.02.present')\", 2), (\"Lemma('present.v.05.present')\", 3), (\"Lemma('present.n.02.present')\", 1)])\n",
      "collecting tokens for  particular\n",
      "indices:    {32768, 15872, 15365, 25611, 32792, 32794, 11291, 16413, 11806, 15906, 36899, 11300, 30244, 1575, 28728, 28729, 14396, 26686, 11331, 11332, 28742, 18504, 2121, 2123, 28756, 15451, 2145, 4708, 1127, 1134, 12917, 26743, 32378, 15996, 4230, 14476, 14477, 31886, 32911, 25741, 2709, 32413, 32421, 22694, 15022, 15024, 12978, 15028, 10423, 27836, 15038, 15040, 27840, 15042, 29894, 32969, 27851, 1742, 31951, 32977, 15065, 1242, 15067, 15071, 27871, 9953, 32506, 1275, 27910, 33043, 2328, 14620, 14633, 16171, 301, 14642, 16178, 26934, 16182, 33082, 24891, 33087, 15173, 26951, 2376, 1870, 16207, 3919, 22359, 11097, 26973, 25441, 33125, 28014, 7549, 32128, 11649, 26503, 15243, 31122, 13716, 13717, 1949, 5024, 15781, 31143, 5032, 15797, 31671, 15803, 15294, 15296, 16322, 10691, 15821, 7630, 15827, 26082, 4070, 6124, 12787, 23541, 11255}\n",
      "dict_items([(\"Lemma('particular.s.01.particular')\", 24), (\"Lemma('particular.n.01.particular')\", 5), (\"Lemma('particular.s.02.particular')\", 11), (\"Lemma('especial.s.01.particular')\", 5)])\n",
      "collecting tokens for  area\n",
      "indices:    {23605}\n",
      "dict_items([])\n",
      "collecting tokens for  include\n",
      "indices:    {32273, 9747, 3731, 14998, 2584, 27041, 2849, 11562, 2991, 3505, 2744, 11839, 1091, 31947, 1868, 22095, 14943, 14176, 31586, 21474, 22502, 25193, 15466, 754, 13043, 3189}\n",
      "dict_items([(\"Lemma('include.v.01.include')\", 20), (\"Lemma('include.v.03.include')\", 4), (\"Lemma('include.v.02.include')\", 1), (\"Lemma('admit.v.03.include')\", 1)])\n",
      "collecting tokens for  longer\n",
      "indices:    {31235, 1539, 10245, 34313, 11277, 25613, 34839, 26136, 15385, 13337, 1560, 16418, 6178, 10789, 29221, 2599, 31786, 16427, 5675, 11307, 13358, 16434, 16435, 16438, 17978, 15931, 12861, 27200, 11842, 20044, 34894, 30804, 19033, 25692, 19037, 28253, 25696, 15969, 27749, 27750, 3694, 5742, 3700, 22133, 12927, 3715, 13447, 30362, 11931, 27809, 9889, 11950, 9905, 36019, 10425, 27322, 7356, 9919, 30409, 21196, 27863, 30942, 19166, 1251, 19690, 29423, 1266, 25339, 18171, 23810, 5379, 26884, 23302, 4871, 34055, 34581, 3862, 1303, 34584, 1305, 12064, 1323, 6962, 6965, 32568, 25918, 33087, 15171, 8532, 17751, 28507, 17757, 13668, 19306, 9589, 1401, 1402, 18299, 24958, 24959, 7045, 27526, 15763, 33172, 18846, 30110, 13219, 31658, 12718, 9144, 11709, 16829, 21951, 26562, 9668, 7113, 24010, 2517, 15327, 33760, 5096, 16364, 10225, 13812, 10235, 10238}\n",
      "dict_items([(\"Lemma('long.a.02.long')\", 7), (\"Lemma('longer.r.01.longer')\", 16), (\"Lemma('long.a.01.long')\", 8)])\n",
      "collecting tokens for  living\n",
      "indices:    {444}\n",
      "dict_items([])\n",
      "collecting tokens for  contain\n",
      "indices:    {3200, 4483, 32780, 5371, 3985, 31260, 14748, 23200, 1446, 27946, 18732, 4530, 27188, 15925, 12601, 33087, 31553, 3138, 14790, 21832, 1868, 3150, 3154, 3156, 7767, 7675, 3671, 28890, 4189, 26083, 3949, 753, 1915}\n",
      "dict_items([(\"Lemma('incorporate.v.02.contain')\", 25), (\"Lemma('hold.v.11.contain')\", 6), (\"Lemma('control.v.02.contain')\", 2)])\n",
      "collecting tokens for  precise\n",
      "indices:    {16135, 11404, 3992, 2585, 14637, 4911, 4789, 16442, 19516, 8253, 10691, 14794, 14795, 26323, 27091, 3931, 26212, 14820, 31332, 9333}\n",
      "dict_items([(\"Lemma('precise.a.01.precise')\", 15), (\"Lemma('accurate.s.02.precise')\", 1)])\n",
      "collecting tokens for  information\n",
      "indices:    {3333, 2824, 34296, 139, 3730, 2716, 15906, 15916, 16301, 33206, 9783, 33212, 33218, 14791, 25928, 3405, 1113, 3050, 33016, 3707}\n",
      "dict_items([(\"Lemma('information.n.01.information')\", 7), (\"Lemma('information.n.02.information')\", 6)])\n",
      "collecting tokens for  ages\n",
      "indices:    {19525, 31015, 3880, 3888, 3929, 24348}\n",
      "dict_items([(\"Lemma('age.n.01.age')\", 3)])\n",
      "collecting tokens for  date\n",
      "indices:    {11264, 11265, 16898, 32262, 11, 22030, 14879, 20021, 33337, 33342, 5188, 11335, 594, 21079, 600, 36461, 9840, 25201, 9334, 15481, 23192, 24740, 30889, 32426, 32437, 15547, 15549, 15551, 20180, 15578, 34013, 15582, 15581, 15589, 25836, 30959, 25845, 5365, 33016, 12034, 25363, 37143, 22296, 21785, 28952, 11043, 22314, 28971, 28974, 28980, 33087, 28998, 20807, 29002, 15180, 21838, 29006, 21348, 29032, 29036, 29040, 25974, 9592, 31107, 32644, 9607, 28553, 15253, 14750, 22944, 10147, 14764, 17331, 20921, 17345, 15327, 11235, 21993}\n",
      "dict_items([(\"Lemma('date.n.01.date')\", 18), (\"Lemma('date.n.05.date')\", 1), (\"Lemma('date.v.01.date')\", 1), (\"Lemma('date.n.03.date')\", 3), (\"Lemma('date.n.02.date')\", 2), (\"Lemma('date.v.03.date')\", 1), (\"Lemma('date.n.04.date')\", 1)])\n",
      "collecting tokens for  birth\n",
      "indices:    {3756, 3758, 3702, 3734, 33016, 23767, 20988}\n",
      "dict_items([(\"Lemma('birth.n.01.birth')\", 3)])\n",
      "collecting tokens for  especially\n",
      "indices:    {2496, 31520, 2720, 4645, 16422, 14663, 12807, 25129, 10891, 12815, 32860, 32890, 11260, 31805}\n",
      "dict_items([(\"Lemma('particularly.r.01.especially')\", 9)])\n",
      "collecting tokens for  relatively\n",
      "indices:    {174}\n",
      "dict_items([(\"Lemma('relatively.r.01.relatively')\", 1)])\n",
      "collecting tokens for  stable\n",
      "indices:    {6465, 29016, 29158, 16198, 29000, 5382, 4617, 4586, 30412, 32940, 18347, 31887, 4967, 29139, 28980, 28952, 28989}\n",
      "dict_items([(\"Lemma('stable.a.01.stable')\", 3), (\"Lemma('stable.s.02.stable')\", 2), (\"Lemma('stable.n.01.stable')\", 1)])\n",
      "collecting tokens for  communities\n",
      "indices:    {5249, 5250, 5252, 4606, 13307, 28692, 22683, 15644, 22690, 32431, 24882, 33075, 13371, 33087, 13377, 24900, 5446, 24907, 20300, 24909, 23762, 23764, 2773, 32982, 27868, 12260, 32617, 26475, 32621, 32625, 32502, 13305, 4603, 23550}\n",
      "dict_items([(\"Lemma('community.n.01.community')\", 10)])\n",
      "collecting tokens for  records\n",
      "indices:    {33088, 21572, 2812, 10181, 32267, 1804, 34284, 30233, 33007, 21490, 1780, 761, 7452, 2462}\n",
      "dict_items([(\"Lemma('phonograph_record.n.01.record')\", 3), (\"Lemma('record.n.01.record')\", 3)])\n",
      "collecting tokens for  marital\n",
      "indices:    {33028, 11972, 33163, 30827, 26525, 30773, 30811, 11997, 33182, 33087}\n",
      "dict_items([(\"Lemma('marital.a.01.marital')\", 2)])\n",
      "collecting tokens for  status\n",
      "indices:    {33028, 32390, 23686, 22795, 24076, 13197, 30225, 32275, 32917, 22039, 13336, 13337, 20633, 2459, 13981, 33182, 32926, 6943, 2078, 15647, 32932, 32934, 25767, 31789, 16431, 14767, 2097, 21426, 12851, 13364, 32948, 21431, 14207, 33087, 22464, 27840, 32963, 16452, 16453, 30919, 24651, 22219, 13775, 33108, 11477, 26197, 1236, 22236, 20319, 32992, 32994, 13287, 1772, 33133, 4596, 31733, 23287, 26747, 13951}\n",
      "dict_items([(\"Lemma('status.n.01.status')\", 18), (\"Lemma('condition.n.01.status')\", 1)])\n",
      "collecting tokens for  others\n",
      "indices:    {28304, 32625, 22252, 23981}\n",
      "dict_items([])\n",
      "collecting tokens for  test\n",
      "indices:    {3587, 5252, 24844, 14733, 4239, 4240, 20627, 32276, 22678, 5782, 30874, 36640, 24610, 2980, 28582, 25384, 29096, 33193, 15657, 33200, 11189, 3514, 3517, 3520, 14280, 27338, 27339, 15690, 4043, 15695, 2896, 22608, 211, 12372, 22621, 21730, 23780, 24302, 3439, 14586, 3071}\n",
      "dict_items([(\"Lemma('trial.n.02.test')\", 4), (\"Lemma('test.v.01.test')\", 8), (\"Lemma('test.n.04.test')\", 2), (\"Lemma('test.n.02.test')\", 1)])\n",
      "collecting tokens for  form\n",
      "indices:    {27031, 15906, 31223, 1156, 4774, 15878, 31878, 30989, 16430, 36431, 32561, 27196, 6046, 15639, 26360, 31578, 32028, 4382}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('form.n.01.form')\", 2), (\"Lemma('kind.n.01.form')\", 3), (\"Lemma('form.v.02.form')\", 1), (\"Lemma('human_body.n.01.form')\", 1)])\n",
      "collecting tokens for  fidelity\n",
      "indices:    {1807, 33038, 1783}\n",
      "dict_items([])\n",
      "collecting tokens for  experience\n",
      "indices:    {27651, 12300, 12301, 16399, 2066, 27669, 11297, 11298, 5160, 4653, 30254, 2097, 4657, 4659, 4664, 2616, 4667, 8252, 9790, 13379, 8260, 11333, 21573, 2122, 26187, 2123, 2126, 24144, 25681, 27217, 34388, 31836, 7261, 32350, 30815, 2656, 30814, 2147, 26215, 30823, 30825, 1642, 4203, 34920, 32886, 32887, 22649, 31876, 13447, 20616, 31880, 31882, 31884, 31885, 31886, 32908, 6806, 11929, 31900, 1693, 31908, 28326, 31913, 8365, 31932, 1221, 13510, 1223, 28362, 1230, 1234, 1235, 24276, 13525, 1241, 1242, 1243, 1244, 1260, 1774, 29936, 14577, 23794, 1269, 26369, 1282, 14596, 1292, 1807, 1811, 14618, 14625, 14629, 29991, 1832, 14633, 32041, 31533, 19764, 32055, 16199, 13642, 13643, 30541, 14669, 13646, 13647, 13649, 4947, 13652, 14676, 4949, 34647, 13655, 13658, 4955, 13659, 13660, 33118, 29537, 12641, 13667, 13670, 5479, 13672, 11625, 27500, 13677, 13676, 5491, 24948, 11126, 15738, 24956, 28543, 1408, 28546, 30083, 21903, 34704, 31123, 15766, 16791, 33179, 26529, 6050, 14241, 14244, 33188, 26534, 2471, 14242, 24497, 7602, 7604, 31157, 32182, 2492, 13244, 16316, 27583, 2498, 33219, 33231, 15826, 13266, 33236, 20437, 12246, 33249, 13281, 33250, 28133, 33255, 28137, 33258, 33259, 24557, 33262, 33261, 15861, 27639, 15866, 27644}\n",
      "dict_items([(\"Lemma('experience.n.01.experience')\", 26), (\"Lemma('experience.n.02.experience')\", 26), (\"Lemma('experience.v.03.experience')\", 3), (\"Lemma('experience.n.03.experience')\", 18), (\"Lemma('know.v.05.experience')\", 5), (\"Lemma('experience.v.01.experience')\", 3)])\n",
      "collecting tokens for  gauge\n",
      "indices:    {29057, 29125, 29126, 31879, 29131, 11181, 29133, 29136, 34518, 29913, 34522, 8318}\n",
      "dict_items([(\"Lemma('gauge.n.01.gauge')\", 1), (\"Lemma('estimate.v.01.gauge')\", 1)])\n",
      "collecting tokens for  accepted\n",
      "indices:    {9603, 32388, 5892, 6, 5253, 36871, 37004, 22412, 31632, 22551, 32154, 29477, 2476, 11182, 27569, 15285, 14773, 11448, 28602, 33212, 25919, 12224, 1348, 23878, 1352, 1359, 11217, 30164, 5600, 23657, 7664, 14321, 25969, 30707, 23675, 36478, 14335}\n",
      "dict_items([(\"Lemma('accept.v.01.accept')\", 11), (\"Lemma('accept.v.02.accept')\", 6), (\"Lemma('accept.v.05.accept')\", 2), (\"Lemma('accept.v.04.accept')\", 3), (\"Lemma('accept.v.03.accept')\", 6), (\"Lemma('bear.v.06.accept')\", 2)])\n",
      "collecting tokens for  abstract\n",
      "indices:    {4963, 27114, 13643, 11086, 11087, 15255, 26321, 5394, 16375, 19572, 26453, 11286, 12215, 16342, 14713, 16350}\n",
      "dict_items([(\"Lemma('abstraction.n.01.abstract')\", 1), (\"Lemma('abstract.s.02.abstract')\", 1), (\"Lemma('abstract.a.01.abstract')\", 5), (\"Lemma('abstract.v.01.abstract')\", 2), (\"Lemma('abstract.v.03.abstract')\", 1)])\n",
      "collecting tokens for  painters\n",
      "indices:    {5030}\n",
      "dict_items([(\"Lemma('painter.n.01.painter')\", 1)])\n",
      "collecting tokens for  destruction\n",
      "indices:    {27783, 3464, 17033, 27529, 2572, 27791, 29967, 31256, 11034, 28444, 7709, 28448, 17057, 24994, 27818, 28459, 14253, 827, 25278, 28479, 26197, 27099, 36956, 1257, 12787, 2429}\n",
      "dict_items([(\"Lemma('destruction.n.01.destruction')\", 6), (\"Lemma('destruction.n.02.destruction')\", 5)])\n",
      "collecting tokens for  cities\n",
      "indices:    {24821, 23605, 142, 32503}\n",
      "dict_items([(\"Lemma('city.n.01.city')\", 1)])\n",
      "collecting tokens for  logical\n",
      "indices:    {15873, 27650, 11658, 3220, 27287, 13976, 28444, 34337, 16802, 5025, 11088, 25300, 469, 14431, 30180, 2148, 4965, 2155, 19439, 22775, 34682}\n",
      "dict_items([(\"Lemma('legitimate.s.02.logical')\", 5), (\"Lemma('logical.a.01.logical')\", 6)])\n",
      "collecting tokens for  act\n",
      "indices:    {9837, 22789}\n",
      "dict_items([(\"Lemma('act.n.04.act')\", 1)])\n",
      "collecting tokens for  complete\n",
      "indices:    {32352, 13252, 10857, 1545, 20332, 2076, 25231, 1808, 3729, 5524, 22773, 19094, 16182, 14772, 11546, 32508, 1565, 32510}\n",
      "dict_items([(\"Lemma('complete.a.01.complete')\", 11), (\"Lemma('complete.v.01.complete')\", 1), (\"Lemma('complete.v.02.complete')\", 1)])\n",
      "collecting tokens for  house\n",
      "indices:    {5088, 19122, 22501}\n",
      "dict_items([(\"Lemma('house.n.01.house')\", 2)])\n",
      "collecting tokens for  comfortably\n",
      "indices:    {30177, 17665, 9187, 14379, 16401, 10897, 14387, 8889}\n",
      "dict_items([(\"Lemma('comfortably.r.01.comfortably')\", 5), (\"Lemma('comfortably.r.02.comfortably')\", 2)])\n",
      "collecting tokens for  cooled\n",
      "indices:    {30177, 2913, 1699, 2916, 30529, 2887, 21288, 2856, 30538, 2897, 29464, 5849, 30141, 19166, 3135}\n",
      "dict_items([(\"Lemma('cool.v.01.cool')\", 7), (\"Lemma('cool.v.02.cool')\", 1)])\n",
      "collecting tokens for  little\n",
      "indices:    {9408, 9697, 19525, 22122, 31118, 6771, 24341, 17847, 31800, 19164}\n",
      "dict_items([(\"Lemma('small.a.01.little')\", 3), (\"Lemma('little.a.02.little')\", 1), (\"Lemma('little.n.01.little')\", 1)])\n",
      "collecting tokens for  $\n",
      "indices:    {20512, 20523, 20531, 55, 56, 58, 60, 62, 20554, 26722, 24677, 24679, 110, 128, 130, 24708, 24710, 20624, 145, 20642, 2212, 2221, 20654, 20655, 30896, 20656, 14519, 2232, 20670, 2240, 20674, 2243, 37070, 20690, 20691, 20692, 214, 20694, 20698, 2268, 22750, 22751, 2272, 20706, 20708, 2277, 20710, 20709, 20712, 2279, 20715, 20717, 20718, 239, 30959, 242, 20724, 245, 30964, 20728, 20730, 20754, 20755, 24893, 31043, 31044, 20805, 20807, 20808, 12645, 12646, 12664, 29053, 12683, 29072, 12695, 12696, 29084, 14748, 12702, 12703, 29088, 29090, 29092, 29095, 29097, 29103, 14771, 29108, 29110, 29113, 29116, 29120, 29122, 29124, 20933, 25030, 29126, 25032, 29129, 29128, 29131, 29133, 29134, 463, 29136, 12776, 23024, 29172, 23034, 23035, 521, 522, 14859, 27160, 14877, 21027, 21028, 27174, 23079, 14888, 27179, 14891, 14893, 14894, 14892, 23103, 14915, 23121, 21083, 23151, 23173, 23186, 23190, 2717, 21154, 21164, 21169, 15041, 15043, 2765, 21227, 21229, 21230, 21232, 27384, 13056, 15106, 774, 15112, 15116, 15119, 13072, 15125, 21270, 13097, 23353, 21312, 21313, 23361, 21318, 23366, 23375, 21327, 23396, 21371, 21375, 23445, 15266, 23492, 23506, 5076, 5077, 5118, 5129, 29708, 21517, 29710, 21518, 5135, 29712, 21522, 29709, 25623, 21545, 23606, 5179, 21572, 21578, 11338, 25675, 23628, 21579, 23629, 23636, 23637, 23638, 21616, 21618, 21619, 21620, 21621, 15477, 15479, 15478, 15483, 15498, 21644, 15501, 15502, 21646, 21653, 15516, 21662, 21692, 23760, 15584, 15595, 21756, 21766, 21767, 21769, 21770, 15631, 15632, 21778, 15635, 15634, 21781, 21782, 15636, 15638, 17691, 21787, 21789, 21790, 21798, 21799, 21800, 21803, 23879, 21832, 23881, 23886, 30091, 21918, 21920, 21928, 21930, 21931, 21932, 23990, 30138, 30150, 21968, 30177, 22002, 22003, 22015, 22016, 22017, 24066, 22018, 22043, 11808, 32301, 32303, 22064, 22063, 22067, 24122, 24141, 11936, 11937, 11939, 11940, 22179, 22182, 28327, 13996, 24242, 32443, 32462, 20176, 20177, 20178, 20186, 20189, 1760, 20202, 20203, 20204, 32529, 22337, 20310, 12135, 16232, 16234, 16235, 16237, 16248, 16249, 18304, 18305, 22406, 22407, 22408, 28562, 14245, 6065, 6066, 16313, 22481, 28640, 28649, 20462, 20463, 20464, 32754, 32761, 28669}\n",
      "dict_items([])\n",
      "collecting tokens for  year\n",
      "indices:    {31040, 36961, 23751, 21769, 15465, 26284, 32207, 32563, 22995, 14484, 21882}\n",
      "dict_items([])\n",
      "collecting tokens for  11\n",
      "indices:    {15488, 20224, 20611, 23045, 23302, 27014, 33202, 16261, 27018, 29692, 15121, 32657, 2834, 32658, 3347, 21657, 2844, 541, 29341, 29093, 15141, 5031, 1965, 16176, 21554, 16178, 3764, 29876, 21301, 16183, 33076, 13241, 25914, 27061, 439, 15040, 15042, 28995, 22340, 21570, 24007, 459, 20812, 32718, 592, 21584, 32336, 32469, 23255, 15321, 25947, 3292, 13276, 30177, 21478, 22374, 617, 13034, 12395, 21868, 25964, 624, 31985, 21362, 627, 21881, 20860}\n",
      "dict_items([(\"Lemma('eleventh.s.01.11th')\", 2), (\"Lemma('eleven.s.01.11')\", 10), (\"Lemma('eleven.n.01.11')\", 6)])\n",
      "collecting tokens for  month\n",
      "indices:    {32768, 17409, 22019, 25608, 36360, 21515, 21516, 21517, 21518, 28172, 21519, 21522, 21015, 33317, 32301, 22064, 22067, 12856, 20537, 33337, 5184, 33350, 11337, 21071, 35922, 1621, 1113, 19554, 21610, 16495, 22139, 4743, 1684, 28309, 37012, 669, 683, 25774, 23217, 25781, 5307, 15548, 28352, 15555, 15559, 15560, 15561, 28360, 21196, 32463, 15567, 12511, 29923, 31985, 7926, 247, 10490, 21766, 21260, 8466, 23847, 22318, 21294, 25395, 31030, 25912, 332, 21328, 10580, 26967, 26971, 12129, 23397, 1393, 21875, 25974, 15750, 5516, 21911, 12695, 12696, 22937, 14769, 14770, 963, 25030, 25032, 5577, 24008, 15314, 15317, 15319, 23003, 15327, 15328, 15843, 16362, 23024, 1527, 25594}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('calendar_month.n.01.month')\", 26), (\"Lemma('month.n.02.month')\", 8)])\n",
      "collecting tokens for  worries\n",
      "indices:    {27426, 8802, 8804, 27430, 6254, 12945, 27185, 36148, 27414, 27227, 17691, 8733, 5886}\n",
      "dict_items([(\"Lemma('worry.v.01.worry')\", 3), (\"Lemma('concern.n.04.worry')\", 6), (\"Lemma('worry.n.02.worry')\", 1)])\n",
      "collecting tokens for  small\n",
      "indices:    {1385, 14596, 19335}\n",
      "dict_items([(\"Lemma('minor.s.10.small')\", 1), (\"Lemma('person.n.01.person')\", 1), (\"Lemma('small.a.01.small')\", 1)])\n",
      "collecting tokens for  ones\n",
      "indices:    {23237, 19494, 32170, 10891, 10095, 24500, 27478, 59}\n",
      "dict_items([])\n",
      "collecting tokens for  mother\n",
      "indices:    {36978}\n",
      "dict_items([])\n",
      "collecting tokens for  daughter\n",
      "indices:    {9280, 22252, 25686}\n",
      "dict_items([(\"Lemma('daughter.n.01.daughter')\", 1)])\n",
      "collecting tokens for  might\n",
      "indices:    {9217, 35330, 30211, 6152, 5648, 30229, 27161, 7193, 2587, 2590, 16418, 22054, 2607, 14384, 30768, 35378, 9783, 34874, 22592, 9797, 17485, 34897, 34386, 595, 26197, 20058, 25181, 1120, 23142, 31848, 22635, 10350, 6255, 22640, 10351, 5752, 35967, 35968, 9345, 12934, 35979, 5774, 3727, 17044, 32917, 12965, 23723, 23212, 23725, 8878, 16048, 31920, 6328, 37049, 16570, 31419, 23225, 1213, 12482, 5318, 36039, 11464, 3804, 23773, 14063, 24822, 17151, 5887, 19714, 29443, 6407, 1291, 33554, 26900, 14618, 23835, 18732, 26412, 17199, 9008, 17201, 4402, 7487, 25410, 18250, 3922, 31060, 34132, 30037, 4948, 19293, 33117, 17251, 16229, 1895, 16745, 874, 17258, 23918, 16764, 16765, 33148, 3455, 1926, 33159, 25998, 27022, 3988, 33179, 19359, 23968, 34212, 24493, 5043, 21428, 36791, 1471, 18367, 31679, 12737, 31689, 25038, 36306, 27091, 25042, 33749, 17893, 14312, 33263, 11252, 15349, 19958, 8697, 8703}\n",
      "dict_items([(\"Lemma('might.n.01.might')\", 2)])\n",
      "collecting tokens for  doing\n",
      "indices:    {34821, 17422, 8730, 17946, 34849, 35876, 2598, 19496, 2601, 25129, 22061, 33326, 16433, 16435, 9790, 17982, 19521, 15426, 27717, 10310, 13902, 23631, 30806, 15962, 19546, 1115, 32869, 6249, 10345, 6254, 17007, 25199, 12408, 6265, 647, 17036, 27789, 27795, 9368, 28313, 9369, 33947, 35996, 24216, 10909, 27801, 37026, 32420, 9894, 36521, 6316, 19632, 26290, 28853, 34997, 20153, 10426, 33979, 27838, 19134, 9410, 12997, 19660, 37075, 1237, 26843, 14568, 7402, 10988, 36079, 9469, 25346, 24836, 776, 22284, 36113, 25875, 6936, 23837, 13601, 12069, 21296, 24369, 3888, 24378, 10044, 1362, 344, 25944, 8539, 4971, 35694, 18296, 34690, 25478, 9094, 28553, 7051, 24973, 18322, 22419, 33685, 27545, 926, 11683, 24496, 26545, 33715, 9659, 24000, 35787, 19919, 9168, 33243, 15327, 26593, 25572, 30201, 13306, 25086, 13311}\n",
      "dict_items([(\"Lemma('make.v.01.do')\", 26), (\"Lemma('do.v.03.do')\", 8), (\"Lemma('perform.v.01.do')\", 20), (\"Lemma('do.v.04.do')\", 4), (\"Lemma('benefit.v.02.do_good')\", 1), (\"Lemma('serve.v.09.do')\", 1), (\"Lemma('cause.v.01.do')\", 4), (\"Lemma('practice.v.01.do')\", 2), (\"Lemma('dress.v.16.do')\", 1)])\n",
      "collecting tokens for  hour\n",
      "indices:    {1025, 34308, 1032, 1034, 28171, 28177, 16913, 16915, 21522, 3106, 31266, 29220, 23079, 23080, 10299, 3136, 4161, 35911, 2123, 19538, 13394, 36948, 18013, 36967, 6254, 17519, 22131, 24692, 22133, 33910, 33913, 18553, 7292, 15488, 23169, 21638, 8342, 17559, 19096, 8344, 19615, 19109, 7334, 18090, 9390, 23732, 22202, 36539, 16571, 198, 33486, 3283, 3285, 3291, 14557, 37090, 10477, 20227, 2822, 17679, 26384, 37138, 20756, 17685, 17684, 19734, 6941, 10013, 21279, 26399, 36640, 13086, 30500, 22311, 26410, 7472, 15159, 11064, 5437, 830, 326, 8526, 26963, 34133, 3419, 26974, 30565, 5990, 31081, 20842, 3448, 21375, 31107, 29063, 7051, 19345, 22930, 9623, 28571, 36257, 12706, 17315, 22954, 22959, 12720, 12722, 12740, 25032, 30158, 31698, 27603, 30164, 30679, 11735, 32219, 29147, 11739, 27103, 15843, 12772, 16868, 11747, 32232, 24048, 28661}\n",
      "dict_items([(\"Lemma('hour.n.01.hour')\", 26), (\"Lemma('hour.n.02.hour')\", 15)])\n",
      "collecting tokens for  aunt\n",
      "indices:    {6421}\n",
      "dict_items([])\n",
      "collecting tokens for  asia\n",
      "indices:    {27753}\n",
      "dict_items([])\n",
      "collecting tokens for  philadelphia\n",
      "indices:    {14447}\n",
      "dict_items([(\"Lemma('philadelphia.n.01.Philadelphia')\", 1)])\n",
      "collecting tokens for  byron\n",
      "indices:    {23311}\n",
      "dict_items([])\n",
      "collecting tokens for  inquired\n",
      "indices:    {14498, 8391, 17384, 10687, 10730, 6413, 18862, 20145, 6079, 24796, 10719}\n",
      "dict_items([(\"Lemma('ask.v.01.inquire')\", 8), (\"Lemma('wonder.v.01.inquire')\", 3)])\n",
      "collecting tokens for  however\n",
      "indices:    {34435, 13204, 4950}\n",
      "dict_items([(\"Lemma('however.r.01.however')\", 2)])\n",
      "collecting tokens for  rich\n",
      "indices:    {7712, 10552, 28627, 5212}\n",
      "dict_items([(\"Lemma('rich.a.01.rich')\", 2), (\"Lemma('location.n.01.location')\", 1)])\n",
      "collecting tokens for  theory\n",
      "indices:    {33024, 2177, 16132, 33031, 4872, 27149, 29053, 4879, 13710, 16401, 4241, 16398, 16143, 27797, 5265, 16407, 14103, 5273, 13464, 16416, 3108, 11045, 2984, 36905, 36906, 16425, 33070, 26806, 32952, 11448, 23610, 23611, 13626, 14717, 15678, 26815, 16448, 13636, 26821, 26822, 16072, 16074, 15818, 26828, 16458, 16075, 26191, 15822, 4817, 4818, 4825, 4826, 1499, 15715, 3046, 3047, 2151, 2153, 2150, 3048, 23935, 14703, 3056, 14704, 17394, 22771, 2160, 4853, 32882, 5240, 22777, 4860, 4861, 2559}\n",
      "dict_items([(\"Lemma('theory.n.01.theory')\", 26), (\"Lemma('hypothesis.n.02.theory')\", 11), (\"Lemma('theory.n.03.theory')\", 2)])\n",
      "collecting tokens for  completely\n",
      "indices:    {11293, 12838, 30765, 3633, 27703, 9793, 9798, 3660, 2128, 32342, 2134, 11352, 4697, 33371, 11355, 4707, 2152, 2161, 2181, 29833, 35991, 15512, 20631, 33943, 15005, 34976, 34977, 5298, 30389, 14518, 4285, 36038, 31966, 22756, 5355, 12012, 22267, 30977, 8451, 5389, 30993, 1302, 1304, 20250, 1306, 25884, 1309, 27425, 1326, 2351, 4919, 25401, 24891, 13629, 1347, 27972, 28484, 1359, 21331, 3931, 29024, 15723, 29557, 5504, 3969, 22401, 32133, 9609, 14230, 29079, 1950, 14244, 29096, 30123, 33202, 30139, 17340, 25049, 3035, 33248, 2018, 4070, 5627, 31741}\n",
      "dict_items([(\"Lemma('wholly.r.01.completely')\", 26), (\"Lemma('completely.r.02.completely')\", 10)])\n",
      "collecting tokens for  loss\n",
      "indices:    {388, 2953, 2957, 4111, 36880, 21778, 4252, 3102, 3103, 31008, 31009, 28452, 3109, 6054, 15274, 2858, 12076, 5549, 11697, 25137, 30771, 12084, 312, 22846, 959, 7743, 20670, 36673, 2879, 21574, 13255, 328, 5450, 22219, 14926, 37072, 2513, 25810, 850, 25044, 25426, 214, 32855, 25045, 30680, 26459, 22236, 11100, 31076, 27879, 2152, 31464, 14191, 3313, 14197, 25461, 27767, 7679}\n",
      "dict_items([(\"Lemma('loss.n.02.loss')\", 9), (\"Lemma('loss.n.01.loss')\", 10), (\"Lemma('loss.n.03.loss')\", 3), (\"Lemma('loss.n.04.loss')\", 4), (\"Lemma('loss.n.05.loss')\", 3), (\"Lemma('loss.n.06.loss')\", 1)])\n",
      "collecting tokens for  image\n",
      "indices:    {4481, 2693, 24838, 2313, 32777, 32779, 32781, 23695, 32144, 30739, 32788, 30740, 32790, 5397, 30744, 32793, 32794, 32798, 32800, 28194, 32802, 32804, 32805, 21538, 11303, 32808, 36517, 32809, 32812, 32814, 7599, 32816, 13614, 13616, 13615, 32815, 32821, 1465, 14266, 1466, 19644, 31165, 1467, 27839, 32834, 1474, 18242, 32837, 7877, 32838, 20424, 32843, 13644, 27857, 13651, 31831, 2652, 2654, 2143, 11360, 2148, 2149, 2152, 26216, 2154, 2155, 2156, 14188, 9582, 14191, 13946, 9979}\n",
      "dict_items([(\"Lemma('image.n.01.image')\", 15), (\"Lemma('prototype.n.01.image')\", 2), (\"Lemma('persona.n.02.image')\", 7), (\"Lemma('trope.n.01.image')\", 1), (\"Lemma('picture.n.01.image')\", 5)])\n",
      "collecting tokens for  possibly\n",
      "indices:    {2176, 8828, 27781, 17546, 16395, 27799, 27801, 24477, 23712, 35749, 9784, 6842, 21958, 17611, 2641, 16723, 15706, 11620, 33395, 14452, 11508, 25212}\n",
      "dict_items([(\"Lemma('possibly.r.01.possibly')\", 12)])\n",
      "collecting tokens for  received\n",
      "indices:    {22019, 3, 14342, 22022, 20490, 22031, 21520, 22032, 22043, 22044, 1052, 27678, 24096, 14881, 27681, 22052, 24612, 31783, 24617, 21546, 22571, 28207, 12851, 34869, 28214, 30775, 34359, 5182, 10817, 69, 76, 24141, 23628, 84, 24661, 33375, 28263, 2152, 36980, 36982, 27265, 11403, 24725, 163, 23207, 26282, 23217, 14004, 21174, 14519, 23226, 26814, 15043, 32455, 27344, 32469, 32476, 37085, 29921, 29926, 27369, 24820, 30453, 23286, 16119, 12538, 2825, 2826, 21260, 15629, 20751, 23825, 21781, 18199, 16673, 18212, 12587, 15161, 21309, 15179, 6995, 21334, 25944, 13660, 30559, 2916, 4972, 35695, 9592, 31101, 18304, 18305, 22404, 25482, 20369, 14744, 28571, 17821, 9143, 31674, 15803, 27585, 32710, 463, 10713, 13786, 10718, 484, 32746, 21484, 21486, 20472, 27643}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('pick_up.v.09.receive')\", 10), (\"Lemma('receive.v.05.receive')\", 9), (\"Lemma('receive.v.01.receive')\", 26), (\"Lemma('receive.v.06.receive')\", 4), (\"Lemma('receive.v.02.receive')\", 10), (\"Lemma('experience.v.03.receive')\", 10), (\"Lemma('receive.v.08.receive')\", 1), (\"Lemma('welcome.v.02.receive')\", 1)])\n",
      "collecting tokens for  brain\n",
      "indices:    {2176, 34759, 36052, 34677, 2169, 17309}\n",
      "dict_items([(\"Lemma('brain.n.01.brain')\", 3)])\n",
      "collecting tokens for  far\n",
      "indices:    {13957, 25669, 25163, 33102, 14800, 2236}\n",
      "dict_items([(\"Lemma('far.r.01.far')\", 2)])\n",
      "collecting tokens for  evidence\n",
      "indices:    {27521, 2754, 21346, 16830, 4741, 14855, 4040, 21353, 5003, 4941, 14767, 4916, 20853, 31254, 9783, 14133, 1310}\n",
      "dict_items([(\"Lemma('evidence.n.01.evidence')\", 7), (\"Lemma('evidence.n.02.evidence')\", 3), (\"Lemma('evidence.n.03.evidence')\", 1)])\n",
      "collecting tokens for  indicate\n",
      "indices:    {11392, 14849, 14593, 34053, 16137, 30987, 3340, 25998, 11408, 3348, 2837, 11415, 27679, 17314, 15651, 30755, 31138, 25122, 28711, 16043, 10283, 18349, 3765, 3894, 17207, 24887, 32317, 28862, 33215, 32448, 3392, 14019, 20421, 4167, 2376, 2763, 21068, 32589, 28747, 33108, 728, 27994, 32991, 11232, 13670, 3943, 15592, 35688, 15594, 4202, 32511, 22143}\n",
      "dict_items([(\"Lemma('indicate.v.02.indicate')\", 14), (\"Lemma('bespeak.v.01.indicate')\", 24), (\"Lemma('argue.v.03.indicate')\", 9), (\"Lemma('indicate.v.03.indicate')\", 5)])\n",
      "collecting tokens for  under\n",
      "indices:    {19180, 26077, 31278, 22063}\n",
      "dict_items([])\n",
      "collecting tokens for  control\n",
      "indices:    {22785, 14466, 2307, 34691, 31245, 23960, 31896, 14745, 12314, 3481, 17566, 14623, 14241, 15393, 20257, 27425, 31269, 32549, 34607, 16432, 11316, 1716, 28086, 14909, 28098, 11588, 25669, 30790, 2634, 31358, 21964, 33236, 15838, 14176, 33250, 31975, 25575, 23273, 17769, 27374, 31090, 12274, 32117, 22777, 12286, 22783}\n",
      "dict_items([(\"Lemma('operate.v.03.control')\", 1), (\"Lemma('control.n.01.control')\", 5), (\"Lemma('control.n.02.control')\", 3), (\"Lemma('control.n.03.control')\", 2), (\"Lemma('control.v.02.control')\", 3), (\"Lemma('control_condition.n.01.control')\", 1), (\"Lemma('control.n.05.control')\", 1), (\"Lemma('control.v.01.control')\", 1)])\n",
      "collecting tokens for  contrary\n",
      "indices:    {11488, 1281, 26561, 4836, 6846, 4845, 12302, 29489, 13266, 30099, 12916, 35998, 23806}\n",
      "dict_items([(\"Lemma('contrary.s.01.contrary')\", 2), (\"Lemma('reverse.n.01.contrary')\", 1), (\"Lemma('contrary.s.02.contrary')\", 1)])\n",
      "collecting tokens for  miss\n",
      "indices:    {26713, 29306}\n",
      "dict_items([(\"Lemma('miss.v.03.miss')\", 1)])\n",
      "collecting tokens for  chose\n",
      "indices:    {26243, 33159, 33161, 14478, 26646, 23322, 21147, 21149, 21151, 36000, 15647, 6438, 22987, 34766, 36817, 5598, 25964, 26350, 34671, 8432, 35962, 22140, 22141}\n",
      "dict_items([(\"Lemma('choose.v.01.choose')\", 11), (\"Lemma('choose.v.02.choose')\", 9), (\"Lemma('choose.v.03.choose')\", 3)])\n",
      "collecting tokens for  arrangements\n",
      "indices:    {25345, 8002, 28675, 28741, 23471, 24594, 22644, 12284, 12286}\n",
      "dict_items([(\"Lemma('arrangement.n.03.arrangement')\", 2), (\"Lemma('agreement.n.04.arrangement')\", 1)])\n",
      "collecting tokens for  works\n",
      "indices:    {23323, 26631, 26975, 25999}\n",
      "dict_items([(\"Lemma('work.v.02.work')\", 1)])\n",
      "collecting tokens for  composers\n",
      "indices:    {11202, 11203, 26341, 26324, 26006, 26623}\n",
      "dict_items([(\"Lemma('composer.n.01.composer')\", 2)])\n",
      "collecting tokens for  want\n",
      "indices:    {12162, 33914, 14599, 6794, 7306, 33935, 18325, 11801, 20127, 35831, 35125, 17847, 10680, 7865, 8140, 16973, 9036, 18901, 4442, 1118, 19299, 13156, 16618, 15852, 12141, 31088, 16497, 17778, 14193, 17780, 9458, 29306, 8311, 19962, 26622}\n",
      "dict_items([(\"Lemma('desire.v.01.want')\", 25), (\"Lemma('want.v.02.want')\", 1), (\"Lemma('want.v.03.want')\", 1)])\n",
      "collecting tokens for  discuss\n",
      "indices:    {32260, 23300, 2573, 16149, 33182, 2470, 1575, 2360, 23997, 27327, 22339, 2373, 27594, 13259, 32080, 36703, 3055, 4465, 14067, 8819, 23294}\n",
      "dict_items([(\"Lemma('discourse.v.01.discuss')\", 12), (\"Lemma('hash_out.v.01.discuss')\", 9)])\n",
      "collecting tokens for  second\n",
      "indices:    {25700, 3911, 13739, 12268, 16396, 17424, 13747, 16023, 28763}\n",
      "dict_items([(\"Lemma('second.s.01.second')\", 6), (\"Lemma('second.r.01.second')\", 1)])\n",
      "collecting tokens for  quite\n",
      "indices:    {27425, 22786, 36328, 33673, 26666, 6027, 13759, 1385, 8334, 10319, 661, 13688, 16410, 2587, 13693, 3871}\n",
      "dict_items([(\"Lemma('quite.r.02.quite')\", 7), (\"Lemma('quite.r.01.quite')\", 2), (\"Lemma('quite.r.03.quite')\", 2)])\n",
      "collecting tokens for  different\n",
      "indices:    {13473, 28961, 34339, 15657, 28362, 5035, 27290, 29071, 13043, 3871, 15358, 20247, 2489, 33018, 9949, 16830, 7487}\n",
      "dict_items([(\"Lemma('different.a.01.different')\", 9), (\"Lemma('different.s.02.different')\", 1)])\n",
      "collecting tokens for  fruit\n",
      "indices:    {1697, 1700, 30469, 21639, 1707, 1485, 36207, 29426, 30492}\n",
      "dict_items([(\"Lemma('fruit.n.01.fruit')\", 4)])\n",
      "collecting tokens for  science\n",
      "indices:    {28039}\n",
      "dict_items([])\n",
      "collecting tokens for  connection\n",
      "indices:    {20228, 32901, 14854, 27527, 3464, 1418, 14859, 1291, 2573, 22037, 14870, 20247, 14616, 3994, 15003, 3996, 14748, 13342, 33055, 11039, 31521, 33065, 28725, 14006, 14010, 12222, 27838, 8256, 31167, 4929, 26691, 2372, 28101, 25037, 17230, 26705, 22612, 471, 3420, 22495, 12257, 2401, 32486, 34680, 21625, 15611, 15612}\n",
      "dict_items([(\"Lemma('connection.n.01.connection')\", 12), (\"Lemma('connection.n.02.connection')\", 8)])\n",
      "collecting tokens for  between\n",
      "indices:    {31111, 5140, 13976, 12198, 27816, 25128, 4272, 2502, 34887, 27087, 12885, 3165, 12268, 31853, 2927, 23670, 32503, 20728, 23935}\n",
      "dict_items([])\n",
      "collecting tokens for  scientific\n",
      "indices:    {2560, 27328, 27392, 32708, 3719, 14732, 14735, 22449, 25400, 1238, 1240, 2234, 32699, 32767}\n",
      "dict_items([(\"Lemma('scientific.a.02.scientific')\", 4), (\"Lemma('scientific.a.01.scientific')\", 3)])\n",
      "collecting tokens for  understanding\n",
      "indices:    {4775, 14663, 25129, 25128, 26091, 28141, 14679}\n",
      "dict_items([(\"Lemma('understanding.n.01.understanding')\", 2), (\"Lemma('understand.v.01.understand')\", 1)])\n",
      "collecting tokens for  fear\n",
      "indices:    {35992, 2587, 2594, 19248, 6321, 25138, 28096, 27459, 12998, 5837, 10832, 28117, 5464, 6876, 5084, 6879, 9186, 6897, 1267, 23668, 27519}\n",
      "dict_items([(\"Lemma('fearfully.r.01.fearfully')\", 1), (\"Lemma('fear.n.01.fear')\", 10), (\"Lemma('fear.v.02.fear')\", 5), (\"Lemma('concern.n.02.fear')\", 1)])\n",
      "collecting tokens for  grains\n",
      "indices:    {25121, 30436, 30438, 30440, 30450, 3667, 30484, 30485, 30486, 30460}\n",
      "dict_items([(\"Lemma('grain.n.01.grain')\", 1)])\n",
      "collecting tokens for  seeds\n",
      "indices:    {24228, 1672, 1610, 29516, 1613, 1614, 1612, 1626, 30460, 1629}\n",
      "dict_items([(\"Lemma('seed.n.01.seed')\", 7)])\n",
      "collecting tokens for  used\n",
      "indices:    {13824, 15873, 17410, 3587, 24577, 28685, 29711, 28688, 15891, 1555, 29715, 29212, 4125, 14364, 29729, 10277, 4135, 28711, 29737, 10283, 1580, 1582, 4147, 4148, 3123, 11318, 30263, 29749, 24127, 29760, 28737, 3139, 29765, 28745, 30284, 30285, 9806, 19536, 29778, 3155, 35413, 29782, 14423, 25173, 25692, 3166, 29797, 11366, 3173, 24170, 1644, 3182, 32881, 30323, 29813, 24696, 29817, 11384, 31873, 3201, 8840, 29836, 11409, 11410, 11413, 25749, 11416, 21663, 19616, 15011, 2211, 15018, 1706, 16556, 15020, 15031, 24248, 15545, 17082, 4796, 28861, 11455, 3266, 20162, 15044, 28869, 3268, 1225, 28877, 23760, 29904, 23761, 30419, 29396, 17109, 15062, 33495, 15064, 35028, 15066, 28896, 2279, 28904, 22249, 16107, 15087, 15091, 30454, 5880, 33018, 12031, 28928, 28929, 29443, 33028, 15109, 14085, 5384, 32522, 28939, 30476, 30479, 2835, 28950, 29977, 1305, 30490, 1307, 2333, 20253, 1823, 16160, 11039, 21282, 11042, 3362, 28452, 11046, 21287, 28451, 33065, 36140, 13101, 3377, 3891, 4406, 34102, 9529, 31034, 33085, 14144, 26945, 3909, 2374, 15686, 31047, 15689, 2890, 15696, 13655, 15191, 11610, 15195, 14176, 21864, 8042, 25454, 1396, 20853, 15734, 2423, 21376, 31106, 5509, 22918, 1927, 29574, 29577, 29580, 15756, 32655, 31120, 25491, 2965, 8087, 11675, 16286, 27551, 29089, 21925, 7078, 14762, 4010, 2988, 33197, 6570, 8112, 3508, 4533, 3509, 16309, 7611, 9151, 3522, 15813, 15814, 32711, 3528, 14796, 3532, 33229, 14804, 19417, 28637, 34271, 15840, 3552, 2018, 3555, 13282, 10213, 3563, 3053, 29168, 24562, 11252, 14845}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('use.v.01.use')\", 26), (\"Lemma('secondhand.s.02.used')\", 1), (\"Lemma('exploited.s.02.used')\", 1), (\"Lemma('use.v.02.use')\", 3), (\"Lemma('use.v.03.use')\", 3), (\"Lemma('used.a.01.used')\", 2)])\n",
      "collecting tokens for  dishes\n",
      "indices:    {29184, 10434, 9219, 35071, 9410, 26855, 10345, 10348, 30476, 22111, 9422, 37008, 37005, 37075, 30460, 11999}\n",
      "dict_items([(\"Lemma('dish.n.01.dish')\", 7)])\n",
      "collecting tokens for  three\n",
      "indices:    {27521, 18309, 19343, 18714, 21787, 3868, 289, 11943, 33192, 26550, 14646, 32446, 30398, 22849, 24259, 19532, 35410, 15059, 8274, 22995, 4439, 29656, 12252, 9186, 27746, 35812, 9192, 23027, 5111, 29692}\n",
      "dict_items([(\"Lemma('three.s.01.three')\", 12), (\"Lemma('three.n.01.three')\", 3)])\n",
      "collecting tokens for  four\n",
      "indices:    {13601, 4487, 9449, 14572, 22995, 23348, 437, 32509}\n",
      "dict_items([(\"Lemma('four.s.01.four')\", 5)])\n",
      "collecting tokens for  vague\n",
      "indices:    {25408, 8257, 18849, 14499, 17255, 2184, 11371, 2189, 16206, 31348, 1111, 5752, 13978, 23259}\n",
      "dict_items([(\"Lemma('obscure.s.01.vague')\", 9), (\"Lemma('dim.s.02.vague')\", 1)])\n",
      "collecting tokens for  figures\n",
      "indices:    {16865, 13637, 14245, 2247, 24837, 36074, 11119, 3929, 24026}\n",
      "dict_items([(\"Lemma('figure.n.07.figure')\", 2), (\"Lemma('figure.n.04.figure')\", 2), (\"Lemma('figure.n.01.figure')\", 1), (\"Lemma('digit.n.01.figure')\", 1)])\n",
      "collecting tokens for  family\n",
      "indices:    {22371, 22564, 12268, 31756, 12143, 25554, 6418, 32860, 30013, 21375}\n",
      "dict_items([(\"Lemma('family.n.01.family')\", 1), (\"Lemma('family.n.02.family')\", 1)])\n",
      "collecting tokens for  estate\n",
      "indices:    {27844, 17350, 22492, 22347, 23981, 6104, 27898, 14492, 32381, 25950}\n",
      "dict_items([(\"Lemma('estate.n.01.estate')\", 1)])\n",
      "collecting tokens for  situated\n",
      "indices:    {32385, 26945, 8387, 32388, 32394, 32171, 35678, 3803, 30396, 32381, 26910}\n",
      "dict_items([(\"Lemma('situate.v.01.situate')\", 3), (\"Lemma('located.s.01.situated')\", 1)])\n",
      "collecting tokens for  near\n",
      "indices:    {21509, 7559, 27272, 18855, 18215, 4521, 4524, 36015, 32563, 56, 12473, 16316, 33084, 21442, 3911, 3922, 28627, 19796, 35926, 34136, 22492, 6118, 5993, 22641, 12154, 31358, 1791}\n",
      "dict_items([(\"Lemma('near.a.01.near')\", 8), (\"Lemma('about.r.07.near')\", 1), (\"Lemma('near.r.01.near')\", 1)])\n",
      "collecting tokens for  lake\n",
      "indices:    {30517}\n",
      "dict_items([])\n",
      "collecting tokens for  va\n",
      "indices:    {24964}\n",
      "dict_items([])\n",
      "collecting tokens for  ^\n",
      "indices:    {31620, 13830, 13831, 31626, 31627, 26514, 26795, 33202, 26803, 13881, 33211, 13884, 11454, 33214, 33218, 30022, 33224, 33105, 33242, 23260, 23135, 13791, 33249, 13807, 23153, 13818}\n",
      "dict_items([])\n",
      "collecting tokens for  central\n",
      "indices:    {23240, 20317}\n",
      "dict_items([])\n",
      "collecting tokens for  sweden\n",
      "indices:    {13874}\n",
      "dict_items([(\"Lemma('sweden.n.01.Sweden')\", 1)])\n",
      "collecting tokens for  jury\n",
      "indices:    {2, 3, 20163, 21542, 21353, 15786, 13, 21680, 19, 21685, 21304, 25, 21691}\n",
      "dict_items([(\"Lemma('jury.n.01.jury')\", 5), (\"Lemma('jury.n.02.jury')\", 1)])\n",
      "collecting tokens for  asked\n",
      "indices:    {5744, 5874, 31356, 14182}\n",
      "dict_items([(\"Lemma('ask.v.01.ask')\", 4)])\n",
      "collecting tokens for  judge\n",
      "indices:    {1120, 34522, 21210, 22563}\n",
      "dict_items([(\"Lemma('evaluate.v.02.judge')\", 1), (\"Lemma('estimate.v.01.judge')\", 1)])\n",
      "collecting tokens for  cash\n",
      "indices:    {28416, 22017, 24335, 11666, 16531, 16533, 16538, 21789, 7197, 7198, 20640, 32547, 32548, 21929, 8746, 11696, 21169, 36679, 21348, 12138, 28671}\n",
      "dict_items([(\"Lemma('cash.n.01.cash')\", 6), (\"Lemma('cash.v.01.cash')\", 1)])\n",
      "collecting tokens for  send\n",
      "indices:    {34428, 17793, 31362, 13096, 15596, 36848, 17425, 5137, 12689, 33398, 9691, 30492}\n",
      "dict_items([(\"Lemma('mail.v.02.send')\", 1), (\"Lemma('send.v.01.send')\", 7), (\"Lemma('air.v.03.send')\", 1), (\"Lemma('send.v.02.send')\", 1)])\n",
      "collecting tokens for  written\n",
      "indices:    {3762, 14855}\n",
      "dict_items([(\"Lemma('write.v.05.write')\", 1), (\"Lemma('written.a.01.written')\", 1)])\n",
      "collecting tokens for  definition\n",
      "indices:    {1568, 1569, 1570, 1571, 32900, 23205, 1575, 8233, 1578, 1580, 30164, 27702, 6907, 1310, 4319}\n",
      "dict_items([(\"Lemma('definition.n.02.definition')\", 8), (\"Lemma('definition.n.01.definition')\", 3)])\n",
      "collecting tokens for  difference\n",
      "indices:    {27649, 33288, 25611, 19470, 15378, 11795, 26652, 16414, 13342, 26143, 26146, 34349, 22574, 25650, 1086, 20032, 18500, 3659, 10336, 3687, 27251, 3705, 9853, 27266, 27280, 3742, 23712, 27302, 3754, 15027, 15028, 4275, 3769, 3276, 31961, 11485, 15070, 15071, 31966, 33505, 31967, 3812, 4845, 1775, 31984, 4848, 14581, 31990, 5368, 4857, 31997, 31998, 14599, 30998, 3357, 12062, 16160, 20786, 3892, 3893, 37174, 3897, 3898, 2362, 3899, 15700, 15703, 13144, 21355, 2413, 4463, 24952, 33145, 13186, 33158, 12166, 33160, 12683, 20367, 12175, 29077, 13718, 33188, 2981, 4522, 4523, 33196, 4527, 14769, 14770, 18867, 4533, 3006, 3025, 11221, 3030, 18905, 28126, 19951, 2031, 2037, 12280, 3577}\n",
      "dict_items([(\"Lemma('difference.n.01.difference')\", 26), (\"Lemma('deviation.n.01.difference')\", 9), (\"Lemma('dispute.n.01.difference')\", 1), (\"Lemma('difference.n.04.difference')\", 1)])\n",
      "collecting tokens for  surprised\n",
      "indices:    {24454, 16647, 23178, 18442, 25227, 9359, 35728, 13717, 20375, 9496, 17056, 6181, 36651, 13998, 24373, 9152, 449, 9794, 8516, 15429, 8265, 16713, 16723, 15702, 34137, 8541, 9054, 19679, 9181, 17247, 9069, 25965, 24051, 30838, 27127, 21371}\n",
      "dict_items([(\"Lemma('surprised.a.01.surprised')\", 14), (\"Lemma('surprise.v.01.surprise')\", 12), (\"Lemma('surprise.v.02.surprise')\", 1)])\n",
      "collecting tokens for  roy\n",
      "indices:    {35226}\n",
      "dict_items([])\n",
      "collecting tokens for  stopped\n",
      "indices:    {26880, 36736, 6146, 5763, 28162, 34949, 7174, 8707, 9216, 21513, 14986, 7179, 21387, 9994, 24462, 36751, 6928, 7184, 402, 31507, 36885, 8726, 36631, 35096, 35737, 8603, 16796, 24732, 36638, 18974, 30370, 7971, 6180, 7205, 34086, 1058, 36644, 10153, 20392, 6188, 9007, 9656, 7737, 36285, 7741, 34879, 19142, 22982, 21320, 30411, 33740, 33867, 18126, 28623, 36943, 19286, 8919, 7256, 8537, 24022, 9179, 2268, 8928, 19812, 33892, 36452, 9703, 25832, 36069, 33640, 9961, 31467, 35970, 30578, 6901, 30972}\n",
      "dict_items([(\"Lemma('discontinue.v.01.stop')\", 26), (\"Lemma('stop.v.01.stop')\", 26), (\"Lemma('stop.v.04.stop')\", 3), (\"Lemma('stop.v.05.stop')\", 3), (\"Lemma('stop.v.03.stop')\", 1), (\"Lemma('break.v.10.stop')\", 1), (\"Lemma('check.v.18.stop')\", 1), (\"Lemma('intercept.v.01.stop')\", 1)])\n",
      "collecting tokens for  beside\n",
      "indices:    {14080, 35973, 11014, 31368, 7058, 17043, 33817, 34983, 9513, 34223, 5952, 34881, 33986, 34000, 30166, 34911, 7653, 34792, 879, 2672, 6128, 36726, 34807}\n",
      "dict_items([])\n",
      "collecting tokens for  early\n",
      "indices:    {12499}\n",
      "dict_items([(\"Lemma('early_on.r.01.early')\", 1)])\n",
      "collecting tokens for  country\n",
      "indices:    {24578, 32196, 21092, 12325, 34939}\n",
      "dict_items([(\"Lemma('state.n.04.country')\", 1)])\n",
      "collecting tokens for  teaching\n",
      "indices:    {1316, 22725, 25799, 25801, 15701}\n",
      "dict_items([(\"Lemma('teaching.n.01.teaching')\", 1), (\"Lemma('teach.v.01.teach')\", 1)])\n",
      "collecting tokens for  call\n",
      "indices:    {30945, 27592, 25129, 24777, 20620, 8149, 17206, 36570, 34428}\n",
      "dict_items([(\"Lemma('name.v.01.call')\", 3), (\"Lemma('call.v.07.call')\", 1), (\"Lemma('call.v.02.call')\", 1), (\"Lemma('call.v.03.call')\", 1)])\n",
      "collecting tokens for  mountain\n",
      "indices:    {18202, 29306}\n",
      "dict_items([])\n",
      "collecting tokens for  town\n",
      "indices:    {32385, 6145, 34305, 9222, 32394, 37002, 29837, 17549, 19471, 6037, 20383, 7839, 5159, 32423, 2472, 11434, 12715, 5165, 29250, 19653, 32598, 23133, 33758, 610, 22501, 6505, 5993, 17907}\n",
      "dict_items([(\"Lemma('town.n.02.town')\", 3), (\"Lemma('town.n.01.town')\", 11)])\n",
      "collecting tokens for  consider\n",
      "indices:    {25144, 4481, 25186}\n",
      "dict_items([(\"Lemma('consider.v.05.consider')\", 1), (\"Lemma('consider.v.03.consider')\", 1), (\"Lemma('consider.v.04.consider')\", 1)])\n",
      "collecting tokens for  serving\n",
      "indices:    {29505, 22178, 11907, 11428, 25026, 14910, 25833, 12811, 29165, 27855, 27856, 152, 22043, 23804, 11453, 30142, 5503}\n",
      "dict_items([(\"Lemma('serve.v.07.serve')\", 4), (\"Lemma('serve.v.06.serve')\", 2), (\"Lemma('serve.v.02.serve')\", 5), (\"Lemma('serve.v.01.serve')\", 2), (\"Lemma('service.v.01.serve')\", 4)])\n",
      "collecting tokens for  lines\n",
      "indices:    {37120, 32772, 4999, 18824, 31882, 21004, 32783, 25238, 32791, 25727, 8479, 5024, 28835, 26790, 5031, 32808, 32809, 32810, 32813, 32820, 12856, 23353, 21053, 32838, 3914, 14800, 9171, 20564, 21461, 32092, 22756, 36196, 21991, 14059, 31856, 33520, 5618, 28025, 12156, 7935}\n",
      "dict_items([(\"Lemma('line.n.01.line')\", 1), (\"Lemma('line.n.04.line')\", 4), (\"Lemma('line.n.02.line')\", 2), (\"Lemma('line.n.03.line')\", 2), (\"Lemma('line.n.06.line')\", 1), (\"Lemma('course.n.02.line')\", 2), (\"Lemma('cable.n.02.line')\", 1)])\n",
      "collecting tokens for  production\n",
      "indices:    {14721, 24666, 2749, 28667, 2733, 26959, 25652, 26583, 26362, 1179, 14365}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('production.n.01.production')\", 4), (\"Lemma('production.n.02.production')\", 1)])\n",
      "collecting tokens for  areas\n",
      "indices:    {3584, 24065, 31233, 14850, 24068, 28673, 4096, 4103, 4104, 13322, 2574, 13329, 13331, 13332, 13333, 13337, 24605, 11297, 27681, 30241, 27181, 14383, 14899, 11315, 53, 14905, 29248, 25156, 2629, 27720, 29259, 29267, 26199, 23641, 4186, 4187, 29289, 22634, 31854, 22640, 25208, 23673, 23681, 29847, 22694, 4775, 15528, 31407, 2746, 4798, 11981, 2773, 27862, 21205, 32984, 32473, 27870, 27879, 33002, 5355, 5358, 5359, 33009, 33013, 24823, 5372, 3332, 32517, 33030, 32521, 33048, 15645, 15648, 20260, 15654, 27948, 33069, 15150, 33070, 5424, 33073, 1836, 33075, 25905, 24888, 21305, 1855, 23364, 33093, 2382, 24911, 33103, 1873, 1875, 23894, 1888, 15201, 1889, 11619, 1899, 11629, 1904, 29554, 28531, 1908, 14706, 1909, 15735, 12153, 1915, 897, 1922, 27009, 21889, 14213, 5508, 12167, 32134, 33161, 16269, 33166, 33167, 25487, 16270, 25488, 32148, 5014, 16281, 16288, 16289, 3498, 1964, 25522, 16315, 32700, 30144, 30148, 2513, 27606, 28633, 28634, 986, 4065, 4066, 21986, 32228, 12265, 12779, 30188, 4080, 20466, 3570, 13305, 4090, 21500}\n",
      "dict_items([(\"Lemma('area.n.03.area')\", 9), (\"Lemma('area.n.01.area')\", 26), (\"Lemma('area.n.02.area')\", 13), (\"Lemma('sphere.n.01.area')\", 4), (\"Lemma('area.n.05.area')\", 3)])\n",
      "collecting tokens for  gas\n",
      "indices:    {17926}\n",
      "dict_items([])\n",
      "collecting tokens for  check\n",
      "indices:    {20296, 12155, 33493}\n",
      "dict_items([(\"Lemma('control.v.02.check')\", 1), (\"Lemma('check.v.01.check')\", 1), (\"Lemma('check.v.02.check')\", 1)])\n",
      "collecting tokens for  flight\n",
      "indices:    {23840, 35617, 235, 31916, 26861, 18703, 26415, 15537, 13079, 6907, 18717, 23327}\n",
      "dict_items([(\"Lemma('flight.n.02.flight')\", 4), (\"Lemma('flight.n.01.flight')\", 1), (\"Lemma('escape.n.01.flight')\", 1)])\n",
      "collecting tokens for  todman\n",
      "indices:    {18672}\n",
      "dict_items([(\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  voice\n",
      "indices:    {30209, 10245, 19464, 10249, 35336, 30221, 7694, 7695, 27159, 31769, 30238, 30241, 1060, 8742, 30250, 1070, 33328, 6706, 6709, 8758, 35903, 8781, 34897, 8277, 7767, 5734, 33387, 13419, 10868, 12410, 26236, 10366, 8832, 28292, 5265, 14483, 9375, 33962, 8364, 33965, 23729, 9918, 14016, 36549, 14540, 17620, 7397, 7399, 19181, 36590, 26876, 11010, 6919, 18183, 14091, 6925, 10515, 793, 13594, 24355, 24357, 14121, 18730, 6452, 20792, 24384, 23365, 8527, 7003, 10088, 8553, 17769, 10604, 33658, 17275, 17791, 34697, 28556, 26508, 35214, 34701, 19854, 17815, 11161, 34717, 8094, 34208, 8610, 13731, 8621, 18861, 11195, 8642, 8135, 18376, 15824, 15830, 33754, 32218, 15839, 19939, 5091, 7147, 35824}\n",
      "dict_items([(\"Lemma('spokesperson.n.01.voice')\", 1), (\"Lemma('voice.n.01.voice')\", 26), (\"Lemma('voice.n.05.voice')\", 1), (\"Lemma('articulation.n.03.voice')\", 3), (\"Lemma('voice.n.02.voice')\", 26), (\"Lemma('voice.n.09.voice')\", 1)])\n",
      "collecting tokens for  broke\n",
      "indices:    {5088, 27269, 33770, 23659, 19293, 28076, 12874, 12856, 2393, 31356, 18909}\n",
      "dict_items([(\"Lemma('break.v.04.break')\", 1), (\"Lemma('interrupt.v.04.break')\", 1), (\"Lemma('break.v.02.break')\", 1), (\"Lemma('break.v.10.break')\", 1), (\"Lemma('break_open.v.01.break_open')\", 1)])\n",
      "collecting tokens for  !\n",
      "indices:    {34816, 10246, 30726, 30727, 28682, 10251, 36881, 36883, 18461, 36896, 26657, 18470, 26666, 36908, 34869, 34870, 36919, 36923, 36926, 20550, 2121, 36942, 32853, 36953, 36954, 16479, 36973, 24689, 16508, 6269, 18567, 14472, 16521, 18573, 18576, 4248, 6301, 2206, 8357, 8359, 16557, 16558, 16559, 8372, 37046, 8377, 37061, 14534, 37062, 6347, 6348, 6349, 37068, 37071, 6352, 18641, 18642, 16597, 6358, 37079, 6360, 6361, 6359, 16603, 16604, 6364, 37077, 18655, 6368, 37089, 6370, 18656, 37092, 8421, 6372, 6374, 37098, 2283, 37100, 6380, 37110, 37111, 16633, 6397, 6402, 37128, 6409, 10504, 10505, 10509, 6414, 6415, 10512, 6417, 16656, 6420, 16669, 37149, 37150, 18725, 6440, 37161, 37162, 6450, 18742, 6459, 18751, 35138, 6467, 35140, 6469, 10565, 6473, 337, 6482, 10578, 6484, 22873, 10586, 6493, 24932, 8552, 6508, 6510, 6511, 6514, 31094, 6518, 6520, 6524, 6525, 6527, 6529, 10629, 18821, 31115, 12686, 31120, 8594, 20887, 8601, 35237, 29106, 6583, 8645, 20935, 20936, 8651, 35278, 20944, 20946, 20951, 8663, 25065, 35317, 6647, 6648, 6649, 8698, 8699, 6651, 18940, 33283, 12803, 10766, 10767, 18962, 35355, 6688, 35361, 6690, 35362, 35365, 6694, 6695, 18990, 18992, 6709, 6710, 6712, 19002, 10813, 23102, 35390, 35392, 10822, 10823, 10827, 12875, 16976, 16978, 19030, 10842, 8795, 8796, 12893, 8797, 12890, 19041, 10853, 6761, 6778, 35451, 35452, 35453, 6782, 29309, 6784, 6779, 35456, 35455, 6790, 35463, 35465, 35466, 35475, 35486, 35487, 35488, 27298, 27300, 6821, 35494, 6823, 6826, 27308, 27309, 25260, 6834, 6836, 25271, 23230, 23231, 6848, 35521, 35520, 35523, 6852, 25292, 6861, 19157, 19169, 17122, 6886, 6887, 27382, 27383, 27384, 27385, 35578, 27387, 19196, 25340, 35582, 35583, 35584, 33535, 29433, 6917, 6918, 35595, 19212, 35597, 35598, 25362, 19220, 11032, 19227, 6958, 29490, 29491, 29497, 6974, 6977, 19268, 11083, 6989, 27472, 6994, 27481, 27492, 7013, 27494, 27495, 31596, 27505, 27512, 35711, 7042, 7043, 7049, 7055, 7065, 30713, 7079, 7082, 7086, 31669, 7094, 7095, 11196, 7104, 966, 9176, 9177, 9182, 11250, 11251, 11252, 29696, 17422, 11279, 9234, 9235, 9236, 9237, 11288, 23581, 7207, 25646, 27699, 17463, 11337, 25710, 19574, 19609, 1177, 19611, 1183, 1199, 9406, 9416, 13514, 9441, 9449, 9451, 1261, 1262, 17654, 9463, 25853, 9474, 25860, 9483, 13594, 17691, 17693, 9531, 36156, 36158, 1342, 30020, 36166, 9543, 36173, 36176, 36178, 36180, 19797, 19798, 36183, 36182, 19804, 36192, 19815, 36214, 36223, 36228, 13702, 36236, 36238, 9616, 9617, 36245, 13719, 23964, 19871, 19873, 9634, 36259, 19878, 19879, 19880, 17840, 17841, 17844, 17849, 36282, 13757, 19902, 19903, 19913, 7627, 13781, 15830, 15831, 19929, 17883, 17887, 17891, 7651, 26089, 17901, 17902, 1519, 1520, 1528, 19961, 19962, 19963, 28155, 1532, 1545, 1554, 1556, 1558, 1559, 17950, 7713, 7714, 7717, 7718, 36391, 1576, 7721, 36395, 1582, 3639, 36407, 1600, 17995, 28237, 7765, 22110, 34408, 18026, 36459, 18028, 18027, 36462, 36467, 18036, 36469, 30325, 36471, 30327, 36473, 36474, 36484, 36488, 30350, 18064, 30366, 30368, 30369, 36532, 28343, 30391, 9926, 18141, 5867, 5868, 7918, 24306, 7923, 7922, 18165, 28422, 28423, 28436, 10006, 10010, 10018, 7976, 18216, 30508, 18221, 18222, 18238, 18239, 18252, 24397, 10063, 34640, 18259, 10073, 30565, 10088, 18281, 10090, 10089, 18282, 18284, 28528, 18288, 28545, 28546, 28547, 28549, 36742, 28552, 6024, 30602, 30603, 28555, 30605, 28558, 30607, 28559, 30609, 30610, 10132, 28564, 28565, 28568, 10145, 22435, 22439, 10152, 30634, 10156, 30637, 30638, 10158, 30639, 30642, 10166, 30650, 30652, 30655, 10176, 30663, 30668, 28620, 28622, 22483, 14295, 30684, 24542, 30704, 18423, 34809}\n",
      "dict_items([])\n",
      "collecting tokens for  nearly\n",
      "indices:    {865, 1926, 3142, 2473, 34427, 846, 6480, 2611, 13076, 23381, 33179}\n",
      "dict_items([(\"Lemma('about.r.07.nearly')\", 8)])\n",
      "collecting tokens for  easy\n",
      "indices:    {16643, 13318, 775, 5003, 6540, 26893, 16398, 16144, 12818, 19352, 4377, 28442, 34329, 14236, 29470, 29345, 32556, 11953, 13234, 11443, 14386, 21815, 1976, 31680, 27461, 34509, 17873, 1618, 34391, 7264, 15846, 12145, 20596, 9078, 7035}\n",
      "dict_items([(\"Lemma('easy.a.01.easy')\", 18), (\"Lemma('easy.s.04.easy')\", 1), (\"Lemma('easy.s.02.easy')\", 1)])\n",
      "collecting tokens for  remember\n",
      "indices:    {33605, 32198, 34217, 17644, 8334, 32689, 26618, 10749}\n",
      "dict_items([(\"Lemma('remember.v.01.remember')\", 6), (\"Lemma('remember.v.02.remember')\", 2)])\n",
      "collecting tokens for  big\n",
      "indices:    {18933, 17926}\n",
      "dict_items([(\"Lemma('large.a.01.big')\", 1)])\n",
      "collecting tokens for  hans\n",
      "indices:    {8957}\n",
      "dict_items([(\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  going\n",
      "indices:    {37120, 17793, 23435, 7822, 8336, 36114, 30612, 19734, 24218, 10909, 22564, 34983, 27946, 24619, 13358, 17594, 16571, 23356, 30013, 28994, 6851, 29395, 36179, 6745, 4442, 21353, 9330, 27774}\n",
      "dict_items([(\"Lemma('run.v.03.go')\", 1), (\"Lemma('go.v.16.go')\", 1), (\"Lemma('travel.v.01.go')\", 4), (\"Lemma('go.v.02.go')\", 1), (\"Lemma('become.v.01.go')\", 1), (\"Lemma('survive.v.01.go')\", 1)])\n",
      "collecting tokens for  while\n",
      "indices:    {33294, 36502, 14455, 34456, 23193, 5024, 28065, 36138, 5550, 1458, 17588, 8245, 30013, 24899, 25669, 33229, 339, 27746, 19441, 2679, 29306}\n",
      "dict_items([])\n",
      "collecting tokens for  still\n",
      "indices:    {14593, 33090, 34249, 1385, 17419, 22122, 1458, 19254}\n",
      "dict_items([(\"Lemma('still.r.01.still')\", 4), (\"Lemma('however.r.01.still')\", 1)])\n",
      "collecting tokens for  pa\n",
      "indices:    {8964}\n",
      "dict_items([(\"Lemma('dad.n.01.pa')\", 1)])\n",
      "collecting tokens for  yellow\n",
      "indices:    {4096, 7299, 13572, 3609, 7836, 27568, 24376, 11322, 25915, 28733, 31552, 31315, 30550, 10585, 19932, 4064, 18786, 26994, 7416}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('yellow.n.01.yellow')\", 2), (\"Lemma('yellow.s.01.yellow')\", 6), (\"Lemma('yellow.s.03.yellow')\", 1), (\"Lemma('chicken.s.01.yellow')\", 1)])\n",
      "collecting tokens for  sick\n",
      "indices:    {15616, 35873, 15617, 16870, 13002, 6156, 9005, 12559, 9807, 10358, 13119}\n",
      "dict_items([(\"Lemma('nauseated.s.01.sick')\", 5), (\"Lemma('ill.a.01.sick')\", 2), (\"Lemma('sick.n.01.sick')\", 1)])\n",
      "collecting tokens for  described\n",
      "indices:    {9232, 4117, 4131, 14884, 14889, 11305, 30251, 32811, 3635, 30260, 8765, 4169, 3146, 14412, 32333, 4173, 24145, 5207, 5208, 2648, 2682, 32895, 11400, 15517, 15006, 31411, 3255, 30905, 15041, 4294, 30920, 3280, 4308, 16089, 11996, 12000, 29927, 28937, 20240, 16145, 26900, 2843, 14121, 299, 15664, 25910, 11080, 11083, 2894, 3919, 12630, 26466, 13163, 13168, 10610, 10611, 31094, 31100, 9607, 2965, 26546, 15794, 4018, 3510, 32186, 15804, 3529, 33232, 33236, 10712, 3544, 3549, 16864, 33249, 5601, 3555, 33250, 3565, 3567, 13302}\n",
      "dict_items([(\"Lemma('describe.v.01.describe')\", 26), (\"Lemma('report.v.01.describe')\", 26)])\n",
      "collecting tokens for  reader\n",
      "indices:    {26529, 26142, 32106, 15820, 4333, 29042, 29043, 3993, 14586, 20510}\n",
      "dict_items([(\"Lemma('reader.n.01.reader')\", 3)])\n",
      "collecting tokens for  discovery\n",
      "indices:    {12401, 27801, 10275, 11501}\n",
      "dict_items([(\"Lemma('discovery.n.03.discovery')\", 1), (\"Lemma('discovery.n.01.discovery')\", 1)])\n",
      "collecting tokens for  personality\n",
      "indices:    {14219, 32653, 12053, 31006, 22304, 33192, 33194, 15661, 33197, 33199, 14513, 15672, 9145, 4667, 27721, 35659, 31822, 27729, 10833, 26587, 15842, 33254, 9583, 22392, 10746, 23933}\n",
      "dict_items([(\"Lemma('personality.n.01.personality')\", 8), (\"Lemma('personality.n.02.personality')\", 1)])\n",
      "collecting tokens for  stood\n",
      "indices:    {35333, 36358, 8711, 35341, 36368, 27673, 27675, 35359, 6687, 33830, 18986, 18475, 26154, 7215, 35890, 10806, 9782, 36408, 14904, 33850, 16963, 9796, 16965, 35404, 77, 33869, 35412, 6740, 10330, 5216, 34917, 7781, 7785, 17514, 618, 33385, 10359, 9340, 14467, 33412, 33428, 5781, 6297, 9369, 17571, 31400, 27307, 34988, 17069, 9389, 7857, 19123, 17588, 26805, 36023, 7352, 36027, 29372, 17087, 29376, 36036, 27333, 16589, 9426, 6868, 27352, 19161, 10458, 10466, 6893, 19696, 6389, 31478, 29944, 18681, 29948, 7428, 9477, 17672, 18186, 6926, 9999, 34580, 36628, 36121, 6426, 7458, 13603, 33572, 36137, 36138, 19243, 33582, 28977, 7474, 31539, 8497, 23863, 8506, 16703, 17731, 8519, 6472, 16715, 17740, 27473, 9554, 17746, 35159, 20824, 20823, 7006, 19807, 18274, 9572, 27496, 8557, 7021, 34163, 4983, 36728, 36730, 4997, 25992, 8592, 7056, 19882, 28077, 7090, 34227, 18359, 19899, 8648, 14280, 34254, 16847, 16853, 19928, 9178, 9180, 10207, 33760, 33762, 34275, 9191, 7143, 33769, 34282, 9197, 19950, 5105, 10233, 19967}\n",
      "dict_items([(\"Lemma('stand.v.01.stand')\", 26), (\"Lemma('stand.v.04.stand')\", 1), (\"Lemma('stand.v.02.stand')\", 19), (\"Lemma('stand_by.v.01.stand_by')\", 1), (\"Lemma('stand.v.03.stand')\", 12), (\"Lemma('digest.v.03.stand')\", 1), (\"Lemma('stand.v.07.stand')\", 2), (\"Lemma('stand.v.09.stand')\", 1), (\"Lemma('stand.v.10.stand')\", 1), (\"Lemma('stand_still.v.01.stand_still')\", 1)])\n",
      "collecting tokens for  pulled\n",
      "indices:    {18693, 36358, 18568, 1548, 1036, 9230, 271, 2961, 17298, 2966, 29335, 18713, 6428, 18334, 17830, 18986, 28721, 19891, 6196, 19895, 18616, 18487, 28732, 29886, 33598, 17600, 3011, 28742, 20679, 20550, 6216, 24392, 10441, 18895, 13011, 20056, 17754, 34268, 30563, 35945, 17642, 7806, 34287, 34290, 10355, 26617, 8954, 11646}\n",
      "dict_items([(\"Lemma('pull.v.01.pull')\", 25), (\"Lemma('pull.v.03.pull')\", 2), (\"Lemma('attract.v.01.pull')\", 3), (\"Lemma('pull.v.08.pull')\", 1), (\"Lemma('draw.v.05.pull')\", 1), (\"Lemma('pull.v.04.pull')\", 1)])\n",
      "collecting tokens for  coat\n",
      "indices:    {29572, 36740, 19080, 10392, 16796, 10406, 18983, 18986, 18987, 18988, 29881, 22458, 31806, 16832, 17735, 18122, 16844, 5453, 12624, 29780, 18134, 29783, 18136, 29784, 16857, 7516, 36714, 18154, 29809, 21618, 6386, 36731, 9470}\n",
      "dict_items([(\"Lemma('coat.v.01.coat')\", 1), (\"Lemma('coat.n.01.coat')\", 21)])\n",
      "collecting tokens for  shoulders\n",
      "indices:    {10496, 36865, 9473, 34064, 36754, 31506, 35989, 13593, 29338, 26522, 9118, 10913, 34978, 35107, 12834, 18986, 34091, 10419, 1590, 9655, 19254, 17473, 10561, 1989, 4038, 25669, 8783, 9171, 2005, 9178, 5869, 16883, 10357, 23033, 18684, 34687}\n",
      "dict_items([(\"Lemma('shoulder.n.01.shoulder')\", 23)])\n",
      "collecting tokens for  started\n",
      "indices:    {19990, 33824, 18465, 36387, 25635, 8740, 18986, 36911, 18994, 12338, 10290, 20021, 6715, 9286, 12873, 19531, 36939, 5199, 12890, 18011, 20062, 18533, 21612, 18542, 23662, 1655, 33400, 18561, 1668, 16517, 30345, 34955, 33420, 37005, 37008, 1169, 28819, 3732, 36512, 15521, 29347, 18597, 14502, 17578, 29356, 31412, 33461, 22200, 32443, 36031, 33477, 8397, 19151, 31439, 10455, 35035, 21725, 12511, 34532, 36069, 8423, 35572, 20727, 35576, 36095, 32514, 19203, 18692, 270, 24848, 17682, 27924, 35605, 35094, 31513, 8474, 34077, 10013, 24863, 21802, 309, 23350, 21821, 8511, 16713, 30540, 31055, 18256, 36689, 33618, 21330, 11088, 9557, 19289, 34140, 19805, 31072, 29025, 34154, 21867, 34669, 2929, 3442, 31606, 7546, 7548, 21378, 22915, 19844, 34183, 34186, 7052, 1933, 31126, 19865, 18330, 20378, 12705, 6562, 22439, 18343, 22954, 19892, 34229, 949, 8119, 22970, 4029, 7107, 19911, 7112, 22985, 21450, 14795, 9163, 9165, 4047, 18383, 25056, 28645, 19942, 9197, 18925, 27120, 34292, 31734, 33785, 10748, 32766, 18943}\n",
      "dict_items([(\"Lemma('get_down.v.07.start')\", 26), (\"Lemma('startle.v.02.start')\", 2), (\"Lemma('begin.v.03.start')\", 18), (\"Lemma('originate.v.02.start')\", 9), (\"Lemma('begin.v.02.start')\", 6), (\"Lemma('depart.v.03.start')\", 13), (\"Lemma('start.v.08.start')\", 5), (\"Lemma('start.v.06.start')\", 5), (\"Lemma('start.v.09.start')\", 1), (\"Lemma('start.v.10.start')\", 1)])\n",
      "collecting tokens for  slide\n",
      "indices:    {34336, 33985, 12705, 32707, 6435, 4135, 28841, 18986, 32715, 32717, 19802, 32719, 34096, 30960, 28727, 19833, 11866, 34174}\n",
      "dict_items([(\"Lemma('slide.v.03.slide')\", 1), (\"Lemma('skid.v.04.slide')\", 5), (\"Lemma('slide.n.05.slide')\", 1), (\"Lemma('slide.n.02.slide')\", 1), (\"Lemma('slither.v.01.slide')\", 2), (\"Lemma('slide.n.04.slide')\", 1), (\"Lemma('slide.n.01.slide')\", 1)])\n",
      "collecting tokens for  off\n",
      "indices:    {30721, 17409, 17911, 35843, 20485, 9222, 19467, 11279, 34321, 34324, 19990, 31255, 19484, 8226, 7203, 31266, 11819, 2605, 18937, 35385, 59, 11836, 36412, 25151, 6216, 28745, 36938, 7758, 10328, 25688, 30816, 6240, 33377, 12899, 29797, 613, 7270, 36968, 617, 36454, 27243, 14950, 622, 8816, 31347, 24692, 9336, 18552, 36474, 22137, 12412, 28797, 33405, 20095, 8829, 1665, 1666, 33411, 34438, 21639, 22154, 19085, 36498, 7830, 29336, 10406, 33961, 31915, 29355, 5811, 31925, 14518, 5813, 3258, 3260, 23741, 12476, 1218, 23747, 194, 198, 7878, 18632, 5833, 24265, 10955, 7164, 31438, 18638, 36558, 21712, 17108, 32980, 7380, 5847, 33494, 9946, 21722, 26333, 24290, 35556, 230, 30439, 2280, 8938, 8940, 12524, 18679, 12535, 19191, 13568, 37120, 13572, 33540, 19718, 31498, 18699, 9489, 18197, 36635, 28963, 23845, 5413, 34600, 23338, 37164, 22828, 6956, 35629, 34096, 28978, 22836, 24373, 13110, 23353, 25411, 11075, 5445, 19270, 18247, 30534, 30540, 28498, 29013, 17237, 22873, 35673, 14180, 3428, 22887, 22889, 26474, 1391, 21874, 35699, 374, 29561, 30587, 380, 34173, 34687, 30591, 17796, 12680, 8073, 6536, 10129, 16785, 20883, 24468, 22937, 27034, 12704, 6563, 12197, 7592, 424, 31147, 18861, 29615, 19893, 9142, 6586, 6587, 444, 36286, 9662, 16832, 18883, 459, 16844, 20941, 24025, 12762, 10714, 8666, 30173, 5598, 9182, 14303, 12769, 17378, 994, 29666, 30181, 15846, 29671, 9186, 2026, 12779, 3564, 26607, 36848, 24049, 6641, 499, 17904, 7671, 36857, 7676, 26622, 29695}\n",
      "dict_items([(\"Lemma('off.r.03.off')\", 3), (\"Lemma('off.a.01.off')\", 3), (\"Lemma('away.r.01.off')\", 2), (\"Lemma('off.r.02.off')\", 2)])\n",
      "collecting tokens for  let\n",
      "indices:    {9488, 18476, 35909}\n",
      "dict_items([(\"Lemma('let.v.01.let')\", 1)])\n",
      "collecting tokens for  scream\n",
      "indices:    {30889, 18986, 37166, 7220, 6293, 6295, 36056, 36221, 6047}\n",
      "dict_items([(\"Lemma('shout.v.02.scream')\", 4), (\"Lemma('scream.n.01.scream')\", 5)])\n",
      "collecting tokens for  sound\n",
      "indices:    {12804, 34694, 34312, 24200, 16138, 6923, 24072, 19341, 7824, 33808, 31122, 11409, 14483, 26389, 34197, 19094, 18960, 30233, 30234, 26786, 20771, 2724, 24357, 26406, 26538, 4907, 13355, 6186, 31919, 19248, 25523, 35765, 34741, 16951, 6197, 10425, 10811, 33724, 316, 1087, 24903, 26695, 2761, 26957, 16590, 5837, 14803, 13655, 36056, 7003, 1755, 20315, 26077, 15839, 33888, 1760, 25826, 7648, 9697, 33516, 31598, 32879, 2158, 753, 33524, 31861, 1780, 20216, 12410, 31613}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('sound.n.03.sound')\", 3), (\"Lemma('sound.a.01.sound')\", 4), (\"Lemma('sound.n.02.sound')\", 4), (\"Lemma('sound.v.01.sound')\", 7), (\"Lemma('audio.n.01.sound')\", 2), (\"Lemma('sound.n.01.sound')\", 6), (\"Lemma('sound.a.03.sound')\", 1), (\"Lemma('sound.n.04.sound')\", 1), (\"Lemma('sound.v.03.sound')\", 1), (\"Lemma('sound.v.02.sound')\", 1), (\"Lemma('healthy.s.04.sound')\", 1), (\"Lemma('good.s.17.sound')\", 1)])\n",
      "collecting tokens for  blowing\n",
      "indices:    {25763, 2948, 2887, 3143, 2890, 18986, 2955, 18989, 7019, 26387, 19161, 30588}\n",
      "dict_items([(\"Lemma('blow.v.02.blow')\", 2), (\"Lemma('blowing.n.01.blowing')\", 3), (\"Lemma('blow.v.01.blow')\", 1), (\"Lemma('float.v.01.blow')\", 1), (\"Lemma('blow.v.06.blow')\", 1)])\n",
      "collecting tokens for  signed\n",
      "indices:    {22913, 5125, 9861, 24723, 16790, 25256, 20913, 14520, 14523, 20927, 23361, 214, 470, 11736, 21210, 34399, 481, 29922, 31985, 5107, 501, 14453, 8825, 35707}\n",
      "dict_items([(\"Lemma('sign.v.01.sign')\", 10), (\"Lemma('sign.v.03.sign')\", 3), (\"Lemma('sign.v.02.sign')\", 6), (\"Lemma('sign.v.04.sign')\", 2), (\"Lemma('signed.a.01.signed')\", 3)])\n",
      "collecting tokens for  shaw\n",
      "indices:    {26448}\n",
      "dict_items([])\n",
      "collecting tokens for  staff\n",
      "indices:    {6658, 33061, 32357, 22501, 20561, 32146, 24148, 33046, 21534}\n",
      "dict_items([(\"Lemma('person.n.01.person')\", 1), (\"Lemma('staff.v.01.staff')\", 1)])\n",
      "collecting tokens for  1959\n",
      "indices:    {21248, 15490, 3331, 21894, 21896, 5129, 32268, 3341, 20753, 32401, 2836, 15126, 280, 2841, 23450, 3993, 665, 28701, 25758, 20768, 288, 21540, 4133, 21285, 21544, 3371, 13996, 24111, 1073, 3378, 4019, 21937, 3381, 32695, 32698, 26810, 4031, 33090, 4036, 4804, 4806, 20679, 22598, 4044, 4047, 22992, 4049, 32722, 20303, 4054, 4057, 21978, 4059, 32348, 28637, 21853, 32735, 3936, 481, 32762, 32479, 4196, 31208, 32747, 3947, 11885, 32764, 32752, 24819, 32759, 22010, 21756, 33021}\n",
      "dict_items([])\n",
      "collecting tokens for  spent\n",
      "indices:    {11649, 34946, 24963, 31620, 25090, 25094, 33163, 21260, 21517, 146, 15635, 31635, 24981, 26259, 35860, 30104, 152, 24346, 18586, 9491, 14495, 37151, 20512, 10535, 23848, 13736, 18219, 34732, 20531, 7604, 20150, 14392, 23360, 8259, 12360, 23882, 21323, 33102, 15184, 9837, 5974, 5083, 24800, 17377, 10467, 2787, 13795, 19560, 21353, 25706, 4971, 13932, 25837, 10094, 7535, 25838, 16753, 35439, 25714, 21739, 16243, 28406, 22903, 14070, 29297, 18298, 32892}\n",
      "dict_items([(\"Lemma('spend.v.01.spend')\", 26), (\"Lemma('spend.v.02.spend')\", 15), (\"Lemma('spend.v.03.spend')\", 3)])\n",
      "collecting tokens for  riding\n",
      "indices:    {7681, 18309, 6920, 7690, 28555, 10380, 7694, 34576, 35605, 36245, 31269, 5046, 5047, 35259, 35260, 19261, 5054, 21442, 7883, 30412, 34637, 33358, 16716, 18003, 6745, 18270, 10467, 19172, 35811, 5107, 18300}\n",
      "dict_items([(\"Lemma('ride.v.02.ride')\", 6), (\"Lemma('ride.v.01.ride')\", 19), (\"Lemma('ride.v.03.ride')\", 1), (\"Lemma('ride_herd.v.01.ride_herd')\", 1)])\n",
      "collecting tokens for  ranch\n",
      "indices:    {30115, 18628, 5051, 35208, 10441, 35889, 35028, 22296, 36665, 5050, 35163, 30142, 29279}\n",
      "dict_items([(\"Lemma('ranch.n.01.ranch')\", 2)])\n",
      "collecting tokens for  broad\n",
      "indices:    {4880, 18002, 16463}\n",
      "dict_items([(\"Lemma('broad.s.03.broad')\", 1), (\"Lemma('wide.a.01.broad')\", 1), (\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  daylight\n",
      "indices:    {21507, 10467, 30566, 2590, 5066, 2123, 27499, 36014, 35375, 29294, 35696, 13821, 35678}\n",
      "dict_items([(\"Lemma('daylight.n.02.daylight')\", 2), (\"Lemma('day.n.04.daylight')\", 3)])\n",
      "collecting tokens for  less\n",
      "indices:    {2182, 16909, 25342, 147, 36884, 1812, 11544, 11546, 25247, 4770, 15140, 5417, 26155, 27051, 5420, 10667, 23728, 11572, 14773, 20021, 33086, 27073, 18246, 4937, 18250, 33102, 3919, 34385, 27732, 31579, 4445, 2919, 15595, 3310, 31727, 31215, 22000, 27766, 14071, 3702, 3707, 25214, 15871}\n",
      "dict_items([(\"Lemma('less.r.01.less')\", 10), (\"Lemma('less.a.01.less')\", 3), (\"Lemma('less.r.02.less')\", 2)])\n",
      "collecting tokens for  seem\n",
      "indices:    {11267, 12806, 24584, 2569, 24587, 10252, 26644, 36376, 31262, 3614, 33312, 18463, 34342, 34349, 22574, 27184, 22577, 24113, 26160, 2611, 26166, 10808, 13369, 3642, 26684, 1084, 31804, 8778, 10316, 19022, 31823, 11861, 19553, 15973, 2150, 25703, 6256, 14452, 32380, 20095, 27263, 32386, 24707, 32390, 23691, 32913, 6802, 4242, 3729, 32917, 6808, 35482, 25755, 32413, 32926, 30365, 22697, 30377, 37035, 22699, 32949, 12981, 1720, 32958, 19647, 22209, 29379, 32965, 26316, 22733, 26842, 14043, 8416, 25313, 10467, 26341, 32998, 36071, 33001, 13555, 13557, 21237, 27898, 36092, 16125, 5376, 5381, 14598, 14599, 14602, 1804, 33038, 16143, 5399, 283, 21278, 13598, 25375, 800, 35617, 6948, 4901, 1320, 4908, 26412, 34606, 1329, 16178, 2356, 28468, 26422, 5429, 24887, 22849, 838, 31047, 4944, 33108, 30548, 5462, 31572, 1367, 5468, 4958, 18281, 25450, 9578, 24949, 11643, 23931, 26494, 13696, 9088, 18819, 22921, 27542, 27543, 33181, 18336, 30625, 30624, 27556, 36263, 31148, 14259, 23482, 36283, 24517, 33233, 6103, 984, 7135, 11232, 26081, 24036, 4583, 24040, 8172, 17391, 10749}\n",
      "dict_items([(\"Lemma('look.v.02.seem')\", 26), (\"Lemma('appear.v.04.seem')\", 12)])\n",
      "collecting tokens for  federal\n",
      "indices:    {31771}\n",
      "dict_items([])\n",
      "collecting tokens for  funds\n",
      "indices:    {2788, 69, 14886, 27748, 31689, 20653, 13, 15, 16304, 23761, 20210, 23636, 16309, 20405, 16279, 32760, 20922, 14748}\n",
      "dict_items([(\"Lemma('funds.n.01.funds')\", 5), (\"Lemma('fund.n.01.fund')\", 4)])\n",
      "collecting tokens for  account\n",
      "indices:    {1280, 17409, 26754, 33667, 31747, 900, 4606, 14859, 25357, 25487, 27792, 12175, 27794, 2835, 16016, 13329, 29949, 11930, 14619, 29209, 22045, 33568, 13729, 25506, 11681, 27556, 3109, 2592, 14894, 8368, 22065, 13362, 14771, 26035, 16565, 12342, 4278, 9272, 6141, 2102, 16053, 19132, 21952, 12482, 5315, 32837, 26186, 28235, 844, 26190, 26836, 12119, 32984, 15832, 5212, 25443, 2916, 1381, 13798, 20711, 21477, 2670, 17394, 16114, 16244, 32500, 21235, 8823, 22392, 2681, 25979, 2300, 21757, 21246}\n",
      "dict_items([(\"Lemma('account_for.v.01.account_for')\", 1), (\"Lemma('account.n.03.account')\", 2), (\"Lemma('history.n.02.account')\", 6), (\"Lemma('report.n.03.account')\", 3), (\"Lemma('explanation.n.01.account')\", 2), (\"Lemma('account.n.06.account')\", 1)])\n",
      "collecting tokens for  nation\n",
      "indices:    {13769, 24026, 25057, 29239}\n",
      "dict_items([(\"Lemma('nation.n.02.nation')\", 1)])\n",
      "collecting tokens for  expenditures\n",
      "indices:    {15497, 15500, 12181, 12182, 15002, 15003, 21920, 32549, 32550, 32554, 32555, 32177, 32180, 23619, 11341, 25305, 16243, 15476, 15477, 16246, 16249, 16250, 15486}\n",
      "dict_items([(\"Lemma('outgo.n.01.expenditure')\", 14)])\n",
      "collecting tokens for  vocational\n",
      "indices:    {16258, 13282, 16294, 13776, 16279, 16275, 20212, 13303, 13274, 15006}\n",
      "dict_items([(\"Lemma('vocational.a.01.vocational')\", 7)])\n",
      "collecting tokens for  education\n",
      "indices:    {11880, 22700, 23225, 4604, 158}\n",
      "dict_items([(\"Lemma('education.n.03.education')\", 1), (\"Lemma('education.n.02.education')\", 1)])\n",
      "collecting tokens for  return\n",
      "indices:    {12297, 22031, 16912, 16913, 17935, 34834, 22036, 36892, 16926, 20519, 3646, 36930, 12359, 8264, 34377, 26203, 2663, 4215, 24184, 9337, 127, 35977, 21132, 4240, 14482, 14995, 17556, 8354, 18596, 18597, 15543, 14520, 15546, 21178, 15548, 15549, 15550, 29887, 15552, 15551, 29888, 15560, 15561, 15563, 15565, 12496, 15568, 15571, 15575, 30936, 30937, 27357, 15581, 15584, 7400, 15592, 15595, 15596, 1773, 15597, 15598, 23283, 18691, 18695, 15630, 15631, 24335, 15636, 15637, 21270, 22296, 12057, 22300, 22314, 11054, 14141, 14142, 14658, 16710, 14154, 23393, 23394, 1383, 22383, 6000, 30580, 20862, 36758, 20891, 12700, 31647, 11680, 36271, 25523, 26036, 5058, 4547, 31684, 31682, 10182, 1996, 14284, 5076, 28129, 15333, 20972, 22516, 13814, 33276}\n",
      "dict_items([(\"Lemma('return.v.01.return')\", 25), (\"Lemma('revert.v.01.return')\", 6), (\"Lemma('tax_return.n.01.return')\", 25), (\"Lemma('restitution.n.03.return')\", 3), (\"Lemma('render.v.07.return')\", 9), (\"Lemma('return.n.02.return')\", 5), (\"Lemma('return.n.03.return')\", 1), (\"Lemma('hark_back.v.01.return')\", 1), (\"Lemma('return.v.05.return')\", 1), (\"Lemma('return.n.05.return')\", 2)])\n",
      "collecting tokens for  serve\n",
      "indices:    {26560, 7552, 11256, 25022, 10680, 32648, 31852, 12464, 11217, 34385, 31699, 10453, 29494, 3863, 26622, 27737, 22109, 29182}\n",
      "dict_items([(\"Lemma('serve.v.01.serve')\", 6), (\"Lemma('serve.v.06.serve')\", 3), (\"Lemma('serve.v.03.serve')\", 3), (\"Lemma('serve.v.07.serve')\", 3), (\"Lemma('serve.v.02.serve')\", 2), (\"Lemma('serve.v.05.serve')\", 1)])\n",
      "collecting tokens for  claim\n",
      "indices:    {15544}\n",
      "dict_items([])\n",
      "collecting tokens for  refund\n",
      "indices:    {15544}\n",
      "dict_items([])\n",
      "collecting tokens for  tax\n",
      "indices:    {20645, 139, 25038, 22035, 22036, 32149, 32375, 33368, 15545, 22042, 59, 32412}\n",
      "dict_items([(\"Lemma('tax.v.01.tax')\", 1), (\"Lemma('tax.n.01.tax')\", 3)])\n",
      "collecting tokens for  does\n",
      "indices:    {25128, 5874, 2363, 27786}\n",
      "dict_items([(\"Lemma('perform.v.01.do')\", 1)])\n",
      "collecting tokens for  phil\n",
      "indices:    {19990}\n",
      "dict_items([(\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  promise\n",
      "indices:    {23297, 14726, 32907, 4747, 19477, 19478, 19479, 17689, 11935, 23843, 5929, 13621, 23608, 6841, 8761, 28991, 31424, 23618, 1475, 8393, 5194, 27341, 29007, 11216, 27351, 87, 27356, 9579, 36211, 22773}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('promise.v.02.promise')\", 2), (\"Lemma('promise.v.01.promise')\", 4), (\"Lemma('promise.n.01.promise')\", 8), (\"Lemma('promise.n.02.promise')\", 6)])\n",
      "collecting tokens for  ever\n",
      "indices:    {23296, 900, 30597, 12933, 7430, 9609, 34954, 523, 24845, 22926, 12816, 10897, 31120, 16785, 32022, 24863, 26792, 26412, 25519, 28976, 16819, 22323, 30900, 27832, 26937, 35773, 33470, 4669, 11072, 21696, 32195, 36291, 16709, 20293, 74, 23115, 25421, 20942, 11859, 26709, 1242, 34399, 26083, 36579, 35173, 24294, 31844, 26090, 26091, 9708, 36972, 28142, 5874, 35061, 16888, 22398}\n",
      "dict_items([(\"Lemma('ever.r.01.ever')\", 13), (\"Lemma('ever.r.03.ever')\", 1), (\"Lemma('always.r.01.ever')\", 1)])\n",
      "collecting tokens for  gave\n",
      "indices:    {31749, 17928, 11280, 19477, 18453, 25113, 21529, 8732, 34844, 36382, 8735, 2590, 3108, 8233, 16941, 1071, 35380, 8248, 21562, 4163, 12355, 23110, 19527, 586, 3147, 30286, 26192, 20050, 22098, 23127, 22106, 28254, 23140, 20069, 19559, 28263, 6760, 14442, 16503, 28280, 30841, 30842, 2170, 5244, 30840, 19582, 18562, 36998, 33417, 27276, 30863, 30866, 24732, 19614, 33951, 6307, 26787, 35496, 1193, 21674, 36520, 26794, 29354, 9390, 36528, 30896, 3764, 27318, 183, 26297, 187, 33469, 8896, 193, 5313, 24261, 26323, 3285, 33495, 24286, 36578, 35045, 34534, 27369, 6893, 24816, 12539, 33532, 18171, 9473, 32002, 37123, 772, 27395, 24326, 12037, 10505, 18699, 4363, 17677, 9997, 12559, 32017, 32018, 20244, 14102, 12566, 32024, 23337, 35631, 15667, 25395, 14131, 5433, 23867, 22843, 20287, 10749, 14147, 5445, 18758, 36680, 14152, 19786, 6989, 14161, 2390, 17750, 4953, 352, 26977, 26465, 35686, 24938, 9579, 16747, 18797, 26485, 17278, 34174, 391, 9608, 17801, 25994, 19342, 31631, 9618, 28563, 26004, 916, 28568, 26008, 2972, 2978, 28068, 7592, 26537, 33200, 32689, 33202, 19381, 14773, 26554, 5565, 11198, 33220, 20932, 8138, 469, 28117, 17880, 20953, 33242, 3552, 21477, 18416, 27121, 9203, 3571, 8692, 9717, 36343, 7160, 36861}\n",
      "dict_items([(\"Lemma('give.v.03.give')\", 21), (\"Lemma('give.v.09.give')\", 6), (\"Lemma('give.v.01.give')\", 26), (\"Lemma('give.v.04.give')\", 13), (\"Lemma('establish.v.05.give')\", 2), (\"Lemma('give.v.08.give')\", 4), (\"Lemma('yield.v.01.give')\", 26), (\"Lemma('give.v.07.give')\", 12), (\"Lemma('hold.v.03.give')\", 5), (\"Lemma('give.v.21.give')\", 1), (\"Lemma('give.v.14.give')\", 3), (\"Lemma('surrender.v.02.give_up')\", 1), (\"Lemma('give.v.15.give')\", 3), (\"Lemma('give.v.05.give')\", 7), (\"Lemma('sacrifice.v.01.give')\", 4), (\"Lemma('collapse.v.01.give')\", 1), (\"Lemma('unwrap.v.02.give_away')\", 1), (\"Lemma('pass.v.05.give')\", 1), (\"Lemma('give.v.18.give')\", 1), (\"Lemma('render.v.04.give')\", 2), (\"Lemma('give.v.10.give')\", 2), (\"Lemma('impart.v.01.give')\", 1), (\"Lemma('give.v.27.give')\", 1)])\n",
      "collecting tokens for  give\n",
      "indices:    {19200, 7552, 34947, 28549, 18181, 12039, 139, 31630, 18066, 24341, 23064, 3738, 22688, 15905, 21922, 34339, 4770, 14121, 25004, 14645, 4920, 28601, 12345, 19259, 14909, 35135, 9921, 17219, 21573, 4422, 30665, 9292, 33229, 12241, 32853, 20823, 30811, 8923, 29666, 16611, 9832, 28909, 15089, 15358}\n",
      "dict_items([(\"Lemma('give.v.04.give')\", 4), (\"Lemma('grant.v.05.give')\", 1), (\"Lemma('give.v.03.give')\", 5), (\"Lemma('give.v.01.give')\", 10), (\"Lemma('yield.v.01.give')\", 8), (\"Lemma('give.v.07.give')\", 1), (\"Lemma('impart.v.01.give')\", 2), (\"Lemma('give.v.09.give')\", 1), (\"Lemma('forfeit.v.01.give_up')\", 1), (\"Lemma('hold.v.03.give')\", 1), (\"Lemma('contribute.v.02.give')\", 1), (\"Lemma('move_over.v.01.give')\", 1), (\"Lemma('establish.v.05.give')\", 1), (\"Lemma('give.v.14.give')\", 1)])\n",
      "collecting tokens for  giving\n",
      "indices:    {28164, 32005, 22921, 1033, 13710, 9871, 35470, 27153, 14609, 9747, 7822, 8857, 27424, 34085, 28582, 36267, 2864, 8244, 22201, 32059, 18244, 21061, 29894, 36040, 32458, 14925, 35409, 33491, 27478, 27608, 25816, 26475, 10735, 15734, 26364}\n",
      "dict_items([(\"Lemma('give.v.03.give')\", 7), (\"Lemma('yield.v.01.give')\", 10), (\"Lemma('give.v.01.give')\", 5), (\"Lemma('give.v.04.give')\", 2), (\"Lemma('hold.v.03.give')\", 2), (\"Lemma('give.v.18.give')\", 1), (\"Lemma('thank.v.01.give_thanks')\", 1)])\n",
      "collecting tokens for  once\n",
      "indices:    {12038, 18215, 12784, 7921, 25430}\n",
      "dict_items([(\"Lemma('once.r.03.once')\", 3)])\n",
      "collecting tokens for  enough\n",
      "indices:    {35330, 18435, 31236, 28680, 5644, 4622, 6161, 8211, 33822, 18466, 25129, 27690, 2607, 29232, 8244, 12345, 23612, 25661, 4156, 19526, 36431, 36945, 22109, 36448, 1636, 2664, 29294, 6255, 17012, 17014, 34428, 34941, 2690, 14984, 139, 35470, 13973, 23201, 10401, 20135, 25768, 1707, 14519, 32957, 2761, 30422, 35542, 25817, 8924, 23776, 24293, 16101, 36077, 4333, 14065, 33523, 17142, 16633, 24827, 1790, 3332, 7428, 36107, 16651, 10514, 23316, 2836, 26394, 2333, 20765, 36127, 6943, 34591, 17704, 10024, 33578, 37167, 17199, 27962, 29506, 29514, 33611, 15183, 25941, 4950, 23902, 3940, 24933, 35702, 12154, 3454, 11134, 11136, 33154, 18309, 22924, 19341, 29078, 5022, 19362, 16292, 11175, 18348, 13749, 11702, 14268, 9668, 7622, 36296, 31693, 12239, 23506, 28627, 34782, 16865, 28642, 25078, 24566, 12793, 18426, 33276}\n",
      "dict_items([(\"Lemma('adequate.s.02.enough')\", 15), (\"Lemma('enough.n.01.enough')\", 5), (\"Lemma('enough.r.01.enough')\", 26)])\n",
      "collecting tokens for  believed\n",
      "indices:    {18688, 3460, 35974, 3338, 20750, 32016, 35985, 3729, 19477, 32024, 9248, 12584, 27820, 35117, 29230, 28076, 34431, 5554, 13491, 26805, 26038, 26039, 12215, 18873, 27319, 12348, 27325, 28607, 33345, 27970, 12483, 28099, 28107, 22606, 463, 12752, 26830, 27862, 20311, 5210, 13149, 35679, 30944, 13151, 12386, 31586, 8678, 1384, 35309, 9454, 17775, 7664, 13171, 28152, 18300, 27261, 894, 4223}\n",
      "dict_items([(\"Lemma('believe.v.01.believe')\", 26), (\"Lemma('think.v.01.believe')\", 18), (\"Lemma('believe.v.04.believe')\", 2), (\"Lemma('believe.v.03.believe')\", 3)])\n",
      "collecting tokens for  always\n",
      "indices:    {26945, 9729, 6853, 13735, 34462, 17358, 5874, 31547, 3678}\n",
      "dict_items([(\"Lemma('always.r.01.always')\", 6)])\n",
      "collecting tokens for  believe\n",
      "indices:    {12295, 24081, 33298, 20503, 10788, 2602, 2611, 14393, 10819, 30281, 2634, 33357, 10834, 14420, 5211, 23131, 12892, 6751, 27233, 22625, 10851, 28263, 34919, 22634, 36464, 25201, 115, 34434, 12954, 27813, 28343, 24250, 2238, 2248, 27336, 27343, 17114, 27873, 7912, 27369, 27370, 1265, 4852, 9984, 12546, 19723, 14099, 3351, 5418, 1331, 5429, 32069, 24915, 33107, 8020, 8021, 13145, 7005, 14175, 23914, 8042, 24950, 24951, 22393, 25982, 21906, 22427, 34715, 7070, 16800, 33188, 15279, 14259, 9658, 13764, 1477, 30663, 24523, 32213, 13269, 24535, 11232, 13292, 2032, 2545, 2546, 2549, 10746, 12287}\n",
      "dict_items([(\"Lemma('believe.v.04.believe')\", 3), (\"Lemma('believe.v.01.believe')\", 26), (\"Lemma('believe.v.03.believe')\", 22), (\"Lemma('think.v.01.believe')\", 18)])\n",
      "collecting tokens for  finally\n",
      "indices:    {13976}\n",
      "dict_items([(\"Lemma('finally.r.01.finally')\", 1)])\n",
      "collecting tokens for  thing\n",
      "indices:    {36359, 19464, 35853, 12813, 13326, 22544, 3598, 4627, 8213, 27158, 26136, 20000, 31265, 30754, 20003, 34338, 1569, 10279, 28714, 30763, 9775, 30256, 11323, 20545, 34887, 12875, 33359, 9301, 3679, 10335, 13409, 15974, 36456, 24682, 2156, 26225, 6257, 13425, 20083, 20084, 25718, 29815, 632, 14458, 25723, 31355, 34939, 17025, 16002, 20099, 27781, 13446, 7814, 18568, 27272, 7817, 28299, 29835, 36493, 8329, 8334, 27786, 36498, 5269, 5270, 2197, 22678, 9879, 12953, 33947, 36511, 20128, 16546, 35492, 5285, 37030, 14505, 20650, 36522, 27310, 31407, 16561, 16570, 27838, 8384, 22209, 24258, 10949, 25798, 10951, 31431, 27337, 27334, 35533, 7376, 16597, 16085, 33494, 31448, 17631, 11488, 10465, 4834, 25313, 23782, 26855, 7910, 34541, 6894, 1263, 1265, 13553, 36082, 6900, 1781, 4852, 36087, 19703, 4857, 33521, 5367, 10492, 20222, 14594, 28933, 5383, 1287, 8456, 1801, 4875, 11025, 32020, 19733, 19740, 32028, 21791, 1314, 6946, 35106, 1317, 6950, 297, 18218, 12587, 1324, 31532, 26412, 36143, 36148, 4404, 822, 7991, 2360, 33593, 30522, 19771, 11068, 31548, 22846, 36669, 14145, 4930, 835, 34125, 13646, 33613, 27472, 16718, 339, 17752, 13147, 7517, 26462, 7518, 34656, 9058, 19300, 25958, 36202, 18288, 27507, 2419, 30587, 22398, 18308, 24452, 33673, 30090, 10125, 19855, 33171, 6549, 6043, 18331, 18336, 31136, 33705, 35244, 11696, 13745, 36277, 19894, 9146, 20923, 36284, 35771, 30657, 30658, 10691, 30660, 30666, 2507, 36813, 19406, 7631, 6096, 977, 10194, 8147, 19922, 8662, 10711, 24538, 34779, 30683, 2526, 26081, 33761, 24547, 35812, 32229, 32230, 10729, 23019, 23020, 7152, 17395, 10229, 15862, 6140, 6654}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('thing.n.03.thing')\", 11), (\"Lemma('thing.n.08.thing')\", 11), (\"Lemma('matter.n.01.thing')\", 10), (\"Lemma('thing.n.09.thing')\", 10), (\"Lemma('thing.n.05.thing')\", 15), (\"Lemma('thing.n.01.thing')\", 26), (\"Lemma('thing.n.02.thing')\", 14), (\"Lemma('thing.n.07.thing')\", 10), (\"Lemma('thing.n.10.thing')\", 3), (\"Lemma('thing.n.04.thing')\", 10)])\n",
      "collecting tokens for  whole\n",
      "indices:    {11906, 26243, 4228, 24451, 23686, 11650, 6792, 2569, 31362, 36875, 20109, 33294, 25359, 23696, 24467, 22676, 14230, 4759, 29336, 6553, 20246, 26523, 32413, 11295, 9768, 26281, 27945, 11179, 32041, 26029, 5811, 10292, 3507, 10680, 697, 3258, 16063, 7488, 23872, 11970, 11075, 27970, 22849, 1479, 17096, 15183, 341, 9301, 11991, 12504, 31577, 26715, 5083, 26588, 36445, 13279, 15359, 24033, 6627, 27109, 4456, 30441, 29932, 6380, 1136, 32241, 28656, 17395, 33010, 20084, 12150, 25465, 23288, 14201, 25727}\n",
      "dict_items([(\"Lemma('whole.a.01.whole')\", 26), (\"Lemma('whole.n.01.whole')\", 1)])\n",
      "collecting tokens for  telling\n",
      "indices:    {26371, 6022, 10121, 10001, 17810, 16785, 27284, 19477, 30230, 30231, 36625, 30234, 33947, 24863, 18336, 16672, 30243, 20899, 812, 35373, 6581, 8245, 26298, 8126, 2495, 10302, 11329, 21700, 9797, 17485, 19414, 33634, 36582, 17383, 24691, 21368, 4600, 15995, 2428}\n",
      "dict_items([(\"Lemma('state.v.01.tell')\", 8), (\"Lemma('tell.v.02.tell')\", 12), (\"Lemma('order.v.01.tell')\", 5), (\"Lemma('tell.v.03.tell')\", 4), (\"Lemma('assure.v.02.tell')\", 1), (\"Lemma('tell.v.05.tell')\", 2), (\"Lemma('tell.v.07.tell')\", 2), (\"Lemma('revealing.s.01.telling')\", 1)])\n",
      "collecting tokens for  lie\n",
      "indices:    {3076, 12167, 35847, 4999, 4489, 4487, 3088, 30865, 2193, 10259, 19477, 34584, 5017, 12065, 29346, 4899, 4260, 12329, 26155, 555, 11314, 27063, 36791, 27834, 32828, 32829, 23999, 2624, 24389, 8645, 26185, 16850, 16851, 7636, 31957, 2004, 10970, 2011, 23900, 13797, 36198, 28267, 879, 9588, 4863}\n",
      "dict_items([(\"Lemma('lie.v.01.lie')\", 12), (\"Lemma('lie.v.06.lie')\", 2), (\"Lemma('lie.v.04.lie')\", 2), (\"Lemma('lie.n.01.lie')\", 3), (\"Lemma('lie.v.02.lie')\", 4), (\"Lemma('lie_down.v.01.lie')\", 2), (\"Lemma('dwell.v.02.lie')\", 3), (\"Lemma('lie.v.05.lie')\", 1)])\n",
      "collecting tokens for  host\n",
      "indices:    {1041, 3474, 37138, 18848, 11174, 31785, 10796, 14002, 3640, 14012, 14014, 2495, 11199, 11457, 10818, 27466, 3658, 16461, 1229, 11343, 27471, 36962, 36964, 6756, 36968, 1527}\n",
      "dict_items([(\"Lemma('master_of_ceremonies.n.01.host')\", 3), (\"Lemma('host.n.06.host')\", 1), (\"Lemma('horde.n.01.host')\", 5), (\"Lemma('host.n.01.host')\", 7), (\"Lemma('host.n.03.host')\", 3)])\n",
      "collecting tokens for  heart\n",
      "indices:    {31878}\n",
      "dict_items([])\n",
      "collecting tokens for  shall\n",
      "indices:    {27488, 25186, 27459, 4935, 14855, 14861, 36207, 4308, 14645, 24148, 13788, 18589}\n",
      "dict_items([])\n",
      "collecting tokens for  graduate\n",
      "indices:    {20900, 9288, 35753, 21032, 13290, 21038, 23118, 13214, 23160, 13241, 250, 25691, 12604, 13213, 21694, 2105}\n",
      "dict_items([(\"Lemma('graduate.v.01.graduate')\", 2), (\"Lemma('alumnus.n.01.graduate')\", 3), (\"Lemma('graduate.s.01.graduate')\", 3)])\n",
      "collecting tokens for  portland\n",
      "indices:    {20785}\n",
      "dict_items([])\n",
      "collecting tokens for  university\n",
      "indices:    {21698, 6750}\n",
      "dict_items([(\"Lemma('university.n.02.university')\", 1)])\n",
      "collecting tokens for  college\n",
      "indices:    {164, 5606}\n",
      "dict_items([(\"Lemma('college.n.01.college')\", 1)])\n",
      "collecting tokens for  law\n",
      "indices:    {16396, 29039}\n",
      "dict_items([])\n",
      "collecting tokens for  sarah\n",
      "indices:    {16674}\n",
      "dict_items([])\n",
      "collecting tokens for  found\n",
      "indices:    {18435, 32773, 18, 10274, 32804, 4134, 14375, 18473, 2093, 24623, 12336, 12342, 6208, 14404, 36934, 34888, 14408, 14414, 14416, 2134, 6244, 16492, 32880, 14455, 26745, 2172, 34941, 34942, 30849, 30850, 34957, 14477, 14479, 4240, 37009, 8337, 18575, 8341, 22687, 4270, 32946, 30915, 10435, 14533, 8393, 14539, 2253, 16590, 37082, 30953, 12529, 12542, 2348, 26924, 16691, 20789, 12605, 26945, 12618, 33099, 2382, 335, 18783, 2401, 10616, 14712, 6534, 33159, 4499, 10645, 33201, 10673, 440, 2489, 2493, 31169, 14806, 14809, 14813, 12784, 25112, 14877, 25118, 14878, 21028, 551, 16945, 14899, 29239, 16959, 23108, 12879, 35410, 12885, 16984, 2652, 635, 35458, 23174, 652, 23184, 35474, 35483, 29349, 31398, 4782, 688, 691, 4789, 693, 6843, 700, 33475, 35524, 29385, 29387, 33483, 10955, 29392, 29396, 10965, 4824, 21212, 35564, 8952, 8966, 8967, 6932, 13079, 21275, 23326, 2847, 13101, 21296, 21300, 25403, 33607, 21333, 19292, 17258, 17261, 21359, 7033, 9081, 9082, 9086, 9091, 9096, 27531, 11149, 33678, 21392, 11162, 17306, 21408, 25509, 35759, 5040, 2996, 13243, 5058, 9156, 11205, 15306, 13259, 31699, 9181, 5087, 17377, 27618, 19425, 31717, 9191, 11241, 17386, 17390, 15342, 9201, 3069, 35842, 3075, 35845, 15368, 3080, 23572, 11285, 15387, 11297, 3112, 3114, 3118, 15422, 11332, 23623, 11335, 9292, 27726, 11350, 3161, 3177, 7276, 21622, 35959, 9345, 9346, 13449, 29837, 17550, 27794, 5268, 23715, 21670, 5287, 36011, 3243, 11439, 3248, 9397, 5306, 5312, 5316, 27855, 23762, 3282, 13524, 3286, 3289, 7388, 11485, 7390, 11490, 31988, 34051, 25860, 25862, 27923, 21794, 21797, 7467, 34111, 17736, 1354, 34127, 5458, 25939, 34132, 15700, 34140, 34142, 1377, 36196, 34154, 1387, 34155, 5487, 28025, 15738, 1407, 17797, 34188, 7564, 15761, 15762, 17831, 13735, 15785, 5556, 32182, 34232, 5561, 5562, 5569, 21956, 36297, 36310, 17879, 15842, 13797, 36330, 34283, 15860, 34294, 3577, 3580, 3582, 3583, 34304, 13827, 3590, 15882, 28176, 7704, 36383, 24110, 20021, 15927, 9794, 15943, 20039, 26187, 32336, 3670, 34411, 32373, 24184, 3710, 3717, 34437, 13966, 3727, 36518, 1712, 32433, 7857, 3776, 28355, 3782, 30406, 34520, 7897, 3803, 34528, 3812, 3813, 16117, 3831, 14076, 12038, 5899, 14104, 14110, 18206, 20256, 26402, 7974, 18220, 7988, 18231, 28476, 28477, 24394, 36684, 1871, 1872, 36689, 18267, 18286, 18294, 18305, 3975, 3985, 3989, 4005, 10152, 10157, 6061, 14255, 12216, 12217, 18362, 34749, 16320, 4039, 8144, 4055, 28633, 6105, 28634, 28638, 22498, 22499, 4078, 36854}\n",
      "dict_items([(\"Lemma('detect.v.01.find')\", 26), (\"Lemma('witness.v.02.find')\", 18), (\"Lemma('discover.v.04.find')\", 18), (\"Lemma('find.v.01.find')\", 26), (\"Lemma('find.v.10.find')\", 9), (\"Lemma('determine.v.01.find')\", 26), (\"Lemma('rule.v.04.find')\", 11), (\"Lemma('find.v.03.find')\", 26), (\"Lemma('find.v.13.find')\", 4), (\"Lemma('line_up.v.02.find')\", 14), (\"Lemma('discover.v.03.find')\", 20), (\"Lemma('found.a.01.found')\", 1), (\"Lemma('find.v.05.find')\", 18), (\"Lemma('receive.v.02.find')\", 5), (\"Lemma('found.n.01.found')\", 1)])\n",
      "collecting tokens for  right\n",
      "indices:    {14593, 35076, 4751, 4880, 25489, 17043, 34329, 11036, 27816, 25266, 27446, 17340, 33852, 5824, 27461, 19659, 35032, 28763, 28380, 4061, 8415, 24164, 34277, 26091, 16511}\n",
      "dict_items([(\"Lemma('correct.a.01.right')\", 1), (\"Lemma('right.r.01.right')\", 1), (\"Lemma('right.n.01.right')\", 1), (\"Lemma('right.a.04.right')\", 1), (\"Lemma('right.r.02.right')\", 1), (\"Lemma('right.n.02.right')\", 2)])\n",
      "collecting tokens for  key\n",
      "indices:    {36608, 29890, 7427, 12932, 11720, 13801, 20489, 6159, 5903, 36498, 31315, 23284, 498, 21238, 27513, 3610, 23292, 21534}\n",
      "dict_items([(\"Lemma('cardinal.s.01.key')\", 2), (\"Lemma('key.n.01.key')\", 2), (\"Lemma('identify.v.05.key')\", 1), (\"Lemma('key.n.02.key')\", 2), (\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  door\n",
      "indices:    {18946, 19976, 34314, 9227, 5133, 34319, 16914, 34323, 34324, 6165, 8735, 8738, 8740, 30759, 2089, 27689, 16937, 6192, 19506, 18484, 19510, 19511, 7736, 7737, 18487, 9788, 16957, 18494, 9279, 16956, 18495, 17471, 6211, 34892, 35406, 35407, 6228, 9812, 35414, 35933, 23648, 5734, 18534, 35432, 33385, 35434, 35433, 17517, 8302, 5231, 31346, 31347, 21111, 21623, 36472, 9338, 18554, 9850, 28286, 33412, 28292, 22150, 28294, 35973, 33931, 17547, 34960, 33936, 9366, 9367, 34967, 17559, 9370, 8346, 17562, 17561, 17563, 17055, 18592, 16545, 17570, 17571, 19616, 6309, 9382, 9383, 17063, 19113, 6313, 17066, 9385, 9386, 30889, 29865, 29863, 29363, 17588, 7349, 29368, 21176, 14014, 9920, 10946, 10947, 7364, 25286, 33992, 24266, 7370, 36560, 18132, 36566, 29402, 16607, 7392, 16610, 7396, 13032, 35049, 10986, 34025, 13548, 34030, 16622, 34031, 34033, 36590, 10483, 9465, 7420, 5886, 7423, 30974, 18176, 18178, 7427, 18180, 18182, 18183, 16650, 16651, 23308, 35083, 36628, 35092, 33560, 33562, 6428, 33569, 13601, 33575, 33577, 9001, 34091, 33582, 33583, 9007, 7474, 16691, 23346, 33587, 7479, 6458, 33605, 16713, 17738, 9548, 24396, 13655, 17240, 34136, 27482, 5471, 34148, 16742, 11111, 16746, 18294, 24951, 19322, 36730, 12157, 36736, 17284, 17285, 17288, 9614, 9624, 18330, 35738, 35742, 35245, 31151, 1968, 18357, 18358, 33722, 17854, 16832, 33729, 35778, 18370, 18372, 18374, 5063, 35784, 18887, 19914, 9674, 19917, 18386, 35794, 9686, 9688, 34265, 34267, 34269, 36318, 15840, 7137, 5088, 28643, 5092, 21479, 34280, 5097, 5098, 5101, 36337, 7155, 17398, 7161, 7162}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('door.n.01.door')\", 26), (\"Lemma('doorway.n.01.door')\", 26), (\"Lemma('door.n.03.door')\", 1)])\n",
      "collecting tokens for  fortunately\n",
      "indices:    {4398}\n",
      "dict_items([(\"Lemma('fortunately.r.01.fortunately')\", 1)])\n",
      "collecting tokens for  towns\n",
      "indices:    {32612, 32613, 32620, 32557, 32556, 32503, 24826, 32411, 32412, 32413}\n",
      "dict_items([])\n",
      "collecting tokens for  possible\n",
      "indices:    {11392, 2, 2819, 29829, 24198, 30091, 16144, 33169, 30483, 3731, 14613, 5013, 34964, 1817, 3481, 9881, 3486, 1696, 35617, 31907, 22055, 14632, 3241, 19370, 3240, 15664, 178, 3123, 20788, 35636, 14643, 1716, 13490, 20793, 31290, 25659, 3065, 4416, 26560, 28354, 22723, 4674, 14913, 14912, 27591, 25928, 21831, 28102, 1355, 591, 13904, 30804, 3926, 11095, 13788, 12765, 19164, 22625, 11618, 4580, 2790, 20328, 34153, 13675, 16108, 2925, 2805, 28661, 33141, 16120, 12917, 25465, 891, 18302}\n",
      "dict_items([(\"Lemma('potential.a.01.possible')\", 6), (\"Lemma('possible.a.01.possible')\", 26)])\n",
      "collecting tokens for  exceptions\n",
      "indices:    {32380, 24931, 32580, 2568, 23433, 21995, 32303, 14741, 13334, 13339, 32444}\n",
      "dict_items([(\"Lemma('exception.n.01.exception')\", 4)])\n",
      "collecting tokens for  too\n",
      "indices:    {17024, 31909, 12038, 9160, 5744, 29424, 17749, 3766, 26908, 27965, 13759}\n",
      "dict_items([(\"Lemma('besides.r.02.too')\", 2), (\"Lemma('excessively.r.01.too')\", 4)])\n",
      "collecting tokens for  difficult\n",
      "indices:    {26121, 28170, 3086, 31247, 2577, 3602, 27670, 10271, 10278, 1069, 10287, 32305, 14899, 27700, 14390, 6200, 15421, 5185, 35910, 31823, 27728, 30811, 2658, 36976, 23672, 32377, 9849, 3200, 1157, 13962, 32395, 14477, 4750, 13968, 4757, 22682, 20635, 32411, 3230, 23201, 11430, 25770, 15530, 25772, 20655, 16060, 31424, 25283, 31431, 23753, 31435, 22733, 16079, 208, 27346, 723, 25812, 35541, 3805, 16094, 36581, 14565, 16131, 2820, 27914, 32015, 23825, 16149, 20249, 14621, 2334, 35624, 32557, 18733, 26420, 32054, 12086, 24896, 32580, 17237, 1367, 15192, 26456, 26969, 14686, 31582, 15718, 32623, 36208, 7025, 7033, 23935, 3458, 31121, 3494, 15785, 22963, 28606, 32193, 5058, 4035, 11218, 24530, 12249, 4575, 25570, 11243, 19439, 31215, 15349, 5112, 13307, 14332}\n",
      "dict_items([(\"Lemma('difficult.a.01.difficult')\", 26)])\n",
      "collecting tokens for  position\n",
      "indices:    {22660, 10633, 12940, 15757, 3089, 29594, 11295, 28832, 15785, 8235, 31033, 31034, 32957, 31805, 1983, 20416, 23617, 1985, 31172, 23752, 25035, 28748, 1355, 3923, 5078, 18916, 31077, 3556, 28521, 3054, 11119, 11377, 15221, 34810}\n",
      "dict_items([(\"Lemma('position.n.01.position')\", 6), (\"Lemma('position.n.03.position')\", 2), (\"Lemma('position.n.04.position')\", 4), (\"Lemma('position.n.07.position')\", 2), (\"Lemma('position.n.06.position')\", 2), (\"Lemma('status.n.01.position')\", 1), (\"Lemma('situation.n.02.position')\", 1)])\n",
      "collecting tokens for  finance\n",
      "indices:    {23876, 23366, 20719}\n",
      "dict_items([(\"Lemma('finance.v.01.finance')\", 2)])\n",
      "collecting tokens for  proposed\n",
      "indices:    {5509, 25743, 21398, 15257, 27807, 23327, 23463, 2737, 2738, 20532, 20533, 11448, 27083, 20172, 21966, 20432, 12372, 29921, 20843, 20335, 113, 20209, 32510}\n",
      "dict_items([(\"Lemma('propose.v.01.propose')\", 6), (\"Lemma('project.v.08.propose')\", 6)])\n",
      "collecting tokens for  change\n",
      "indices:    {30210, 11268, 16391, 26634, 26635, 25100, 4117, 11301, 12327, 11831, 10300, 22590, 10814, 31808, 31813, 31816, 15948, 14931, 11864, 24157, 30818, 35941, 2662, 15463, 31849, 4721, 33908, 11382, 33405, 4228, 18053, 24200, 26767, 4250, 31906, 1700, 4803, 16579, 27847, 31952, 14554, 32987, 25312, 5861, 1273, 20220, 29440, 22275, 34059, 3345, 16155, 23841, 12073, 31018, 12075, 13103, 3919, 32596, 32599, 32088, 22889, 28521, 4463, 12656, 24434, 13683, 12146, 11634, 24438, 10618, 29052, 22397, 2431, 13697, 13698, 24451, 36226, 4999, 11656, 31118, 5010, 15778, 15781, 4529, 33207, 33208, 4537, 33211, 9660, 23487, 7618, 15810, 4037, 17349, 33227, 16342, 4582, 1510, 30186, 12780, 33260, 36335, 25076, 16383}\n",
      "dict_items([(\"Lemma('change.v.01.change')\", 17), (\"Lemma('change.n.05.change')\", 1), (\"Lemma('change.n.02.change')\", 13), (\"Lemma('change.n.03.change')\", 6), (\"Lemma('change.v.02.change')\", 6), (\"Lemma('change.v.06.change')\", 3), (\"Lemma('change.n.01.change')\", 14), (\"Lemma('change.v.03.change')\", 4), (\"Lemma('switch.v.03.change')\", 5), (\"Lemma('change.n.04.change')\", 2), (\"Lemma('change.n.07.change')\", 1)])\n",
      "collecting tokens for  county\n",
      "indices:    {13}\n",
      "dict_items([])\n",
      "collecting tokens for  judges\n",
      "indices:    {25019, 20167}\n",
      "dict_items([])\n",
      "collecting tokens for  commissioners\n",
      "indices:    {28039}\n",
      "dict_items([])\n",
      "collecting tokens for  engineers\n",
      "indices:    {1089, 15766, 32311, 1784, 23420, 28637}\n",
      "dict_items([(\"Lemma('engineer.n.01.engineer')\", 3)])\n",
      "collecting tokens for  assessors\n",
      "indices:    {32418, 32420, 32422, 32395, 32427, 32429, 32430, 32431, 32433, 32403, 32435, 32405, 32437, 32404, 32441, 32377, 32406}\n",
      "dict_items([])\n",
      "collecting tokens for  lived\n",
      "indices:    {2184, 26763, 36364, 6030, 20878, 2190, 29214, 34212, 18215, 2472, 16815, 16818, 14387, 11444, 21556, 14392, 8770, 11334, 11465, 18250, 19541, 28117, 31704, 1510, 9581, 35189, 35705}\n",
      "dict_items([(\"Lemma('be.v.11.live')\", 4), (\"Lemma('populate.v.01.live')\", 13), (\"Lemma('live.v.02.live')\", 7), (\"Lemma('exist.v.02.live')\", 1), (\"Lemma('survive.v.01.live')\", 2)])\n",
      "collecting tokens for  valuable\n",
      "indices:    {15393, 1730, 34359, 262, 32487, 32683, 23020, 25293, 1933, 11471, 630, 1238, 1949}\n",
      "dict_items([(\"Lemma('valuable.a.01.valuable')\", 5), (\"Lemma('valuable.s.02.valuable')\", 2)])\n",
      "collecting tokens for  knowledge\n",
      "indices:    {9989, 11269, 14348, 27533, 16142, 23568, 21524, 23572, 23574, 3480, 3481, 33945, 14364, 25633, 25506, 32674, 24738, 1571, 3490, 552, 5160, 2091, 32428, 32427, 11696, 2354, 31413, 14390, 26809, 24764, 4671, 17984, 28224, 27330, 33219, 2886, 33223, 21451, 2637, 27982, 36303, 4817, 31058, 32978, 27091, 31062, 26199, 27350, 35676, 1118, 9695, 1119, 5858, 27876, 17640, 25961, 14697, 25067, 14699, 23531, 13288, 9576, 28139, 14065, 22514, 17907, 33259, 20216, 30969, 12795}\n",
      "dict_items([(\"Lemma('cognition.n.01.knowledge')\", 26)])\n",
      "collecting tokens for  regarding\n",
      "indices:    {25035, 11633, 32530, 25939, 20, 4277, 27800, 32380, 25341}\n",
      "dict_items([(\"Lemma('involve.v.01.regard')\", 4), (\"Lemma('see.v.05.regard')\", 1)])\n",
      "collecting tokens for  site\n",
      "indices:    {29824, 29956, 29832, 29963, 29845, 1814, 1817, 1819, 25116, 28702, 1823, 1825, 1827, 26532, 1829, 1830, 1832, 1834, 1835, 29356, 1837, 1840, 1842, 1843, 1844, 12469, 5433, 1850, 1852, 1854, 5446, 1862, 14024, 21834, 1868, 1870, 5199, 1871, 1873, 1874, 3671, 1883, 1894, 1895, 1896, 27242, 1902, 28528, 14835, 12531, 125, 1913, 1915, 21629}\n",
      "dict_items([(\"Lemma('site.n.01.site')\", 26), (\"Lemma('site.n.02.site')\", 1)])\n",
      "collecting tokens for  opinions\n",
      "indices:    {20369, 32406, 671, 1829, 1830, 15782, 4648, 20276, 26937, 26683, 7357, 27328, 25930, 37072, 32978, 24658, 15449, 31707, 24668, 31730, 27260}\n",
      "dict_items([(\"Lemma('opinion.n.01.opinion')\", 6), (\"Lemma('opinion.n.02.opinion')\", 1)])\n",
      "collecting tokens for  offer\n",
      "indices:    {32129, 14215, 28170, 24331, 14904, 20432, 8692, 25332, 14133, 23960, 26969, 11352, 21884, 18045}\n",
      "dict_items([(\"Lemma('offer.v.02.offer')\", 3), (\"Lemma('offer.v.01.offer')\", 9), (\"Lemma('volunteer.v.02.offer')\", 1)])\n",
      "collecting tokens for  varied\n",
      "indices:    {3721, 3342, 14223, 27162, 5532, 1829, 31272, 10288, 14901, 1206, 3766, 11323, 32319, 12998, 32585, 27852, 26073, 4700, 3300, 26343, 15848, 22762, 32620, 30700, 2927, 27888, 19569, 5490, 2808, 30717}\n",
      "dict_items([(\"Lemma('varied.a.01.varied')\", 9), (\"Lemma('change.v.03.vary')\", 6), (\"Lemma('vary.v.04.vary')\", 3), (\"Lemma('deviate.v.02.vary')\", 4)])\n",
      "collecting tokens for  professional\n",
      "indices:    {28584, 11880, 22073, 508, 26077, 27901}\n",
      "dict_items([(\"Lemma('professional.a.01.professional')\", 2)])\n",
      "collecting tokens for  experiences\n",
      "indices:    {771, 2181, 14223, 24722, 30739, 4885, 14621, 14238, 14627, 1829, 16293, 15404, 11948, 12590, 26931, 29240, 4793, 33343, 15680, 8262, 2252, 32208, 15825, 24530, 32851, 33233, 32088, 1373, 25062, 7274, 24556, 32115, 4213, 27637}\n",
      "dict_items([(\"Lemma('experience.n.01.experience')\", 6), (\"Lemma('experience.n.03.experience')\", 8), (\"Lemma('experience.n.02.experience')\", 4), (\"Lemma('experience.v.01.experience')\", 2), (\"Lemma('experience.v.03.experience')\", 1)])\n",
      "collecting tokens for  slight\n",
      "indices:    {28801, 2565, 12677, 22918, 30224, 8594, 2965, 12073, 25392, 31027, 26827, 26831, 26832, 30543, 32986, 31963, 36577, 25446, 13420, 4463, 21871, 13679, 4079, 29558, 21880, 3705, 6010, 3580, 29565}\n",
      "dict_items([(\"Lemma('rebuff.n.01.slight')\", 2)])\n",
      "collecting tokens for  pain\n",
      "indices:    {18443, 18446, 34834, 34071, 34073, 5659, 8866, 35107, 17576, 4265, 4266, 4267, 2218, 30763, 4272, 34866, 30771, 27316, 20918, 30390, 30777, 4921, 34879, 36032, 24257, 30786, 7743, 30789, 24782, 14419, 30804, 7637, 34902, 4054, 27352, 30807, 19157, 4059, 30811, 4832, 4834, 4836, 9191, 17000, 4840, 8681, 30823, 4845, 4847, 7667, 34931, 34803, 34805, 10743, 7028, 4857}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('pain.n.01.pain')\", 16), (\"Lemma('pain.n.03.pain')\", 6), (\"Lemma('pain.n.02.pain')\", 8)])\n",
      "collecting tokens for  head\n",
      "indices:    {29602, 19300, 17094, 10667, 6316, 27343, 23311, 10680, 6907, 37054, 9215}\n",
      "dict_items([(\"Lemma('head.n.01.head')\", 6), (\"Lemma('mind.n.01.head')\", 1)])\n",
      "collecting tokens for  both\n",
      "indices:    {3264, 25921, 33057, 24164, 22502, 3582, 14954, 30763, 4620, 2352, 18418, 14387, 9401, 29083, 5310, 26975}\n",
      "dict_items([])\n",
      "collecting tokens for  elements\n",
      "indices:    {27875, 4292, 5413, 1223, 2664, 15721, 22153, 26270, 15723, 2640, 20216, 15763, 1236, 26622, 13464, 15707, 27550}\n",
      "dict_items([(\"Lemma('component.n.01.element')\", 9), (\"Lemma('component.n.03.element')\", 2)])\n",
      "collecting tokens for  willingness\n",
      "indices:    {32898, 1346, 5351, 22634, 14223, 32880, 5137, 14419, 15320, 1051}\n",
      "dict_items([(\"Lemma('willingness.n.01.willingness')\", 7)])\n",
      "collecting tokens for  hold\n",
      "indices:    {20810, 34508, 23311, 1663, 33912, 17020, 6046, 32223}\n",
      "dict_items([(\"Lemma('hold.v.02.hold')\", 1), (\"Lemma('keep.v.01.hold')\", 1), (\"Lemma('appreciation.n.01.hold')\", 1), (\"Lemma('deem.v.01.hold')\", 1), (\"Lemma('hold.v.03.hold')\", 1)])\n",
      "collecting tokens for  reflected\n",
      "indices:    {2952, 31756, 2829, 12303, 8848, 2832, 31510, 12319, 16423, 31787, 4275, 14395, 31805, 31806, 1733, 10440, 23625, 5834, 32848, 15313, 17366, 22615, 11359, 32228, 16872, 17390, 36979, 33787}\n",
      "dict_items([(\"Lemma('reflect.v.01.reflect')\", 12), (\"Lemma('chew_over.v.01.reflect')\", 6), (\"Lemma('reflect.v.04.reflect')\", 3), (\"Lemma('reflect.v.03.reflect')\", 6)])\n",
      "collecting tokens for  letter\n",
      "indices:    {24323, 30084, 13701, 26122, 26384, 9617, 33940, 24217, 36506, 24219, 36633, 12573, 24221, 24223, 27300, 25256, 8876, 10618, 2095, 10746, 35507, 35508, 30392, 25403, 5308, 14018, 27587, 11460, 5320, 25034, 21451, 12619, 21196, 25040, 15569, 25041, 13395, 25042, 25048, 25049, 22616, 35939, 20329, 26859, 26091, 9581, 10734, 7663, 34927, 7665, 18292, 21748, 7672, 12538, 7675, 9598}\n",
      "dict_items([(\"Lemma('letter.n.01.letter')\", 19), (\"Lemma('letter.n.02.letter')\", 1)])\n",
      "collecting tokens for  president\n",
      "indices:    {20212}\n",
      "dict_items([])\n",
      "collecting tokens for  ambassador\n",
      "indices:    {24145}\n",
      "dict_items([])\n",
      "collecting tokens for  e.\n",
      "indices:    {20771}\n",
      "dict_items([])\n",
      "collecting tokens for  thompson\n",
      "indices:    {21886}\n",
      "dict_items([])\n",
      "collecting tokens for  russia\n",
      "indices:    {12353}\n",
      "dict_items([(\"Lemma('soviet_union.n.01.Russia')\", 1)])\n",
      "collecting tokens for  late\n",
      "indices:    {9668, 27334, 26792, 25129, 5035, 24145, 307, 22844}\n",
      "dict_items([(\"Lemma('late.a.01.late')\", 1), (\"Lemma('late.r.01.late')\", 1)])\n",
      "collecting tokens for  february\n",
      "indices:    {3762}\n",
      "dict_items([(\"Lemma('february.n.01.February')\", 1)])\n",
      "collecting tokens for  field\n",
      "indices:    {3714, 17926, 25646, 4604, 21529, 21562, 14364, 3133}\n",
      "dict_items([(\"Lemma('discipline.n.01.field')\", 1), (\"Lemma('field.n.03.field')\", 2), (\"Lemma('sphere.n.01.field')\", 1), (\"Lemma('field.n.05.field')\", 1)])\n",
      "collecting tokens for  ripe\n",
      "indices:    {5035}\n",
      "dict_items([])\n",
      "collecting tokens for  southerners\n",
      "indices:    {2540}\n",
      "dict_items([(\"Lemma('southerner.n.01.Southerner')\", 1)])\n",
      "collecting tokens for  step\n",
      "indices:    {16387, 16900, 5129, 15891, 31765, 22041, 29727, 18464, 27689, 8747, 15916, 33848, 15930, 5193, 29770, 12874, 26705, 25181, 25200, 17528, 10876, 29824, 35971, 29827, 12966, 15018, 9386, 15020, 15031, 28856, 27337, 9931, 27341, 11476, 25820, 5363, 20230, 20237, 27408, 28442, 29470, 34080, 13605, 33584, 27957, 10552, 1337, 1338, 34110, 10561, 30021, 5958, 23880, 34123, 29007, 14166, 2395, 20840, 24425, 26478, 20338, 19315, 14196, 25464, 28548, 1929, 20362, 19338, 8094, 9634, 15808, 15809, 15810, 15811, 15812, 12233, 11722, 25060, 12264, 12268, 14832, 14320, 18421}\n",
      "dict_items([(\"Lemma('measure.n.01.step')\", 23), (\"Lemma('step.v.02.step')\", 1), (\"Lemma('step.v.01.step')\", 5), (\"Lemma('footstep.n.03.step')\", 6), (\"Lemma('step.n.04.step')\", 2), (\"Lemma('step.n.03.step')\", 3), (\"Lemma('gradation.n.01.step')\", 1)])\n",
      "collecting tokens for  write\n",
      "indices:    {12546, 9605, 6022, 10631, 6793, 14480, 4370, 28435, 36506, 8349, 26015, 12576, 25633, 13985, 34599, 2471, 8746, 11182, 21941, 23221, 19765, 31804, 21184, 17858, 27587, 14540, 14415, 24914, 8152, 25049, 29916, 31965, 14564, 1384, 26089, 36202, 27627, 6508, 5869, 8686, 6511, 26096, 26097, 30703, 34931, 11252, 4341, 14455, 31737, 6778}\n",
      "dict_items([(\"Lemma('write.v.01.write')\", 19), (\"Lemma('write.v.02.write')\", 11), (\"Lemma('publish.v.03.write')\", 5), (\"Lemma('write.v.05.write')\", 3), (\"Lemma('write.v.04.write')\", 2), (\"Lemma('compose.v.02.write')\", 3), (\"Lemma('spell.v.03.write')\", 1), (\"Lemma('write_down.v.01.write_down')\", 1), (\"Lemma('write.v.07.write')\", 2)])\n",
      "collecting tokens for  phenomenon\n",
      "indices:    {16144, 3859, 11413, 16408, 4258, 3363, 33202, 31796, 24374, 5432, 2874, 33219, 31816, 2889, 34633, 12750, 5457, 2143, 26721, 13168, 4465, 14576, 15859, 31089, 1397, 1274}\n",
      "dict_items([(\"Lemma('phenomenon.n.01.phenomenon')\", 12), (\"Lemma('phenomenon.n.02.phenomenon')\", 5)])\n",
      "collecting tokens for  southern\n",
      "indices:    {14507}\n",
      "dict_items([(\"Lemma('southern.a.01.southern')\", 1)])\n",
      "collecting tokens for  urban\n",
      "indices:    {5473, 31842, 28102, 31848, 5418, 4590, 4783, 2382, 29041, 33072, 33075, 4788, 31825, 11794, 32985, 21500, 13182}\n",
      "dict_items([(\"Lemma('urban.a.01.urban')\", 3), (\"Lemma('urban.a.02.urban')\", 2)])\n",
      "collecting tokens for  economy\n",
      "indices:    {15489, 21890, 24164, 4620, 32277, 14201, 24124}\n",
      "dict_items([(\"Lemma('economy.n.01.economy')\", 3)])\n",
      "collecting tokens for  pains\n",
      "indices:    {14116, 34917, 26091, 21611, 22610, 34835, 31796, 7701, 24371, 2261, 7158, 31705}\n",
      "dict_items([(\"Lemma('pain.n.03.pain')\", 1), (\"Lemma('striving.n.01.pains')\", 3)])\n",
      "collecting tokens for  transition\n",
      "indices:    {14849, 25744, 34461, 20638, 4642, 20645, 20652, 32173, 14842, 31796, 32572, 32577, 11214, 15055, 32592, 23896, 2397, 14701, 32622, 26484, 14841, 27642, 25724, 14845, 14846}\n",
      "dict_items([(\"Lemma('passage.n.01.transition')\", 8), (\"Lemma('conversion.n.01.transition')\", 2)])\n",
      "collecting tokens for  labor\n",
      "indices:    {23973}\n",
      "dict_items([])\n",
      "collecting tokens for  problems\n",
      "indices:    {32260, 20997, 18437, 14348, 1042, 4626, 4629, 22566, 23591, 22569, 30762, 15402, 23596, 25139, 10805, 15414, 14399, 14400, 24644, 32328, 32329, 30794, 16461, 2638, 11343, 15452, 30812, 31842, 29289, 31852, 24182, 32378, 32892, 4741, 25736, 32904, 4247, 14488, 25758, 2719, 15522, 28323, 23717, 2727, 4775, 3244, 13485, 173, 25775, 2734, 28849, 174, 4789, 4278, 1719, 1208, 4793, 32954, 4283, 25279, 32964, 30407, 25290, 25294, 722, 25302, 17121, 23265, 14062, 10991, 14063, 32500, 23284, 21237, 23288, 14591, 24831, 16131, 23300, 12038, 20231, 4359, 20232, 16143, 16148, 12057, 12061, 2336, 29989, 29990, 25900, 4398, 30516, 30011, 24893, 11076, 15173, 27463, 32587, 22347, 23897, 14174, 15200, 5472, 31075, 7015, 11624, 11625, 5489, 5491, 33140, 7542, 3455, 30081, 1939, 24981, 15254, 14237, 14240, 5537, 3493, 32679, 3497, 26035, 22451, 30139, 32193, 24001, 2501, 20423, 11720, 11721, 11722, 27595, 32210, 2522, 25564, 32225, 4580, 4587, 27119, 4596}\n",
      "dict_items([(\"Lemma('problem.n.01.problem')\", 26), (\"Lemma('trouble.n.01.problem')\", 5), (\"Lemma('problem.n.02.problem')\", 11)])\n",
      "collecting tokens for  list\n",
      "indices:    {15881, 15882, 11819, 15916, 29470, 9423, 12178, 12659, 21810, 9881, 1815, 8729, 8666, 13310}\n",
      "dict_items([(\"Lemma('list.n.01.list')\", 9), (\"Lemma('list.v.01.list')\", 2), (\"Lemma('list.v.02.list')\", 1)])\n",
      "collecting tokens for  obviously\n",
      "indices:    {3714, 17227, 32876, 17549, 4206, 1331, 27091, 24476}\n",
      "dict_items([(\"Lemma('obviously.r.01.obviously')\", 5)])\n",
      "collecting tokens for  endless\n",
      "indices:    {18658, 28323, 35526, 37096, 33803, 36122, 10637, 27439, 23696, 35544, 2352, 31796, 29238, 4663, 10646, 26554}\n",
      "dict_items([(\"Lemma('endless.s.01.endless')\", 4), (\"Lemma('endless.s.02.endless')\", 1)])\n",
      "collecting tokens for  expect\n",
      "indices:    {3459, 35077, 16646, 25349, 26505, 11659, 24333, 16909, 24339, 31764, 26517, 3352, 14233, 12186, 24478, 4256, 24480, 9890, 24488, 8232, 9256, 3118, 24500, 17466, 33084, 15678, 21063, 16077, 27088, 14289, 21975, 35544, 16990, 14431, 2530, 16101, 9832, 4203, 13420, 20335, 4595, 12157}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('expect.v.01.expect')\", 26), (\"Lemma('ask.v.04.expect')\", 4), (\"Lemma('expect.v.03.expect')\", 2)])\n",
      "collecting tokens for  general\n",
      "indices:    {20307, 25036, 13}\n",
      "dict_items([(\"Lemma('general.a.01.general')\", 1)])\n",
      "collecting tokens for  phonologic\n",
      "indices:    {16128, 16134, 16073, 16137, 16075, 16076, 16077, 16139, 16092, 16094}\n",
      "dict_items([(\"Lemma('phonological.a.01.phonologic')\", 9)])\n",
      "collecting tokens for  adequate\n",
      "indices:    {12161, 24964, 5510, 4241, 27153, 32150, 14751, 27937, 31013, 1318, 2091, 16301, 2223, 25263, 16053, 25026, 31171, 22724, 22723, 22725, 24915, 32727, 34520, 32352, 25446, 871, 23532, 15860, 16373, 5498, 12159}\n",
      "dict_items([(\"Lemma('adequate.s.02.adequate')\", 3), (\"Lemma('adequate.a.01.adequate')\", 9)])\n",
      "collecting tokens for  tone\n",
      "indices:    {22699, 16075, 19789, 26091, 16063, 1425, 13203, 10481, 16086, 17334, 19417, 16090, 10940, 16095}\n",
      "dict_items([(\"Lemma('tone.n.01.tone')\", 5), (\"Lemma('tone.n.02.tone')\", 4), (\"Lemma('spirit.n.02.tone')\", 1), (\"Lemma('tone.n.07.tone')\", 1)])\n",
      "collecting tokens for  fast\n",
      "indices:    {34945, 30594, 18947, 901, 28678, 22920, 20105, 24203, 11147, 16511, 34447, 22287, 1047, 1176, 17818, 36127, 15391, 34338, 29091, 36133, 25255, 30888, 23345, 33716, 21817, 18746, 35516, 14783, 14784, 14785, 30531, 25413, 25670, 29128, 18635, 19791, 209, 854, 18263, 18136, 11866, 23899, 34010, 24417, 2274, 21732, 34660, 30960, 242, 19828, 1524, 13558, 1530, 34043, 17276, 34431}\n",
      "dict_items([(\"Lemma('fast.a.01.fast')\", 9), (\"Lemma('fast.r.02.fast')\", 1), (\"Lemma('fast.r.01.fast')\", 14), (\"Lemma('fast.n.01.fast')\", 1)])\n",
      "collecting tokens for  double\n",
      "indices:    {384, 29057, 15106, 389, 29062, 26502, 29961, 393, 27787, 29066, 29068, 7306, 30995, 18458, 31131, 13215, 15139, 7467, 30123, 10670, 9269, 4535, 1720, 4541, 1725, 194, 33091, 22467, 18627, 25670, 8907, 203, 30156, 29902, 1750, 10711, 10725, 230, 871, 15975, 24041, 30187, 369, 372, 15096, 12540, 22015}\n",
      "dict_items([(\"Lemma('double.s.01.double')\", 5), (\"Lemma('double.n.01.double')\", 7), (\"Lemma('double.s.03.double')\", 4), (\"Lemma('double.s.02.double')\", 5), (\"Lemma('double.v.01.double')\", 3)])\n",
      "collecting tokens for  play\n",
      "indices:    {13824, 7683, 2569, 23051, 23055, 23059, 34846, 25633, 11813, 3624, 34864, 17968, 10805, 567, 569, 15424, 577, 25665, 22594, 2643, 33368, 17504, 33381, 6251, 4212, 31865, 1146, 30845, 1149, 638, 26240, 30846, 8840, 6285, 6286, 659, 22165, 669, 20643, 37029, 37036, 13489, 4279, 190, 7875, 21700, 13532, 26845, 14558, 1246, 1247, 1251, 22756, 1254, 1258, 26862, 1263, 1266, 1269, 21239, 1276, 1280, 1281, 261, 25362, 801, 14627, 12069, 295, 31535, 11064, 313, 13630, 319, 36673, 13634, 323, 327, 334, 26960, 17744, 31570, 2391, 350, 353, 374, 375, 3978, 907, 909, 24988, 31653, 26544, 20913, 15806, 446, 13251, 26569, 20964, 36327, 17391, 26608, 22526, 22527}\n",
      "dict_items([(\"Lemma('play.n.02.play')\", 6), (\"Lemma('play.n.01.play')\", 16), (\"Lemma('play.v.03.play')\", 7), (\"Lemma('play.v.02.play')\", 7), (\"Lemma('play.v.05.play')\", 9), (\"Lemma('play.v.01.play')\", 17), (\"Lemma('play.n.03.play')\", 4), (\"Lemma('play.v.14.play')\", 1), (\"Lemma('play.v.06.play')\", 2), (\"Lemma('play.n.05.play')\", 2), (\"Lemma('play.v.13.play')\", 1), (\"Lemma('play.v.16.play')\", 1), (\"Lemma('play.v.12.play')\", 1), (\"Lemma('play.v.10.play')\", 1), (\"Lemma('maneuver.n.03.play')\", 4), (\"Lemma('act.v.03.play')\", 1), (\"Lemma('act.v.05.play')\", 1), (\"Lemma('play.n.06.play')\", 1), (\"Lemma('play.n.08.play')\", 1), (\"Lemma('play.v.11.play')\", 1), (\"Lemma('play.v.15.play')\", 1)])\n",
      "collecting tokens for  period\n",
      "indices:    {14592, 24577, 24581, 27910, 27526, 26763, 5515, 5524, 34837, 31508, 661, 14748, 11422, 4639, 12064, 25122, 25123, 25638, 36660, 16436, 4020, 30013, 3905, 33090, 32708, 20678, 24777, 15563, 13776, 20432, 1104, 1878, 30173, 2790, 14825, 21230, 27633, 1397, 33023}\n",
      "dict_items([(\"Lemma('time_period.n.01.period')\", 15), (\"Lemma('period.n.02.period')\", 1)])\n",
      "collecting tokens for  earlier\n",
      "indices:    {865, 21220, 27688, 14634, 32620, 22700, 12784, 11508, 22006, 5240, 1113, 24028, 13534}\n",
      "dict_items([(\"Lemma('early.a.01.early')\", 1), (\"Lemma('in_the_first_place.r.01.earlier')\", 1), (\"Lemma('earlier.r.01.earlier')\", 2), (\"Lemma('sooner.r.01.earlier')\", 1)])\n",
      "collecting tokens for  centuries\n",
      "indices:    {2560, 4993, 2566, 5000, 27531, 29196, 1935, 22673, 30743, 27165, 5022, 2591, 27555, 31407, 34740, 15285, 16439, 14651, 2620, 2621, 29249, 31174, 16198, 14280, 16458, 1227, 28110, 14287, 1232, 14673, 27731, 27736, 14710, 31222, 12281, 12028, 2301, 8702}\n",
      "dict_items([(\"Lemma('century.n.01.century')\", 24)])\n",
      "collecting tokens for  pottery\n",
      "indices:    {29537, 8803, 29539, 5000, 5033, 4972, 5004, 5009, 4978, 5016, 5018, 5019, 5021}\n",
      "dict_items([(\"Lemma('pottery.n.01.pottery')\", 10), (\"Lemma('pottery.n.02.pottery')\", 1)])\n",
      "collecting tokens for  remains\n",
      "indices:    {26112, 5376, 27522, 12930, 1794, 5000, 23688, 27530, 1545, 27276, 32013, 4877, 31888, 2704, 27157, 5269, 23959, 2838, 2329, 24475, 25118, 31518, 30240, 26784, 26150, 20393, 4393, 1451, 37167, 560, 14005, 4538, 20415, 27712, 29377, 13889, 4931, 26823, 30410, 13264, 13393, 36945, 1242, 5467, 28891, 25435, 13536, 22753, 3682, 31845, 28520, 22249, 1642, 3051, 2156, 12780, 23918, 11509, 3959, 12920, 23802, 891}\n",
      "dict_items([(\"Lemma('stay.v.01.remain')\", 26), (\"Lemma('remain.v.03.remain')\", 15), (\"Lemma('stay.v.04.remain')\", 1), (\"Lemma('persist.v.03.remain')\", 2), (\"Lemma('remains.n.01.remains')\", 1)])\n",
      "collecting tokens for  secure\n",
      "indices:    {5000, 25363, 15383, 25761, 4651, 33197, 4658, 9906, 32582, 12488, 14795, 24270, 25555, 32216, 22495, 33381, 16230, 4967, 25071, 29681, 28790, 15350, 31995, 31996}\n",
      "dict_items([(\"Lemma('guarantee.v.02.secure')\", 1), (\"Lemma('fasten.v.01.secure')\", 2), (\"Lemma('secure.a.01.secure')\", 3), (\"Lemma('secure.v.03.secure')\", 1), (\"Lemma('secure.a.02.secure')\", 2), (\"Lemma('procure.v.01.secure')\", 11)])\n",
      "collecting tokens for  source\n",
      "indices:    {28178, 14100, 14103, 1047, 32037, 27562, 15020, 15148, 23982, 1718, 33084, 61, 3268, 26197, 1118, 1119, 16862, 31842, 2918, 10216, 14443, 12524, 31852, 22515, 20343, 14712, 3451, 14845, 3327}\n",
      "dict_items([(\"Lemma('beginning.n.04.source')\", 10), (\"Lemma('source.n.02.source')\", 3), (\"Lemma('source.n.03.source')\", 3), (\"Lemma('informant.n.01.source')\", 1), (\"Lemma('source.n.04.source')\", 2)])\n",
      "collecting tokens for  material\n",
      "indices:    {3588, 1029, 3589, 23559, 3086, 22031, 1043, 3093, 3094, 30749, 3615, 14368, 3105, 3106, 3110, 2043, 15424, 4689, 1106, 28758, 3159, 28760, 11352, 31842, 1125, 1126, 31852, 1647, 3186, 12917, 30839, 5753, 6780, 12928, 30850, 30852, 35975, 26254, 13460, 14485, 25236, 25238, 32937, 29892, 29896, 29899, 14540, 1227, 16089, 30938, 3811, 3313, 3315, 3316, 2811, 5371, 31485, 3329, 1287, 3337, 5385, 2828, 27917, 7442, 2326, 3352, 2329, 3354, 2332, 2346, 2348, 2350, 16178, 2356, 25909, 2870, 16187, 3388, 3389, 16190, 12606, 2363, 2371, 26436, 1353, 2891, 11612, 31069, 31071, 3430, 15207, 36714, 33143, 2423, 7551, 15746, 31109, 5000, 2962, 2973, 2975, 3999, 16292, 31141, 5034, 7607, 12223, 18881, 32705, 28098, 28101, 13256, 27597, 3028, 32725, 3542, 3032, 28121, 26075, 12261, 4076, 32750, 4591, 3566, 32751, 4086, 12793, 15867, 3582, 31231}\n",
      "dict_items([(\"Lemma('material.n.01.material')\", 26), (\"Lemma('material.n.02.material')\", 26), (\"Lemma('material.s.01.material')\", 5), (\"Lemma('fabric.n.01.material')\", 4), (\"Lemma('material.a.02.material')\", 3), (\"Lemma('material.n.04.material')\", 3), (\"Lemma('material.a.03.material')\", 1), (\"Lemma('material.s.04.material')\", 1)])\n",
      "collecting tokens for  age\n",
      "indices:    {33016, 3868}\n",
      "dict_items([(\"Lemma('age.n.01.age')\", 1)])\n",
      "collecting tokens for  hopes\n",
      "indices:    {9348, 25478, 5000, 15372, 30477, 272, 32657, 11924, 20255, 4770, 20522, 1213, 22848, 27840, 10441, 31690, 2251, 12366, 32210, 22612, 18516, 216, 34905, 30425, 23131, 21342, 24041, 2282, 22893, 28669, 11252, 17013, 24182, 2299, 24829, 23166}\n",
      "dict_items([(\"Lemma('hope.v.01.hope')\", 10), (\"Lemma('hope.n.01.hope')\", 6), (\"Lemma('hope.n.02.hope')\", 3), (\"Lemma('hope.v.03.hope')\", 4), (\"Lemma('hope.n.04.hope')\", 1), (\"Lemma('promise.n.02.hope')\", 1)])\n",
      "collecting tokens for  fears\n",
      "indices:    {5000, 2574, 2577, 27413, 2582, 27414, 17048, 2584, 19349, 2583, 2588, 2592, 27427, 27430, 27445, 5813, 27450, 2620, 27457, 2627, 27459, 16325, 11209, 31690, 2635, 32847, 24147, 25172, 32854, 32855, 2521, 5849, 16346, 27486, 6754}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('fear.n.01.fear')\", 18), (\"Lemma('concern.n.02.fear')\", 2), (\"Lemma('fear.v.01.fear')\", 2)])\n",
      "collecting tokens for  begin\n",
      "indices:    {12067, 12934, 23562, 25931, 9455, 1936, 21393, 3862, 11095, 1817, 2045}\n",
      "dict_items([(\"Lemma('get_down.v.07.begin')\", 6), (\"Lemma('begin.v.03.begin')\", 1), (\"Lemma('begin.v.02.begin')\", 1)])\n",
      "collecting tokens for  show\n",
      "indices:    {8693}\n",
      "dict_items([(\"Lemma('show.v.01.show')\", 1)])\n",
      "collecting tokens for  scenes\n",
      "indices:    {29316, 26887, 5000, 24810, 24778, 1066, 17037, 11244, 2383, 26251, 26961, 26764, 9653, 29270, 35322, 2429, 2399}\n",
      "dict_items([(\"Lemma('scene.n.01.scene')\", 1), (\"Lemma('scene.n.04.scene')\", 2), (\"Lemma('view.n.02.scene')\", 2), (\"Lemma('scene.n.06.scene')\", 2), (\"Lemma('picture.n.04.scene')\", 1)])\n",
      "collecting tokens for  human\n",
      "indices:    {12162, 1156, 25349, 36241, 2201, 32028, 27804, 12574, 8232, 27818, 14643, 14646, 36023, 11256, 27834, 27840, 12997, 1479, 14280, 34891, 15189, 10848, 3811, 36974, 30831, 34677, 3831, 10744, 27901, 24831}\n",
      "dict_items([(\"Lemma('human.a.03.human')\", 2), (\"Lemma('homo.n.02.human')\", 1), (\"Lemma('human.a.01.human')\", 6)])\n",
      "collecting tokens for  life\n",
      "indices:    {2685, 9583}\n",
      "dict_items([(\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  death\n",
      "indices:    {32065, 1482, 23851, 1484, 33852, 31088, 25105, 26165, 31100, 16862}\n",
      "dict_items([(\"Lemma('death.n.01.death')\", 1), (\"Lemma('death.n.02.death')\", 2)])\n",
      "collecting tokens for  six\n",
      "indices:    {18824, 21769, 14572, 32503}\n",
      "dict_items([(\"Lemma('six.s.01.six')\", 2)])\n",
      "collecting tokens for  u.\n",
      "indices:    {25603}\n",
      "dict_items([])\n",
      "collecting tokens for  s.\n",
      "indices:    {25603}\n",
      "dict_items([])\n",
      "collecting tokens for  aid\n",
      "indices:    {498, 22501}\n",
      "dict_items([(\"Lemma('aid.n.02.aid')\", 1)])\n",
      "collecting tokens for  american\n",
      "indices:    {23973}\n",
      "dict_items([])\n",
      "collecting tokens for  total\n",
      "indices:    {22912, 3329, 4480, 22016, 25860, 15489, 14854, 28807, 14856, 2953, 14855, 21778, 22930, 15381, 15382, 23577, 14877, 11422, 288, 289, 23332, 2858, 30255, 22705, 2996, 14909, 32708, 22726, 25415, 22729, 26197, 30680, 32760, 32730, 21230, 3439, 32882, 1780, 28917, 14838, 14966, 16248, 16249, 4476}\n",
      "dict_items([(\"Lemma('entire.s.01.total')\", 11), (\"Lemma('sum.n.05.total')\", 6), (\"Lemma('sum.n.02.total')\", 1), (\"Lemma('total.v.01.total')\", 2)])\n",
      "collecting tokens for  hundred\n",
      "indices:    {17409, 29188, 28171, 10765, 21009, 8728, 8216, 33817, 25117, 31795, 14389, 13366, 17983, 8782, 19539, 14420, 35925, 5220, 8807, 8296, 14444, 35956, 20598, 14461, 12416, 12941, 18585, 16538, 12460, 17581, 28342, 5832, 21709, 3279, 10448, 6867, 32469, 24790, 33493, 34520, 18649, 29921, 29922, 13540, 9445, 10472, 29930, 6382, 6399, 13056, 10497, 29966, 31510, 27927, 10521, 18715, 18716, 18718, 37151, 33582, 27955, 27956, 2359, 1339, 24893, 18238, 5454, 1363, 1368, 20319, 7522, 1891, 1382, 3431, 31594, 31596, 1390, 13685, 32631, 1405, 30590, 2431, 32641, 35208, 32649, 15752, 1420, 25485, 12686, 12690, 32658, 32665, 22937, 32669, 32675, 10150, 12718, 32690, 13748, 28119, 28640, 9188, 28646, 10216, 32745, 33776}\n",
      "dict_items([(\"Lemma('hundred.s.01.hundred')\", 23), (\"Lemma('hundred.n.01.hundred')\", 1)])\n",
      "collecting tokens for  million\n",
      "indices:    {12296, 20, 35860, 25623, 27163, 27164, 25117, 27167, 27174, 55, 56, 14905, 58, 60, 12348, 24636, 14915, 35922, 35923, 25171, 3162, 94, 11871, 24679, 26732, 11884, 15477, 15478, 15479, 15483, 19588, 20615, 11917, 15502, 11918, 11919, 15501, 23186, 28309, 14999, 23197, 20642, 172, 20654, 20655, 20656, 32434, 30898, 28346, 23226, 2243, 26826, 20172, 20183, 22750, 37093, 3304, 6379, 20205, 20206, 20207, 20208, 13040, 20214, 20215, 37112, 24825, 3321, 13056, 7957, 27417, 23834, 27418, 37154, 27943, 27955, 25397, 24892, 23361, 20805, 21830, 26951, 23879, 25414, 23886, 20836, 16232, 1385, 16234, 16235, 16237, 1392, 16247, 16248, 16249, 6021, 24970, 25485, 25487, 24977, 1944, 21917, 21928, 27049, 21930, 21931, 27052, 21934, 25533, 12223, 24005, 25038, 17382, 23529, 20462, 20463, 21999, 20464, 21502, 22015}\n",
      "dict_items([(\"Lemma('million.s.01.million')\", 26), (\"Lemma('million.n.01.million')\", 10)])\n",
      "collecting tokens for  dollars\n",
      "indices:    {13056, 8192, 24704, 25219, 20100, 31751, 25096, 24970, 35851, 25484, 25485, 12686, 24977, 35860, 8086, 17687, 8728, 22937, 18586, 36640, 37154, 33314, 33317, 27431, 27432, 5929, 14889, 27433, 24108, 172, 32434, 33460, 2228, 24892, 36673, 11203, 21827, 21830, 36679, 23629, 25038, 5456, 35922, 19539, 20181, 20183, 8153, 28506, 17370, 94, 12001, 33508, 37093, 101, 23528, 20205, 20206, 21616, 35956, 27125, 27124, 20215, 11897, 23546}\n",
      "dict_items([(\"Lemma('dollar.n.02.dollar')\", 6), (\"Lemma('dollar.n.01.dollar')\", 14)])\n",
      "collecting tokens for  exact\n",
      "indices:    {16001, 11011, 20367, 33555, 16807, 2864, 26935, 29893, 12229, 29895, 2247, 5701, 2126, 2128, 11096, 29913, 30041, 1388, 5359, 11379, 1784, 10876}\n",
      "dict_items([(\"Lemma('exact.a.01.exact')\", 8), (\"Lemma('accurate.s.02.exact')\", 7)])\n",
      "collecting tokens for  here\n",
      "indices:    {10259, 3911}\n",
      "dict_items([(\"Lemma('here.r.01.here')\", 2)])\n",
      "collecting tokens for  feel\n",
      "indices:    {34821, 19466, 2062, 15, 29208, 19480, 19482, 19481, 35865, 4632, 19483, 21530, 19484, 30247, 2599, 24113, 25141, 1593, 35901, 33342, 8769, 9295, 5722, 8286, 30310, 1145, 19577, 31867, 35962, 1661, 20619, 10894, 10895, 23187, 25238, 25242, 33435, 31902, 19616, 34472, 25768, 37041, 25778, 25779, 8884, 16569, 6330, 8895, 6337, 22729, 24788, 24790, 218, 6874, 22236, 22241, 1250, 24805, 19691, 1261, 6894, 4845, 36080, 13554, 36595, 21752, 1791, 35073, 12546, 27398, 24327, 27400, 27915, 33548, 37134, 5906, 9495, 19735, 28953, 10010, 283, 19226, 282, 1824, 33569, 25897, 20265, 33583, 21810, 24376, 4925, 34113, 32068, 36683, 24914, 9555, 30038, 7511, 23896, 34139, 16224, 32100, 13669, 1388, 7532, 35181, 30064, 31088, 34165, 36219, 22908, 28549, 25479, 35723, 22417, 22418, 10131, 22432, 19362, 33702, 6569, 31661, 31149, 31666, 12214, 12218, 35258, 32193, 8130, 17872, 27100, 2525, 23519, 32224, 33249, 17890, 17891, 25577, 30698, 32235, 4586, 25069, 15854, 13294, 15857, 21494, 34300, 8189}\n",
      "dict_items([(\"Lemma('find.v.05.feel')\", 26), (\"Lemma('feel.v.01.feel')\", 26), (\"Lemma('feel.v.07.feel')\", 3), (\"Lemma('feel.v.03.feel')\", 16), (\"Lemma('feel.v.04.feel')\", 10), (\"Lemma('feel.n.01.feel')\", 5), (\"Lemma('feel.v.08.feel')\", 1), (\"Lemma('feel.v.05.feel')\", 10), (\"Lemma('palpate.v.01.feel')\", 1), (\"Lemma('feel.v.06.feel')\", 1), (\"Lemma('tactile_property.n.01.feel')\", 1), (\"Lemma('spirit.n.02.feel')\", 1), (\"Lemma('feel.v.09.feel')\", 1), (\"Lemma('feel.v.11.feel')\", 1)])\n",
      "collecting tokens for  certain\n",
      "indices:    {37002, 27789, 16144, 37138, 4243, 11295, 11296, 4775, 27692, 33086, 31065, 5852, 4192, 25061, 27753, 7798, 33016, 13305, 16124, 17023}\n",
      "dict_items([(\"Lemma('certain.s.01.certain')\", 10), (\"Lemma('certain.a.02.certain')\", 1)])\n",
      "collecting tokens for  percentage\n",
      "indices:    {22022, 22024, 32919, 12186, 12700, 15261, 2472, 16169, 13227, 28462, 11567, 15024, 15022, 15027, 15028, 15029, 15032, 15041, 15043, 2501, 21832, 25928, 15050, 15051, 2511, 25295, 23506, 15065, 33115, 28007, 1385, 1388, 11376, 15219, 13172, 19445, 1398, 2039, 13182}\n",
      "dict_items([(\"Lemma('percentage.n.01.percentage')\", 23), (\"Lemma('share.n.01.percentage')\", 6)])\n",
      "collecting tokens for  ten\n",
      "indices:    {18058, 33418, 18064, 35730, 8732, 31394, 27174, 5160, 9649, 36925, 36673, 1091, 34117, 10566, 25545, 25171, 33508, 23012, 1385, 8811, 11124, 19706, 6907, 10749, 19582}\n",
      "dict_items([(\"Lemma('ten.n.01.ten')\", 4), (\"Lemma('ten.s.01.ten')\", 10)])\n",
      "collecting tokens for  oh\n",
      "indices:    {6518}\n",
      "dict_items([])\n",
      "collecting tokens for  'm\n",
      "indices:    {35329, 19464, 33291, 23052, 23564, 17933, 22539, 23058, 33298, 17433, 35868, 17951, 17952, 33313, 17442, 18975, 33319, 17449, 18992, 20017, 33329, 18995, 34867, 22583, 33337, 18490, 20543, 33347, 17481, 16974, 23123, 23125, 23126, 16474, 33897, 19052, 16494, 33394, 36467, 19572, 19578, 19068, 19584, 19082, 19084, 11918, 37007, 16528, 19087, 34451, 20127, 33443, 18083, 20133, 33447, 19112, 19630, 28336, 34994, 33972, 17080, 17594, 16572, 33983, 17089, 19658, 14540, 34513, 36563, 34516, 37086, 35039, 35042, 35055, 35056, 36592, 33528, 36088, 36090, 17659, 36091, 35070, 35082, 36108, 33548, 36113, 19740, 14128, 36659, 36148, 36662, 36663, 33593, 36667, 36175, 18259, 36691, 34652, 34660, 30565, 13178, 17793, 16771, 24454, 16785, 18322, 17300, 13206, 20887, 34200, 34209, 13730, 34213, 19879, 17834, 24505, 17852, 18879, 19907, 19912, 33739, 23500, 34252, 23501, 19919, 30680, 17883, 19932, 19936, 34791, 18409, 20470, 34811, 36350}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('be.v.01.be')\", 26), (\"Lemma('be.v.02.be')\", 7), (\"Lemma('be.v.03.be')\", 5), (\"Lemma('be.v.08.be')\", 1)])\n",
      "collecting tokens for  sorry\n",
      "indices:    {17155, 23564, 7308, 26644, 18975, 33702, 19499, 36652, 18992, 33329, 10940, 7741, 36297, 36091, 9317, 7402, 25965, 10233, 36474, 17659}\n",
      "dict_items([])\n",
      "collecting tokens for  use\n",
      "indices:    {12162, 17444, 1894, 5418, 1646, 1557, 20853, 9783, 14808, 14646, 24218, 29244, 20317}\n",
      "dict_items([(\"Lemma('use.v.01.use')\", 7), (\"Lemma('use.n.01.use')\", 3), (\"Lemma('function.n.02.use')\", 1), (\"Lemma('consumption.n.03.use')\", 1)])\n",
      "collecting tokens for  em\n",
      "indices:    {36352, 6662, 35465, 35595, 6543, 20117, 20118, 36250, 17949, 35503, 36278, 36926, 24388, 19146, 20064, 5480, 33899, 18287, 18806, 35578}\n",
      "dict_items([])\n",
      "collecting tokens for  light\n",
      "indices:    {31754, 29068, 10003, 34324, 2201, 15133, 3232, 30241, 1569, 18723, 3236, 33578, 32170, 15148, 5549, 35249, 18354, 4153, 29890, 27459, 3268, 18771, 217, 36570, 35294, 8802, 24546, 27492, 9192, 33641, 11499, 11371, 15470, 1646, 25465, 7164, 1151}\n",
      "dict_items([(\"Lemma('light.n.01.light')\", 8), (\"Lemma('luminosity.n.01.light')\", 1), (\"Lemma('light.n.03.light')\", 1), (\"Lemma('light.n.02.light')\", 2), (\"Lemma('light.a.04.light')\", 1), (\"Lemma('light.a.01.light')\", 4), (\"Lemma('light.n.08.light')\", 1), (\"Lemma('light.a.05.light')\", 1), (\"Lemma('light.s.09.light')\", 1)])\n",
      "collecting tokens for  company\n",
      "indices:    {21769, 10299, 17926}\n",
      "dict_items([(\"Lemma('caller.n.01.company')\", 1)])\n",
      "collecting tokens for  got\n",
      "indices:    {6656, 1539, 18438, 35856, 19484, 17948, 23075, 16933, 36908, 26670, 29231, 18484, 19522, 18005, 17001, 17003, 10352, 17012, 10870, 17020, 23169, 10883, 33923, 33926, 18571, 18063, 20112, 33426, 10386, 9874, 6302, 9376, 10402, 10405, 22181, 29355, 2221, 9396, 9401, 25274, 36538, 26302, 33471, 33470, 199, 19660, 14550, 30945, 2280, 34025, 35052, 33525, 34039, 18684, 6397, 34046, 12561, 6418, 23317, 19734, 35097, 21281, 35621, 9006, 19759, 18223, 7992, 7487, 22848, 17729, 17221, 34633, 22347, 25936, 33618, 34134, 22872, 19297, 26474, 33659, 10114, 17801, 398, 9112, 411, 11165, 34213, 24489, 19884, 24497, 17842, 36273, 30651, 444, 30661, 35789, 17870, 35286, 5079, 18391, 17371, 34271, 17893, 19945, 19947, 499, 7158, 8183, 30712, 19962, 6141}\n",
      "dict_items([(\"Lemma('pay_back.v.02.get')\", 3), (\"Lemma('get.v.01.get')\", 23), (\"Lemma('get.v.03.get')\", 4), (\"Lemma('have.v.01.have_got')\", 3), (\"Lemma('receive.v.02.get')\", 5), (\"Lemma('contract.v.04.get')\", 1), (\"Lemma('become.v.01.get')\", 10), (\"Lemma('bring.v.04.get')\", 4), (\"Lemma('get.v.14.get')\", 1), (\"Lemma('raise.v.02.get_up')\", 1), (\"Lemma('get_up.v.04.get_up')\", 1), (\"Lemma('have.v.17.get')\", 2), (\"Lemma('grow.v.08.get')\", 1), (\"Lemma('arrive.v.01.get')\", 6)])\n",
      "collecting tokens for  run\n",
      "indices:    {36097, 1926, 21772, 32146, 186, 23098, 21700, 453, 33093, 7112, 457, 12874, 32461, 22990, 25936, 21585, 20181, 3556, 1509, 230, 33767, 19953, 34677, 29176}\n",
      "dict_items([(\"Lemma('run.n.01.run')\", 3), (\"Lemma('run.n.07.run')\", 1), (\"Lemma('test.n.05.run')\", 1), (\"Lemma('run.v.05.run')\", 2), (\"Lemma('function.v.01.run')\", 1), (\"Lemma('operate.v.01.run')\", 3), (\"Lemma('play.v.18.run')\", 2), (\"Lemma('run.v.01.run')\", 2), (\"Lemma('run.v.18.run')\", 1), (\"Lemma('run.v.16.run')\", 1)])\n",
      "collecting tokens for  heavy\n",
      "indices:    {900, 22282, 19221, 19864, 19225, 24220, 23838, 9630, 33695, 15521, 12834, 7840, 31141, 5670, 10538, 2988, 1580, 29108, 8504, 14395, 9799, 27210, 9171, 12631, 19673, 29408, 15207, 7145, 17258, 1646, 15087, 20084, 21626}\n",
      "dict_items([(\"Lemma('heavy.a.01.heavy')\", 13), (\"Lemma('heavy.a.02.heavy')\", 4), (\"Lemma('heavy.s.07.heavy')\", 1), (\"Lemma('heavy.a.03.heavy')\", 1), (\"Lemma('clayey.s.02.heavy')\", 1)])\n",
      "collecting tokens for  line\n",
      "indices:    {36208, 31878}\n",
      "dict_items([])\n",
      "collecting tokens for  need\n",
      "indices:    {18052, 24072, 2571, 25231, 32273, 6035, 29465, 30105, 26908, 15521, 11685, 20268, 1325, 36012, 15663, 1328, 7605, 11702, 15296, 13894, 22728, 12104, 11729, 10451, 19540, 28117, 32088, 27737, 35032, 15704, 7520, 24034, 12134, 20203, 12141, 5489, 11636, 26105}\n",
      "dict_items([(\"Lemma('want.v.02.need')\", 5), (\"Lemma('need.n.01.need')\", 12), (\"Lemma('necessitate.v.01.need')\", 6)])\n",
      "collecting tokens for  box\n",
      "indices:    {24368, 34897, 11110, 21374}\n",
      "dict_items([])\n",
      "collecting tokens for  extra\n",
      "indices:    {263, 24714, 36107, 28816, 274, 20115, 20117, 26901, 29975, 26904, 5789, 286, 15521, 3620, 3110, 10286, 20654, 12080, 27189, 8247, 9784, 23361, 34886, 30169, 986, 30043, 22750, 35808, 608, 21988, 35815, 23528, 29417, 12138, 17390, 30446, 5105, 27633, 29685, 36092, 11774, 34303}\n",
      "dict_items([(\"Lemma('excess.s.01.extra')\", 4)])\n",
      "collecting tokens for  factories\n",
      "indices:    {19491, 23975, 24135, 23438, 21840, 6032, 5426, 25171, 32146, 854, 5431}\n",
      "dict_items([(\"Lemma('factory.n.01.factory')\", 5)])\n",
      "collecting tokens for  center\n",
      "indices:    {18225, 32453, 3911}\n",
      "dict_items([(\"Lemma('center.n.01.center')\", 2)])\n",
      "collecting tokens for  market\n",
      "indices:    {25799, 2728, 31511, 24055, 5275}\n",
      "dict_items([(\"Lemma('market.n.02.market')\", 1), (\"Lemma('market.n.01.market')\", 1)])\n",
      "collecting tokens for  often\n",
      "indices:    {31591, 30890, 10667, 12784, 12051, 3701, 4950, 13305, 2587, 1308, 30495}\n",
      "dict_items([(\"Lemma('frequently.r.01.often')\", 8)])\n",
      "collecting tokens for  city\n",
      "indices:    {24164, 24168, 20307, 20319, 31547, 23935}\n",
      "dict_items([])\n",
      "collecting tokens for  hated\n",
      "indices:    {19203, 19204, 7943, 19209, 35854, 35873, 8867, 36142, 13874, 36801, 17991, 6729, 36436, 8921, 8026, 15837, 28392, 7145, 17258, 15857, 36981}\n",
      "dict_items([(\"Lemma('despised.s.01.hated')\", 1), (\"Lemma('hate.v.01.hate')\", 19)])\n",
      "collecting tokens for  goddamn\n",
      "indices:    {6738, 8651}\n",
      "dict_items([(\"Lemma('damn.s.01.goddamn')\", 1)])\n",
      "collecting tokens for  army\n",
      "indices:    {23666, 23981}\n",
      "dict_items([])\n",
      "collecting tokens for  anyhow\n",
      "indices:    {34466, 27529, 14091, 11831, 4858, 10140}\n",
      "dict_items([(\"Lemma('anyhow.r.01.anyhow')\", 4)])\n",
      "collecting tokens for  60\n",
      "indices:    {22148, 29063, 21896, 3207, 21899, 2317, 20366, 29965, 30743, 30872, 27036, 29092, 680, 13353, 23849, 21931, 21930, 24880, 12720, 18870, 25784, 12730, 15291, 25531, 30397, 2750, 21950, 11578, 21949, 14914, 14788, 23877, 30404, 25415, 15049, 21323, 21327, 848, 11473, 5591, 2904, 5592, 23000, 32348, 23005, 23009, 2275, 27110, 20839, 3304, 26727, 23018, 23019, 20462, 5495, 28539, 27004}\n",
      "dict_items([(\"Lemma('sixty.s.01.60')\", 20)])\n",
      "collecting tokens for  mm.\n",
      "indices:    {3265, 2408, 4073, 26388, 25784, 11385, 4061, 3262, 3263}\n",
      "dict_items([(\"Lemma('millimeter.n.01.mm')\", 7)])\n",
      "collecting tokens for  57\n",
      "indices:    {33090, 33093, 33062, 27178, 23184, 25784, 23577, 16189}\n",
      "dict_items([])\n",
      "collecting tokens for  rifle\n",
      "indices:    {29056, 29057, 18309, 34950, 10375, 29067, 12689, 35351, 17570, 17571, 17572, 17575, 29096, 35626, 18219, 35378, 25785, 5054, 29119, 5837, 5847, 21209, 35299, 11876, 17260, 17134, 17136, 35568, 11892, 6904, 29050, 29053, 17534}\n",
      "dict_items([(\"Lemma('rifle.n.01.rifle')\", 16)])\n",
      "collecting tokens for  owned\n",
      "indices:    {15496, 21644, 36368, 28953, 23577, 15259, 12575, 15267, 21550, 10543, 31412, 25784, 12095, 12097, 12102, 2759, 17101, 5072, 25059, 15845, 15846, 1895, 15218, 626, 508}\n",
      "dict_items([(\"Lemma('own.v.01.own')\", 22), (\"Lemma('own.s.01.own')\", 1), (\"Lemma('owned.a.01.owned')\", 1)])\n",
      "collecting tokens for  along\n",
      "indices:    {12992, 17923, 11110, 34441, 14507, 35411, 25238, 5111}\n",
      "dict_items([(\"Lemma('along.r.04.along')\", 1)])\n",
      "collecting tokens for  crouch\n",
      "indices:    {18409, 7133}\n",
      "dict_items([(\"Lemma('person.n.01.person')\", 1), (\"Lemma('crouch.v.01.crouch')\", 1)])\n",
      "collecting tokens for  surrounding\n",
      "indices:    {30440, 19248, 2901, 23712}\n",
      "dict_items([(\"Lemma('encompassing.s.02.surrounding')\", 2)])\n",
      "collecting tokens for  distance\n",
      "indices:    {2561, 18436, 3085, 8718, 532, 11285, 33832, 28721, 28723, 5172, 11326, 36932, 19541, 14443, 34427, 9859, 5254, 28807, 25224, 29344, 8353, 29875, 3253, 14016, 36035, 32965, 32966, 3271, 5833, 29395, 5846, 5851, 3300, 3301, 29929, 3309, 3310, 10488, 1789, 28934, 28946, 3347, 10514, 20247, 26401, 33572, 36646, 33582, 16179, 18228, 16180, 12087, 35640, 30543, 10576, 9554, 5468, 30052, 3431, 3433, 12145, 35704, 3451, 18817, 2445, 2963, 12196, 35247, 23989, 5047, 24506, 10183, 9675, 12248, 2016, 33770, 3060, 3062, 3064, 10745, 3067}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('distance.n.01.distance')\", 26), (\"Lemma('distance.n.03.distance')\", 4), (\"Lemma('distance.n.02.distance')\", 3), (\"Lemma('distance.n.04.distance')\", 3)])\n",
      "collecting tokens for  band\n",
      "indices:    {26403, 36551, 26955, 25774, 22511, 2958, 14546, 21555, 35539, 2427, 25362, 2424, 6745, 26427}\n",
      "dict_items([(\"Lemma('set.n.05.band')\", 3), (\"Lemma('band.n.06.band')\", 1), (\"Lemma('band.n.02.band')\", 1)])\n",
      "collecting tokens for  advance\n",
      "indices:    {35971, 20236, 17549, 8722, 14739, 21912, 29727, 32546, 20516, 32550, 21295, 25779, 24631, 29240, 13626, 25789, 25790, 22720, 31299, 30793, 28748, 2128, 30807, 21976, 22247, 25968, 25200, 25970}\n",
      "dict_items([(\"Lemma('promote.v.01.advance')\", 2), (\"Lemma('boost.v.04.advance')\", 3), (\"Lemma('gain.v.05.advance')\", 2), (\"Lemma('advance.v.05.advance')\", 1)])\n",
      "collecting tokens for  retreat\n",
      "indices:    {26024, 12489, 12745, 5071, 36027, 29980, 29821, 5851}\n",
      "dict_items([(\"Lemma('retreat.n.01.retreat')\", 2), (\"Lemma('withdraw.v.01.retreat')\", 2)])\n",
      "collecting tokens for  watched\n",
      "indices:    {13568, 19459, 28421, 19333, 18569, 8586, 34953, 21388, 20108, 17806, 21774, 7947, 9484, 5649, 34827, 10390, 35607, 13591, 8476, 6941, 21277, 7838, 6685, 6177, 20126, 24228, 34429, 16933, 14631, 5290, 18092, 23472, 18353, 37168, 33587, 9655, 14904, 10425, 5697, 19265, 22211, 17734, 36422, 7113, 7116, 7165, 33619, 9428, 30425, 10458, 5851, 10207, 34156, 8943, 36720, 7159, 18808, 8572, 36989}\n",
      "dict_items([(\"Lemma('watch.v.02.watch')\", 17), (\"Lemma('watch.v.03.watch')\", 8), (\"Lemma('watch.v.01.watch')\", 26), (\"Lemma('watch.v.04.watch')\", 3)])\n",
      "collecting tokens for  brothers\n",
      "indices:    {12676, 16490, 21565, 19518, 24703}\n",
      "dict_items([(\"Lemma('brother.n.01.brother')\", 2)])\n",
      "collecting tokens for  later\n",
      "indices:    {508, 23973}\n",
      "dict_items([(\"Lemma('subsequently.r.01.later')\", 1)])\n",
      "collecting tokens for  joined\n",
      "indices:    {2437, 3079, 8202, 19595, 33932, 31633, 19346, 32660, 27672, 21533, 19614, 159, 19616, 11432, 20909, 12462, 430, 35387, 14524, 11456, 21697, 23748, 7372, 29388, 35276, 332, 26829, 14545, 29647, 36051, 20441, 5086, 18019, 12516, 227, 33510, 486, 9701, 22891, 35314, 31609, 1274, 21631}\n",
      "dict_items([(\"Lemma('join.v.01.join')\", 26), (\"Lemma('join.v.04.join')\", 5), (\"Lemma('join.v.02.join')\", 3), (\"Lemma('join.v.03.join')\", 2), (\"Lemma('joined.s.01.joined')\", 1)])\n",
      "collecting tokens for  instruction\n",
      "indices:    {28707, 19333, 29894, 11431, 11432, 27999, 32714, 747, 11280, 24468, 11350, 27607, 9336, 32698, 21883, 34684, 15005, 767}\n",
      "dict_items([(\"Lemma('education.n.01.instruction')\", 5), (\"Lemma('teaching.n.01.instruction')\", 2), (\"Lemma('direction.n.06.instruction')\", 2)])\n",
      "collecting tokens for  added\n",
      "indices:    {14859, 33807, 21529, 3098, 25115, 26652, 15909, 15912, 42, 24111, 25152, 34890, 23119, 15953, 29781, 14422, 8281, 1625, 29795, 1642, 9841, 4212, 27771, 24727, 31898, 24220, 12445, 21664, 27298, 37027, 18087, 12465, 16050, 3255, 26295, 699, 9918, 19647, 8897, 21704, 200, 3273, 10962, 20692, 3285, 16085, 218, 23773, 3295, 34015, 28905, 22251, 237, 25838, 755, 21240, 30461, 1279, 28932, 28935, 15114, 16658, 15124, 17692, 22301, 25391, 11576, 9532, 21308, 31041, 36676, 21321, 25418, 23382, 20824, 17240, 19807, 3936, 24420, 11110, 31594, 16235, 16237, 369, 5492, 372, 20343, 23932, 29564, 20351, 18817, 22403, 20359, 5514, 14226, 16276, 22943, 31647, 5029, 31655, 20394, 22956, 24495, 23990, 7608, 31678, 3520, 30150, 28103, 33223, 5576, 30155, 29132, 20433, 32722, 20434, 17365, 8154, 35809, 11234, 20965, 35304, 22513}\n",
      "dict_items([(\"Lemma('add.v.02.add')\", 26), (\"Lemma('add.v.01.add')\", 26), (\"Lemma('lend.v.01.add')\", 2), (\"Lemma('add.v.04.add')\", 1)])\n",
      "collecting tokens for  bible\n",
      "indices:    {28039}\n",
      "dict_items([])\n",
      "collecting tokens for  reading\n",
      "indices:    {23557, 7302, 31115, 28300, 31120, 31121, 15892, 16022, 31130, 19616, 31139, 24740, 31141, 24742, 15657, 14634, 15915, 14392, 15675, 15680, 9408, 16594, 14942, 14302, 15456, 9186, 15723, 26097, 14712, 763}\n",
      "dict_items([(\"Lemma('reading.n.01.reading')\", 8), (\"Lemma('read.v.01.read')\", 11), (\"Lemma('read.v.02.read')\", 1)])\n",
      "collecting tokens for  german\n",
      "indices:    {25176}\n",
      "dict_items([])\n",
      "collecting tokens for  curriculum\n",
      "indices:    {25954, 33126, 11432, 16264, 2090, 2057, 2041, 16286}\n",
      "dict_items([(\"Lemma('course_of_study.n.01.curriculum')\", 6)])\n",
      "collecting tokens for  poor\n",
      "indices:    {19717, 33032, 12565, 149, 4759, 1836, 19759, 36144, 24761, 6586, 24763, 13628, 32317, 20416, 5955, 30404, 25804, 36306, 21977, 23385, 5212, 8165, 16490, 11252, 26363, 33662}\n",
      "dict_items([(\"Lemma('poor.a.02.poor')\", 4), (\"Lemma('hapless.s.01.poor')\", 3), (\"Lemma('poor.a.03.poor')\", 1)])\n",
      "collecting tokens for  de\n",
      "indices:    {21445, 4774, 33061, 27975, 27079, 27141, 11083, 9355, 28398, 1521, 11189, 6999, 31674, 13468, 1565}\n",
      "dict_items([])\n",
      "collecting tokens for  getting\n",
      "indices:    {22212}\n",
      "dict_items([(\"Lemma('arrive.v.01.get')\", 1)])\n",
      "collecting tokens for  necessary\n",
      "indices:    {2050, 14853, 4614, 25096, 4617, 14859, 21516, 14860, 13328, 16402, 21523, 27157, 9767, 9768, 32818, 14898, 29748, 27192, 30777, 36411, 31804, 7230, 27717, 23109, 4682, 15949, 22606, 15450, 27231, 15458, 32356, 32873, 2154, 32877, 32373, 9349, 26759, 14986, 32913, 20626, 22679, 26267, 15004, 23709, 22685, 15003, 4776, 1709, 25264, 32957, 14015, 32960, 15552, 22728, 26826, 14042, 23259, 28894, 22751, 1767, 29417, 29935, 15088, 23281, 5362, 26355, 15606, 15607, 28926, 32513, 16130, 28931, 22785, 4362, 19743, 1311, 15141, 15142, 20776, 15144, 4908, 25901, 4913, 11259, 15688, 15177, 32587, 15181, 30545, 20821, 3417, 14685, 25446, 32615, 22887, 25449, 35689, 34676, 20853, 25464, 4994, 5509, 12169, 15242, 14733, 3982, 11668, 14741, 14748, 25506, 12196, 4007, 14761, 30636, 35759, 15793, 29106, 2994, 19381, 33205, 4022, 32184, 32185, 32186, 4028, 19901, 31678, 19904, 27598, 20431, 33233, 27095, 31193, 12766, 14815, 5093, 1510, 4585, 15343, 25073, 19954, 14839, 11771, 28671}\n",
      "dict_items([(\"Lemma('necessary.a.01.necessary')\", 26), (\"Lemma('necessary.s.02.necessary')\", 1)])\n",
      "collecting tokens for  andrei\n",
      "indices:    {7912}\n",
      "dict_items([(\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  directors\n",
      "indices:    {26563, 20681, 24618, 234, 5196, 20812, 15277, 15278, 21744, 14221, 22101, 13306, 2780}\n",
      "dict_items([(\"Lemma('director.n.01.director')\", 2), (\"Lemma('director.n.02.director')\", 2)])\n",
      "collecting tokens for  manchester\n",
      "indices:    {5140}\n",
      "dict_items([(\"Lemma('manchester.n.01.Manchester')\", 1)])\n",
      "collecting tokens for  power\n",
      "indices:    {28675, 24588, 31245, 31244, 30735, 25128, 16432, 4657, 5200, 26197, 24666, 20059, 24156, 24168, 10857, 12921, 27259, 34428, 12929, 12931, 12934, 20112, 20627, 20120, 32925, 28318, 7839, 28835, 3236, 12965, 12978, 27831, 12994, 22723, 29902, 23774, 31969, 12005, 1254, 1257, 1266, 25338, 1280, 27912, 22793, 27919, 1809, 3345, 28442, 27936, 25888, 27938, 21287, 14634, 13635, 13637, 13128, 15195, 2918, 12134, 22894, 28527, 34677, 12673, 32130, 25475, 32146, 28079, 28081, 6581, 15286, 32183, 31159, 28086, 21430, 28091, 12236, 1485, 24014, 12241, 28117, 28146, 28151, 24057}\n",
      "dict_items([(\"Lemma('power.n.01.power')\", 21), (\"Lemma('office.n.04.power')\", 1), (\"Lemma('power.n.05.power')\", 3), (\"Lemma('power.n.02.power')\", 2), (\"Lemma('exponent.n.03.power')\", 2)])\n",
      "collecting tokens for  john\n",
      "indices:    {20312}\n",
      "dict_items([])\n",
      "collecting tokens for  m.\n",
      "indices:    {20771}\n",
      "dict_items([])\n",
      "collecting tokens for  l.\n",
      "indices:    {15003}\n",
      "dict_items([])\n",
      "collecting tokens for  william\n",
      "indices:    {18215}\n",
      "dict_items([])\n",
      "collecting tokens for  f.\n",
      "indices:    {25036}\n",
      "dict_items([])\n",
      "collecting tokens for  george\n",
      "indices:    {1179}\n",
      "dict_items([])\n",
      "collecting tokens for  smith\n",
      "indices:    {22252}\n",
      "dict_items([])\n",
      "collecting tokens for  useless\n",
      "indices:    {5751, 14600, 11696, 19604, 23125, 12405, 20503, 20282, 19354}\n",
      "dict_items([(\"Lemma('useless.a.01.useless')\", 4)])\n",
      "collecting tokens for  anything\n",
      "indices:    {17793, 34821, 16775, 13435, 8334, 36114, 1558, 411, 20127, 33571, 19370, 32052, 31669, 33974, 17847, 35773, 16830, 31679, 9921, 23747, 19912, 22344, 19915, 9292, 19021, 35025, 34386, 20052, 17502, 36319, 2020, 6124, 6898, 1267, 27124, 30709, 4858, 12027}\n",
      "dict_items([])\n",
      "collecting tokens for  racing\n",
      "indices:    {27095, 23590, 27080, 28010, 35406, 27087, 27088, 28562, 27091, 23127, 19225, 30268, 27070}\n",
      "dict_items([(\"Lemma('rush.v.01.race')\", 3)])\n",
      "collecting tokens for  cars\n",
      "indices:    {27946, 32277, 20237}\n",
      "dict_items([])\n",
      "collecting tokens for  goal\n",
      "indices:    {3463, 4749, 32917, 32918, 20376, 21656, 35999, 21920, 32166, 32936, 298, 24107, 12970, 16817, 14776, 32956, 25026, 14149, 4809, 15820, 11724, 23805, 219, 19548, 25820, 14174, 7907, 4581, 20838, 23527, 12264, 14827, 2028, 23533, 494, 29296, 32881, 14832, 5491, 12922, 22139, 32125, 4606}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('goal.n.01.goal')\", 22)])\n",
      "collecting tokens for  psychological\n",
      "indices:    {24206, 13217, 30241, 34595, 4275, 4279, 30393, 30395, 30787, 2631, 25544, 27212, 27727, 2515, 27227, 25949, 25956, 27876, 25959, 2030, 4591, 10238}\n",
      "dict_items([(\"Lemma('psychological.s.01.psychological')\", 6), (\"Lemma('psychological.a.02.psychological')\", 2)])\n",
      "collecting tokens for  barriers\n",
      "indices:    {27745, 22855, 30792, 27753, 24426, 3854, 496, 3410, 36983, 23704, 13273, 3803, 10238, 7839}\n",
      "dict_items([(\"Lemma('barrier.n.03.barrier')\", 2), (\"Lemma('barrier.n.01.barrier')\", 2), (\"Lemma('barrier.n.02.barrier')\", 3)])\n",
      "collecting tokens for  prevented\n",
      "indices:    {2370, 29026, 35715, 4743, 5549, 17646, 1263, 31003, 4625, 17582, 18354, 28724, 5428, 5524, 2901, 33243, 10238}\n",
      "dict_items([(\"Lemma('prevent.v.02.prevent')\", 11), (\"Lemma('prevent.v.01.prevent')\", 6)])\n",
      "collecting tokens for  hal\n",
      "indices:    {10269}\n",
      "dict_items([])\n",
      "collecting tokens for  thus\n",
      "indices:    {15906}\n",
      "dict_items([(\"Lemma('therefore.r.01.thus')\", 1)])\n",
      "collecting tokens for  prokofieff\n",
      "indices:    {11188}\n",
      "dict_items([(\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  union\n",
      "indices:    {12541}\n",
      "dict_items([(\"Lemma('union.n.02.Union')\", 1)])\n",
      "collecting tokens for  soviet\n",
      "indices:    {12992}\n",
      "dict_items([(\"Lemma('soviet.a.01.Soviet')\", 1)])\n",
      "collecting tokens for  socialist\n",
      "indices:    {20356}\n",
      "dict_items([])\n",
      "collecting tokens for  produced\n",
      "indices:    {34944, 0, 3459, 3589, 4235, 15374, 3471, 14356, 4245, 23962, 15899, 4250, 2459, 2462, 27167, 15519, 4125, 14634, 3628, 24109, 14767, 1202, 14771, 11062, 32568, 14777, 22596, 12357, 11462, 22599, 14536, 25415, 25418, 26059, 32720, 14416, 1364, 22998, 32855, 3545, 14426, 27740, 12510, 3295, 25695, 2789, 2661, 26090, 3438, 2416, 2417, 22514, 16369, 14321, 2549, 8054, 28661, 3702, 29305, 22650, 11261}\n",
      "dict_items([(\"Lemma('produce.v.02.produce')\", 16), (\"Lemma('produce.v.01.produce')\", 26), (\"Lemma('produce.v.04.produce')\", 4), (\"Lemma('produce.v.06.produce')\", 6), (\"Lemma('produce.v.03.produce')\", 8)])\n",
      "collecting tokens for  twentieth\n",
      "indices:    {11861, 31838, 16439}\n",
      "dict_items([(\"Lemma('twentieth.s.01.twentieth')\", 2)])\n",
      "collecting tokens for  century\n",
      "indices:    {27521, 14596, 11189}\n",
      "dict_items([(\"Lemma('century.n.01.century')\", 2)])\n",
      "collecting tokens for  l\n",
      "indices:    {3976, 32780, 5550, 32815, 5490, 5558}\n",
      "dict_items([(\"Lemma('liter.n.01.l')\", 3)])\n",
      "collecting tokens for  meets\n",
      "indices:    {22659, 32771, 32781, 32783, 32785, 26142, 4511, 32804, 32805, 26662, 32806, 32816, 32821, 28360, 32841, 32843, 24276, 14437, 26345}\n",
      "dict_items([(\"Lemma('converge.v.01.meet')\", 11), (\"Lemma('meet.v.10.meet')\", 1), (\"Lemma('meet.v.02.meet')\", 2), (\"Lemma('meet.v.05.meet')\", 1), (\"Lemma('touch.v.05.meet')\", 1), (\"Lemma('suffer.v.10.meet')\", 1)])\n",
      "collecting tokens for  q\n",
      "indices:    {4524}\n",
      "dict_items([])\n",
      "collecting tokens for  points\n",
      "indices:    {32771, 32775, 32776, 32781, 32783, 32785, 32282, 32796, 30238, 32801, 32802, 32803, 32804, 25125, 32805, 32815, 25648, 27696, 32826, 14397, 14909, 28735, 31294, 28737, 32834, 28739, 28738, 32841, 29770, 32842, 32843, 31824, 5206, 26198, 4706, 4715, 31858, 2170, 20604, 2685, 31358, 2175, 2690, 25730, 27284, 23196, 23715, 14005, 14006, 22198, 14014, 14018, 14020, 25299, 26333, 26856, 16106, 12017, 14077, 16126, 23813, 263, 20241, 274, 18206, 286, 25388, 4397, 5424, 24882, 3895, 828, 6976, 36680, 26969, 20827, 23916, 15730, 27009, 4487, 4491, 29068, 4493, 4497, 4500, 4501, 4502, 4513, 14763, 4531, 4532, 4533, 4534, 10679, 439, 4539, 7612, 4544, 4546, 4548, 28613, 28614, 4554, 4561, 4562, 4566, 4569, 13274, 12773, 12266, 26616, 26107, 22013}\n",
      "dict_items([(\"Lemma('charge.v.17.point')\", 3), (\"Lemma('point.n.02.point')\", 10), (\"Lemma('detail.n.01.point')\", 5), (\"Lemma('point.n.01.point')\", 22), (\"Lemma('point.n.10.point')\", 1), (\"Lemma('orient.v.01.point')\", 1), (\"Lemma('indicate.v.02.point')\", 4), (\"Lemma('point.n.14.point')\", 1), (\"Lemma('point.n.07.point')\", 1)])\n",
      "collecting tokens for  passes\n",
      "indices:    {22272, 32775, 24968, 11807, 29105, 13876, 28745, 32843, 28748, 342, 344, 858, 1499, 14816, 354, 356, 30577, 25592, 23547, 30077}\n",
      "dict_items([(\"Lemma('elapse.v.01.pass')\", 2), (\"Lemma('travel_by.v.01.pass')\", 3), (\"Lemma('pass.v.05.pass')\", 1), (\"Lemma('run.v.03.pass')\", 3), (\"Lemma('base_on_balls.n.01.pass')\", 3), (\"Lemma('pass.v.01.pass')\", 1), (\"Lemma('pass.n.03.pass')\", 1), (\"Lemma('pass.n.05.pass')\", 1)])\n",
      "collecting tokens for  unique\n",
      "indices:    {4356, 15877, 3082, 29329, 4498, 5395, 32787, 21524, 32790, 16281, 32794, 1440, 30753, 1443, 1444, 1060, 3238, 30888, 1451, 1452, 10031, 34747, 7868, 25419, 3404, 15820, 33358, 13647, 15822, 29266, 2531, 26087, 3455, 31349, 29822, 28543}\n",
      "dict_items([(\"Lemma('alone.s.04.unique')\", 9), (\"Lemma('unique.s.02.unique')\", 2)])\n",
      "collecting tokens for  generator\n",
      "indices:    {32800, 32802, 32775, 32776, 32843, 34445, 34451, 2197, 11386, 32795, 34428, 2878}\n",
      "dict_items([(\"Lemma('generator.n.02.generator')\", 1), (\"Lemma('generator.n.01.generator')\", 1)])\n",
      "collecting tokens for  regulus\n",
      "indices:    {15513, 32838}\n",
      "dict_items([])\n",
      "collecting tokens for  whose\n",
      "indices:    {11266, 32775, 29191, 526, 22543, 14863, 32787, 24596, 29206, 31769, 25629, 29216, 34341, 12837, 32809, 23599, 1075, 22071, 12348, 13894, 23111, 32846, 23120, 13906, 14419, 20472, 25180, 14430, 5220, 26213, 1126, 26215, 12906, 5227, 2669, 14450, 36980, 14452, 32374, 1143, 26746, 10880, 9345, 1154, 17549, 1173, 13980, 21149, 21150, 32421, 11430, 23726, 29362, 22707, 30902, 12986, 4797, 14015, 7359, 37055, 7360, 15044, 21704, 1740, 5324, 14544, 27860, 26325, 1754, 27362, 31972, 12006, 10986, 29930, 25843, 25332, 28413, 13567, 12545, 13572, 13063, 32013, 22798, 7437, 32537, 36122, 5407, 1316, 11046, 15655, 12583, 1325, 20786, 25908, 6966, 23864, 14650, 22853, 13638, 19786, 10571, 12619, 12622, 26450, 28665, 14688, 12641, 16227, 16228, 23395, 2921, 12651, 3948, 21359, 9584, 2417, 33142, 28025, 27003, 15229, 11145, 36238, 14230, 32668, 31137, 3491, 26022, 22951, 11180, 14253, 18870, 9145, 26042, 9147, 9148, 25540, 4550, 10695, 18887, 972, 23500, 11214, 4559, 23504, 12245, 28631, 22489, 13786, 14809, 1500, 22492, 4576, 13280, 27104, 36320, 15845, 488, 10219, 26096, 24051, 1527, 28152, 4601}\n",
      "dict_items([])\n",
      "collecting tokens for  secants\n",
      "indices:    {32832, 32833, 32835, 32775, 32840, 32841, 32808, 32783, 32784, 32819, 32791, 32824, 32795, 32797, 32830}\n",
      "dict_items([])\n",
      "collecting tokens for  \\\n",
      "indices:    {32774, 32775, 32776, 32781, 32782, 32783, 32785, 32800, 32801, 32802, 32803, 32810, 32812, 32813, 32817, 32818, 32819, 32820, 32821, 32822, 32824, 32826, 32828, 32829, 32831, 32832, 32834, 32835, 32836, 32837, 32839, 32840, 32841, 32843}\n",
      "dict_items([])\n",
      "collecting tokens for  g\n",
      "indices:    {3541, 3098, 12885}\n",
      "dict_items([(\"Lemma('gram.n.01.g')\", 2)])\n",
      "collecting tokens for  wrong\n",
      "indices:    {25600, 19970, 17934, 26126, 17950, 27682, 16931, 15404, 15405, 15407, 34352, 30257, 15412, 17460, 30264, 568, 26687, 17985, 10311, 15441, 24147, 26196, 13909, 36438, 2654, 26208, 14433, 15971, 36471, 7295, 34441, 36494, 25750, 35481, 34457, 36515, 34471, 30897, 35512, 16576, 33984, 16579, 24273, 22740, 22232, 7392, 28404, 25336, 25852, 14589, 27904, 14593, 32020, 32021, 4889, 31003, 17193, 31039, 12629, 13146, 8539, 34662, 24435, 25461, 894, 4994, 10633, 28050, 8594, 15770, 15772, 18349, 20401, 9649, 12211, 21938, 36796, 17340, 25029, 24007, 35792, 15834, 19936, 29668, 29669, 33263, 19963, 10751}\n",
      "dict_items([(\"Lemma('incorrect.a.01.wrong')\", 13), (\"Lemma('wrong.a.02.wrong')\", 9), (\"Lemma('amiss.s.01.wrong')\", 3), (\"Lemma('improper.s.03.wrong')\", 6), (\"Lemma('wrong.n.01.wrong')\", 2), (\"Lemma('wrong.n.02.wrong')\", 1), (\"Lemma('incorrectly.r.02.wrong')\", 1)])\n",
      "collecting tokens for  meaning\n",
      "indices:    {15852, 24742, 16182, 35831}\n",
      "dict_items([(\"Lemma('meaning.n.01.meaning')\", 2), (\"Lemma('mean.v.01.mean')\", 1)])\n",
      "collecting tokens for  words\n",
      "indices:    {30210, 31236, 5136, 13332, 7188, 5656, 30234, 32799, 5157, 30253, 27699, 5683, 17476, 12875, 32853, 2144, 10850, 5230, 13428, 629, 35959, 35963, 9359, 14483, 31388, 16045, 8884, 19647, 24773, 1230, 24275, 22744, 32985, 14570, 22770, 26867, 3829, 27388, 36096, 32005, 9997, 31507, 4372, 24855, 19746, 14634, 15664, 22849, 27459, 27461, 33101, 13655, 35679, 16738, 27493, 24938, 19818, 15723, 28025, 27518, 13695, 895, 21384, 23950, 36760, 30106, 16807, 31150, 1465, 32198, 26060, 15827, 31704, 19417, 8668, 7654, 28137, 11241, 27117, 15857, 25589, 26104}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('discussion.n.02.word')\", 1), (\"Lemma('word.n.01.word')\", 15), (\"Lemma('word.n.02.word')\", 3), (\"Lemma('words.n.01.words')\", 13), (\"Lemma('lyric.n.01.words')\", 3), (\"Lemma('words.n.03.words')\", 2)])\n",
      "collecting tokens for  instance\n",
      "indices:    {23942, 15878, 14344, 4233, 22032, 2705, 30228, 20886, 25367, 26008, 4250, 26271, 23587, 2341, 33709, 3630, 2864, 30003, 15669, 34361, 24891, 19516, 31168, 2369, 3777, 12994, 25921, 3659, 13643, 2635, 2126, 26961, 27730, 14293, 34390, 19547, 24539, 2267, 7519, 2146, 28006, 1895, 31976, 2539, 29291, 16877, 11117, 4464, 13682, 22259, 23922, 25461, 3448, 28665, 1150}\n",
      "dict_items([(\"Lemma('case.n.01.instance')\", 7), (\"Lemma('example.n.01.instance')\", 2)])\n",
      "collecting tokens for  altered\n",
      "indices:    {24194, 4228, 11503, 16190, 2129, 27569, 21267, 30228, 1713, 31190, 10519, 4249, 36122, 4254}\n",
      "dict_items([(\"Lemma('change.v.03.alter')\", 2), (\"Lemma('change.v.01.alter')\", 12)])\n",
      "collecting tokens for  quality\n",
      "indices:    {9345, 14721, 1799, 1929, 2058, 11661, 26515, 14617, 31902, 11681, 30497, 14634, 31410, 3123, 7609, 33088, 1859, 1863, 11849, 25802, 11726, 10575, 13648, 13524, 25446, 15468, 23920, 5491, 26485, 12155, 26111}\n",
      "dict_items([(\"Lemma('timbre.n.01.quality')\", 2), (\"Lemma('quality.n.01.quality')\", 7), (\"Lemma('quality.n.02.quality')\", 8), (\"Lemma('quality.n.03.quality')\", 2)])\n",
      "collecting tokens for  communication\n",
      "indices:    {32130, 30213, 33164, 781, 32909, 25357, 26906, 2335, 4775, 30254, 30255, 14007, 15417, 14016, 27714, 27715, 27718, 27719, 22729, 32972, 32978, 22739, 27733, 15832, 26458, 14043, 27739, 11485, 12767, 14177, 14049, 12264, 26094, 24560, 33520, 1012, 7540, 31099}\n",
      "dict_items([(\"Lemma('communication.n.01.communication')\", 9), (\"Lemma('communication.n.02.communication')\", 3)])\n",
      "collecting tokens for  third\n",
      "indices:    {21882, 498, 3862}\n",
      "dict_items([(\"Lemma('third.r.01.third')\", 1), (\"Lemma('third.s.01.third')\", 1)])\n",
      "collecting tokens for  examples\n",
      "indices:    {12674, 14211, 16132, 15524, 3908, 4421, 31530, 5035, 4394, 4397, 25235, 25683, 11352, 14719}\n",
      "dict_items([(\"Lemma('example.n.01.example')\", 10), (\"Lemma('model.n.07.example')\", 1)])\n",
      "collecting tokens for  definitely\n",
      "indices:    {320, 33913, 32450, 1094, 583, 27593, 1401, 14476, 2800, 30228, 25365, 25557, 600, 26073, 27258, 25948, 1086}\n",
      "dict_items([(\"Lemma('decidedly.r.01.definitely')\", 8)])\n",
      "collecting tokens for  fire\n",
      "indices:    {20312}\n",
      "dict_items([])\n",
      "collecting tokens for  directed\n",
      "indices:    {1011, 1179, 14887}\n",
      "dict_items([(\"Lemma('direct.v.01.direct')\", 1), (\"Lemma('direct.v.03.direct')\", 2)])\n",
      "collecting tokens for  dallas\n",
      "indices:    {142}\n",
      "dict_items([(\"Lemma('dallas.n.01.Dallas')\", 1)])\n",
      "collecting tokens for  sen.\n",
      "indices:    {106}\n",
      "dict_items([])\n",
      "collecting tokens for  mel\n",
      "indices:    {12853}\n",
      "dict_items([])\n",
      "collecting tokens for  chandler\n",
      "indices:    {22252}\n",
      "dict_items([])\n",
      "collecting tokens for  spirit\n",
      "indices:    {1283, 12808, 8334, 26787, 22693, 1191, 7080, 28202, 22698, 5035, 25139, 24761, 20291, 1226, 12620, 12879, 1236, 2644, 1242, 4980, 26361, 31101}\n",
      "dict_items([(\"Lemma('spirit.n.01.spirit')\", 6), (\"Lemma('liveliness.n.02.spirit')\", 1), (\"Lemma('intent.n.02.spirit')\", 1), (\"Lemma('spirit.n.02.spirit')\", 3), (\"Lemma('spirit.n.03.spirit')\", 1)])\n",
      "collecting tokens for  garryowen\n",
      "indices:    {12890}\n",
      "dict_items([(\"Lemma('location.n.01.location')\", 1)])\n",
      "collecting tokens for  ca\n",
      "indices:    {17608}\n",
      "dict_items([])\n",
      "collecting tokens for  another\n",
      "indices:    {18817, 6023, 8703, 16396, 31920, 339, 14772, 29205, 888, 27999}\n",
      "dict_items([])\n",
      "collecting tokens for  pair\n",
      "indices:    {26242, 390, 9480, 24585, 3602, 27538, 35099, 23329, 21542, 17072, 20914, 14006, 30776, 33978, 29754, 189, 30271, 9151, 7489, 706, 29888, 199, 200, 7758, 335, 14428, 30557, 19678, 4447, 19680, 4450, 484, 36965, 5621, 33526, 11127, 8057, 7805, 9342}\n",
      "dict_items([(\"Lemma('pair.n.01.pair')\", 12), (\"Lemma('pair.n.03.pair')\", 5), (\"Lemma('couple.n.04.pair')\", 7)])\n",
      "collecting tokens for  title\n",
      "indices:    {14892, 5207, 470, 27263}\n",
      "dict_items([(\"Lemma('title.n.01.title')\", 1), (\"Lemma('championship.n.01.title')\", 1)])\n",
      "collecting tokens for  8\n",
      "indices:    {13841, 21522, 14871, 6680, 14873, 29722, 27163, 27175, 42, 11319, 21563, 29757, 586, 4171, 21583, 28241, 28754, 597, 14942, 28260, 28777, 11376, 21105, 626, 28785, 21106, 21622, 11399, 28810, 28812, 28821, 28826, 28828, 28830, 11427, 28836, 29862, 28844, 29869, 3763, 2741, 3768, 15034, 3770, 15035, 15039, 21700, 4305, 28882, 11483, 222, 32481, 28913, 15091, 15092, 27390, 264, 27407, 2840, 2841, 27426, 4390, 23339, 22828, 16183, 29498, 16189, 22334, 24896, 16196, 20806, 22345, 20813, 29517, 29522, 12115, 13149, 23396, 16236, 12142, 5490, 3957, 21366, 27511, 30076, 381, 1405, 27011, 22405, 16267, 20882, 21912, 928, 28580, 25003, 940, 21931, 942, 22448, 27568, 21937, 22973, 4029, 961, 4033, 17345, 22988, 3535, 3544, 20976, 21489, 29690}\n",
      "dict_items([(\"Lemma('eight.s.01.8')\", 26), (\"Lemma('eighth.s.01.eighth')\", 1), (\"Lemma('eight.n.01.8')\", 3)])\n",
      "collecting tokens for  national\n",
      "indices:    {29306, 4604}\n",
      "dict_items([(\"Lemma('national.a.02.national')\", 1)])\n",
      "collecting tokens for  defense\n",
      "indices:    {3402, 15470, 20785, 15511, 27801, 3482, 15485, 20319}\n",
      "dict_items([(\"Lemma('defense.n.02.defense')\", 1), (\"Lemma('defense.n.01.defense')\", 1)])\n",
      "collecting tokens for  1958\n",
      "indices:    {5128, 12311, 4125, 20527, 21551, 562, 60, 32337, 22098, 4195, 32360, 619, 15481, 4751, 23184, 4756, 4757, 4758, 4761, 4763, 4771, 4804, 32479, 21225, 2794, 3825, 2814, 3331, 3334, 20743, 3338, 25867, 3344, 1808, 2846, 2850, 2853, 3366, 3371, 3377, 3381, 25418, 21336, 21337, 3933, 21343, 3942, 31594, 16236, 26480, 23414, 16249, 31100, 14720, 21894, 21898, 16267, 21899, 14749, 15263, 4001, 15268, 4008, 15273, 15276, 4023, 4024, 4029, 4030, 4031, 4032, 4033, 4034, 4035, 22992, 23515, 12255, 32756, 22015}\n",
      "dict_items([])\n",
      "collecting tokens for  spur\n",
      "indices:    {14442, 16267, 29902, 26737, 7889, 2389, 32150, 5436}\n",
      "dict_items([(\"Lemma('spur.v.01.spur')\", 2), (\"Lemma('goad.n.02.spur')\", 3), (\"Lemma('branch_line.n.01.spur')\", 1), (\"Lemma('spur.n.02.spur')\", 1)])\n",
      "collecting tokens for  trend\n",
      "indices:    {29825, 12035, 16262, 22279, 24583, 16267, 16271, 24207, 27550, 3363, 25005, 12985, 4031, 28101, 11976, 20299, 23377, 32982, 23387, 26334, 28007, 23402, 27760, 24691, 21876, 15219, 11766, 25334, 24573}\n",
      "dict_items([(\"Lemma('tendency.n.04.trend')\", 8), (\"Lemma('drift.n.05.trend')\", 1), (\"Lemma('course.n.03.trend')\", 1)])\n",
      "collecting tokens for  toward\n",
      "indices:    {24192, 2951, 4617, 34956, 5005, 33423, 8464, 25999, 17298, 33814, 20251, 35997, 33766, 10527, 23968, 13601, 8740, 26790, 23339, 12333, 15663, 23089, 7605, 23605, 23351, 18491, 27711, 25026, 22978, 9155, 12615, 23752, 31439, 29395, 33364, 10068, 19286, 24406, 9171, 26841, 32986, 15964, 5212, 25181, 18657, 25955, 17764, 36710, 24423, 33767, 12264, 24426, 2667, 20460, 31467, 9835, 14954, 25200, 27760, 18546, 2423, 34040, 18553, 23805}\n",
      "dict_items([])\n",
      "collecting tokens for  schools\n",
      "indices:    {16261, 2057, 16268, 21007, 24216, 23578, 157, 15647, 17704, 23593, 168, 22699, 5035, 20785, 23219, 20405, 24896, 2112, 2117, 13770, 24406, 15704, 25950, 16251, 20199, 11880, 11881, 106, 20203, 20204, 16238, 13299, 13303, 12155}\n",
      "dict_items([(\"Lemma('school.n.01.school')\", 11), (\"Lemma('school.n.04.school')\", 1)])\n",
      "collecting tokens for  roleplaying\n",
      "indices:    {15814, 15820, 15756, 15821, 15731, 15764, 15733, 15734, 15763, 15739}\n",
      "dict_items([(\"Lemma('roleplaying.n.01.roleplaying')\", 10)])\n",
      "collecting tokens for  testing\n",
      "indices:    {15744, 14725, 14733, 28701, 28702, 25378, 11569, 15537, 25395, 14775, 25402, 15675, 831, 24640, 25409, 15816, 15817, 25422, 25424, 25425, 25428, 25433, 22623, 3171, 3173, 25448, 25456, 15741, 15743}\n",
      "dict_items([(\"Lemma('examination.n.05.testing')\", 2), (\"Lemma('testing.n.01.testing')\", 5), (\"Lemma('testing.n.02.testing')\", 4), (\"Lemma('test.v.01.test')\", 1)])\n",
      "collecting tokens for  understood\n",
      "indices:    {9602, 8451, 15876, 7298, 31241, 32522, 29946, 32012, 25483, 33680, 12819, 17689, 33179, 6814, 36385, 2468, 25386, 17708, 28718, 13747, 19133, 28861, 14659, 15428, 15817, 2636, 25552, 34898, 20564, 13657, 3931, 13660, 19420, 14046, 13802, 8048, 3184, 10608, 16885, 12662, 27258, 28156}\n",
      "dict_items([(\"Lemma('understand.v.01.understand')\", 26), (\"Lemma('understand.v.02.understand')\", 3), (\"Lemma('understand.v.04.understand')\", 1), (\"Lemma('sympathize.v.02.understand')\", 1), (\"Lemma('silent.s.03.understood')\", 1), (\"Lemma('understand.v.03.understand')\", 3), (\"Lemma('understood.a.01.understood')\", 1)])\n",
      "collecting tokens for  represents\n",
      "indices:    {24071, 3084, 16020, 16022, 16023, 16025, 16026, 16027, 4509, 3869, 16031, 16030, 1450, 25013, 3893, 1337, 13374, 31808, 15943, 15817, 32205, 20431, 12247, 32219, 1504, 28905, 1385, 22387, 13946, 892}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('typify.v.02.represent')\", 11), (\"Lemma('represent.v.01.represent')\", 13), (\"Lemma('represent.v.04.represent')\", 2), (\"Lemma('exemplify.v.01.represent')\", 3), (\"Lemma('constitute.v.01.represent')\", 1)])\n",
      "collecting tokens for  major\n",
      "indices:    {25921, 25698, 15489, 12900, 24970, 13, 498, 33046, 22648, 3482, 18875, 32446}\n",
      "dict_items([(\"Lemma('major.a.01.major')\", 3), (\"Lemma('major.n.01.major')\", 1)])\n",
      "collecting tokens for  uses\n",
      "indices:    {14721, 12931, 12163, 32519, 32520, 1931, 26251, 27023, 14741, 11418, 15643, 26364, 2728, 2348, 3500, 20405, 2360, 15930, 2363, 30140, 965, 2760, 15817, 12126, 14565, 30821, 12008, 32874, 2684, 2685, 11390}\n",
      "dict_items([(\"Lemma('use.v.01.use')\", 20), (\"Lemma('function.n.02.use')\", 5), (\"Lemma('use.n.01.use')\", 1), (\"Lemma('use.n.03.use')\", 1), (\"Lemma('use.v.03.use')\", 1)])\n",
      "collecting tokens for  procedure\n",
      "indices:    {25090, 4198, 17658, 15756, 14867, 4950, 4794, 18683}\n",
      "dict_items([(\"Lemma('operation.n.07.procedure')\", 3), (\"Lemma('procedure.n.01.procedure')\", 3)])\n",
      "collecting tokens for  became\n",
      "indices:    {16390, 36359, 30216, 12297, 5133, 35342, 7696, 529, 10777, 5152, 16416, 39, 21550, 16433, 33333, 13878, 16440, 16442, 6202, 13885, 574, 20033, 16451, 1608, 22091, 13912, 24679, 13931, 14453, 37017, 8857, 4763, 29340, 29342, 29344, 12449, 1185, 1189, 4265, 31916, 29362, 28344, 30907, 33472, 27330, 28354, 21193, 12490, 21707, 11468, 14029, 14544, 30931, 8918, 18135, 23256, 5337, 27867, 24796, 10971, 21726, 5855, 7903, 13026, 36068, 23271, 1769, 1771, 5357, 12018, 5362, 22776, 6393, 18170, 27900, 13052, 2313, 7946, 13581, 5392, 5393, 27922, 12052, 14100, 31515, 13598, 35616, 36133, 4905, 21292, 21305, 5434, 22843, 12609, 30023, 30535, 4936, 4940, 21325, 22350, 25423, 36689, 22354, 5971, 30036, 4951, 4954, 22876, 17244, 12639, 18276, 30565, 31595, 9580, 31598, 15215, 19311, 2929, 25459, 9589, 2421, 2422, 34682, 12668, 31614, 5504, 13701, 31623, 11147, 34699, 31636, 12702, 28068, 21925, 5034, 10674, 33720, 4028, 1473, 4035, 12228, 31173, 13766, 11212, 1486, 15826, 26579, 15827, 22995, 5081, 14307, 15844, 5096, 18416, 18932, 10746, 5116, 6141}\n",
      "dict_items([(\"Lemma('become.v.02.become')\", 26), (\"Lemma('become.v.01.become')\", 26), (\"Lemma('become.v.03.become')\", 1)])\n",
      "collecting tokens for  increasingly\n",
      "indices:    {25732, 23558, 36493, 32143, 13968, 13204, 4632, 4764, 9383, 1325, 14899, 11061, 32567, 20033, 17217, 30529, 16204, 26572, 25440, 14689, 13922, 16361, 25451, 3053, 27887, 27249, 30833, 21239, 12921}\n",
      "dict_items([(\"Lemma('increasingly.r.01.increasingly')\", 16)])\n",
      "collecting tokens for  dogs\n",
      "indices:    {28546, 11140, 11150, 28569, 7961, 7088, 25140, 28725, 28726, 25144, 28729, 20026, 20027, 28730, 20030, 20034, 8774, 28743, 28619, 3811, 20714, 20717, 3824, 30709, 22773, 28537}\n",
      "dict_items([(\"Lemma('dog.n.01.dog')\", 9), (\"Lemma('chase.v.01.dog')\", 1)])\n",
      "collecting tokens for  picture\n",
      "indices:    {30211, 28170, 27664, 31251, 36884, 26133, 26134, 11292, 11298, 24111, 12345, 19527, 14410, 19544, 1113, 11368, 8298, 11371, 3184, 35958, 14467, 31881, 23695, 26257, 3729, 22675, 1171, 10901, 20633, 3225, 9881, 11422, 22696, 5356, 34544, 14065, 29941, 5373, 5378, 5382, 5402, 5404, 802, 5411, 37158, 29996, 37167, 21296, 2867, 9532, 9542, 9543, 27976, 9544, 33101, 5459, 9557, 2390, 27992, 27994, 2395, 1372, 4448, 9569, 26979, 4452, 4453, 2407, 30569, 17770, 2411, 17772, 2413, 28530, 17778, 17786, 27516, 17793, 899, 27014, 23434, 28554, 14220, 31115, 26521, 17818, 26523, 26526, 16802, 31154, 1482, 14283, 1498, 24052, 17401, 2047}\n",
      "dict_items([(\"Lemma('word_picture.n.01.picture')\", 1), (\"Lemma('video.n.01.picture')\", 3), (\"Lemma('painting.n.01.picture')\", 10), (\"Lemma('movie.n.01.picture')\", 1), (\"Lemma('mental_picture.n.01.picture')\", 9), (\"Lemma('picture.n.01.picture')\", 15), (\"Lemma('picture.n.05.picture')\", 1), (\"Lemma('picture.n.04.picture')\", 5)])\n",
      "collecting tokens for  repeated\n",
      "indices:    {36992, 34887, 30804, 14037, 4949, 20246, 4950, 31961}\n",
      "dict_items([(\"Lemma('repeat.v.01.repeat')\", 3), (\"Lemma('duplicate.v.01.repeat')\", 2)])\n",
      "collecting tokens for  polls\n",
      "indices:    {15456, 25063, 77, 20814, 79, 86, 23707}\n",
      "dict_items([(\"Lemma('polls.n.01.polls')\", 3)])\n",
      "collecting tokens for  disclosed\n",
      "indices:    {1313, 12326, 30956, 28717, 20558, 21296, 20722, 22748, 20277, 21974, 20535, 7352, 21756, 21759}\n",
      "dict_items([(\"Lemma('unwrap.v.02.disclose')\", 13)])\n",
      "collecting tokens for  married\n",
      "indices:    {10656, 12546, 2472, 33102, 16921, 10654}\n",
      "dict_items([(\"Lemma('marry.v.01.marry')\", 3), (\"Lemma('married.a.01.married')\", 2)])\n",
      "collecting tokens for  couples\n",
      "indices:    {4450, 30754, 4453, 12326, 4454, 26251, 5963, 17111, 22362, 24252, 22173, 4446}\n",
      "dict_items([(\"Lemma('couple.n.01.couple')\", 6)])\n",
      "collecting tokens for  using\n",
      "indices:    {21505, 13282, 5411, 3811, 18817, 26867, 3507, 21787, 11388, 1663}\n",
      "dict_items([(\"Lemma('use.v.01.use')\", 10)])\n",
      "collecting tokens for  practice\n",
      "indices:    {1666, 31747, 32388, 6786, 31749, 32263, 25736, 2055, 11150, 21781, 5273, 32154, 284, 286, 23205, 13995, 32427, 32309, 34742, 32310, 22200, 25144, 21178, 24508, 15811, 26308, 25674, 16078, 23632, 31320, 12767, 608, 1889, 36453, 11495, 2279, 3177, 14060, 4462, 25969, 32882, 23924, 12920}\n",
      "dict_items([(\"Lemma('exercise.n.03.practice')\", 3), (\"Lemma('practice.n.03.practice')\", 2), (\"Lemma('practice.n.01.practice')\", 5), (\"Lemma('practice.n.04.practice')\", 2), (\"Lemma('practice.v.01.practice')\", 1), (\"Lemma('rehearse.v.01.practice')\", 1)])\n",
      "collecting tokens for  64\n",
      "indices:    {15297, 353, 28806, 21815, 28807, 32486, 23756, 28845, 23415, 16189, 15295}\n",
      "dict_items([])\n",
      "collecting tokens for  young\n",
      "indices:    {30976, 12641, 9408, 18595, 32196, 5989, 7432, 3762, 14455, 26365}\n",
      "dict_items([(\"Lemma('young.a.01.young')\", 4), (\"Lemma('young.n.01.young')\", 1)])\n",
      "collecting tokens for  wife\n",
      "indices:    {9408, 23355, 12546, 18020, 5051, 16806, 775, 8745, 30763, 35226, 15281, 9204, 10645, 12599, 9401, 30266, 35003, 26365}\n",
      "dict_items([(\"Lemma('wife.n.01.wife')\", 12)])\n",
      "collecting tokens for  girl\n",
      "indices:    {30211, 14596, 33287, 32651, 8204, 13199, 33295, 2214, 3880, 17837, 3888, 19254, 7992, 7993, 3903, 10947, 13251, 19268, 30790, 19527, 9292, 36431, 3923, 10330, 30945, 9596, 36478, 33279}\n",
      "dict_items([(\"Lemma('girl.n.01.girl')\", 9), (\"Lemma('female_child.n.01.girl')\", 7), (\"Lemma('girlfriend.n.02.girl')\", 2)])\n",
      "collecting tokens for  thought\n",
      "indices:    {22535, 14351, 10256, 8211, 32794, 4122, 36899, 12327, 8242, 16443, 34898, 14420, 4187, 16477, 2143, 8289, 2149, 16492, 10369, 34951, 10377, 37010, 8345, 30882, 34980, 34984, 37034, 4267, 30896, 10426, 37062, 30919, 37069, 37070, 35024, 8412, 26849, 35047, 14577, 8452, 10503, 37129, 10506, 269, 10513, 35099, 8478, 24868, 18724, 18730, 12587, 18732, 2349, 14636, 20787, 20789, 14651, 20796, 20797, 18753, 10580, 16726, 12632, 14683, 14685, 14686, 14690, 16740, 14693, 14695, 16745, 14702, 16753, 6513, 14706, 6515, 29045, 18809, 6522, 4475, 33150, 33175, 35223, 18841, 35225, 8616, 10677, 18874, 2495, 35265, 6596, 22992, 33241, 8669, 18920, 8681, 10730, 10740, 33271, 16891, 16894, 18949, 27145, 16907, 29209, 12844, 31286, 33343, 6719, 8770, 8775, 8781, 8799, 17000, 8809, 8810, 19060, 634, 27277, 8860, 6816, 10921, 10967, 8926, 8929, 19177, 35567, 35569, 4857, 17151, 4869, 6925, 19218, 27414, 23320, 4889, 23330, 6950, 17195, 9009, 6969, 23356, 35661, 11088, 15188, 6999, 11100, 17253, 17255, 17257, 9068, 19309, 9071, 7028, 9078, 4987, 7050, 15252, 27554, 27555, 27558, 9156, 11205, 31704, 17372, 9181, 33772, 7149, 7154, 19442, 9204, 9206, 19452, 21502, 33791, 17408, 29701, 33799, 7193, 19489, 9256, 7209, 7210, 19502, 7217, 7218, 7219, 19505, 7220, 7221, 19511, 7226, 15419, 7228, 7229, 9281, 9284, 19539, 33877, 17501, 19553, 13409, 35963, 35965, 35968, 19589, 35982, 35990, 13467, 9372, 17565, 35998, 27808, 5285, 1192, 11443, 17591, 5311, 31936, 36041, 1226, 1228, 13517, 31961, 9436, 1244, 9453, 7408, 3316, 19702, 19703, 17670, 19721, 32014, 19733, 17689, 1306, 25882, 21811, 17721, 1339, 17725, 7487, 15681, 19784, 34125, 25938, 17750, 13660, 17758, 17763, 15716, 11641, 9596, 11650, 17800, 32137, 11663, 34192, 21909, 15772, 7594, 36269, 15798, 36299, 17869, 15828, 36308, 36317, 28129, 7662, 26094, 19964, 34301, 34321, 26131, 30230, 5658, 5666, 5672, 7733, 17979, 30271, 7751, 18021, 13927, 36466, 36468, 30326, 30334, 30348, 26278, 36520, 13999, 30394, 36543, 36547, 30407, 5836, 1746, 36564, 36576, 16106, 24311, 14072, 12031, 14085, 34567, 9996, 14110, 34597, 30508, 7980, 7991, 5953, 10053, 5959, 32592, 6002, 36734, 30598, 30606, 24463, 22419, 6058, 10161, 10169, 18367, 10194, 34775, 36830, 36841, 34794, 8172, 10227, 28670}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('think.v.03.think')\", 26), (\"Lemma('think.v.01.think')\", 26), (\"Lemma('remember.v.01.think')\", 5), (\"Lemma('idea.n.01.thought')\", 17), (\"Lemma('thinking.n.01.thought')\", 12), (\"Lemma('think_of.v.04.think_of')\", 3), (\"Lemma('think.v.02.think')\", 26), (\"Lemma('thought.n.03.thought')\", 11)])\n",
      "collecting tokens for  doubt\n",
      "indices:    {25730, 3714, 11143, 24971, 16655, 425, 16172, 16047, 14392, 12861, 11078, 10823, 26698, 34635, 2507, 25554, 6742, 35296, 23140, 2284, 1269}\n",
      "dict_items([(\"Lemma('doubt.n.01.doubt')\", 4)])\n",
      "collecting tokens for  hit\n",
      "indices:    {386, 29064, 661, 11030, 29078, 667, 414, 19871, 25890, 35374, 437, 29127, 18763, 23000, 348, 23009, 23139, 23021, 34035, 18804, 7796, 638}\n",
      "dict_items([(\"Lemma('hit.v.01.hit')\", 6), (\"Lemma('score.v.01.hit')\", 2), (\"Lemma('hit.n.01.hit')\", 1), (\"Lemma('hit.v.02.hit')\", 5), (\"Lemma('hit.v.03.hit')\", 3), (\"Lemma('reach.v.01.hit')\", 1), (\"Lemma('stumble.v.03.hit')\", 1)])\n",
      "collecting tokens for  side\n",
      "indices:    {28449, 775, 33992, 3655, 19850, 34027, 12652, 4490, 5512, 26631, 34029, 27473, 33777, 29523, 4564, 19180, 29306, 2845}\n",
      "dict_items([(\"Lemma('side.n.01.side')\", 2), (\"Lemma('side.n.04.side')\", 1), (\"Lemma('side.n.07.side')\", 2)])\n",
      "collecting tokens for  barn\n",
      "indices:    {36230, 9192, 18377, 9225, 17195, 20044, 13548, 31835, 35151, 18352, 18355, 23700, 36245, 18487, 9402, 18363, 16670, 21343}\n",
      "dict_items([(\"Lemma('barn.n.01.barn')\", 12)])\n",
      "collecting tokens for  garden\n",
      "indices:    {1073}\n",
      "dict_items([])\n",
      "collecting tokens for  fresh\n",
      "indices:    {30469, 26633, 1291, 1170, 30484, 29979, 35238, 28711, 27305, 15147, 17068, 29236, 26036, 25014, 11448, 1213, 22595, 31558, 16590, 13655, 9566, 6756, 35173, 33523, 12150, 6519, 22134, 9209, 7548}\n",
      "dict_items([(\"Lemma('fresh.a.01.fresh')\", 9), (\"Lemma('fresh.s.02.fresh')\", 1), (\"Lemma('fresh.s.04.fresh')\", 3), (\"Lemma('fresh.a.05.fresh')\", 1)])\n",
      "collecting tokens for  result\n",
      "indices:    {11296, 22689, 2849, 15489, 25799, 25128, 4905, 27786, 2220, 25036, 23379, 1812, 23990, 21688, 27801, 16124, 31069, 30686}\n",
      "dict_items([(\"Lemma('result.v.01.result')\", 2), (\"Lemma('consequence.n.01.result')\", 4), (\"Lemma('result.n.03.result')\", 1)])\n",
      "collecting tokens for  better\n",
      "indices:    {12808, 28694, 26142, 21538, 23609, 35907, 30790, 30793, 1629, 607, 6240, 16991, 25200, 115, 29316, 12940, 25231, 29336, 23193, 36509, 27807, 28319, 27814, 9403, 16572, 16573, 25282, 27330, 16068, 16075, 721, 33494, 218, 17626, 220, 1772, 1271, 9979, 35073, 19718, 19218, 37138, 26909, 17182, 1824, 34601, 26412, 20269, 13622, 26425, 19264, 28996, 22852, 12614, 17733, 23379, 13150, 15208, 29034, 12140, 12143, 13170, 29042, 1916, 1917, 26492, 17789, 22397, 24964, 26501, 17290, 1941, 30106, 30110, 24478, 25504, 22951, 24491, 24494, 34734, 13747, 24500, 27073, 471, 14303, 34272, 8674, 11238, 6121, 22511, 6141, 14334, 18943}\n",
      "dict_items([(\"Lemma('better.r.01.better')\", 11), (\"Lemma('well.r.03.well')\", 1), (\"Lemma('better.a.01.better')\", 23), (\"Lemma('better.a.02.better')\", 3), (\"Lemma('better.n.01.better')\", 1), (\"Lemma('better.s.03.better')\", 1), (\"Lemma('better.r.02.better')\", 1)])\n",
      "collecting tokens for  self\n",
      "indices:    {9583, 21495}\n",
      "dict_items([(\"Lemma('self.n.01.self')\", 1)])\n",
      "collecting tokens for  rosy\n",
      "indices:    {24194, 11172, 4998, 6503, 244, 23420, 30014, 2111}\n",
      "dict_items([(\"Lemma('blushful.s.02.rosy')\", 1), (\"Lemma('rose-colored.s.01.rosy')\", 1), (\"Lemma('flushed.s.01.rosy')\", 1)])\n",
      "collecting tokens for  seems\n",
      "indices:    {24578, 30596, 24965, 10633, 20491, 11661, 31120, 2838, 24983, 32406, 16154, 14620, 9885, 14623, 31520, 1570, 26403, 28963, 25890, 17700, 27559, 24744, 32425, 3756, 10618, 4272, 28465, 34866, 26033, 25140, 4275, 32948, 9400, 26431, 16191, 4929, 23377, 3921, 25310, 10848, 16101, 1510, 4858, 1513, 1514, 26094, 2800, 11509, 29946, 5371, 14078, 2431}\n",
      "dict_items([(\"Lemma('look.v.02.seem')\", 26), (\"Lemma('appear.v.04.seem')\", 14)])\n",
      "collecting tokens for  improve\n",
      "indices:    {11521, 11522, 1923, 24707, 16135, 1032, 3463, 2056, 11532, 30107, 4125, 21278, 23838, 2722, 12195, 27825, 9783, 2363, 4157, 2879, 4160, 24516, 32586, 23371, 1611, 15950, 1615, 4050, 29911, 13288, 20208, 29043, 244}\n",
      "dict_items([(\"Lemma('better.v.02.improve')\", 26), (\"Lemma('better.v.03.improve')\", 1)])\n",
      "collecting tokens for  start\n",
      "indices:    {35058, 31356, 1062}\n",
      "dict_items([(\"Lemma('get_down.v.07.start')\", 1), (\"Lemma('begin.v.03.start')\", 1)])\n",
      "collecting tokens for  appeared\n",
      "indices:    {26112, 3585, 32769, 1059, 3116, 14908, 14401, 26186, 14413, 14414, 22098, 18529, 22627, 35939, 21607, 22637, 31863, 14461, 22656, 21640, 14473, 20111, 21649, 12434, 4755, 4756, 9363, 4758, 35489, 27303, 9903, 7861, 21180, 20676, 4818, 7394, 244, 17142, 31498, 29971, 3864, 6430, 26912, 36645, 6953, 28971, 26929, 15668, 14134, 6972, 34114, 33101, 25423, 26451, 17238, 18774, 4955, 36713, 4974, 8561, 25458, 35697, 5497, 8578, 35718, 33676, 15761, 21394, 22933, 1431, 23961, 33181, 33194, 29098, 5555, 29107, 5045, 34742, 29109, 15803, 31165, 18883, 15823, 29138, 15324, 33273, 3054, 18930, 18931, 1527, 3577, 14330}\n",
      "dict_items([(\"Lemma('look.v.02.appear')\", 26), (\"Lemma('appear.v.02.appear')\", 26), (\"Lemma('appear.v.03.appear')\", 12), (\"Lemma('appear.v.04.appear')\", 4), (\"Lemma('appear.v.06.appear')\", 1), (\"Lemma('appear.v.05.appear')\", 3), (\"Lemma('appear.v.07.appear')\", 1)])\n",
      "collecting tokens for  win\n",
      "indices:    {1413, 24840, 652, 24974, 28563, 4635, 22050, 28453, 12965, 28454, 28072, 23849, 23978, 683, 28592, 16305, 28595, 24510, 28612, 28613, 26182, 28615, 24138, 5706, 6989, 23121, 15446, 11993, 20450, 8807, 8042, 23019, 13169, 19954, 24819, 244, 627, 24821}\n",
      "dict_items([(\"Lemma('acquire.v.05.win')\", 14), (\"Lemma('win.v.01.win')\", 21), (\"Lemma('win.n.01.win')\", 1)])\n",
      "collecting tokens for  st.\n",
      "indices:    {23323}\n",
      "dict_items([])\n",
      "collecting tokens for  purse\n",
      "indices:    {6756, 19055, 239, 21296, 25143, 16570, 19643, 17917}\n",
      "dict_items([(\"Lemma('bag.n.04.purse')\", 4), (\"Lemma('purse.n.03.purse')\", 1)])\n",
      "collecting tokens for  speed\n",
      "indices:    {21505, 25700}\n",
      "dict_items([])\n",
      "collecting tokens for  reserve\n",
      "indices:    {24026}\n",
      "dict_items([])\n",
      "collecting tokens for  psychology\n",
      "indices:    {28128, 13204, 2100, 23542, 14335}\n",
      "dict_items([(\"Lemma('psychology.n.01.psychology')\", 2)])\n",
      "collecting tokens for  shown\n",
      "indices:    {24072, 4110, 4113, 25108, 4118, 24648, 27724, 28752, 2129, 28754, 607, 11374, 28783, 28789, 36987, 22142, 22146, 11394, 3205, 19077, 11402, 28810, 28812, 4237, 4239, 23189, 11417, 21146, 11419, 4253, 11424, 11427, 17572, 23719, 13992, 29863, 29866, 32429, 8877, 4786, 14006, 10427, 23740, 25789, 23036, 14016, 8388, 14033, 4819, 14050, 14057, 4841, 22769, 29940, 11517, 33022, 15103, 2822, 2823, 15111, 15115, 15116, 15120, 15123, 16157, 15141, 2858, 15147, 15152, 21296, 15154, 28980, 16695, 31546, 2383, 32594, 22355, 2901, 2910, 2912, 35680, 29025, 32614, 15721, 2924, 877, 32620, 5490, 3955, 24437, 3961, 5501, 2943, 3456, 4483, 2948, 2949, 33671, 903, 5513, 2958, 10645, 1430, 5543, 22444, 32684, 4017, 961, 13249, 14788, 3533, 4559, 20437, 14302, 31199, 32737, 21991, 3570, 12790, 31740, 3581, 14334}\n",
      "dict_items([(\"Lemma('express.v.01.show')\", 5), (\"Lemma('show.v.01.show')\", 26), (\"Lemma('picture.v.02.show')\", 26), (\"Lemma('usher.v.01.show')\", 2), (\"Lemma('prove.v.02.show')\", 15), (\"Lemma('indicate.v.02.show')\", 3), (\"Lemma('show.v.04.show')\", 4), (\"Lemma('show.v.10.show')\", 1), (\"Lemma('testify.v.02.show')\", 11), (\"Lemma('read.v.08.show')\", 2), (\"Lemma('reflect.v.04.shine')\", 1)])\n",
      "collecting tokens for  suspicion\n",
      "indices:    {34649, 13978, 2123, 17023}\n",
      "dict_items([(\"Lemma('intuition.n.02.suspicion')\", 3)])\n",
      "collecting tokens for  combine\n",
      "indices:    {29536, 32907, 12140, 20216}\n",
      "dict_items([(\"Lemma('compound.v.05.combine')\", 1), (\"Lemma('unite.v.03.combine')\", 1), (\"Lemma('combine.n.01.combine')\", 1), (\"Lemma('compound.v.02.combine')\", 1)])\n",
      "collecting tokens for  provide\n",
      "indices:    {21376, 3329, 30082, 14721, 15108, 33028, 5509, 27655, 31884, 1808, 21653, 25238, 32283, 32284, 23580, 14365, 28703, 15521, 32674, 24611, 24610, 15140, 11558, 6953, 11562, 14636, 13358, 2300, 24000, 14912, 4674, 29890, 2628, 23362, 15174, 32967, 25928, 15820, 15436, 1873, 4950, 36951, 25176, 986, 30043, 33121, 4580, 4581, 15208, 15465, 20202, 107, 3050, 16366, 20343, 21882, 31995, 21628}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('supply.v.01.provide')\", 26), (\"Lemma('provide.v.02.provide')\", 6)])\n",
      "collecting tokens for  target\n",
      "indices:    {3466, 14991, 20751, 29072, 3483, 31390, 15390, 4387, 30246, 24103, 680, 28457, 3498, 28459, 28460, 28461, 28458, 18736, 4401, 21701, 3401, 27724, 33869, 11988, 4437, 21722, 11867, 28520, 28521, 28525, 11629, 18670, 2288, 28528, 11512}\n",
      "dict_items([(\"Lemma('target.n.03.target')\", 3), (\"Lemma('target.n.01.target')\", 6), (\"Lemma('aim.n.02.target')\", 2), (\"Lemma('prey.n.01.target')\", 2)])\n",
      "collecting tokens for  antagonism\n",
      "indices:    {4263, 22795, 27724, 4267, 4270, 4208, 4273, 4272}\n",
      "dict_items([])\n",
      "collecting tokens for  indispensable\n",
      "indices:    {5248, 12929, 31715, 22724, 24292, 29443, 27724, 20216, 32219, 10971}\n",
      "dict_items([(\"Lemma('indispensable.a.01.indispensable')\", 2), (\"Lemma('essential.s.01.indispensable')\", 1)])\n",
      "collecting tokens for  exist\n",
      "indices:    {4233, 23946, 30732, 13326, 13712, 31248, 32146, 22803, 2323, 4631, 5273, 1314, 13346, 4008, 32810, 4271, 2481, 822, 16316, 4543, 31295, 12993, 2880, 30792, 30794, 27724, 11980, 4562, 3796, 14813, 14817, 4706, 4839, 4587, 2411, 3950, 7920, 14068, 27259, 27134}\n",
      "dict_items([(\"Lemma('exist.v.01.exist')\", 26)])\n",
      "collecting tokens for  naturally\n",
      "indices:    {16490, 10203, 2109}\n",
      "dict_items([(\"Lemma('naturally.r.03.naturally')\", 1), (\"Lemma('naturally.r.01.naturally')\", 2)])\n",
      "collecting tokens for  crowd\n",
      "indices:    {2692, 9990, 9868, 3600, 26775, 1053, 26399, 9631, 6305, 1058, 22950, 22438, 9640, 1322, 9643, 428, 45, 29484, 9655, 36280, 31545, 1082, 34491, 19511, 14013, 7107, 25157, 456, 9675, 19790, 20945, 25694, 24800, 491, 10233, 9851, 252, 2686}\n",
      "dict_items([(\"Lemma('crowd.n.01.crowd')\", 25), (\"Lemma('crowd.n.02.crowd')\", 1)])\n",
      "collecting tokens for  consequently\n",
      "indices:    {4220}\n",
      "dict_items([(\"Lemma('consequently.r.01.consequently')\", 1)])\n",
      "collecting tokens for  breaks\n",
      "indices:    {10788, 14013, 13418, 13868, 30221, 11822, 12784, 789, 216, 2429}\n",
      "dict_items([(\"Lemma('fault.n.04.break')\", 1), (\"Lemma('breakage.n.03.break')\", 1), (\"Lemma('violate.v.01.break')\", 1)])\n",
      "collecting tokens for  temporary\n",
      "indices:    {23360, 25379, 21893, 4218, 32748, 24145, 12055, 30520, 32858, 5500, 30936}\n",
      "dict_items([(\"Lemma('impermanent.a.01.temporary')\", 3)])\n",
      "collecting tokens for  groups\n",
      "indices:    {23552, 23556, 22532, 4616, 31243, 24598, 1048, 21535, 28705, 2083, 16431, 30256, 27696, 20530, 16432, 20532, 20533, 4184, 4700, 11877, 27752, 4726, 26753, 25219, 3208, 26251, 14476, 23711, 2723, 32956, 14013, 27842, 27843, 27852, 32985, 27876, 24818, 24821, 27414, 2326, 3862, 2331, 16165, 25389, 20272, 2353, 16184, 25400, 16221, 11625, 13162, 5482, 20335, 33137, 24949, 14228, 27540, 20886, 20894, 32161, 4003, 33188, 33195, 33197, 33199, 33200, 4017, 3506, 32693, 4035, 31230, 17351, 12239, 12258, 12259, 2033, 31221, 4603, 23550}\n",
      "dict_items([(\"Lemma('group.n.01.group')\", 26), (\"Lemma('group.n.02.group')\", 1)])\n",
      "collecting tokens for  ranging\n",
      "indices:    {11900, 15524, 25670, 1031, 32905, 21994, 4108, 32623, 30577, 22289, 1715, 14901, 33045, 21493, 5658, 3292, 14013, 33790}\n",
      "dict_items([(\"Lemma('range.v.01.range')\", 13), (\"Lemma('roll.v.12.range')\", 2), (\"Lemma('ranging.a.01.ranging')\", 2), (\"Lemma('range.v.04.range')\", 1)])\n",
      "collecting tokens for  size\n",
      "indices:    {3, 29714, 36370, 4116, 12314, 1566, 21025, 11827, 10292, 3651, 30789, 3654, 1611, 1612, 11341, 29779, 3162, 26729, 28778, 3692, 3693, 15473, 9334, 3703, 3707, 22653, 29836, 22672, 3732, 1174, 3734, 3742, 32927, 15518, 1698, 29860, 3754, 29870, 3761, 29875, 5811, 14013, 14015, 14016, 26826, 2268, 24797, 3304, 3305, 3306, 22763, 16113, 5372, 3325, 22275, 28942, 33041, 28945, 27922, 27921, 28950, 28951, 31513, 27931, 3360, 1825, 16165, 19238, 21289, 5417, 15660, 27949, 27957, 27960, 30008, 27962, 3386, 4929, 4937, 3408, 1872, 3410, 3413, 2904, 4953, 1886, 6496, 3429, 29546, 35692, 3438, 17263, 28528, 1906, 2931, 7543, 2936, 34681, 3456, 29057, 14726, 11659, 14239, 30119, 27056, 10689, 18904, 30168, 30175, 30176, 16357, 23530, 28669, 15871}\n",
      "dict_items([(\"Lemma('size.n.01.size')\", 26), (\"Lemma('size.n.02.size')\", 1), (\"Lemma('size.s.01.size')\", 2), (\"Lemma('size_up.v.01.size_up')\", 1)])\n",
      "collecting tokens for  cluster\n",
      "indices:    {6946, 14648, 5380, 5090, 9674, 34570, 9686, 13336, 6938, 14684, 14013}\n",
      "dict_items([(\"Lemma('cluster.v.01.cluster')\", 2), (\"Lemma('bunch.n.01.cluster')\", 7), (\"Lemma('bunch.v.02.cluster')\", 1)])\n",
      "collecting tokens for  twenty\n",
      "indices:    {28544, 18529, 36640, 23328, 14455, 5157, 26945, 36649, 23318, 32407, 12473, 17374}\n",
      "dict_items([(\"Lemma('twenty.s.01.twenty')\", 4)])\n",
      "collecting tokens for  times\n",
      "indices:    {23536}\n",
      "dict_items([])\n",
      "collecting tokens for  during\n",
      "indices:    {31027}\n",
      "dict_items([])\n",
      "collecting tokens for  marriage\n",
      "indices:    {10242, 12043}\n",
      "dict_items([(\"Lemma('marriage.n.01.marriage')\", 2)])\n",
      "collecting tokens for  strange\n",
      "indices:    {8071, 33673, 33260, 1102, 13040, 8112, 2130, 16919, 10299}\n",
      "dict_items([(\"Lemma('strange.s.02.strange')\", 2), (\"Lemma('strange.a.01.strange')\", 5)])\n",
      "collecting tokens for  girls\n",
      "indices:    {36480, 36993, 36992, 900, 903, 13192, 14472, 30215, 37003, 15757, 32657, 3857, 5906, 3862, 13722, 3868, 9629, 10141, 10144, 15659, 30768, 8370, 13235, 1206, 3894, 1217, 25666, 19526, 3911, 3914, 31691, 25675, 25679, 3919, 3921, 25682, 3922, 36431, 25686, 10713, 6495, 22240, 24292, 24684, 11885, 36719, 13172, 6133, 13174, 21365, 13049, 22394, 13179, 11900, 14463}\n",
      "dict_items([(\"Lemma('daughter.n.01.girl')\", 2), (\"Lemma('girl.n.01.girl')\", 20), (\"Lemma('female_child.n.01.girl')\", 12), (\"Lemma('girlfriend.n.02.girl')\", 1)])\n",
      "collecting tokens for  telephoned\n",
      "indices:    {37128, 12684, 12690, 5106, 948, 8722, 20950, 7293, 17823}\n",
      "dict_items([(\"Lemma('call.v.03.telephone')\", 9)])\n",
      "collecting tokens for  announce\n",
      "indices:    {21123, 21124, 14023, 37128, 20969, 21134, 9840, 20497, 16890, 20988, 33149, 18271}\n",
      "dict_items([(\"Lemma('announce.v.01.announce')\", 9), (\"Lemma('announce.v.02.announce')\", 3)])\n",
      "collecting tokens for  letch\n",
      "indices:    {37138}\n",
      "dict_items([])\n",
      "collecting tokens for  needs\n",
      "indices:    {4616, 4623, 34833, 25634, 28710, 27691, 4655, 20016, 4656, 11323, 24648, 27723, 23631, 32857, 23642, 32353, 32866, 32865, 11878, 27244, 1669, 15495, 25224, 32904, 141, 12947, 20115, 23187, 2721, 26278, 22699, 28332, 19633, 11956, 11957, 28349, 30402, 22729, 27353, 27360, 20192, 20193, 27884, 9974, 32505, 25340, 30463, 24324, 30981, 27908, 2312, 35080, 1815, 792, 12060, 31013, 12090, 7484, 16193, 32067, 26959, 7000, 14171, 1884, 1887, 12128, 1890, 14181, 14182, 33127, 16237, 15219, 20346, 14208, 14721, 14210, 32130, 14212, 13706, 29067, 1421, 9101, 16275, 32663, 16282, 16283, 26010, 32159, 16289, 25506, 21922, 4524, 16307, 11704, 23993, 25026, 13258, 23506, 32224, 992, 23011, 23012, 15845, 32230, 20455, 4584, 1001, 28650, 23532, 2044, 4606}\n",
      "dict_items([(\"Lemma('necessitate.v.01.need')\", 18), (\"Lemma('want.v.02.need')\", 14), (\"Lemma('need.n.01.need')\", 12), (\"Lemma('need.n.02.need')\", 18), (\"Lemma('motivation.n.01.need')\", 5)])\n",
      "collecting tokens for  formulated\n",
      "indices:    {27809, 1444, 31142, 11662, 16432, 12947, 31774, 3167}\n",
      "dict_items([(\"Lemma('give_voice.v.01.formulate')\", 2), (\"Lemma('explicate.v.02.formulate')\", 3), (\"Lemma('invent.v.01.formulate')\", 2), (\"Lemma('formulate.v.04.formulate')\", 1)])\n",
      "collecting tokens for  greater\n",
      "indices:    {15704, 1355, 23678}\n",
      "dict_items([(\"Lemma('greater.a.01.greater')\", 2)])\n",
      "collecting tokens for  precision\n",
      "indices:    {14850, 32899, 28934, 27782, 29068, 31247, 12947, 26899, 33050, 26915, 4928, 36938, 3919, 28887, 14808, 11099, 28511, 14064, 18932, 28532}\n",
      "dict_items([(\"Lemma('preciseness.n.02.precision')\", 8)])\n",
      "collecting tokens for  campaign\n",
      "indices:    {12934, 14344, 392, 24586, 24974, 12947, 12309, 24087, 12951, 28065, 24611, 24868, 20388, 23718, 13863, 24871, 20392, 26667, 20395, 48, 20401, 4785, 51, 20404, 26681, 26685, 36670, 26686, 19136, 26178, 20420, 12613, 20424, 20936, 12620, 81, 32466, 32468, 84, 19032, 25698, 20455, 11881, 32237, 23794, 10098, 27768, 27770}\n",
      "dict_items([(\"Lemma('campaign.n.02.campaign')\", 4), (\"Lemma('political_campaign.n.01.campaign')\", 7), (\"Lemma('campaign.v.01.campaign')\", 4), (\"Lemma('campaign.n.03.campaign')\", 2)])\n",
      "collecting tokens for  done\n",
      "indices:    {17408, 28672, 25108, 11287, 1560, 31258, 11803, 16924, 22563, 1589, 19000, 17985, 16452, 7237, 17993, 1611, 8780, 8783, 27728, 8784, 8787, 19544, 23642, 19034, 31837, 14434, 31844, 20085, 32376, 12412, 9343, 27782, 25227, 27275, 37005, 26764, 36498, 25753, 27801, 20127, 23201, 7846, 20134, 35498, 4784, 29877, 20665, 28861, 31428, 3278, 14040, 12504, 24795, 16097, 24823, 22777, 25859, 26890, 1310, 36128, 18211, 36132, 31015, 17705, 28973, 31025, 18228, 20797, 18249, 5451, 33105, 1876, 28501, 24421, 17770, 1396, 24453, 14214, 24454, 19336, 23431, 17803, 26509, 10127, 6546, 30617, 6554, 1437, 20385, 3490, 11686, 25511, 11701, 3002, 10683, 14271, 32194, 1988, 26569, 13262, 11736, 3035, 22495, 3041, 19425, 11238, 10729, 6121, 8684, 29181}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('do.v.08.do')\", 3), (\"Lemma('make.v.01.do')\", 26), (\"Lemma('perform.v.01.do')\", 18), (\"Lemma('do.v.03.do')\", 17), (\"Lemma('done.s.01.done')\", 3), (\"Lemma('benefit.v.02.do_good')\", 1), (\"Lemma('cause.v.01.do')\", 3), (\"Lemma('do.v.04.do')\", 1)])\n",
      "collecting tokens for  fail\n",
      "indices:    {36225, 25476, 12947, 4635, 4253, 2078, 35999, 15390, 21922, 15395, 1962, 4267, 27573, 4919, 6455, 36795, 30404, 20427, 1741, 8909, 6875, 25437, 29413, 15717, 3687, 15345, 1778, 28532, 25855}\n",
      "dict_items([(\"Lemma('fail.v.01.fail')\", 17), (\"Lemma('fail.v.04.fail')\", 1), (\"Lemma('fail.v.02.fail')\", 8), (\"Lemma('fail.v.05.fail')\", 1), (\"Lemma('fail.v.03.fail')\", 1)])\n",
      "collecting tokens for  see\n",
      "indices:    {15610, 25603, 17357}\n",
      "dict_items([(\"Lemma('understand.v.02.see')\", 2)])\n",
      "collecting tokens for  serious\n",
      "indices:    {20483, 10890, 32149, 25752, 14488, 20251, 27423, 31009, 3234, 12197, 22826, 24106, 559, 31025, 11443, 2228, 13634, 14916, 26436, 17733, 21703, 30792, 26055, 30793, 5078, 19544, 9180, 30812, 24416, 5473, 3426, 24423, 2037, 14454, 26872}\n",
      "dict_items([(\"Lemma('serious.s.02.serious')\", 2), (\"Lemma('serious.a.01.serious')\", 12), (\"Lemma('good.s.16.serious')\", 1), (\"Lemma('dangerous.s.02.serious')\", 2)])\n",
      "collecting tokens for  student\n",
      "indices:    {13252, 14663, 13223, 27852, 27774}\n",
      "dict_items([(\"Lemma('student.n.01.student')\", 2), (\"Lemma('scholar.n.01.student')\", 1)])\n",
      "collecting tokens for  quarrel\n",
      "indices:    {12377, 17382, 21321, 2057, 20139, 4912, 25840, 12947, 34393, 16604}\n",
      "dict_items([(\"Lemma('quarrel.v.01.quarrel')\", 6), (\"Lemma('quarrel.n.01.quarrel')\", 1)])\n",
      "collecting tokens for  reactions\n",
      "indices:    {4242, 14455, 4249, 4250, 4253, 4254, 3236, 3237, 25382, 3238, 26022, 26021, 13865, 3244, 12590, 31924, 4921, 26940, 33216, 33220, 33223, 33225, 33226, 4053, 1373, 4203, 33260, 30830, 33262, 30831, 30835, 33143, 22650}\n",
      "dict_items([(\"Lemma('chemical_reaction.n.01.reaction')\", 4), (\"Lemma('reaction.n.02.reaction')\", 4), (\"Lemma('reaction.n.03.reaction')\", 4)])\n",
      "collecting tokens for  conclusions\n",
      "indices:    {30208, 15424, 2400, 1120, 16331, 4973, 3823, 22736, 4985}\n",
      "dict_items([(\"Lemma('decision.n.02.conclusion')\", 5), (\"Lemma('conclusion.n.02.conclusion')\", 1), (\"Lemma('termination.n.05.conclusion')\", 1)])\n",
      "collecting tokens for  space\n",
      "indices:    {4354, 1033, 5386, 28043, 4363, 25485, 5387, 36111, 9747, 4382, 5411, 34597, 34221, 2734, 23983, 13229, 29237, 27964, 27965, 12225, 19137, 4292, 26822, 4298, 1235, 27992, 4314, 10590, 4960, 15078, 13549, 2158, 4337, 25077, 24695, 32762, 3071}\n",
      "dict_items([(\"Lemma('space.n.03.space')\", 4), (\"Lemma('space.n.01.space')\", 6), (\"Lemma('space.n.02.space')\", 2), (\"Lemma('space.n.07.space')\", 1), (\"Lemma('outer_space.n.01.space')\", 1)])\n",
      "collecting tokens for  course\n",
      "indices:    {28675, 13323, 26124, 542, 26659, 17957, 34349, 26671, 29240, 2109, 21070, 24146, 19035, 19560, 14955, 33398, 29306, 32892, 10877, 16510, 17024, 12929, 27782, 23688, 36509, 34463, 16032, 5296, 4797, 23742, 12992, 30917, 24779, 24780, 17114, 6874, 22241, 4839, 23783, 31466, 34542, 25327, 16631, 14592, 26896, 1301, 10527, 36647, 31529, 27436, 16180, 27958, 36666, 18747, 14663, 22856, 18760, 22859, 23372, 14158, 33103, 12117, 18776, 3419, 15197, 24926, 33117, 26979, 26980, 16229, 873, 31089, 33138, 3441, 22905, 890, 22907, 30077, 3454, 1409, 32131, 15756, 8081, 11154, 23956, 3484, 1436, 22942, 17318, 15785, 22954, 937, 12202, 11182, 34734, 27061, 24518, 2502, 2512, 977, 27090, 3028, 8151, 23000, 24028, 15850, 13294, 26611, 2037, 26102, 24055, 15357}\n",
      "dict_items([(\"Lemma('course.n.01.course')\", 5), (\"Lemma('course.n.02.course')\", 8), (\"Lemma('course.n.03.course')\", 3), (\"Lemma('course.n.04.course')\", 2), (\"Lemma('path.n.04.course')\", 2)])\n",
      "collecting tokens for  marshal\n",
      "indices:    {25740}\n",
      "dict_items([])\n",
      "collecting tokens for  himself\n",
      "indices:    {13825, 13826, 6657, 20481, 20998, 10252, 34829, 5133, 6668, 11281, 36883, 13845, 17945, 30749, 18463, 1571, 8236, 6701, 2610, 14388, 14389, 12853, 34871, 34872, 14392, 16954, 31800, 36412, 31807, 23104, 18500, 13893, 1610, 23115, 31308, 17484, 8780, 9293, 24144, 14417, 23122, 83, 12879, 5205, 86, 8281, 26202, 5212, 6749, 28254, 17503, 30816, 35934, 30819, 19558, 13415, 36968, 6764, 31852, 28272, 23153, 25714, 34932, 23156, 14453, 35959, 17016, 31863, 9339, 1147, 27259, 25726, 3710, 5760, 20096, 5251, 5768, 16012, 14477, 1168, 13969, 4754, 1173, 5782, 27799, 33431, 27800, 29339, 17052, 13980, 18587, 17056, 27299, 19621, 8874, 36012, 11440, 6835, 26698, 7350, 27320, 8889, 6330, 7355, 10427, 6843, 19645, 18621, 14531, 6339, 27845, 7371, 2256, 8183, 14558, 6879, 26336, 17634, 12008, 21226, 28395, 7407, 34032, 7408, 18672, 1268, 35062, 35064, 36601, 23293, 18688, 36610, 17667, 771, 9991, 36615, 19719, 9994, 34571, 9488, 20244, 36629, 19735, 18717, 17694, 36640, 22305, 24353, 12587, 11051, 9007, 18226, 10552, 2361, 26425, 17212, 34111, 18242, 26949, 24392, 35661, 4941, 339, 17748, 17749, 25944, 4954, 7518, 14176, 870, 10598, 10088, 14697, 16745, 17259, 876, 24944, 25969, 887, 25976, 7547, 9598, 31103, 8574, 17796, 18312, 6536, 24970, 31627, 6539, 25999, 24976, 11154, 915, 10139, 31134, 16799, 11168, 28065, 12194, 19363, 28068, 35749, 1446, 28069, 6568, 1449, 15791, 26544, 26033, 6579, 2483, 6581, 9146, 19398, 18887, 6600, 24521, 12232, 33227, 1992, 9167, 32212, 19413, 26583, 17882, 988, 9181, 19422, 19423, 27104, 15841, 13788, 34272, 13794, 8681, 23018, 35819, 7147, 11244, 23021, 26090, 26099, 36854, 34806, 15865}\n",
      "dict_items([])\n",
      "collecting tokens for  gets\n",
      "indices:    {12928, 17793, 23427, 8325, 261, 13964, 27025, 33433, 285, 287, 1187, 27045, 11944, 36905, 2350, 2353, 31155, 31157, 15669, 36281, 11067, 2367, 36291, 24388, 25413, 14022, 29773, 28365, 11856, 28369, 13904, 1878, 30807, 23127, 9565, 33633, 15997, 33641, 1002, 4460, 15858, 23538, 26226, 27514, 24955, 4477, 8318, 26367}\n",
      "dict_items([(\"Lemma('become.v.01.get')\", 14), (\"Lemma('experience.v.03.get')\", 1), (\"Lemma('arrive.v.01.get')\", 2), (\"Lemma('get.v.14.get')\", 1), (\"Lemma('get.v.01.get')\", 9), (\"Lemma('receive.v.02.get')\", 4), (\"Lemma('bring.v.04.get')\", 1), (\"Lemma('have.v.17.get')\", 2), (\"Lemma('get.v.03.get')\", 1), (\"Lemma('get_across.v.01.get_across')\", 1), (\"Lemma('get.v.11.get')\", 1)])\n",
      "collecting tokens for  old\n",
      "indices:    {36780, 11036, 34284, 6042}\n",
      "dict_items([(\"Lemma('old.a.01.old')\", 1)])\n",
      "collecting tokens for  mantle\n",
      "indices:    {23012}\n",
      "dict_items([])\n",
      "collecting tokens for  nature\n",
      "indices:    {27905, 11269, 1670, 28169, 14220, 5260, 31119, 5271, 27801, 36890, 32028, 11294, 16415, 14239, 5024, 2468, 5031, 14633, 26671, 2481, 13621, 26808, 1466, 11324, 23742, 14280, 30153, 2637, 27343, 14673, 25298, 16211, 11985, 26201, 14426, 14171, 24156, 24157, 28249, 9949, 36320, 13793, 23265, 26975, 14437, 3944, 32233, 3817, 13801, 29934, 28142, 27762, 13044, 22645, 12278, 32120, 32891, 14590, 12287}\n",
      "dict_items([(\"Lemma('nature.n.04.nature')\", 1), (\"Lemma('nature.n.01.nature')\", 16), (\"Lemma('nature.n.02.nature')\", 3), (\"Lemma('nature.n.03.nature')\", 3)])\n",
      "collecting tokens for  maris\n",
      "indices:    {23027}\n",
      "dict_items([])\n",
      "collecting tokens for  furthermore\n",
      "indices:    {26753}\n",
      "dict_items([])\n",
      "collecting tokens for  strikes\n",
      "indices:    {14230, 13655}\n",
      "dict_items([(\"Lemma('strike.n.01.strike')\", 1), (\"Lemma('strike.v.01.strike')\", 1)])\n",
      "collecting tokens for  note\n",
      "indices:    {2664, 30255, 4307, 30229, 1562, 24188, 8415}\n",
      "dict_items([(\"Lemma('note.v.03.note')\", 2), (\"Lemma('notice.v.02.note')\", 2), (\"Lemma('note.v.04.note')\", 1)])\n",
      "collecting tokens for  throw\n",
      "indices:    {29698, 21891, 20620, 21009, 16536, 17049, 10906, 31133, 416, 10785, 20646, 29101, 1966, 36913, 185, 24015, 19800, 7385, 8796, 8165, 28396, 22773, 6778, 8700, 18943}\n",
      "dict_items([(\"Lemma('throw.n.02.throw')\", 1), (\"Lemma('throw.v.01.throw')\", 11), (\"Lemma('shed.v.01.throw')\", 2), (\"Lemma('throw.n.01.throw')\", 3), (\"Lemma('throw.v.08.throw')\", 1), (\"Lemma('throw.v.04.throw')\", 1), (\"Lemma('give.v.07.throw')\", 1), (\"Lemma('throw.v.02.throw')\", 1)])\n",
      "collecting tokens for  away\n",
      "indices:    {1544, 12296, 6670, 36367, 36379, 35357, 8735, 18464, 25132, 7215, 12345, 35388, 14910, 16960, 35905, 25669, 11861, 5721, 26714, 1629, 16477, 17504, 23649, 19047, 20074, 6778, 21635, 28806, 21639, 7817, 19085, 9871, 8848, 18063, 17556, 2214, 11943, 31913, 10413, 2228, 12981, 11959, 22203, 16572, 33475, 18640, 26834, 26835, 36052, 9947, 36060, 14560, 36064, 19688, 8940, 30451, 6900, 17657, 6907, 1790, 26368, 37121, 9985, 12546, 12036, 19207, 5385, 9485, 37138, 6938, 23330, 29995, 23340, 5420, 27439, 17201, 5429, 35639, 5948, 35134, 35646, 8528, 20821, 36185, 31580, 19806, 5472, 4960, 35681, 30052, 9576, 7020, 19308, 33646, 35698, 24949, 19833, 27515, 31612, 19331, 35715, 35203, 28551, 19335, 12681, 26508, 8590, 399, 26514, 34710, 36763, 13216, 9634, 6563, 12706, 19877, 12710, 34213, 12715, 33708, 19885, 20912, 5043, 26550, 27575, 7101, 9661, 21951, 13759, 16838, 28102, 36297, 33738, 457, 9678, 36313, 8156, 22504, 5097, 35308, 33776, 19958, 10742, 33784, 25590, 19962}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('away.s.01.away')\", 1), (\"Lemma('away.r.01.away')\", 20), (\"Lemma('aside.r.02.away')\", 6), (\"Lemma('away.r.02.away')\", 5), (\"Lemma('away.r.04.away')\", 1), (\"Lemma('away.r.06.away')\", 1), (\"Lemma('away.r.07.away')\", 1)])\n",
      "collecting tokens for  beat\n",
      "indices:    {32065, 32036, 32106, 33811, 34006, 32120}\n",
      "dict_items([])\n",
      "collecting tokens for  front\n",
      "indices:    {4618, 19467, 17423, 36368, 1561, 33817, 5670, 27689, 16937, 29750, 7736, 1593, 4669, 17471, 5195, 18517, 9304, 5734, 17512, 29812, 19080, 17551, 34969, 12965, 34986, 1198, 34992, 29369, 36027, 7361, 33474, 199, 21193, 10441, 35036, 7396, 13540, 34024, 37102, 34039, 34041, 9467, 7935, 6911, 6913, 36098, 7427, 2307, 35587, 5387, 20748, 23308, 12558, 35083, 30992, 30994, 35092, 23319, 5913, 13601, 5411, 27446, 33595, 7486, 36677, 19286, 34136, 34141, 29023, 34144, 18786, 34148, 11111, 24944, 36730, 9599, 36740, 9608, 393, 392, 36765, 9630, 34209, 18354, 16823, 9151, 14785, 5059, 6090, 2012, 16865, 12260, 17893}\n",
      "dict_items([(\"Lemma('front.a.01.front')\", 8), (\"Lemma('battlefront.n.01.front')\", 5), (\"Lemma('front.n.01.front')\", 4), (\"Lemma('front.n.03.front')\", 2), (\"Lemma('front.n.04.front')\", 2)])\n",
      "collecting tokens for  shop\n",
      "indices:    {21194, 12620, 8293}\n",
      "dict_items([])\n",
      "collecting tokens for  sixth\n",
      "indices:    {20386, 3556, 370}\n",
      "dict_items([(\"Lemma('sixth.s.01.sixth')\", 2)])\n",
      "collecting tokens for  governor\n",
      "indices:    {20328, 20936}\n",
      "dict_items([])\n",
      "collecting tokens for  club\n",
      "indices:    {444}\n",
      "dict_items([])\n",
      "collecting tokens for  hotel\n",
      "indices:    {36961, 33396, 32478}\n",
      "dict_items([])\n",
      "collecting tokens for  week\n",
      "indices:    {30466, 25220, 18309, 36875, 21781, 19624, 297, 20522, 5687, 323, 30550, 24026, 25700, 22373, 14950, 29039, 27633, 17778, 6772, 14838, 33148, 10621}\n",
      "dict_items([(\"Lemma('week.n.01.week')\", 9), (\"Lemma('week.n.03.week')\", 1)])\n",
      "collecting tokens for  efforts\n",
      "indices:    {24744, 5530, 23780, 14954}\n",
      "dict_items([(\"Lemma('attempt.n.01.effort')\", 1)])\n",
      "collecting tokens for  stay\n",
      "indices:    {35328, 15171, 10377, 36875, 881, 2262, 34941}\n",
      "dict_items([(\"Lemma('stay.v.01.stay')\", 4), (\"Lemma('stay.v.02.stay')\", 1), (\"Lemma('stay.v.05.stay')\", 1)])\n",
      "collecting tokens for  shape\n",
      "indices:    {22272, 35074, 29060, 5385, 18442, 5003, 28812, 27157, 6937, 30106, 5405, 14241, 28834, 5412, 18468, 28839, 2855, 31913, 1450, 29738, 3118, 31919, 5296, 689, 3122, 31923, 24369, 30008, 31933, 25665, 4929, 18755, 3011, 3141, 30789, 24006, 26315, 21197, 3021, 4945, 1490, 3921, 3026, 24918, 13655, 36056, 35033, 4950, 25948, 1890, 1891, 15460, 26473, 28016, 31861, 29563}\n",
      "dict_items([(\"Lemma('condition.n.05.shape')\", 1), (\"Lemma('shape.n.01.shape')\", 20), (\"Lemma('determine.v.02.shape')\", 4), (\"Lemma('shape.n.04.shape')\", 2), (\"Lemma('shape.n.02.shape')\", 1)])\n",
      "collecting tokens for  help\n",
      "indices:    {35137, 4580, 27848, 35180, 11117, 35025, 16884, 20150, 24566, 32860}\n",
      "dict_items([(\"Lemma('help.v.01.help')\", 6), (\"Lemma('help_oneself.v.01.help')\", 1), (\"Lemma('help.v.02.help')\", 1)])\n",
      "collecting tokens for  team\n",
      "indices:    {257, 643, 259, 515, 646, 262, 649, 1289, 650, 651, 265, 23060, 1942, 24727, 1943, 23064, 15648, 165, 680, 179, 4407, 441, 24510, 577, 195, 452, 23108, 11718, 583, 460, 24780, 8910, 18255, 336, 22992, 19792, 334, 339, 18263, 23005, 23006, 10461, 10466, 24803, 484, 24802, 31334, 11879, 11372, 508, 494, 622, 625, 11763, 11764, 632, 636}\n",
      "dict_items([(\"Lemma('team.n.01.team')\", 26), (\"Lemma('team.n.02.team')\", 4)])\n",
      "collecting tokens for  knee\n",
      "indices:    {3872, 321, 320, 18563, 17600, 8773, 8423, 27048, 17610, 18891, 10383, 339, 12564, 255}\n",
      "dict_items([(\"Lemma('knee.n.01.knee')\", 13)])\n",
      "collecting tokens for  skorich\n",
      "indices:    {465}\n",
      "dict_items([(\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  played\n",
      "indices:    {26242, 17026, 22920, 14474, 13581, 22926, 17935, 1168, 1041, 26001, 8081, 277, 26005, 24475, 36640, 31653, 26792, 16555, 17324, 36652, 33838, 303, 22321, 20028, 2621, 11070, 24508, 36544, 11201, 2624, 20675, 321, 11199, 451, 19534, 35919, 21715, 26582, 31190, 26583, 4954, 28001, 8802, 22504, 31721, 23274, 14446, 1007, 22511, 22514, 32246, 887, 26489, 1019, 24447}\n",
      "dict_items([(\"Lemma('play.v.03.play')\", 5), (\"Lemma('play.v.01.play')\", 14), (\"Lemma('play.v.02.play')\", 11), (\"Lemma('play.v.13.play')\", 1), (\"Lemma('played.a.01.played')\", 1), (\"Lemma('act.v.03.play')\", 6), (\"Lemma('play.v.17.play')\", 1), (\"Lemma('play.v.16.play')\", 1), (\"Lemma('play.v.06.play')\", 6), (\"Lemma('play.v.10.play')\", 1), (\"Lemma('play.v.09.play')\", 2), (\"Lemma('play.v.07.play')\", 1), (\"Lemma('play.v.11.play')\", 1), (\"Lemma('act.v.05.play')\", 1), (\"Lemma('play.v.18.play')\", 1)])\n",
      "collecting tokens for  football\n",
      "indices:    {1928, 27179, 24779, 303, 24703, 27962, 508, 255}\n",
      "dict_items([(\"Lemma('football.n.01.football')\", 2)])\n",
      "collecting tokens for  career\n",
      "indices:    {31619, 6148, 31748, 30215, 12811, 31627, 17421, 34297, 13841, 27159, 8348, 13856, 32674, 20900, 37, 165, 8236, 37167, 14515, 22201, 11450, 19390, 9156, 20932, 14544, 12240, 11476, 14935, 32215, 471, 475, 477, 12004, 31592, 32232, 12010, 31720, 36971, 23919, 31731, 116, 37109, 15477, 4596, 32249, 31610, 31614}\n",
      "dict_items([(\"Lemma('career.n.01.career')\", 18), (\"Lemma('career.n.02.career')\", 7)])\n",
      "collecting tokens for  pittsburgh\n",
      "indices:    {31593}\n",
      "dict_items([])\n",
      "collecting tokens for  24\n",
      "indices:    {27010, 20227, 15624, 29322, 15115, 667, 5520, 20371, 20756, 5526, 5527, 32664, 153, 5528, 5531, 155, 27036, 27038, 27039, 27040, 927, 21026, 5533, 27037, 5535, 16157, 27041, 4137, 33204, 22070, 29758, 3779, 11587, 28229, 3781, 25414, 20168, 25415, 4042, 23115, 33224, 3791, 3920, 29137, 3538, 5589, 1621, 22359, 3926, 3419, 30300, 12511, 21475, 11747, 31971, 28262, 2409, 29041, 25714, 32756}\n",
      "dict_items([(\"Lemma('twenty-four.s.01.24')\", 24), (\"Lemma('twenty-four.n.01.24')\", 3), (\"Lemma('twenty-fourth.s.01.24th')\", 1)])\n",
      "collecting tokens for  %\n",
      "indices:    {22019, 22026, 3102, 4127, 3103, 4128, 3108, 22056, 22057, 22058, 31788, 22063, 22064, 22067, 27191, 4158, 4159, 3137, 27203, 3150, 32336, 27231, 15476, 15481, 15488, 15497, 15003, 15021, 15022, 15025, 15027, 3254, 32446, 22209, 3272, 15049, 32460, 15052, 15063, 15065, 15068, 15070, 15582, 23276, 15623, 29464, 27418, 11550, 27425, 27426, 16170, 2858, 2864, 2865, 11572, 16189, 11598, 31056, 2904, 30574, 21912, 21920, 33195, 21931, 33202, 33203, 33204, 33207, 33208, 27066, 3520, 3525, 33224, 4042, 3535, 21968, 21969, 3536, 21984, 21985, 21991, 3560, 21992, 16362, 21994, 16363, 21993, 16368, 22005, 22006, 22011, 22013}\n",
      "dict_items([])\n",
      "collecting tokens for  10\n",
      "indices:    {25600, 11264, 14854, 14855, 28688, 4120, 22552, 28188, 28197, 3121, 29749, 4151, 3128, 11319, 4153, 62, 4159, 13887, 4166, 5194, 24138, 23117, 28241, 28243, 28764, 28766, 1126, 26729, 26730, 619, 626, 631, 3707, 11918, 663, 12440, 24730, 3744, 21153, 22181, 21158, 680, 24233, 170, 683, 21160, 22202, 19131, 20154, 20157, 11454, 15039, 3265, 2246, 4295, 3784, 12998, 28875, 2766, 23254, 20183, 26328, 20186, 21212, 22750, 2274, 2790, 2279, 4330, 21227, 20206, 20207, 2798, 20208, 15091, 247, 21753, 15610, 20734, 15615, 11522, 21765, 15111, 28938, 11532, 2831, 3857, 21782, 278, 27418, 286, 3359, 27425, 11555, 15141, 11558, 11559, 31016, 31015, 31019, 15147, 21807, 21815, 24890, 22336, 29505, 11584, 22340, 21828, 21319, 25415, 11596, 28493, 18253, 25934, 22359, 15191, 20833, 22372, 11624, 20840, 20331, 26991, 21362, 22910, 11652, 30088, 21385, 20364, 16269, 23439, 27538, 11681, 939, 29103, 22447, 33204, 4022, 12728, 11705, 33208, 11719, 5580, 4045, 3535, 5583, 20432, 14806, 12759, 21976, 25053, 21982, 27110, 21991, 14831, 16368, 1529, 5118}\n",
      "dict_items([(\"Lemma('ten.s.01.10')\", 26), (\"Lemma('ten.n.01.10')\", 4), (\"Lemma('tenth.s.01.tenth')\", 2)])\n",
      "collecting tokens for  subjects\n",
      "indices:    {5376, 11267, 27525, 11270, 27527, 9610, 16016, 13845, 25238, 25495, 156, 2721, 15652, 33189, 33190, 15654, 33192, 33193, 11434, 33196, 22446, 33199, 33201, 2098, 33203, 33204, 2100, 33202, 33207, 33208, 26165, 33210, 33213, 33215, 33216, 33089, 25922, 2115, 11330, 33219, 33223, 32456, 33224, 32714, 26188, 32717, 23118, 33234, 33235, 31828, 32211, 33236, 33246, 31839, 4576, 33248, 33252, 33253, 33255, 14440, 15975, 33260, 29295, 33263, 33264, 29299}\n",
      "dict_items([(\"Lemma('subject.n.02.subject')\", 4), (\"Lemma('discipline.n.01.subject')\", 5), (\"Lemma('subject.n.01.subject')\", 2), (\"Lemma('subject.v.02.subject')\", 1), (\"Lemma('topic.n.02.subject')\", 2), (\"Lemma('subject.n.05.subject')\", 1), (\"Lemma('subject.n.06.subject')\", 2), (\"Lemma('national.n.01.subject')\", 2)])\n",
      "collecting tokens for  shifted\n",
      "indices:    {33220, 33196, 5165, 1198, 33199, 33198, 6291, 33204, 25751, 19416, 2810, 9660, 7165, 29342, 29695}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('shift.v.02.shift')\", 4), (\"Lemma('switch.v.04.shift')\", 8), (\"Lemma('transfer.v.04.shift')\", 2), (\"Lemma('stir.v.02.shift')\", 1)])\n",
      "collecting tokens for  negative\n",
      "indices:    {16385, 24459, 13710, 20239, 3220, 3221, 32916, 14360, 32921, 2971, 14112, 2978, 2981, 2982, 32935, 13617, 33204, 27958, 16185, 15678, 16068, 22734, 34514, 31188, 34519, 3550, 13663, 3552, 13666, 3555, 25830, 3559, 3562, 32107, 3573, 27895, 1274, 25853, 3071}\n",
      "dict_items([(\"Lemma('negative.a.01.negative')\", 12), (\"Lemma('negative.a.02.negative')\", 2), (\"Lemma('negative.n.01.negative')\", 1), (\"Lemma('negative.s.03.negative')\", 1)])\n",
      "collecting tokens for  positive\n",
      "indices:    {27266, 33214, 28139, 33229, 4336, 20785, 27832, 34515, 14131, 14360, 2972, 31358, 33983}\n",
      "dict_items([(\"Lemma('positive.a.01.positive')\", 3)])\n",
      "collecting tokens for  reaction\n",
      "indices:    {23944, 32904, 12685, 4239, 34705, 2328, 3100, 3101, 4253, 12191, 3288, 3105, 3234, 20259, 3236, 4261, 3239, 3242, 5295, 22833, 22066, 33203, 33204, 31924, 33205, 33202, 33208, 3257, 33209, 3259, 33211, 3260, 3518, 3262, 33210, 3265, 4160, 33219, 3269, 837, 16325, 3272, 33223, 2890, 3275, 33222, 3277, 33229, 3279, 3283, 3285, 33238, 3286, 7896, 3289, 3290, 32856, 3292, 3293, 32862, 3295, 36575, 3297, 27874, 9699, 3300, 24417, 22630, 4207, 25974, 20217, 20478}\n",
      "dict_items([(\"Lemma('chemical_reaction.n.01.reaction')\", 26), (\"Lemma('reaction.n.02.reaction')\", 6), (\"Lemma('reaction.n.03.reaction')\", 3)])\n",
      "collecting tokens for  kohnstamm-positive\n",
      "indices:    {33236}\n",
      "dict_items([])\n",
      "collecting tokens for  passage\n",
      "indices:    {1152, 25348, 26254, 14995, 9366, 22810, 13599, 26660, 11300, 23590, 26411, 20652, 11059, 32439, 9659, 3389, 30783, 12352, 14787, 12357, 12365, 4177, 1495, 93, 2655, 16357, 16232, 15849, 34154, 16363, 22892, 16365, 30577, 34161, 15858, 27890, 6909}\n",
      "dict_items([(\"Lemma('passage.n.01.passage')\", 6), (\"Lemma('passage.n.06.passage')\", 2), (\"Lemma('passage.n.03.passage')\", 4), (\"Lemma('enactment.n.01.passage')\", 3), (\"Lemma('passage.n.05.passage')\", 3), (\"Lemma('passage.n.02.passage')\", 3), (\"Lemma('passage.n.08.passage')\", 1), (\"Lemma('passage.n.07.passage')\", 1)])\n",
      "collecting tokens for  sales\n",
      "indices:    {11777, 15621, 21881, 32270, 11681, 20643, 22056, 22057, 22060, 20654, 22063, 2737, 22066, 11701, 11709, 21572, 24009, 21971, 21844, 5460, 24024, 19032, 24026, 21985, 20327, 21991, 21993, 20332, 21871, 21874, 32374, 34297, 11898}\n",
      "dict_items([(\"Lemma('sale.n.02.sale')\", 4), (\"Lemma('sale.n.01.sale')\", 3)])\n",
      "collecting tokens for  davis\n",
      "indices:    {20645}\n",
      "dict_items([])\n",
      "collecting tokens for  effect\n",
      "indices:    {26632, 35855, 3087, 3089, 19, 13849, 16412, 2611, 1082, 2618, 1088, 2624, 10826, 30286, 20559, 36970, 8298, 4716, 25196, 24179, 22138, 11388, 27787, 9356, 27789, 8335, 4239, 27793, 27794, 4242, 16018, 8341, 25751, 4253, 29857, 27809, 20645, 9387, 20652, 4779, 15026, 4790, 31930, 22715, 27836, 6843, 4803, 12996, 36039, 22731, 15053, 21198, 3279, 9938, 28889, 3290, 15069, 3297, 3298, 36578, 2790, 3303, 3306, 3307, 3311, 3312, 5361, 11506, 11507, 16111, 1787, 1279, 5378, 23300, 16135, 1799, 1802, 22799, 26899, 26904, 31000, 25373, 28449, 23330, 25380, 23844, 14633, 14634, 11052, 33080, 32056, 3386, 2363, 25405, 27454, 15682, 27972, 3397, 3398, 1351, 2887, 20297, 3414, 3930, 26459, 15712, 24418, 14181, 32622, 19311, 24948, 9594, 29564, 15229, 23422, 9596, 3968, 21888, 13697, 3973, 10633, 21899, 11659, 23954, 11163, 12191, 14239, 27553, 25506, 12195, 15274, 34730, 13739, 29613, 13230, 35760, 30141, 21958, 16327, 28103, 33233, 25042, 31190, 16347, 2523, 16861, 14828, 14829, 24056, 16380}\n",
      "dict_items([(\"Lemma('consequence.n.01.effect')\", 26), (\"Lemma('effect.n.03.effect')\", 6), (\"Lemma('impression.n.02.effect')\", 7), (\"Lemma('effect.v.01.effect')\", 7), (\"Lemma('effect.n.04.effect')\", 2), (\"Lemma('affect.v.01.affect')\", 2)])\n",
      "collecting tokens for  problem\n",
      "indices:    {24069, 13322, 2063, 23574, 24604, 27680, 15417, 31805, 15423, 31808, 20546, 22595, 15432, 30792, 585, 22603, 15441, 31825, 24145, 30807, 32860, 27742, 26718, 2660, 9835, 4215, 35450, 12931, 12932, 12933, 32908, 27281, 25752, 27290, 18076, 23201, 22702, 32433, 28855, 32441, 22713, 4799, 22212, 16075, 28875, 22732, 16083, 22752, 16120, 25341, 23810, 16139, 11036, 25890, 4907, 5422, 24882, 20788, 16193, 28481, 28484, 24902, 20297, 17739, 15189, 11613, 29034, 15723, 32625, 11634, 11636, 1924, 5509, 24969, 3478, 3483, 11684, 2469, 34726, 17318, 18367, 5577, 5586, 16341, 13272, 1501, 5116}\n",
      "dict_items([(\"Lemma('problem.n.02.problem')\", 6), (\"Lemma('problem.n.01.problem')\", 26), (\"Lemma('trouble.n.01.problem')\", 3)])\n",
      "collecting tokens for  apartment\n",
      "indices:    {36961, 17736, 20973, 17556, 16828}\n",
      "dict_items([(\"Lemma('apartment.n.01.apartment')\", 3)])\n",
      "collecting tokens for  primarily\n",
      "indices:    {24193, 3202, 1292, 4877, 27789, 32017, 14739, 5013, 25366, 5015, 16152, 26778, 13339, 32925, 25765, 23208, 2601, 2348, 33068, 14391, 33080, 3396, 3911, 3150, 3790, 2774, 14690, 3814, 3815, 33001, 3817, 23019, 11372, 15213, 16239, 16240, 28017, 11379, 23284, 3189, 14204, 31998, 25343}\n",
      "dict_items([(\"Lemma('chiefly.r.01.primarily')\", 26)])\n",
      "collecting tokens for  plan\n",
      "indices:    {22563, 20199, 23752, 26219, 29424, 21562, 29244, 32509, 32446}\n",
      "dict_items([(\"Lemma('plan.v.03.plan')\", 1), (\"Lemma('plan.v.01.plan')\", 1)])\n",
      "collecting tokens for  existing\n",
      "indices:    {5506, 5509, 5255, 23816, 5513, 1422, 11666, 16278, 14999, 27544, 5529, 14745, 27545, 5151, 16295, 3881, 16297, 1836, 25901, 2862, 1839, 16814, 1843, 16436, 5434, 22715, 12994, 29127, 16074, 15442, 23526, 20844, 15213, 20206, 32622, 12268, 1905, 11890, 33138, 499, 32373, 5497}\n",
      "dict_items([(\"Lemma('exist.v.01.exist')\", 8), (\"Lemma('existent.a.01.existing')\", 3), (\"Lemma('existing.s.03.existing')\", 2)])\n",
      "collecting tokens for  gardner\n",
      "indices:    {17176}\n",
      "dict_items([])\n",
      "collecting tokens for  included\n",
      "indices:    {26913, 15617, 19555, 23364, 3875, 32483, 32489, 30089, 3692, 22782, 32531, 5235, 12660, 2845, 29246, 32447}\n",
      "dict_items([(\"Lemma('include.v.01.include')\", 13), (\"Lemma('admit.v.03.include')\", 1), (\"Lemma('include.v.02.include')\", 1), (\"Lemma('include.v.03.include')\", 1)])\n",
      "collecting tokens for  dumont\n",
      "indices:    {20403}\n",
      "dict_items([])\n",
      "collecting tokens for  almost\n",
      "indices:    {9280, 27841, 17536, 26690, 23935, 31536, 12978, 6045, 21375}\n",
      "dict_items([(\"Lemma('about.r.07.almost')\", 4)])\n",
      "collecting tokens for  place\n",
      "indices:    {30304, 15077, 13031, 18066, 34836, 36436, 26908, 29594, 36060, 9949, 34911}\n",
      "dict_items([(\"Lemma('position.n.01.place')\", 1), (\"Lemma('place.n.06.place')\", 1), (\"Lemma('put.v.01.place')\", 1), (\"Lemma('stead.n.01.place')\", 1)])\n",
      "collecting tokens for  doctrine\n",
      "indices:    {905, 27341, 28141, 14959, 15284, 14078}\n",
      "dict_items([(\"Lemma('doctrine.n.01.doctrine')\", 3)])\n",
      "collecting tokens for  formal\n",
      "indices:    {16394, 16399, 14226, 14869, 31896, 5401, 14244, 16423, 14506, 22652, 22193, 32052, 4791, 21688, 22591, 16453, 5701, 1353, 16459, 32860, 14045, 27998, 8289, 8676, 14445, 16252, 16254}\n",
      "dict_items([(\"Lemma('formal.a.01.formal')\", 13), (\"Lemma('formal.s.02.formal')\", 3), (\"Lemma('formal.a.03.formal')\", 2)])\n",
      "collecting tokens for  separation\n",
      "indices:    {1570, 20547, 16197, 9577, 16459, 9356, 9589, 16440, 8475}\n",
      "dict_items([(\"Lemma('separation.n.01.separation')\", 3), (\"Lemma('separation.n.02.separation')\", 3), (\"Lemma('separation.n.05.separation')\", 1), (\"Lemma('interval.n.03.separation')\", 1)])\n",
      "collecting tokens for  international\n",
      "indices:    {22614, 16396, 27006}\n",
      "dict_items([(\"Lemma('international.a.01.international')\", 1)])\n",
      "collecting tokens for  municipal\n",
      "indices:    {14721, 5263, 32403, 21146, 20378, 23714, 23717, 28711, 16441, 24896, 24898, 21190, 12108, 31053, 16464, 23760, 12260, 1903, 32371, 501, 31609, 12668}\n",
      "dict_items([(\"Lemma('municipal.a.01.municipal')\", 9)])\n",
      "collecting tokens for  view\n",
      "indices:    {14721, 20484, 22412, 31254, 1047, 27939, 27559, 16048, 18354, 16307, 14970, 30266, 16063, 2496, 28102, 5989, 23530, 9837, 24826}\n",
      "dict_items([(\"Lemma('opinion.n.01.view')\", 1), (\"Lemma('view.n.07.view')\", 1), (\"Lemma('view.n.03.view')\", 1), (\"Lemma('see.v.05.view')\", 1), (\"Lemma('position.n.03.view')\", 2), (\"Lemma('opinion.n.02.view')\", 1), (\"Lemma('view.n.02.view')\", 1)])\n",
      "collecting tokens for  parts\n",
      "indices:    {14721, 26242, 16130, 34691, 5382, 14727, 2953, 4362, 4363, 30861, 15886, 16014, 28815, 6800, 13326, 33043, 27670, 5405, 11427, 16164, 28837, 7715, 16167, 24744, 11306, 15402, 26028, 4141, 26926, 2605, 32940, 20273, 10289, 26291, 21299, 2229, 14646, 26296, 26427, 33084, 14783, 32961, 1090, 27970, 11588, 8903, 4936, 4939, 24908, 13774, 28880, 28882, 25942, 20183, 13275, 2908, 2269, 26588, 15969, 26594, 29799, 26983, 21864, 11370, 15730, 27001, 22266, 24061, 4735}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('part.n.03.part')\", 4), (\"Lemma('region.n.01.part')\", 5), (\"Lemma('part.n.10.part')\", 1), (\"Lemma('part.n.09.part')\", 2), (\"Lemma('part.n.02.part')\", 7), (\"Lemma('part.n.01.part')\", 12), (\"Lemma('part.n.11.part')\", 2), (\"Lemma('parts.n.01.parts')\", 1)])\n",
      "collecting tokens for  universal\n",
      "indices:    {2592, 3714, 1226, 2159, 15288, 16413}\n",
      "dict_items([(\"Lemma('cosmopolitan.s.03.universal')\", 5)])\n",
      "collecting tokens for  legal\n",
      "indices:    {27905, 31746, 31237, 22793, 31242, 31754, 5264, 26643, 10139, 14876, 14108, 23842, 21428, 12344, 21562, 20156, 15549, 31173, 16454, 15561, 16457, 16459, 13903, 34256, 24144, 33363, 21460, 25814, 25816, 11738, 5339, 11101, 11870, 27871, 13920, 13923, 15460, 25063, 31719, 34027, 15596, 15597, 15598, 27887, 27888, 14196, 27900}\n",
      "dict_items([(\"Lemma('legal.a.01.legal')\", 9), (\"Lemma('legal.a.04.legal')\", 2), (\"Lemma('legal.s.03.legal')\", 3), (\"Lemma('legal.a.02.legal')\", 5)])\n",
      "collecting tokens for  system\n",
      "indices:    {16396, 14233, 2592, 4770, 4774, 3240, 32939, 32945, 34483, 4792, 14912, 24899, 28104, 24913, 23521, 28513, 31719, 5489, 24949}\n",
      "dict_items([(\"Lemma('system.n.01.system')\", 2), (\"Lemma('system.n.07.system')\", 1), (\"Lemma('system.n.02.system')\", 1)])\n",
      "collecting tokens for  named\n",
      "indices:    {20101, 30215, 21642, 15883, 10638, 34198, 31129, 18202, 29339, 6042, 160, 6312, 28584, 17708, 6061, 31793, 12468, 33973, 10554, 34238, 28607, 17225, 22218, 18250, 17228, 25677, 26066, 12641, 36708, 34021, 12517, 21220, 29165, 21743, 20592, 29183}\n",
      "dict_items([(\"Lemma('name.v.03.name')\", 3), (\"Lemma('name.v.05.name')\", 1), (\"Lemma('name.v.01.name')\", 18), (\"Lemma('appoint.v.01.name')\", 1)])\n",
      "collecting tokens for  charge\n",
      "indices:    {1, 25218, 17409, 29955, 1415, 1416, 27020, 8716, 35598, 35597, 6928, 8337, 17426, 12946, 3220, 3221, 20, 12183, 12184, 36884, 36890, 21650, 21673, 20396, 2224, 15408, 35634, 21680, 33460, 35637, 21302, 11450, 27963, 20666, 21692, 12223, 22337, 31042, 20673, 8004, 6399, 12866, 32334, 35791, 12880, 26831, 20432, 15187, 17621, 5462, 14039, 16349, 15838, 15967, 22114, 21091, 5346, 12645, 30950, 22501, 32237, 30317, 11504, 24178, 32116, 33268, 20985, 3194, 23551}\n",
      "dict_items([(\"Lemma('charge.v.03.charge')\", 3), (\"Lemma('charge.n.01.charge')\", 4), (\"Lemma('charge.n.03.charge')\", 1), (\"Lemma('charge.v.09.charge')\", 1), (\"Lemma('charge.n.04.charge')\", 2), (\"Lemma('charge.n.02.charge')\", 6), (\"Lemma('care.n.05.charge')\", 2), (\"Lemma('mission.n.03.charge')\", 2), (\"Lemma('charge.v.06.charge')\", 1)])\n",
      "collecting tokens for  majdanek\n",
      "indices:    {8006}\n",
      "dict_items([(\"Lemma('location.n.01.location')\", 1)])\n",
      "collecting tokens for  above\n",
      "indices:    {9186, 26690, 31560, 31177, 20137, 3004, 4394, 23629, 35677, 3280, 4604, 3026, 4792, 10585, 31420, 35992}\n",
      "dict_items([(\"Lemma('above.r.01.above')\", 2)])\n",
      "collecting tokens for  glowing\n",
      "indices:    {29411, 22086, 19786, 5854, 3377, 29534, 6841, 29501, 29406}\n",
      "dict_items([(\"Lemma('glowing.s.01.glowing')\", 1)])\n",
      "collecting tokens for  ivory\n",
      "indices:    {23299, 11109, 11110, 10860, 11128, 11322, 7774}\n",
      "dict_items([(\"Lemma('ivory.n.01.ivory')\", 4)])\n",
      "collecting tokens for  baton\n",
      "indices:    {19219}\n",
      "dict_items([])\n",
      "collecting tokens for  pointed\n",
      "indices:    {23685, 27910, 10374, 6409, 650, 12426, 22539, 10257, 21526, 6809, 3994, 2201, 7839, 4257, 33571, 13221, 1322, 31281, 20788, 35256, 20536, 18491, 3004, 14909, 29378, 67, 579, 6852, 14918, 10571, 33611, 6480, 20434, 30419, 34388, 9179, 2013, 5854, 9182, 7518, 35679, 18531, 23781, 4718, 17904, 33905, 13682, 4724, 21237, 14072, 36735}\n",
      "dict_items([(\"Lemma('orient.v.01.point')\", 5), (\"Lemma('bespeak.v.01.point')\", 1), (\"Lemma('indicate.v.02.point')\", 6), (\"Lemma('steer.v.01.point')\", 3), (\"Lemma('charge.v.17.point')\", 3), (\"Lemma('pointed.a.01.pointed')\", 1)])\n",
      "collecting tokens for  clouds\n",
      "indices:    {18700, 18701, 31375, 18832, 29203, 19225, 19226, 25376, 19233, 18733, 35249, 26162, 27955, 5815, 36423, 14791, 20048, 5854, 3427, 6885, 28647, 28519, 33769, 18666, 28524, 30580, 6391, 25595}\n",
      "dict_items([(\"Lemma('cloud.n.02.cloud')\", 12), (\"Lemma('cloud.n.01.cloud')\", 3)])\n",
      "collecting tokens for  valley\n",
      "indices:    {23605}\n",
      "dict_items([])\n",
      "collecting tokens for  trustee\n",
      "indices:    {6134, 14879}\n",
      "dict_items([(\"Lemma('trustee.n.01.trustee')\", 1)])\n",
      "collecting tokens for  common\n",
      "indices:    {32546, 14909, 11332, 23779, 5219, 5035, 12556, 28141, 16433, 14098, 16436, 5275, 4988, 573, 27196, 6907}\n",
      "dict_items([(\"Lemma('park.n.02.common')\", 1), (\"Lemma('common.a.02.common')\", 3), (\"Lemma('common.a.01.common')\", 4), (\"Lemma('common.s.03.common')\", 1)])\n",
      "collecting tokens for  property\n",
      "indices:    {32384, 32385, 15620, 15621, 32393, 32394, 5260, 12173, 21646, 21644, 32401, 22034, 32529, 19219, 32407, 32411, 5275, 36125, 32413, 30, 32416, 20512, 23202, 5419, 32427, 32431, 2736, 2737, 2738, 32435, 8883, 25137, 34353, 2739, 32568, 34361, 21430, 14773, 25021, 20676, 4422, 27850, 5079, 90, 31870, 2785, 2788, 27877, 2790, 27885, 8687, 27894, 32375, 32376, 32377, 32378, 32380, 32382, 32383}\n",
      "dict_items([(\"Lemma('property.n.01.property')\", 14), (\"Lemma('place.n.02.property')\", 3), (\"Lemma('property.n.02.property')\", 2)])\n",
      "collecting tokens for  provides\n",
      "indices:    {5248, 20737, 16258, 22148, 26757, 15881, 3850, 1803, 1932, 1929, 5262, 16275, 3605, 13973, 2167, 2712, 5400, 22043, 2718, 15009, 15010, 2593, 3879, 1960, 28458, 20523, 20524, 4017, 33084, 4667, 33083, 5820, 32956, 11327, 1856, 3391, 12098, 32960, 14911, 703, 32706, 28103, 3784, 2772, 14805, 29270, 4694, 4692, 1248, 15202, 23528, 16238, 13935, 11375, 3054, 26227, 25463, 27642, 4731, 32382}\n",
      "dict_items([(\"Lemma('supply.v.01.provide')\", 26), (\"Lemma('provide.v.03.provide')\", 4)])\n",
      "collecting tokens for  share\n",
      "indices:    {11782, 23942, 11659, 19474, 1043, 11680, 15266, 32551, 21800, 29991, 21799, 16174, 26945, 15051, 12620, 15054, 16334, 15055, 11739, 15067, 16223, 28002, 25319, 24168, 1515, 11759, 27633, 21234, 23027, 30586}\n",
      "dict_items([(\"Lemma('share.v.02.share')\", 3), (\"Lemma('partake.v.02.share')\", 2), (\"Lemma('share.n.01.share')\", 8), (\"Lemma('share.v.01.share')\", 3), (\"Lemma('share.v.05.share')\", 1), (\"Lemma('share.v.04.share')\", 1), (\"Lemma('parcel.n.02.share')\", 1), (\"Lemma('share.n.02.share')\", 1), (\"Lemma('contribution.n.01.share')\", 1)])\n",
      "collecting tokens for  fund\n",
      "indices:    {21937, 14364}\n",
      "dict_items([(\"Lemma('store.n.02.fund')\", 1)])\n",
      "collecting tokens for  keeping\n",
      "indices:    {14080, 24451, 27526, 13191, 37002, 32267, 33551, 37138, 9491, 8468, 33431, 14496, 36132, 30888, 11953, 1975, 20795, 21066, 17234, 7640, 33240, 33754, 30813, 14308, 30181, 2021, 5357, 1647, 15473, 36082, 10233, 12925}\n",
      "dict_items([(\"Lemma('prevent.v.02.keep')\", 3), (\"Lemma('keep.v.01.keep')\", 19), (\"Lemma('keeping.n.01.keeping')\", 1), (\"Lemma('keep.v.03.keep')\", 2), (\"Lemma('prolong.v.02.keep_up')\", 1), (\"Lemma('keep_away.v.01.keep_away')\", 1)])\n",
      "collecting tokens for  apparently\n",
      "indices:    {14800, 59, 3811, 3701}\n",
      "dict_items([(\"Lemma('apparently.r.01.apparently')\", 4)])\n",
      "collecting tokens for  feeling\n",
      "indices:    {12615, 36328, 21531, 14646, 2587}\n",
      "dict_items([(\"Lemma('feel.v.01.feel')\", 1), (\"Lemma('feeling.n.01.feeling')\", 2), (\"Lemma('impression.n.01.feeling')\", 1)])\n",
      "collecting tokens for  involvement\n",
      "indices:    {2308, 13639, 13642, 15381, 7675, 16123, 31197, 27871}\n",
      "dict_items([(\"Lemma('engagement.n.07.involvement')\", 4), (\"Lemma('involvement.n.02.involvement')\", 1), (\"Lemma('interest.n.01.involvement')\", 1)])\n",
      "collecting tokens for  technical\n",
      "indices:    {64, 27105, 26914, 32129, 4580, 26077, 27788, 4628, 15766, 13303, 4792, 11289, 16251, 4604, 2749}\n",
      "dict_items([(\"Lemma('technical.a.01.technical')\", 2), (\"Lemma('technical.a.03.technical')\", 1), (\"Lemma('technical.a.02.technical')\", 2)])\n",
      "collecting tokens for  visible\n",
      "indices:    {27779, 2823, 2826, 5010, 30742, 18721, 3363, 4906, 32170, 16814, 9148, 32957, 9150, 13759, 25153, 6341, 32846, 21334, 11353, 11355, 11369, 13546, 11371, 12784, 17524, 16123, 30333}\n",
      "dict_items([(\"Lemma('visible.a.01.visible')\", 13), (\"Lemma('visible.s.02.visible')\", 2)])\n",
      "collecting tokens for  significance\n",
      "indices:    {27778, 32259, 27908, 14597, 32519, 4744, 14602, 27532, 1807, 32406, 31133, 36899, 24743, 12327, 4778, 4650, 13494, 14646, 20155, 16191, 16192, 4801, 22594, 22723, 14274, 27594, 1867, 27645, 30802, 3797, 13277, 2655, 1377, 26212, 15997, 32742, 5227, 21996, 26733, 14575, 2671, 13935, 19441, 4215, 16123, 32893, 16126, 11263}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('significance.n.01.significance')\", 20), (\"Lemma('significance.n.02.significance')\", 6), (\"Lemma('meaning.n.01.significance')\", 2)])\n",
      "collecting tokens for  practical\n",
      "indices:    {14725, 32905, 16137, 22284, 14615, 30877, 2719, 25506, 2724, 16429, 31926, 27575, 25794, 21573, 27339, 25436, 13534, 3168, 12641, 24418, 3170, 13285, 2793, 27115, 31084, 16235, 25200, 27760, 27770, 21883, 16126, 20991}\n",
      "dict_items([(\"Lemma('practical.a.01.practical')\", 12), (\"Lemma('hardheaded.s.02.practical')\", 1)])\n",
      "collecting tokens for  flood\n",
      "indices:    {2597, 12709, 6471, 25139, 30516, 22773, 14971, 30527}\n",
      "dict_items([(\"Lemma('flood.n.01.flood')\", 2), (\"Lemma('flood.n.02.flood')\", 1)])\n",
      "collecting tokens for  beginning\n",
      "indices:    {21893, 22534, 25356, 20881, 30994, 11282, 29461, 31129, 14746, 27302, 13865, 9002, 12202, 32685, 13486, 1454, 1458, 10935, 33848, 29373, 29119, 12613, 1481, 1482, 29134, 33102, 4950, 31961, 5466, 36445, 2400, 12644, 36710, 20967, 4966, 14570, 15850, 2412, 22894, 16112, 30451, 13684, 32628, 32246, 1146, 29947, 32764, 1918, 32767}\n",
      "dict_items([(\"Lemma('beginning.n.02.beginning')\", 3), (\"Lemma('get_down.v.07.begin')\", 10), (\"Lemma('beginning.n.03.beginning')\", 4), (\"Lemma('begin.v.02.begin')\", 4), (\"Lemma('beginning.n.01.beginning')\", 8), (\"Lemma('begin.v.03.begin')\", 1)])\n",
      "collecting tokens for  1953\n",
      "indices:    {22018, 15320, 20228, 21853, 22595, 26606, 15311, 12253, 26929, 273, 23951, 4020, 15319, 31640, 13052, 3933, 5182}\n",
      "dict_items([])\n",
      "collecting tokens for  scotty\n",
      "indices:    {5606}\n",
      "dict_items([(\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  murmured\n",
      "indices:    {7236, 19268, 35047, 36295, 36362, 5611, 34987, 18541, 13718, 35551}\n",
      "dict_items([(\"Lemma('murmur.v.01.murmur')\", 10)])\n",
      "collecting tokens for  thanks\n",
      "indices:    {21384, 25905, 24919}\n",
      "dict_items([])\n",
      "collecting tokens for  softly\n",
      "indices:    {19106, 7234, 19748, 5656, 9230, 16719, 5745, 23730, 31410, 17748, 17717, 23734, 33686, 13205, 34138}\n",
      "dict_items([(\"Lemma('softly.r.01.softly')\", 7), (\"Lemma('softly.r.02.softly')\", 2)])\n",
      "collecting tokens for  father\n",
      "indices:    {14153}\n",
      "dict_items([])\n",
      "collecting tokens for  bend\n",
      "indices:    {585, 35203, 28318}\n",
      "dict_items([(\"Lemma('bend.v.01.bend')\", 2)])\n",
      "collecting tokens for  height\n",
      "indices:    {32012, 3991, 27543, 12189, 35744, 27559, 29226, 14254, 2992, 2993, 2994, 2995, 1590, 12730, 3141, 32214, 30046, 29797, 24936, 5611, 26993, 27003, 28924, 22271}\n",
      "dict_items([(\"Lemma('height.n.01.height')\", 6), (\"Lemma('stature.n.02.height')\", 2), (\"Lemma('acme.n.01.height')\", 2)])\n",
      "collecting tokens for  across\n",
      "indices:    {7840, 18785, 18595, 16884, 11508}\n",
      "dict_items([])\n",
      "collecting tokens for  table\n",
      "indices:    {2944, 8755, 30013}\n",
      "dict_items([(\"Lemma('table.n.01.table')\", 1), (\"Lemma('table.n.02.table')\", 1)])\n",
      "collecting tokens for  turn\n",
      "indices:    {29632, 27136, 7552, 15132, 14663, 34441, 30731, 36335, 34321, 21332, 33462, 18396}\n",
      "dict_items([(\"Lemma('turn.v.01.turn')\", 1), (\"Lemma('turning.n.04.turn')\", 1), (\"Lemma('turn.v.06.turn')\", 1), (\"Lemma('bend.n.01.turn')\", 1)])\n",
      "collecting tokens for  brown\n",
      "indices:    {10958, 5310}\n",
      "dict_items([(\"Lemma('brown.s.01.brown')\", 1)])\n",
      "collecting tokens for  ear\n",
      "indices:    {9345, 30218, 1806, 29204, 27420, 19872, 13609, 14506, 9643, 26541, 26933, 17847, 28091, 18898, 14552, 18907, 2272, 1767, 5611, 5612, 36345, 26235, 5887}\n",
      "dict_items([(\"Lemma('auricle.n.02.ear')\", 2), (\"Lemma('ear.n.02.ear')\", 4), (\"Lemma('ear.n.01.ear')\", 9)])\n",
      "collecting tokens for  cylinder\n",
      "indices:    {29640, 28913, 28917, 28919}\n",
      "dict_items([])\n",
      "collecting tokens for  volume\n",
      "indices:    {21934}\n",
      "dict_items([])\n",
      "collecting tokens for  determined\n",
      "indices:    {14854, 14856, 14859, 26650, 2586, 32802, 15913, 32834, 12373, 15963, 32349, 22627, 25195, 24686, 12399, 26235, 32388, 31878, 4761, 8347, 23196, 32931, 32933, 31910, 10429, 14015, 31944, 3275, 3276, 18638, 3797, 26838, 2780, 28906, 11507, 4340, 28918, 28919, 27898, 28925, 28943, 28945, 16161, 32042, 16172, 23860, 10551, 20289, 32583, 26963, 2913, 13666, 2929, 2930, 15225, 13191, 28051, 2976, 2977, 5033, 13226, 14768, 14769, 14770, 6069, 14773, 3518, 3519, 12228, 34764, 16340, 31700, 28636, 3047, 11244, 16370, 27127}\n",
      "dict_items([(\"Lemma('determine.v.03.determine')\", 10), (\"Lemma('determine.v.01.determine')\", 23), (\"Lemma('determined.s.01.determined')\", 9), (\"Lemma('decide.v.01.determine')\", 3), (\"Lemma('determine.v.02.determine')\", 9), (\"Lemma('specify.v.02.determine')\", 7), (\"Lemma('determine.v.06.determine')\", 3)])\n",
      "collecting tokens for  combustion\n",
      "indices:    {28932, 28935, 28936, 28937, 28940, 28941, 14772, 28917, 28918, 14774, 28920, 5434}\n",
      "dict_items([(\"Lemma('combustion.n.01.combustion')\", 2)])\n",
      "collecting tokens for  chamber\n",
      "indices:    {29288, 3556, 28917}\n",
      "dict_items([(\"Lemma('chamber.n.01.chamber')\", 1)])\n",
      "collecting tokens for  measured\n",
      "indices:    {2944, 11395, 2822, 2835, 28950, 12061, 2846, 2847, 2848, 15009, 2849, 33572, 2980, 27181, 2864, 817, 22578, 3763, 3126, 14780, 15677, 14781, 3139, 24899, 3270, 14797, 15695, 3538, 4061, 2016, 14817, 2916, 2917, 2920, 2921, 2161, 2803, 18548, 2932, 28918, 2808, 2938, 35195, 2943}\n",
      "dict_items([(\"Lemma('measure.v.01.measure')\", 14), (\"Lemma('quantify.v.02.measure')\", 11), (\"Lemma('measure.v.04.measure')\", 3), (\"Lemma('measure.v.03.measure')\", 7)])\n",
      "collecting tokens for  liquid\n",
      "indices:    {29443, 28941, 11411, 3231, 4128, 3232, 3619, 4132, 3238, 3240, 4141, 3246, 3245, 19251, 3259, 3262, 3265, 3273, 3275, 3277, 3152, 17747, 36052, 14806, 3287, 14808, 14809, 14812, 14813, 3294, 14815, 14816, 8550, 28918, 12790, 3195, 28925}\n",
      "dict_items([(\"Lemma('liquid.n.02.liquid')\", 5), (\"Lemma('liquid.a.01.liquid')\", 15), (\"Lemma('liquid.n.01.liquid')\", 3), (\"Lemma('liquid.n.03.liquid')\", 3)])\n",
      "collecting tokens for  known\n",
      "indices:    {10754, 36867, 3590, 10251, 26646, 26652, 31260, 16929, 14884, 31783, 13356, 5167, 26672, 6210, 21063, 3149, 33358, 18001, 26706, 18003, 31321, 19547, 15965, 23133, 25695, 8801, 30306, 36449, 11876, 4197, 11877, 26722, 11886, 33902, 23665, 3700, 21109, 4214, 14453, 22654, 3204, 27786, 4747, 15505, 28307, 4243, 32412, 6814, 4257, 6824, 23721, 4778, 37039, 32436, 34485, 22199, 10423, 26807, 6843, 29373, 18621, 2241, 29382, 26311, 1230, 8914, 29915, 29917, 20702, 3293, 26339, 3814, 28903, 17646, 26353, 2802, 22779, 3841, 1282, 13570, 1288, 16141, 9997, 10511, 30482, 29971, 29973, 17685, 31512, 10521, 16666, 2333, 2846, 31009, 35108, 28456, 28457, 24368, 17713, 3377, 13617, 23858, 11061, 28470, 21826, 21827, 23877, 10056, 30538, 3919, 8538, 2395, 30554, 13661, 12638, 18276, 30568, 3945, 3437, 14190, 31087, 16753, 3954, 25459, 25464, 11128, 20347, 18301, 33153, 27522, 3461, 23946, 24464, 31633, 2963, 33171, 1433, 31129, 3491, 29093, 31142, 31653, 34734, 4017, 16819, 2484, 35259, 20417, 32195, 24531, 17876, 18905, 3038, 17382, 16873, 34798, 12277, 16383, 8696, 16377, 33275, 12284, 26111}\n",
      "dict_items([(\"Lemma('known.a.01.known')\", 26), (\"Lemma('know.v.03.know')\", 1), (\"Lemma('know.v.01.know')\", 26), (\"Lemma('know.v.05.know')\", 7), (\"Lemma('know.v.02.know')\", 14), (\"Lemma('know.v.04.know')\", 12), (\"Lemma('acknowledge.v.06.know')\", 4)])\n",
      "collecting tokens for  necessity\n",
      "indices:    {32004, 2055, 30482, 22804, 10004, 12314, 25244, 14877, 25506, 30499, 2085, 6824, 14385, 24764, 27715, 27594, 14676, 27096, 30813, 22878, 24157, 28512, 36202, 15473, 32755, 34679, 1275, 32511}\n",
      "dict_items([(\"Lemma('necessity.n.01.necessity')\", 8), (\"Lemma('necessity.n.02.necessity')\", 1)])\n",
      "collecting tokens for  remove\n",
      "indices:    {24164, 4486, 36966, 31304, 5354, 1680, 4177, 2193, 14998, 30198, 27898}\n",
      "dict_items([(\"Lemma('remove.v.01.remove')\", 11)])\n",
      "collecting tokens for  highway\n",
      "indices:    {48}\n",
      "dict_items([])\n",
      "collecting tokens for  agency\n",
      "indices:    {23670}\n",
      "dict_items([])\n",
      "collecting tokens for  government\n",
      "indices:    {21769, 25057}\n",
      "dict_items([])\n",
      "collecting tokens for  40000\n",
      "indices:    {14916, 25351, 21769, 3563, 32462, 11891, 25364, 25371}\n",
      "dict_items([])\n",
      "collecting tokens for  americans\n",
      "indices:    {24831}\n",
      "dict_items([])\n",
      "collecting tokens for  every\n",
      "indices:    {13601, 18149, 13447, 26448, 25528, 15738}\n",
      "dict_items([])\n",
      "collecting tokens for  destroying\n",
      "indices:    {3393, 26841, 28521, 28458, 27211, 12236, 22736, 25364, 13910, 25305, 28478}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('demolish.v.03.destroy')\", 1), (\"Lemma('destroy.v.01.destroy')\", 7), (\"Lemma('destroy.v.02.destroy')\", 3)])\n",
      "collecting tokens for  taxpayers\n",
      "indices:    {25088, 20192, 25090, 15555, 21604, 102, 20362, 21610, 25101, 24943, 16, 15599, 24178, 15579}\n",
      "dict_items([(\"Lemma('taxpayer.n.01.taxpayer')\", 5)])\n",
      "collecting tokens for  silly\n",
      "indices:    {36611, 16708, 22436, 16709, 23594, 8366, 36243, 25364, 16629, 26358, 10968, 10682}\n",
      "dict_items([(\"Lemma('cockamamie.s.01.silly')\", 5), (\"Lemma('airheaded.s.01.silly')\", 1)])\n",
      "collecting tokens for  heads\n",
      "indices:    {19333, 30214, 18698, 28939, 31372, 28940, 12564, 12567, 23834, 31774, 32680, 22191, 22585, 25274, 5951, 22595, 34764, 4819, 24020, 5846, 17238, 30305, 35557, 18541, 11119, 26870, 36728, 25337, 11133, 26878, 31487}\n",
      "dict_items([(\"Lemma('head.v.02.head')\", 2), (\"Lemma('head.n.01.head')\", 9), (\"Lemma('mind.n.01.head')\", 1)])\n",
      "collecting tokens for  group\n",
      "indices:    {32992, 32986, 3618, 22687}\n",
      "dict_items([(\"Lemma('group.n.01.group')\", 1)])\n",
      "collecting tokens for  building\n",
      "indices:    {32446}\n",
      "dict_items([])\n",
      "collecting tokens for  development\n",
      "indices:    {2728, 23605, 142}\n",
      "dict_items([(\"Lemma('development.n.01.development')\", 1)])\n",
      "collecting tokens for  industry\n",
      "indices:    {11654, 16275, 28695, 28700, 16286, 21922, 26284, 16305, 20405, 23481, 24634, 23487, 24896, 16328, 16334, 1113, 16356, 2418, 11896}\n",
      "dict_items([(\"Lemma('industry.n.01.industry')\", 7), (\"Lemma('industry.n.02.industry')\", 3)])\n",
      "collecting tokens for  raise\n",
      "indices:    {16386, 12164, 1674, 12172, 22797, 1553, 32149, 10290, 24245, 1592, 15042, 23619, 20039, 16328, 9289, 12117, 12118, 16345, 30938, 16348, 20708, 10597, 17002, 20714, 16109, 16366, 33139, 31862}\n",
      "dict_items([(\"Lemma('raise.v.02.raise')\", 3), (\"Lemma('raise.v.01.raise')\", 8), (\"Lemma('raise.v.04.raise')\", 3), (\"Lemma('lift.v.10.raise')\", 1), (\"Lemma('grow.v.07.raise')\", 6), (\"Lemma('rear.v.02.raise')\", 3)])\n",
      "collecting tokens for  support\n",
      "indices:    {22016, 23559, 31752, 31756, 31758, 4624, 27153, 31254, 23580, 4645, 24615, 22579, 24639, 25151, 69, 15446, 26198, 15450, 15458, 2148, 26725, 32870, 25190, 15465, 32874, 3691, 11882, 14954, 32878, 32367, 32881, 15475, 4723, 23671, 23672, 25219, 14983, 32913, 27284, 4758, 22679, 20634, 22683, 15005, 15009, 20646, 25768, 25772, 23726, 4784, 1201, 29361, 22707, 4788, 15047, 15049, 21706, 23756, 15052, 5324, 23760, 1234, 3810, 28387, 9954, 16103, 28396, 28397, 9967, 27889, 27890, 24821, 28920, 23289, 27898, 27899, 23809, 28418, 1803, 15635, 33043, 15637, 36652, 20272, 22853, 23881, 2377, 20299, 12620, 24909, 24910, 22862, 5465, 22874, 32097, 16232, 25448, 20846, 4990, 7552, 24962, 21892, 32134, 32137, 24970, 32655, 32657, 21908, 916, 6042, 32157, 23466, 16305, 2485, 16312, 9148, 32703, 24000, 4550, 32711, 32714, 4557, 23522, 14824, 32749, 25583, 33264, 28151}\n",
      "dict_items([(\"Lemma('support.v.02.support')\", 9), (\"Lemma('hold.v.10.support')\", 5), (\"Lemma('support.n.03.support')\", 4), (\"Lemma('support.v.01.support')\", 11), (\"Lemma('documentation.n.03.support')\", 3), (\"Lemma('back.v.01.support')\", 4), (\"Lemma('support.n.01.support')\", 15), (\"Lemma('support.n.08.support')\", 2), (\"Lemma('support.n.06.support')\", 2), (\"Lemma('support.n.02.support')\", 8), (\"Lemma('confirm.v.01.support')\", 2), (\"Lemma('corroborate.v.03.support')\", 1), (\"Lemma('subscribe.v.03.support')\", 1), (\"Lemma('defend.v.01.support')\", 1), (\"Lemma('accompaniment.n.02.support')\", 1), (\"Lemma('support.n.07.support')\", 1)])\n",
      "collecting tokens for  cultural\n",
      "indices:    {27840, 11234, 5026, 23876, 2056, 32944, 23569, 22515, 2323, 32948, 11260}\n",
      "dict_items([(\"Lemma('cultural.s.02.cultural')\", 1), (\"Lemma('cultural.a.01.cultural')\", 3), (\"Lemma('cultural.a.03.cultural')\", 1)])\n",
      "collecting tokens for  performing\n",
      "indices:    {26077, 195, 28484, 32136, 26408, 26573, 22191, 15549, 1210, 18811, 20285, 1950, 1951}\n",
      "dict_items([(\"Lemma('perform.v.03.perform')\", 4), (\"Lemma('perform.v.01.perform')\", 5), (\"Lemma('perform.v.02.perform')\", 2)])\n",
      "collecting tokens for  arts\n",
      "indices:    {26761}\n",
      "dict_items([])\n",
      "collecting tokens for  rural\n",
      "indices:    {21353, 59, 4604}\n",
      "dict_items([(\"Lemma('rural.a.01.rural')\", 1)])\n",
      "collecting tokens for  land\n",
      "indices:    {20728, 1120, 13700, 1894, 18250, 29240, 5418, 12782, 23761, 25362, 31409, 36436, 5489, 24887, 1944, 12121, 26618}\n",
      "dict_items([(\"Lemma('land.n.02.land')\", 2), (\"Lemma('country.n.02.land')\", 1), (\"Lemma('nation.n.02.land')\", 1), (\"Lemma('domain.n.02.land')\", 1), (\"Lemma('land.n.04.land')\", 1), (\"Lemma('land.n.01.land')\", 3)])\n",
      "collecting tokens for  study\n",
      "indices:    {21505, 15652, 14791, 33102, 5744, 32945, 27633, 29562, 6750}\n",
      "dict_items([(\"Lemma('analyze.v.01.study')\", 2), (\"Lemma('survey.n.01.study')\", 2), (\"Lemma('study.v.02.study')\", 1)])\n",
      "collecting tokens for  being\n",
      "indices:    {32385, 3464, 29965, 19343, 9362, 20119, 9881, 1819, 33054, 32041, 24367, 16182, 19831, 33090, 15701, 25941, 25309, 29024, 10848, 25700, 14954, 14966, 14455, 25465, 31870}\n",
      "dict_items([(\"Lemma('be.v.01.be')\", 2), (\"Lemma('be.v.03.be')\", 2)])\n",
      "collecting tokens for  carried\n",
      "indices:    {17931, 4619, 13851, 30236, 27688, 12845, 12334, 21042, 20530, 13877, 21054, 30271, 14419, 36451, 11391, 34948, 13976, 5788, 5789, 34978, 33957, 21163, 18095, 35509, 25781, 26293, 14522, 14017, 10435, 28874, 7890, 12505, 35044, 36069, 29926, 14059, 12525, 18673, 12028, 16124, 7422, 35072, 32519, 6921, 278, 33052, 12579, 33060, 33065, 33069, 7475, 8512, 33091, 33092, 31054, 6992, 12624, 15186, 33624, 34147, 34155, 32116, 27519, 19331, 18314, 14740, 32669, 22436, 32694, 22969, 10684, 9155, 36810, 9166, 7644, 13277, 28129, 3554, 1509, 3563, 14827, 23540, 7158}\n",
      "dict_items([(\"Lemma('transport.v.02.carry')\", 25), (\"Lemma('carry.v.09.carry')\", 2), (\"Lemma('carry.v.08.carry')\", 2), (\"Lemma('carry.v.02.carry')\", 13), (\"Lemma('carry.v.15.carry')\", 1), (\"Lemma('follow_through.v.02.carry_out')\", 1), (\"Lemma('impart.v.03.carry')\", 3), (\"Lemma('dribble.v.03.carry')\", 1)])\n",
      "collecting tokens for  contract\n",
      "indices:    {26384, 21522, 14099, 14100, 21530, 16667, 14748, 16671, 21161, 23606, 16453, 23877, 16455, 16454, 16456, 30541, 34382, 20686, 24912, 22094, 20687, 11736, 27748, 2790, 31596, 16635}\n",
      "dict_items([(\"Lemma('contract.n.01.contract')\", 8), (\"Lemma('contract.v.01.contract')\", 2)])\n",
      "collecting tokens for  rhode\n",
      "indices:    {164}\n",
      "dict_items([])\n",
      "collecting tokens for  agricultural\n",
      "indices:    {14721, 12165, 35526, 32135, 32520, 25736, 25738, 12459, 23211, 22795, 25740, 2728, 4624, 2774, 25560, 25563, 4604}\n",
      "dict_items([(\"Lemma('agricultural.a.01.agricultural')\", 6)])\n",
      "collecting tokens for  type\n",
      "indices:    {3844, 3974, 11145, 6793, 1815, 28961, 28712, 28714, 32563, 11707, 27073, 3274, 726, 4950, 31065, 14942, 24677, 14822, 21242, 2813}\n",
      "dict_items([(\"Lemma('type.n.01.type')\", 12)])\n",
      "collecting tokens for  playing\n",
      "indices:    {26628, 23072, 23079, 23080, 30256, 595, 26710, 18017, 1128, 13928, 26218, 13959, 26247, 37003, 8859, 26785, 682, 10943, 1728, 1735, 2251, 1740, 1741, 1746, 1747, 1750, 1756, 1757, 1759, 14560, 37115, 1790, 23300, 13584, 273, 37144, 23838, 10535, 36651, 12588, 36657, 6454, 26425, 26439, 26441, 33610, 27980, 19794, 6495, 26477, 22384, 31609, 26490, 34682, 9594, 22909, 9599, 22914, 25989, 11143, 394, 25994, 22925, 22928, 912, 15761, 20895, 27043, 26533, 15786, 26539, 22963, 442, 9659, 9663, 22980, 35785, 26572, 26575, 23005, 26589, 20967, 26604, 23029}\n",
      "dict_items([(\"Lemma('play.v.01.play')\", 21), (\"Lemma('act.v.03.play')\", 9), (\"Lemma('playing.n.01.playing')\", 10), (\"Lemma('play.v.05.play')\", 6), (\"Lemma('play.v.03.play')\", 10), (\"Lemma('play.v.02.play')\", 1), (\"Lemma('play.v.11.play')\", 2), (\"Lemma('play.v.07.play')\", 3), (\"Lemma('toy.v.02.play')\", 1), (\"Lemma('play.v.20.play')\", 1), (\"Lemma('dally.v.04.play')\", 1), (\"Lemma('play.v.10.play')\", 2), (\"Lemma('play.v.06.play')\", 2), (\"Lemma('play.v.12.play')\", 1), (\"Lemma('playing.n.02.playing')\", 1), (\"Lemma('play.v.15.play')\", 1)])\n",
      "collecting tokens for  actually\n",
      "indices:    {23629, 20853}\n",
      "dict_items([])\n",
      "collecting tokens for  mine\n",
      "indices:    {35939, 35028, 10404}\n",
      "dict_items([])\n",
      "collecting tokens for  scene\n",
      "indices:    {30080, 26659, 9731, 1062, 23274, 35918, 22705, 11294, 1054, 17023}\n",
      "dict_items([(\"Lemma('picture.n.04.scene')\", 1), (\"Lemma('view.n.02.scene')\", 1), (\"Lemma('scene.n.02.scene')\", 1), (\"Lemma('scene.n.06.scene')\", 1)])\n",
      "collecting tokens for  built\n",
      "indices:    {35332, 5133, 15119, 7951, 17424, 15122, 37138, 29972, 29333, 15124, 19864, 29337, 31522, 20132, 29989, 7590, 5415, 31528, 12468, 29373, 23360, 8393, 26446, 3151, 28753, 34897, 18517, 34271, 28640, 29923, 12515, 26979, 14691, 2411, 5485, 8687, 23151, 29937, 1397, 12026, 15099, 1917, 15102, 29951}\n",
      "dict_items([(\"Lemma('construct.v.01.build')\", 26), (\"Lemma('build.v.03.build')\", 1), (\"Lemma('built.s.01.built')\", 1), (\"Lemma('build_up.v.02.build')\", 1)])\n",
      "collecting tokens for  something\n",
      "indices:    {10694, 36942, 18895, 2190, 9204, 9949}\n",
      "dict_items([])\n",
      "collecting tokens for  pollen\n",
      "indices:    {3616, 25121, 3621, 3624, 3666, 3667, 36692, 3605, 3668, 3639}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('pollen.n.01.pollen')\", 8)])\n",
      "collecting tokens for  initiative\n",
      "indices:    {22658, 14213, 25610, 25612, 25613, 14228, 11673, 22683, 25632, 15398, 15400, 6061, 23998, 32591, 25810, 27879, 12012, 12526, 16239, 32503}\n",
      "dict_items([(\"Lemma('enterprise.n.03.initiative')\", 5), (\"Lemma('first_step.n.01.initiative')\", 4)])\n",
      "collecting tokens for  administration\n",
      "indices:    {24970, 20620, 32366}\n",
      "dict_items([])\n",
      "collecting tokens for  remain\n",
      "indices:    {2820, 36489, 23820, 34957, 11405, 31244, 28817, 4625, 13458, 22289, 7313, 4246, 4626, 29337, 7067, 14748, 5405, 8480, 6948, 2343, 3368, 3752, 7081, 14379, 30515, 1335, 21822, 1472, 17217, 11973, 3657, 23116, 2511, 26960, 17234, 11988, 11862, 34903, 25051, 2396, 32221, 13536, 1633, 16352, 24034, 36964, 28517, 23014, 16239, 16240, 2545, 11250, 28147, 2548, 11380, 3824, 32639, 892, 7037, 5630, 25599}\n",
      "dict_items([(\"Lemma('stay.v.01.remain')\", 26), (\"Lemma('stay.v.04.remain')\", 14), (\"Lemma('persist.v.03.remain')\", 2), (\"Lemma('remain.v.03.remain')\", 6)])\n",
      "collecting tokens for  local\n",
      "indices:    {10656, 10558, 28675, 16294, 27687, 5180, 15312, 16305, 13182, 147, 16304, 8245, 20337, 32375, 4988, 32478}\n",
      "dict_items([(\"Lemma('local.a.01.local')\", 3), (\"Lemma('local.n.01.local')\", 1)])\n",
      "collecting tokens for  districts\n",
      "indices:    {33028, 16263, 16264, 16265, 32523, 32525, 33038, 32529, 20626, 16281, 24609, 4777, 16303, 33072, 20789, 13239, 33079, 5474, 13296, 16241, 16243, 16245, 121}\n",
      "dict_items([(\"Lemma('district.n.01.district')\", 12)])\n",
      "collecting tokens for  winston\n",
      "indices:    {9465}\n",
      "dict_items([(\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  basket\n",
      "indices:    {9511, 9512, 36071, 36139, 16688, 7184, 17748, 29465, 697, 9533, 16702}\n",
      "dict_items([(\"Lemma('basket.n.01.basket')\", 6), (\"Lemma('wastepaper_basket.n.01.wastebasket')\", 1)])\n",
      "collecting tokens for  although\n",
      "indices:    {26873, 18723, 3678, 4921}\n",
      "dict_items([])\n",
      "collecting tokens for  breathing\n",
      "indices:    {33857, 34915, 27205, 25669, 1033, 34282, 32714, 11375, 16815, 10002, 10099, 34038, 17561, 18170, 8990}\n",
      "dict_items([(\"Lemma('breathing.n.01.breathing')\", 5), (\"Lemma('breathe.v.01.breathe')\", 4)])\n",
      "collecting tokens for  heavily\n",
      "indices:    {24449, 901, 262, 27017, 8603, 21405, 14242, 4784, 4788, 17589, 1344, 9425, 36306, 9945, 3811, 35430, 25575, 26874, 22654}\n",
      "dict_items([(\"Lemma('heavily.r.01.heavily')\", 11)])\n",
      "collecting tokens for  shayne\n",
      "indices:    {34027}\n",
      "dict_items([])\n",
      "collecting tokens for  either\n",
      "indices:    {26448, 4474}\n",
      "dict_items([])\n",
      "collecting tokens for  recognized\n",
      "indices:    {4611, 2180, 30979, 32132, 33033, 7178, 7179, 31114, 21390, 33811, 31765, 2586, 34844, 27550, 33055, 33440, 28575, 25506, 32175, 4016, 12214, 19005, 32957, 20298, 3147, 5324, 7117, 2128, 33745, 34772, 3414, 20569, 16345, 19419, 32379, 22751, 17375, 24418, 5091, 7012, 23779, 2151, 489, 759, 492, 11502, 31984, 24945, 31988, 501, 34038, 19444, 31989, 9850, 32251}\n",
      "dict_items([(\"Lemma('acknowledge.v.06.recognize')\", 16), (\"Lemma('spot.v.02.recognize')\", 7), (\"Lemma('recognize.v.02.recognize')\", 10), (\"Lemma('accepted.s.01.recognized')\", 3), (\"Lemma('recognize.v.04.recognize')\", 9), (\"Lemma('acknowledge.v.04.recognize')\", 2), (\"Lemma('greet.v.01.recognize')\", 2), (\"Lemma('accredit.v.01.recognize')\", 1)])\n",
      "collecting tokens for  describe\n",
      "indices:    {30853, 2825, 12044, 15889, 31249, 28820, 2582, 4375, 15007, 4384, 28710, 15663, 15937, 4929, 13636, 4421, 4942, 27982, 37072, 2639, 1618, 1506, 11117, 4465, 34038, 1785, 8702}\n",
      "dict_items([(\"Lemma('describe.v.01.describe')\", 19), (\"Lemma('report.v.01.describe')\", 7), (\"Lemma('identify.v.05.describe')\", 1)])\n",
      "collecting tokens for  come\n",
      "indices:    {13447, 9995, 29725, 10269, 10019, 17444, 8508, 30398, 35137, 13124, 30790, 30420, 30686, 13534, 30304, 1120, 36839, 28395, 31870}\n",
      "dict_items([(\"Lemma('arrive.v.01.come')\", 7), (\"Lemma('come.v.04.come')\", 1), (\"Lemma('come.v.01.come')\", 4), (\"Lemma('come.v.03.come')\", 2)])\n",
      "collecting tokens for  companion\n",
      "indices:    {36544, 10528, 19428, 23592, 33611, 33517, 34030, 6317, 2128, 13682, 17714, 28154, 21659, 12543}\n",
      "dict_items([(\"Lemma('companion.n.01.companion')\", 6), (\"Lemma('companion.n.02.companion')\", 1)])\n",
      "collecting tokens for  white\n",
      "indices:    {3609, 22501, 6037}\n",
      "dict_items([(\"Lemma('white.a.02.white')\", 1), (\"Lemma('white.n.02.white')\", 1)])\n",
      "collecting tokens for  former\n",
      "indices:    {31238, 31528, 9832, 24874, 3692, 13266, 14098, 884, 20312, 10744}\n",
      "dict_items([(\"Lemma('former.a.01.former')\", 4), (\"Lemma('former.s.03.former')\", 1)])\n",
      "collecting tokens for  appearance\n",
      "indices:    {30977, 7941, 27159, 36122, 36511, 290, 35750, 4906, 1835, 13628, 192, 18502, 34889, 3658, 19662, 16723, 26708, 2644, 4951, 15320, 17880, 30301, 24673, 13410, 1894, 4840, 29931, 31472, 5617, 13682, 29940, 5623, 32760, 6910}\n",
      "dict_items([(\"Lemma('appearance.n.01.appearance')\", 13), (\"Lemma('appearance.n.02.appearance')\", 4), (\"Lemma('appearance.n.03.appearance')\", 2), (\"Lemma('appearance.n.04.appearance')\", 1), (\"Lemma('appearance.n.05.appearance')\", 1)])\n",
      "collecting tokens for  newer\n",
      "indices:    {26980, 26568, 29097, 34287, 4784, 689, 13682, 24764, 28079, 21749, 15511, 15484, 11870}\n",
      "dict_items([(\"Lemma('new.a.01.new')\", 6)])\n",
      "collecting tokens for  felt\n",
      "indices:    {19969, 34820, 5639, 33276, 5652, 34838, 3096, 7192, 30234, 5659, 36896, 8737, 9248, 6176, 33829, 6182, 19498, 15402, 19501, 7215, 31793, 7222, 33334, 32312, 33849, 34878, 4671, 34879, 36418, 5703, 34381, 33357, 9303, 33370, 7772, 33885, 6241, 33378, 36450, 36964, 9314, 16492, 10863, 22640, 7794, 5752, 27768, 34938, 14459, 36476, 22653, 30332, 24188, 17029, 8843, 2189, 14478, 30351, 146, 23187, 30355, 36498, 35994, 16551, 31912, 7850, 2218, 2223, 23216, 19632, 9909, 34487, 23228, 6844, 17598, 27330, 5827, 7883, 18123, 36045, 17100, 8395, 37072, 37073, 19157, 9945, 5850, 18651, 18653, 5857, 5859, 4840, 33520, 6897, 34035, 22775, 16636, 1282, 32004, 34059, 37132, 10000, 10003, 10004, 28437, 6934, 19735, 34068, 26393, 36634, 6939, 36636, 36124, 17180, 10015, 14112, 10016, 5410, 30499, 16164, 6943, 35106, 20258, 37160, 34091, 19756, 36652, 34096, 4914, 9010, 33586, 34101, 34112, 7490, 7492, 20293, 8520, 22349, 36686, 33103, 35664, 20821, 35671, 19287, 22363, 27998, 7009, 30563, 25956, 33125, 25955, 36199, 10088, 24939, 7535, 35695, 32113, 28018, 9074, 7538, 13685, 35701, 18807, 35704, 33149, 33154, 15746, 15752, 8587, 17805, 11663, 33683, 35735, 18840, 33179, 9628, 33182, 27558, 12710, 9641, 31659, 35756, 9647, 5042, 15795, 35252, 15797, 12214, 9144, 8123, 21948, 19389, 6589, 7101, 4032, 32188, 22979, 13764, 16835, 8655, 35280, 8145, 6608, 36307, 15826, 2517, 33238, 33233, 8146, 36313, 15834, 33243, 18717, 12254, 33247, 6624, 8161, 17376, 7648, 36327, 25064, 35310, 25071, 26096, 13808, 17396, 33269, 7669, 22005, 16374, 10233, 31740, 7679}\n",
      "dict_items([(\"Lemma('feel.v.05.feel')\", 14), (\"Lemma('find.v.05.feel')\", 26), (\"Lemma('feel.v.03.feel')\", 26), (\"Lemma('feel.v.04.feel')\", 17), (\"Lemma('feel.v.01.feel')\", 26), (\"Lemma('feel.v.06.feel')\", 12), (\"Lemma('feel.v.07.feel')\", 5), (\"Lemma('palpate.v.01.feel')\", 2), (\"Lemma('feel.v.09.feel')\", 2), (\"Lemma('feel.v.08.feel')\", 2)])\n",
      "collecting tokens for  tired\n",
      "indices:    {36994, 5639, 19464, 35210, 26515, 7704, 11163, 2168, 8733, 23196, 22557, 24224, 19484, 24234, 19759, 34941, 36153, 7226, 14526, 25793, 17235, 11997, 6245, 35056, 7409, 241, 7792, 19700, 8436, 36088, 5882, 1661}\n",
      "dict_items([(\"Lemma('tire.v.01.tire')\", 3), (\"Lemma('tired.a.01.tired')\", 6), (\"Lemma('tire.v.02.tire')\", 2)])\n",
      "collecting tokens for  calm\n",
      "indices:    {26693}\n",
      "dict_items([])\n",
      "collecting tokens for  took\n",
      "indices:    {0, 22528, 31746, 17410, 11269, 9222, 8201, 12, 36877, 36878, 10769, 22545, 532, 1044, 30742, 19991, 36890, 1053, 21533, 35360, 6177, 18464, 8740, 26668, 25650, 9778, 16948, 30264, 9785, 2620, 10813, 9279, 36415, 19521, 16960, 10307, 12868, 23107, 20550, 34890, 22090, 17484, 1613, 7757, 12874, 18513, 22610, 9312, 23138, 21603, 11875, 34917, 11878, 12901, 7270, 14952, 10347, 24684, 35950, 27761, 21618, 27251, 35961, 1657, 14459, 36474, 25726, 23166, 24704, 34948, 27270, 7815, 30856, 16522, 14474, 33931, 4748, 9358, 7311, 10890, 4746, 10892, 24723, 10384, 36501, 23190, 8343, 23194, 36003, 23204, 36520, 10414, 4270, 7856, 8881, 19118, 30899, 27315, 27829, 6838, 14510, 17641, 9402, 22203, 35516, 17082, 191, 20672, 23235, 8902, 17095, 35529, 202, 14539, 27337, 31440, 9425, 21712, 4820, 30932, 11993, 23772, 18142, 23263, 7393, 2274, 5346, 19171, 23269, 21734, 8422, 19173, 33513, 5866, 18154, 13036, 23277, 19694, 4847, 18669, 10477, 18674, 31475, 18672, 5363, 29943, 18170, 11003, 5888, 4865, 9472, 26881, 23302, 23304, 11018, 18699, 9997, 21780, 36629, 16664, 17689, 21785, 7962, 9215, 18714, 29983, 5408, 23328, 28966, 34598, 23336, 20778, 12587, 26412, 7472, 7473, 37170, 34611, 24372, 18741, 18230, 36151, 16696, 13113, 20789, 17769, 26423, 21314, 19270, 12615, 17736, 24394, 18251, 2382, 19791, 21326, 10577, 30036, 34133, 30549, 10068, 6487, 34144, 7523, 36199, 28009, 11114, 9066, 17772, 17770, 31597, 364, 28010, 4977, 23922, 9585, 18292, 14196, 9583, 9591, 22392, 17787, 34171, 30591, 2431, 18817, 9092, 13702, 10631, 9094, 19338, 33163, 21388, 15759, 34704, 22416, 15248, 7058, 28052, 399, 28053, 27544, 23450, 27547, 28058, 28571, 9118, 17820, 34208, 6046, 17827, 21411, 33712, 1458, 36276, 34234, 11197, 14269, 36286, 11203, 455, 26571, 16844, 6605, 11216, 36817, 6610, 7633, 34260, 14290, 12247, 31705, 16858, 23515, 18395, 18905, 17378, 15338, 36331, 17391, 9200, 6128, 35311, 1523, 13812, 5623, 4782, 17917, 34303}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('take.v.04.take')\", 26), (\"Lemma('accept.v.02.take')\", 7), (\"Lemma('bring.v.01.take')\", 12), (\"Lemma('take.v.02.take')\", 26), (\"Lemma('receive.v.05.take_in')\", 1), (\"Lemma('lead.v.01.take')\", 16), (\"Lemma('film.v.01.take')\", 2), (\"Lemma('aim.v.01.take')\", 2), (\"Lemma('assume.v.03.take')\", 7), (\"Lemma('take.v.09.take')\", 8), (\"Lemma('take.v.01.take')\", 15), (\"Lemma('necessitate.v.01.take')\", 7), (\"Lemma('take.v.06.take')\", 4), (\"Lemma('take.v.08.take')\", 4), (\"Lemma('take_a_look.v.01.take_a_look')\", 3), (\"Lemma('choose.v.01.take')\", 3), (\"Lemma('form.v.03.take_form')\", 1), (\"Lemma('fill.v.04.take')\", 6), (\"Lemma('take.v.19.take')\", 4), (\"Lemma('take.v.15.take')\", 4), (\"Lemma('remove.v.01.take')\", 6), (\"Lemma('consume.v.02.take')\", 5), (\"Lemma('return.v.05.take_back')\", 2), (\"Lemma('take.v.27.take')\", 1), (\"Lemma('assume.v.05.take')\", 2), (\"Lemma('consider.v.03.take')\", 2), (\"Lemma('take.v.21.take')\", 3), (\"Lemma('breathe.v.01.take_a_breath')\", 2), (\"Lemma('take_pains.v.01.take_pains')\", 1), (\"Lemma('ask_out.v.01.take_out')\", 1), (\"Lemma('challenge.v.04.take_exception')\", 1), (\"Lemma('take_care.v.01.take_care')\", 1), (\"Lemma('take_off.v.03.take_off')\", 1), (\"Lemma('gamble.v.01.take_a_chance')\", 1), (\"Lemma('take.v.20.take')\", 2), (\"Lemma('take_in.v.01.take_in')\", 1), (\"Lemma('take.v.29.take')\", 1), (\"Lemma('lease.v.04.take')\", 1), (\"Lemma('take_away.v.01.take_away')\", 1), (\"Lemma('depart.v.04.take_leave')\", 1), (\"Lemma('take.v.24.take')\", 1)])\n",
      "collecting tokens for  doctor\n",
      "indices:    {27425, 20196, 9359, 9392, 30099, 2238}\n",
      "dict_items([(\"Lemma('doctor.n.01.doctor')\", 3)])\n",
      "collecting tokens for  nervous\n",
      "indices:    {16864, 36577, 4226, 20035, 10786, 28552, 26699, 36877, 2253, 2255, 2256, 2196, 24565, 36566, 9593, 27452, 11006}\n",
      "dict_items([(\"Lemma('nervous.s.01.nervous')\", 4)])\n",
      "collecting tokens for  care\n",
      "indices:    {37120, 24964, 9350, 36873, 33290, 13964, 32908, 9872, 36880, 13970, 31383, 10522, 669, 5661, 22558, 27425, 26785, 36004, 2342, 36521, 2217, 13355, 10413, 23214, 25139, 5178, 30394, 30399, 15424, 35907, 36293, 5702, 5703, 37065, 32714, 35531, 20172, 1997, 20173, 20174, 32848, 28625, 9047, 20185, 32858, 32859, 7899, 17371, 8411, 8923, 20192, 9442, 27110, 27111, 15463, 20199, 17002, 30059, 34026, 20716, 32878, 33647, 11761, 28532, 24949, 17788, 20221, 10622}\n",
      "dict_items([(\"Lemma('caution.n.03.care')\", 2), (\"Lemma('care.v.01.care')\", 26), (\"Lemma('wish.v.02.care')\", 2), (\"Lemma('care.n.06.care')\", 1), (\"Lemma('take_care.v.01.take_care')\", 1), (\"Lemma('care.v.02.care')\", 4)])\n",
      "collecting tokens for  appropriate\n",
      "indices:    {2309, 25094, 15241, 15242, 3468, 28943, 32917, 1305, 3493, 2598, 4268, 33072, 16309, 15930, 2118, 3913, 33233, 1362, 3033, 3293, 13663, 4580, 14949, 15340, 32877, 33400, 9596}\n",
      "dict_items([(\"Lemma('appropriate.a.01.appropriate')\", 17), (\"Lemma('allow.v.04.appropriate')\", 1), (\"Lemma('appropriate.v.02.appropriate')\", 1)])\n",
      "collecting tokens for  action\n",
      "indices:    {25475, 20227, 17924, 27786, 24845, 26775, 22807, 3225, 14746, 27801, 27804, 23710, 15393, 35491, 12325, 18480, 5937, 15412, 27958, 13634, 14786, 23364, 2123, 15443, 3158, 4695, 31961, 16346, 20058, 14942, 14048, 14950, 19441, 4727}\n",
      "dict_items([(\"Lemma('legal_action.n.01.action')\", 1), (\"Lemma('action.n.01.action')\", 12), (\"Lemma('military_action.n.01.action')\", 3), (\"Lemma('natural_process.n.01.action')\", 2), (\"Lemma('action.n.02.action')\", 2), (\"Lemma('action.n.07.action')\", 1)])\n",
      "collecting tokens for  handling\n",
      "indices:    {28544, 28705, 29071, 14519, 11674, 21370, 28703}\n",
      "dict_items([(\"Lemma('manage.v.02.handle')\", 3), (\"Lemma('handling.n.01.handling')\", 1)])\n",
      "collecting tokens for  forms\n",
      "indices:    {24577, 15880, 15881, 15882, 15885, 15887, 15890, 30739, 15891, 30745, 11291, 15902, 15906, 15915, 15916, 15919, 15921, 15922, 15926, 15931, 27708, 15936, 15937, 15943, 15945, 15948, 15950, 15951, 19535, 15955, 15956, 15958, 15959, 4699, 4708, 27242, 4206, 5236, 32374, 32376, 22153, 31899, 4255, 1719, 5829, 28370, 26323, 28385, 2792, 5360, 5371, 14591, 27398, 2321, 1311, 1314, 1318, 27432, 27433, 26429, 14655, 16194, 16196, 14663, 13642, 16207, 13654, 35674, 4956, 14177, 16227, 16228, 35686, 14200, 35707, 3471, 32145, 28058, 35747, 4008, 35753, 5032, 7607, 11232, 4580, 15856, 15858}\n",
      "dict_items([(\"Lemma('kind.n.01.form')\", 13), (\"Lemma('form.v.02.form')\", 1), (\"Lemma('form.n.01.form')\", 26), (\"Lemma('form.n.03.form')\", 8), (\"Lemma('shape.n.02.form')\", 4), (\"Lemma('form.n.09.form')\", 1), (\"Lemma('shape.n.01.form')\", 2), (\"Lemma('human_body.n.01.form')\", 1), (\"Lemma('form.v.03.form')\", 1), (\"Lemma('form.n.07.form')\", 1)])\n",
      "collecting tokens for  taken\n",
      "indices:    {37012, 20246, 12826, 21275, 5275, 6042, 34462, 26281, 21428, 2102, 16838, 20167, 3144, 21973, 6998, 17754, 2271, 14816, 3426, 31976, 21353, 2026, 25200, 29047, 7674}\n",
      "dict_items([(\"Lemma('consider.v.03.take')\", 1), (\"Lemma('consume.v.02.take')\", 1), (\"Lemma('take.v.21.take')\", 2), (\"Lemma('take.v.01.take')\", 3), (\"Lemma('take.v.04.take')\", 1), (\"Lemma('take_away.v.04.take_away')\", 1), (\"Lemma('take.v.08.take')\", 1), (\"Lemma('take_a_look.v.01.take_a_look')\", 1), (\"Lemma('lead.v.01.take')\", 1), (\"Lemma('take.v.02.take')\", 1), (\"Lemma('capitalize.v.01.take_advantage')\", 1), (\"Lemma('take.v.19.take')\", 1)])\n",
      "collecting tokens for  theirs\n",
      "indices:    {34027, 24332}\n",
      "dict_items([])\n",
      "collecting tokens for  storage\n",
      "indices:    {15874, 131, 15940, 29701, 29703, 5192, 29704, 29705, 15881, 29804, 32394, 1713, 15891, 5431, 14813}\n",
      "dict_items([(\"Lemma('storage.n.01.storage')\", 7), (\"Lemma('storage.n.03.storage')\", 1), (\"Lemma('storehouse.n.01.storage')\", 1)])\n",
      "collecting tokens for  plywood\n",
      "indices:    {29858, 29766, 29803, 29804, 28658, 29725, 29721, 29722, 29757}\n",
      "dict_items([])\n",
      "collecting tokens for  3000\n",
      "indices:    {11458, 11402, 28492, 29709, 29710, 21872, 27057, 12754, 24242, 27188, 14320, 28498, 29338, 22111}\n",
      "dict_items([])\n",
      "collecting tokens for  rubbed\n",
      "indices:    {33668, 36773, 34469, 9064, 24393, 7850, 33653, 29338, 35038}\n",
      "dict_items([(\"Lemma('rub.v.01.rub')\", 8), (\"Lemma('rub.v.02.rub')\", 1)])\n",
      "collecting tokens for  streets\n",
      "indices:    {29964, 6030, 25230, 7822, 24210, 26772, 29334, 9627, 25115, 36123, 13602, 10531, 12965, 20906, 21164, 2606, 7472, 10546, 6962, 25142, 6071, 25143, 18106, 30525, 22847, 21444, 18503, 21327, 6992, 21204, 21205, 22744, 29275, 7007, 13029, 13809, 10481, 21625, 7931, 7548}\n",
      "dict_items([(\"Lemma('street.n.01.street')\", 17), (\"Lemma('street.n.03.street')\", 2), (\"Lemma('street.n.02.street')\", 1)])\n",
      "collecting tokens for  ago\n",
      "indices:    {20993, 34305, 1031, 524, 10765, 30742, 2070, 25117, 27677, 34341, 26667, 14379, 2094, 9776, 31287, 2620, 573, 31809, 29249, 23107, 17990, 14407, 22600, 11334, 590, 10832, 10834, 14420, 10328, 19032, 25697, 27746, 10853, 21606, 31848, 4713, 18538, 34923, 23147, 10861, 32367, 26737, 35955, 32885, 24191, 11904, 11397, 25227, 28301, 2192, 28308, 35998, 25759, 12959, 28323, 21673, 683, 12972, 28334, 8367, 7344, 12977, 12979, 25269, 17080, 19131, 24768, 21185, 28354, 34497, 24260, 2246, 26825, 1227, 17614, 21711, 6867, 7893, 14044, 2268, 30943, 30945, 27362, 227, 28389, 2278, 1769, 32496, 21234, 762, 13052, 7425, 14084, 23300, 22280, 20234, 30996, 9492, 13078, 17686, 20761, 10013, 28959, 26912, 13602, 13603, 6438, 20270, 35118, 22321, 31538, 31539, 818, 27957, 27451, 25915, 30013, 28990, 12608, 27973, 14149, 20295, 31048, 23881, 5453, 22350, 1363, 22361, 20317, 24927, 1382, 21867, 13681, 10609, 24433, 11124, 1401, 9086, 24446, 13695, 29057, 25986, 28544, 21377, 35198, 1420, 10647, 14328, 36760, 3994, 13211, 22937, 11168, 34212, 10150, 10151, 13736, 31665, 14773, 13751, 11194, 13759, 28608, 35264, 31170, 27076, 13765, 24005, 32198, 17356, 26573, 21455, 21969, 9170, 31187, 24020, 13779, 28634, 13786, 31196, 22493, 26078, 31200, 28645, 493, 22000, 23028, 22005, 31222, 1527, 8696, 28667, 22524, 10749}\n",
      "dict_items([(\"Lemma('ago.r.01.ago')\", 26)])\n",
      "collecting tokens for  star\n",
      "indices:    {339, 23164, 7910}\n",
      "dict_items([(\"Lemma('ace.n.03.star')\", 1)])\n",
      "collecting tokens for  jazz\n",
      "indices:    {26401, 26419, 32036}\n",
      "dict_items([])\n",
      "collecting tokens for  range\n",
      "indices:    {17664, 2832, 2833, 29073, 15521, 11306, 3758, 34479, 21298, 12850, 697, 18246, 3914, 4312, 22617, 26077, 16104, 3177, 14825, 26347, 32509, 30199, 23288, 28667, 28669}\n",
      "dict_items([(\"Lemma('scope.n.01.range')\", 8), (\"Lemma('range.n.02.range')\", 1), (\"Lemma('range.n.03.range')\", 1), (\"Lemma('range.v.01.range')\", 1), (\"Lemma('range.n.05.range')\", 1)])\n",
      "collecting tokens for  styles\n",
      "indices:    {698, 689, 30124, 11244}\n",
      "dict_items([(\"Lemma('style.n.03.style')\", 2), (\"Lemma('expressive_style.n.01.style')\", 1)])\n",
      "collecting tokens for  values\n",
      "indices:    {30208, 14850, 16402, 11291, 16417, 11306, 4665, 4667, 13388, 4685, 4684, 4686, 4688, 4689, 4690, 4691, 3166, 4702, 4703, 4705, 3174, 4722, 32883, 36979, 4724, 27256, 26760, 32921, 3238, 1707, 32944, 1713, 28856, 4281, 4283, 28351, 27840, 27841, 32962, 32963, 27860, 25819, 32987, 32995, 27877, 27879, 27880, 27885, 14577, 3319, 1785, 14585, 14595, 27907, 4358, 3861, 32545, 31522, 31523, 1833, 3370, 3371, 3369, 5420, 15666, 3894, 1847, 3383, 16189, 33086, 1856, 3906, 3907, 5445, 3914, 1882, 16219, 1888, 13666, 1894, 4468, 31605, 4469, 4475, 4479, 2944, 4502, 4503, 34715, 4508, 15274, 4535, 9144, 4540, 4546, 4548, 4549, 4565, 14806, 4567, 4568, 4571, 4573, 3561, 14828, 14841}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('value.n.01.value')\", 26), (\"Lemma('values.n.01.values')\", 18), (\"Lemma('value.n.02.value')\", 12), (\"Lemma('value.n.04.value')\", 2), (\"Lemma('respect.v.01.value')\", 1), (\"Lemma('ethic.n.01.value-system')\", 1), (\"Lemma('value.n.03.value')\", 3)])\n",
      "collecting tokens for  temperature\n",
      "indices:    {2945, 5505, 2948, 2949, 2950, 2951, 2954, 2827, 2828, 2956, 2830, 2955, 30097, 30101, 13081, 2841, 2848, 1699, 1700, 2855, 1704, 10030, 14816, 2865, 2870, 3126, 4921, 3134, 2938, 5568, 3137, 3136, 3523, 3525, 27207, 1865, 3537, 1621, 2943, 14808, 3290, 2906, 3292, 14813, 3035, 2910, 30560, 11489, 2913, 15196, 3044, 30174, 3042, 30566, 30175, 14825, 14829, 30062, 2799, 2802, 14835, 2930, 2931, 1910, 2935, 2937, 2810, 2940, 14847}\n",
      "dict_items([(\"Lemma('temperature.n.01.temperature')\", 26), (\"Lemma('temperature.n.02.temperature')\", 1)])\n",
      "collecting tokens for  derived\n",
      "indices:    {21251, 3334, 25629, 3358, 3367, 3372, 3375, 3377, 3378, 3381, 3130, 3131, 3785, 31946, 3788, 2637, 26446, 14806, 15958, 14809, 28128, 31208, 2794, 10219, 25972, 3319, 3326}\n",
      "dict_items([(\"Lemma('derive.v.03.derive')\", 5), (\"Lemma('deduce.v.01.derive')\", 14), (\"Lemma('derive.v.02.derive')\", 4), (\"Lemma('derive.v.04.derive')\", 2), (\"Lemma('derived.a.01.derived')\", 1)])\n",
      "collecting tokens for  instrument\n",
      "indices:    {2432, 4773, 14822, 2985, 2986, 2988, 14316, 31439, 22416, 14836, 30232, 18745, 15165}\n",
      "dict_items([(\"Lemma('instrument.n.01.instrument')\", 6), (\"Lemma('instrument.n.02.instrument')\", 2)])\n",
      "collecting tokens for  compared\n",
      "indices:    {2951, 27818, 25972, 15926, 3225, 5310}\n",
      "dict_items([(\"Lemma('compare.v.01.compare')\", 5), (\"Lemma('compare.v.03.compare')\", 1)])\n",
      "collecting tokens for  associated\n",
      "indices:    {21698, 2661, 27562, 32715, 33260, 3386, 25294, 3119, 4207, 21907, 4476, 2234, 30811, 3484, 1791}\n",
      "dict_items([(\"Lemma('associate.v.01.associate')\", 5)])\n",
      "collecting tokens for  helium\n",
      "indices:    {14816, 14817, 14818, 14819, 34497, 14803, 14804, 14806, 14808, 14809, 14812, 14813, 14815}\n",
      "dict_items([(\"Lemma('helium.n.01.helium')\", 12)])\n",
      "collecting tokens for  4\n",
      "indices:    {21510, 14869, 4118, 24605, 14878, 4130, 28195, 14884, 14373, 14889, 12342, 1079, 28218, 58, 22588, 570, 24636, 28223, 1088, 25665, 3141, 590, 21583, 21584, 4177, 28754, 23637, 21589, 28760, 21593, 28250, 1633, 24673, 28771, 613, 28780, 620, 22641, 28794, 1658, 28802, 28806, 135, 28808, 11402, 138, 29323, 143, 656, 657, 28824, 11931, 156, 2717, 15516, 3744, 29349, 3763, 15027, 15548, 20168, 15561, 32974, 15567, 4305, 28883, 15070, 15072, 15073, 15075, 3301, 25835, 20203, 12526, 21230, 25843, 29943, 26886, 22286, 21774, 26384, 25359, 3858, 26386, 22292, 23325, 16163, 16167, 16168, 15146, 4397, 16175, 3888, 30513, 3890, 29492, 3898, 29498, 3900, 16189, 16192, 4420, 20806, 3910, 11591, 22345, 20810, 11595, 11596, 20813, 29517, 3920, 3410, 29522, 11602, 29524, 29532, 15709, 22364, 23391, 29536, 23393, 23395, 21351, 22376, 4460, 25965, 5487, 29040, 29039, 25970, 32627, 5493, 20855, 5495, 26491, 5502, 12671, 29568, 2946, 2948, 390, 5511, 29574, 2955, 16268, 29581, 5515, 28567, 14749, 419, 22948, 28579, 29607, 939, 21931, 21935, 27568, 33199, 28591, 4020, 951, 28601, 956, 22973, 22983, 22985, 22987, 16332, 22988, 3535, 15314, 14803, 5588, 22995, 14806, 24026, 4059, 24030, 12769, 20967, 22506, 3569, 30194, 30195, 1529, 3580}\n",
      "dict_items([(\"Lemma('four.n.01.4')\", 11), (\"Lemma('four.s.01.4')\", 26), (\"Lemma('fourth.s.01.fourth')\", 1), (\"Lemma('fourth.s.01.4th')\", 1)])\n",
      "collecting tokens for  vapor\n",
      "indices:    {3104, 14817, 14818, 14816, 11499, 14797, 4145, 14806, 14809, 14815}\n",
      "dict_items([(\"Lemma('vaporization.n.02.vapor')\", 1), (\"Lemma('vapor.n.01.vapor')\", 2)])\n",
      "collecting tokens for  pressures\n",
      "indices:    {2971, 25759, 23969, 2978, 2984, 2985, 12996, 16328, 26699, 14806, 32986, 16347, 14815, 22623, 14817, 16355, 25572, 14824, 14825, 11628, 3827, 34676, 37117, 893, 11263}\n",
      "dict_items([(\"Lemma('pressure.n.02.pressure')\", 7), (\"Lemma('pressure.n.01.pressure')\", 8)])\n",
      "collecting tokens for  differences\n",
      "indices:    {12288, 15012, 4648, 33066, 16087, 27278, 15695, 30832, 14638, 3889, 16179, 3796, 3797, 4246, 31991, 16086, 3165}\n",
      "dict_items([(\"Lemma('difference.n.01.difference')\", 8), (\"Lemma('deviation.n.01.difference')\", 3)])\n",
      "collecting tokens for  7\n",
      "indices:    {20482, 12805, 12808, 12813, 28180, 21015, 12833, 12836, 12837, 14886, 14890, 4141, 12854, 5176, 12856, 28218, 12867, 28234, 587, 21583, 28752, 592, 28754, 30297, 24162, 28776, 618, 28268, 12910, 29295, 28783, 623, 28789, 7292, 28796, 28799, 28803, 28810, 30355, 28823, 28827, 11424, 11425, 21666, 675, 21668, 11937, 3763, 15033, 5308, 17604, 12998, 20683, 27341, 13021, 15085, 240, 28913, 22789, 21774, 23313, 3345, 7960, 21275, 296, 23337, 3381, 16183, 11576, 16189, 16192, 328, 20809, 25934, 1362, 22368, 353, 4451, 22371, 4455, 22375, 16232, 22377, 16234, 32630, 15226, 15229, 15231, 27011, 15238, 2956, 28580, 25003, 21931, 27567, 9655, 30138, 24007, 22988, 3541, 14806, 10713, 11747, 16368, 20979}\n",
      "dict_items([(\"Lemma('seven.s.01.7')\", 22), (\"Lemma('seven.n.01.7')\", 3)])\n",
      "collecting tokens for  respectively\n",
      "indices:    {32776, 4491, 11035, 29090, 3882, 16176, 16177, 4274, 4276, 3894, 2237, 29129, 15052, 4564, 32341, 14806, 4565, 4061, 23679, 3569, 15474, 4475, 3583}\n",
      "dict_items([(\"Lemma('respectively.r.01.respectively')\", 18)])\n",
      "collecting tokens for  replied\n",
      "indices:    {28160, 18688, 26884, 10630, 8344, 10671, 31667, 24756, 22582, 20152, 10701, 35535, 15829, 15833, 20697, 15855, 20852, 12023, 19578}\n",
      "dict_items([(\"Lemma('answer.v.01.reply')\", 19)])\n",
      "collecting tokens for  helva\n",
      "indices:    {34732}\n",
      "dict_items([])\n",
      "collecting tokens for  outside\n",
      "indices:    {31172, 15077, 23752, 29647, 16304, 35288, 9401, 16410, 33820}\n",
      "dict_items([(\"Lemma('outside.a.01.outside')\", 1), (\"Lemma('external.s.02.outside')\", 1)])\n",
      "collecting tokens for  hospital\n",
      "indices:    {20196, 21445, 36436, 8245, 21210}\n",
      "dict_items([(\"Lemma('hospital.n.01.hospital')\", 1)])\n",
      "collecting tokens for  diagnostic\n",
      "indices:    {32742, 31051, 32876, 32879, 2260, 30232, 32892, 20189}\n",
      "dict_items([(\"Lemma('diagnostic.a.01.diagnostic')\", 1)])\n",
      "collecting tokens for  service\n",
      "indices:    {27073, 15591}\n",
      "dict_items([])\n",
      "collecting tokens for  costs\n",
      "indices:    {15489, 23410, 37108, 15478, 15003}\n",
      "dict_items([(\"Lemma('cost.n.01.cost')\", 2)])\n",
      "collecting tokens for  excess\n",
      "indices:    {28804, 15623, 22045, 29601, 2864, 32434, 5559, 29623, 3256, 24892, 27196, 29886, 15041, 29764, 11205, 27205, 8777, 29642, 11732, 22747, 20189, 32349, 1889, 37093, 26342, 29797, 29553, 2550, 28797}\n",
      "dict_items([(\"Lemma('excess.n.01.excess')\", 4), (\"Lemma('excess.n.02.excess')\", 1), (\"Lemma('excess.s.01.excess')\", 4)])\n",
      "collecting tokens for  20\n",
      "indices:    {4126, 4132, 21560, 27195, 21572, 11336, 27226, 28255, 25695, 13922, 11365, 20590, 28783, 22642, 24695, 30843, 22140, 13953, 28292, 23173, 29322, 29324, 3725, 21657, 3738, 3755, 30387, 22202, 3264, 3272, 15562, 15563, 20173, 20189, 21730, 30948, 12522, 20214, 21754, 15100, 12028, 15103, 15622, 11532, 12046, 21264, 3858, 275, 21270, 27417, 11546, 33053, 11551, 13091, 23843, 2853, 25383, 22314, 16176, 817, 22833, 25397, 22860, 21327, 31055, 29528, 11620, 29039, 28528, 1393, 29041, 21883, 32640, 29057, 29058, 22405, 32649, 30113, 23973, 21415, 21416, 4015, 33203, 5557, 28598, 12730, 29116, 4032, 29120, 29122, 22465, 25026, 29125, 26567, 29129, 30156, 3534, 3535, 4047, 14802, 21978, 15328, 21985, 3560, 21999, 504, 11257, 22011, 11263}\n",
      "dict_items([(\"Lemma('twenty.s.01.20')\", 26), (\"Lemma('twenty.n.01.20')\", 2), (\"Lemma('twentieth.s.01.20th')\", 1)])\n",
      "collecting tokens for  patient\n",
      "indices:    {23562, 33291, 30238, 30240, 30241, 30242, 30243, 30244, 30247, 13866, 30257, 30258, 30265, 33357, 23636, 33365, 23638, 30827, 11375, 11377, 11397, 11402, 11405, 2192, 11424, 25772, 30416, 27352, 2265, 2266, 20186, 20188, 20189, 20198, 37120, 4907, 20780, 4915, 4919, 4922, 4923, 4925, 4927, 4928, 4929, 4930, 4931, 4933, 4940, 4941, 4950, 4954, 4956, 4958, 4960, 4961, 4962, 3948, 24955, 34684, 24957, 24958, 24959, 8610, 4019, 4020, 4024, 4030, 4032, 8642, 4035, 15823, 4048, 28624, 4050, 28626, 4059, 15840, 15841, 15842, 15844, 15845, 15849, 15850, 15855, 15857, 15858, 15861, 15865}\n",
      "dict_items([(\"Lemma('patient.n.01.patient')\", 26), (\"Lemma('patient.a.01.patient')\", 3)])\n",
      "collecting tokens for  faithful\n",
      "indices:    {832, 1187, 1347, 28171, 25749, 1335}\n",
      "dict_items([(\"Lemma('faithful.a.01.faithful')\", 4)])\n",
      "collecting tokens for  excited\n",
      "indices:    {13026, 35717, 30408, 11402, 4203, 6027, 28174, 34511, 6773, 8725, 10742, 34008, 31674, 10460, 9597, 34046}\n",
      "dict_items([(\"Lemma('stimulate.v.01.excite')\", 3), (\"Lemma('excite.v.01.excite')\", 5), (\"Lemma('excited.a.02.excited')\", 2), (\"Lemma('aroused.s.06.excited')\", 2)])\n",
      "collecting tokens for  holy\n",
      "indices:    {1434}\n",
      "dict_items([])\n",
      "collecting tokens for  scriptures\n",
      "indices:    {6452}\n",
      "dict_items([(\"Lemma('bible.n.01.Scripture')\", 1)])\n",
      "collecting tokens for  sources\n",
      "indices:    {14721, 2819, 27525, 30470, 30473, 28174, 4622, 14098, 27923, 2718, 31263, 21407, 26784, 15399, 25640, 28082, 31797, 15166, 2751, 33089, 2498, 31299, 2754, 14790, 14792, 30282, 2645, 28886, 1237, 31705, 11740, 16350, 11358, 2784, 2783, 11362, 27884, 13678, 1902, 2801, 3314, 2804, 3061, 15094, 3323}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('beginning.n.04.source')\", 13), (\"Lemma('source.n.03.source')\", 2), (\"Lemma('source.n.02.source')\", 5), (\"Lemma('source.n.04.source')\", 4), (\"Lemma('informant.n.01.source')\", 1)])\n",
      "collecting tokens for  ought\n",
      "indices:    {12930, 22419, 36883, 1175, 12952, 10016, 16418, 18341, 36140, 36273, 10931, 9523, 6069, 36160, 1217, 26182, 27847, 12233, 17097, 24144, 10327, 13276, 13281, 19555, 19564, 17269, 10361, 10363, 35710}\n",
      "dict_items([])\n",
      "collecting tokens for  open\n",
      "indices:    {28576, 7520, 3714, 9120, 5959, 15336, 10958, 17588, 8245, 6683}\n",
      "dict_items([(\"Lemma('open.a.02.open')\", 3), (\"Lemma('open.s.06.open')\", 1), (\"Lemma('open.a.01.open')\", 1), (\"Lemma('open.a.05.open')\", 1)])\n",
      "collecting tokens for  everyone\n",
      "indices:    {25603, 18215, 1255}\n",
      "dict_items([])\n",
      "collecting tokens for  draw\n",
      "indices:    {28800, 18661, 30670, 11281, 29682, 12915}\n",
      "dict_items([(\"Lemma('draw.n.01.draw')\", 1), (\"Lemma('pull.v.01.draw')\", 2), (\"Lemma('trace.v.02.draw')\", 1), (\"Lemma('draw.v.19.draw')\", 1), (\"Lemma('draw.v.06.draw')\", 1)])\n",
      "collecting tokens for  purity\n",
      "indices:    {28129, 13956, 30057, 26314, 3245, 28174, 25554, 14456, 31545, 19610, 27035}\n",
      "dict_items([(\"Lemma('purity.n.01.purity')\", 3), (\"Lemma('purity.n.02.purity')\", 1)])\n",
      "collecting tokens for  errors\n",
      "indices:    {27105, 2849, 20259, 2832, 15796, 21945}\n",
      "dict_items([(\"Lemma('mistake.n.01.error')\", 1), (\"Lemma('erroneousness.n.01.error')\", 2)])\n",
      "collecting tokens for  royal\n",
      "indices:    {19335, 29039}\n",
      "dict_items([])\n",
      "collecting tokens for  informed\n",
      "indices:    {7296, 2188, 23565, 12558, 21390, 9617, 2195, 23573, 2202, 12570, 34588, 19357, 23331, 292, 31780, 5157, 33196, 9855, 35888, 33203, 1972, 14261, 2100, 20277, 20797, 33220, 33221, 5068, 32716, 24143, 26837, 33245, 35677, 25063, 232, 17385, 33260, 14318, 33262, 9329, 36851, 115, 27640, 34682, 14335}\n",
      "dict_items([(\"Lemma('inform.v.01.inform')\", 26), (\"Lemma('informed.a.01.informed')\", 2)])\n",
      "collecting tokens for  among\n",
      "indices:    {32992, 15012, 30888, 34922, 13976, 23981, 32503, 12952, 36570, 380, 10269}\n",
      "dict_items([])\n",
      "collecting tokens for  conference\n",
      "indices:    {23751, 23752, 22601, 25941, 32478}\n",
      "dict_items([])\n",
      "collecting tokens for  top\n",
      "indices:    {6658, 7170, 33928, 22154, 3856, 12818, 13586, 661, 35617, 15397, 33578, 22828, 35629, 26415, 1970, 20919, 29629, 12353, 3142, 3144, 3914, 6733, 339, 12767, 18534, 29800, 20084, 12660}\n",
      "dict_items([(\"Lemma('top.n.01.top')\", 6), (\"Lemma('top.a.01.top')\", 2), (\"Lemma('peak.n.04.top')\", 1), (\"Lemma('top.n.02.top')\", 4)])\n",
      "collecting tokens for  rushing\n",
      "indices:    {13088, 352, 353, 355, 292, 289, 9391, 35353, 35547}\n",
      "dict_items([(\"Lemma('rush.v.01.rush')\", 1), (\"Lemma('rush.n.07.rushing')\", 5), (\"Lemma('rush.v.02.rush')\", 1), (\"Lemma('rush.v.03.rush')\", 1)])\n",
      "collecting tokens for  won't\n",
      "indices:    {7714, 292, 9060, 582, 806, 8328, 813, 8525, 6415, 8754, 2675, 10614, 10937, 954, 794, 8317, 34270}\n",
      "dict_items([])\n",
      "collecting tokens for  mercer\n",
      "indices:    {14507}\n",
      "dict_items([(\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  read\n",
      "indices:    {5216, 13601, 31650, 27459, 29675, 16333}\n",
      "dict_items([(\"Lemma('read.v.01.read')\", 4), (\"Lemma('read.v.02.read')\", 1)])\n",
      "collecting tokens for  tell\n",
      "indices:    {865, 8901, 8262}\n",
      "dict_items([(\"Lemma('tell.v.03.tell')\", 1), (\"Lemma('tell.v.05.tell')\", 1)])\n",
      "collecting tokens for  killpath\n",
      "indices:    {17664}\n",
      "dict_items([])\n",
      "collecting tokens for  leaned\n",
      "indices:    {17665, 17028, 34949, 18950, 34948, 29199, 23830, 6301, 36646, 17578, 12974, 17584, 20145, 35380, 8629, 10569, 19409, 8537, 19934, 17632, 17253, 7018, 17646, 36590, 6386, 20084}\n",
      "dict_items([(\"Lemma('lean.v.01.lean')\", 14), (\"Lemma('tend.v.01.lean')\", 2), (\"Lemma('lean.v.02.lean')\", 3)])\n",
      "collecting tokens for  foot\n",
      "indices:    {22274, 391, 267, 2194, 2196, 11542, 17687, 11544, 36122, 3872, 5809, 22961, 29105, 193, 28498, 7253, 9182, 5729, 7777, 29690, 3707, 29692}\n",
      "dict_items([(\"Lemma('foot.n.02.foot')\", 5), (\"Lemma('foot.n.01.foot')\", 6), (\"Lemma('foot.n.07.foot')\", 1), (\"Lemma('foot.n.03.foot')\", 1)])\n",
      "collecting tokens for  slipped\n",
      "indices:    {18306, 19080, 35978, 33429, 13845, 36017, 30899, 35636, 35131, 5059, 7109, 35784, 4937, 35662, 35666, 13012, 6485, 23386, 23902, 17632, 36323, 15077, 8302, 9841}\n",
      "dict_items([(\"Lemma('skid.v.04.slip')\", 5), (\"Lemma('slip.v.04.slip')\", 3), (\"Lemma('steal.v.02.slip')\", 8), (\"Lemma('slip.v.02.slip')\", 4), (\"Lemma('slip.v.05.slip')\", 1), (\"Lemma('slip_on.v.01.slip_on')\", 1), (\"Lemma('err.v.01.slip')\", 1)])\n",
      "collecting tokens for  chair\n",
      "indices:    {25722, 17159, 12810, 7058, 37138, 8340, 5908, 5654, 20123, 35104, 6049, 34211, 35749, 26918, 35109, 8103, 34983, 7856, 1968, 1970, 17598, 16832, 26951, 11466, 17610, 16844, 11470, 5199, 9812, 21981, 36318, 8670, 17632, 7264, 5603, 15972, 16997, 15846, 1003, 7404, 7405, 7406, 7407, 8814, 8694, 32248, 8826}\n",
      "dict_items([(\"Lemma('chair.n.01.chair')\", 26), (\"Lemma('professorship.n.01.chair')\", 2)])\n",
      "collecting tokens for  put\n",
      "indices:    {25230, 23311, 6547, 20627, 1308, 31397, 16422, 34983, 9132, 15156, 1716, 33589, 13759, 12358, 33368, 16857, 29675, 17644, 1646, 25200, 881, 14453}\n",
      "dict_items([(\"Lemma('put.v.01.put')\", 9), (\"Lemma('put.v.02.put')\", 7), (\"Lemma('lay.v.02.put_down')\", 1)])\n",
      "collecting tokens for  again\n",
      "indices:    {6336, 5824, 27521, 35141, 18215, 36939, 36780, 13739, 6126, 12881, 25430, 19990, 7163, 3582}\n",
      "dict_items([(\"Lemma('again.r.01.again')\", 8)])\n",
      "collecting tokens for  frowning\n",
      "indices:    {17724, 9517}\n",
      "dict_items([(\"Lemma('frown.v.01.frown')\", 2)])\n",
      "collecting tokens for  tried\n",
      "indices:    {1030, 5642, 35346, 535, 34839, 7703, 543, 544, 8736, 19492, 18474, 15414, 8251, 20035, 6731, 2639, 25168, 21074, 34398, 8806, 12906, 34923, 17009, 10354, 10356, 14452, 23161, 31356, 17028, 12433, 5272, 36506, 10907, 12443, 36001, 6309, 6312, 22187, 21676, 17584, 24753, 5813, 20666, 6847, 24263, 33480, 204, 22233, 36061, 36579, 37117, 36101, 17158, 34061, 26384, 24853, 30487, 8472, 5914, 283, 16669, 7453, 23329, 5410, 35108, 21291, 26412, 26414, 6960, 18226, 11067, 35132, 35133, 7998, 35134, 17723, 27474, 31060, 6997, 8534, 21336, 17755, 17761, 21347, 7014, 9062, 35696, 8570, 15740, 10119, 36231, 36233, 15754, 27532, 16797, 16800, 6562, 29096, 14253, 28599, 19384, 33213, 6597, 33228, 26573, 6102, 5081, 35292, 25568, 34785, 21475, 30692, 5607, 16873, 11244, 34801, 16884, 34293, 7671, 7675}\n",
      "dict_items([(\"Lemma('test.v.01.try')\", 6), (\"Lemma('try.v.01.try')\", 26), (\"Lemma('judge.v.05.try')\", 4), (\"Lemma('sample.v.01.try')\", 1), (\"Lemma('test.v.01.try_out')\", 1)])\n",
      "collecting tokens for  reach\n",
      "indices:    {15104, 13569, 22018, 14594, 7558, 13318, 13576, 27142, 17542, 35341, 35342, 8590, 23316, 3732, 21656, 33181, 798, 19357, 21920, 17827, 31910, 34086, 25638, 21673, 29999, 18352, 32431, 12722, 9906, 36021, 18870, 33847, 7991, 7998, 15551, 12480, 33858, 35266, 21705, 33866, 32462, 7119, 18383, 7125, 5848, 21336, 2909, 26719, 10848, 6754, 25699, 17763, 32101, 25316, 16360, 3304, 17128, 8936, 10604, 23533, 11884, 3311, 36333, 33018, 3698, 13559, 18425, 26746, 27003, 26492, 1022, 29434}\n",
      "dict_items([(\"Lemma('range.n.02.reach')\", 1), (\"Lemma('reach.v.04.reach')\", 9), (\"Lemma('reach.v.01.reach')\", 25), (\"Lemma('compass.n.03.reach')\", 1), (\"Lemma('reach.v.02.reach')\", 7), (\"Lemma('reach.n.03.reach')\", 2), (\"Lemma('reach.v.06.reach')\", 4), (\"Lemma('reach.v.07.reach')\", 3), (\"Lemma('reach.v.03.reach')\", 6), (\"Lemma('scope.n.01.reach')\", 2), (\"Lemma('achieve.v.01.reach')\", 5)])\n",
      "collecting tokens for  never\n",
      "indices:    {8074, 36875, 10340, 9204}\n",
      "dict_items([(\"Lemma('never.r.01.never')\", 2)])\n",
      "collecting tokens for  knew\n",
      "indices:    {25600, 35840, 15362, 30208, 7684, 19460, 35846, 19462, 8712, 35848, 27140, 34312, 12812, 12813, 11270, 9231, 7185, 16914, 35858, 34836, 7702, 16919, 12825, 36378, 12827, 17402, 6180, 33829, 19496, 36904, 16901, 10794, 8236, 558, 6195, 36407, 22584, 8250, 12860, 8254, 6719, 20032, 26693, 9287, 5703, 8776, 1541, 35915, 33356, 12875, 33358, 33361, 22611, 30293, 16471, 36952, 30299, 7771, 17501, 13405, 16479, 12384, 6241, 35938, 23647, 16480, 20070, 33383, 30311, 6249, 16488, 18024, 6256, 17013, 35959, 24184, 20089, 16506, 35962, 7290, 19461, 12414, 634, 16512, 16003, 34436, 12422, 34439, 5773, 7824, 37011, 8853, 2197, 5783, 6822, 35494, 17582, 20143, 36527, 19123, 7862, 34487, 6840, 9403, 9407, 33472, 7360, 18630, 35015, 9932, 18637, 36046, 19152, 6147, 17618, 21718, 10970, 8412, 20701, 17122, 5861, 8935, 17643, 8939, 33518, 24302, 30961, 17650, 28401, 35065, 9979, 18693, 9992, 6925, 34576, 19217, 9490, 17682, 34068, 28434, 9491, 27928, 16665, 27933, 27934, 16671, 34079, 34601, 17710, 10543, 5934, 33586, 17204, 31543, 21817, 7998, 10059, 33612, 18252, 10576, 17744, 17746, 1371, 8031, 18783, 10597, 10601, 10602, 17769, 27502, 35694, 9583, 9590, 36215, 12663, 31097, 9084, 33148, 21382, 22929, 9617, 16785, 12693, 6037, 15770, 7073, 17829, 16809, 35754, 11183, 7089, 19379, 18867, 19381, 36276, 18868, 17847, 22971, 35259, 17340, 19390, 28608, 6599, 36299, 7628, 22989, 36813, 7118, 8147, 17879, 12249, 19418, 16859, 10204, 19421, 9184, 16867, 7141, 7142, 15336, 9193, 8682, 33258, 34798, 7663, 10223, 7665, 17907, 16886, 33275, 7673, 33274, 28155}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('know.v.02.know')\", 26), (\"Lemma('know.v.01.know')\", 26), (\"Lemma('know.v.03.know')\", 26), (\"Lemma('know.v.04.know')\", 12), (\"Lemma('know.v.05.know')\", 5), (\"Lemma('acknowledge.v.06.know')\", 2)])\n",
      "collecting tokens for  lieutenant\n",
      "indices:    {12871}\n",
      "dict_items([])\n",
      "collecting tokens for  spotted\n",
      "indices:    {21217, 18819, 18724, 18759, 22954, 22093, 18638, 19151, 5047, 17491, 309, 9846, 19126}\n",
      "dict_items([(\"Lemma('descry.v.01.spot')\", 13)])\n",
      "collecting tokens for  shell\n",
      "indices:    {34753, 34755, 13575}\n",
      "dict_items([(\"Lemma('carapace.n.01.shell')\", 1)])\n",
      "collecting tokens for  walked\n",
      "indices:    {35331, 23044, 33803, 7695, 7700, 8728, 8253, 16961, 8260, 33354, 23115, 36434, 17493, 6234, 7268, 8815, 19056, 13423, 10873, 33406, 33416, 34952, 17545, 33420, 8845, 35985, 28306, 27281, 33428, 5780, 33429, 34969, 35994, 35485, 36000, 7333, 17065, 29355, 17584, 19126, 29369, 36026, 29374, 5824, 22213, 29382, 29389, 33998, 22223, 29393, 13523, 29395, 24790, 29403, 34524, 7396, 34025, 31467, 17136, 6916, 7942, 17160, 17674, 33553, 36628, 9493, 13593, 36634, 19748, 7461, 24367, 34608, 28978, 8504, 36674, 34646, 12631, 34136, 36713, 362, 19308, 366, 17776, 19836, 22913, 28545, 12681, 24468, 408, 16795, 16797, 36768, 35746, 10663, 6582, 16822, 9146, 19397, 17862, 9183, 34274, 35811, 9188, 36844, 34287, 36340, 16890}\n",
      "dict_items([(\"Lemma('walk.v.01.walk')\", 26), (\"Lemma('walk.v.02.walk')\", 2), (\"Lemma('walk.v.03.walk')\", 2)])\n",
      "collecting tokens for  main\n",
      "indices:    {23810, 31235, 12933, 17926, 4880, 36885, 16023, 2845, 2855, 15402, 28720, 27186, 9396, 11453, 36424, 12881, 14803, 33364, 21205, 35288, 25057, 11234, 13030, 32494, 6389, 36730}\n",
      "dict_items([(\"Lemma('chief.s.01.main')\", 12)])\n",
      "collecting tokens for  viet\n",
      "indices:    {21405}\n",
      "dict_items([])\n",
      "collecting tokens for  nam\n",
      "indices:    {21405}\n",
      "dict_items([])\n",
      "collecting tokens for  rice\n",
      "indices:    {316}\n",
      "dict_items([(\"Lemma('group.n.01.group')\", 1)])\n",
      "collecting tokens for  surplus\n",
      "indices:    {11907, 25481, 16269, 16271, 16280, 16281, 27167, 16288, 16289, 2736, 2739, 20405, 24247, 2745, 2746, 24134, 23629, 5199, 12125, 992, 31203}\n",
      "dict_items([(\"Lemma('excess.s.01.surplus')\", 7), (\"Lemma('excess.n.01.surplus')\", 7)])\n",
      "collecting tokens for  next\n",
      "indices:    {9216, 26371, 11652, 13830, 27016, 37002, 22924, 21132, 20883, 21530, 9634, 26491, 18216, 36649, 33705, 32170, 17580, 5687, 21176, 31419, 13251, 23880, 27465, 19275, 27341, 23118, 211, 23636, 29015, 10330, 29407, 11618, 18661, 1895, 20840, 8809, 20328, 26475, 20332, 3692, 14955, 17778, 4731, 36351}\n",
      "dict_items([(\"Lemma('next.r.01.next')\", 3), (\"Lemma('adjacent.s.01.next')\", 5)])\n",
      "collecting tokens for  tons\n",
      "indices:    {3392, 30273, 24134, 36134, 25414, 21831, 27434, 30414, 5072, 27921, 30162, 35923, 29941, 30326, 23834, 19036, 24126, 27167}\n",
      "dict_items([(\"Lemma('short_ton.n.01.ton')\", 2), (\"Lemma('tons.n.01.tons')\", 1)])\n",
      "collecting tokens for  destroyed\n",
      "indices:    {27526, 27528, 27913, 4633, 7709, 8866, 28461, 28336, 30513, 3634, 1713, 28470, 11067, 28476, 28477, 14402, 25923, 12484, 14533, 24134, 11214, 5072, 2642, 27235, 28528}\n",
      "dict_items([(\"Lemma('destroy.v.02.destroy')\", 12), (\"Lemma('destroy.v.01.destroy')\", 10), (\"Lemma('destroyed.a.01.destroyed')\", 1), (\"Lemma('destroyed.s.02.destroyed')\", 1)])\n",
      "collecting tokens for  thoughts\n",
      "indices:    {17570, 17253, 14426, 14695, 36010, 13005, 2133, 13818, 16827, 2652, 1471}\n",
      "dict_items([(\"Lemma('idea.n.01.thought')\", 9)])\n",
      "collecting tokens for  raced\n",
      "indices:    {5056, 6369, 12706, 23340, 19262, 6995, 8596, 18205, 35422}\n",
      "dict_items([(\"Lemma('rush.v.01.race')\", 9)])\n",
      "collecting tokens for  painfully\n",
      "indices:    {28448, 1316, 25702, 33704, 6995, 18484, 5877, 14906, 36062}\n",
      "dict_items([(\"Lemma('painfully.r.01.painfully')\", 5)])\n",
      "collecting tokens for  past\n",
      "indices:    {24578, 520, 11278, 1042, 7700, 36386, 14371, 10283, 14389, 27195, 8255, 17988, 68, 25159, 20559, 14928, 33364, 11352, 21083, 2147, 14954, 21099, 17517, 4724, 19061, 7289, 30847, 22656, 35968, 20614, 24198, 2188, 17037, 16524, 15504, 7827, 23707, 22685, 22175, 22181, 29350, 22699, 33971, 5301, 27832, 27326, 29382, 32455, 25288, 29393, 29395, 24278, 24279, 4851, 21236, 4858, 23806, 20229, 22279, 20244, 21791, 31520, 27425, 14659, 3403, 1869, 2895, 6992, 31056, 19794, 32082, 16212, 31060, 20823, 6499, 25454, 12656, 14710, 34678, 35706, 24442, 7040, 34688, 21376, 12674, 36253, 21408, 21922, 18851, 18852, 12203, 20400, 9649, 32689, 9142, 9146, 31170, 6596, 20942, 16854, 473, 2529, 34274, 33259, 33261, 12785}\n",
      "dict_items([(\"Lemma('past.n.02.past')\", 3), (\"Lemma('by.r.01.past')\", 7), (\"Lemma('past.n.01.past')\", 10), (\"Lemma('past.a.01.past')\", 19), (\"Lemma('past.s.02.past')\", 1), (\"Lemma('past.n.03.past')\", 1)])\n",
      "collecting tokens for  sister\n",
      "indices:    {14453, 6522, 13885}\n",
      "dict_items([(\"Lemma('sister.n.01.sister')\", 2)])\n",
      "collecting tokens for  mary\n",
      "indices:    {8442}\n",
      "dict_items([(\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  yet\n",
      "indices:    {31852}\n",
      "dict_items([])\n",
      "collecting tokens for  western\n",
      "indices:    {22428}\n",
      "dict_items([])\n",
      "collecting tokens for  influence\n",
      "indices:    {12802, 20503, 2079, 1568, 16432, 24144, 26208, 27745, 14440, 23656, 4211, 4726, 27256, 4733, 4235, 4237, 18062, 4752, 4241, 26777, 3225, 32925, 12958, 12959, 12960, 4256, 32927, 12963, 36518, 4276, 12980, 28855, 12990, 27857, 26329, 3311, 2294, 2296, 14077, 14592, 14593, 14596, 14605, 14094, 14098, 804, 23866, 15682, 35653, 26950, 13639, 14666, 22351, 13647, 27993, 12121, 12636, 27998, 14690, 13671, 14704, 28017, 14706, 32115, 28019, 14709, 14711, 14716, 27531, 3988, 32154, 27550, 25506, 28069, 7084, 21436, 33214, 33218, 32205, 31713, 30185, 3052, 3053, 26096, 32241, 28146, 31221, 31734, 27134}\n",
      "dict_items([(\"Lemma('determine.v.02.influence')\", 3), (\"Lemma('influence.v.01.influence')\", 9), (\"Lemma('influence.n.03.influence')\", 7), (\"Lemma('influence.n.01.influence')\", 24), (\"Lemma('influence.n.02.influence')\", 8), (\"Lemma('influence.n.04.influence')\", 3)])\n",
      "collecting tokens for  40\n",
      "indices:    {27019, 23823, 29073, 3858, 30996, 27672, 3356, 21920, 288, 27425, 419, 423, 29097, 4137, 23597, 29103, 3120, 3123, 4022, 27191, 25015, 21563, 5567, 1729, 30148, 21318, 15049, 25417, 15052, 30414, 29008, 21841, 1106, 14928, 29012, 12759, 15063, 15065, 3290, 27226, 15064, 11870, 20965, 22374, 24812, 23150, 3694, 4083, 22140, 20606}\n",
      "dict_items([(\"Lemma('forty.n.01.40')\", 3), (\"Lemma('forty.s.01.40')\", 19)])\n",
      "collecting tokens for  kennedy\n",
      "indices:    {25036}\n",
      "dict_items([])\n",
      "collecting tokens for  26\n",
      "indices:    {32513, 1026, 260, 3218, 15123, 3604, 24594, 274, 3739, 929, 28202, 14765, 25389, 4019, 824, 22330, 22204, 21309, 4031, 25035, 12748, 3920, 3795, 24027, 347, 32608, 32610, 29925, 24812, 29039, 29040, 23028}\n",
      "dict_items([(\"Lemma('twenty-six.s.01.26')\", 10), (\"Lemma('twenty-six.n.01.26')\", 1)])\n",
      "collecting tokens for  nixon\n",
      "indices:    {20936}\n",
      "dict_items([])\n",
      "collecting tokens for  14\n",
      "indices:    {21507, 22019, 263, 29323, 23184, 21266, 25877, 21399, 28184, 21915, 3740, 26999, 25888, 26784, 21027, 3747, 11429, 15268, 31015, 31016, 25256, 28971, 428, 28588, 3758, 14769, 14770, 25010, 16178, 11572, 11576, 23226, 28221, 3776, 14915, 15171, 5189, 22855, 2813, 24272, 3920, 3794, 12115, 26328, 23258, 21212, 21992, 22377, 25705, 21867, 24812, 11625, 12142, 22380, 16368, 21873, 15466, 4084, 21367, 21373, 21503}\n",
      "dict_items([(\"Lemma('fourteenth.s.01.fourteenth')\", 1), (\"Lemma('fourteen.s.01.14')\", 18), (\"Lemma('fourteen.n.01.14')\", 1)])\n",
      "collecting tokens for  realization\n",
      "indices:    {25505, 1058, 12835, 31909, 27305, 20247, 32686, 35759, 1021, 2070, 8471, 12920, 31901}\n",
      "dict_items([(\"Lemma('realization.n.01.realization')\", 3), (\"Lemma('realization.n.02.realization')\", 3)])\n",
      "collecting tokens for  substance\n",
      "indices:    {3202, 27236, 3428, 1286, 23559, 4009, 26185, 36044, 22157, 3789, 3215, 26351, 4015, 1455, 3989, 13621, 32761, 27869}\n",
      "dict_items([(\"Lemma('substance.n.01.substance')\", 8), (\"Lemma('meaning.n.02.substance')\", 1)])\n",
      "collecting tokens for  learn\n",
      "indices:    {1924, 23435, 21005, 6800, 2065, 23441, 24218, 30747, 35869, 27293, 1957, 32683, 26540, 14511, 28848, 13103, 25275, 30651, 15806, 15808, 32065, 14288, 27728, 1877, 6618, 27487, 15200, 10848, 15720, 16493, 5997, 34675, 757, 17658, 12796, 1918}\n",
      "dict_items([(\"Lemma('learn.v.01.learn')\", 25), (\"Lemma('learn.v.02.learn')\", 8), (\"Lemma('memorize.v.01.learn')\", 2)])\n",
      "collecting tokens for  developed\n",
      "indices:    {257, 14594, 3845, 15366, 32137, 27017, 3851, 3852, 5005, 13710, 14223, 22933, 31129, 2586, 793, 14748, 3225, 14238, 15519, 32165, 27686, 5031, 14632, 14248, 32174, 30771, 4020, 32182, 3000, 11705, 32184, 21307, 16440, 4030, 14782, 32192, 3776, 1344, 14275, 37061, 1990, 32711, 26309, 1989, 32714, 3404, 32716, 23116, 5584, 22353, 28498, 23510, 4059, 28635, 1883, 13280, 3170, 13795, 36069, 20326, 1638, 14821, 31210, 13291, 11500, 14572, 11374, 32622, 4975, 32497, 4980, 13174, 15863, 32374, 32122, 20735}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('develop.v.03.develop')\", 9), (\"Lemma('develop.v.01.develop')\", 12), (\"Lemma('build_up.v.05.develop')\", 3), (\"Lemma('originate.v.01.develop')\", 5), (\"Lemma('evolve.v.01.develop')\", 12), (\"Lemma('grow.v.08.develop')\", 8), (\"Lemma('developed.a.01.developed')\", 11), (\"Lemma('develop.v.09.develop')\", 2), (\"Lemma('develop.v.10.develop')\", 1), (\"Lemma('explicate.v.02.develop')\", 2)])\n",
      "collecting tokens for  strong\n",
      "indices:    {792, 16018, 12988, 23240}\n",
      "dict_items([(\"Lemma('strong.a.01.strong')\", 2)])\n",
      "collecting tokens for  conviction\n",
      "indices:    {27142, 21385, 14859, 17036, 25232, 12304, 25370, 28061, 25505, 21411, 12323, 1189, 12328, 5037, 35759, 32688, 1331, 34868, 23224, 15290, 21692, 27326, 15832, 31706, 13149, 27886, 22769, 27635, 32885, 15225, 16127}\n",
      "dict_items([(\"Lemma('conviction.n.01.conviction')\", 10), (\"Lemma('conviction.n.02.conviction')\", 3)])\n",
      "collecting tokens for  grew\n",
      "indices:    {33284, 13576, 7048, 14091, 35600, 36120, 14489, 6042, 25505, 36001, 14244, 29223, 13736, 5034, 29227, 23599, 36017, 9652, 10167, 23097, 6457, 12219, 19641, 23241, 20045, 11215, 11216, 16977, 19665, 36947, 9940, 30928, 28123, 7773, 8541, 13408, 7649, 19939, 13539, 12515, 23654, 26343, 14571, 31601, 28019, 9589, 12406, 5752}\n",
      "dict_items([(\"Lemma('originate.v.01.grow')\", 4), (\"Lemma('grow.v.02.grow')\", 8), (\"Lemma('mature.v.01.grow')\", 3), (\"Lemma('turn.v.07.grow')\", 21), (\"Lemma('grow.v.03.grow')\", 4), (\"Lemma('develop.v.14.grow')\", 2)])\n",
      "collecting tokens for  insights\n",
      "indices:    {11424, 25505, 13217, 28385, 27848, 27851, 15755, 33101, 14428, 13621, 14716}\n",
      "dict_items([(\"Lemma('insight.n.03.insight')\", 1), (\"Lemma('penetration.n.02.insight')\", 4), (\"Lemma('insight.n.02.insight')\", 1)])\n",
      "collecting tokens for  dimensions\n",
      "indices:    {3714, 16108, 28909, 12717}\n",
      "dict_items([(\"Lemma('dimension.n.01.dimension')\", 2), (\"Lemma('property.n.04.dimension')\", 1)])\n",
      "collecting tokens for  contribute\n",
      "indices:    {14593, 3333, 16137, 3211, 14739, 4633, 32674, 29219, 29992, 12207, 26676, 32567, 11834, 16061, 31689, 2030, 11759, 3316, 4214, 26493, 24190, 16127}\n",
      "dict_items([(\"Lemma('lend.v.01.contribute')\", 10), (\"Lemma('contribute.v.02.contribute')\", 9), (\"Lemma('put_up.v.08.contribute')\", 1), (\"Lemma('contribute.v.03.contribute')\", 2)])\n",
      "collecting tokens for  acceptable\n",
      "indices:    {20256, 25505, 24418, 20293, 33223, 32135, 33225, 16363, 22861, 28686, 23829, 24918, 25497, 2041}\n",
      "dict_items([(\"Lemma('acceptable.a.01.acceptable')\", 2)])\n",
      "collecting tokens for  solutions\n",
      "indices:    {11721, 12225, 4382, 29991}\n",
      "dict_items([(\"Lemma('solution.n.03.solution')\", 2), (\"Lemma('solution.n.04.solution')\", 1)])\n",
      "collecting tokens for  urgent\n",
      "indices:    {32192, 25505, 36129, 23363, 27554, 22626, 14023, 37064, 12055, 26455, 16054, 17815, 6296, 5980, 23100}\n",
      "dict_items([(\"Lemma('pressing.s.01.urgent')\", 6)])\n",
      "collecting tokens for  political\n",
      "indices:    {27905, 12934, 2569, 24843, 31244, 16396, 4751, 5648, 4626, 25366, 25495, 24598, 4633, 14359, 23195, 26141, 4770, 20771, 16422, 4774, 21416, 4775, 4778, 4779, 32175, 4792, 24000, 20417, 22852, 27850, 27852, 10832, 24658, 25814, 27991, 11478, 25816, 31194, 28001, 31719, 31721, 36971, 11894, 31224, 25081, 23807}\n",
      "dict_items([(\"Lemma('political.a.01.political')\", 11), (\"Lemma('political.a.03.political')\", 2), (\"Lemma('political.a.02.political')\", 2)])\n",
      "collecting tokens for  issues\n",
      "indices:    {29824, 7041, 4994, 27905, 4750, 24208, 14352, 21909, 2711, 15255, 21914, 25599, 31773, 29855, 25505, 2469, 23853, 20401, 23602, 24115, 20404, 26685, 27838, 23870, 26187, 22617, 20447, 20449, 2539, 32875, 27886, 20467, 1527, 22648, 32762, 32895}\n",
      "dict_items([(\"Lemma('issue.n.02.issue')\", 1), (\"Lemma('issue.n.01.issue')\", 6), (\"Lemma('publish.v.02.issue')\", 1)])\n",
      "collecting tokens for  pleasant\n",
      "indices:    {36179}\n",
      "dict_items([])\n",
      "collecting tokens for  fall\n",
      "indices:    {22496, 24578, 20936, 23752, 4751, 5140, 27034}\n",
      "dict_items([(\"Lemma('fall.n.01.fall')\", 2)])\n",
      "collecting tokens for  argiento\n",
      "indices:    {7590}\n",
      "dict_items([(\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  offering\n",
      "indices:    {22145, 11786, 13075, 26786, 21930, 21931, 21804, 29363, 25655, 2105, 16325, 34374, 21967, 12499, 11733, 26721, 4584, 25832, 2040, 5626}\n",
      "dict_items([(\"Lemma('offer.v.01.offer')\", 10), (\"Lemma('offer.v.02.offer')\", 3), (\"Lemma('offer.v.06.offer')\", 1)])\n",
      "collecting tokens for  unnecessary\n",
      "indices:    {13888, 20193, 18308, 11786, 34444, 22607, 25744, 32753, 32561, 27127, 15739, 27324, 16063}\n",
      "dict_items([(\"Lemma('unnecessary.a.01.unnecessary')\", 5)])\n",
      "collecting tokens for  medical\n",
      "indices:    {21369, 20199, 27174, 33046}\n",
      "dict_items([])\n",
      "collecting tokens for  services\n",
      "indices:    {15003, 15012, 2749}\n",
      "dict_items([(\"Lemma('services.n.01.services')\", 2)])\n",
      "collecting tokens for  shots\n",
      "indices:    {23689, 10762, 11786, 22921, 29070, 17943, 538, 22947, 4388, 17576, 25389, 18227, 22964, 25395, 18239, 25408, 18628, 5062, 25414, 4424, 25417, 4458, 4460, 4478}\n",
      "dict_items([(\"Lemma('shot.n.02.shot')\", 2), (\"Lemma('shooting.n.01.shot')\", 9), (\"Lemma('stroke.n.01.shot')\", 1), (\"Lemma('injection.n.03.shot')\", 1)])\n",
      "collecting tokens for  lamp\n",
      "indices:    {22273, 3300, 3301, 29150, 3268, 11786, 16715, 16746, 14159, 4145, 4146, 3253, 35194, 22267, 18109, 22270}\n",
      "dict_items([(\"Lemma('lamp.n.01.lamp')\", 10)])\n",
      "collecting tokens for  treatments\n",
      "indices:    {31841, 4161, 4195, 4165, 4197, 11786, 2253, 2259, 4252}\n",
      "dict_items([(\"Lemma('treatment.n.02.treatment')\", 4), (\"Lemma('treatment.n.01.treatment')\", 4)])\n",
      "collecting tokens for  etc.\n",
      "indices:    {3461, 29703, 11786, 29714, 4377, 26780, 25629, 3230, 2988, 14137, 15549, 32458, 4303, 11730, 27868, 3166, 3424, 14050, 30691, 27879, 25068, 21869, 2158, 27631, 24561, 28530, 24562, 24693, 25211, 32380, 15869}\n",
      "dict_items([(\"Lemma('and_so_forth.r.01.etc.')\", 5)])\n",
      "collecting tokens for  writers\n",
      "indices:    {26944, 517, 2472, 491, 10860, 31820, 22445, 31852, 28560, 31827, 32052, 31829, 31831, 32120, 28441, 2333}\n",
      "dict_items([(\"Lemma('writer.n.01.writer')\", 5)])\n",
      "collecting tokens for  faulkner\n",
      "indices:    {31800}\n",
      "dict_items([])\n",
      "collecting tokens for  robert\n",
      "indices:    {25036}\n",
      "dict_items([])\n",
      "collecting tokens for  warren\n",
      "indices:    {5874}\n",
      "dict_items([(\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  led\n",
      "indices:    {12298, 8718, 23060, 31783, 31784, 22569, 16432, 5179, 36412, 31814, 12870, 12880, 26708, 27738, 91, 17501, 26209, 7781, 22634, 17006, 12407, 25724, 19071, 24194, 4738, 35970, 23183, 26769, 24724, 665, 5786, 7840, 678, 27814, 6312, 30896, 12466, 19635, 25269, 25270, 194, 18646, 32470, 13017, 31962, 1242, 11509, 22780, 5888, 24331, 3340, 18703, 20753, 32020, 20761, 14105, 14109, 18722, 32050, 18739, 7991, 27451, 21820, 8513, 1350, 35152, 26486, 36727, 22393, 15241, 23951, 7058, 14228, 2969, 27548, 21406, 2465, 23969, 4002, 27554, 7592, 15792, 34737, 20415, 450, 36821, 470, 27108, 17398, 31222, 3071}\n",
      "dict_items([(\"Lemma('lead.v.05.lead')\", 13), (\"Lemma('lead.v.01.lead')\", 21), (\"Lemma('lead.v.03.lead')\", 7), (\"Lemma('lead.v.08.lead')\", 7), (\"Lemma('lead.v.04.lead')\", 6), (\"Lemma('leave.v.07.lead')\", 12), (\"Lemma('head.v.02.lead')\", 5), (\"Lemma('contribute.v.03.lead')\", 1), (\"Lemma('go.v.25.lead')\", 1), (\"Lemma('precede.v.04.lead')\", 1), (\"Lemma('run.v.03.lead')\", 7), (\"Lemma('conduct.v.02.lead')\", 2)])\n",
      "collecting tokens for  somewhat\n",
      "indices:    {4736, 13192, 4749, 20237, 15761, 1427, 13204, 29077, 4119, 3481, 16155, 15133, 24611, 22951, 10279, 26924, 3758, 3887, 25392, 24626, 2867, 28979, 12469, 4792, 4921, 33095, 10953, 7370, 10575, 1749, 23133, 13795, 1133, 33134, 34033, 14452, 25975}\n",
      "dict_items([(\"Lemma('slightly.r.01.somewhat')\", 22), (\"Lemma('reasonably.r.01.somewhat')\", 2)])\n",
      "collecting tokens for  important\n",
      "indices:    {1859, 20771, 23461, 2502, 24841, 8329, 3179, 28141, 2512, 1425, 14098, 14707, 31536, 23536, 17847, 2749, 33086, 30495}\n",
      "dict_items([(\"Lemma('important.a.01.important')\", 10)])\n",
      "collecting tokens for  sort\n",
      "indices:    {18306, 16131, 11779, 11141, 6030, 14095, 29071, 19094, 5275, 30750, 6943, 17824, 36004, 37166, 14255, 37049, 31547, 2493, 9668, 8393, 16075, 31179, 35661, 4941, 31448, 36706, 23650, 26982, 8811, 25969, 35700, 6778}\n",
      "dict_items([(\"Lemma('kind.n.01.sort')\", 16)])\n",
      "collecting tokens for  renaissance\n",
      "indices:    {2709}\n",
      "dict_items([(\"Lemma('renaissance.n.01.Renaissance')\", 1)])\n",
      "collecting tokens for  why\n",
      "indices:    {36259}\n",
      "dict_items([])\n",
      "collecting tokens for  investigation\n",
      "indices:    {15296}\n",
      "dict_items([])\n",
      "collecting tokens for  questioning\n",
      "indices:    {30945, 20162, 36890, 13672, 14377, 30252, 8242, 4691, 18229, 16727, 19353, 23994, 18268}\n",
      "dict_items([(\"Lemma('interrogate.v.02.question')\", 1), (\"Lemma('questioning.n.01.questioning')\", 4), (\"Lemma('wonder.v.02.question')\", 1), (\"Lemma('question.v.01.question')\", 3), (\"Lemma('questioning.s.01.questioning')\", 1)])\n",
      "collecting tokens for  merely\n",
      "indices:    {30480, 280, 28314, 6811, 5659, 16418, 12963, 27685, 18347, 22702, 25523, 1467, 6207, 26560, 16063, 14531, 22725, 18887, 24008, 18891, 27089, 4178, 24148, 25173, 25816, 16238, 2799, 2680, 4858, 4731, 18302}\n",
      "dict_items([(\"Lemma('merely.r.01.merely')\", 19)])\n",
      "collecting tokens for  male\n",
      "indices:    {12036, 26250, 3598, 3601, 36498, 36497, 27540, 26662, 33576, 27562, 30767, 3760, 4019, 1715, 9402, 27078, 26443, 3661, 26452, 22104, 21599, 33131, 10092, 22390, 33014, 3702, 12026, 12543}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('male.a.01.male')\", 8), (\"Lemma('male.n.01.male')\", 2), (\"Lemma('male.n.02.male')\", 1)])\n",
      "collecting tokens for  creature\n",
      "indices:    {7816, 7145, 28237, 6386, 16018, 26549, 22390, 31863, 1467, 573, 7807}\n",
      "dict_items([(\"Lemma('animal.n.01.creature')\", 7)])\n",
      "collecting tokens for  resist\n",
      "indices:    {23520, 16384, 16898, 14432, 24640, 25541, 12928, 22631, 22152, 5856, 32042, 16646, 31659, 36200, 4721, 22390, 14459, 25339}\n",
      "dict_items([(\"Lemma('defy.v.02.resist')\", 9), (\"Lemma('resist.v.02.resist')\", 7), (\"Lemma('protest.v.02.resist')\", 2)])\n",
      "collecting tokens for  corps\n",
      "indices:    {6012}\n",
      "dict_items([])\n",
      "collecting tokens for  ballet\n",
      "indices:    {26077, 937, 22395, 22333}\n",
      "dict_items([(\"Lemma('ballet.n.01.ballet')\", 1)])\n",
      "collecting tokens for  based\n",
      "indices:    {28169, 15881, 23823, 3861, 16409, 4634, 27801, 27554, 32034, 15527, 27559, 15017, 3758, 4784, 28081, 4272, 4275, 28852, 14643, 30781, 26815, 27076, 16455, 3913, 26827, 25035, 3151, 14803, 5207, 24024, 1120, 14050, 11625, 20203, 14830, 3823, 12792, 22779, 12284}\n",
      "dict_items([(\"Lemma('establish.v.08.base')\", 26), (\"Lemma('based.s.02.based')\", 1), (\"Lemma('based.s.01.based')\", 1)])\n",
      "collecting tokens for  figure\n",
      "indices:    {11936, 14061, 36013}\n",
      "dict_items([(\"Lemma('figure.n.01.figure')\", 1), (\"Lemma('figure.n.07.figure')\", 1)])\n",
      "collecting tokens for  considering\n",
      "indices:    {22849, 36436, 3476}\n",
      "dict_items([(\"Lemma('see.v.05.consider')\", 1), (\"Lemma('study.v.03.consider')\", 1)])\n",
      "collecting tokens for  depreciation\n",
      "indices:    {25825, 22721, 15619, 15620, 30406, 32340, 12182, 23483, 32349}\n",
      "dict_items([(\"Lemma('depreciation.n.01.depreciation')\", 2), (\"Lemma('depreciation.n.02.depreciation')\", 1)])\n",
      "collecting tokens for  vehicles\n",
      "indices:    {32387, 3332, 3333, 32263, 32265, 29194, 32271, 32272, 32273, 32283, 32284, 32286, 32287, 32290, 32301, 32308, 32315, 20412, 32325, 14031, 1104, 32338, 1106, 32340, 32348, 32351, 32355, 32358, 32363, 32364, 11771}\n",
      "dict_items([(\"Lemma('vehicle.n.01.vehicle')\", 5)])\n",
      "collecting tokens for  pool\n",
      "indices:    {30080, 37138, 22165, 32286, 29990, 29995, 12333, 13358, 19122, 30007, 30011, 30013, 30659, 32330, 10713, 32345, 19035, 32352, 30052, 32357, 8693, 30074}\n",
      "dict_items([(\"Lemma('pool.n.01.pool')\", 2), (\"Lemma('pool.v.01.pool')\", 1), (\"Lemma('pool.n.03.pool')\", 1)])\n",
      "collecting tokens for  personnel\n",
      "indices:    {901, 12811, 32146, 4628, 10261, 15769, 10267, 4765, 33068, 12978, 13235, 11701, 22713, 11709, 24000, 22735, 32475, 32476, 15580, 32353, 14054, 32493, 15471, 32751, 21490, 21491, 15476, 15477, 10230, 21493, 15480, 15478}\n",
      "dict_items([(\"Lemma('force.n.04.personnel')\", 16)])\n",
      "collecting tokens for  travel\n",
      "indices:    {12765, 8768, 24866, 28355, 13223, 32648, 32297, 13067, 26925, 32302, 12175, 32303, 29105, 36598, 22807, 3421, 22173, 25150}\n",
      "dict_items([(\"Lemma('travel.v.01.travel')\", 5), (\"Lemma('travel.n.01.travel')\", 3), (\"Lemma('travel.v.03.travel')\", 1), (\"Lemma('change_of_location.n.01.travel')\", 1), (\"Lemma('travel.v.02.travel')\", 1)])\n",
      "collecting tokens for  10000\n",
      "indices:    {522, 28562, 21778, 12716, 27180, 32440, 2232, 2237, 23103, 20933, 23375, 32721, 29398, 30167, 32349, 12645, 20838, 14830, 245, 29309}\n",
      "dict_items([])\n",
      "collecting tokens for  annually\n",
      "indices:    {3712, 2241, 2243, 27014, 22248, 32365, 20717, 6065, 23506, 32349}\n",
      "dict_items([(\"Lemma('annually.r.01.annually')\", 4)])\n",
      "collecting tokens for  economical\n",
      "indices:    {1889, 14724, 30149, 32548, 30118, 15881, 2730, 11730, 11929, 32280, 14169, 14172, 32349, 11774}\n",
      "dict_items([(\"Lemma('economical.s.03.economical')\", 1), (\"Lemma('economic.s.03.economical')\", 6), (\"Lemma('economic.a.01.economical')\", 2)])\n",
      "collecting tokens for  car\n",
      "indices:    {35970, 24451, 18947, 21635, 33926, 21511, 33417, 24714, 24715, 21387, 33419, 20750, 21009, 17043, 33685, 9892, 24369, 33587, 33461, 22458, 33729, 21442, 33475, 17736, 21332, 9178, 27102, 22238, 22239, 21611, 17003, 34029, 21871, 21874, 17907, 33396, 18933, 18937}\n",
      "dict_items([(\"Lemma('car.n.01.car')\", 9)])\n",
      "collecting tokens for  payment\n",
      "indices:    {14853, 14856, 14859, 32270, 22036, 12695, 14873, 22043, 14876, 14877, 14878, 21662, 14880, 14881, 14882, 14883, 11811, 14879, 32299, 14893, 14894, 14895, 32563, 15549, 15551, 20676, 32458, 31051, 20186, 20187, 32349, 15585, 31203, 25188}\n",
      "dict_items([(\"Lemma('payment.n.01.payment')\", 7), (\"Lemma('payment.n.02.payment')\", 13)])\n",
      "collecting tokens for  allowances\n",
      "indices:    {32288, 32289, 32290, 26627, 32292, 32291, 22023, 32296, 22026, 32298, 32302, 32304, 32273, 32279, 32349, 62, 32287}\n",
      "dict_items([(\"Lemma('allowance.n.02.allowance')\", 1)])\n",
      "collecting tokens for  holmes\n",
      "indices:    {13957}\n",
      "dict_items([(\"Lemma('sherlock_holmes.n.01.Holmes')\", 1)])\n",
      "collecting tokens for  colorado\n",
      "indices:    {15312}\n",
      "dict_items([])\n",
      "collecting tokens for  applied\n",
      "indices:    {14852, 33030, 28937, 31114, 31248, 4242, 2198, 14232, 10264, 4251, 3998, 11423, 23712, 4513, 32935, 31018, 22059, 29867, 10285, 28718, 22061, 4269, 28849, 33074, 16434, 27565, 3506, 3001, 11451, 26812, 3003, 3133, 24128, 25285, 3910, 2886, 11466, 14540, 29772, 30415, 11348, 7636, 1631, 3554, 2787, 32997, 3045, 22760, 15592, 14824, 36456, 14825, 29936, 23542, 12795, 2301, 3839}\n",
      "dict_items([(\"Lemma('use.v.01.apply')\", 25), (\"Lemma('apply.v.02.apply')\", 7), (\"Lemma('put_on.v.07.apply')\", 6), (\"Lemma('lend_oneself.v.01.apply')\", 2), (\"Lemma('give.v.20.apply')\", 1), (\"Lemma('apply.v.03.apply')\", 3)])\n",
      "collecting tokens for  technique\n",
      "indices:    {2434, 1543, 2439, 11400, 1805, 29454, 11407, 26769, 11283, 31891, 16153, 27035, 925, 11423, 14624, 4131, 12069, 14381, 3506, 25651, 9144, 1082, 11969, 14664, 26442, 33228, 22736, 727, 11355, 11357, 2666, 28140, 11372, 14070, 11257, 2554, 11387, 26237}\n",
      "dict_items([(\"Lemma('technique.n.01.technique')\", 25), (\"Lemma('proficiency.n.02.technique')\", 2)])\n",
      "collecting tokens for  soft\n",
      "indices:    {18945, 22147, 4102, 4107, 1163, 7180, 9595, 8596, 35989, 29462, 35988, 29464, 9243, 11423, 28448, 35744, 16927, 22947, 14507, 3502, 686, 564, 31414, 19256, 7611, 4925, 29503, 16576, 1215, 28482, 3269, 720, 36433, 36563, 12884, 29910, 3160, 29529, 19550, 1631, 7263, 16492, 18284, 8558, 31599, 34159, 29558, 25334, 25337, 26490, 25339}\n",
      "dict_items([(\"Lemma('soft.a.01.soft')\", 15), (\"Lemma('soft.a.02.soft')\", 4), (\"Lemma('easy.r.03.soft')\", 1), (\"Lemma('soft.a.03.soft')\", 4)])\n",
      "collecting tokens for  tissue\n",
      "indices:    {17153, 3854, 33681, 4125, 11423, 31016, 2219, 31024, 9521, 11315, 11316, 4149, 4150, 4152, 3768, 9528, 4155, 4157, 32702, 4164, 4167, 4169, 4175, 3412, 4183, 3803, 4063, 4065, 4193, 4194, 4068, 3937, 4198, 4199, 3817, 3818, 4075, 4202, 3948, 11385, 11386}\n",
      "dict_items([(\"Lemma('tissue.n.01.tissue')\", 26), (\"Lemma('tissue.n.02.tissue')\", 3)])\n",
      "collecting tokens for  obtained\n",
      "indices:    {24066, 3096, 3114, 3120, 3124, 3128, 3129, 3134, 29758, 23620, 3141, 32325, 3143, 1097, 3145, 12362, 3174, 11404, 29841, 11423, 15021, 15023, 3249, 15027, 15033, 20154, 15034, 20156, 15037, 15035, 15039, 15040, 15042, 29900, 15566, 15066, 15070, 29921, 22755, 13543, 2792, 15093, 3319, 3324, 3325, 3330, 33030, 33041, 3345, 15639, 2844, 15653, 33078, 33080, 12090, 3388, 33101, 27985, 20316, 20317, 3432, 21390, 4499, 2964, 29588, 15262, 4003, 2981, 4013, 2990, 4525, 16309, 3511, 25016, 3516, 14781, 3006, 31167, 14784, 14786, 3528, 1488, 3544, 3548, 13279, 13285, 13291, 14833, 25085}\n",
      "dict_items([(\"Lemma('receive.v.02.obtain')\", 13), (\"Lemma('obtain.v.01.obtain')\", 26)])\n",
      "collecting tokens for  extremely\n",
      "indices:    {24832, 3845, 3847, 26505, 3085, 28564, 32662, 33177, 10105, 25753, 11423, 16288, 29096, 22706, 32054, 15160, 26430, 31935, 23743, 3784, 26057, 31433, 29264, 11866, 14174, 94, 28510, 32496, 3184, 3186, 3568, 3192, 32377, 3962, 13950, 3583}\n",
      "dict_items([(\"Lemma('extremely.r.02.extremely')\", 6), (\"Lemma('highly.r.01.extremely')\", 11)])\n",
      "collecting tokens for  results\n",
      "indices:    {4992, 33028, 14725, 4486, 1030, 4741, 11530, 23562, 2833, 14356, 3988, 27800, 14360, 14748, 33054, 3244, 4012, 4782, 3766, 23609, 15674, 4539, 15035, 4537, 14654, 33090, 24131, 24771, 26566, 4041, 14799, 15696, 3282, 34515, 16217, 4962, 22755, 4456, 14825, 14317, 14830, 15726, 3702, 32892}\n",
      "dict_items([(\"Lemma('consequence.n.01.result')\", 17), (\"Lemma('result.n.03.result')\", 5), (\"Lemma('leave.v.07.result')\", 4), (\"Lemma('solution.n.02.result')\", 5), (\"Lemma('result.v.01.result')\", 1)])\n",
      "collecting tokens for  pat\n",
      "indices:    {18595}\n",
      "dict_items([(\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  turned\n",
      "indices:    {35841, 22531, 19974, 10247, 18951, 34310, 34314, 33803, 18963, 18965, 1050, 5666, 8740, 5671, 33831, 33328, 1075, 26676, 34869, 5686, 34871, 26171, 16958, 10818, 8259, 12356, 22599, 17482, 33354, 10319, 2131, 18004, 34901, 12371, 12887, 12376, 34393, 20056, 33364, 6236, 5717, 35422, 29792, 6240, 34401, 608, 20071, 32872, 33897, 12394, 23149, 17006, 8815, 18545, 20082, 33908, 20598, 12407, 33913, 35964, 17532, 10366, 35970, 25732, 5767, 20105, 12940, 8845, 26253, 11922, 10900, 30357, 10390, 31899, 33954, 29348, 17572, 19622, 33958, 6822, 17575, 16554, 9387, 29350, 14505, 5806, 7848, 5300, 14517, 8886, 33465, 35002, 36540, 33469, 33468, 33471, 33470, 5824, 2247, 8904, 10440, 33482, 33486, 12496, 29393, 1236, 9432, 7388, 7392, 8929, 34019, 8419, 16622, 34031, 31479, 26872, 13561, 34040, 7416, 6398, 17152, 19201, 13569, 18176, 773, 776, 20744, 9997, 5391, 33554, 34067, 7962, 29981, 19236, 36644, 294, 6952, 14121, 37161, 33580, 302, 6967, 35639, 18234, 33595, 19771, 19266, 8519, 36167, 4938, 19787, 19791, 8528, 339, 5463, 16728, 35673, 22872, 35678, 4960, 18785, 4963, 17764, 6501, 19819, 31599, 36720, 25461, 2934, 9591, 27515, 19836, 9600, 6533, 36742, 19333, 20360, 10121, 19345, 8595, 31124, 27029, 15767, 19863, 34714, 22939, 28060, 8091, 18334, 35233, 17826, 18339, 15781, 36774, 18343, 5031, 14249, 32682, 35244, 19884, 25518, 33708, 33712, 432, 35250, 34231, 35256, 7609, 8641, 30147, 12227, 8131, 9668, 15355, 19913, 9163, 35281, 35794, 31187, 36312, 18397, 34784, 10213, 12774, 9192, 5097, 35308, 35311, 6642, 16883, 35828, 21495, 36344, 33784, 33786, 22523, 22524}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('turn.v.01.turn')\", 26), (\"Lemma('pass.v.05.turn_over')\", 2), (\"Lemma('turn.v.11.turn')\", 1), (\"Lemma('become.v.02.turn')\", 7), (\"Lemma('change_state.v.01.turn')\", 8), (\"Lemma('turn.v.04.turn')\", 3), (\"Lemma('switch_off.v.01.turn_off')\", 1), (\"Lemma('revert.v.01.turn_back')\", 1), (\"Lemma('turn.v.08.turn')\", 2), (\"Lemma('twist.v.10.turn')\", 1), (\"Lemma('turn.v.14.turn')\", 1), (\"Lemma('refuse.v.02.turn_down')\", 2), (\"Lemma('turn.v.07.turn')\", 3), (\"Lemma('change_by_reversal.v.01.turn')\", 2), (\"Lemma('turn.v.13.turn')\", 1), (\"Lemma('turn.v.06.turn')\", 1)])\n",
      "collecting tokens for  survey\n",
      "indices:    {27425, 26761, 2716}\n",
      "dict_items([])\n",
      "collecting tokens for  deliberately\n",
      "indices:    {897, 5666, 22883, 31873, 14465, 27813, 16359, 17832, 27787, 27804, 5399, 15829, 18007, 36153, 35802, 34652}\n",
      "dict_items([(\"Lemma('intentionally.r.01.deliberately')\", 7), (\"Lemma('measuredly.r.01.deliberately')\", 1)])\n",
      "collecting tokens for  factor\n",
      "indices:    {32899, 12042, 3342, 26774, 2167, 28697, 20380, 20641, 2981, 3367, 3370, 33198, 13109, 11831, 15676, 22590, 4801, 20294, 15688, 23243, 33227, 28493, 31186, 4307, 12500, 32981, 32982, 27994, 27995, 1886, 4702, 26209, 31715, 15716, 33254, 28905, 1902, 16370, 4722, 21236, 3191, 15225, 1789, 16510}\n",
      "dict_items([(\"Lemma('divisor.n.01.factor')\", 4), (\"Lemma('component.n.01.factor')\", 6), (\"Lemma('factor.n.01.factor')\", 11), (\"Lemma('agent.n.04.factor')\", 1)])\n",
      "collecting tokens for  physical\n",
      "indices:    {2176, 1185, 5250, 24544, 25542, 11880, 11881, 18123, 35759, 3184, 14834, 14418, 13628, 12286}\n",
      "dict_items([(\"Lemma('physical.s.03.physical')\", 1), (\"Lemma('physical.a.01.physical')\", 6)])\n",
      "collecting tokens for  isolation\n",
      "indices:    {13956, 32966, 13960, 12970, 32912, 3504, 32914, 32981, 2680, 32955, 32988}\n",
      "dict_items([(\"Lemma('isolation.n.03.isolation')\", 1), (\"Lemma('isolation.n.02.isolation')\", 1), (\"Lemma('isolation.n.01.isolation')\", 2)])\n",
      "collecting tokens for  static\n",
      "indices:    {26496, 19522, 16453, 3400, 31151, 27823, 2164, 32981, 34428, 11325, 3198}\n",
      "dict_items([(\"Lemma('inactive.s.10.static')\", 1)])\n",
      "collecting tokens for  situation\n",
      "indices:    {24071, 20488, 26637, 15382, 4634, 15899, 15904, 15393, 30754, 13352, 26153, 36912, 30768, 9783, 30776, 8250, 30788, 15429, 30793, 14922, 2638, 31824, 32848, 32853, 24155, 30812, 2657, 30821, 32871, 32875, 27761, 18548, 32372, 11894, 24191, 32392, 12945, 16017, 33940, 2712, 27802, 32411, 27305, 13481, 4267, 22710, 23734, 23742, 4286, 27848, 32981, 27866, 1246, 27883, 6894, 26356, 3322, 13057, 24848, 24849, 23828, 2328, 11037, 16159, 32543, 1313, 1314, 1318, 27128, 20265, 5419, 13612, 25901, 22835, 22839, 20283, 22849, 1348, 32585, 845, 22354, 25942, 24918, 14168, 30553, 24930, 15725, 11630, 32622, 33135, 20338, 17796, 31111, 1419, 12684, 23438, 21402, 6059, 33708, 34736, 30644, 27577, 21947, 21948, 23997, 2494, 447, 33216, 15814, 16327, 34760, 33225, 33223, 21962, 17868, 8141, 13780, 23508, 9684, 33239, 5080, 10201, 13269, 2524, 8158, 2531, 6115, 33254, 23015, 2539, 25586, 13304, 8188, 6142}\n",
      "dict_items([(\"Lemma('situation.n.01.situation')\", 26), (\"Lemma('situation.n.02.situation')\", 7)])\n",
      "collecting tokens for  holding\n",
      "indices:    {30720, 35331, 33412, 18563, 4614, 37001, 28041, 29580, 12304, 4754, 6932, 29078, 16664, 27290, 24347, 34721, 23845, 7595, 19884, 31025, 34484, 10550, 14008, 27963, 27331, 24007, 714, 15823, 24784, 27349, 7767, 19296, 9954, 9315, 18413, 9069, 29550, 26991, 9070, 19059, 6260}\n",
      "dict_items([(\"Lemma('hold.v.03.hold')\", 2), (\"Lemma('hold.v.10.hold')\", 3), (\"Lemma('hold.v.02.hold')\", 11), (\"Lemma('hold_up.v.02.hold_up')\", 1), (\"Lemma('keep.v.01.hold')\", 6), (\"Lemma('hold.v.16.hold')\", 2), (\"Lemma('hold.v.23.hold')\", 1), (\"Lemma('hold.v.11.hold')\", 2), (\"Lemma('harbor.v.01.hold')\", 1), (\"Lemma('retention.n.01.holding')\", 1), (\"Lemma('retain.v.03.hold')\", 1), (\"Lemma('restrain.v.03.hold')\", 1)])\n",
      "collecting tokens for  hands\n",
      "indices:    {33796, 27912, 28297, 19210, 526, 6898, 8087, 12443, 18587, 34083, 18219, 19884, 7921, 35758, 35636, 13749, 1974, 15799, 26622, 5177, 7354, 9661, 9662, 13760, 19905, 1985, 3011, 33988, 23107, 13508, 35399, 37065, 17866, 7116, 36047, 12624, 29395, 9174, 26455, 19800, 18009, 27774, 2008, 2012, 994, 8676, 2021, 2020, 34792, 23273, 34541, 34669, 22511, 4464, 36721, 34034, 6897, 9460, 5877, 25076, 19441, 5874, 27897, 18426, 18683, 36733, 17662}\n",
      "dict_items([(\"Lemma('hand.n.01.hand')\", 26), (\"Lemma('hand.n.06.hand')\", 1), (\"Lemma('hands.n.01.hands')\", 2), (\"Lemma('hired_hand.n.01.hand')\", 1)])\n",
      "collecting tokens for  product\n",
      "indices:    {28545, 20358, 5003, 11663, 11667, 22812, 15261, 22690, 21923, 32930, 2728, 11691, 11692, 11694, 3247, 12721, 3250, 14772, 11701, 14774, 4281, 2362, 4285, 2750, 15039, 21826, 11715, 21574, 16334, 16336, 16340, 16343, 19033, 19036, 11622, 4327, 11633, 11640, 11642, 15742}\n",
      "dict_items([(\"Lemma('merchandise.n.01.product')\", 18), (\"Lemma('product.n.03.product')\", 5), (\"Lemma('product.n.02.product')\", 5), (\"Lemma('product.n.04.product')\", 2)])\n",
      "collecting tokens for  minds\n",
      "indices:    {4993, 12675, 25733, 27531, 24333, 28303, 27539, 24987, 28194, 23596, 13751, 25912, 14265, 14651, 23037, 833, 31685, 14277, 11207, 34760, 2377, 11209, 27261, 27734, 11095, 31707, 7773, 27358, 28385, 13154, 5220, 4968, 14188, 26096, 1271, 14717}\n",
      "dict_items([(\"Lemma('mind.n.01.mind')\", 14), (\"Lemma('mind.n.02.mind')\", 1), (\"Lemma('thinker.n.01.mind')\", 2), (\"Lemma('judgment.n.01.mind')\", 1)])\n",
      "collecting tokens for  hearts\n",
      "indices:    {1121}\n",
      "dict_items([])\n",
      "collecting tokens for  lloyd\n",
      "indices:    {21886}\n",
      "dict_items([])\n",
      "collecting tokens for  neck\n",
      "indices:    {36085, 2026, 9709, 25950}\n",
      "dict_items([(\"Lemma('neck.n.01.neck')\", 2)])\n",
      "collecting tokens for  taught\n",
      "indices:    {11281, 2071, 30622, 2598, 10029, 10933, 28860, 11326, 10046, 10047, 7106, 36303, 24275, 25686, 15707, 8031, 34400, 30437, 14455}\n",
      "dict_items([(\"Lemma('teach.v.01.teach')\", 19)])\n",
      "collecting tokens for  traffic\n",
      "indices:    {23430}\n",
      "dict_items([])\n",
      "collecting tokens for  pretty\n",
      "indices:    {36480, 16004, 6536, 8329, 6540, 33296, 36246, 10395, 5915, 26524, 2423, 26663, 8744, 29099, 24876, 10420, 16182, 34887, 4937, 36304, 22482, 2646, 27224, 16473, 16474, 34526, 5598, 30307, 26341, 33126, 30567, 36327, 14453, 33271}\n",
      "dict_items([(\"Lemma('reasonably.r.01.pretty')\", 6), (\"Lemma('pretty.s.02.pretty')\", 2), (\"Lemma('person.n.01.person')\", 1), (\"Lemma('pretty.s.01.pretty')\", 4)])\n",
      "collecting tokens for  kid\n",
      "indices:    {8961, 9064, 8972, 9036, 17744, 8952, 19793, 26616, 8923, 8956, 9278}\n",
      "dict_items([(\"Lemma('child.n.01.kid')\", 9)])\n",
      "collecting tokens for  told\n",
      "indices:    {14349, 17940, 7712, 23075, 7724, 61, 17475, 10820, 9284, 10822, 9293, 2647, 13918, 9830, 30318, 21618, 34932, 18043, 10377, 33419, 9356, 20109, 33422, 37025, 33446, 10919, 8874, 27307, 28330, 36526, 21169, 21685, 18621, 9405, 21701, 21705, 13516, 35022, 10961, 10971, 9440, 17634, 7915, 16630, 8439, 5881, 30976, 25857, 23314, 23316, 21780, 4887, 20771, 7972, 16688, 21305, 5948, 17219, 9542, 8006, 16742, 36217, 10618, 15746, 21893, 20358, 17800, 7563, 6545, 31122, 35223, 26522, 411, 25500, 16803, 15787, 35757, 948, 6582, 33207, 33211, 36286, 446, 20421, 33221, 36297, 21962, 6101, 17881, 9697, 24034, 34276, 7654, 18411, 19442, 22525}\n",
      "dict_items([(\"Lemma('state.v.01.tell')\", 26), (\"Lemma('tell.v.02.tell')\", 26), (\"Lemma('order.v.01.tell')\", 12), (\"Lemma('tell.v.03.tell')\", 12)])\n",
      "collecting tokens for  follow\n",
      "indices:    {11577, 35826}\n",
      "dict_items([(\"Lemma('comply.v.01.follow')\", 2)])\n",
      "collecting tokens for  williams\n",
      "indices:    {23621}\n",
      "dict_items([])\n",
      "collecting tokens for  score\n",
      "indices:    {29647}\n",
      "dict_items([(\"Lemma('score.v.02.score')\", 1)])\n",
      "collecting tokens for  whether\n",
      "indices:    {28928, 2308, 14987, 34444, 25613, 25740, 28056, 27801, 15012, 28454, 1191, 31278, 4668, 12228, 1359, 3279, 16723, 25446, 12141, 31215, 26747}\n",
      "dict_items([])\n",
      "collecting tokens for  part\n",
      "indices:    {16333}\n",
      "dict_items([(\"Lemma('part.n.01.part')\", 1)])\n",
      "collecting tokens for  collection\n",
      "indices:    {31664, 26761, 14572}\n",
      "dict_items([(\"Lemma('collection.n.01.collection')\", 1)])\n",
      "collecting tokens for  headquarters\n",
      "indices:    {23554, 30916, 13031, 21577, 23274, 21772, 35856, 24081, 23536, 7315, 26071, 34007, 33015, 22333, 28703}\n",
      "dict_items([(\"Lemma('headquarters.n.01.headquarters')\", 1)])\n",
      "collecting tokens for  remainder\n",
      "indices:    {31233, 5346, 20708, 11047, 31051, 23534, 1072, 23415, 3354, 32411, 156, 5598}\n",
      "dict_items([(\"Lemma('remainder.n.01.remainder')\", 6)])\n",
      "collecting tokens for  divided\n",
      "indices:    {28864, 12260, 5030, 17676, 17549, 16179, 26427, 32509}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('divide.v.01.divide')\", 3), (\"Lemma('separate.v.01.divide')\", 1), (\"Lemma('divide.v.02.divide')\", 2), (\"Lemma('divided.a.01.divided')\", 1), (\"Lemma('separate.v.02.divide')\", 1)])\n",
      "collecting tokens for  libraries\n",
      "indices:    {23553, 23554, 23559, 23561, 23572, 23573, 23577, 28352, 32707, 14414, 23502, 23508, 23509, 23512, 23514, 31580, 31581, 23517, 23524, 23532, 23534, 23535, 23540, 32630, 23545, 23546, 23550}\n",
      "dict_items([(\"Lemma('library.n.02.library')\", 1)])\n",
      "collecting tokens for  designated\n",
      "indices:    {21665, 14018, 15053, 23534, 3573, 13270, 30037, 20732, 23678, 27551}\n",
      "dict_items([(\"Lemma('designate.v.01.designate')\", 9), (\"Lemma('delegate.v.02.designate')\", 1)])\n",
      "collecting tokens for  subject\n",
      "indices:    {26371, 27782, 24168, 14441, 33229, 4792, 14767, 14643, 13846, 27031, 33240, 5404}\n",
      "dict_items([(\"Lemma('subject.n.02.subject')\", 1), (\"Lemma('subject.n.01.subject')\", 4)])\n",
      "collecting tokens for  centers\n",
      "indices:    {33034, 22413, 13844, 3861, 31261, 1311, 3871, 11426, 3874, 31268, 31266, 13350, 3881, 13994, 4783, 3887, 3891, 3894, 5431, 11065, 31295, 4930, 3907, 13383, 3400, 21079, 32728, 31322, 31324, 27740, 15969, 5474, 21092, 15973, 28777, 2155, 2156, 20845, 23534, 26479, 11890, 14841, 13183}\n",
      "dict_items([(\"Lemma('focus_on.v.01.center')\", 4), (\"Lemma('center.n.07.center')\", 3), (\"Lemma('center.n.01.center')\", 13), (\"Lemma('center.n.03.center')\", 1), (\"Lemma('center.n.11.center')\", 1)])\n",
      "collecting tokens for  fury\n",
      "indices:    {28964}\n",
      "dict_items([])\n",
      "collecting tokens for  hanover\n",
      "indices:    {28990}\n",
      "dict_items([])\n",
      "collecting tokens for  hoot\n",
      "indices:    {31570, 29027, 35198}\n",
      "dict_items([(\"Lemma('hoot.v.01.hoot')\", 1)])\n",
      "collecting tokens for  working\n",
      "indices:    {36097, 31756, 2061, 15118, 15757, 36112, 25500, 21537, 17700, 8229, 8232, 35758, 16815, 2753, 17733, 23640, 6104, 24408, 25052, 14556, 12637, 29676, 370, 28915, 16895}\n",
      "dict_items([(\"Lemma('work.v.01.work')\", 7), (\"Lemma('function.v.01.work')\", 1), (\"Lemma('working.s.01.working')\", 2), (\"Lemma('work.v.09.work')\", 1), (\"Lemma('work.v.02.work')\", 4), (\"Lemma('work.v.03.work')\", 1)])\n",
      "collecting tokens for  together\n",
      "indices:    {2944, 27526, 31239, 37138, 8211, 35094, 29599, 7204, 8232, 27563, 7215, 36018, 15539, 17589, 29237, 25144, 23609, 26308, 6088, 2640, 14943, 14690, 36196, 22373, 28775, 4071, 14312, 2664, 16490, 3184, 28915, 20596, 7927, 15102}\n",
      "dict_items([(\"Lemma('together.r.02.together')\", 4), (\"Lemma('together.r.01.together')\", 3), (\"Lemma('in_concert.r.01.together')\", 1), (\"Lemma('together.r.04.together')\", 2), (\"Lemma('together.r.03.together')\", 1)])\n",
      "collecting tokens for  best\n",
      "indices:    {30112, 9186, 217, 9029, 5418, 24077, 9837, 16333, 24368, 21070, 19922, 37138, 13904, 1816, 25465, 28380, 26141, 12831}\n",
      "dict_items([(\"Lemma('best.r.02.best')\", 2), (\"Lemma('best.a.01.best')\", 7), (\"Lemma('best.n.01.best')\", 1)])\n",
      "collecting tokens for  work\n",
      "indices:    {9881, 26761, 325, 31278}\n",
      "dict_items([(\"Lemma('work.v.01.work')\", 1)])\n",
      "collecting tokens for  weeks\n",
      "indices:    {12409, 23300, 15148, 22445, 21007, 8211, 16921, 20379, 24028, 573, 28990}\n",
      "dict_items([(\"Lemma('week.n.01.week')\", 5)])\n",
      "collecting tokens for  importance\n",
      "indices:    {32896, 36224, 14721, 32259, 16132, 4230, 12043, 27534, 24206, 3472, 3473, 2323, 12308, 14101, 15510, 3476, 8344, 11929, 15513, 16283, 4763, 15519, 33055, 15524, 4008, 33194, 3498, 4012, 15282, 2484, 4276, 6838, 4920, 26682, 27322, 4669, 19777, 1729, 32705, 32706, 14021, 29897, 27594, 13259, 26188, 30797, 15309, 11087, 3408, 32977, 4690, 2003, 32723, 8401, 24151, 31191, 16345, 35675, 31197, 13281, 35681, 5225, 6890, 3183, 14063, 32498, 4211, 15988, 4213, 6772, 24952, 14713, 34683, 11645}\n",
      "dict_items([(\"Lemma('importance.n.01.importance')\", 26), (\"Lemma('importance.n.02.importance')\", 4)])\n",
      "collecting tokens for  actions\n",
      "indices:    {809, 14954, 36974, 10003, 29083}\n",
      "dict_items([(\"Lemma('action.n.01.action')\", 2), (\"Lemma('military_action.n.01.action')\", 1)])\n",
      "collecting tokens for  drugs\n",
      "indices:    {3968, 3969, 3970, 3971, 3973, 4230, 3975, 4231, 4233, 4232, 4235, 3974, 3988, 4245, 4253, 3503, 2224, 32102, 30957, 32118, 11514, 3963, 3967}\n",
      "dict_items([(\"Lemma('drug.n.01.drug')\", 19)])\n",
      "collecting tokens for  respect\n",
      "indices:    {14853, 14854, 15368, 32776, 14860, 31757, 14863, 14864, 14866, 30226, 27156, 14877, 14880, 14881, 26148, 25125, 1069, 24116, 24117, 34379, 2638, 34383, 5206, 15449, 3686, 1127, 25199, 11376, 633, 4230, 25736, 25242, 12450, 32427, 4271, 4277, 2230, 26296, 32965, 15053, 19666, 1244, 22755, 22279, 33044, 3865, 15644, 23842, 14633, 15661, 3889, 3894, 6983, 2375, 30025, 3913, 8031, 13156, 14181, 13676, 14193, 14726, 14735, 14745, 22432, 14768, 27569, 2996, 6581, 32202, 32218, 13274, 28651, 13296, 16369, 1010, 4601}\n",
      "dict_items([(\"Lemma('respect.v.01.respect')\", 2), (\"Lemma('deference.n.01.respect')\", 1), (\"Lemma('obedience.n.03.respect')\", 1), (\"Lemma('respect.n.01.respect')\", 9), (\"Lemma('respect.n.03.respect')\", 3), (\"Lemma('esteem.n.01.respect')\", 5), (\"Lemma('respect.v.02.respect')\", 2)])\n",
      "collecting tokens for  rebel\n",
      "indices:    {7712, 21405, 12614}\n",
      "dict_items([(\"Lemma('rebel.n.01.Rebel')\", 1)])\n",
      "collecting tokens for  glad\n",
      "indices:    {20448, 17062, 31150, 10159, 36015, 36273, 17658, 24827}\n",
      "dict_items([(\"Lemma('glad.s.02.glad')\", 1), (\"Lemma('glad.a.01.glad')\", 2)])\n",
      "collecting tokens for  north\n",
      "indices:    {18714, 7822, 12334}\n",
      "dict_items([(\"Lemma('north.a.01.north')\", 1), (\"Lemma('north.r.01.north')\", 1)])\n",
      "collecting tokens for  won\n",
      "indices:    {2, 35842, 521, 19468, 1566, 17444, 7726, 562, 16946, 23090, 572, 11836, 17471, 26177, 26181, 33349, 11850, 22095, 23120, 21586, 27221, 21589, 599, 21597, 21602, 626, 26743, 29306, 18053, 16522, 18082, 20131, 22179, 20135, 25772, 18609, 14525, 29886, 34496, 33494, 16599, 20695, 25827, 18152, 24815, 240, 18163, 16631, 28931, 24839, 24840, 33548, 24337, 278, 27928, 36640, 14114, 24876, 24880, 24881, 9523, 30031, 342, 26977, 13155, 19300, 23912, 23913, 16749, 33648, 12146, 17278, 28544, 28545, 21891, 388, 22917, 18316, 24976, 18322, 28562, 25491, 1943, 22936, 22935, 22939, 20894, 22944, 28576, 30116, 24486, 35239, 24494, 19894, 26045, 36289, 11202, 451, 36293, 2503, 18388, 31203, 30179, 30181, 35822, 19954, 1527}\n",
      "dict_items([(\"Lemma('win.v.01.win')\", 26), (\"Lemma('acquire.v.05.win')\", 16)])\n",
      "collecting tokens for  war\n",
      "indices:    {12856}\n",
      "dict_items([])\n",
      "collecting tokens for  shares\n",
      "indices:    {26507, 26508, 5135, 15251, 21917, 21792, 15265, 21793, 21795, 21794, 15269, 15266, 21929, 21930, 15277, 21934, 21807, 21808, 21937, 21939, 24636, 1501, 29921}\n",
      "dict_items([(\"Lemma('share.n.02.share')\", 6), (\"Lemma('partake.v.02.share')\", 2), (\"Lemma('share.v.01.share')\", 1)])\n",
      "collecting tokens for  process\n",
      "indices:    {15363, 11268, 15366, 4615, 15884, 30221, 30736, 23568, 11286, 20504, 14360, 2589, 4639, 30752, 34340, 27685, 13348, 13351, 27688, 27687, 13357, 13358, 30768, 16433, 34362, 26682, 15935, 9792, 15939, 31812, 2628, 30790, 15445, 27234, 14438, 2153, 11373, 3184, 3199, 4736, 31875, 26759, 3211, 4749, 3213, 3215, 4753, 12434, 32918, 32921, 3225, 31901, 3229, 3230, 31902, 4769, 32930, 4259, 4772, 31907, 31909, 12969, 26795, 28858, 4798, 20165, 4808, 3786, 32978, 32989, 32995, 32996, 32998, 33004, 750, 14575, 5362, 14583, 16131, 24836, 3862, 25397, 1337, 4939, 4954, 13666, 24420, 4976, 15730, 14726, 11148, 35725, 11161, 17314, 27560, 12204, 32173, 11692, 15289, 15290, 15292, 15303, 31185, 1504, 1507, 27621, 15334, 32237, 32240, 11256, 23545, 27643, 15359}\n",
      "dict_items([(\"Lemma('procedure.n.01.process')\", 26), (\"Lemma('process.n.02.process')\", 1)])\n",
      "collecting tokens for  animal\n",
      "indices:    {2693, 11526, 14091, 4235, 3981, 3979, 36239, 30736, 30735, 30737, 3989, 30753, 16163, 16164, 11556, 5032, 26538, 18477, 9010, 1466, 27707, 26175, 11584, 18369, 11586, 11587, 34624, 16197, 26182, 18376, 26185, 3660, 35151, 3407, 4434, 3668, 4833, 4834, 26980, 26857, 20716, 4845, 20718, 15858, 27250, 4852, 27251, 3839}\n",
      "dict_items([(\"Lemma('animal.n.01.animal')\", 26), (\"Lemma('animal.s.01.animal')\", 1)])\n",
      "collecting tokens for  true\n",
      "indices:    {2530, 30307, 13435, 13558, 1400, 15545, 31963, 13437}\n",
      "dict_items([(\"Lemma('true.a.01.true')\", 6)])\n",
      "collecting tokens for  conscious\n",
      "indices:    {31104, 26755, 2312, 30736, 34065, 24338, 2328, 33436, 13982, 27810, 34979, 31913, 2474, 26795, 14634, 16433, 14388, 16442, 31163, 16443, 13759, 30785, 16194, 14403, 32450, 16453, 12228, 30790, 32860, 8542, 31202, 9197, 36718, 22001, 14712}\n",
      "dict_items([(\"Lemma('conscious.s.01.conscious')\", 7), (\"Lemma('conscious.a.02.conscious')\", 6)])\n",
      "collecting tokens for  creative\n",
      "indices:    {30729, 30730, 30732, 30733, 30736, 7568, 4630, 32031, 30752, 21919, 30253, 25648, 14653, 1341, 32062, 1344, 22726, 22728, 32076, 11214, 2647, 27994, 11229, 32095, 11234, 27493, 14438, 32104, 11255, 7545, 11259, 14204, 11263}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('creative.a.01.creative')\", 13), (\"Lemma('creative.s.02.creative')\", 2)])\n",
      "collecting tokens for  ability\n",
      "indices:    {28041, 28554, 30732, 3212, 30736, 23569, 23189, 28694, 663, 26008, 6040, 22304, 29857, 30649, 4922, 23613, 3902, 14910, 28608, 26049, 12100, 25288, 2761, 2763, 23889, 36311, 32216, 4956, 14175, 4960, 32868, 22631, 13289, 26218, 20842, 17004, 12272, 5489, 14195, 14197, 28149, 31095, 633, 12027, 14204, 638}\n",
      "dict_items([(\"Lemma('ability.n.01.ability')\", 16), (\"Lemma('ability.n.02.ability')\", 6)])\n",
      "collecting tokens for  sharp\n",
      "indices:    {6907, 1125, 20678, 29068, 13808, 17361, 14418, 34035, 28379, 11326, 7839}\n",
      "dict_items([(\"Lemma('astute.s.01.sharp')\", 1), (\"Lemma('crisp.s.01.sharp')\", 2), (\"Lemma('acuate.s.01.sharp')\", 1)])\n",
      "collecting tokens for  edges\n",
      "indices:    {20618, 3214, 28825, 9626, 11315, 29625, 29629, 29631, 14787, 29638, 4937, 29527, 29658, 29786, 1888, 29800, 26219, 29678, 29679, 29552, 29553, 29687, 28793, 5756, 29689}\n",
      "dict_items([(\"Lemma('edge.n.01.edge')\", 5), (\"Lemma('edge.n.03.edge')\", 1), (\"Lemma('boundary.n.02.edge')\", 1)])\n",
      "collecting tokens for  restless\n",
      "indices:    {21920, 13827, 31881, 26415, 20624, 35545, 10555, 5756}\n",
      "dict_items([(\"Lemma('restless.s.01.restless')\", 2)])\n",
      "collecting tokens for  sea\n",
      "indices:    {19490, 8867, 24034, 10213, 36453, 8901, 30345, 12333, 12718, 12781, 12751, 36369, 36339, 8884, 27988, 27519, 8890, 7839}\n",
      "dict_items([(\"Lemma('sea.n.01.sea')\", 7)])\n",
      "collecting tokens for  waves\n",
      "indices:    {2816, 29700, 11408, 11409, 12706, 12707, 12710, 12714, 19244, 12717, 12722, 14004, 12726, 12729, 29372, 2811, 12864, 12740, 12741, 12742, 6727, 12744, 27977, 12746, 12747, 27979, 12749, 27975, 30289, 12754, 12759, 12796, 12774, 10475, 12779, 2157, 2158, 18930, 12789, 12790, 2809, 12795, 5756, 12797}\n",
      "dict_items([(\"Lemma('wave.n.01.wave')\", 23), (\"Lemma('wave.n.03.wave')\", 7), (\"Lemma('wave.n.02.wave')\", 1)])\n",
      "collecting tokens for  themselves\n",
      "indices:    {23556, 2574, 14350, 16399, 34835, 11799, 31774, 1573, 2090, 32300, 27696, 24624, 24625, 25140, 9786, 13370, 31804, 25151, 13897, 30794, 2642, 15452, 26205, 14433, 3689, 27753, 27243, 25197, 27762, 32373, 629, 5756, 36992, 36996, 25733, 3723, 3211, 3214, 24207, 11410, 19603, 17555, 26259, 26773, 13973, 13464, 25753, 27292, 27293, 12448, 28323, 30373, 37031, 13479, 20144, 25779, 2228, 24246, 2744, 35514, 32443, 7867, 20667, 2234, 24770, 24773, 11974, 25286, 21704, 27334, 37067, 31948, 27853, 27857, 36051, 5844, 27861, 17115, 30431, 36585, 21749, 24825, 30969, 31998, 12031, 13569, 12033, 27907, 5381, 21258, 32014, 30478, 13584, 18194, 14104, 5402, 5404, 4893, 17185, 21794, 2337, 27425, 20774, 28454, 20266, 4908, 20781, 20782, 4400, 13621, 6967, 32059, 12606, 32065, 5954, 14661, 32076, 1868, 32078, 13647, 26960, 13648, 1878, 13655, 32091, 348, 1373, 15200, 13670, 13671, 35692, 31085, 1391, 24435, 24437, 32118, 25466, 20347, 14208, 21378, 22402, 15753, 22409, 35209, 32140, 27020, 32143, 32144, 16785, 25495, 24988, 17822, 31135, 12192, 4004, 2473, 32172, 1965, 13230, 1969, 34737, 1970, 32188, 34752, 32192, 26051, 13764, 25541, 33225, 11721, 25547, 31704, 21979, 33244, 2525, 2528, 29155, 1507, 33252, 27110, 14311, 27111, 30695, 29164, 16366, 25072, 5112, 29692, 29693, 4606}\n",
      "dict_items([])\n",
      "collecting tokens for  upward\n",
      "indices:    {30348, 34066, 1563, 10532, 35626, 34097, 36020, 21814, 15052, 33230, 23377, 9171, 33238, 24022, 18531, 18533, 18663, 23402, 5756}\n",
      "dict_items([(\"Lemma('upward.s.01.upward')\", 1), (\"Lemma('up.r.01.upward')\", 6)])\n",
      "collecting tokens for  angry\n",
      "indices:    {33289, 24202, 23052, 23053, 6925, 36500, 10388, 17044, 23064, 34458, 34975, 33576, 19246, 34612, 31676, 31678, 18635, 8654, 19154, 36830, 12258, 18021, 9071, 10744, 18426, 5756}\n",
      "dict_items([(\"Lemma('angry.a.01.angry')\", 12), (\"Lemma('angry.s.02.angry')\", 1)])\n",
      "collecting tokens for  motion\n",
      "indices:    {9881}\n",
      "dict_items([])\n",
      "collecting tokens for  papa-san\n",
      "indices:    {5757}\n",
      "dict_items([(\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  sat\n",
      "indices:    {34822, 9224, 19977, 10764, 9230, 36370, 18966, 19990, 10792, 19506, 10812, 19011, 36420, 16965, 7757, 9304, 9306, 10844, 36444, 36448, 9315, 9317, 36966, 20078, 36989, 5758, 20107, 34962, 8340, 17044, 20123, 9382, 8870, 17585, 9396, 29367, 17598, 9409, 33475, 7885, 17102, 8398, 33485, 21716, 8919, 29403, 7901, 35038, 8418, 35562, 10987, 7404, 7917, 35054, 9460, 17657, 13568, 26370, 5890, 26888, 28427, 5901, 13583, 10002, 26394, 17691, 10523, 19232, 24353, 19752, 36649, 7978, 36652, 36653, 5951, 13122, 6979, 31554, 10572, 22353, 6496, 9571, 8039, 8050, 36739, 19849, 36755, 16787, 17813, 9630, 15799, 19896, 16832, 19918, 17885, 5603, 7653, 34792, 6128, 2033, 7667}\n",
      "dict_items([(\"Lemma('sit.v.01.sit')\", 26), (\"Lemma('sit_down.v.01.sit')\", 5), (\"Lemma('sit.v.02.sit')\", 12), (\"Lemma('ride.v.01.sit')\", 1), (\"Lemma('sit.v.04.sit')\", 1)])\n",
      "collecting tokens for  smooth\n",
      "indices:    {28800, 13577, 28816, 18970, 34206, 5756, 28838, 28841, 36017, 3635, 4925, 30781, 29631, 704, 8132, 28757, 26838, 88, 29784, 1626, 2397, 8185, 10597, 29672, 26473, 8173, 4083, 8180, 28793, 29563, 29564, 29565}\n",
      "dict_items([(\"Lemma('smooth.a.01.smooth')\", 10), (\"Lemma('smooth.a.03.smooth')\", 1), (\"Lemma('polish.v.01.smooth')\", 1), (\"Lemma('politic.s.02.smooth')\", 3), (\"Lemma('smooth.v.01.smooth')\", 3)])\n",
      "collecting tokens for  money\n",
      "indices:    {18305, 37121, 515, 19075, 12037, 25090, 20871, 775, 521, 8074, 11147, 13, 18578, 19219, 21780, 2327, 21271, 16665, 9626, 18587, 16668, 12186, 5275, 21663, 36132, 11940, 25256, 17705, 2217, 2347, 23598, 14898, 52, 32567, 8247, 16570, 11835, 16443, 18621, 13759, 31684, 36677, 18244, 16455, 2252, 23630, 23506, 2258, 5463, 11736, 33368, 5083, 989, 992, 29921, 25826, 23139, 33380, 17381, 6756, 17383, 12648, 15591, 30186, 20203, 36076, 11759, 8177, 11763, 28662, 30711, 30712, 23931, 36092, 8191}\n",
      "dict_items([(\"Lemma('money.n.01.money')\", 26), (\"Lemma('money.n.02.money')\", 6)])\n",
      "collecting tokens for  argument\n",
      "indices:    {17664, 22786, 4867, 22663, 14343, 3723, 14347, 16658, 12948, 1313, 26148, 37156, 20911, 434, 21811, 12212, 4533, 4919, 1336, 16569, 32058, 4796, 4547, 4931, 4548, 27771, 1355, 16333, 11856, 4561, 13658, 4570, 6112, 14432, 12002, 25444, 26725, 21479, 12009, 5484, 4848, 4850, 14326, 25976, 29945, 14459, 16382, 12415}\n",
      "dict_items([(\"Lemma('argument.n.01.argument')\", 19), (\"Lemma('controversy.n.01.argument')\", 13), (\"Lemma('argument.n.03.argument')\", 2), (\"Lemma('argument.n.04.argument')\", 1)])\n",
      "collecting tokens for  husband\n",
      "indices:    {16903, 26636, 26640, 26641, 8210, 26644, 21015, 8727, 22051, 21541, 21544, 30760, 30248, 30763, 22573, 21038, 30777, 10811, 8770, 23114, 32844, 27217, 30803, 30805, 22103, 30812, 30815, 7277, 30834, 25214, 26240, 7297, 643, 36486, 37009, 33945, 24730, 33947, 36010, 11960, 11965, 22205, 25792, 11969, 11973, 11985, 11987, 11989, 11991, 11992, 11993, 8410, 21213, 17118, 11998, 12000, 2271, 12002, 2276, 2277, 12006, 12005, 12011, 12013, 12014, 12015, 12017, 37117, 12036, 37126, 775, 37129, 12050, 12052, 12059, 12065, 33570, 12066, 37158, 17202, 24919, 16742, 10614, 16761, 20863, 13815, 20873, 36240, 33170, 36247, 10657, 25003, 15280, 8113, 25010, 15281, 15284, 33718, 1479, 28617, 31693, 26076, 8156, 10225, 10227, 14324, 10743, 5626}\n",
      "dict_items([(\"Lemma('husband.n.01.husband')\", 26)])\n",
      "collecting tokens for  until\n",
      "indices:    {609}\n",
      "dict_items([])\n",
      "collecting tokens for  matter\n",
      "indices:    {10242, 16899, 14853, 1030, 11271, 20997, 5130, 26638, 25615, 25616, 25617, 10770, 21009, 26644, 30231, 15384, 7194, 7196, 21536, 34337, 36899, 1576, 8233, 17452, 19503, 24116, 10293, 2102, 32312, 2106, 34371, 27725, 32846, 13390, 1105, 15444, 27220, 2134, 1621, 26197, 3158, 3167, 32352, 2146, 10341, 25194, 32363, 20076, 2157, 2159, 25712, 36977, 3699, 8819, 2165, 2171, 30843, 12924, 27262, 3199, 36995, 25733, 8328, 29833, 34443, 3211, 27279, 22677, 8345, 22683, 8348, 671, 1184, 25762, 22692, 6822, 23206, 17583, 7863, 20155, 16063, 1220, 26822, 1223, 20678, 26827, 26829, 1230, 19667, 15573, 19672, 8414, 3807, 20703, 10977, 12002, 19682, 24804, 22754, 29924, 25829, 25313, 24810, 33002, 16115, 17139, 24309, 13559, 6911, 9987, 27917, 19727, 34576, 16149, 281, 10526, 33055, 2337, 36134, 34092, 12080, 24891, 32572, 20285, 26940, 32577, 24898, 17734, 32587, 30540, 32588, 20302, 10581, 14680, 5980, 31581, 26980, 31590, 32615, 14696, 32617, 20333, 31085, 16752, 5489, 20851, 24952, 26493, 22397, 14719, 33162, 10655, 24991, 23970, 30115, 8614, 23977, 17836, 19372, 14256, 18352, 435, 25017, 34751, 30658, 12228, 18374, 459, 34256, 15825, 8665, 27097, 36826, 28636, 32218, 27103, 2019, 24547, 12261, 2025, 12266, 15850, 2033, 20468, 16374, 10745, 15868, 23038}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('topic.n.02.matter')\", 19), (\"Lemma('matter.n.01.matter')\", 21), (\"Lemma('count.v.02.matter')\", 13), (\"Lemma('matter.n.03.matter')\", 7)])\n",
      "collecting tokens for  settled\n",
      "indices:    {8832, 4993, 7302, 9226, 7822, 14230, 36122, 25758, 2335, 7328, 13472, 36641, 6947, 16548, 8875, 30893, 12463, 5554, 9398, 5815, 18870, 8889, 22843, 5564, 36287, 4803, 24006, 24264, 11210, 36043, 28621, 31694, 2513, 15187, 33364, 17363, 34393, 13405, 21342, 5345, 12002, 30561, 23270, 23529, 34157, 12399, 8569}\n",
      "dict_items([(\"Lemma('sink.v.04.settle')\", 2), (\"Lemma('decide.v.02.settle')\", 3), (\"Lemma('settle.v.01.settle')\", 14), (\"Lemma('settle.v.10.settle')\", 1), (\"Lemma('settle.v.04.settle')\", 3), (\"Lemma('settle.v.09.settle')\", 2), (\"Lemma('settled.a.01.settled')\", 2), (\"Lemma('reconcile.v.03.settle')\", 3), (\"Lemma('settle.v.03.settle')\", 4), (\"Lemma('colonized.s.01.settled')\", 1), (\"Lemma('settle.v.07.settle')\", 2)])\n",
      "collecting tokens for  favor\n",
      "indices:    {12929, 30052, 35374, 19441, 21562, 31996}\n",
      "dict_items([(\"Lemma('favor.n.02.favor')\", 1), (\"Lemma('favor.v.03.favor')\", 1)])\n",
      "collecting tokens for  job\n",
      "indices:    {20995, 6148, 11785, 8205, 8207, 8210, 11287, 8217, 17946, 22556, 19486, 2084, 24101, 22053, 20006, 17960, 11306, 20015, 5170, 11828, 31285, 11830, 11831, 29753, 11837, 15421, 17982, 8253, 29765, 3668, 36438, 35930, 12894, 26212, 12901, 31334, 33383, 14952, 3180, 1647, 9843, 2681, 20096, 36481, 2178, 12930, 20100, 24198, 16009, 9866, 10382, 28814, 32401, 24722, 24211, 26772, 14997, 2714, 19615, 19112, 36522, 21163, 9900, 1205, 20670, 16577, 29891, 35012, 14539, 14540, 21196, 29903, 721, 35539, 17110, 11993, 220, 12006, 12008, 12009, 12011, 32494, 9458, 26890, 5899, 23825, 23827, 20767, 18208, 22309, 28455, 5427, 21811, 28472, 17722, 12093, 12094, 28478, 26432, 31042, 18243, 12102, 35654, 25927, 12111, 341, 35670, 20311, 12126, 12640, 17770, 24942, 12145, 12147, 11640, 29058, 30084, 17289, 24973, 26509, 15757, 24976, 15761, 18321, 16280, 30617, 11165, 16289, 11683, 1956, 29093, 16292, 28579, 34216, 16297, 16294, 16301, 15790, 31662, 16306, 13239, 11706, 13244, 16316, 13247, 31682, 22467, 24004, 13254, 25031, 469, 26586, 13279, 480, 482, 13285, 30181, 13287, 13288, 24563, 19958, 30201, 13306}\n",
      "dict_items([(\"Lemma('occupation.n.01.job')\", 26), (\"Lemma('job.n.04.job')\", 2), (\"Lemma('job.n.02.job')\", 26), (\"Lemma('job.n.03.job')\", 3), (\"Lemma('job.n.05.job')\", 1)])\n",
      "collecting tokens for  mean\n",
      "indices:    {27649, 6148, 30730, 24074, 21518, 12817, 33302, 33311, 17439, 10784, 17954, 11299, 13347, 14372, 13350, 11815, 34848, 18475, 34865, 15409, 30262, 18998, 33337, 3131, 27721, 19018, 19019, 31822, 15441, 36951, 5722, 22624, 19043, 26217, 12914, 36468, 12916, 16502, 6272, 27776, 31362, 27780, 27781, 27784, 13456, 12963, 13994, 31404, 20145, 28852, 27829, 33974, 35003, 8892, 37052, 18631, 10952, 17619, 4826, 33499, 4827, 9441, 20706, 9443, 4836, 8944, 31987, 24308, 32500, 4851, 4859, 35077, 5902, 20241, 2321, 30997, 5909, 1303, 3865, 3866, 1306, 3868, 29469, 3869, 3358, 14626, 14627, 28452, 14631, 23336, 12076, 4399, 31535, 29489, 3889, 3888, 3892, 1333, 3894, 3893, 16179, 35125, 16182, 14646, 3901, 10051, 27972, 9544, 3913, 3914, 13643, 3917, 15697, 4949, 33111, 3927, 8028, 15710, 16736, 10080, 15712, 32616, 24952, 2938, 10618, 2940, 6016, 10124, 31117, 2957, 27538, 24982, 3991, 29079, 20376, 30119, 2476, 2478, 20399, 17850, 1469, 10181, 7115, 33742, 28118, 26584, 26589, 1502, 33248, 10730, 19955, 17912, 17915}\n",
      "dict_items([(\"Lemma('entail.v.01.mean')\", 26), (\"Lemma('average.s.01.mean')\", 16), (\"Lemma('mean.v.01.mean')\", 26), (\"Lemma('mean.n.01.mean')\", 9), (\"Lemma('think_of.v.04.mean')\", 7), (\"Lemma('mean.v.03.mean')\", 9), (\"Lemma('intend.v.01.mean')\", 6), (\"Lemma('base.s.05.mean')\", 1), (\"Lemma('mean.v.05.mean')\", 1), (\"Lemma('hateful.s.02.mean')\", 3)])\n",
      "collecting tokens for  practically\n",
      "indices:    {11689, 6042, 17926, 15415}\n",
      "dict_items([(\"Lemma('practically.r.01.practically')\", 4)])\n",
      "collecting tokens for  end\n",
      "indices:    {11392, 17801, 28809, 12299, 13452, 35223, 5399, 14615, 14748, 29214, 24863, 21281, 13601, 29736, 32170, 7595, 23852, 301, 1454, 31531, 5687, 33848, 4544, 25669, 19527, 29128, 20041, 20430, 21326, 471, 24666, 15964, 31582, 32612, 3556, 7910, 14314, 35692, 29677, 14959, 8560, 7408, 25200, 2423, 25848, 890, 12283, 24188}\n",
      "dict_items([(\"Lemma('end.n.03.end')\", 4), (\"Lemma('end.v.01.end')\", 2), (\"Lemma('end.v.02.end')\", 5), (\"Lemma('end.n.02.end')\", 8), (\"Lemma('end.n.05.end')\", 3), (\"Lemma('goal.n.01.end')\", 1), (\"Lemma('end.n.08.end')\", 1), (\"Lemma('end.n.01.end')\", 2), (\"Lemma('end.n.06.end')\", 1)])\n",
      "collecting tokens for  methodist\n",
      "indices:    {1395}\n",
      "dict_items([(\"Lemma('methodist.a.01.Methodist')\", 1)])\n",
      "collecting tokens for  church\n",
      "indices:    {1430, 27687}\n",
      "dict_items([])\n",
      "collecting tokens for  churches\n",
      "indices:    {12304, 20847}\n",
      "dict_items([])\n",
      "collecting tokens for  madden\n",
      "indices:    {17334}\n",
      "dict_items([(\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  able\n",
      "indices:    {16898, 19464, 4621, 29710, 5141, 5654, 29719, 26136, 30234, 13339, 16925, 26667, 15406, 2607, 35378, 33844, 20535, 12344, 23102, 8255, 12350, 25155, 28228, 12881, 27734, 2647, 2139, 8288, 5217, 30817, 23141, 24168, 32875, 10861, 23666, 19572, 24188, 20097, 25732, 6280, 9868, 20621, 24721, 35474, 20625, 23189, 27798, 10901, 33942, 20125, 11424, 32932, 12457, 17579, 174, 27823, 25264, 2761, 16075, 23250, 37082, 16091, 30939, 23259, 27360, 14562, 28898, 28901, 25830, 7400, 27881, 26859, 241, 2290, 1784, 26362, 21758, 778, 24842, 18705, 21795, 28453, 26406, 18727, 20782, 17716, 28480, 322, 323, 8002, 4942, 31057, 339, 29017, 4955, 22366, 14174, 24933, 16230, 14697, 12650, 15724, 25967, 30066, 31604, 13696, 26504, 27531, 14221, 3984, 917, 20888, 32152, 5016, 10139, 14239, 32161, 22947, 21924, 20393, 11181, 31665, 13746, 7603, 31154, 16307, 26033, 12219, 16315, 34749, 17342, 23491, 5059, 13768, 12744, 31183, 2000, 21460, 36309, 15832, 10204, 33251, 11237, 36839, 13288, 24553, 33261, 12270, 33262, 25075, 11255, 23546, 27133, 28671}\n",
      "dict_items([(\"Lemma('able.a.01.able')\", 26), (\"Lemma('able.s.02.able')\", 5), (\"Lemma('able.s.03.able')\", 4)])\n",
      "collecting tokens for  find\n",
      "indices:    {28102, 30665, 30731, 4524, 24821}\n",
      "dict_items([(\"Lemma('determine.v.01.find')\", 2), (\"Lemma('find.v.05.find')\", 1)])\n",
      "collecting tokens for  fault\n",
      "indices:    {19717, 25286, 6791, 24519, 6792, 11180, 32012, 20022, 36184, 17342}\n",
      "dict_items([(\"Lemma('mistake.n.01.fault')\", 4), (\"Lemma('defect.n.03.fault')\", 1)])\n",
      "collecting tokens for  statement\n",
      "indices:    {15362, 22030, 27153, 2588, 16422, 31786, 27695, 27696, 24111, 6192, 30264, 24130, 30279, 20571, 20576, 20580, 15973, 34919, 14459, 22652, 12418, 31875, 10886, 4754, 30868, 5271, 1193, 13995, 13997, 22706, 20171, 4815, 3802, 4829, 4830, 4317, 15581, 16101, 16115, 32500, 29939, 16118, 24828, 4869, 26378, 16144, 23825, 22804, 15639, 36633, 21786, 1308, 1309, 21287, 15669, 11064, 21304, 20294, 33096, 5463, 13155, 10621, 10625, 21381, 31116, 31122, 1439, 17831, 20395, 21425, 14258, 21427, 21426, 21428, 1466, 21435, 15292, 20413, 17342, 31678, 31679, 20417, 3004, 21959, 25035, 21461, 15331, 15334, 15847, 31208, 15335, 14312, 15339, 27631, 15864}\n",
      "dict_items([(\"Lemma('statement.n.01.statement')\", 26), (\"Lemma('argument.n.01.statement')\", 8)])\n",
      "collecting tokens for  assumption\n",
      "indices:    {27776, 3072, 1025, 15235, 30339, 3358, 14883, 3367, 3372, 33197, 4911, 4912, 3377, 2488, 3003, 14660, 4292, 32839, 21832, 4439, 26202, 13921, 14691, 31206, 16379}\n",
      "dict_items([(\"Lemma('assumption.n.02.assumption')\", 5), (\"Lemma('premise.n.01.assumption')\", 12), (\"Lemma('assumption.n.03.assumption')\", 1)])\n",
      "collecting tokens for  friends\n",
      "indices:    {25129, 24077, 19639}\n",
      "dict_items([(\"Lemma('friend.n.01.friend')\", 1)])\n",
      "collecting tokens for  humans\n",
      "indices:    {10054, 22443, 10092, 27821, 11154, 17240, 2488, 7900, 21502}\n",
      "dict_items([(\"Lemma('homo.n.02.human')\", 1)])\n",
      "collecting tokens for  liberal\n",
      "indices:    {20980}\n",
      "dict_items([])\n",
      "collecting tokens for  least\n",
      "indices:    {14337, 1026, 12291, 32264, 16907, 28171, 4621, 15885, 15886, 26639, 30744, 4640, 30243, 31783, 17959, 25642, 2602, 11307, 10794, 15171, 24623, 33842, 33844, 32308, 9782, 33847, 2104, 1079, 32309, 24120, 11835, 15424, 14401, 26691, 3652, 1096, 1097, 16458, 14412, 25679, 4691, 30804, 20057, 34395, 31835, 34400, 14945, 13409, 31335, 26727, 9838, 26736, 27760, 36466, 22133, 32373, 27255, 12408, 20090, 20606, 6784, 19073, 22658, 23169, 34952, 10889, 20105, 14986, 25740, 3725, 29325, 33935, 25744, 12945, 14484, 19096, 20120, 155, 23197, 27807, 31906, 3748, 32932, 19109, 27306, 3246, 25264, 19633, 32436, 16054, 26807, 1208, 37047, 1211, 37057, 18131, 25301, 30425, 22235, 23260, 27870, 9438, 26848, 10465, 16101, 7400, 12008, 23275, 33004, 30961, 16118, 3319, 30456, 27897, 15100, 15103, 15105, 20227, 13059, 30469, 5894, 25349, 25860, 5388, 13072, 30996, 19220, 5397, 25366, 6938, 15132, 5405, 23838, 28449, 15655, 25383, 15656, 1321, 15147, 25388, 17709, 28462, 14632, 13617, 819, 9526, 8503, 19257, 26426, 1340, 829, 23874, 16194, 13123, 24901, 1348, 5447, 31046, 1353, 1354, 32587, 25415, 30029, 1360, 28496, 1362, 24913, 1368, 27994, 31578, 4958, 31071, 27999, 14689, 15713, 14691, 24932, 4965, 15206, 13161, 24431, 16241, 15219, 24952, 22396, 894, 29057, 28034, 23943, 31111, 23945, 17292, 1936, 1425, 24980, 28054, 22941, 5026, 2467, 31653, 6568, 18857, 2474, 21418, 25515, 21416, 27049, 6066, 25013, 32182, 21431, 2488, 25531, 15803, 26048, 1987, 21956, 11715, 26052, 4550, 26055, 1989, 23500, 13261, 4559, 17360, 3538, 25556, 36824, 13273, 10202, 35290, 27609, 31197, 3559, 12779, 11758, 3567, 15858, 17907, 21494, 31230}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('least.r.01.least')\", 5), (\"Lemma('least.a.01.least')\", 2)])\n",
      "collecting tokens for  partly\n",
      "indices:    {19621, 15478}\n",
      "dict_items([(\"Lemma('partially.r.01.partly')\", 2)])\n",
      "collecting tokens for  sympathy\n",
      "indices:    {5313, 24831, 5319, 23824, 2102, 19423}\n",
      "dict_items([(\"Lemma('sympathy.n.01.sympathy')\", 2)])\n",
      "collecting tokens for  views\n",
      "indices:    {24204, 1036, 25748, 15252, 16412, 11424, 14636, 26157, 20655, 1844, 2488, 1849, 1848, 1851, 2494, 16450, 29251, 1869, 25039, 2896, 32210, 8787, 5332, 22613, 25046, 11481, 20333, 3823, 20335, 25585, 22648, 2169, 27005}\n",
      "dict_items([(\"Lemma('view.n.02.view')\", 6), (\"Lemma('scene.n.08.view')\", 2), (\"Lemma('position.n.03.view')\", 6), (\"Lemma('opinion.n.02.view')\", 2), (\"Lemma('see.v.05.view')\", 1), (\"Lemma('opinion.n.01.view')\", 2), (\"Lemma('view.n.03.view')\", 1)])\n",
      "collecting tokens for  stand\n",
      "indices:    {10628, 12304, 13586, 28053, 29846, 20246, 21530, 19374, 20785, 23604, 20793, 1081, 20795, 33855, 1985, 1346, 3523, 31567, 9425, 27478, 13529, 27739, 24159, 10470, 31726, 20468, 14201, 30074}\n",
      "dict_items([(\"Lemma('rack.n.05.stand')\", 1), (\"Lemma('stand.v.08.stand')\", 2), (\"Lemma('stand.n.03.stand')\", 1), (\"Lemma('stand.v.04.stand')\", 3), (\"Lemma('stand.v.06.stand')\", 3), (\"Lemma('stand.n.02.stand')\", 1), (\"Lemma('stand.v.01.stand')\", 4), (\"Lemma('stand.v.07.stand')\", 1)])\n",
      "collecting tokens for  public\n",
      "indices:    {1376, 22338, 9837, 10958, 11282}\n",
      "dict_items([(\"Lemma('populace.n.01.public')\", 1), (\"Lemma('public.a.01.public')\", 2)])\n",
      "collecting tokens for  teach\n",
      "indices:    {19844, 1544, 11274, 283, 2075, 157, 1439, 28577, 10276, 8998, 2095, 25025, 23233, 2115, 10051, 5966, 22362, 24569, 22113, 25955, 6767, 14063, 14578, 757, 759, 35961}\n",
      "dict_items([(\"Lemma('teach.v.01.teach')\", 26)])\n",
      "collecting tokens for  christian\n",
      "indices:    {28039}\n",
      "dict_items([])\n",
      "collecting tokens for  faith\n",
      "indices:    {14080, 1409, 16901, 27918, 13328, 27408, 1302, 1431, 25369, 1308, 7073, 28323, 37156, 28326, 32679, 17192, 2476, 25523, 28341, 20793, 27326, 27330, 4674, 27341, 27601, 22354, 27350, 27992, 27994, 34395, 28254, 27487, 14435, 8041, 27501, 13044, 28023, 27515}\n",
      "dict_items([(\"Lemma('religion.n.01.faith')\", 8), (\"Lemma('faith.n.02.faith')\", 4), (\"Lemma('religion.n.02.faith')\", 1)])\n",
      "collecting tokens for  harder\n",
      "indices:    {11712, 28963, 8932, 7879, 29896, 31112, 5450, 1674, 5357, 10800, 23603, 661, 25431, 22362, 733}\n",
      "dict_items([(\"Lemma('difficult.a.01.hard')\", 6), (\"Lemma('hard.r.01.hard')\", 1), (\"Lemma('hard.s.04.hard')\", 2)])\n",
      "collecting tokens for  those\n",
      "indices:    {32625, 10891, 2502}\n",
      "dict_items([])\n",
      "collecting tokens for  explains\n",
      "indices:    {27238, 22694, 20999, 31596, 4239, 31025, 25050, 2139}\n",
      "dict_items([(\"Lemma('explain.v.01.explain')\", 8)])\n",
      "collecting tokens for  slender\n",
      "indices:    {26112, 7552, 6436, 18886, 11430, 36455, 425, 7370, 8913, 689, 22516, 7544, 22362, 252, 1951}\n",
      "dict_items([(\"Lemma('slender.s.01.slender')\", 6), (\"Lemma('slender.s.04.slender')\", 1), (\"Lemma('lissome.s.01.slender')\", 1), (\"Lemma('slender.s.02.slender')\", 3)])\n",
      "collecting tokens for  vice\n",
      "indices:    {6000, 30945}\n",
      "dict_items([])\n",
      "collecting tokens for  sunday\n",
      "indices:    {447}\n",
      "dict_items([(\"Lemma('sunday.n.01.Sunday')\", 1)])\n",
      "collecting tokens for  class\n",
      "indices:    {28576, 13735}\n",
      "dict_items([(\"Lemma('class.n.03.class')\", 1)])\n",
      "collecting tokens for  wooden\n",
      "indices:    {29957, 29963, 20107, 10638, 6035, 29602, 33579, 10540, 5806, 29618, 29646, 18517, 15074, 29540, 29926, 29545, 29546, 29551, 12537}\n",
      "dict_items([(\"Lemma('wooden.s.01.wooden')\", 7)])\n",
      "collecting tokens for  sculpture\n",
      "indices:    {7554, 2404, 5001, 11051, 7598, 7568, 21105, 7538, 7410, 5014, 11133}\n",
      "dict_items([(\"Lemma('sculpture.n.01.sculpture')\", 7), (\"Lemma('sculpture.n.02.sculpture')\", 3)])\n",
      "collecting tokens for  representing\n",
      "indices:    {14208, 20704, 99, 23560, 37098, 14219, 15692, 20139, 15694, 22509, 2704, 22515, 1364, 32443, 22783}\n",
      "dict_items([(\"Lemma('represent.v.03.represent')\", 1), (\"Lemma('represent.v.04.represent')\", 4), (\"Lemma('represent.v.01.represent')\", 4), (\"Lemma('represent.v.05.represent')\", 1), (\"Lemma('typify.v.02.represent')\", 3), (\"Lemma('defend.v.06.represent')\", 2)])\n",
      "collecting tokens for  bent\n",
      "indices:    {23306, 31754, 36749, 29199, 1553, 17561, 8606, 16927, 34722, 35109, 14502, 31399, 36647, 36393, 31397, 24368, 1983, 9162, 16716, 5712, 2004, 14442, 9461, 28410, 11133, 31487}\n",
      "dict_items([(\"Lemma('crouch.v.01.bend')\", 2), (\"Lemma('bend.v.01.bend')\", 9), (\"Lemma('bend.v.02.bend')\", 5), (\"Lemma('bent.n.01.bent')\", 2), (\"Lemma('deflect.v.02.bend')\", 1)])\n",
      "collecting tokens for  backward\n",
      "indices:    {27809, 27801, 30147, 1591, 6386, 31795, 2007, 4569, 23834, 34108, 11133}\n",
      "dict_items([(\"Lemma('back.r.02.backward')\", 2), (\"Lemma('backward.a.01.backward')\", 2), (\"Lemma('backward.r.02.backward')\", 1)])\n",
      "collecting tokens for  bodies\n",
      "indices:    {34689, 31489, 4102, 4103, 3593, 2064, 10261, 27926, 28054, 10264, 27935, 34810, 21431, 12727, 2617, 15417, 30395, 36926, 16190, 31424, 23874, 21187, 36040, 11081, 34891, 27470, 4687, 25681, 34642, 34646, 25815, 34650, 28635, 4188, 24797, 28638, 7773, 10714, 11489, 11490, 22627, 8573, 35557, 2793, 10484, 34679, 10232, 25337, 23802, 22268, 11133}\n",
      "dict_items([(\"Lemma('body.n.01.body')\", 9), (\"Lemma('body.n.04.body')\", 6), (\"Lemma('body.n.02.body')\", 2), (\"Lemma('celestial_body.n.01.heavenly_body')\", 1), (\"Lemma('body.n.06.body')\", 1), (\"Lemma('body.n.03.body')\", 1)])\n",
      "collecting tokens for  particularly\n",
      "indices:    {24581, 2310, 10890, 13196, 16144, 4634, 32925, 15521, 3239, 14633, 12074, 25646, 2863, 14384, 22705, 21297, 17729, 22725, 17351, 14152, 12104, 26959, 27862, 22625, 15842, 33002, 14059, 1654, 6266, 21628, 32511}\n",
      "dict_items([(\"Lemma('particularly.r.01.particularly')\", 19)])\n",
      "collecting tokens for  attention\n",
      "indices:    {18437, 11291, 20509, 22558, 24096, 30245, 15401, 15407, 16432, 23601, 23599, 15414, 30775, 20025, 3646, 14399, 18504, 13391, 30812, 25697, 26744, 17528, 14974, 9342, 9345, 36997, 34437, 16006, 16010, 14477, 25237, 25751, 5300, 20149, 17588, 18624, 32451, 1735, 16082, 1236, 9942, 13530, 5855, 22752, 17127, 12011, 17142, 32506, 11005, 3327, 14592, 14620, 27426, 14634, 25905, 11064, 31544, 35652, 4424, 26441, 14664, 14667, 14152, 24406, 13655, 25945, 26471, 24936, 24938, 14702, 29038, 35698, 14713, 32124, 11645, 11656, 32150, 3482, 28060, 11680, 25506, 32674, 32165, 26035, 6581, 14271, 32192, 31177, 34764, 12236, 9683, 13272, 3033, 30176, 35812, 8166, 1515, 27118, 30198, 22522}\n",
      "dict_items([(\"Lemma('attention.n.01.attention')\", 26), (\"Lemma('care.n.01.attention')\", 7), (\"Lemma('attention.n.06.attention')\", 1), (\"Lemma('attention.n.04.attention')\", 3), (\"Lemma('attention.n.05.attention')\", 2), (\"Lemma('attention.n.03.attention')\", 1)])\n",
      "collecting tokens for  howard\n",
      "indices:    {9280}\n",
      "dict_items([(\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  railroad\n",
      "indices:    {5165, 21957}\n",
      "dict_items([])\n",
      "collecting tokens for  drastic\n",
      "indices:    {21155, 24200, 22856, 21898, 22827, 24203, 1517, 25306}\n",
      "dict_items([(\"Lemma('drastic.s.01.drastic')\", 1)])\n",
      "collecting tokens for  decline\n",
      "indices:    {25824, 24129, 30753, 21155, 27877, 27880, 15274, 3147, 14904, 5455, 13329, 22066, 14900, 21876, 13914, 25880, 31513, 14906}\n",
      "dict_items([(\"Lemma('decline.n.01.decline')\", 4), (\"Lemma('decline.n.02.decline')\", 2), (\"Lemma('decay.n.02.decline')\", 1), (\"Lemma('worsen.v.01.decline')\", 2)])\n",
      "collecting tokens for  freight\n",
      "indices:    {14912, 29027, 23493, 18503, 22808, 6490, 36125, 14911}\n",
      "dict_items([(\"Lemma('cargo.n.01.freight')\", 3)])\n",
      "collecting tokens for  loading\n",
      "indices:    {28642, 21155, 5540, 5541, 5592, 34759, 5591, 29464}\n",
      "dict_items([(\"Lemma('load.n.02.loading')\", 2), (\"Lemma('load.n.01.loading')\", 2), (\"Lemma('load.v.01.load')\", 1)])\n",
      "collecting tokens for  due\n",
      "indices:    {8811, 29835, 15567, 3919, 13265, 4178, 13747, 30420, 25105, 27126, 25400, 11546, 4923}\n",
      "dict_items([(\"Lemma('due.s.02.due')\", 1), (\"Lemma('due.a.01.due')\", 1)])\n",
      "collecting tokens for  severe\n",
      "indices:    {37117, 27525, 21445, 14973, 33032, 23401, 4969, 2863, 37108, 4054, 30809, 5019, 21661, 15391}\n",
      "dict_items([(\"Lemma('austere.s.01.severe')\", 2), (\"Lemma('severe.s.01.severe')\", 3), (\"Lemma('hard.s.04.severe')\", 1)])\n",
      "collecting tokens for  slump\n",
      "indices:    {21155, 24645, 593, 34033, 35572, 35605, 24023, 441}\n",
      "dict_items([(\"Lemma('slump.n.01.slump')\", 2), (\"Lemma('slump.v.01.slump')\", 3)])\n",
      "collecting tokens for  movement\n",
      "indices:    {21890, 24546, 31870, 31947, 5837, 28078, 19157, 4950, 14455, 27774, 31902, 15391}\n",
      "dict_items([(\"Lemma('motion.n.06.movement')\", 1), (\"Lemma('movement.n.03.movement')\", 3)])\n",
      "collecting tokens for  goods\n",
      "indices:    {14213, 21911, 5144, 5275, 21155, 11685, 36908, 20783, 12474, 16443, 12480, 35522, 24009, 5455, 5477, 12520, 22761, 12523, 12524, 12525, 36080, 24054, 22779, 5244}\n",
      "dict_items([])\n",
      "collecting tokens for  necessitated\n",
      "indices:    {5506, 21155, 25484, 15660, 4057, 25305, 15511, 32760, 11865, 5500}\n",
      "dict_items([(\"Lemma('necessitate.v.01.necessitate')\", 7), (\"Lemma('necessitate.v.02.necessitate')\", 3)])\n",
      "collecting tokens for  novelist\n",
      "indices:    {31840, 14596, 14410, 11180, 26675, 14388, 27031, 13786}\n",
      "dict_items([(\"Lemma('novelist.n.01.novelist')\", 5)])\n",
      "collecting tokens for  atlanta\n",
      "indices:    {21474}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([])\n",
      "collecting tokens for  birmingham\n",
      "indices:    {1378}\n",
      "dict_items([(\"Lemma('birmingham.n.02.Birmingham')\", 1)])\n",
      "collecting tokens for  chicago\n",
      "indices:    {23430}\n",
      "dict_items([])\n",
      "collecting tokens for  favorites\n",
      "indices:    {14416, 29016, 884, 27078}\n",
      "dict_items([(\"Lemma('favorite.n.01.favorite')\", 2)])\n",
      "collecting tokens for  a.\n",
      "indices:    {20312}\n",
      "dict_items([])\n",
      "collecting tokens for  species\n",
      "indices:    {3841, 10632, 3605, 3989, 3734, 3610, 3611, 3614, 16164, 10791, 26537, 3630, 9401, 3649, 10691, 10819, 3652, 3663, 1872, 10848, 3938, 10851, 3836, 3686, 34540, 4211, 10612, 5238, 14583, 3834, 3835, 3708, 3711}\n",
      "dict_items([(\"Lemma('species.n.01.species')\", 26), (\"Lemma('species.n.02.species')\", 5)])\n",
      "collecting tokens for  england\n",
      "indices:    {1385}\n",
      "dict_items([(\"Lemma('england.n.01.England')\", 1)])\n",
      "collecting tokens for  sometimes\n",
      "indices:    {12784, 31920}\n",
      "dict_items([(\"Lemma('sometimes.r.01.sometimes')\", 1)])\n",
      "collecting tokens for  referred\n",
      "indices:    {20364, 24973, 12556, 32409, 3993, 2852, 30245, 6061, 2992, 3001, 12476, 17341, 31166, 3649, 1221, 15050, 15051, 1230, 2260, 10708, 14427, 28899, 25192, 10740, 25847}\n",
      "dict_items([(\"Lemma('refer.v.03.refer')\", 8), (\"Lemma('refer.v.04.refer')\", 4), (\"Lemma('refer.v.02.refer')\", 3), (\"Lemma('mention.v.01.refer')\", 8), (\"Lemma('denote.v.02.refer')\", 1), (\"Lemma('consult.v.02.refer')\", 1)])\n",
      "collecting tokens for  lawn\n",
      "indices:    {8290, 10883, 22504, 10537, 20881}\n",
      "dict_items([(\"Lemma('lawn.n.01.lawn')\", 3)])\n",
      "collecting tokens for  bee\n",
      "indices:    {3649, 18635, 3662, 3636, 3605, 3672, 3673, 10746, 10747, 3677}\n",
      "dict_items([(\"Lemma('bee.n.01.bee')\", 8)])\n",
      "collecting tokens for  6\n",
      "indices:    {22533, 21512, 3080, 15375, 21008, 4132, 28204, 12335, 11319, 12861, 28227, 21060, 28741, 587, 28236, 1633, 22113, 618, 109, 22127, 623, 28785, 3695, 21617, 15477, 631, 15481, 32893, 28812, 11416, 11931, 21670, 3763, 25783, 15033, 3263, 193, 15559, 15560, 28875, 2766, 32976, 24272, 28882, 20177, 32466, 215, 26328, 15582, 15077, 15604, 15103, 29958, 267, 2836, 21782, 26399, 29492, 29495, 3908, 22340, 20806, 3910, 3909, 3913, 11595, 12619, 22861, 3920, 11602, 11604, 3925, 4439, 3929, 22369, 359, 22376, 20847, 21367, 21881, 30076, 21373, 30077, 384, 16260, 29066, 5526, 5527, 5528, 5530, 11681, 25001, 15273, 27568, 25531, 3516, 22973, 961, 458, 4048, 3543, 15328, 14826, 20976, 30194, 20979, 30195, 23032, 15353, 3578}\n",
      "dict_items([(\"Lemma('six.s.01.6')\", 26), (\"Lemma('six.n.01.6')\", 2), (\"Lemma('sixth.s.01.6th')\", 1)])\n",
      "collecting tokens for  15\n",
      "indices:    {34304, 5135, 28182, 4120, 25115, 3099, 25123, 21541, 21544, 4136, 4139, 4140, 21549, 31788, 32303, 4144, 4151, 4166, 11335, 24138, 28236, 4174, 25679, 25707, 26732, 26736, 15488, 29323, 28300, 11917, 28301, 11420, 6836, 15547, 15548, 3262, 15550, 15552, 15553, 3776, 15555, 15554, 15559, 15560, 15561, 28875, 15567, 24272, 215, 6872, 15577, 21207, 21212, 12509, 15581, 223, 28389, 15589, 15608, 2812, 21246, 263, 3339, 21772, 13077, 20760, 25881, 16167, 20776, 2858, 16176, 817, 16178, 16196, 16197, 20807, 29518, 3920, 29520, 28502, 29528, 28505, 13149, 32608, 354, 32610, 21349, 22376, 22378, 16237, 26993, 26999, 5500, 22912, 22914, 22922, 21392, 27536, 30097, 27043, 12712, 28587, 22958, 4020, 14773, 29110, 452, 12740, 30149, 21449, 15306, 30159, 21458, 14813, 12768, 25059, 20464, 3572, 504}\n",
      "dict_items([(\"Lemma('fifteen.s.01.15')\", 26), (\"Lemma('fifteen.n.01.15')\", 4), (\"Lemma('fifteenth.s.01.15th')\", 1)])\n",
      "collecting tokens for  albert\n",
      "indices:    {25999}\n",
      "dict_items([])\n",
      "collecting tokens for  quoted\n",
      "indices:    {32448, 28929, 21824, 31592, 14313, 3338, 24973, 26736, 37105, 10098, 21779, 21810, 24760, 10778, 413, 21534}\n",
      "dict_items([(\"Lemma('quote.v.01.quote')\", 16)])\n",
      "collecting tokens for  saying\n",
      "indices:    {30593, 26755, 4868, 9603, 23172, 28164, 27274, 32012, 28430, 37007, 13456, 17298, 21779, 16915, 6806, 24471, 36249, 10778, 413, 36510, 7071, 20000, 20128, 21534, 20003, 936, 30251, 24748, 36267, 21685, 23481, 7226, 20411, 27325, 14657, 1348, 37061, 23623, 24904, 14409, 9160, 32203, 19536, 10836, 6741, 15831, 27096, 32857, 9177, 19547, 33244, 1373, 15454, 19933, 20704, 19932, 25314, 9571, 15843, 14308, 31079, 7147, 4846, 4847, 34798, 37105, 10098, 12916, 18037, 35958, 9204, 12409, 4858, 9086, 1407}\n",
      "dict_items([(\"Lemma('state.v.01.say')\", 26), (\"Lemma('allege.v.01.say')\", 8), (\"Lemma('suppose.v.01.say')\", 1)])\n",
      "collecting tokens for  woman\n",
      "indices:    {36101, 7432, 34954, 34828, 26636, 26126, 9359, 12044, 34193, 10514, 34321, 8473, 34212, 22564, 8230, 30248, 19759, 19765, 19767, 30906, 6970, 30785, 34887, 36296, 8779, 2256, 14431, 36196, 34792, 11880, 33130, 10351}\n",
      "dict_items([(\"Lemma('woman.n.01.woman')\", 11)])\n",
      "collecting tokens for  final\n",
      "indices:    {12225, 2182, 27528, 28265, 15657, 26861, 32882, 23795, 22644, 22036, 26072, 15359}\n",
      "dict_items([(\"Lemma('concluding.s.01.final')\", 1), (\"Lemma('final.s.02.final')\", 2)])\n",
      "collecting tokens for  folk\n",
      "indices:    {26752, 13824, 2318, 5268, 20894, 13855, 1318, 2362, 2370, 2375, 2377, 27985, 6104, 14553, 26075, 26077, 24034, 31587, 31588, 29158, 26349, 29295, 11122}\n",
      "dict_items([(\"Lemma('folk.n.01.folk')\", 8), (\"Lemma('tribe.n.01.folk')\", 1)])\n",
      "collecting tokens for  songs\n",
      "indices:    {26083, 1095, 6794, 26348, 14572, 9837, 26515, 11252, 14548, 14484, 1081, 26492, 11257, 20894}\n",
      "dict_items([(\"Lemma('song.n.01.song')\", 9)])\n",
      "collecting tokens for  shouted\n",
      "indices:    {36742, 36872, 35596, 34320, 35610, 35486, 9634, 8739, 31397, 19878, 18857, 34869, 23230, 6468, 12876, 7885, 6223, 26068, 37078, 19799, 22873, 8795, 33652, 35454}\n",
      "dict_items([(\"Lemma('shout.v.02.shout')\", 5), (\"Lemma('shout.v.01.shout')\", 18)])\n",
      "collecting tokens for  cowboy\n",
      "indices:    {18276, 36653, 11950, 13743, 36655, 2449, 36659, 26068, 18234}\n",
      "dict_items([(\"Lemma('cowboy.n.01.cowboy')\", 5)])\n",
      "collecting tokens for  marty\n",
      "indices:    {33811}\n",
      "dict_items([])\n",
      "collecting tokens for  faced\n",
      "indices:    {23432, 34569, 22794, 21900, 27924, 10271, 11684, 25771, 34992, 20659, 35450, 20412, 6461, 16832, 19398, 16076, 31825, 24145, 30553, 22878, 2530, 34674, 1269, 5498, 30079}\n",
      "dict_items([(\"Lemma('confront.v.02.face')\", 15), (\"Lemma('confront.v.01.face')\", 4), (\"Lemma('faced.a.01.faced')\", 2), (\"Lemma('confront.v.03.face')\", 2), (\"Lemma('front.v.01.face')\", 2)])\n",
      "collecting tokens for  east\n",
      "indices:    {20317}\n",
      "dict_items([])\n",
      "collecting tokens for  road\n",
      "indices:    {9222, 6952, 21611, 36720, 24368, 29205, 21375}\n",
      "dict_items([(\"Lemma('road.n.01.road')\", 2)])\n",
      "collecting tokens for  deer\n",
      "indices:    {981, 29926}\n",
      "dict_items([(\"Lemma('deer.n.01.deer')\", 1)])\n",
      "collecting tokens for  fallen\n",
      "indices:    {14368, 31522, 36420, 22745, 1509, 29065, 35225, 14478, 24783, 34161, 30513, 10419, 30995, 10841, 29210, 30681, 13567}\n",
      "dict_items([(\"Lemma('fall.v.03.fall')\", 3), (\"Lemma('fall.v.07.fall')\", 1), (\"Lemma('fall.v.01.fall')\", 4), (\"Lemma('fall.v.13.fall')\", 1), (\"Lemma('fall.v.12.fall')\", 1)])\n",
      "collecting tokens for  gun\n",
      "indices:    {18785, 17588}\n",
      "dict_items([(\"Lemma('person.n.01.person')\", 1), (\"Lemma('gun.n.01.gun')\", 1)])\n",
      "collecting tokens for  missiles\n",
      "indices:    {28453, 28454, 21735, 15527, 28458, 14957, 14031, 31282, 21715, 28467, 31260, 31292, 15519}\n",
      "dict_items([(\"Lemma('missile.n.01.missile')\", 3)])\n",
      "collecting tokens for  expense\n",
      "indices:    {17409, 30082, 2066, 22036, 12183, 26523, 10148, 21160, 13951, 3636, 25652, 13367, 16441, 3643, 62, 26571, 11855, 211, 28500, 5462, 12506, 5083, 30176, 2784, 20706, 20192, 24164, 24176, 21879, 1662, 30079}\n",
      "dict_items([(\"Lemma('expense.n.01.expense')\", 11), (\"Lemma('expense.n.02.expense')\", 4)])\n",
      "collecting tokens for  aircraft\n",
      "indices:    {32387, 25867, 15501, 15521, 15531, 28465, 15537, 28467, 28471, 30527, 28481, 18754, 28484, 18757, 18760, 28496, 28502, 28505, 28523, 31341, 28526}\n",
      "dict_items([(\"Lemma('aircraft.n.01.aircraft')\", 6)])\n",
      "collecting tokens for  resulted\n",
      "indices:    {2566, 32392, 23956, 5020, 4252, 3486, 24737, 5537, 24739, 4904, 2089, 16436, 21945, 22845, 14922, 32335, 5585, 28500, 4052, 28636, 349, 12637, 15345, 32760, 22011, 22012, 22527}\n",
      "dict_items([(\"Lemma('leave.v.07.result')\", 15), (\"Lemma('result.v.01.result')\", 12)])\n",
      "collecting tokens for  effort\n",
      "indices:    {27137, 4610, 11779, 20485, 11276, 4635, 22568, 15402, 12331, 10291, 1588, 23609, 26687, 30786, 11342, 22606, 22607, 22614, 22115, 13932, 11373, 28269, 23669, 4729, 25209, 6783, 35459, 22661, 16009, 142, 34961, 146, 20630, 15511, 4764, 32415, 671, 23214, 185, 32442, 32451, 14023, 12488, 23754, 1753, 21722, 32482, 5354, 12011, 24818, 1782, 37118, 771, 34064, 23838, 6952, 34094, 21296, 14651, 32582, 339, 28500, 20820, 28502, 5989, 28024, 32635, 21378, 36226, 24457, 3478, 2459, 2462, 2463, 16290, 32165, 12197, 32167, 14760, 11688, 16295, 32169, 16298, 32168, 32174, 9651, 2487, 8633, 20423, 20424, 12233, 26570, 20426, 11725, 6098, 19413, 33238, 2015, 12263, 12265, 4593, 6641, 4598, 21496, 24058, 21499}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('attempt.n.01.effort')\", 26), (\"Lemma('effort.n.02.effort')\", 9), (\"Lemma('feat.n.01.effort')\", 2)])\n",
      "collecting tokens for  develop\n",
      "indices:    {23940, 14724, 2566, 14725, 32904, 30217, 1930, 4617, 33165, 14222, 22285, 15118, 16398, 1021, 24596, 30484, 794, 15771, 28699, 25633, 32674, 16162, 20774, 14631, 11944, 1962, 34730, 34348, 1836, 11697, 11698, 31159, 27834, 3643, 24893, 5312, 27457, 13249, 12483, 1988, 34753, 1355, 28495, 28499, 28500, 28502, 28506, 32347, 14171, 14042, 32860, 11873, 27617, 24034, 13284, 24037, 32623, 32883, 14195, 28532, 4603, 24061, 9214}\n",
      "dict_items([(\"Lemma('originate.v.01.develop')\", 1), (\"Lemma('evolve.v.01.develop')\", 14), (\"Lemma('develop.v.03.develop')\", 12), (\"Lemma('develop.v.01.develop')\", 11), (\"Lemma('train.v.01.develop')\", 2), (\"Lemma('develop.v.10.develop')\", 3), (\"Lemma('develop.v.09.develop')\", 2), (\"Lemma('develop.v.12.develop')\", 2), (\"Lemma('explicate.v.02.develop')\", 1), (\"Lemma('grow.v.08.develop')\", 3), (\"Lemma('build_up.v.05.develop')\", 5), (\"Lemma('develop.v.14.develop')\", 1), (\"Lemma('modernize.v.02.develop')\", 1)])\n",
      "collecting tokens for  season\n",
      "indices:    {3592, 26646, 27169, 25636, 29224, 31785, 3625, 3634, 1075, 9269, 22069, 23093, 9272, 25151, 578, 581, 582, 585, 595, 11871, 34916, 612, 1124, 617, 618, 624, 631, 1664, 2691, 654, 661, 665, 1181, 1695, 32440, 26296, 26301, 30404, 26339, 26864, 13047, 252, 256, 264, 268, 277, 280, 289, 290, 298, 12074, 22334, 1872, 21848, 26977, 360, 22379, 26475, 26477, 26478, 26479, 22384, 29037, 22383, 22381, 1912, 377, 30073, 22404, 22405, 22406, 24965, 22408, 26505, 912, 27025, 27034, 31648, 31652, 24486, 26534, 24497, 27062, 20927, 26563, 965, 967, 26568, 20940, 24012, 20941, 464, 22998, 23003, 476, 479, 20967, 20978}\n",
      "dict_items([(\"Lemma('season.n.01.season')\", 26), (\"Lemma('season.n.02.season')\", 8)])\n",
      "collecting tokens for  birds\n",
      "indices:    {9401, 25331, 31420, 35989}\n",
      "dict_items([(\"Lemma('bird.n.01.bird')\", 1)])\n",
      "collecting tokens for  tumbled\n",
      "indices:    {18562, 6212, 18570, 34063, 624, 6930, 35635, 6462, 8671}\n",
      "dict_items([(\"Lemma('tumble.v.01.tumble')\", 7), (\"Lemma('topple.v.02.tumble')\", 1), (\"Lemma('tumble.v.03.tumble')\", 1)])\n",
      "collecting tokens for  low\n",
      "indices:    {35203, 15012, 24677, 3019, 30124, 18733, 19854, 34029, 35248, 3568, 3026, 11572, 6045, 26143}\n",
      "dict_items([(\"Lemma('low.a.05.low')\", 2), (\"Lemma('low.a.01.low')\", 5), (\"Lemma('low.a.02.low')\", 1)])\n",
      "collecting tokens for  18\n",
      "indices:    {14853, 29322, 5516, 3725, 15247, 22930, 20760, 21784, 23325, 26405, 29095, 2855, 28201, 28971, 21164, 22958, 22063, 22321, 22961, 20913, 28213, 29110, 11189, 3900, 4031, 28225, 28995, 4036, 23801, 21445, 20168, 11336, 3915, 14924, 846, 3535, 20303, 3793, 3794, 25811, 32723, 83, 1366, 3922, 26330, 3292, 24285, 20473, 5596, 24928, 29280, 26338, 3554, 21478, 22506, 26731, 22380, 23405, 3694, 624, 21492, 24820, 20472, 23161, 12799}\n",
      "dict_items([(\"Lemma('eighteen.s.01.18')\", 18), (\"Lemma('eighteenth.s.01.18th')\", 1)])\n",
      "collecting tokens for  19\n",
      "indices:    {21632, 29324, 22541, 15632, 22804, 16404, 21657, 3740, 2844, 542, 3744, 12580, 25639, 25383, 33192, 16178, 21443, 21445, 30918, 333, 25040, 3794, 5203, 3926, 13912, 22489, 4061, 5086, 25188, 31723, 26732, 624, 29040, 23161, 20987, 12028}\n",
      "dict_items([(\"Lemma('nineteen.s.01.19')\", 8), (\"Lemma('nineteen.n.01.19')\", 2)])\n",
      "collecting tokens for  race\n",
      "indices:    {20320, 28968, 30540, 27343, 27834, 24703}\n",
      "dict_items([])\n",
      "collecting tokens for  grade\n",
      "indices:    {27412, 22676, 19229, 29856, 29858, 15651, 15652, 15653, 29862, 15655, 423, 29865, 21427, 2356, 3253, 29110, 29108, 23224, 16179, 15685, 15686, 15687, 29128, 15691, 13261, 29133, 24929, 24419, 24420, 15718, 30833, 30706, 24568, 13311}\n",
      "dict_items([(\"Lemma('grade_school.n.01.grade_school')\", 1), (\"Lemma('class.n.02.grade')\", 11), (\"Lemma('grade.n.02.grade')\", 3), (\"Lemma('grade.n.03.grade')\", 1)])\n",
      "collecting tokens for  1\n",
      "indices:    {32770, 32772, 12294, 20, 32790, 4125, 32804, 38, 32810, 32814, 12342, 4151, 4153, 4158, 4159, 4163, 28741, 4166, 28752, 4177, 28754, 2134, 28759, 28760, 28764, 28766, 28771, 24679, 28777, 28788, 28800, 2177, 28802, 28806, 28808, 24712, 138, 28828, 4253, 28830, 28836, 28844, 4281, 4285, 4289, 4295, 32971, 223, 20710, 20715, 20722, 2297, 20732, 20734, 28938, 267, 2318, 28951, 4392, 33080, 4412, 28992, 4420, 22855, 4439, 33114, 4451, 20837, 4455, 4460, 29040, 374, 4474, 4475, 4478, 4479, 27011, 391, 29066, 33163, 27021, 27036, 27037, 27038, 12710, 29099, 14769, 14770, 4533, 29110, 33214, 29122, 33219, 29125, 33224, 4554, 22995, 14809, 14811, 20966, 14822, 23032, 12793, 21008, 14884, 23079, 23080, 14895, 589, 29265, 597, 27229, 25186, 21093, 617, 618, 619, 621, 623, 25225, 653, 21142, 15005, 15009, 15023, 15027, 21171, 15035, 27340, 15060, 15066, 21212, 2783, 2808, 2817, 23303, 2830, 2833, 27412, 2850, 25378, 4908, 4915, 2868, 29492, 15159, 23353, 29498, 2874, 4925, 2880, 4930, 27459, 4932, 29517, 2896, 29526, 29531, 2910, 29534, 29536, 4960, 21349, 21351, 21367, 31609, 15226, 23423, 29568, 2944, 29574, 29579, 29581, 2957, 29587, 2969, 2973, 29598, 29607, 27567, 11184, 15289, 25531, 29645, 15315, 15318, 15319, 15320, 21465, 15323, 15326, 15328, 29690, 5120, 3088, 13331, 3091, 3098, 1054, 21548, 29749, 3141, 3153, 11356, 15481, 11398, 3206, 21658, 29862, 29869, 3263, 21695, 15563, 15571, 27871, 15584, 27872, 15595, 15600, 29940, 25851, 25852, 3331, 21773, 21777, 3347, 15641, 11549, 3366, 11565, 11568, 3377, 25911, 11588, 11589, 11595, 11596, 15696, 15697, 1362, 11603, 3410, 3413, 11602, 11608, 1381, 3432, 3438, 5501, 5513, 5536, 5543, 21931, 21932, 21936, 3513, 3514, 3515, 3517, 3523, 3524, 3525, 3529, 3531, 3534, 30164, 30167, 3545, 24025, 21984, 3556, 21994, 3562, 3564, 3567, 3569, 3570, 3571, 3572, 3573, 3576, 3577, 3580, 22013, 28157, 15872, 22016, 22018, 3586, 1546, 30221, 30226, 28182, 1565, 28192, 28199, 28201, 22058, 28206, 22063, 28208, 28210, 28211, 28213, 28216, 28218, 32315, 28221, 32319, 28223, 28227, 32337, 28246, 28250, 26204, 28252, 24162, 32359, 28264, 3694, 32377, 30330, 30331, 32378, 3725, 3735, 11931, 3744, 3751, 13992, 14000, 1717, 14006, 3768, 14008, 24248, 3772, 3774, 3776, 3777, 3779, 3783, 3784, 20180, 20181, 20183, 3803, 14057, 3819, 14077, 32512, 32513, 32515, 3844, 3845, 3846, 3848, 32521, 3849, 3851, 3853, 3856, 3861, 16167, 16175, 3887, 16177, 3891, 32566, 3899, 16189, 16192, 30529, 3906, 30532, 32586, 30539, 3914, 3917, 32594, 32595, 12116, 32600, 32604, 12128, 32609, 32614, 32620, 12141, 28528, 32629, 16247, 24451, 22414, 32697, 32702, 4034, 4035, 16329, 32714, 16333, 4048, 32748, 4083, 32756}\n",
      "dict_items([(\"Lemma('one.s.01.1')\", 26), (\"Lemma('one.n.01.1')\", 20), (\"Lemma('first.s.02.1st')\", 2)])\n",
      "collecting tokens for  2\n",
      "indices:    {16384, 4096, 32772, 4101, 4110, 4116, 22553, 28, 4126, 4135, 4147, 12342, 4158, 28754, 28760, 28766, 28771, 28779, 28788, 28790, 28791, 2178, 28802, 28804, 28806, 28809, 24719, 32919, 28824, 4253, 20638, 26790, 28844, 198, 20680, 32972, 224, 20710, 20715, 2299, 258, 12547, 2319, 28952, 28954, 28956, 28958, 28960, 28965, 4392, 28972, 28974, 28975, 28983, 33080, 4411, 28988, 28990, 28991, 4416, 28995, 4420, 22855, 28999, 29002, 29003, 29006, 29007, 29008, 29009, 29012, 29015, 29018, 33119, 29027, 29028, 20837, 29029, 29032, 29033, 29034, 29035, 29036, 4460, 29038, 29039, 29040, 29041, 4464, 22912, 14728, 393, 29066, 27021, 33166, 14749, 422, 29099, 22959, 14769, 14770, 29110, 14777, 22971, 29122, 33219, 29125, 453, 4555, 459, 22995, 20955, 14817, 20976, 23032, 20986, 12794, 21025, 25123, 21028, 14884, 23080, 14894, 25137, 12854, 12855, 14905, 25158, 590, 23121, 27231, 23137, 23138, 25187, 21094, 27247, 626, 21123, 25225, 21134, 23193, 15005, 15009, 15021, 2741, 4809, 4814, 15062, 15064, 21212, 21217, 2808, 23289, 781, 2840, 795, 2854, 808, 31528, 15148, 4910, 15155, 29492, 4916, 2871, 29498, 31549, 4927, 2882, 4932, 2886, 29517, 2899, 2901, 29529, 2905, 29531, 29534, 2910, 29536, 4960, 21351, 2924, 21367, 15226, 2943, 2945, 2949, 29579, 2958, 29598, 27568, 945, 15289, 15308, 29645, 29660, 21471, 15328, 29690, 3088, 3089, 13331, 1054, 29749, 11320, 11322, 21566, 25665, 3153, 27732, 27752, 11394, 3207, 1164, 3218, 15513, 21666, 5288, 5291, 29869, 25781, 25786, 15555, 5327, 21712, 15571, 15578, 27871, 15597, 27887, 21747, 25851, 3331, 34051, 32005, 11529, 15626, 3338, 23823, 3345, 11551, 11561, 11562, 11565, 11568, 3381, 11580, 11586, 11596, 11598, 15696, 1362, 11603, 11608, 15710, 3429, 3450, 5518, 26015, 5540, 21931, 21935, 21936, 3520, 3522, 5573, 3525, 21959, 5582, 3535, 3536, 3544, 3545, 3551, 3567, 3569, 3570, 30195, 3572, 3571, 34294, 30194, 3576, 3577, 3581, 15872, 28165, 1546, 1547, 30221, 1565, 28192, 28195, 28197, 22056, 22057, 22065, 28210, 28216, 28225, 30275, 26186, 28238, 28241, 30296, 28250, 28255, 32351, 32359, 22130, 32377, 30330, 32378, 3725, 3735, 11931, 3744, 11937, 3751, 1717, 32443, 3774, 14016, 14018, 3781, 14021, 3783, 26328, 32486, 3819, 3844, 3845, 3847, 3848, 3849, 3852, 3855, 3856, 14104, 3867, 16167, 3880, 3887, 16175, 16177, 3890, 3891, 3888, 16183, 3900, 22334, 3905, 30539, 3918, 3919, 3923, 3927, 22364, 12141, 16247, 24451, 3976, 22408, 26517, 28587, 16322, 4037, 16330, 4085, 14335}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('two.n.01.2')\", 11), (\"Lemma('two.s.01.2')\", 26)])\n",
      "collecting tokens for  inch\n",
      "indices:    {32513, 28930, 1666, 22148, 28931, 2954, 267, 18448, 29713, 29073, 28949, 1658, 13080, 30076, 29722, 29729, 21026, 29862, 29869, 3119, 33712, 26545, 29876, 29877, 29110, 29749, 11320, 29754, 29758, 29759, 19007, 193, 29122, 29125, 7115, 29778, 2903, 215, 3672, 29532, 15073, 2914, 15075, 16611, 11367, 28911, 28912, 22130, 15091, 23032, 29690, 29692, 30077, 15103}\n",
      "dict_items([(\"Lemma('inch.n.01.inch')\", 19), (\"Lemma('column_inch.n.01.inch')\", 2)])\n",
      "collecting tokens for  barrel\n",
      "indices:    {29101, 22875, 29051, 29084, 19165, 7134, 29119}\n",
      "dict_items([(\"Lemma('barrel.n.02.barrel')\", 2)])\n",
      "collecting tokens for  inspired\n",
      "indices:    {9602, 11267, 28041, 5903, 31894, 27545, 25244, 11056, 29110, 11331, 27336, 32073, 27342, 4697, 20826, 25698, 28023, 26104, 11262}\n",
      "dict_items([(\"Lemma('inspire.v.01.inspire')\", 6), (\"Lemma('inspire.v.02.inspire')\", 5), (\"Lemma('divine.s.06.inspired')\", 1), (\"Lemma('cheer.v.05.inspire')\", 1), (\"Lemma('prompt.v.02.inspire')\", 4)])\n",
      "collecting tokens for  popularity\n",
      "indices:    {28897, 30023, 27559, 5706, 2446, 2384, 20243, 2293, 29110, 8470, 25661, 2302}\n",
      "dict_items([(\"Lemma('popularity.n.01.popularity')\", 5)])\n",
      "collecting tokens for  model\n",
      "indices:    {7591, 16328, 7595, 7596, 34636, 16334, 29072, 29107, 1752}\n",
      "dict_items([(\"Lemma('exemplar.n.01.model')\", 1), (\"Lemma('model.n.03.model')\", 3), (\"Lemma('model.n.01.model')\", 2)])\n",
      "collecting tokens for  pump\n",
      "indices:    {7685, 29129, 29134, 8317, 8318}\n",
      "dict_items([(\"Lemma('pump.n.01.pump')\", 3)])\n",
      "collecting tokens for  fact\n",
      "indices:    {31232, 25088, 3589, 1030, 15368, 5131, 30220, 2572, 31246, 14865, 19, 16405, 30743, 30231, 27672, 16407, 11289, 13341, 13344, 14369, 27680, 2593, 13346, 2594, 31783, 8231, 12329, 16425, 7721, 14380, 11821, 3630, 14383, 30766, 10286, 30770, 4658, 30257, 11316, 13366, 5175, 14384, 30265, 4692, 16436, 23609, 30781, 22590, 19007, 27712, 32321, 27200, 31810, 24643, 1091, 13897, 16457, 24139, 2636, 25165, 2635, 1103, 16464, 30801, 30800, 32336, 2126, 14415, 2134, 30805, 5208, 34393, 5209, 2648, 2136, 2651, 34398, 4191, 5207, 14946, 2146, 26724, 4709, 11878, 9317, 30820, 25191, 30826, 27753, 4716, 27247, 27248, 31346, 23154, 31861, 36983, 34425, 2171, 25724, 27772, 15998, 26750, 25726, 22657, 30846, 22659, 35967, 23686, 23175, 23687, 2697, 4234, 20105, 27276, 25741, 1674, 29835, 25748, 4247, 27287, 22682, 26778, 33436, 4254, 22688, 25762, 22692, 32934, 12968, 9386, 12970, 13997, 27823, 16051, 32948, 22709, 27829, 32445, 27839, 22719, 3265, 1731, 23747, 25800, 3279, 8912, 11984, 22739, 32984, 26329, 10977, 1762, 32994, 22757, 11495, 12010, 31980, 1776, 16114, 4852, 25846, 5879, 37112, 25334, 3835, 4348, 31998, 23810, 31492, 261, 16134, 4359, 32008, 19720, 12366, 32013, 12045, 16655, 13385, 16658, 20242, 32018, 32020, 3862, 4375, 6935, 21273, 21274, 17691, 29468, 16155, 16157, 16161, 26402, 27427, 21795, 17189, 1313, 17707, 4907, 25401, 24889, 1337, 14649, 25915, 15688, 2376, 17738, 30540, 27981, 20302, 33102, 25427, 1364, 341, 36179, 12632, 5465, 31577, 25944, 32093, 23901, 864, 23394, 25443, 15716, 1892, 1383, 27496, 26985, 27499, 14189, 25966, 31086, 31085, 4977, 2929, 32114, 15220, 33135, 32628, 12664, 15225, 25981, 33157, 18309, 27527, 24968, 33162, 10123, 17805, 27539, 27542, 29079, 11672, 15770, 33183, 33186, 420, 12198, 25513, 13740, 18349, 23985, 15284, 1461, 4533, 22973, 28095, 2495, 12227, 35269, 27077, 25035, 13264, 6097, 6098, 2514, 22996, 12245, 25045, 28626, 27100, 24028, 13280, 993, 28130, 12259, 16358, 2535, 12266, 23022, 8688, 15346, 28146, 12788, 4599, 28152, 24575}\n",
      "dict_items([(\"Lemma('fact.n.02.fact')\", 25), (\"Lemma('fact.n.01.fact')\", 26), (\"Lemma('fact.n.03.fact')\", 9), (\"Lemma('fact.n.04.fact')\", 2)])\n",
      "collecting tokens for  neat\n",
      "indices:    {5440, 26947, 10952, 36328, 9582, 28622, 27539, 8563, 11221, 30676, 35927, 15669, 9497, 18684, 9205, 31260, 30005}\n",
      "dict_items([(\"Lemma('neat.s.01.neat')\", 7), (\"Lemma('clean.s.17.neat')\", 1), (\"Lemma('neat.s.02.neat')\", 1)])\n",
      "collecting tokens for  balance\n",
      "indices:    {32002, 4231, 12040, 6281, 4234, 4236, 4238, 32015, 4624, 23825, 4241, 27539, 4244, 35347, 11798, 16402, 32016, 2713, 30618, 4247, 4252, 4253, 4254, 35867, 23456, 4255, 4256, 2858, 14895, 11697, 10418, 1586, 13366, 4278, 24888, 28090, 34108, 1597, 24894, 36029, 25152, 23618, 20239, 28100, 27541, 2887, 23883, 22605, 2766, 22606, 26063, 1743, 25043, 31960, 23386, 4242, 32479, 31969, 4243, 21610, 24172, 24813, 2925, 4208, 14066, 34290, 4215, 31999}\n",
      "dict_items([(\"Lemma('balance.n.01.balance')\", 26), (\"Lemma('balance.n.02.balance')\", 3), (\"Lemma('balance.v.01.balance')\", 4), (\"Lemma('balance.v.02.balance')\", 3), (\"Lemma('balance_of_power.n.01.balance_of_power')\", 1)])\n",
      "collecting tokens for  subtle\n",
      "indices:    {31904, 26405, 26534, 31909, 5861, 31850, 34059, 14638, 36208, 27539, 26419, 11221, 26901, 1692, 11229, 6142}\n",
      "dict_items([(\"Lemma('elusive.s.03.subtle')\", 3)])\n",
      "collecting tokens for  equilibrium\n",
      "indices:    {2949, 3276, 27564, 25618, 27539, 3220, 2998, 3001, 2941}\n",
      "dict_items([(\"Lemma('equilibrium.n.01.equilibrium')\", 3), (\"Lemma('chemical_equilibrium.n.01.equilibrium')\", 2)])\n",
      "collecting tokens for  special\n",
      "indices:    {26753, 15756, 32525, 20620, 3087, 32529, 13846, 22039, 9881, 14620, 22685, 36254, 26785, 31266, 20645, 25006, 25024, 26304, 3144, 9697, 29288, 32489, 9835, 107, 8178, 12917, 26749, 23678, 33023}\n",
      "dict_items([(\"Lemma('especial.s.01.special')\", 2), (\"Lemma('special.s.02.special')\", 3), (\"Lemma('special.s.04.special')\", 1), (\"Lemma('particular.s.01.special')\", 5)])\n",
      "collecting tokens for  chinese\n",
      "indices:    {27559}\n",
      "dict_items([])\n",
      "collecting tokens for  controversy\n",
      "indices:    {12256, 12259, 4742, 20329, 32234, 74, 31690, 20525, 2031, 21521, 82, 24154, 1339, 27324, 7069}\n",
      "dict_items([(\"Lemma('controversy.n.01.controversy')\", 8)])\n",
      "collecting tokens for  bitterly\n",
      "indices:    {32234, 26026, 36624, 2518, 36120, 8347, 37052, 35199}\n",
      "dict_items([(\"Lemma('bitterly.r.02.bitterly')\", 1), (\"Lemma('bitterly.r.01.bitterly')\", 1)])\n",
      "collecting tokens for  fought\n",
      "indices:    {32007, 32011, 24205, 32020, 18837, 32023, 27305, 26026, 814, 815, 34223, 30385, 30382, 34108, 13376, 26050, 22851, 6602, 26197, 31997, 18525, 25311, 31713, 31587, 34152, 37097, 28393, 22896, 23796, 25085}\n",
      "dict_items([(\"Lemma('fight.v.02.fight')\", 9), (\"Lemma('contend.v.06.fight')\", 16), (\"Lemma('fight.v.03.fight')\", 1), (\"Lemma('crusade.v.01.fight')\", 1)])\n",
      "collecting tokens for  presidential\n",
      "indices:    {31717}\n",
      "dict_items([])\n",
      "collecting tokens for  campaigns\n",
      "indices:    {11649, 30277, 32234, 14347, 26026, 14352, 31194, 23798, 26681, 23930}\n",
      "dict_items([(\"Lemma('political_campaign.n.01.campaign')\", 1), (\"Lemma('campaign.n.02.campaign')\", 1)])\n",
      "collecting tokens for  character\n",
      "indices:    {22400, 35713, 1018, 26247, 1032, 1931, 11149, 31885, 6285, 30734, 1682, 31766, 32920, 30747, 30748, 22685, 30751, 26656, 30752, 25888, 10788, 6266, 13863, 1832, 26664, 14586, 26294, 26295, 2617, 7610, 33339, 14400, 13634, 13635, 27076, 1091, 1096, 26572, 31823, 14160, 14418, 14419, 27860, 13654, 1878, 13655, 4826, 13659, 5340, 26337, 36962, 14435, 32229, 23657, 32234, 6891, 10732, 15467, 1006, 12016, 26738, 1017, 12282, 31996}\n",
      "dict_items([(\"Lemma('fictional_character.n.01.character')\", 5), (\"Lemma('quality.n.03.character')\", 12), (\"Lemma('character.n.04.character')\", 5), (\"Lemma('character.n.06.character')\", 1), (\"Lemma('character.n.03.character')\", 11), (\"Lemma('character.n.07.character')\", 1)])\n",
      "collecting tokens for  dignity\n",
      "indices:    {5317, 31430, 19397, 26104, 36969, 2315, 9498, 32205, 22157, 1007, 27279, 14673, 12239, 32216, 22138, 19742, 33855}\n",
      "dict_items([(\"Lemma('dignity.n.01.dignity')\", 6), (\"Lemma('dignity.n.02.dignity')\", 2)])\n",
      "collecting tokens for  honesty\n",
      "indices:    {28385, 2313, 32234, 13962, 26092, 24299, 32216, 32157}\n",
      "dict_items([(\"Lemma('honesty.n.01.honesty')\", 2)])\n",
      "collecting tokens for  editor\n",
      "indices:    {31712, 771, 5284, 645, 34217, 34220, 22445, 5294, 34223, 5296, 5297, 2489, 26970}\n",
      "dict_items([(\"Lemma('editor.n.01.editor')\", 5)])\n",
      "collecting tokens for  criticism\n",
      "indices:    {27330, 26090, 25036, 11633, 13464}\n",
      "dict_items([(\"Lemma('criticism.n.01.criticism')\", 1), (\"Lemma('criticism.n.03.criticism')\", 1)])\n",
      "collecting tokens for  trial\n",
      "indices:    {15296, 21346, 12198, 36975, 11189, 4474}\n",
      "dict_items([(\"Lemma('test.n.05.trial')\", 1)])\n",
      "collecting tokens for  conducted\n",
      "indices:    {23553, 1, 33027, 22403, 28550, 15753, 32521, 16266, 11274, 23947, 2953, 23951, 23955, 33043, 14739, 31638, 33046, 31640, 926, 12448, 5285, 26795, 5292, 22700, 11191, 21560, 32697, 32695, 32696, 6076, 13245, 22335, 11199, 21699, 32712, 32713, 5578, 5579, 25681, 24913, 12648, 12649, 31594, 3436, 22382, 3440, 11889, 11890, 26488, 16253}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('conduct.v.02.conduct')\", 19), (\"Lemma('conduct.v.01.conduct')\", 26), (\"Lemma('behave.v.02.conduct')\", 1), (\"Lemma('lead.v.01.conduct')\", 1), (\"Lemma('impart.v.03.conduct')\", 1)])\n",
      "collecting tokens for  breeze\n",
      "indices:    {9304, 11044}\n",
      "dict_items([(\"Lemma('breeze.n.01.breeze')\", 1)])\n",
      "collecting tokens for  exactly\n",
      "indices:    {9314, 28003, 8552, 8745, 34636, 2190, 30005, 2455, 4312, 1207, 16925}\n",
      "dict_items([(\"Lemma('precisely.r.01.exactly')\", 7), (\"Lemma('precisely.r.03.exactly')\", 1)])\n",
      "collecting tokens for  pocket\n",
      "indices:    {35845, 18949, 34183, 18568, 35978, 18570, 34068, 9377, 36779, 14511, 7473, 23349, 18362, 9152, 10563, 36043, 12624, 10963, 17752, 17754, 6494, 34143, 34020, 34025, 12654, 8177, 35958, 34039, 18173}\n",
      "dict_items([(\"Lemma('pocket.n.01.pocket')\", 15), (\"Lemma('pouch.n.02.pocket')\", 1)])\n",
      "collecting tokens for  icy\n",
      "indices:    {1155, 10247, 36043, 36139, 11150, 21327, 36050, 33682, 36122, 30589}\n",
      "dict_items([(\"Lemma('icy.s.03.icy')\", 1), (\"Lemma('frigid.s.03.icy')\", 2)])\n",
      "collecting tokens for  deep\n",
      "indices:    {2489, 23494}\n",
      "dict_items([])\n",
      "collecting tokens for  grove\n",
      "indices:    {6405}\n",
      "dict_items([])\n",
      "collecting tokens for  pamela\n",
      "indices:    {35967}\n",
      "dict_items([])\n",
      "collecting tokens for  embrace\n",
      "indices:    {32097, 5957, 35144, 36043, 24795, 19568, 6450, 13945, 25722, 2139}\n",
      "dict_items([(\"Lemma('embrace.v.02.embrace')\", 3), (\"Lemma('embrace.v.01.embrace')\", 2), (\"Lemma('espouse.v.03.embrace')\", 1), (\"Lemma('embrace.n.01.embrace')\", 1)])\n",
      "collecting tokens for  wisman\n",
      "indices:    {31356}\n",
      "dict_items([])\n",
      "collecting tokens for  code\n",
      "indices:    {16436}\n",
      "dict_items([])\n",
      "collecting tokens for  fragments\n",
      "indices:    {31363, 18887, 11050, 3275, 18643, 31352, 31353, 31359}\n",
      "dict_items([(\"Lemma('fragment.n.01.fragment')\", 3), (\"Lemma('shard.n.01.fragment')\", 1)])\n",
      "collecting tokens for  possession\n",
      "indices:    {36066, 31363, 6567, 25928, 13834, 14763, 5036, 4913, 5938, 36052, 19327, 28442, 6047}\n",
      "dict_items([(\"Lemma('possession.n.01.possession')\", 6), (\"Lemma('possession.n.02.possession')\", 2)])\n",
      "collecting tokens for  button\n",
      "indices:    {31363, 31272, 31306, 18762, 31342, 29199, 18804, 2581, 18710, 18779}\n",
      "dict_items([(\"Lemma('push_button.n.01.button')\", 5)])\n",
      "collecting tokens for  us\n",
      "indices:    {3598, 3089, 31763, 9747, 15898, 3610, 35357, 30751, 12319, 1569, 10790, 2598, 28200, 25129, 35370, 34349, 14384, 9780, 9785, 17469, 3646, 2112, 25155, 25156, 7237, 25157, 27725, 27217, 21074, 2130, 19540, 2133, 28249, 13404, 31851, 25195, 25200, 36976, 4215, 31358, 12931, 24714, 16527, 10896, 12943, 27284, 37012, 13463, 12952, 27291, 13471, 1185, 35493, 13479, 13490, 10947, 716, 10961, 24275, 725, 24281, 1242, 36571, 1245, 25826, 4835, 6883, 22244, 24290, 7910, 25081, 23792, 4852, 6902, 6903, 27901, 14085, 4872, 1291, 13068, 25357, 14606, 35087, 23314, 6931, 24339, 14615, 19736, 27929, 27417, 6943, 25890, 28451, 27938, 29991, 27434, 25903, 1328, 28465, 28466, 4915, 821, 13625, 1338, 13124, 26950, 27975, 25421, 27471, 7504, 14671, 14685, 35173, 9062, 25448, 27499, 36716, 27508, 27509, 14712, 27516, 10622, 36734, 23936, 24965, 20358, 13702, 21900, 36750, 16785, 3486, 32685, 13742, 32687, 945, 32689, 26550, 8135, 21960, 17357, 8151, 27105, 9697, 998, 32241, 9717, 8183, 35832, 27129, 2044}\n",
      "dict_items([(\"Lemma('united_states.n.01.US')\", 1)])\n",
      "collecting tokens for  electric\n",
      "indices:    {9632, 21505, 17924, 710, 2279, 10921, 11497, 11499, 15149, 717, 33426, 5908, 15193, 33465, 15195, 5438}\n",
      "dict_items([(\"Lemma('electric.a.01.electric')\", 4)])\n",
      "collecting tokens for  manufacturers\n",
      "indices:    {11648, 29890, 15117, 11574}\n",
      "dict_items([(\"Lemma('manufacturer.n.01.manufacturer')\", 2)])\n",
      "collecting tokens for  recently\n",
      "indices:    {26371, 33061, 32461, 28370, 756, 21369}\n",
      "dict_items([])\n",
      "collecting tokens for  convicted\n",
      "indices:    {21312, 12641, 21539, 22759, 2280, 25866, 28269, 22767, 26192, 25714, 15288}\n",
      "dict_items([(\"Lemma('convict.v.01.convict')\", 8)])\n",
      "collecting tokens for  conspiracy\n",
      "indices:    {22784, 15234, 20504, 7077, 19368, 21676, 15284, 21302, 21303, 21309, 12226, 2527, 22755, 22759, 22767, 22768, 20850, 20851, 20852, 20853, 15227}\n",
      "dict_items([(\"Lemma('conspiracy.n.02.conspiracy')\", 3), (\"Lemma('conspiracy.n.03.conspiracy')\", 2), (\"Lemma('conspiracy.n.01.conspiracy')\", 2)])\n",
      "collecting tokens for  prices\n",
      "indices:    {16384, 22019, 20359, 32270, 12179, 22804, 21, 23451, 5415, 21933, 20784, 25008, 12088, 24635, 16322, 21826, 16325, 11848, 29131, 29133, 16341, 16342, 23384, 23386, 20955, 23391, 21990, 22759, 12135, 32358, 28650, 22763, 23142, 16365, 16366, 22000, 22769, 16370, 22770, 16382}\n",
      "dict_items([(\"Lemma('monetary_value.n.01.price')\", 14), (\"Lemma('price.n.02.price')\", 1)])\n",
      "collecting tokens for  s\n",
      "indices:    {4490, 29965, 26419, 15284, 23219, 29078}\n",
      "dict_items([])\n",
      "collecting tokens for  base\n",
      "indices:    {31976, 22154, 15055, 11119, 23089, 16275, 29589, 36535, 29754, 20253, 11135}\n",
      "dict_items([(\"Lemma('basal.s.02.base')\", 1), (\"Lemma('base.n.08.base')\", 2), (\"Lemma('basis.n.02.base')\", 1)])\n",
      "collecting tokens for  task\n",
      "indices:    {14977, 14981, 23814, 14983, 32136, 22409, 24839, 15242, 27141, 26254, 14350, 26257, 15507, 13461, 1302, 21533, 4767, 10271, 10785, 8480, 33188, 13349, 12331, 23980, 16435, 22837, 16438, 9144, 16443, 11707, 3907, 25283, 15175, 22606, 12880, 31701, 31703, 20572, 32223, 28640, 15719, 23531, 4972, 5357, 18671, 7024, 24821, 24822, 25465}\n",
      "dict_items([(\"Lemma('undertaking.n.01.task')\", 12), (\"Lemma('job.n.02.task')\", 11)])\n",
      "collecting tokens for  force\n",
      "indices:    {24821, 23981}\n",
      "dict_items([])\n",
      "collecting tokens for  navy\n",
      "indices:    {23981}\n",
      "dict_items([])\n",
      "collecting tokens for  marine\n",
      "indices:    {6012}\n",
      "dict_items([])\n",
      "collecting tokens for  units\n",
      "indices:    {15489, 29828, 22149, 30091, 32524, 32400, 32528, 2201, 24604, 32543, 11296, 29858, 4011, 26028, 30125, 4012, 16045, 16044, 33073, 22837, 32567, 30136, 30142, 16198, 14719, 11593, 4045, 16077, 4047, 16079, 20443, 15969, 16101, 30312, 33514, 30316, 4716, 22007, 21240, 21241, 21114, 20606, 4991}\n",
      "dict_items([(\"Lemma('unit_of_measurement.n.01.unit')\", 6), (\"Lemma('unit.n.02.unit')\", 6), (\"Lemma('unit.n.04.unit')\", 2), (\"Lemma('unit.n.03.unit')\", 1)])\n",
      "collecting tokens for  move\n",
      "indices:    {4615, 18449, 31762, 21534, 21535, 21536, 11296, 36387, 11311, 28721, 17970, 28723, 8243, 2617, 28735, 31815, 28747, 18509, 11863, 25689, 8291, 1636, 14955, 19565, 7794, 31379, 20631, 34972, 6305, 31912, 10924, 26799, 35504, 36020, 12470, 7364, 20685, 12503, 218, 30940, 24797, 36060, 8928, 21220, 31465, 3307, 7407, 25855, 20743, 25355, 9488, 17170, 26391, 8476, 34079, 23848, 31530, 18220, 12076, 34097, 30514, 11059, 5427, 22837, 17208, 23371, 14168, 23899, 32093, 4961, 4962, 25443, 13671, 20329, 24426, 24428, 32108, 20846, 18808, 19839, 901, 32137, 8592, 21908, 9113, 24476, 23968, 21922, 11173, 27052, 24493, 5043, 27067, 16315, 20928, 35777, 34767, 17879, 2008, 24038, 30695, 10217, 32748, 497}\n",
      "dict_items([(\"Lemma('travel.v.01.move')\", 18), (\"Lemma('move.v.02.move')\", 17), (\"Lemma('move.v.03.move')\", 13), (\"Lemma('move.v.13.move')\", 1), (\"Lemma('act.v.01.move')\", 1), (\"Lemma('go.v.02.move')\", 5), (\"Lemma('move.n.01.move')\", 7), (\"Lemma('be_active.v.01.move')\", 1), (\"Lemma('move.n.02.move')\", 3), (\"Lemma('motivate.v.01.move')\", 2), (\"Lemma('move.v.12.move')\", 1), (\"Lemma('move.v.04.move')\", 4), (\"Lemma('motion.n.03.move')\", 1), (\"Lemma('move.v.07.move')\", 1)])\n",
      "collecting tokens for  framed\n",
      "indices:    {10530, 35204, 9567, 24583, 18961, 17524, 22709, 29814, 12663, 7738, 10623}\n",
      "dict_items([(\"Lemma('frame.v.05.frame')\", 1), (\"Lemma('ensnare.v.01.frame')\", 1), (\"Lemma('frame.v.01.frame')\", 2), (\"Lemma('frame.v.02.frame')\", 1), (\"Lemma('frame.v.04.frame')\", 1), (\"Lemma('framed.a.01.framed')\", 1)])\n",
      "collecting tokens for  ada\n",
      "indices:    {9503}\n",
      "dict_items([])\n",
      "collecting tokens for  press\n",
      "indices:    {29656, 29602, 8293}\n",
      "dict_items([(\"Lemma('press.v.01.press')\", 2), (\"Lemma('press.n.03.press')\", 1)])\n",
      "collecting tokens for  pieces\n",
      "indices:    {31360, 31361, 31362, 22281, 22282, 3723, 18829, 28814, 28815, 2061, 12564, 29595, 24351, 10143, 5412, 33191, 28842, 22778, 29740, 29741, 29739, 29743, 15920, 29745, 29742, 26925, 29620, 29621, 29622, 31354, 12344, 29752, 29625, 29627, 29628, 12473, 29760, 26177, 8257, 13120, 28754, 32467, 33364, 29653, 28757, 28760, 29657, 20059, 18781, 22493, 28766, 26336, 26337, 29665, 28771, 865, 28773, 26342, 29802, 28779, 28780, 36205, 29550, 29679, 28778, 29681, 29554, 5363, 13812, 28790, 28793, 28794, 29563, 22909, 28798, 22143}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('piece.n.02.piece')\", 3), (\"Lemma('piece.n.01.piece')\", 4), (\"Lemma('part.n.03.piece')\", 2), (\"Lemma('piece.n.05.piece')\", 1), (\"Lemma('firearm.n.01.piece')\", 1)])\n",
      "collecting tokens for  clay\n",
      "indices:    {29602, 29562, 35180, 29594}\n",
      "dict_items([])\n",
      "collecting tokens for  cavity\n",
      "indices:    {3618, 34842, 29602, 29638, 29607, 29549, 29551, 29552, 29622, 34742, 29656, 34746}\n",
      "dict_items([(\"Lemma('pit.n.01.cavity')\", 1)])\n",
      "collecting tokens for  mold\n",
      "indices:    {29604, 13894, 29546, 29580, 29656, 29561}\n",
      "dict_items([(\"Lemma('cast.n.03.mold')\", 1)])\n",
      "collecting tokens for  stranger\n",
      "indices:    {6336, 8871, 16011, 7694, 5328, 31572, 8344, 8697, 6331, 28157, 37086}\n",
      "dict_items([(\"Lemma('stranger.n.01.stranger')\", 7), (\"Lemma('strange.a.01.strange')\", 1)])\n",
      "collecting tokens for  huge\n",
      "indices:    {12738, 5603, 12707, 34469, 12648, 23210, 10187, 35919, 3729, 31474, 22547, 6645}\n",
      "dict_items([(\"Lemma('huge.s.01.huge')\", 7)])\n",
      "collecting tokens for  industries\n",
      "indices:    {25057, 12228, 25061, 20680, 24055, 16316}\n",
      "dict_items([(\"Lemma('industry.n.01.industry')\", 2)])\n",
      "collecting tokens for  involved\n",
      "indices:    {30208, 18437, 25611, 4112, 30231, 2074, 4123, 22047, 31271, 2605, 30256, 30259, 8249, 2108, 13372, 35915, 32845, 15438, 15437, 2645, 26197, 3160, 36441, 26205, 23649, 2658, 19072, 6787, 32909, 14480, 11410, 17048, 37025, 15522, 16552, 28851, 22708, 28853, 28855, 28856, 20153, 18619, 20155, 20160, 22210, 20168, 20171, 25812, 1253, 28902, 4840, 27887, 23284, 21237, 4854, 3320, 28949, 21273, 21278, 31017, 14639, 31045, 20303, 32593, 34641, 20824, 27483, 13662, 13664, 13668, 32614, 32102, 26471, 15235, 19347, 15254, 11673, 20387, 10148, 13733, 17326, 3503, 27570, 32182, 23485, 22978, 27591, 17356, 13773, 12243, 31706, 3039, 2032, 20467, 6143}\n",
      "dict_items([(\"Lemma('involve.v.01.involve')\", 25), (\"Lemma('involved.a.01.involved')\", 23), (\"Lemma('involve.v.02.involve')\", 14), (\"Lemma('involve.v.05.involve')\", 2), (\"Lemma('necessitate.v.01.involve')\", 4), (\"Lemma('involved.s.02.involved')\", 1), (\"Lemma('imply.v.05.involve')\", 3), (\"Lemma('involved.s.03.involved')\", 1)])\n",
      "collecting tokens for  biological\n",
      "indices:    {3393, 3402}\n",
      "dict_items([(\"Lemma('biological.a.01.biological')\", 1)])\n",
      "collecting tokens for  products\n",
      "indices:    {11648, 3393, 3425, 3333, 2728, 11689, 21998, 15118, 11698, 4980, 11669, 23484, 23487}\n",
      "dict_items([(\"Lemma('merchandise.n.01.product')\", 6), (\"Lemma('product.n.02.product')\", 4)])\n",
      "collecting tokens for  attack\n",
      "indices:    {25601, 14978, 18443, 3467, 32014, 25614, 147, 34069, 25752, 18714, 3483, 35484, 34079, 3489, 3491, 3492, 28452, 24104, 11306, 3499, 21676, 20267, 3503, 27184, 25264, 20400, 21169, 22964, 27189, 20788, 25143, 20785, 22202, 27835, 12860, 27453, 31678, 28476, 9659, 28475, 31682, 452, 22980, 3400, 30288, 12881, 26199, 34520, 343, 474, 30299, 28508, 15195, 2654, 12895, 35544, 20319, 5218, 20322, 20450, 20454, 27242, 27116, 25965, 18797, 365, 30318, 5105, 25968, 21750, 23927, 35839}\n",
      "dict_items([(\"Lemma('attack.v.01.attack')\", 6), (\"Lemma('attack.n.02.attack')\", 3), (\"Lemma('attack.n.01.attack')\", 14), (\"Lemma('attack.n.06.attack')\", 1), (\"Lemma('approach.n.01.attack')\", 1), (\"Lemma('attack.v.02.attack')\", 3), (\"Lemma('fire.n.09.attack')\", 2), (\"Lemma('assail.v.01.attack')\", 2), (\"Lemma('attack.v.03.attack')\", 3), (\"Lemma('attack.n.05.attack')\", 1)])\n",
      "collecting tokens for  principle\n",
      "indices:    {22789, 31245, 25495, 23205, 27562, 12217, 32571, 13634, 4675, 31173, 26827, 2892, 26572, 26197, 11742, 31215, 29936, 23924, 887, 31224, 27897, 25083, 31228}\n",
      "dict_items([(\"Lemma('principle.n.02.principle')\", 3), (\"Lemma('principle.n.01.principle')\", 1), (\"Lemma('principle.n.03.principle')\", 1)])\n",
      "collecting tokens for  established\n",
      "indices:    {32897, 9218, 32130, 4617, 14346, 2059, 11276, 7949, 32397, 5386, 14866, 33043, 32404, 5140, 32790, 30231, 16408, 4252, 25374, 34337, 2724, 14247, 9640, 28328, 2730, 1195, 2858, 14841, 4270, 5167, 27696, 15534, 21430, 23607, 9144, 32313, 15675, 16191, 30529, 15428, 2631, 15688, 23243, 32332, 12364, 31949, 4175, 30800, 24014, 32461, 14421, 23894, 21079, 2776, 27865, 13912, 20443, 32475, 13783, 23520, 2151, 27752, 14183, 21226, 14444, 32750, 15216, 4721, 3570, 32627, 12286, 15481, 14842, 31101, 33150}\n",
      "dict_items([(\"Lemma('prove.v.02.establish')\", 14), (\"Lemma('establish.v.01.establish')\", 20), (\"Lemma('establish.v.02.establish')\", 12), (\"Lemma('accomplished.s.03.established')\", 1), (\"Lemma('established.a.01.established')\", 7), (\"Lemma('establish.v.05.establish')\", 2), (\"Lemma('lay_down.v.01.establish')\", 4), (\"Lemma('conventional.s.02.established')\", 1)])\n",
      "collecting tokens for  increase\n",
      "indices:    {25088, 16385, 10261, 24602, 31258, 31259, 27681, 23590, 11815, 32313, 32316, 32318, 63, 62, 2623, 23618, 24640, 73, 23628, 4178, 23636, 25176, 23642, 24164, 24168, 3699, 15477, 15478, 15481, 15484, 15485, 15486, 25741, 4237, 145, 4248, 15001, 16028, 20639, 27813, 24743, 29880, 7872, 29889, 12482, 15044, 18634, 3789, 25304, 27866, 2273, 20709, 12518, 32487, 20713, 3306, 20715, 21230, 20210, 20212, 20214, 11521, 11522, 11529, 3339, 11532, 2830, 2831, 21776, 8470, 20249, 15138, 3367, 3370, 11567, 22835, 31031, 3386, 21820, 24899, 24901, 20302, 21857, 1382, 2413, 5492, 3448, 21896, 25484, 25485, 24467, 3991, 20376, 20381, 21920, 11683, 23472, 5554, 16310, 32701, 24009, 4044, 2010, 24026, 16348, 16351, 16353, 16356, 16357, 16358, 16360, 16361, 8682, 16364, 16365, 16366, 16368, 32760, 16377, 16378, 16379, 16383}\n",
      "dict_items([(\"Lemma('increase.n.03.increase')\", 3), (\"Lemma('increase.v.02.increase')\", 26), (\"Lemma('increase.n.02.increase')\", 16), (\"Lemma('increase.v.01.increase')\", 23), (\"Lemma('increase.n.05.increase')\", 3), (\"Lemma('addition.n.03.increase')\", 16), (\"Lemma('increase.n.04.increase')\", 2)])\n",
      "collecting tokens for  state-owned\n",
      "indices:    {32321, 32322, 32355, 32263, 32266, 32333, 32301, 32271, 32340, 32313, 32286, 32319}\n",
      "dict_items([])\n",
      "collecting tokens for  came\n",
      "indices:    {36869, 18438, 12299, 8209, 22547, 36887, 18459, 24627, 34872, 20537, 22589, 24639, 14424, 26713, 16477, 6239, 34915, 14441, 36972, 14445, 14447, 14448, 10356, 36985, 8315, 30844, 10366, 34945, 22658, 20616, 34959, 14479, 2194, 34962, 14484, 14486, 30871, 16557, 24752, 24758, 12474, 18627, 18628, 6359, 12510, 20707, 10477, 26874, 8442, 257, 10499, 10503, 276, 20765, 18726, 6451, 6454, 12610, 6475, 2381, 336, 35161, 6491, 20831, 12642, 18790, 6505, 29037, 35188, 375, 6521, 33151, 386, 12678, 391, 6538, 6539, 35214, 10641, 2452, 8597, 10645, 6562, 22953, 6571, 8633, 22974, 22976, 12737, 18883, 6596, 6602, 12747, 6605, 31189, 18909, 18914, 31203, 12773, 29167, 23028, 23029, 20993, 23048, 18956, 530, 16918, 35353, 16921, 23068, 16924, 25121, 29222, 6706, 23096, 12862, 12864, 12865, 35398, 12884, 8789, 8793, 10844, 19039, 12896, 610, 35432, 8817, 10866, 19063, 33405, 17023, 33411, 27268, 35459, 8839, 17038, 33437, 33438, 29348, 681, 10921, 29355, 29365, 33465, 31421, 29377, 10947, 33477, 8907, 29389, 33486, 27343, 29394, 8916, 19160, 29403, 35548, 17116, 10974, 6885, 4838, 4840, 8940, 35566, 6895, 6901, 2808, 13052, 6911, 31488, 6916, 13060, 6919, 6920, 6921, 17163, 13067, 6926, 33554, 6935, 31512, 23319, 19239, 13107, 31548, 11073, 27465, 13131, 21339, 21351, 27496, 21356, 9069, 15219, 4980, 7030, 17276, 4994, 7055, 19344, 25498, 35742, 35746, 17321, 25522, 19385, 7101, 35786, 9162, 31691, 17364, 7126, 9181, 17380, 13313, 1027, 33799, 9229, 7191, 33817, 9242, 25640, 5160, 21549, 21561, 33852, 31812, 5192, 13395, 1113, 35933, 13408, 15459, 7273, 23658, 33909, 17574, 1192, 36025, 9404, 29894, 33999, 36051, 7381, 31967, 36065, 1263, 7420, 7421, 1277, 7422, 36096, 7431, 32010, 1300, 32020, 5406, 13601, 36132, 36135, 17704, 34089, 21803, 23852, 34093, 9523, 34104, 21816, 19773, 30014, 34117, 27974, 1370, 19803, 1371, 21888, 19841, 15747, 28036, 19852, 1427, 36244, 36247, 17815, 19865, 19867, 17822, 28064, 19877, 36263, 9643, 19883, 19885, 19891, 13747, 19893, 9655, 1482, 26063, 17884, 13790, 7647, 7646, 9698, 5604, 9701, 7655, 36332, 15854, 7663, 7667, 26103, 7672, 28153, 28158, 32266, 7711, 36387, 5675, 32313, 7738, 9793, 22088, 36425, 22094, 5712, 28242, 36448, 7777, 36451, 7781, 20074, 7796, 30325, 7807, 28301, 16029, 16030, 7839, 24224, 30370, 7847, 24234, 28339, 22197, 28347, 22205, 26307, 24261, 5840, 7889, 18133, 32469, 30427, 34524, 24290, 30435, 24292, 9963, 30448, 5873, 28403, 24313, 28419, 18187, 7953, 26386, 20243, 26389, 18200, 24349, 26402, 30507, 10029, 30518, 26426, 7999, 36673, 14152, 24393, 18252, 34644, 24405, 8026, 20329, 5993, 30585, 6020, 6031, 24463, 3997, 8096, 36769, 12197, 10151, 26549, 18360, 32698, 10172, 24510, 26568, 8151, 36832, 36840, 34792, 14319, 6128, 8178}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('arrive.v.01.come')\", 26), (\"Lemma('come.v.01.come')\", 26), (\"Lemma('come.v.05.come')\", 8), (\"Lemma('come.v.03.come')\", 26), (\"Lemma('come.v.04.come')\", 14), (\"Lemma('hail.v.02.come')\", 4), (\"Lemma('come.v.10.come')\", 2), (\"Lemma('come.v.06.come')\", 2), (\"Lemma('come.v.09.come')\", 1), (\"Lemma('come.v.15.come')\", 1), (\"Lemma('issue_forth.v.01.come')\", 1), (\"Lemma('come_near.v.01.come_near')\", 1)])\n",
      "collecting tokens for  oil\n",
      "indices:    {17926}\n",
      "dict_items([])\n",
      "collecting tokens for  co.\n",
      "indices:    {21837}\n",
      "dict_items([])\n",
      "collecting tokens for  california\n",
      "indices:    {35167}\n",
      "dict_items([])\n",
      "collecting tokens for  tuesday\n",
      "indices:    {325}\n",
      "dict_items([(\"Lemma('tuesday.n.01.Tuesday')\", 1)])\n",
      "collecting tokens for  headed\n",
      "indices:    {20611, 22532, 34436, 20612, 34439, 12809, 34443, 35985, 22546, 33814, 36887, 18714, 20763, 9628, 540, 24094, 6042, 13093, 21928, 18346, 18732, 16177, 25783, 23992, 5049, 18747, 21822, 23620, 25285, 18516, 33364, 23894, 11352, 31713, 484, 18534, 230, 34024, 21097, 28265, 33766, 18541, 500, 19193, 19194, 35964}\n",
      "dict_items([(\"Lemma('headed.a.03.headed')\", 1), (\"Lemma('head.v.02.head')\", 13), (\"Lemma('head.v.04.head')\", 2), (\"Lemma('head.v.01.head')\", 17), (\"Lemma('lead.v.04.head')\", 2), (\"Lemma('headed.a.02.headed')\", 1), (\"Lemma('steer.v.01.head')\", 1), (\"Lemma('headed.s.01.headed')\", 5)])\n",
      "collecting tokens for  dillon\n",
      "indices:    {1138}\n",
      "dict_items([])\n",
      "collecting tokens for  +\n",
      "indices:    {21890, 21891, 17926, 11152, 29072, 29715, 29076, 29078, 25751, 15259, 29084, 7709, 11806, 4125, 21534, 21919, 21156, 21799, 21928, 21161, 172, 11694, 11695, 26416, 12593, 21553, 21563, 14908, 15677, 21566, 14911, 32446, 23876, 14917, 21957, 21959, 12616, 14919, 14922, 21963, 14924, 15692, 21962, 13775, 21961, 14929, 21966, 21964, 13776, 28876, 3918, 23385, 14942, 14943, 21600, 23398, 11622, 11888, 11889, 12535, 33273, 23164}\n",
      "dict_items([(\"Lemma('group.n.01.group')\", 1)])\n",
      "collecting tokens for  similar\n",
      "indices:    {26792, 20317, 3988, 35677}\n",
      "dict_items([(\"Lemma('similar.a.01.similar')\", 1)])\n",
      "collecting tokens for  amount\n",
      "indices:    {3590, 25095, 25094, 14856, 14854, 14859, 14855, 22030, 14862, 14864, 14863, 5139, 14871, 14873, 11806, 3105, 22053, 14888, 14892, 14893, 29741, 14894, 29233, 16437, 3125, 4170, 23626, 15949, 22605, 3151, 34898, 15955, 34386, 15962, 4193, 26721, 25188, 26726, 102, 3180, 27245, 32365, 21626, 3716, 3210, 18583, 24728, 21153, 32430, 1710, 26798, 32435, 3257, 14523, 15036, 15037, 15041, 20674, 16581, 3275, 2764, 15060, 20693, 15062, 20695, 20696, 20181, 15066, 20699, 14043, 15064, 3817, 15594, 30956, 15600, 15605, 20215, 28925, 1792, 21766, 27403, 21777, 21778, 16657, 2859, 1846, 3897, 15678, 2369, 1859, 20310, 12119, 12128, 29546, 14192, 1906, 11125, 23931, 3986, 2971, 21928, 17834, 5547, 1963, 4014, 4015, 14771, 33205, 4537, 31684, 25038, 3542, 28125, 5599, 6116, 34296, 16377, 16378, 15869, 28671}\n",
      "dict_items([(\"Lemma('amount.n.02.amount')\", 26), (\"Lemma('measure.n.02.amount')\", 11), (\"Lemma('sum.n.01.amount')\", 26), (\"Lemma('sum.n.02.amount')\", 3), (\"Lemma('amount.v.01.amount')\", 2), (\"Lemma('total.v.01.amount')\", 1), (\"Lemma('come.v.15.amount')\", 2)])\n",
      "collecting tokens for  held\n",
      "indices:    {21377, 14986, 12683, 15374, 29199, 26384, 20627, 10900, 35605, 2070, 33022, 28056, 26015, 9634, 31395, 18598, 32680, 4779, 22828, 6189, 25774, 24367, 7857, 15281, 35636, 29237, 28086, 12599, 33462, 23353, 15290, 21057, 9411, 24259, 33605, 10955, 2512, 6104, 27774, 35932, 12767, 7777, 11495, 22376, 36333, 8560, 6897, 23410, 7796, 21365, 31990, 18171, 15102}\n",
      "dict_items([(\"Lemma('hold.v.03.hold')\", 8), (\"Lemma('deem.v.01.hold')\", 5), (\"Lemma('keep.v.01.hold')\", 8), (\"Lemma('oblige.v.02.hold')\", 1), (\"Lemma('harbor.v.01.hold')\", 1), (\"Lemma('have.v.01.hold')\", 2), (\"Lemma('restrain.v.03.hold')\", 2), (\"Lemma('bear.v.11.hold')\", 3), (\"Lemma('retain.v.03.hold')\", 2), (\"Lemma('hold.v.14.hold')\", 2), (\"Lemma('hold.v.02.hold')\", 5), (\"Lemma('exsert.v.01.hold_out')\", 1), (\"Lemma('hold.v.11.hold')\", 1)])\n",
      "collecting tokens for  gulf\n",
      "indices:    {18714}\n",
      "dict_items([(\"Lemma('location.n.01.location')\", 1)])\n",
      "collecting tokens for  corp.\n",
      "indices:    {20734}\n",
      "dict_items([])\n",
      "collecting tokens for  cannot\n",
      "indices:    {15363, 4611, 19464, 25610, 12300, 25612, 23570, 25619, 15380, 25621, 10779, 15389, 2078, 1565, 25632, 26148, 34340, 1576, 26154, 28202, 22578, 30771, 4659, 29237, 25652, 2105, 2107, 28736, 28739, 28230, 28231, 31304, 15433, 2127, 31312, 10832, 1112, 5211, 23646, 15458, 27235, 2146, 98, 27234, 15460, 15463, 25191, 28266, 28267, 3692, 3699, 13430, 10871, 31351, 13438, 3198, 4706, 2692, 2183, 13961, 25740, 25744, 25749, 31894, 27286, 25752, 13463, 28316, 12957, 25763, 23719, 21161, 1705, 21163, 25260, 4779, 32951, 16063, 25803, 24267, 28892, 22757, 20200, 13544, 2282, 25834, 12013, 13554, 16117, 16118, 21750, 3318, 25846, 29434, 25855, 4352, 2818, 1286, 22792, 28939, 28940, 37136, 5415, 5416, 12074, 12075, 12076, 29999, 27440, 4913, 2353, 819, 5428, 13622, 13624, 12601, 28474, 16187, 33084, 5957, 24904, 1356, 16205, 25937, 24915, 27476, 8024, 27994, 14174, 4958, 28516, 14180, 28006, 28008, 24938, 2411, 25453, 14191, 14194, 14706, 4989, 14207, 31104, 12159, 32131, 4999, 14215, 14218, 28043, 908, 907, 4501, 7574, 14233, 22426, 32155, 14238, 27558, 4009, 1965, 14261, 15798, 28597, 31162, 26046, 21953, 21956, 25541, 20423, 25547, 19408, 24537, 1505, 1506, 21989, 1510, 6119, 15850, 10733, 28141, 12784, 23539, 13306}\n",
      "dict_items([])\n",
      "collecting tokens for  pushed\n",
      "indices:    {36736, 13568, 21891, 5381, 8850, 33684, 18836, 18710, 8216, 6169, 16154, 24352, 24353, 17571, 26148, 22065, 30898, 20149, 19906, 18762, 33870, 2127, 18779, 26717, 8185, 12895, 8927, 36064, 8422, 18535, 10984, 19174, 10986, 5098, 27122, 10488, 7161, 21499}\n",
      "dict_items([(\"Lemma('push.v.01.push')\", 25), (\"Lemma('push.v.02.push')\", 3), (\"Lemma('strong-arm.v.02.push_around')\", 1), (\"Lemma('advertise.v.02.push')\", 2)])\n",
      "collecting tokens for  communist\n",
      "indices:    {25545}\n",
      "dict_items([])\n",
      "collecting tokens for  makes\n",
      "indices:    {23104, 20919, 30146, 32065, 14599, 21831, 1799, 19594, 10413, 2640, 16016, 5586, 29495, 14615, 12062}\n",
      "dict_items([(\"Lemma('make.v.02.make')\", 8), (\"Lemma('make.v.01.make')\", 2), (\"Lemma('produce.v.02.make')\", 1), (\"Lemma('induce.v.02.make')\", 1)])\n",
      "collecting tokens for  leaders\n",
      "indices:    {20480, 20482, 27140, 24075, 22541, 24590, 24598, 4632, 25629, 4638, 26148, 12846, 20535, 20568, 1113, 23649, 15458, 11883, 27761, 11893, 11894, 25727, 25728, 22659, 25733, 24198, 24205, 27790, 19607, 25752, 4769, 23719, 23725, 8368, 25787, 25793, 4802, 23242, 27852, 31959, 27868, 31968, 25330, 24822, 25346, 25347, 20759, 20760, 20762, 20764, 20765, 14111, 14112, 2373, 22354, 24408, 351, 24429, 23919, 28016, 14710, 24440, 23960, 15771, 14237, 21919, 16304, 16305, 6582, 21433, 20420, 21455, 13272, 27616, 4577, 31723, 31218, 27635, 4599, 4601, 20477, 20478}\n",
      "dict_items([(\"Lemma('leader.n.01.leader')\", 14), (\"Lemma('leadership.n.02.leaders')\", 9)])\n",
      "collecting tokens for  sit\n",
      "indices:    {28419, 9221, 19463, 27657, 19467, 10895, 17679, 5654, 33434, 5791, 6307, 7466, 24247, 8504, 17597, 30654, 2495, 25666, 25155, 31941, 5957, 28361, 33737, 25676, 30679, 11608, 19931, 9310, 9311, 15456, 34911, 9186, 1251, 612, 25071, 1777, 10098, 25076, 30967}\n",
      "dict_items([(\"Lemma('sit.v.02.sit')\", 6), (\"Lemma('sit.v.01.sit')\", 21), (\"Lemma('sit_down.v.01.sit')\", 2), (\"Lemma('sit.v.04.sit')\", 1), (\"Lemma('sit_by.v.01.sit_by')\", 1)])\n",
      "collecting tokens for  inside\n",
      "indices:    {18182, 4490, 21387, 27917, 19218, 33685, 29591, 19607, 34073, 31261, 29599, 6560, 9386, 33578, 17582, 9394, 18356, 15156, 35386, 36412, 20669, 27070, 8006, 35275, 8012, 29646, 35410, 17747, 35539, 35288, 13018, 35678, 29665, 15074, 15078, 17769, 8062, 26868, 34044, 13310}\n",
      "dict_items([(\"Lemma('inside.r.01.inside')\", 3), (\"Lemma('inside.r.02.inside')\", 4), (\"Lemma('inside.n.02.inside')\", 1), (\"Lemma('inside.a.01.inside')\", 1)])\n",
      "collecting tokens for  coffee\n",
      "indices:    {29039}\n",
      "dict_items([])\n",
      "collecting tokens for  pound\n",
      "indices:    {11525, 11528, 267, 9229, 11542, 11543, 11545, 11556, 11560, 11562, 11312, 14769, 14770, 29492, 21824, 10562, 11595, 11596, 22992, 14290, 11602, 11603, 14293, 11606, 29536, 359, 16493, 18673}\n",
      "dict_items([(\"Lemma('pound.n.01.pound')\", 23), (\"Lemma('thump.v.03.pound')\", 2)])\n",
      "collecting tokens for  fist\n",
      "indices:    {10562, 12292, 9893, 18469, 18442, 24458, 18444, 8941, 34032, 34097, 9682, 34106, 34107, 8990}\n",
      "dict_items([(\"Lemma('fist.n.01.fist')\", 8)])\n",
      "collecting tokens for  hear\n",
      "indices:    {1408, 18433, 15747, 10245, 17676, 25742, 17297, 22547, 27158, 31769, 6553, 13596, 34973, 7206, 19241, 19114, 5886, 31150, 26415, 18356, 22327, 35640, 10425, 36026, 35258, 17852, 7741, 20798, 5818, 18361, 5817, 9921, 10940, 17604, 14149, 37062, 9400, 9160, 14023, 27979, 10956, 22354, 16470, 36056, 6873, 14042, 8794, 5734, 8167, 28391, 18409, 33516, 37100, 1262, 9068, 112, 26481, 14065, 9971, 6000, 9336, 761, 18046}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('learn.v.02.hear')\", 10), (\"Lemma('hear.v.01.hear')\", 26), (\"Lemma('hear.v.04.hear')\", 1), (\"Lemma('hear.v.03.hear')\", 1)])\n",
      "collecting tokens for  running\n",
      "indices:    {25728, 35459, 17796, 12676, 35591, 20489, 7324, 10912, 34208, 6825, 27439, 35249, 12988, 35261, 2236, 29378, 323, 32198, 847, 2512, 20436, 9187, 36327, 9459, 884, 35320, 20477}\n",
      "dict_items([(\"Lemma('run.v.01.run')\", 4), (\"Lemma('run.n.07.running')\", 1), (\"Lemma('running.a.01.running')\", 1), (\"Lemma('scat.v.01.run')\", 1), (\"Lemma('run.v.03.run')\", 2), (\"Lemma('run.v.06.run')\", 1), (\"Lemma('campaign.v.01.run')\", 1), (\"Lemma('operate.v.01.run')\", 1), (\"Lemma('function.v.01.run')\", 1), (\"Lemma('run.v.25.run')\", 1), (\"Lemma('range.v.01.run')\", 1)])\n",
      "collecting tokens for  calling\n",
      "indices:    {20460, 15414, 8511}\n",
      "dict_items([(\"Lemma('call.v.02.call')\", 1), (\"Lemma('name.v.01.call')\", 2)])\n",
      "collecting tokens for  soon\n",
      "indices:    {16587}\n",
      "dict_items([(\"Lemma('soon.r.01.soon')\", 1)])\n",
      "collecting tokens for  tree\n",
      "indices:    {30082, 3598, 8340, 11295, 9504, 1697, 16164, 9519, 19260, 21309, 36028, 19261, 19264, 1488, 31446, 9177, 36064, 6244, 13546, 13559}\n",
      "dict_items([(\"Lemma('tree.n.01.tree')\", 13)])\n",
      "collecting tokens for  voices\n",
      "indices:    {9224, 30219, 26512, 6807, 9243, 36769, 24354, 7203, 6308, 13732, 13609, 26803, 36413, 24384, 16582, 12998, 25161, 26058, 24395, 28391, 14568, 15851, 7409, 1013, 33270, 8572, 24444}\n",
      "dict_items([(\"Lemma('voice.n.02.voice')\", 7), (\"Lemma('voice.n.01.voice')\", 3), (\"Lemma('voice.n.07.voice')\", 2), (\"Lemma('voice.n.05.voice')\", 1), (\"Lemma('articulation.n.03.voice')\", 1)])\n",
      "collecting tokens for  forced\n",
      "indices:    {18181, 12296, 35727, 17937, 18846, 173, 12472, 6328, 28730, 12225, 17219, 30540, 12241, 13649, 35676, 34026, 1514, 7276, 9970, 499, 10997, 34806, 24183, 34810, 8574, 34687}\n",
      "dict_items([(\"Lemma('pull.v.01.force')\", 1), (\"Lemma('coerce.v.01.force')\", 12), (\"Lemma('impel.v.01.force')\", 5), (\"Lemma('push.v.01.force')\", 4), (\"Lemma('force.v.04.force')\", 3), (\"Lemma('forced.s.02.forced')\", 1)])\n",
      "collecting tokens for  sale\n",
      "indices:    {27906, 29955, 15496, 13961, 11659, 22034, 22035, 12309, 28311, 15259, 14751, 14752, 15267, 25001, 16553, 2735, 32560, 14769, 14770, 2736, 14767, 5461, 24028, 34016, 23136, 992, 24167, 21865, 22383, 21105, 22001, 1395, 21109, 27898}\n",
      "dict_items([(\"Lemma('sale.n.01.sale')\", 12), (\"Lemma('sale.n.02.sale')\", 2)])\n",
      "collecting tokens for  motors\n",
      "indices:    {15219}\n",
      "dict_items([])\n",
      "collecting tokens for  stock\n",
      "indices:    {21937, 29083}\n",
      "dict_items([])\n",
      "collecting tokens for  christiana\n",
      "indices:    {15278}\n",
      "dict_items([(\"Lemma('group.n.01.group')\", 1)])\n",
      "collecting tokens for  delaware\n",
      "indices:    {6405}\n",
      "dict_items([(\"Lemma('delaware.n.01.Delaware')\", 1)])\n",
      "collecting tokens for  stockholders\n",
      "indices:    {14221, 15248, 15258, 15259, 15261, 15264, 15265, 15266, 15267, 15269, 15270, 15272, 15274, 15277, 21572, 25035, 25037, 25038, 14930, 14203}\n",
      "dict_items([(\"Lemma('stockholder.n.01.stockholder')\", 16)])\n",
      "collecting tokens for  parties\n",
      "indices:    {32256, 20357, 20358, 4743, 18314, 21645, 37138, 4759, 20760, 20761, 20762, 22176, 6947, 15267, 4771, 22435, 22438, 4776, 4777, 4778, 4774, 27444, 27768, 23236, 21061, 23242, 36304, 14045, 19550, 23903, 12000, 9185, 27745, 16360, 36201, 27767, 5112, 20347}\n",
      "dict_items([(\"Lemma('party.n.03.party')\", 5), (\"Lemma('party.n.01.party')\", 6), (\"Lemma('party.n.02.party')\", 2), (\"Lemma('party.n.04.party')\", 1)])\n",
      "collecting tokens for  capital\n",
      "indices:    {2761, 24164, 23670}\n",
      "dict_items([(\"Lemma('capital.n.01.capital')\", 1)])\n",
      "collecting tokens for  gains\n",
      "indices:    {21991, 11534, 21935, 1238, 11575}\n",
      "dict_items([(\"Lemma('gain.n.04.gain')\", 1), (\"Lemma('profit.n.02.gain')\", 1), (\"Lemma('addition.n.03.gain')\", 1)])\n",
      "collecting tokens for  rate\n",
      "indices:    {16384, 16385, 16386, 16387, 24075, 5132, 21518, 22043, 32290, 15396, 32293, 23590, 32295, 20537, 32315, 32316, 22081, 27203, 11846, 23627, 24141, 27247, 3695, 27249, 3703, 32893, 11396, 31365, 3732, 3743, 3745, 32932, 15525, 3236, 32937, 4274, 3765, 32956, 10437, 29900, 15053, 2766, 15582, 33505, 3297, 3301, 32998, 3302, 12518, 11519, 11521, 11522, 3334, 3336, 3339, 11532, 3341, 3342, 16158, 11554, 32550, 11558, 27944, 11564, 11565, 11566, 31024, 16183, 1339, 11580, 24893, 20284, 27968, 24896, 16197, 847, 3919, 24914, 14164, 2902, 27481, 31583, 16227, 2409, 2410, 5492, 2932, 15737, 18810, 23422, 2947, 28556, 3470, 2964, 2966, 2967, 2973, 15267, 5543, 27047, 31147, 35759, 5552, 20406, 12220, 3007, 24007, 25032, 24008, 5578, 5580, 5581, 5583, 21969, 3029, 16347, 3547, 16349, 16350, 16351, 16352, 12765, 16356, 16357, 16358, 16371, 16372, 16373, 16376, 16379, 16380, 16381, 16382, 16383}\n",
      "dict_items([(\"Lemma('rate.n.02.rate')\", 26), (\"Lemma('rate.n.01.rate')\", 26), (\"Lemma('pace.n.03.rate')\", 1), (\"Lemma('rate.v.01.rate')\", 2)])\n",
      "collecting tokens for  useful\n",
      "indices:    {768, 14850, 2819, 2310, 5002, 30220, 33041, 14748, 24093, 2986, 2988, 1841, 27828, 9781, 33082, 31803, 2749, 14400, 14408, 30796, 15948, 28494, 15950, 29904, 22737, 717, 13404, 1892, 26343, 26215, 1900, 13292, 14065, 11762, 2554}\n",
      "dict_items([(\"Lemma('useful.a.01.useful')\", 16)])\n",
      "collecting tokens for  geographical\n",
      "indices:    {30240, 16201, 30218, 2060, 20247, 32912, 33041, 25360, 32914, 24151, 32955}\n",
      "dict_items([(\"Lemma('geographic.a.01.geographical')\", 1)])\n",
      "collecting tokens for  population\n",
      "indices:    {31236, 27681, 4649, 31795, 14899, 30774, 27192, 2627, 20557, 20559, 20566, 20567, 26731, 109, 26738, 26744, 26746, 12942, 32911, 32912, 30353, 32913, 32915, 32917, 32918, 32922, 15002, 32924, 23197, 32925, 32928, 15009, 32932, 15013, 32934, 15012, 15030, 32951, 15032, 32953, 32954, 15031, 32957, 27841, 32963, 32965, 32967, 32968, 32980, 32982, 32991, 32992, 27873, 12518, 27879, 33007, 33027, 33029, 33030, 33032, 33033, 33035, 33038, 33039, 25360, 33041, 33045, 33046, 15653, 15655, 1321, 25389, 33070, 33076, 33079, 33080, 33081, 25400, 21820, 33085, 30015, 24901, 3400, 5452, 4450, 20837, 28006, 1385, 5483, 20845, 13167, 1397, 13183, 5505, 1409, 11651, 3466, 24467, 32152, 3487, 3491, 32171, 25529, 5570, 24518, 23511, 13784, 13281, 2532, 23524, 23531, 12272, 20465, 28670}\n",
      "dict_items([(\"Lemma('population.n.01.population')\", 25), (\"Lemma('population.n.02.population')\", 4), (\"Lemma('population.n.04.population')\", 1), (\"Lemma('population.n.03.population')\", 3)])\n",
      "collecting tokens for  periods\n",
      "indices:    {11777, 3332, 1034, 4621, 11277, 33041, 12563, 11541, 5530, 5537, 2597, 27558, 12074, 15149, 34350, 3886, 32177, 14389, 32698, 11842, 13254, 14674, 32346, 11746, 32611, 11753, 11247, 3700, 24311, 33020}\n",
      "dict_items([(\"Lemma('time_period.n.01.period')\", 19)])\n",
      "collecting tokens for  greek\n",
      "indices:    {13490}\n",
      "dict_items([(\"Lemma('greek.n.02.Greek')\", 1)])\n",
      "collecting tokens for  paper\n",
      "indices:    {31754, 30219, 27664, 12825, 11311, 8253, 32839, 18005, 35420, 24673, 24674, 24677, 6758, 30311, 11373, 8817, 25715, 11381, 4214, 20085, 14455, 28307, 16021, 16022, 30365, 3746, 29881, 9408, 9414, 31945, 17102, 9426, 16089, 29922, 34019, 17641, 28398, 17648, 5363, 5368, 5369, 5372, 5374, 5376, 5379, 5380, 1797, 29446, 13572, 26371, 16139, 28429, 28431, 16143, 16144, 12565, 12566, 5403, 32544, 13601, 5412, 7977, 3885, 9521, 3896, 9528, 27966, 2889, 17740, 3919, 24916, 33625, 12640, 24929, 29549, 29550, 1398, 7546, 7549, 4483, 12177, 29587, 19351, 3993, 29596, 29597, 2984, 34221, 4018, 21942, 3002, 34239, 16321, 16322, 16324, 9668, 16326, 20430, 9680, 9681, 19410, 11730, 9682, 9684, 3027, 3029, 3553, 16865, 3555, 34282, 10219, 29675, 5614, 19441, 34294, 32761}\n",
      "dict_items([(\"Lemma('paper.n.01.paper')\", 26), (\"Lemma('paper.n.05.paper')\", 2), (\"Lemma('newspaper.n.01.paper')\", 8), (\"Lemma('composition.n.08.paper')\", 20), (\"Lemma('paper.n.04.paper')\", 4), (\"Lemma('newspaper.n.02.paper')\", 1)])\n",
      "collecting tokens for  manufacturing\n",
      "indices:    {21237, 11654, 32447}\n",
      "dict_items([(\"Lemma('fabrication.n.03.manufacturing')\", 1)])\n",
      "collecting tokens for  reasons\n",
      "indices:    {31235, 13188, 25479, 30220, 22285, 14862, 3727, 19604, 32405, 27542, 32152, 27289, 20506, 11930, 36379, 23581, 31007, 21792, 16417, 27425, 32163, 31011, 5285, 2345, 23085, 21421, 16429, 28848, 24368, 23474, 26035, 1331, 32565, 3384, 26040, 32570, 32314, 22712, 28601, 13626, 12346, 33219, 27203, 26440, 16074, 588, 15821, 31184, 27346, 15571, 21972, 15573, 22998, 15448, 15837, 2655, 14946, 13157, 32359, 12271, 19312, 31087, 6770, 32879, 27124, 22389, 13174, 11637, 12920, 32377, 12274, 16381, 13182}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('reason.n.01.reason')\", 25), (\"Lemma('reason.v.01.reason')\", 1), (\"Lemma('reason.n.02.reason')\", 6)])\n",
      "collecting tokens for  duty\n",
      "indices:    {20337, 7666, 36595, 27316, 36436, 25022, 35295}\n",
      "dict_items([(\"Lemma('duty.n.01.duty')\", 1)])\n",
      "collecting tokens for  spencer\n",
      "indices:    {19343}\n",
      "dict_items([(\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  watching\n",
      "indices:    {33856, 23747, 1094, 18347, 36684, 25330, 31379, 12818, 10514, 8697, 10330, 16927}\n",
      "dict_items([(\"Lemma('watch.v.01.watch')\", 7), (\"Lemma('watch.v.02.watch')\", 2), (\"Lemma('watch.v.03.watch')\", 2), (\"Lemma('watch.v.04.watch')\", 1)])\n",
      "collecting tokens for  opportunity\n",
      "indices:    {1152, 17928, 24458, 12943, 2070, 16279, 26008, 8473, 22648, 27807, 1824, 32674, 28077, 17198, 15663, 2736, 4017, 2744, 20668, 17214, 28607, 14149, 18758, 12229, 17227, 17231, 22613, 12380, 33117, 28638, 26975, 27616, 14432, 27621, 24172, 14445, 27886, 27640, 20479, 32638, 32639}\n",
      "dict_items([(\"Lemma('opportunity.n.01.opportunity')\", 21)])\n",
      "collecting tokens for  communicate\n",
      "indices:    {25920, 32868, 19312, 19633, 11409, 32916, 25910, 13143, 4637, 4638}\n",
      "dict_items([(\"Lemma('communicate.v.02.communicate')\", 5), (\"Lemma('communicate.v.01.communicate')\", 5)])\n",
      "collecting tokens for  finding\n",
      "indices:    {14721, 26021, 34118, 27527, 14629, 33574, 21642, 9163, 17484, 32890, 22284, 23376, 36312, 11482, 4859, 6687}\n",
      "dict_items([(\"Lemma('discover.v.04.find')\", 3), (\"Lemma('find.v.03.find')\", 4), (\"Lemma('determination.n.01.finding')\", 1), (\"Lemma('discover.v.03.find')\", 1), (\"Lemma('detect.v.01.find')\", 1), (\"Lemma('receive.v.02.find')\", 1), (\"Lemma('find.v.01.find')\", 1), (\"Lemma('find.v.05.find')\", 2)])\n",
      "collecting tokens for  dead\n",
      "indices:    {35137, 865}\n",
      "dict_items([])\n",
      "collecting tokens for  cook\n",
      "indices:    {371, 29422}\n",
      "dict_items([(\"Lemma('cook.v.03.cook')\", 1)])\n",
      "collecting tokens for  caught\n",
      "indices:    {36610, 2262, 11994, 21054, 24831}\n",
      "dict_items([(\"Lemma('catch.v.13.catch')\", 1), (\"Lemma('catch.v.01.catch')\", 1), (\"Lemma('trip_up.v.01.catch')\", 1), (\"Lemma('hitch.v.01.catch')\", 1)])\n",
      "collecting tokens for  russell\n",
      "indices:    {26472}\n",
      "dict_items([])\n",
      "collecting tokens for  horse\n",
      "indices:    {36226, 35203, 3844, 7814, 1928, 10896, 35862, 35612, 16670, 10912, 35617, 28968, 35629, 10926, 35381, 18361, 12476, 35263, 18117, 25173, 3804, 17885, 6240, 28010, 8944, 35572, 7796, 6902, 12535}\n",
      "dict_items([(\"Lemma('horse.n.01.horse')\", 16), (\"Lemma('horse.n.02.horse')\", 1)])\n",
      "collecting tokens for  rode\n",
      "indices:    {7170, 10499, 13060, 18184, 13593, 11168, 29349, 29352, 18090, 5039, 35247, 19252, 5045, 35255, 16827, 18237, 18115, 6340, 29382, 18119, 5065, 7758, 6237, 5086, 29150, 36715, 8184, 35195}\n",
      "dict_items([(\"Lemma('ride.v.01.ride')\", 12), (\"Lemma('tease.v.02.ride')\", 1), (\"Lemma('ride.v.02.ride')\", 10), (\"Lemma('ride.v.04.ride')\", 2)])\n",
      "collecting tokens for  cattle\n",
      "indices:    {11584, 13608, 11560, 11530, 29979, 7828, 5078, 35223, 11515}\n",
      "dict_items([(\"Lemma('cattle.n.01.cattle')\", 6)])\n",
      "collecting tokens for  report\n",
      "indices:    {15296, 8676, 18891, 15376, 22000, 20561, 24026, 36884, 17044, 13274, 14943}\n",
      "dict_items([(\"Lemma('report.v.01.report')\", 2), (\"Lemma('report.n.01.report')\", 4), (\"Lemma('report.v.02.report')\", 1)])\n",
      "collecting tokens for  incident\n",
      "indices:    {3329, 23810, 4869, 29966, 9362, 36499, 7700, 3351, 34458, 5915, 25755, 3354, 25761, 12450, 3364, 12839, 24104, 21681, 24382, 3270, 5065, 22601, 2130, 12254, 3301, 3302, 36971, 2670, 4857, 15862, 23801, 8316, 6909}\n",
      "dict_items([(\"Lemma('incident.n.01.incident')\", 14), (\"Lemma('incident.a.01.incident')\", 7)])\n",
      "collecting tokens for  request\n",
      "indices:    {10116, 14854, 32908, 21520, 14869, 21403, 21404, 20383, 2724, 1959, 23848, 20141, 2094, 15417, 20793, 2749, 450, 21959, 32200, 5065, 21451, 2769, 36436, 15573, 30934, 15575, 15574, 32860, 2782, 28385, 21352, 33394, 764}\n",
      "dict_items([(\"Lemma('request.n.01.request')\", 9), (\"Lemma('request.v.01.request')\", 1), (\"Lemma('request.v.02.request')\", 2), (\"Lemma('request.n.02.request')\", 2)])\n",
      "collecting tokens for  trail\n",
      "indices:    {19200, 35267, 1257, 22164, 36884, 35862, 35863}\n",
      "dict_items([(\"Lemma('trail.n.01.trail')\", 1), (\"Lemma('trail.n.02.trail')\", 1)])\n",
      "collecting tokens for  stayed\n",
      "indices:    {32003, 29700, 29189, 9223, 9227, 34828, 17806, 13583, 25358, 399, 526, 37138, 8724, 36246, 8727, 7708, 19486, 18718, 16928, 10142, 16930, 20900, 24357, 19497, 297, 22957, 14512, 19505, 9654, 5050, 33467, 11454, 5694, 11456, 449, 7487, 10052, 36165, 29384, 36812, 12623, 34902, 12505, 17114, 19039, 27362, 34021, 17512, 6506, 33900, 10476, 10992, 28400, 13052}\n",
      "dict_items([(\"Lemma('stay.v.02.stay')\", 13), (\"Lemma('stay.v.04.stay')\", 6), (\"Lemma('bide.v.01.stay')\", 8), (\"Lemma('stay.v.01.stay')\", 15), (\"Lemma('stay.v.06.stay')\", 2), (\"Lemma('stay.v.05.stay')\", 1), (\"Lemma('stay_in_place.v.01.stay_in_place')\", 1), (\"Lemma('stay_at.v.01.stay_at')\", 1)])\n",
      "collecting tokens for  turning\n",
      "indices:    {1745, 19300}\n",
      "dict_items([(\"Lemma('turn.v.01.turn')\", 1)])\n",
      "collecting tokens for  entered\n",
      "indices:    {16641, 9350, 21767, 14856, 26762, 12427, 18316, 23308, 18190, 26895, 23824, 9361, 1938, 18836, 28569, 35995, 17180, 28189, 9246, 33439, 28574, 5409, 11035, 28579, 14884, 36900, 22181, 14889, 17067, 22187, 557, 7087, 21168, 9393, 28592, 4019, 32180, 9392, 182, 29368, 17337, 28604, 29374, 29378, 3267, 29384, 18377, 14922, 30539, 17738, 13256, 17100, 36051, 29396, 29395, 32726, 15959, 27994, 36958, 9183, 36730, 36963, 11108, 13797, 7016, 31725, 28014, 36721, 12401, 21622, 28535, 23158, 19322}\n",
      "dict_items([(\"Lemma('enter.v.01.enter')\", 26), (\"Lemma('enter.v.02.enter')\", 13), (\"Lemma('enroll.v.01.enter')\", 6), (\"Lemma('record.v.01.enter')\", 4), (\"Lemma('figure.v.02.enter')\", 3), (\"Lemma('enter.v.06.enter')\", 1)])\n",
      "collecting tokens for  square\n",
      "indices:    {27521, 13031, 4487, 4564, 6397}\n",
      "dict_items([(\"Lemma('location.n.01.location')\", 1), (\"Lemma('public_square.n.01.square')\", 1), (\"Lemma('square.n.01.square')\", 2)])\n",
      "collecting tokens for  mosque\n",
      "indices:    {29369}\n",
      "dict_items([])\n",
      "collecting tokens for  gate\n",
      "indices:    {29395, 35806}\n",
      "dict_items([])\n",
      "collecting tokens for  beyond\n",
      "indices:    {34922, 30540, 27885, 18905, 13653, 3321}\n",
      "dict_items([])\n",
      "collecting tokens for  thin\n",
      "indices:    {10370, 7810, 19460, 16515, 3847, 8584, 31496, 18574, 36368, 10514, 37013, 33558, 37015, 33563, 34975, 6435, 680, 27308, 36142, 30767, 34608, 7985, 29106, 35635, 35253, 33590, 8888, 9272, 3770, 31035, 37056, 9409, 29506, 10563, 17600, 24392, 35018, 9422, 36303, 7889, 34260, 21206, 35159, 34523, 24797, 35935, 19680, 4064, 7648, 2020, 7142, 10215, 17256, 33640, 33514, 8811, 10604, 8814, 31470, 8688, 29554, 17138, 8818, 8565, 11382, 34034, 22136, 31481, 26362, 9462, 33663}\n",
      "dict_items([(\"Lemma('thin.a.02.thin')\", 13), (\"Lemma('slender.s.02.thin')\", 5), (\"Lemma('thin.a.01.thin')\", 13), (\"Lemma('thin.v.01.thin')\", 1), (\"Lemma('thin_out.v.01.thin_out')\", 1), (\"Lemma('sparse.s.01.thin')\", 1)])\n",
      "collecting tokens for  gray\n",
      "indices:    {11322, 5140}\n",
      "dict_items([])\n",
      "collecting tokens for  raised\n",
      "indices:    {4096, 24576, 23810, 25090, 29572, 8194, 10374, 6282, 22667, 19342, 4750, 8850, 23186, 23319, 9626, 2076, 15522, 12451, 17571, 24227, 12194, 28327, 35624, 9516, 33325, 35245, 5424, 28595, 15028, 820, 20535, 29367, 25017, 15676, 29887, 30529, 17478, 20172, 5838, 37072, 12753, 36944, 22612, 25685, 16599, 10200, 25946, 4957, 15071, 7520, 16353, 23652, 16357, 16358, 27753, 16234, 6250, 27883, 12779, 36590, 16364, 20714, 36716, 8565, 26869, 1269, 18426}\n",
      "dict_items([(\"Lemma('raise.v.02.raise')\", 14), (\"Lemma('raise.v.03.raise')\", 11), (\"Lemma('raise.v.04.raise')\", 3), (\"Lemma('raise.v.07.raise')\", 7), (\"Lemma('raise.v.01.raise')\", 13), (\"Lemma('lift.v.03.raise')\", 1), (\"Lemma('raised.a.01.raised')\", 4), (\"Lemma('raise.v.09.raise')\", 2), (\"Lemma('arouse.v.01.raise')\", 1), (\"Lemma('grow.v.07.raise')\", 2), (\"Lemma('rear.v.02.raise')\", 3), (\"Lemma('brocaded.s.01.raised')\", 1)])\n",
      "collecting tokens for  cry\n",
      "indices:    {24320, 17283, 12803, 12805, 12806, 14092, 19482, 19501, 22834, 820, 20917, 22838, 9406, 6334, 36416, 12876, 12878, 7758, 18642, 8019, 9303, 12891, 35549, 37092, 8678, 12903, 12904, 9577, 11115, 7920, 34674, 8565}\n",
      "dict_items([(\"Lemma('cry.v.02.cry')\", 6), (\"Lemma('cry.n.04.cry')\", 1), (\"Lemma('cry.v.04.cry')\", 1), (\"Lemma('cry.n.02.cry')\", 2), (\"Lemma('war_cry.n.02.battle_cry')\", 2), (\"Lemma('cry.n.01.cry')\", 4), (\"Lemma('war_cry.n.01.cry')\", 1)])\n",
      "collecting tokens for  bird\n",
      "indices:    {230}\n",
      "dict_items([(\"Lemma('group.n.01.group')\", 1)])\n",
      "collecting tokens for  flock\n",
      "indices:    {30929, 219, 27439}\n",
      "dict_items([(\"Lemma('flock.v.01.flock')\", 1), (\"Lemma('group.n.01.group')\", 1)])\n",
      "collecting tokens for  hammarskjold\n",
      "indices:    {23851}\n",
      "dict_items([])\n",
      "collecting tokens for  despite\n",
      "indices:    {23432, 23410, 14999}\n",
      "dict_items([])\n",
      "collecting tokens for  danger\n",
      "indices:    {12936, 21897, 27785, 16649, 1932, 36237, 21774, 20241, 20243, 24853, 4632, 19226, 13978, 31259, 30240, 27810, 26021, 7087, 14261, 23610, 23866, 23611, 27836, 31290, 23612, 4674, 8771, 24772, 36816, 25425, 36818, 12506, 31963, 12766, 5599, 31969, 22626, 11235, 14435, 22637, 35437, 27375, 23666, 2035, 27636, 30836, 5110, 16500, 21752, 17660}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('risk.n.02.danger')\", 5), (\"Lemma('danger.n.01.danger')\", 12)])\n",
      "collecting tokens for  flew\n",
      "indices:    {13061, 18825, 18829, 1047, 35491, 7844, 8880, 23866, 9790, 33614, 33230, 7634, 214, 21728, 9058, 28393, 10476, 18670, 30575, 35575, 23289, 7420}\n",
      "dict_items([(\"Lemma('fly.v.01.fly')\", 11), (\"Lemma('fly.v.09.fly')\", 1), (\"Lemma('fly.v.04.fly')\", 1), (\"Lemma('fly.v.02.fly')\", 4), (\"Lemma('fly.v.05.fly')\", 1)])\n",
      "collecting tokens for  boat\n",
      "indices:    {28672, 28676, 30534, 28711, 29709, 28661, 36379, 32441, 28699, 28668, 29725, 28671}\n",
      "dict_items([])\n",
      "collecting tokens for  vary\n",
      "indices:    {29835, 28685, 2320, 3860, 33050, 29084, 32926, 32543, 1824, 4388, 32168, 16184, 25532, 32590, 16463, 10837, 30167, 15959, 16343, 3163, 22760, 28650, 21237, 3319}\n",
      "dict_items([(\"Lemma('deviate.v.02.vary')\", 11), (\"Lemma('change.v.03.vary')\", 8), (\"Lemma('vary.v.04.vary')\", 1), (\"Lemma('vary.v.03.vary')\", 4)])\n",
      "collecting tokens for  according\n",
      "indices:    {11036, 20343}\n",
      "dict_items([(\"Lemma('according.s.02.according')\", 1)])\n",
      "collecting tokens for  desires\n",
      "indices:    {13664, 28129, 35200, 32068, 26757, 12068, 28650, 813, 12013, 11985, 9588, 28532, 30709, 792, 5627}\n",
      "dict_items([(\"Lemma('desire.n.01.desire')\", 6), (\"Lemma('desire.v.01.desire')\", 2), (\"Lemma('desire.n.02.desire')\", 1)])\n",
      "collecting tokens for  certainly\n",
      "indices:    {14593, 25090, 27786, 5003, 1429, 19613, 24478, 28964, 6446, 1330, 2611, 9783, 27967, 33102, 3664, 24656, 26709, 4318, 11239, 24560, 9204}\n",
      "dict_items([(\"Lemma('surely.r.01.certainly')\", 12)])\n",
      "collecting tokens for  looked\n",
      "indices:    {6401, 6024, 5624, 34698, 7432, 11023, 33423, 10897, 10514, 7445, 18070, 19607, 19098, 1659, 33821, 9503, 9248, 35064, 19490, 18339, 11300, 8229, 9641, 11179, 7469, 7470, 19248, 17329, 17589, 35253, 34871, 24376, 17464, 37053, 35774, 14398, 34112, 30016, 31684, 33605, 7494, 7505, 5843, 30550, 7256, 7385, 17496, 9181, 17502, 17247, 19555, 36967, 5610, 26859, 6124, 28395, 36734, 36726, 5752, 9082, 33915, 7548, 35198, 9215}\n",
      "dict_items([(\"Lemma('look.v.02.look')\", 10), (\"Lemma('look.v.01.look')\", 26), (\"Lemma('look.v.03.look')\", 2)])\n",
      "collecting tokens for  japanese\n",
      "indices:    {36431}\n",
      "dict_items([])\n",
      "collecting tokens for  blame\n",
      "indices:    {33672, 1162, 26891, 33295, 36504, 36377, 17948, 14237, 23717, 20406, 19255, 7226, 7227, 23234, 25286, 27722, 11850, 19286, 16605, 9952, 16484, 12010, 27117, 35954, 5753, 19199}\n",
      "dict_items([(\"Lemma('blame.n.02.blame')\", 2), (\"Lemma('blame.v.01.blame')\", 9), (\"Lemma('blame.v.02.blame')\", 8), (\"Lemma('incrimination.n.01.blame')\", 2), (\"Lemma('blame.v.03.blame')\", 1)])\n",
      "collecting tokens for  keelson\n",
      "indices:    {29729, 29732, 29733, 29768, 29755, 29742, 29743, 29744, 29721, 29723}\n",
      "dict_items([])\n",
      "collecting tokens for  installed\n",
      "indices:    {3330, 29191, 12170, 7312, 9881, 15138, 30115, 29733, 22309, 36136, 30125, 31278, 1968, 30129, 5173, 21943, 5178, 30142, 30143, 34754, 5187, 21711, 28752, 11349, 12761, 29797, 22375, 6383, 29815, 29811, 25206, 29814}\n",
      "dict_items([(\"Lemma('install.v.01.install')\", 22), (\"Lemma('install.v.01.instal')\", 5), (\"Lemma('install.v.02.install')\", 1)])\n",
      "collecting tokens for  preceded\n",
      "indices:    {25952, 5409, 21284, 15877, 11366, 23790, 22611, 20984, 12312, 15898, 36734}\n",
      "dict_items([(\"Lemma('predate.v.01.precede')\", 3), (\"Lemma('precede.v.03.precede')\", 3), (\"Lemma('precede.v.02.precede')\", 4), (\"Lemma('precede.v.04.precede')\", 1)])\n",
      "collecting tokens for  luncheon\n",
      "indices:    {21120, 22337, 20577, 22180, 37028, 20968, 22729, 14312, 21131, 27665, 37075, 21141, 21143, 20984, 20985, 21274, 29148, 20348}\n",
      "dict_items([(\"Lemma('lunch.n.01.luncheon')\", 1)])\n",
      "collecting tokens for  increased\n",
      "indices:    {24899, 69, 25451, 32907, 2070, 15478, 27545}\n",
      "dict_items([(\"Lemma('increased.a.01.increased')\", 2), (\"Lemma('increase.v.01.increase')\", 1), (\"Lemma('increase.v.02.increase')\", 2)])\n",
      "collecting tokens for  partially\n",
      "indices:    {25989, 2823, 25366, 36759, 33049, 35738, 33949, 16185, 15863, 5062, 21191, 35272, 35921, 34400, 34030, 1907, 15479, 30584, 2809}\n",
      "dict_items([(\"Lemma('partially.r.01.partially')\", 7)])\n",
      "collecting tokens for  decrease\n",
      "indices:    {3367, 24168, 15949, 174, 3347, 15479, 31259, 30425, 5594, 2875, 797}\n",
      "dict_items([(\"Lemma('decrease.v.01.decrease')\", 5), (\"Lemma('decrease.n.01.decrease')\", 4), (\"Lemma('decrease.v.02.decrease')\", 2)])\n",
      "collecting tokens for  56\n",
      "indices:    {288, 290, 15479, 28804, 26629, 28806, 28802, 28809, 28779, 20883, 21971, 28790, 28791, 23004}\n",
      "dict_items([])\n",
      "collecting tokens for  forces\n",
      "indices:    {15489, 22874, 15465}\n",
      "dict_items([(\"Lemma('force.n.04.force')\", 1)])\n",
      "collecting tokens for  planned\n",
      "indices:    {30466, 12473, 16568, 24121, 21562, 12251, 29982}\n",
      "dict_items([(\"Lemma('plan.v.01.plan')\", 4), (\"Lemma('plan.v.02.plan')\", 2)])\n",
      "collecting tokens for  reduction\n",
      "indices:    {23823, 14864, 11537, 23827, 4374, 11545, 5535, 21156, 32164, 21158, 21161, 23988, 2879, 2632, 2637, 15955, 20440, 3293, 32866, 15871, 15474, 15479, 27769, 4218, 4220, 16381, 15870, 5495}\n",
      "dict_items([(\"Lemma('decrease.n.04.reduction')\", 14), (\"Lemma('reduction.n.02.reduction')\", 3), (\"Lemma('reduction.n.03.reduction')\", 1)])\n",
      "collecting tokens for  strength\n",
      "indices:    {23566, 24599, 16926, 24626, 36917, 29752, 36412, 23613, 12869, 36421, 20559, 26194, 29795, 15465, 1644, 25199, 15472, 15471, 15479, 12938, 22671, 12944, 3729, 15507, 12952, 32927, 18096, 27829, 23740, 8902, 19154, 11474, 31962, 23262, 28389, 36071, 6889, 24810, 12027, 24333, 27411, 6932, 6428, 20765, 25904, 23357, 27460, 14167, 23903, 27488, 23910, 3435, 27516, 27518, 11653, 28038, 1930, 21903, 6040, 14235, 1951, 1959, 36263, 1960, 1962, 32679, 23982, 1967, 1971, 1973, 1978, 25532, 25534, 1983, 1984, 1988, 1989, 5070, 32219, 3553, 3559, 19445, 23541, 1021}\n",
      "dict_items([(\"Lemma('strength.n.01.strength')\", 26), (\"Lemma('forte.n.01.strength')\", 2), (\"Lemma('military_capability.n.01.strength')\", 7), (\"Lemma('potency.n.02.strength')\", 1), (\"Lemma('force.n.03.strength')\", 1), (\"Lemma('persuasiveness.n.01.strength')\", 1)])\n",
      "collecting tokens for  components\n",
      "indices:    {16014, 4507, 4508, 4133, 32818, 15479, 4936, 4557, 4560, 4561, 2134, 30166, 4568, 2150, 3561, 15467, 28781, 15470, 2799, 2800, 15473, 28787, 21239}\n",
      "dict_items([(\"Lemma('component.n.01.component')\", 12), (\"Lemma('component.n.03.component')\", 1), (\"Lemma('part.n.01.component')\", 5)])\n",
      "collecting tokens for  1961\n",
      "indices:    {12319, 52, 23092, 22070, 575, 23618, 586, 21604, 15465, 24686, 15474, 15476, 15477, 15478, 15479, 15483, 15486, 20613, 22153, 15498, 20618, 15501, 15502, 20622, 20628, 20635, 168, 181, 20661, 15550, 15552, 15553, 15554, 15562, 15563, 25817, 219, 22749, 20708, 236, 21741, 23277, 21230, 21235, 1783, 20215, 32512, 20228, 32521, 15634, 22804, 1365, 1367, 23400, 1385, 31597, 1392, 23409, 25970, 32626, 21876, 21875, 32630, 23416, 32633, 1402, 23418, 23423, 32640, 23426, 23427, 27015, 32648, 32657, 22932, 29079, 32664, 24475, 24479, 29087, 14753, 32674, 29092, 14765, 32688, 23987, 29107, 29109, 32697, 29115, 32702, 5574, 24012, 22993, 29138, 21975, 23008, 23009, 31203, 31204, 28647, 32748, 14831, 23026, 14835, 20978, 20473, 22010}\n",
      "dict_items([])\n",
      "collecting tokens for  bar\n",
      "indices:    {28832, 28835, 28773, 1928, 17736, 36618, 34000, 36497, 28726, 30359}\n",
      "dict_items([(\"Lemma('barroom.n.01.bar')\", 1)])\n",
      "collecting tokens for  grill\n",
      "indices:    {29184, 29478, 17736, 29417, 29451, 29462, 29431, 29528, 29434}\n",
      "dict_items([(\"Lemma('grillroom.n.01.grill')\", 1), (\"Lemma('grill.v.01.grill')\", 1)])\n",
      "collecting tokens for  picked\n",
      "indices:    {31488, 19200, 13572, 12421, 17799, 35208, 11146, 34955, 25358, 30233, 22298, 7197, 34978, 555, 36780, 34605, 14507, 18479, 9525, 22198, 33466, 5690, 572, 5695, 17221, 5836, 19660, 30929, 17746, 18003, 35539, 30933, 9559, 5721, 35419, 10331, 9821, 7263, 30945, 23906, 22372, 29669, 32103, 12393, 12398, 7791, 36085, 13686, 26486, 24445}\n",
      "dict_items([(\"Lemma('pick_up.v.01.pick_up')\", 3), (\"Lemma('blame.v.02.pick')\", 1), (\"Lemma('collect.v.05.pick_up')\", 2), (\"Lemma('pick.v.01.pick')\", 5), (\"Lemma('pick.v.02.pick')\", 2), (\"Lemma('pick.v.04.pick')\", 1), (\"Lemma('pick_up.v.02.pick_up')\", 2), (\"Lemma('collar.v.01.pick_up')\", 1), (\"Lemma('pick_up.v.03.pick_up')\", 1)])\n",
      "collecting tokens for  burton\n",
      "indices:    {17749}\n",
      "dict_items([(\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  afternoon\n",
      "indices:    {8707, 9230, 19495, 7732, 53, 20026, 7740, 9806, 8273, 8298, 9835, 34950, 26261, 26262, 21142, 9879, 5790, 14497, 9397, 1726, 9929, 10441, 37075, 211, 214, 32485, 34021, 36075, 26354, 7935, 26369, 6402, 8702, 26377, 13587, 19736, 21275, 19741, 13602, 22307, 21799, 7473, 31545, 26426, 26433, 30039, 20829, 35689, 17770, 17772, 9581, 31599, 21361, 17267, 20854, 22903, 21368, 22905, 1914, 30591, 22915, 15749, 21387, 7563, 22926, 21908, 20893, 35756, 34232, 9668, 8655, 12770, 9187, 5616, 7154, 10744, 5630, 21503}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('afternoon.n.01.afternoon')\", 26), (\"Lemma('good_afternoon.n.01.afternoon')\", 1)])\n",
      "collecting tokens for  restrain\n",
      "indices:    {15234, 13763, 20266, 28556, 1069, 8433, 27259, 15229}\n",
      "dict_items([(\"Lemma('restrain.v.01.restrain')\", 4), (\"Lemma('restrict.v.03.restrain')\", 2), (\"Lemma('restrain.v.04.restrain')\", 1)])\n",
      "collecting tokens for  trade\n",
      "indices:    {16251, 32478, 14023}\n",
      "dict_items([(\"Lemma('trade.v.01.trade')\", 1)])\n",
      "collecting tokens for  attempt\n",
      "indices:    {20481, 15234, 20486, 20231, 2568, 26120, 12298, 20237, 1166, 26640, 16660, 18454, 32664, 22809, 14488, 32154, 4637, 26654, 17566, 18591, 36897, 13474, 35363, 20516, 36898, 23331, 15391, 36906, 35628, 30767, 12208, 37170, 4276, 6971, 27836, 36029, 13374, 4031, 25023, 2879, 23746, 16707, 16708, 23747, 1350, 197, 13256, 27726, 32340, 24153, 12506, 16732, 5340, 32860, 5856, 4833, 14945, 11492, 24424, 37097, 16746, 12011, 1260, 28014, 16750, 11252, 3446, 8567, 23929, 37119}\n",
      "dict_items([(\"Lemma('attempt.n.01.attempt')\", 26), (\"Lemma('try.v.01.attempt')\", 13), (\"Lemma('attack.n.05.attempt')\", 2), (\"Lemma('undertake.v.01.attempt')\", 2)])\n",
      "collecting tokens for  court\n",
      "indices:    {22821, 37108, 20685}\n",
      "dict_items([])\n",
      "collecting tokens for  decision\n",
      "indices:    {36993, 15234, 22021, 13701, 27142, 23176, 23183, 13328, 15377, 31761, 15763, 4757, 22040, 5401, 27801, 21403, 17820, 23583, 27808, 23585, 27809, 22047, 7719, 1832, 1833, 7598, 22831, 15281, 179, 11833, 27579, 27837, 27586, 31811, 31812, 27587, 13251, 13255, 26695, 31305, 18761, 5959, 2509, 14032, 22737, 24147, 31317, 20693, 7767, 13656, 20569, 31320, 31321, 471, 7768, 12121, 5600, 31339, 23917, 14062, 27896, 27897, 10618, 15229, 33150, 383}\n",
      "dict_items([(\"Lemma('decision.n.01.decision')\", 19), (\"Lemma('decision.n.02.decision')\", 7), (\"Lemma('decision.n.03.decision')\", 2)])\n",
      "collecting tokens for  weight\n",
      "indices:    {8579, 3204, 19460, 11525, 11528, 16511, 34061, 34170, 34065, 25618, 28947, 13587, 11542, 3991, 11543, 11545, 31130, 3739, 3740, 3102, 3103, 2976, 1533, 24608, 2979, 30752, 3109, 31139, 1569, 1580, 1581, 11312, 11568, 15666, 27189, 1592, 6906, 34107, 16319, 29119, 11584, 29762, 11586, 12867, 1991, 27207, 24265, 25804, 3150, 26704, 24787, 33109, 11606, 215, 217, 27226, 218, 27231, 33122, 7522, 21350, 34026, 2026, 7408, 34162, 34290, 34164, 10357, 9334, 11639, 1529, 1530, 25981, 29695}\n",
      "dict_items([(\"Lemma('weight.n.01.weight')\", 24), (\"Lemma('weight.n.03.weight')\", 3), (\"Lemma('weight.n.04.weight')\", 1), (\"Lemma('weight.n.02.weight')\", 4)])\n",
      "collecting tokens for  behind\n",
      "indices:    {13223, 21993, 20237, 34029, 7921, 35250, 17044, 21206, 6874, 10523}\n",
      "dict_items([])\n",
      "collecting tokens for  smashed\n",
      "indices:    {5088, 6212, 454, 18442, 18225, 18843, 6199, 10712, 34107}\n",
      "dict_items([(\"Lemma('smash.v.02.smash')\", 2), (\"Lemma('smash.v.01.smash')\", 6)])\n",
      "collecting tokens for  face\n",
      "indices:    {16898, 7171, 10245, 34316, 27661, 18971, 16927, 21539, 25637, 26153, 18477, 46, 25133, 33328, 34869, 7736, 7738, 28737, 581, 14922, 10315, 12883, 25686, 7767, 13403, 16478, 35935, 7265, 13411, 18021, 16998, 13416, 16491, 5744, 34930, 13939, 19570, 10870, 5752, 19065, 18042, 8830, 7301, 2694, 8847, 30355, 7318, 20120, 20635, 27805, 34975, 34982, 17575, 28839, 9388, 9389, 36014, 21164, 7857, 10419, 19125, 17590, 182, 7351, 21174, 7354, 6846, 27842, 7880, 35019, 18635, 35021, 206, 25807, 16590, 6865, 6869, 19158, 27353, 19681, 18146, 8419, 36066, 24805, 8929, 19174, 35560, 6377, 1262, 19183, 19696, 31475, 18170, 6398, 775, 9995, 34060, 12050, 8469, 9495, 35615, 35616, 35108, 19750, 34088, 7977, 6954, 25900, 33580, 34097, 31026, 6450, 34612, 19255, 24376, 10553, 17723, 19773, 21823, 17727, 19269, 27463, 11080, 24392, 19786, 33611, 10061, 10574, 10573, 31571, 20821, 9045, 16727, 34139, 23900, 18269, 25442, 24931, 16740, 9058, 16738, 23400, 11624, 31596, 8051, 22388, 27515, 6012, 19838, 6014, 33668, 17287, 19853, 32653, 7056, 21905, 11160, 23448, 24986, 14237, 22436, 18853, 33705, 18346, 30639, 35257, 31162, 3006, 30658, 34242, 19908, 5058, 8134, 18883, 7112, 21957, 23502, 7121, 9170, 11219, 7122, 7125, 7123, 26072, 26585, 18396, 4575, 4580, 4581, 21479, 7145, 5098, 7146, 33772, 9707, 18414, 5610, 5618, 16884, 18935, 18424, 8185, 5627}\n",
      "dict_items([(\"Lemma('confront.v.02.face')\", 19), (\"Lemma('face.n.03.face')\", 17), (\"Lemma('face.n.01.face')\", 26), (\"Lemma('confront.v.01.face')\", 16), (\"Lemma('face.v.04.face')\", 1), (\"Lemma('face.n.07.face')\", 1), (\"Lemma('front.v.01.face')\", 1), (\"Lemma('expression.n.01.face')\", 2), (\"Lemma('face.n.04.face')\", 1)])\n",
      "collecting tokens for  ma\n",
      "indices:    {9067}\n",
      "dict_items([(\"Lemma('ma.n.01.ma')\", 1)])\n",
      "collecting tokens for  went\n",
      "indices:    {37120, 34052, 7428, 34566, 35973, 28164, 5641, 13581, 35731, 7956, 35348, 403, 26775, 36502, 7707, 25507, 22563, 26405, 9004, 35759, 12592, 12850, 18739, 17588, 7477, 34941, 15799, 21685, 19646, 34112, 24897, 10818, 324, 6214, 13256, 12360, 10701, 5838, 33486, 33102, 30290, 30291, 34134, 34136, 9304, 8794, 20059, 34913, 8293, 35943, 9192, 36328, 22251, 9067, 18669, 7408, 19058, 22900, 25716, 7796, 8183, 17659, 23164, 12413, 27774, 16511}\n",
      "dict_items([(\"Lemma('travel.v.01.go')\", 22), (\"Lemma('go.v.02.go')\", 3), (\"Lemma('continue.v.01.go_on')\", 1), (\"Lemma('proceed.v.04.go')\", 1), (\"Lemma('die.v.01.go')\", 1)])\n",
      "collecting tokens for  sleeping\n",
      "indices:    {5861, 27434, 13581}\n",
      "dict_items([(\"Lemma('sleep.v.01.sleep')\", 1)])\n",
      "collecting tokens for  andy\n",
      "indices:    {9850}\n",
      "dict_items([(\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  bake\n",
      "indices:    {9907}\n",
      "dict_items([(\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  'd\n",
      "indices:    {36355, 8205, 34323, 8211, 34324, 8214, 8215, 24601, 6683, 36383, 8226, 17451, 18989, 33330, 35381, 35896, 17466, 36923, 33340, 33343, 19520, 9281, 33346, 9292, 9813, 16983, 1623, 19032, 18011, 19037, 16991, 17504, 17506, 33380, 18021, 17510, 33383, 18020, 33900, 33902, 19055, 19056, 19057, 7283, 9332, 16502, 34935, 30328, 17015, 18043, 636, 31357, 17021, 19070, 19075, 8840, 33929, 20104, 9867, 19087, 19088, 18066, 33428, 6808, 19103, 18080, 30880, 30884, 16555, 18093, 19631, 19119, 14511, 16562, 16561, 16565, 16566, 33463, 19127, 19129, 16569, 8887, 16568, 9406, 18110, 36544, 16577, 16578, 35010, 33473, 8902, 37062, 33480, 33481, 18122, 16592, 35024, 35026, 36563, 7381, 35542, 31447, 8920, 16598, 8922, 8923, 14557, 8926, 33503, 14558, 14561, 14560, 24291, 22238, 34021, 9949, 6891, 17644, 17645, 238, 28395, 34544, 8945, 9970, 17657, 17658, 34043, 19205, 20744, 269, 19214, 8974, 17680, 17679, 35091, 16662, 5911, 35096, 5914, 18203, 5915, 18205, 35102, 16672, 9505, 6950, 9005, 24881, 9018, 19259, 18238, 36163, 18243, 9029, 17733, 16711, 18252, 29516, 36698, 9053, 9054, 18271, 9058, 8042, 30571, 9068, 9069, 18286, 9071, 36212, 30581, 29046, 30583, 9080, 9078, 18298, 36219, 35702, 17789, 9086, 18297, 9082, 33665, 9089, 9091, 35719, 9096, 16779, 8081, 17297, 16785, 8084, 8086, 24475, 8094, 8095, 8611, 11172, 36262, 36269, 36270, 36271, 36272, 34224, 34226, 34225, 36277, 20920, 36286, 9665, 22980, 17355, 17868, 17356, 17357, 17361, 24531, 17876, 8150, 36827, 33759, 9697, 9700, 17382, 17383, 18409, 8172, 8183, 8185, 5629}\n",
      "dict_items([])\n",
      "collecting tokens for  talk\n",
      "indices:    {23300, 18438, 30475, 36879, 31507, 403, 19613, 23070, 14623, 13346, 6138, 31528, 19646, 23370, 27087, 18391, 18140, 5604, 18023, 35304, 18418, 6900, 13306, 635}\n",
      "dict_items([(\"Lemma('speak.v.03.talk')\", 1), (\"Lemma('talk.v.02.talk')\", 3), (\"Lemma('talk.v.01.talk')\", 10), (\"Lemma('talk.n.03.talk')\", 1), (\"Lemma('talk.n.01.talk')\", 1), (\"Lemma('spill_the_beans.v.01.talk')\", 1)])\n",
      "collecting tokens for  kind\n",
      "indices:    {18432, 33286, 11273, 28688, 3093, 27159, 13847, 27160, 5659, 1564, 30748, 34338, 13859, 36386, 24101, 13355, 2606, 2096, 14899, 16947, 2613, 34358, 27191, 20024, 4667, 23613, 14910, 2626, 9294, 2639, 15440, 2641, 19541, 3160, 13401, 19546, 27739, 19548, 23132, 19551, 10335, 32869, 20079, 30837, 17013, 10870, 3193, 134, 34951, 19593, 9866, 9867, 7306, 2706, 23187, 37013, 10903, 6808, 23705, 32413, 32415, 22689, 1702, 26791, 7849, 23211, 16555, 684, 16557, 10413, 16560, 16561, 17075, 22708, 26295, 8895, 7360, 22722, 4808, 31435, 37069, 10961, 26323, 25812, 11989, 27863, 28375, 4825, 14052, 14053, 10981, 35047, 1258, 22767, 14064, 30454, 26367, 5389, 7438, 4879, 35086, 27927, 25369, 26906, 31516, 285, 36125, 14623, 19740, 23330, 16675, 1316, 5925, 20774, 34601, 20778, 31530, 14634, 4398, 4399, 35124, 26934, 20280, 36670, 13631, 30528, 4926, 5956, 34633, 12622, 334, 12113, 4950, 30044, 14173, 34652, 13158, 12134, 11624, 14187, 35181, 12142, 12141, 34672, 6001, 29044, 6006, 886, 10616, 22393, 36215, 892, 10623, 28033, 32138, 17804, 18316, 13199, 12178, 30712, 7578, 32156, 925, 13215, 21921, 34722, 13219, 11171, 33701, 1959, 8104, 25513, 31145, 937, 27056, 12211, 33205, 12215, 30140, 32194, 21960, 34761, 22473, 6095, 36303, 35793, 33232, 26074, 28635, 9183, 2528, 13281, 28640, 20448, 24041, 1526, 23544, 28157}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('kind.n.01.kind')\", 26), (\"Lemma('kind.a.01.kind')\", 3)])\n",
      "collecting tokens for  p.\n",
      "indices:    {15003}\n",
      "dict_items([])\n",
      "collecting tokens for  setting\n",
      "indices:    {11788, 24846, 9879, 24604, 20253, 4780, 25779, 24887, 22843, 29247, 26569, 18635, 9547, 16336, 14424, 36441, 15704, 32987, 20446, 18014, 15724, 31856, 31347, 7795, 16374}\n",
      "dict_items([(\"Lemma('setting.n.02.setting')\", 1), (\"Lemma('ensnare.v.01.set_up')\", 1), (\"Lemma('determine.v.03.set')\", 3), (\"Lemma('setting.n.01.setting')\", 4)])\n",
      "collecting tokens for  wedding\n",
      "indices:    {20866, 19205, 19206, 19461, 7433, 20876, 20877, 30869, 9629, 20897, 20902, 30760, 34221, 26926, 21046, 21049, 17339, 13119, 21058, 34243, 34295}\n",
      "dict_items([(\"Lemma('wedding.n.01.wedding')\", 2)])\n",
      "collecting tokens for  thomas\n",
      "indices:    {13739}\n",
      "dict_items([])\n",
      "collecting tokens for  loving\n",
      "indices:    {21058, 2658, 9382, 22471, 11208, 36297, 31976, 4971, 30797, 27346, 30869, 791, 30777, 26938}\n",
      "dict_items([(\"Lemma('love.v.01.love')\", 4), (\"Lemma('loving.a.01.loving')\", 3)])\n",
      "collecting tokens for  jr.\n",
      "indices:    {32483}\n",
      "dict_items([])\n",
      "collecting tokens for  live\n",
      "indices:    {32000, 9729, 27394, 13827, 30090, 12174, 9742, 1042, 26259, 30611, 26517, 27158, 5906, 25110, 34456, 31390, 20899, 31524, 21414, 11175, 20135, 10284, 36140, 30132, 36535, 21049, 1338, 23354, 5436, 30651, 8771, 20036, 37062, 27462, 34887, 34249, 8010, 26828, 20046, 27343, 28627, 19540, 1494, 28121, 24796, 27485, 28254, 28253, 13150, 13149, 24933, 27499, 111, 22256, 25072, 1778, 26739, 34674, 22260, 13044, 10746, 13180, 10749, 34814}\n",
      "dict_items([(\"Lemma('survive.v.01.live')\", 10), (\"Lemma('populate.v.01.live')\", 26), (\"Lemma('exist.v.02.live')\", 4), (\"Lemma('live.v.02.live')\", 12), (\"Lemma('be.v.11.live')\", 4), (\"Lemma('live.a.01.live')\", 2)])\n",
      "collecting tokens for  trip\n",
      "indices:    {20866, 19202, 36995, 20877, 399, 16016, 20883, 13076, 20888, 22171, 36892, 10142, 11935, 34472, 11944, 30760, 34731, 29357, 5038, 23983, 22580, 18869, 31412, 21046, 21049, 12480, 29249, 21058, 36546, 24132, 25163, 15992, 28365, 27986, 27987, 27988, 36179, 30553, 31835, 5468, 8285, 30558, 30559, 12511, 8286, 5858, 28642, 30580, 30584, 24699, 16638}\n",
      "dict_items([(\"Lemma('trip.n.01.trip')\", 17)])\n",
      "collecting tokens for  orleans\n",
      "indices:    {21070}\n",
      "dict_items([])\n",
      "collecting tokens for  la\n",
      "indices:    {26945}\n",
      "dict_items([])\n",
      "collecting tokens for  watson\n",
      "indices:    {8551}\n",
      "dict_items([(\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  stared\n",
      "indices:    {18434, 7171, 33794, 33797, 36742, 19210, 22923, 1036, 31506, 36757, 19991, 13591, 8607, 19234, 18852, 6693, 17450, 17585, 35124, 19644, 17602, 17858, 10818, 17863, 35790, 12622, 10585, 5852, 35551, 33760, 6367, 5987, 35047, 18283, 17645, 36590, 8562, 7154, 34036, 33269, 6646, 6136, 7162}\n",
      "dict_items([(\"Lemma('gaze.v.01.stare')\", 26)])\n",
      "collecting tokens for  curve\n",
      "indices:    {4481, 4483, 32771, 32772, 32774, 4487, 34435, 29199, 4496, 3345, 32784, 4499, 4500, 32791, 32795, 32796, 3869, 3870, 32804, 32807, 32810, 4525, 32814, 4526, 32818, 4537, 3905, 32835, 32836, 32839, 32840, 19793, 16369}\n",
      "dict_items([(\"Lemma('curve.n.02.curve')\", 5), (\"Lemma('curve.n.01.curve')\", 9), (\"Lemma('curve.n.03.curve')\", 1)])\n",
      "collecting tokens for  symbol\n",
      "indices:    {32771, 35975, 2313, 35977, 28944, 32784, 32796, 32801, 10786, 32681, 28202, 4265, 23852, 7984, 13874, 24118, 1465, 26554, 13626, 27197, 22718, 20415, 28863, 28865, 28870, 28873, 11083, 28876, 28877, 13774, 26964, 8405, 19423, 13799, 32233, 1008, 32114, 11263}\n",
      "dict_items([(\"Lemma('symbol.n.01.symbol')\", 10), (\"Lemma('symbol.n.02.symbol')\", 2)])\n",
      "collecting tokens for  since\n",
      "indices:    {15296, 23752, 5165, 24367, 15919, 27965}\n",
      "dict_items([])\n",
      "collecting tokens for  |\n",
      "indices:    {4132, 3304, 4042, 32843, 3982, 3509, 32791, 11385, 32794, 32795, 32796, 3549, 14814, 3359}\n",
      "dict_items([(\"Lemma('one.n.01.one')\", 1)])\n",
      "collecting tokens for  hence\n",
      "indices:    {14224, 4345}\n",
      "dict_items([(\"Lemma('therefore.r.01.hence')\", 2)])\n",
      "collecting tokens for  invariant\n",
      "indices:    {32772, 4326, 32809, 32810, 4299, 32783, 32786, 32819, 32824, 32825, 32796, 4318}\n",
      "dict_items([(\"Lemma('invariant.s.01.invariant')\", 3)])\n",
      "collecting tokens for  single\n",
      "indices:    {17939, 13336, 24601, 4634, 1560, 32796, 32806, 3116, 22579, 5173, 13365, 3126, 3128, 23104, 16457, 15948, 30800, 11866, 2652, 2654, 23136, 24161, 31842, 3173, 30312, 4713, 32877, 23158, 17529, 18555, 31870, 18560, 22662, 32400, 26769, 32401, 13464, 17561, 33956, 11942, 26790, 4775, 31412, 16053, 183, 187, 4284, 12477, 199, 202, 26826, 8912, 211, 14049, 7906, 20711, 14568, 16104, 33004, 10478, 21243, 37123, 268, 18201, 21289, 11070, 11591, 30025, 32585, 4432, 33107, 4438, 16217, 14697, 14187, 32622, 22383, 18300, 2429, 4476, 385, 14210, 388, 22916, 390, 18309, 22408, 393, 33162, 21384, 22426, 5531, 4515, 4516, 4522, 23982, 4528, 3509, 3510, 4535, 14267, 30140, 11711, 16320, 4544, 12739, 16336, 16337, 25555, 5589, 31702, 22998, 24034, 11750, 12776, 31721, 14320, 16373, 33782, 28661, 33275}\n",
      "dict_items([(\"Lemma('individual.a.01.single')\", 26), (\"Lemma('single.n.01.single')\", 6), (\"Lemma('discriminate.v.02.single_out')\", 1)])\n",
      "collecting tokens for  point\n",
      "indices:    {5140}\n",
      "dict_items([])\n",
      "collecting tokens for  larger\n",
      "indices:    {29185, 4610, 3090, 18502, 5203, 10847, 26720, 1638, 11373, 12406, 31862, 32393, 32913, 32402, 16020, 7832, 32939, 32942, 3760, 29874, 22708, 32950, 32957, 32958, 32960, 22726, 29896, 32968, 16079, 32979, 25820, 32992, 29413, 16105, 24811, 5358, 13043, 23300, 33029, 33030, 2823, 3341, 3345, 3348, 3861, 2836, 5402, 16156, 7967, 28471, 3386, 28997, 3409, 12118, 16215, 12124, 12134, 13671, 34679, 21879, 16259, 28038, 11655, 18314, 11661, 3983, 3984, 31122, 10647, 11676, 5020, 11679, 29089, 23466, 11693, 14789, 29640, 31694, 2511, 6097, 11729, 17373, 4068, 16368, 23546, 6143}\n",
      "dict_items([(\"Lemma('bigger.s.01.larger')\", 26), (\"Lemma('large.a.01.large')\", 5)])\n",
      "collecting tokens for  numerical\n",
      "indices:    {3170, 3174, 28038, 27527, 27548, 32967, 27532, 13708, 13710, 28880, 4502, 28856, 3132}\n",
      "dict_items([(\"Lemma('numeric.s.02.numerical')\", 4), (\"Lemma('numeral.a.01.numerical')\", 1)])\n",
      "collecting tokens for  agreements\n",
      "indices:    {37088, 20728, 22628, 31707, 23477, 34390, 14870, 34392, 20730, 22651, 14748}\n",
      "dict_items([(\"Lemma('agreement.n.01.agreement')\", 2)])\n",
      "collecting tokens for  calls\n",
      "indices:    {20736, 2694, 27146, 24203, 20751, 32146, 24723, 1813, 2328, 7323, 17821, 5418, 23725, 26670, 21683, 5172, 21301, 949, 1720, 20411, 5183, 5184, 20800, 11075, 25668, 27206, 27590, 5705, 23930, 20944, 1872, 82, 5460, 85, 84, 27096, 32472, 13531, 32475, 4705, 31334, 13673, 20730, 32877, 1905, 13426, 757, 25210, 31861, 22009, 25978, 25211, 27132}\n",
      "dict_items([(\"Lemma('name.v.01.call')\", 9), (\"Lemma('call.v.03.call')\", 1), (\"Lemma('call.n.01.call')\", 5), (\"Lemma('call.v.02.call')\", 8), (\"Lemma('call.v.05.call')\", 1), (\"Lemma('visit.v.03.call')\", 1)])\n",
      "collecting tokens for  purchase\n",
      "indices:    {15746, 32357, 11339, 32272, 20432, 20728, 22812, 28671}\n",
      "dict_items([(\"Lemma('buy.v.01.purchase')\", 3)])\n",
      "collecting tokens for  acre\n",
      "indices:    {21988, 5541, 12135, 21834, 21708, 8687, 5490, 12116, 5591, 5592, 20730, 12090, 20734, 5503}\n",
      "dict_items([(\"Lemma('acre.n.01.acre')\", 9)])\n",
      "collecting tokens for  tract\n",
      "indices:    {24036, 23879, 6092, 21708, 11406, 16143, 3409, 20731, 3420, 20734}\n",
      "dict_items([(\"Lemma('tract.n.01.tract')\", 1), (\"Lemma('tract.n.02.tract')\", 1), (\"Lemma('tract.n.03.tract')\", 1)])\n",
      "collecting tokens for  exceptional\n",
      "indices:    {15973, 24486, 11271, 31722, 32267, 4907, 2829, 16014, 32787, 32798, 32795, 32830}\n",
      "dict_items([(\"Lemma('exceeding.s.01.exceptional')\", 3), (\"Lemma('especial.s.01.exceptional')\", 2)])\n",
      "collecting tokens for  transformed\n",
      "indices:    {32788, 32789, 32791, 32792, 32795, 5407, 32800, 32802, 32803, 14633, 32820, 32823, 27322, 32827, 32830, 12234, 14546, 31188, 31192, 9585}\n",
      "dict_items([(\"Lemma('transform.v.01.transform')\", 12), (\"Lemma('transform.v.02.transform')\", 5), (\"Lemma('transform.v.03.transform')\", 2), (\"Lemma('transformed.s.01.transformed')\", 1)])\n",
      "collecting tokens for  entire\n",
      "indices:    {11264, 25604, 27656, 21001, 1545, 25102, 23568, 28177, 32788, 1047, 24600, 1561, 32795, 2080, 32802, 32803, 10276, 27687, 24104, 23595, 1582, 12855, 14912, 25159, 32847, 24153, 2139, 2654, 33375, 12895, 2148, 23678, 11907, 22162, 8853, 11421, 11422, 14495, 26783, 2216, 11438, 25263, 27324, 27330, 15052, 225, 23276, 17646, 27897, 16635, 21247, 32513, 20737, 34053, 13575, 27933, 2845, 15653, 28455, 27948, 5427, 819, 4921, 3392, 3907, 27981, 23896, 18265, 20824, 18264, 4444, 35677, 28511, 4450, 28005, 26982, 15217, 4978, 23414, 26497, 21378, 24462, 27535, 28568, 15775, 15274, 12715, 31151, 25008, 4550, 5575, 1479, 4559, 28631, 4069, 23537, 5105}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('entire.s.01.entire')\", 26), (\"Lemma('integral.s.02.entire')\", 5), (\"Lemma('entire.s.03.entire')\", 1)])\n",
      "collecting tokens for  congruence\n",
      "indices:    {32803, 32808, 32809, 32783, 32784, 32785, 32791, 32795, 32797}\n",
      "dict_items([])\n",
      "collecting tokens for  involution\n",
      "indices:    {32772, 32811, 32786, 32822, 32791, 32824, 32825, 32795}\n",
      "dict_items([])\n",
      "collecting tokens for  variable\n",
      "indices:    {11268, 5519, 15644, 2852, 16178, 3398, 4426, 15946, 15696, 27729, 4563, 11358, 26344, 4457, 2920, 4456, 4461, 2926, 4468, 4475, 4476, 4479}\n",
      "dict_items([(\"Lemma('variable.s.03.variable')\", 1), (\"Lemma('varying.s.01.variable')\", 2), (\"Lemma('variable.a.01.variable')\", 6), (\"Lemma('variable.n.01.variable')\", 2)])\n",
      "collecting tokens for  ensemble\n",
      "indices:    {26338, 26664, 26408, 1036, 1806, 1753}\n",
      "dict_items([(\"Lemma('ensemble.n.01.ensemble')\", 3)])\n",
      "collecting tokens for  generally\n",
      "indices:    {4937, 139, 26219, 14453, 15639}\n",
      "dict_items([(\"Lemma('by_and_large.r.01.generally')\", 4)])\n",
      "collecting tokens for  satisfying\n",
      "indices:    {22688, 22689, 19398, 26344, 27401, 2027, 24301, 16118, 1049, 33179, 11164}\n",
      "dict_items([(\"Lemma('satisfy.v.01.satisfy')\", 1)])\n",
      "collecting tokens for  rather\n",
      "indices:    {3236, 13957, 19625, 29034, 8334, 3087, 27087, 5648, 3922, 2228, 24598, 14646, 2646, 11036, 14398, 3455}\n",
      "dict_items([(\"Lemma('rather.r.02.rather')\", 5), (\"Lemma('rather.r.01.rather')\", 4)])\n",
      "collecting tokens for  trying\n",
      "indices:    {20482, 12934, 26505, 6793, 14223, 25489, 31507, 18452, 33431, 2327, 22812, 23455, 16162, 27043, 27940, 28963, 25763, 32679, 808, 4778, 11051, 33462, 24887, 10428, 19645, 36036, 19911, 19912, 19657, 7758, 35539, 33364, 34652, 36074, 5363}\n",
      "dict_items([(\"Lemma('try.v.01.try')\", 26), (\"Lemma('trying.s.01.trying')\", 2)])\n",
      "collecting tokens for  prepared\n",
      "indices:    {23300, 21767, 29832, 32137, 14095, 21265, 3092, 4757, 15252, 27287, 11929, 4125, 27812, 19622, 3366, 15662, 21423, 5039, 2095, 25139, 29492, 29241, 29498, 3002, 27324, 23229, 32190, 17341, 20286, 32193, 3262, 5057, 27583, 30277, 22852, 15171, 29514, 4171, 3532, 29517, 3277, 3279, 11600, 3280, 32718, 21461, 35542, 12885, 14424, 3288, 24408, 32731, 30394, 32730, 3541, 9696, 15201, 9698, 32738, 30054, 24062, 4843, 32492, 22895, 30447, 24191, 242, 3954, 17908, 24052, 22387, 759, 34297, 31354, 36990, 12927}\n",
      "dict_items([(\"Lemma('prepared.a.01.prepared')\", 13), (\"Lemma('cook.v.02.prepare')\", 10), (\"Lemma('organize.v.05.prepare')\", 3), (\"Lemma('fix.v.12.prepare')\", 24), (\"Lemma('prepare.v.05.prepare')\", 1), (\"Lemma('prepare.v.03.prepare')\", 3)])\n",
      "collecting tokens for  case\n",
      "indices:    {16386, 14854, 11783, 25099, 26644, 17942, 22039, 2076, 14880, 22566, 2598, 26664, 14886, 35374, 36913, 32820, 3639, 32828, 32830, 8770, 20039, 35412, 36950, 14436, 14437, 13926, 12905, 25194, 25195, 30318, 9839, 32887, 34948, 25232, 9361, 13971, 32404, 23702, 13978, 15003, 4256, 23201, 29871, 21679, 21680, 9394, 20147, 2226, 31925, 21685, 15539, 23737, 20158, 7364, 4295, 20169, 15565, 20685, 22735, 5330, 22738, 32980, 11992, 11996, 4838, 4327, 24298, 2282, 37100, 16109, 3310, 2800, 27891, 4853, 4854, 24828, 9468, 22782, 20234, 3855, 22812, 18717, 12061, 21793, 4907, 20788, 20790, 2361, 36155, 16196, 15701, 1375, 23392, 25441, 28514, 20322, 26975, 25446, 36201, 3435, 30060, 24949, 34687, 26495, 31108, 4486, 15241, 21386, 31114, 32141, 35727, 22933, 15254, 34210, 15266, 15783, 15784, 12203, 18347, 18350, 15792, 12209, 15281, 34228, 15290, 3002, 2494, 14271, 13255, 21963, 27096, 15322, 3039, 14819, 22001, 31733}\n",
      "dict_items([(\"Lemma('case.n.08.case')\", 2), (\"Lemma('case.n.01.case')\", 17), (\"Lemma('case.n.04.case')\", 7), (\"Lemma('event.n.02.case')\", 16), (\"Lemma('lawsuit.n.01.case')\", 7), (\"Lemma('case.n.09.case')\", 1), (\"Lemma('case.n.06.case')\", 2), (\"Lemma('case.n.05.case')\", 2)])\n",
      "collecting tokens for  nothing\n",
      "indices:    {34385}\n",
      "dict_items([])\n",
      "collecting tokens for  bad\n",
      "indices:    {13321, 14349, 19482, 18468, 30757, 25641, 25644, 20016, 21071, 33368, 13920, 3169, 16486, 22633, 30315, 8309, 20094, 24212, 20118, 7326, 34989, 8877, 27315, 23734, 8895, 5317, 25801, 4819, 4829, 9953, 4834, 4836, 4838, 15590, 4840, 4845, 4846, 4847, 1265, 4854, 16633, 4857, 17658, 4860, 27391, 4865, 35074, 19716, 18694, 30985, 4875, 19725, 24848, 18705, 26385, 5915, 31008, 4896, 4901, 34601, 12080, 30002, 33586, 5941, 7993, 25410, 9034, 5986, 34166, 34167, 13688, 2423, 9091, 6532, 9096, 11148, 9103, 6559, 6562, 20416, 27078, 27081, 33744, 7633, 27089, 5076, 17372, 19421, 7142, 27128}\n",
      "dict_items([(\"Lemma('bad.a.01.bad')\", 26), (\"Lemma('bad.n.01.bad')\", 2), (\"Lemma('badly.r.06.bad')\", 1), (\"Lemma('bad.s.04.bad')\", 1)])\n",
      "collecting tokens for  occurred\n",
      "indices:    {15232, 21639, 3336, 21512, 3339, 25875, 5537, 16421, 31274, 21681, 14770, 14769, 15413, 33205, 10874, 21176, 6969, 17210, 34750, 3904, 3905, 34889, 2123, 6092, 12749, 31184, 2132, 5594, 15835, 33761, 12769, 4962, 4836, 17254, 12390, 33384, 33257, 4858, 4843, 24811, 4847, 24436, 21364, 11509, 2934, 4857, 2298, 4859}\n",
      "dict_items([(\"Lemma('happen.v.01.occur')\", 26), (\"Lemma('occur.v.02.occur')\", 11)])\n",
      "collecting tokens for  sense\n",
      "indices:    {36362, 16395, 15885, 31760, 26132, 32790, 2070, 26648, 4633, 28694, 6687, 16426, 34348, 14382, 559, 15409, 24115, 4669, 4670, 33854, 27718, 2630, 34888, 1097, 27211, 26187, 24653, 24652, 26197, 27737, 5216, 10850, 34404, 32871, 17009, 12914, 36979, 3699, 12919, 5240, 13433, 5241, 12923, 31868, 9341, 12926, 27771, 22655, 12924, 2696, 27788, 14989, 27790, 12431, 26258, 22677, 5269, 27800, 13464, 5275, 31902, 22687, 22689, 28322, 7330, 22690, 26786, 36519, 13484, 27823, 27316, 26295, 4280, 27321, 27840, 27329, 14533, 22726, 22727, 2248, 22728, 26315, 27342, 26323, 26328, 14552, 25821, 25309, 23779, 1768, 14569, 4840, 4843, 25834, 4854, 26361, 1280, 4865, 27908, 14597, 14598, 14599, 23816, 14602, 14604, 22284, 4879, 14609, 23830, 16663, 14616, 23834, 6945, 32546, 32547, 26403, 14633, 14634, 4905, 4908, 4909, 4910, 1327, 4913, 32051, 13620, 4917, 20792, 12601, 4922, 4923, 14143, 4928, 4929, 4930, 4931, 12101, 26951, 20302, 19281, 13650, 13653, 28502, 13660, 8542, 4958, 13664, 17761, 26975, 16228, 13671, 13672, 13674, 4971, 31085, 32115, 26486, 13177, 29050, 24443, 893, 14206, 4483, 15754, 13195, 13197, 34193, 34194, 5014, 5020, 24989, 5022, 26529, 9636, 16808, 34729, 34730, 1451, 15787, 26031, 15279, 1460, 9144, 13753, 23993, 12219, 26557, 16835, 24520, 25544, 9679, 20952, 11228, 13277, 26077, 4576, 4577, 32228, 13286, 13291, 15851, 1011, 27645}\n",
      "dict_items([(\"Lemma('sense.n.01.sense')\", 26), (\"Lemma('sense.n.02.sense')\", 21), (\"Lemma('sense.n.05.sense')\", 1), (\"Lemma('sense.n.03.sense')\", 4), (\"Lemma('feel.v.03.sense')\", 7), (\"Lemma('common_sense.n.01.sense')\", 4)])\n",
      "collecting tokens for  reason\n",
      "indices:    {17929, 8336, 35992, 13468, 26908, 29983, 11295, 13894, 36052, 22614, 27999, 5985, 36579, 8035, 17644, 15342, 9455, 4220, 5363, 27126, 1916}\n",
      "dict_items([(\"Lemma('argue.v.01.reason')\", 1), (\"Lemma('reason.n.01.reason')\", 7), (\"Lemma('reason.n.02.reason')\", 4), (\"Lemma('reason.v.03.reason')\", 1)])\n",
      "collecting tokens for  says\n",
      "indices:    {6023, 12940, 5367, 21070, 31056, 30420, 18875, 27095, 24603, 27198}\n",
      "dict_items([(\"Lemma('state.v.01.say')\", 8), (\"Lemma('allege.v.01.say')\", 2)])\n",
      "collecting tokens for  density\n",
      "indices:    {3359, 3361, 29858, 5415, 3368, 2993, 3380, 24888, 2875, 24895, 3139, 3140, 26823, 36044, 23511, 14830, 5360, 12272, 3070}\n",
      "dict_items([(\"Lemma('density.n.01.density')\", 10), (\"Lemma('concentration.n.02.density')\", 2)])\n",
      "collecting tokens for  universe\n",
      "indices:    {5024, 28167, 20041, 31511, 28121, 26815}\n",
      "dict_items([(\"Lemma('universe.n.01.universe')\", 2)])\n",
      "collecting tokens for  directions\n",
      "indices:    {3019, 1644, 29675, 27549, 33821}\n",
      "dict_items([(\"Lemma('direction.n.02.direction')\", 1), (\"Lemma('direction.n.06.direction')\", 1)])\n",
      "collecting tokens for  debate\n",
      "indices:    {14359}\n",
      "dict_items([(\"Lemma('argument.n.03.debate')\", 1)])\n",
      "collecting tokens for  rid\n",
      "indices:    {24000, 10946, 17955, 7046, 25754, 28040, 21705, 18736, 36560, 23154, 21905, 34933, 16504, 14361, 34170}\n",
      "dict_items([(\"Lemma('rid.v.01.rid')\", 3)])\n",
      "collecting tokens for  payne\n",
      "indices:    {17228}\n",
      "dict_items([(\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  castro\n",
      "indices:    {28395}\n",
      "dict_items([])\n",
      "collecting tokens for  republican\n",
      "indices:    {24831}\n",
      "dict_items([])\n",
      "collecting tokens for  election\n",
      "indices:    {12620, 20399, 81, 11282, 25019, 12671}\n",
      "dict_items([(\"Lemma('election.n.01.election')\", 2), (\"Lemma('election.n.02.election')\", 1)])\n",
      "collecting tokens for  religious\n",
      "indices:    {5250, 5252, 12306, 25110, 19607, 5016, 1436, 22685, 22687, 12324, 31529, 13618, 32052, 13494, 13496, 4665, 4668, 4674, 22727, 4687, 4692, 1365, 22363, 4706, 14690, 11495, 4727, 31721, 28265, 27886, 20335, 1397, 11894, 27767, 27768, 26102}\n",
      "dict_items([(\"Lemma('religious.s.01.religious')\", 4)])\n",
      "collecting tokens for  issue\n",
      "indices:    {4608, 32769, 15368, 5129, 17931, 25611, 23583, 22047, 12323, 26150, 23590, 23592, 55, 56, 57, 58, 61, 24159, 12399, 24697, 27259, 22662, 28300, 20626, 4760, 29852, 20637, 20636, 22709, 27321, 16076, 17111, 31964, 27871, 27872, 23780, 31989, 23286, 23288, 25343, 25856, 32000, 27909, 32013, 23309, 29464, 21791, 21801, 21802, 24880, 21812, 21815, 25911, 25401, 25403, 15679, 21825, 20805, 23878, 25929, 30026, 1358, 24410, 14171, 22887, 25965, 1405, 20366, 14735, 14747, 28063, 23972, 20388, 20395, 11182, 20399, 435, 12212, 20412, 2519, 12766, 12259, 12263, 20462, 5110, 32759, 32758, 32761, 32762, 32763, 32764, 34303}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('issue.n.01.issue')\", 15), (\"Lemma('issue.v.02.issue')\", 2), (\"Lemma('write_out.v.02.issue')\", 1), (\"Lemma('issue.n.02.issue')\", 2), (\"Lemma('issue.v.03.issue')\", 1), (\"Lemma('publish.v.02.issue')\", 5), (\"Lemma('issue.n.04.issue')\", 1)])\n",
      "collecting tokens for  idea\n",
      "indices:    {25088, 33793, 10250, 6155, 7693, 26647, 6172, 18472, 15417, 25148, 27199, 19542, 27227, 21083, 6238, 5237, 12409, 15995, 34947, 20109, 12945, 17554, 17046, 33946, 28326, 26790, 14000, 16063, 26819, 23747, 23751, 7368, 14023, 26827, 4300, 25294, 28380, 36599, 22267, 7419, 11012, 27919, 14608, 14609, 20244, 14100, 14613, 14103, 24865, 10023, 26414, 9527, 17729, 14666, 25930, 14668, 14669, 14671, 14673, 36178, 14681, 30042, 17754, 30567, 30060, 14704, 22394, 9610, 19341, 2448, 9617, 17812, 18838, 27550, 36264, 23467, 14255, 20912, 14258, 14272, 14275, 31177, 33226, 26572, 12241, 28116, 1495, 36312, 1497, 31195, 20956, 13279, 14303, 28129, 1513, 31213, 24051, 28151}\n",
      "dict_items([(\"Lemma('idea.n.01.idea')\", 26), (\"Lemma('idea.n.03.idea')\", 1), (\"Lemma('mind.n.06.idea')\", 3)])\n",
      "collecting tokens for  unhappy\n",
      "indices:    {7360, 36262, 13515, 24014, 26194, 5971, 12690, 30546, 4886, 20409, 25755, 26397, 19486}\n",
      "dict_items([(\"Lemma('unhappy.a.01.unhappy')\", 5), (\"Lemma('dysphoric.a.01.unhappy')\", 1)])\n",
      "collecting tokens for  sweet\n",
      "indices:    {4192, 26979, 4164, 4198, 26631, 6794, 29387, 5963, 13549, 7343, 18874, 7155, 14643, 12538, 1692, 4125, 5151}\n",
      "dict_items([(\"Lemma('angelic.s.03.sweet')\", 1), (\"Lemma('odoriferous.s.03.sweet')\", 1)])\n",
      "collecting tokens for  fourteen\n",
      "indices:    {22995, 21375}\n",
      "dict_items([])\n",
      "collecting tokens for  middle\n",
      "indices:    {9186, 19525, 22667, 16593, 186, 3868, 7549}\n",
      "dict_items([(\"Lemma('middle.n.03.middle')\", 1), (\"Lemma('center.n.01.middle')\", 3), (\"Lemma('in-between.s.01.middle')\", 1)])\n",
      "collecting tokens for  west\n",
      "indices:    {26945, 2423}\n",
      "dict_items([(\"Lemma('west.n.03.West')\", 1)])\n",
      "collecting tokens for  observed\n",
      "indices:    {14848, 11265, 2817, 16387, 1418, 2827, 13206, 11286, 4120, 2841, 4249, 25243, 33182, 36383, 3233, 3364, 1317, 18605, 29999, 2101, 4279, 13368, 2105, 23622, 3659, 3276, 12753, 3283, 10841, 24314, 16091, 3292, 2140, 11485, 3296, 14817, 26467, 3301, 26599, 5992, 13161, 6891, 3947, 2798, 2799, 2801, 2802, 12531, 24052, 4341, 32630, 13178, 2814, 2815}\n",
      "dict_items([(\"Lemma('detect.v.01.observe')\", 26), (\"Lemma('note.v.01.observe')\", 9), (\"Lemma('note.v.03.observe')\", 4), (\"Lemma('respect.v.02.observe')\", 2), (\"Lemma('ascertained.s.01.observed')\", 5), (\"Lemma('observe.v.04.observe')\", 2), (\"Lemma('observe.v.06.observe')\", 2)])\n",
      "collecting tokens for  community\n",
      "indices:    {1283, 22700, 174, 22293, 20343, 4604, 2749}\n",
      "dict_items([(\"Lemma('community.n.01.community')\", 3)])\n",
      "collecting tokens for  religion\n",
      "indices:    {4675, 13156, 23542}\n",
      "dict_items([(\"Lemma('religion.n.01.religion')\", 1), (\"Lemma('religion.n.02.religion')\", 1)])\n",
      "collecting tokens for  activities\n",
      "indices:    {23557, 32134, 32655, 14224, 14748, 27550, 28703, 2597, 31530, 31532, 13359, 13360, 32182, 21570, 23366, 4813, 12767, 3582, 11880, 25833, 8299, 32495, 32499, 37112, 32507, 22782}\n",
      "dict_items([(\"Lemma('action.n.02.activity')\", 3), (\"Lemma('activity.n.01.activity')\", 6)])\n",
      "collecting tokens for  jews\n",
      "indices:    {13182}\n",
      "dict_items([(\"Lemma('jew.n.01.Jew')\", 1)])\n",
      "collecting tokens for  regard\n",
      "indices:    {14208, 12290, 14595, 11143, 32524, 5261, 12301, 4367, 16400, 25488, 30227, 15380, 23828, 20247, 9369, 32154, 13341, 32925, 28703, 27810, 16420, 15657, 27308, 4911, 32687, 16051, 1459, 13622, 4919, 13624, 12217, 34359, 14144, 21441, 14410, 23244, 2638, 13262, 16463, 11986, 12245, 36310, 24151, 22870, 33498, 11869, 4958, 3807, 32992, 31843, 15846, 13161, 25841, 2673, 15860, 3830, 16374, 27260, 13181, 10622}\n",
      "dict_items([(\"Lemma('respect.n.01.regard')\", 4), (\"Lemma('see.v.05.regard')\", 13), (\"Lemma('attentiveness.n.01.regard')\", 1), (\"Lemma('think_of.v.03.regard_as')\", 2), (\"Lemma('gaze.n.01.regard')\", 1), (\"Lemma('involve.v.01.regard')\", 1), (\"Lemma('regard.v.02.regard')\", 1)])\n",
      "collecting tokens for  stronger\n",
      "indices:    {22662, 16012, 12052, 33172, 17559, 16027, 16030, 1056, 16040, 26154, 16945, 23091, 5689, 4032, 24514, 21706, 20819, 2399, 5728, 14433, 11500, 11506, 5752, 5630}\n",
      "dict_items([(\"Lemma('strong.a.01.strong')\", 9), (\"Lemma('strong.s.02.strong')\", 2), (\"Lemma('strongly.r.01.strongly')\", 1), (\"Lemma('potent.s.02.strong')\", 1)])\n",
      "collecting tokens for  rose\n",
      "indices:    {35248, 33641, 34284}\n",
      "dict_items([(\"Lemma('rise.v.01.rise')\", 1)])\n",
      "collecting tokens for  gm.\n",
      "indices:    {4032, 4035, 4071, 4076, 4080, 4094, 4026, 4061, 4030}\n",
      "dict_items([(\"Lemma('gram.n.01.gm')\", 9)])\n",
      "collecting tokens for  oct.\n",
      "indices:    {21937}\n",
      "dict_items([])\n",
      "collecting tokens for  complained\n",
      "indices:    {4032, 36864, 5082, 5283, 7619, 12676, 29224, 105, 29225, 21195, 21611, 14457, 9466, 9211, 11997, 22558}\n",
      "dict_items([(\"Lemma('complain.v.01.complain')\", 16)])\n",
      "collecting tokens for  knees\n",
      "indices:    {27267, 2698, 31498, 34067, 34070, 13593, 34978, 33827, 22436, 35636, 6328, 1979, 17086, 4032, 7109, 18891, 19664, 8528, 36051, 2004, 2015, 18913, 2020, 12646, 35438, 9460, 29175, 34172}\n",
      "dict_items([(\"Lemma('knee.n.01.knee')\", 13), (\"Lemma('stifle.n.01.knee')\", 2), (\"Lemma('knee.n.03.knee')\", 1)])\n",
      "collecting tokens for  older\n",
      "indices:    {11265, 9602, 11779, 11781, 9222, 8840, 11666, 8852, 28055, 9628, 16414, 30752, 33954, 13219, 11431, 3376, 4784, 4018, 15540, 16437, 10167, 17721, 8889, 31803, 24764, 5953, 27332, 34374, 10566, 20040, 20043, 20045, 2510, 16461, 3406, 9169, 13778, 846, 32982, 35929, 18009, 9308, 19552, 23520, 30305, 1507, 28000, 24547, 16230, 24551, 21989, 30827, 109, 13165, 28017, 2289, 13171, 28020, 14454}\n",
      "dict_items([(\"Lemma('aged.s.01.older')\", 11), (\"Lemma('old.a.02.old')\", 9), (\"Lemma('old.a.01.old')\", 16), (\"Lemma('elder.s.01.older')\", 2)])\n",
      "collecting tokens for  slowly\n",
      "indices:    {13568, 35203, 4996, 27043, 33955, 34085, 1062, 33580, 19884, 1970, 35636, 19637, 8504, 3260, 5963, 332, 9425, 30420, 35161, 29534, 4966, 8427, 22131, 34169, 19967}\n",
      "dict_items([(\"Lemma('slowly.r.01.slowly')\", 14)])\n",
      "collecting tokens for  handle\n",
      "indices:    {21989, 16075, 5515, 29645, 29646, 28717, 29647, 29651, 24244, 19511}\n",
      "dict_items([(\"Lemma('manage.v.02.handle')\", 5)])\n",
      "collecting tokens for  meat\n",
      "indices:    {30476, 29458, 30496, 25001, 29482, 25002, 25005, 25013, 25014, 27191, 24245, 27194, 9674, 29521, 5986, 29411, 22117, 29414, 29418, 29422, 26863, 29425, 12532, 29432, 29434}\n",
      "dict_items([(\"Lemma('meat.n.01.meat')\", 2)])\n",
      "collecting tokens for  potatoes\n",
      "indices:    {22117, 23372, 26863, 29425, 30425, 30422, 29432, 24249, 36990, 29471}\n",
      "dict_items([])\n",
      "collecting tokens for  corn\n",
      "indices:    {21826, 19490, 27013, 21989, 22795, 29425, 3027, 11572, 7733, 30424, 22009, 9146}\n",
      "dict_items([(\"Lemma('corn.n.03.corn')\", 1), (\"Lemma('corn.n.02.corn')\", 1), (\"Lemma('corn.n.01.corn')\", 1)])\n",
      "collecting tokens for  foil\n",
      "indices:    {30359, 14786, 30199, 21935}\n",
      "dict_items([(\"Lemma('thwart.v.01.foil')\", 1), (\"Lemma('foil.n.01.foil')\", 1)])\n",
      "collecting tokens for  hand\n",
      "indices:    {35681, 18785, 3875, 8131, 5963, 11692, 34061, 7184, 32146, 35987, 29267, 14292, 34911}\n",
      "dict_items([(\"Lemma('hand.n.08.hand')\", 1), (\"Lemma('hand.n.01.hand')\", 3)])\n",
      "collecting tokens for  b-52\n",
      "indices:    {15539}\n",
      "dict_items([(\"Lemma('b-52.n.01.B-52')\", 1)])\n",
      "collecting tokens for  crew\n",
      "indices:    {19332, 31365, 18694, 23304, 29832, 34952, 30344, 10260, 23321, 10266, 12441, 25369, 19357, 23328, 12450, 21670, 30375, 21671, 18861, 12334, 7344, 23348, 12362, 18004, 5845, 12376, 12377, 12378, 12396, 12397, 12407, 34427, 12413, 8062}\n",
      "dict_items([(\"Lemma('crew.n.01.crew')\", 15), (\"Lemma('gang.n.03.crew')\", 4)])\n",
      "collecting tokens for  required\n",
      "indices:    {25095, 15879, 15884, 14861, 16399, 23573, 15896, 29728, 14884, 15909, 14895, 2607, 28724, 36917, 15931, 3136, 30273, 16452, 31306, 15950, 15442, 15955, 15962, 15458, 28775, 2155, 9326, 5742, 2168, 3705, 11386, 3707, 15484, 31365, 29842, 3732, 153, 2714, 2201, 158, 20643, 13992, 23215, 25263, 29871, 3257, 15552, 30407, 15052, 2764, 15571, 21204, 29921, 2785, 3816, 25833, 3311, 15113, 13069, 15630, 15640, 1831, 14633, 2898, 32596, 2904, 32614, 15718, 2922, 1899, 13162, 29550, 22899, 10100, 22900, 25465, 32123, 26493, 5507, 5508, 20375, 14748, 21920, 31138, 16292, 15269, 15270, 15275, 25005, 34733, 21424, 32177, 26041, 34751, 28608, 32193, 14793, 5585, 986, 13275, 11231, 29670, 32748, 4592, 15356}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('needed.s.01.required')\", 13), (\"Lemma('necessitate.v.01.require')\", 26), (\"Lemma('ask.v.04.require')\", 6), (\"Lemma('command.v.02.require')\", 8), (\"Lemma('compulsory.s.01.required')\", 1), (\"Lemma('want.v.02.require')\", 1)])\n",
      "collecting tokens for  copy\n",
      "indices:    {8448, 26754, 34692, 31365, 34714, 34715, 20909, 26171, 13628, 15294, 17343, 36951, 1755, 16865, 15330, 484, 26724, 20330, 32492, 25968, 25970, 1782, 32759, 31736}\n",
      "dict_items([(\"Lemma('copy.n.02.copy')\", 4), (\"Lemma('copy.v.01.copy')\", 2), (\"Lemma('transcript.n.02.copy')\", 3), (\"Lemma('copy.n.03.copy')\", 1)])\n",
      "collecting tokens for  message\n",
      "indices:    {23300, 32005, 24327, 9869, 5136, 12690, 23315, 5151, 1321, 13995, 12205, 12845, 23291, 14027, 27746, 14051, 36199, 17513, 20219, 20220, 31101, 31103}\n",
      "dict_items([(\"Lemma('message.n.01.message')\", 8), (\"Lemma('message.n.02.message')\", 3)])\n",
      "collecting tokens for  pull\n",
      "indices:    {6018, 1544, 25738, 24458, 29068, 24462, 1551, 12816, 1553, 2962, 8590, 10388, 20630, 9367, 26521, 29466, 8094, 17440, 5795, 33575, 33586, 7611, 27330, 33986, 19273, 24653, 5967, 18640, 18386, 34652, 12644, 17006, 8559, 13559, 20349}\n",
      "dict_items([(\"Lemma('attract.v.01.pull')\", 2), (\"Lemma('draw_up.v.02.pull_up')\", 1), (\"Lemma('pull.n.01.pull')\", 4), (\"Lemma('pull.v.01.pull')\", 8), (\"Lemma('pull.v.03.pull')\", 3), (\"Lemma('pull.n.02.pull')\", 2), (\"Lemma('pull_the_leg_of.v.01.pull_the_leg_of')\", 1), (\"Lemma('pull.n.03.pull')\", 1), (\"Lemma('perpetrate.v.01.pull')\", 1), (\"Lemma('draw.v.05.pull')\", 1)])\n",
      "collecting tokens for  curves\n",
      "indices:    {32800, 32801, 4510, 3868, 4486, 4521, 4533, 4501, 25302, 31510, 32793, 32799, 32798, 4543}\n",
      "dict_items([(\"Lemma('curve.n.01.curve')\", 6), (\"Lemma('curve.n.02.curve')\", 1)])\n",
      "collecting tokens for  c\n",
      "indices:    {4524}\n",
      "dict_items([])\n",
      "collecting tokens for  **f\n",
      "indices:    {3072, 3073, 3075, 3078, 3082, 3084, 3085, 3088, 3092, 3095, 3096, 3097, 3098, 3101, 3103, 3105, 3107, 3109, 3112, 3115, 3119, 3120, 3126, 3127, 3128, 3136, 3139, 3140, 3145, 2849, 2864, 2873, 2902, 2927, 2928, 2935, 2939, 2940, 2941, 2943, 2944, 4481, 4484, 2949, 4485, 4488, 4490, 4491, 4492, 2957, 4494, 2955, 2954, 4499, 4500, 4501, 4503, 4505, 4506, 4508, 4509, 4511, 4512, 4517, 4518, 4519, 4520, 4524, 4525, 4527, 4528, 4529, 4530, 4533, 4535, 4536, 4537, 4538, 4540, 4542, 4547, 4553, 4554, 4556, 4563, 4564, 4565, 4566, 4567, 4568, 4571, 4572, 4573, 3042, 3043, 3044, 3045, 3046, 3047, 3048, 3051, 3054, 3055, 3058, 3059, 3060, 3061, 3062, 3063, 3064, 3065, 3066, 3067, 3068, 3069, 3070}\n",
      "dict_items([])\n",
      "collecting tokens for  coincide\n",
      "indices:    {25748, 4501, 37143, 3896, 32793, 5404}\n",
      "dict_items([(\"Lemma('coincide.v.01.coincide')\", 4), (\"Lemma('concur.v.02.coincide')\", 1), (\"Lemma('coincide.v.03.coincide')\", 1)])\n",
      "collecting tokens for  finite\n",
      "indices:    {4354, 37060, 27717, 4548, 4296, 4520, 4362, 4523, 4497, 4337, 4501, 4280, 4507}\n",
      "dict_items([(\"Lemma('finite.a.01.finite')\", 11)])\n",
      "collecting tokens for  otherwise\n",
      "indices:    {27392, 29890, 5794, 33117}\n",
      "dict_items([])\n",
      "collecting tokens for  analytic\n",
      "indices:    {4481, 4482, 31908, 4519, 16071, 4521, 4522, 4523, 4526, 4501, 4533, 16088, 4537, 16061}\n",
      "dict_items([(\"Lemma('analytic.a.01.analytic')\", 10), (\"Lemma('analytic.a.02.analytic')\", 3)])\n",
      "collecting tokens for  impossible\n",
      "indices:    {29105, 17458, 28003, 32780}\n",
      "dict_items([(\"Lemma('impossible.s.02.impossible')\", 1)])\n",
      "collecting tokens for  spite\n",
      "indices:    {1281, 6787, 3716, 8200, 29960, 27530, 20105, 3593, 33038, 13969, 9243, 28063, 6822, 37158, 7721, 30257, 7859, 14012, 36029, 2116, 4179, 4051, 15704, 27353, 30689, 29924, 9445, 1382, 33257, 25835, 13292, 24172, 28532, 2805, 2550, 25855}\n",
      "dict_items([(\"Lemma('malice.n.01.spite')\", 1)])\n",
      "collecting tokens for  31\n",
      "indices:    {32386, 32389, 32391, 32533, 14870, 32536, 32537, 28827, 32540, 32541, 20767, 25765, 26790, 5287, 32697, 15547, 32702, 15552, 15553, 28992, 64, 20168, 3920, 21456, 23122, 3926, 3800, 21337, 23645, 94, 24035, 29034, 25835, 32748, 23406, 25846, 27511}\n",
      "dict_items([])\n",
      "collecting tokens for  professor\n",
      "indices:    {27818, 30979, 1557}\n",
      "dict_items([(\"Lemma('professor.n.01.professor')\", 1)])\n",
      "collecting tokens for  recalled\n",
      "indices:    {7040, 641, 8866, 5347, 25348, 11207, 31657, 25835, 22125, 25517, 26576, 1362, 21716, 6813}\n",
      "dict_items([(\"Lemma('remember.v.01.recall')\", 12), (\"Lemma('recall.v.04.recall')\", 1), (\"Lemma('hark_back.v.01.recall')\", 1)])\n",
      "collecting tokens for  direction\n",
      "indices:    {20685, 4498, 33011, 4499, 15704, 31386, 1179, 36060}\n",
      "dict_items([(\"Lemma('direction.n.03.direction')\", 2), (\"Lemma('guidance.n.01.direction')\", 1), (\"Lemma('management.n.01.direction')\", 1)])\n",
      "collecting tokens for  november\n",
      "indices:    {5169}\n",
      "dict_items([(\"Lemma('november.n.01.November')\", 1)])\n",
      "collecting tokens for  25\n",
      "indices:    {29696, 29706, 14893, 12854, 21563, 27203, 12870, 25688, 25690, 21083, 21085, 605, 26731, 21611, 29295, 12913, 14966, 11385, 21631, 14978, 3725, 2715, 2717, 3758, 3254, 2749, 2750, 28875, 15052, 2769, 32474, 2781, 2782, 3812, 2792, 25835, 15598, 764, 11522, 23301, 15116, 28952, 29467, 1820, 21794, 25890, 11556, 16167, 3367, 24882, 25414, 20295, 31048, 20808, 21323, 3920, 1366, 27481, 32608, 32610, 11620, 29039, 29040, 26993, 22903, 21375, 27010, 22406, 15248, 27025, 15257, 21918, 928, 929, 30113, 21415, 12713, 13227, 430, 22961, 22962, 437, 9655, 24504, 20924, 27072, 25027, 30156, 32722, 14813, 24029, 15328, 14825, 23026, 22005, 22524, 26110}\n",
      "dict_items([(\"Lemma('twenty-five.s.01.25')\", 26), (\"Lemma('twenty-five.n.01.25')\", 3), (\"Lemma('twenty-fifth.s.01.twenty-fifth')\", 2)])\n",
      "collecting tokens for  th\n",
      "indices:    {11265, 21507, 12805, 12808, 28171, 12813, 22541, 22545, 16404, 25115, 12833, 25123, 12836, 12837, 24617, 21548, 22070, 12854, 12856, 25659, 30269, 12867, 11335, 21583, 29265, 13912, 14940, 30300, 25695, 29280, 13922, 12910, 29322, 28300, 24720, 14995, 14998, 21503, 15003, 24734, 22179, 22197, 15548, 20161, 15555, 15559, 15560, 15561, 20168, 20169, 15567, 26845, 32481, 25835, 12527, 12028, 29963, 29984, 13091, 12580, 28971, 22850, 21829, 21319, 12619, 20819, 22359, 22886, 22383, 28528, 32627, 32630, 28542, 22911, 22912, 32641, 22914, 32640, 22910, 32649, 22410, 22412, 32656, 32657, 32658, 22930, 32664, 32665, 27038, 28574, 27041, 22956, 22958, 22959, 11182, 22961, 28591, 11189, 22973, 22975, 26560, 22977, 22978, 22982, 26567, 22985, 26570, 22987, 26569, 22489, 11257, 11263}\n",
      "dict_items([])\n",
      "collecting tokens for  fort\n",
      "indices:    {12499}\n",
      "dict_items([])\n",
      "collecting tokens for  massachusetts\n",
      "indices:    {164}\n",
      "dict_items([])\n",
      "collecting tokens for  twelve\n",
      "indices:    {24198, 32393, 33132, 13395, 20532, 32853, 33396}\n",
      "dict_items([(\"Lemma('twelve.s.01.twelve')\", 1)])\n",
      "collecting tokens for  months\n",
      "indices:    {520, 33300, 31260, 15393, 22062, 23605, 21560, 34874, 24127, 11870, 15477, 27767, 3709, 30849, 24198, 32393, 5774, 2192, 20134, 20654, 21172, 34487, 30398, 16598, 10977, 36068, 21230, 23801, 20751, 24848, 20244, 20761, 20763, 37150, 8483, 20772, 20261, 21814, 21817, 31039, 17219, 10566, 3917, 3919, 27986, 3923, 854, 22364, 12642, 34665, 24429, 20847, 24432, 23409, 25462, 23415, 23416, 23418, 15750, 9607, 23432, 24461, 26517, 12696, 1434, 12188, 34732, 6573, 5553, 32179, 8641, 15306, 21455, 22992, 10207, 12256, 15844, 15848, 15850, 34292, 11775}\n",
      "dict_items([(\"Lemma('calendar_month.n.01.month')\", 18), (\"Lemma('month.n.02.month')\", 15)])\n",
      "collecting tokens for  active\n",
      "indices:    {9668, 21927, 25833, 1258, 15466, 3179, 15465, 15470, 15409, 3219, 15476, 28565, 15480, 25627, 32863}\n",
      "dict_items([(\"Lemma('active_agent.n.01.active')\", 2), (\"Lemma('active.s.02.active')\", 5), (\"Lemma('active.a.01.active')\", 1), (\"Lemma('active.a.07.active')\", 1), (\"Lemma('active.a.03.active')\", 1)])\n",
      "collecting tokens for  equivalent\n",
      "indices:    {15884, 28949, 16405, 3864, 16026, 16027, 2075, 5533, 16158, 11550, 16033, 16034, 11046, 16039, 16040, 16043, 1725, 25414, 15686, 26569, 15691, 22747, 2143, 24291, 23396, 36330, 25835, 28906}\n",
      "dict_items([(\"Lemma('equivalent.n.01.equivalent')\", 11)])\n",
      "collecting tokens for  wherever\n",
      "indices:    {32384, 6401, 11095, 11442, 35125, 20247, 9209, 6938}\n",
      "dict_items([])\n",
      "collecting tokens for  military\n",
      "indices:    {25128, 3476}\n",
      "dict_items([(\"Lemma('military.a.02.military')\", 1)])\n",
      "collecting tokens for  pay\n",
      "indices:    {15617, 130, 18437, 23435, 23823, 35087, 21780, 19736, 24220, 25253, 32679, 9266, 16307, 14518, 22781, 13754, 11836, 11838, 12607, 15552, 15554, 27202, 11845, 20172, 25805, 25038, 27343, 20216, 35025, 20186, 989, 23392, 28010, 20203, 12140, 20204, 16241, 21495, 15476, 15477, 28662, 15478, 15480, 30845, 25214}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('pay.v.01.pay')\", 24), (\"Lemma('give.v.05.pay')\", 4), (\"Lemma('wage.n.01.pay')\", 5), (\"Lemma('yield.v.10.pay')\", 1), (\"Lemma('pay.v.05.pay')\", 2), (\"Lemma('pay_up.v.01.pay')\", 1)])\n",
      "collecting tokens for  formula\n",
      "indices:    {28928, 28929, 29186, 28935, 28937, 28938, 14091, 33164, 908, 28942, 32786, 28950, 28951, 20256, 15905, 4398, 4399, 28854, 440, 28857, 28856, 16190, 575, 24645, 19142, 15047, 32585, 3024, 20561, 20564, 3030, 19032, 28891, 20188, 28895, 28902, 28905, 28908, 32622, 28914, 4469, 28919, 15481, 3070}\n",
      "dict_items([(\"Lemma('recipe.n.01.formula')\", 4), (\"Lemma('formula.n.01.formula')\", 7), (\"Lemma('formula.n.03.formula')\", 3), (\"Lemma('formula.n.04.formula')\", 1)])\n",
      "collecting tokens for  providing\n",
      "indices:    {24546, 24547, 25289, 25140, 32151, 11640, 11257, 15003}\n",
      "dict_items([(\"Lemma('supply.v.01.provide')\", 7)])\n",
      "collecting tokens for  retired\n",
      "indices:    {15478}\n",
      "dict_items([(\"Lemma('retired.s.01.retired')\", 1)])\n",
      "collecting tokens for  prior\n",
      "indices:    {21698}\n",
      "dict_items([])\n",
      "collecting tokens for  effective\n",
      "indices:    {16384, 4609, 23553, 4617, 2569, 11, 2586, 12314, 12318, 4643, 1574, 27691, 2605, 1583, 32845, 24147, 26198, 14941, 11873, 3177, 15477, 15481, 11389, 12418, 2180, 11396, 32903, 28301, 15517, 21153, 4771, 4781, 4788, 27833, 32958, 32460, 27864, 18658, 5358, 15089, 1785, 22785, 22786, 22791, 15111, 25355, 28945, 22811, 799, 20262, 14121, 20782, 25902, 21809, 28481, 25925, 3399, 22867, 2389, 12644, 22378, 1391, 3958, 32130, 18308, 32647, 26505, 3467, 32142, 25492, 26005, 16278, 11670, 14748, 20384, 21926, 14760, 14764, 12221, 21441, 12226, 11720, 11722, 33227, 32214, 27608, 16346, 16349, 27618, 11235, 30180, 4591, 4592}\n",
      "dict_items([(\"Lemma('effective.s.02.effective')\", 13), (\"Lemma('effective.a.01.effective')\", 26), (\"Lemma('effective.s.04.effective')\", 4), (\"Lemma('effective.s.05.effective')\", 1), (\"Lemma('effective.s.03.effective')\", 6)])\n",
      "collecting tokens for  june\n",
      "indices:    {14484}\n",
      "dict_items([])\n",
      "collecting tokens for  looking\n",
      "indices:    {7184, 36083, 18595}\n",
      "dict_items([(\"Lemma('look.v.01.look')\", 1)])\n",
      "collecting tokens for  enjoyed\n",
      "indices:    {9478, 14477, 14478, 13582, 34703, 8334, 13075, 12563, 24344, 34202, 36522, 36267, 26027, 21933, 9390, 34734, 14515, 12980, 13113, 25027, 25287, 22860, 2384, 30930, 1236, 23902, 9185, 13797, 36327, 31720, 34665, 11885, 14446, 27888, 21234, 36341, 21494, 12917, 22521, 9084}\n",
      "dict_items([(\"Lemma('enjoy.v.04.enjoy')\", 6), (\"Lemma('enjoy.v.02.enjoy')\", 8), (\"Lemma('enjoy.v.01.enjoy')\", 19), (\"Lemma('love.v.02.enjoy')\", 5), (\"Lemma('delight.v.02.enjoy')\", 1)])\n",
      "collecting tokens for  assemble\n",
      "indices:    {20322, 27267, 29602, 28842, 14735, 3599, 4751, 29596}\n",
      "dict_items([(\"Lemma('assemble.v.01.assemble')\", 4), (\"Lemma('meet.v.07.assemble')\", 4)])\n",
      "collecting tokens for  frame\n",
      "indices:    {21244, 28805, 28806, 7437, 7438, 28815, 31122, 20243, 10901, 29720, 28825, 25626, 22557, 7461, 29861, 28842, 29738, 18862, 28719, 36272, 28718, 25650, 9523, 35449, 33083, 33084, 1472, 35393, 27074, 31557, 12616, 35403, 28752, 26448, 28754, 28755, 28756, 1624, 28770, 29795, 29801, 2409, 28780, 28786, 28787, 28789, 1655, 28793, 1659, 28796, 28797, 1534, 35967}\n",
      "dict_items([(\"Lemma('human_body.n.01.frame')\", 3), (\"Lemma('frame.n.01.frame')\", 5), (\"Lemma('frame.v.01.frame')\", 1), (\"Lemma('frame.v.02.frame')\", 1), (\"Lemma('frame.n.02.frame')\", 1)])\n",
      "collecting tokens for  captain\n",
      "indices:    {12334, 23339, 7982}\n",
      "dict_items([(\"Lemma('captain.n.01.captain')\", 1), (\"Lemma('master.n.07.captain')\", 1)])\n",
      "collecting tokens for  display\n",
      "indices:    {26405, 1191, 8299, 11664, 25018, 5019, 22493}\n",
      "dict_items([(\"Lemma('expose.v.03.display')\", 5), (\"Lemma('display.n.02.display')\", 1)])\n",
      "collecting tokens for  monitoring\n",
      "indices:    {13993, 13994, 14028, 14029, 8301, 14060, 14032, 14034, 14039, 14042, 14043}\n",
      "dict_items([(\"Lemma('monitoring.n.01.monitoring')\", 4), (\"Lemma('monitor.v.01.monitor')\", 7)])\n",
      "collecting tokens for  tied\n",
      "indices:    {20096, 389, 392, 7197, 12193, 36387, 12212, 11830, 183, 22209, 28482, 13129, 35274, 20173, 22995, 32340, 27734, 30556, 8803, 36331, 18286, 13561}\n",
      "dict_items([(\"Lemma('tie.v.03.tie')\", 4), (\"Lemma('tie.v.01.tie')\", 6), (\"Lemma('tie.v.02.tie')\", 4), (\"Lemma('connect.v.01.tie')\", 2)])\n",
      "collecting tokens for  nassau\n",
      "indices:    {23545}\n",
      "dict_items([])\n",
      "collecting tokens for  ohio\n",
      "indices:    {21957}\n",
      "dict_items([])\n",
      "collecting tokens for  detergent\n",
      "indices:    {3202, 3203, 3204, 3212, 3216, 3228, 3229, 3230, 3147, 3148, 3149, 3151, 3152, 3158, 3159, 3168, 29410, 8803, 3171, 3173, 3174, 3176}\n",
      "dict_items([(\"Lemma('detergent.n.01.detergent')\", 17), (\"Lemma('detergent.n.02.detergent')\", 1)])\n",
      "collecting tokens for  luck\n",
      "indices:    {18529, 18530, 31684, 30404, 31688, 18827, 9931, 17263, 34900, 35829}\n",
      "dict_items([(\"Lemma('luck.n.02.luck')\", 3), (\"Lemma('fortune.n.04.luck')\", 1), (\"Lemma('luck.n.03.luck')\", 1)])\n",
      "collecting tokens for  itself\n",
      "indices:    {17920, 10753, 25601, 23560, 29706, 25613, 16402, 12307, 15895, 4632, 24089, 26142, 15392, 16417, 22058, 12332, 3634, 25654, 32823, 26681, 15419, 32316, 15421, 1084, 62, 14916, 17991, 16455, 31817, 26189, 34895, 15441, 1108, 27290, 15449, 2651, 1116, 13405, 2654, 27801, 27235, 10852, 14436, 32884, 11380, 24184, 29309, 11389, 25727, 11392, 27266, 13446, 25735, 4743, 5769, 6281, 27791, 10895, 4754, 13460, 15510, 8857, 7834, 16027, 12955, 11421, 27806, 26269, 4256, 27809, 16026, 4259, 23204, 8872, 27304, 23210, 31913, 34482, 5303, 23741, 29375, 3777, 4802, 26819, 26820, 32968, 22731, 27339, 11981, 27344, 22740, 1242, 31451, 37085, 5856, 4836, 4840, 2297, 37115, 4860, 5373, 4864, 4865, 23809, 5388, 2319, 5392, 5393, 1809, 25367, 5401, 28447, 1312, 1832, 5417, 34604, 4909, 24368, 4913, 11061, 30011, 13628, 24383, 15681, 20290, 4933, 31559, 2888, 32586, 2379, 25420, 31564, 13646, 14673, 1362, 13652, 26966, 13654, 24920, 13656, 24410, 13655, 2403, 35686, 16742, 11625, 32105, 4969, 5487, 28018, 24946, 12659, 25460, 2422, 4983, 2423, 14207, 7046, 14216, 3979, 27531, 3980, 2447, 4500, 5014, 1943, 2456, 35736, 25498, 25502, 27550, 1445, 30119, 12200, 27561, 1451, 23980, 4526, 14258, 15282, 6067, 21429, 1462, 4535, 12216, 6070, 9146, 12217, 16828, 7614, 1986, 25037, 34768, 26577, 7634, 26073, 2522, 16349, 3040, 9186, 16357, 15848, 26601, 1513, 15852, 25583, 11250, 23539, 15860, 31221, 16374, 15863, 12793}\n",
      "dict_items([])\n",
      "collecting tokens for  determine\n",
      "indices:    {28454, 4950, 1716, 15022}\n",
      "dict_items([(\"Lemma('determine.v.01.determine')\", 3), (\"Lemma('decide.v.01.determine')\", 1)])\n",
      "collecting tokens for  ratio\n",
      "indices:    {28928, 2180, 28938, 28939, 28942, 28945, 28951, 2847, 16168, 15021, 15022, 15036, 32319, 3141, 4042, 3276, 28495, 3152, 3279, 28502, 15063, 15065, 3306, 28917}\n",
      "dict_items([(\"Lemma('ratio.n.01.ratio')\", 14)])\n",
      "collecting tokens for  allotted\n",
      "indices:    {15041, 15046, 25095, 36006, 23881, 21808, 53, 15036, 15037}\n",
      "dict_items([(\"Lemma('assign.v.02.allot')\", 5), (\"Lemma('accord.v.02.allot')\", 2), (\"Lemma('distribute.v.01.allot')\", 2)])\n",
      "collecting tokens for  sum\n",
      "indices:    {4480, 4355, 23559, 27536, 27537, 27538, 24978, 24981, 22686, 14888, 4280, 15034, 15041, 27970, 4292, 34117, 2247, 4301, 27350, 4311, 17370, 989, 20209, 13556, 8696, 16635, 4476}\n",
      "dict_items([(\"Lemma('sum.n.01.sum')\", 5), (\"Lemma('kernel.n.03.sum')\", 1), (\"Lemma('sum.n.02.sum')\", 3), (\"Lemma('sum.n.03.sum')\", 1), (\"Lemma('sum.n.05.sum')\", 1)])\n",
      "collecting tokens for  commission\n",
      "indices:    {23605}\n",
      "dict_items([])\n",
      "collecting tokens for  planning\n",
      "indices:    {17023, 23605, 32503}\n",
      "dict_items([(\"Lemma('planning.n.01.planning')\", 1)])\n",
      "collecting tokens for  official\n",
      "indices:    {24097, 27893}\n",
      "dict_items([])\n",
      "collecting tokens for  recording\n",
      "indices:    {1763, 30215, 26325, 764, 1087}\n",
      "dict_items([(\"Lemma('recording.n.01.recording')\", 2)])\n",
      "collecting tokens for  machines\n",
      "indices:    {20432, 34297, 20433}\n",
      "dict_items([])\n",
      "collecting tokens for  business\n",
      "indices:    {24837, 2761, 24842, 27852, 16524, 16304, 4604, 9362, 15219, 22293, 444, 2749}\n",
      "dict_items([(\"Lemma('business.n.01.business')\", 2), (\"Lemma('business.n.05.business')\", 1), (\"Lemma('business.n.04.business')\", 1), (\"Lemma('business.n.06.business')\", 1)])\n",
      "collecting tokens for  order\n",
      "indices:    {5024, 7784, 1355, 18795, 16333, 17263, 11036}\n",
      "dict_items([(\"Lemma('orderliness.n.02.order')\", 1), (\"Lemma('order.v.02.order')\", 1), (\"Lemma('order.n.03.order')\", 1), (\"Lemma('order.n.01.order')\", 1)])\n",
      "collecting tokens for  prevent\n",
      "indices:    {11528, 23688, 5512, 3982, 31759, 32017, 31121, 12689, 22804, 23957, 32149, 14231, 791, 5275, 796, 20253, 9630, 20256, 20646, 4776, 2862, 28719, 32175, 3122, 30006, 20535, 12986, 15804, 33213, 22846, 29888, 22592, 30786, 21187, 15044, 30406, 3144, 1998, 15055, 27728, 19537, 25168, 15961, 32858, 29659, 33245, 2909, 33247, 31075, 14949, 14824, 20459, 23281, 5362, 25075, 23283, 29560, 12920, 22779, 14460, 29566}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('prevent.v.01.prevent')\", 26), (\"Lemma('prevent.v.02.prevent')\", 19)])\n",
      "collecting tokens for  suits\n",
      "indices:    {22081, 21187, 5604, 35812, 328, 9585, 30043, 25715, 11928, 23034, 23035}\n",
      "dict_items([(\"Lemma('suit.n.01.suit')\", 2)])\n",
      "collecting tokens for  happened\n",
      "indices:    {30211, 6019, 14085, 12294, 34826, 7308, 24466, 26387, 8211, 23317, 5656, 9757, 27425, 14116, 21797, 17446, 30628, 18474, 26412, 558, 22906, 34993, 33586, 17204, 30900, 12727, 31416, 14523, 6907, 31940, 35524, 14535, 25288, 6909, 17098, 18381, 6607, 17746, 32851, 25944, 26201, 36186, 16603, 10977, 33762, 35173, 4838, 25958, 18024, 34410, 4845, 30453, 25462, 30072, 10874, 19451, 10492, 34045}\n",
      "dict_items([(\"Lemma('happen.v.01.happen')\", 26), (\"Lemma('happen.v.03.happen')\", 4), (\"Lemma('happen.v.02.happen')\", 4), (\"Lemma('happen.v.04.happen')\", 3)])\n",
      "collecting tokens for  meetings\n",
      "indices:    {20229, 4753, 12965, 2726, 11695, 9653, 22714, 576, 21187, 32708, 28364, 29261, 5329, 32725, 28376, 12000, 14562, 20580, 11756, 16253}\n",
      "dict_items([(\"Lemma('meeting.n.02.meeting')\", 1), (\"Lemma('meeting.n.01.meeting')\", 9), (\"Lemma('meeting.n.04.meeting')\", 1)])\n",
      "collecting tokens for  ample\n",
      "indices:    {1888, 2561, 15551, 15651, 13927, 1033, 26442, 15339, 4941, 24884, 3061, 23513, 17178, 29053, 29119}\n",
      "dict_items([(\"Lemma('ample.a.01.ample')\", 8), (\"Lemma('ample.s.02.ample')\", 2)])\n",
      "collecting tokens for  sets\n",
      "indices:    {32787, 32661, 1560, 29849, 1562, 30365, 1565, 16160, 4388, 29745, 26290, 4402, 9534, 4424, 32714, 32715, 32719, 3285, 1110, 986, 32731, 32732, 32734, 16111, 28408, 32254, 26751}\n",
      "dict_items([(\"Lemma('set.n.02.set')\", 1), (\"Lemma('set.n.01.set')\", 5), (\"Lemma('jell.v.01.set')\", 1), (\"Lemma('stage_set.n.01.set')\", 1), (\"Lemma('fix.v.12.set')\", 1), (\"Lemma('set.n.03.set')\", 3), (\"Lemma('set.v.10.set')\", 1), (\"Lemma('set.v.04.set')\", 1), (\"Lemma('assign.v.04.set_apart')\", 1)])\n",
      "collecting tokens for  homes\n",
      "indices:    {5122, 30090, 12, 32915, 32280, 11803, 22813, 15645, 21025, 19492, 12331, 7600, 7602, 21683, 20790, 30647, 5434, 11967, 29247, 30405, 6087, 6092, 31316, 16597, 22493, 29285, 25319, 6506, 12779, 5486, 20208, 9201, 25074, 28656, 3445, 12151, 32380, 21373}\n",
      "dict_items([(\"Lemma('dwelling.n.01.home')\", 12), (\"Lemma('home.n.01.home')\", 5)])\n",
      "collecting tokens for  independent\n",
      "indices:    {13894, 168, 7306, 31223, 5404, 4382}\n",
      "dict_items([(\"Lemma('independent.a.01.independent')\", 4)])\n",
      "collecting tokens for  seasons\n",
      "indices:    {29920, 2561, 1824, 11268, 1862, 27049, 28090, 22419, 24501, 437, 27033, 666, 26525, 11902, 17599}\n",
      "dict_items([(\"Lemma('season.n.01.season')\", 3), (\"Lemma('season.n.02.season')\", 5)])\n",
      "collecting tokens for  fly\n",
      "indices:    {11107, 18668, 29904, 29905, 29906, 21713, 20948, 7381, 31477, 30576, 30520, 22992, 945, 10746, 7197, 31358, 959}\n",
      "dict_items([(\"Lemma('fly.v.01.fly')\", 6), (\"Lemma('fly.n.01.fly')\", 1), (\"Lemma('fly.v.03.fly')\", 2), (\"Lemma('fly.v.04.fly')\", 1), (\"Lemma('tent-fly.n.01.fly')\", 1)])\n",
      "collecting tokens for  helped\n",
      "indices:    {31233, 25858, 36867, 17796, 31239, 33291, 11660, 18315, 17424, 28562, 36626, 7706, 17949, 14242, 28073, 11437, 22576, 15795, 10934, 10938, 10300, 12992, 10050, 20291, 2259, 32856, 15708, 11234, 36837, 9319, 35053, 10095, 28016, 5111, 14712, 28030, 35071}\n",
      "dict_items([(\"Lemma('help.v.01.help')\", 26), (\"Lemma('help.v.03.help')\", 3), (\"Lemma('help.v.02.help')\", 5)])\n",
      "collecting tokens for  kate\n",
      "indices:    {7738}\n",
      "dict_items([(\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  juanita\n",
      "indices:    {7738}\n",
      "dict_items([(\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  flower\n",
      "indices:    {29369, 26718}\n",
      "dict_items([])\n",
      "collecting tokens for  yard\n",
      "indices:    {29441, 6466, 290, 29443, 1603, 5670, 9697, 30127, 13936, 29073, 23090, 5654, 246, 12154, 9503}\n",
      "dict_items([(\"Lemma('yard.n.01.yard')\", 2), (\"Lemma('yard.n.02.yard')\", 4)])\n",
      "collecting tokens for  evenings\n",
      "indices:    {33154, 30151, 24585, 31562, 25004, 22573, 14446, 11152, 26451, 29463}\n",
      "dict_items([(\"Lemma('evening.n.01.evening')\", 2)])\n",
      "collecting tokens for  fat\n",
      "indices:    {27202, 36068, 10245, 17096, 36085, 33589, 35928, 35355, 36415}\n",
      "dict_items([(\"Lemma('adipose_tissue.n.01.fat')\", 1), (\"Lemma('fat.a.01.fat')\", 1)])\n",
      "collecting tokens for  bees\n",
      "indices:    {3591, 3624, 3625, 19111, 3647, 3599, 3664, 10483, 3669, 3606, 13561, 7706, 3676, 3646, 3679}\n",
      "dict_items([(\"Lemma('bee.n.01.bee')\", 11)])\n",
      "collecting tokens for  purple\n",
      "indices:    {26984, 24562, 14677, 22872, 5945}\n",
      "dict_items([(\"Lemma('purple.n.01.purple')\", 1)])\n",
      "collecting tokens for  earned\n",
      "indices:    {162, 37093, 549, 24199, 22089, 522, 16492, 37070, 15634, 23411, 2258, 23415, 23416, 28411, 17373}\n",
      "dict_items([(\"Lemma('earn.v.02.earn')\", 6), (\"Lemma('gain.v.08.earn')\", 7), (\"Lemma('earned.a.01.earned')\", 2)])\n",
      "collecting tokens for  per\n",
      "indices:    {14854, 11783, 14855, 3083, 32268, 27672, 14873, 23577, 27163, 23578, 32288, 32290, 24837, 32293, 32294, 32295, 3112, 13353, 13354, 27175, 14893, 32301, 47, 13360, 13361, 32303, 62, 32319, 5184, 21572, 14916, 4168, 27210, 4171, 4172, 23633, 23636, 32341, 23638, 32346, 32348, 32350, 26731, 3695, 26736, 11376, 24695, 26744, 27256, 11385, 32890, 24702, 25735, 20624, 2717, 20638, 21153, 15009, 15012, 21158, 21160, 15017, 15018, 15019, 15020, 15021, 15022, 21173, 1717, 2766, 32463, 3279, 20177, 20178, 20691, 20180, 15061, 3285, 15063, 3283, 15065, 20692, 15059, 12522, 21227, 20203, 21229, 12526, 21230, 21232, 11546, 21235, 24820, 21246, 11521, 11522, 11523, 21765, 11526, 11527, 11528, 11525, 3336, 11529, 11532, 11533, 21773, 23823, 11536, 11538, 5396, 11541, 5397, 11543, 11542, 11545, 11540, 11547, 16155, 11549, 25374, 16157, 11544, 11553, 11550, 11555, 11556, 288, 11558, 15140, 11560, 23849, 3370, 11562, 3372, 11565, 11568, 21815, 1385, 12090, 11580, 16189, 16188, 24893, 3392, 16191, 3390, 11587, 16196, 11589, 24897, 11584, 11593, 11595, 11596, 5454, 846, 848, 21841, 11602, 11606, 13149, 13150, 23391, 23393, 23395, 23396, 356, 1382, 355, 23912, 2409, 12650, 1387, 23914, 23405, 13166, 13167, 5487, 23407, 23406, 23411, 21873, 3443, 1398, 5495, 5496, 21876, 14194, 21875, 23418, 23415, 16253, 5503, 23416, 13185, 23426, 3457, 16260, 12163, 20358, 16261, 15752, 33161, 3982, 3438, 3439, 5528, 13727, 5535, 15266, 13227, 12720, 14769, 14770, 12722, 2993, 16313, 27581, 4035, 24007, 4045, 5583, 11735, 24025, 11226, 24027, 11739, 15327, 15328, 5489, 21988, 23524, 27110, 21874, 23528, 16362, 16365, 30197}\n",
      "dict_items([])\n",
      "collecting tokens for  cent\n",
      "indices:    {8194, 27672, 23577, 23578, 8226, 13353, 13354, 47, 13360, 13361, 5184, 21572, 26731, 26736, 24695, 26744, 24702, 25735, 30866, 20638, 21153, 21158, 21160, 21173, 13167, 3279, 20177, 20178, 20180, 2268, 12522, 21227, 21229, 12526, 21230, 21232, 21235, 24820, 21246, 21765, 24837, 3336, 23823, 288, 23849, 3372, 21815, 3390, 21826, 16196, 5454, 846, 848, 21841, 13149, 13150, 23391, 23393, 23395, 23396, 1382, 23912, 1385, 23914, 1387, 23405, 3438, 13166, 5487, 23407, 23406, 23411, 21873, 3443, 1398, 23415, 5496, 23416, 23418, 5495, 21876, 16253, 13185, 23426, 16260, 16261, 20358, 15752, 33161, 5528, 13727, 5535, 13227, 27581, 24007, 5583, 24025, 24027, 23524, 27110, 21874, 21875, 30197}\n",
      "dict_items([(\"Lemma('penny.n.02.cent')\", 2), (\"Lemma('cent.n.01.cent')\", 1)])\n",
      "collecting tokens for  preceding\n",
      "indices:    {11143, 32393, 11530, 32426, 32810, 16044, 8878, 32823, 32186, 14396, 32839, 3919, 28626, 15571, 15577, 865, 25188, 27748, 9576, 23407, 23411}\n",
      "dict_items([(\"Lemma('preceding.a.01.preceding')\", 7), (\"Lemma('predate.v.01.precede')\", 2)])\n",
      "collecting tokens for  choice\n",
      "indices:    {32902, 139, 1037, 28433, 28434, 24850, 1302, 13212, 4775, 27816, 27817, 20775, 23728, 28601, 30906, 25427, 12279, 36309, 11735, 29015, 25439, 27875, 30700, 28662, 24567}\n",
      "dict_items([(\"Lemma('choice.n.01.choice')\", 3), (\"Lemma('option.n.02.choice')\", 1), (\"Lemma('choice.n.02.choice')\", 3)])\n",
      "collecting tokens for  germany\n",
      "indices:    {31624}\n",
      "dict_items([])\n",
      "collecting tokens for  industrial\n",
      "indices:    {23973}\n",
      "dict_items([])\n",
      "collecting tokens for  soul\n",
      "indices:    {27393, 27143, 27405, 24333, 27022, 10520, 10651, 13820, 7073, 11048, 6062, 2352, 19381, 1462, 36409, 1466, 25154, 27972, 8778, 9186, 23909, 10599, 27376, 27504, 27380, 28026, 27388, 27389, 28286}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('soul.n.01.soul')\", 9), (\"Lemma('soul.n.03.soul')\", 2), (\"Lemma('person.n.01.soul')\", 1), (\"Lemma('soul.n.04.soul')\", 1)])\n",
      "collecting tokens for  free\n",
      "indices:    {23666, 1430}\n",
      "dict_items([])\n",
      "collecting tokens for  enterprise\n",
      "indices:    {20355, 15495, 15261, 22690, 22691, 22820, 32167, 23850, 22711, 14135, 5199, 32724, 12118, 14686, 37087, 25058, 25059, 23909, 20348, 22761, 14204}\n",
      "dict_items([(\"Lemma('enterprise.n.01.enterprise')\", 4), (\"Lemma('enterprise.n.02.enterprise')\", 2)])\n",
      "collecting tokens for  jubal\n",
      "indices:    {10141}\n",
      "dict_items([(\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  digby\n",
      "indices:    {9995}\n",
      "dict_items([(\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  disappearance\n",
      "indices:    {14496, 19329, 4270, 31826, 4662, 10230, 10136, 34650}\n",
      "dict_items([(\"Lemma('fade.n.02.disappearance')\", 1), (\"Lemma('disappearance.n.01.disappearance')\", 4), (\"Lemma('disappearance.n.02.disappearance')\", 1)])\n",
      "collecting tokens for  dismissed\n",
      "indices:    {30305, 24904, 35017, 20154, 6127, 15285, 10136, 31738, 15226}\n",
      "dict_items([(\"Lemma('dismiss.v.01.dismiss')\", 5), (\"Lemma('dismiss.v.02.dismiss')\", 2), (\"Lemma('dismiss.v.03.dismiss')\", 1)])\n",
      "collecting tokens for  mike\n",
      "indices:    {35308}\n",
      "dict_items([])\n",
      "collecting tokens for  finger\n",
      "indices:    {36736, 3459, 37126, 6409, 29070, 9487, 9486, 9747, 27284, 23192, 10136, 4135, 27953, 5887, 27958, 35130, 29631, 3911, 714, 10955, 3916, 30800, 9182, 5984, 10597, 10982, 33638, 14323, 31095, 11000, 13567}\n",
      "dict_items([(\"Lemma('finger.n.01.finger')\", 12)])\n",
      "collecting tokens for  gotten\n",
      "indices:    {20743, 137, 10699, 9900, 24941, 10221, 33101, 9813, 10136}\n",
      "dict_items([(\"Lemma('bring.v.04.get')\", 1), (\"Lemma('experience.v.03.get')\", 1)])\n",
      "collecting tokens for  supreme\n",
      "indices:    {4920, 26945, 25727}\n",
      "dict_items([(\"Lemma('supreme.s.01.supreme')\", 1)])\n",
      "collecting tokens for  worried\n",
      "indices:    {8205, 2581, 36247, 35480, 10136, 18719, 17057, 6178, 27425, 20017, 10810, 36284, 20037, 36935, 34513, 13015, 5719, 30298, 5984, 16864, 35809, 8170, 5610, 17783, 33277}\n",
      "dict_items([(\"Lemma('disquieted.s.01.worried')\", 7), (\"Lemma('worry.v.01.worry')\", 3), (\"Lemma('worry.v.03.worry')\", 4), (\"Lemma('worry.v.02.worry')\", 3)])\n",
      "collecting tokens for  bothered\n",
      "indices:    {14563, 35657, 271, 18034, 28664, 31478, 24503, 10136, 18009, 382, 5663}\n",
      "dict_items([(\"Lemma('annoy.v.01.bother')\", 4), (\"Lemma('trouble_oneself.v.01.bother')\", 3), (\"Lemma('trouble.v.02.bother')\", 4)])\n",
      "collecting tokens for  things\n",
      "indices:    {36224, 1924, 1033, 1674, 13835, 26379, 22793, 12178, 14615, 37025, 27425, 18339, 23844, 14242, 8230, 27430, 37161, 27692, 13101, 14638, 31536, 26419, 16054, 37047, 14646, 20025, 8763, 21182, 24385, 9155, 25029, 4935, 10440, 14281, 4937, 21960, 34639, 10832, 31571, 11862, 34135, 8024, 4958, 1251, 30824, 25193, 36076, 13165, 17907, 13558}\n",
      "dict_items([(\"Lemma('thing.n.01.thing')\", 7), (\"Lemma('thing.n.08.thing')\", 2), (\"Lemma('thing.n.03.thing')\", 4), (\"Lemma('thing.n.04.thing')\", 5), (\"Lemma('matter.n.01.thing')\", 1), (\"Lemma('thing.n.02.thing')\", 4), (\"Lemma('things.n.01.things')\", 2), (\"Lemma('thing.n.09.thing')\", 1), (\"Lemma('thing.n.10.thing')\", 1)])\n",
      "collecting tokens for  sure\n",
      "indices:    {34277, 24299, 12143, 9461, 29754, 18782}\n",
      "dict_items([(\"Lemma('certain.a.02.sure')\", 2), (\"Lemma('certain.s.07.sure')\", 1)])\n",
      "collecting tokens for  whatever\n",
      "indices:    {1346, 25316, 15852, 17358, 17263, 8336, 6897, 1236, 4854, 27801, 20059}\n",
      "dict_items([])\n",
      "collecting tokens for  price\n",
      "indices:    {22016, 19395, 22793, 11626, 22781}\n",
      "dict_items([(\"Lemma('price.n.03.price')\", 1), (\"Lemma('price.n.02.price')\", 1)])\n",
      "collecting tokens for  chiefly\n",
      "indices:    {28055, 3939, 22597, 2470, 23372, 28077, 3726, 6167, 6393, 2394, 6044, 28062}\n",
      "dict_items([(\"Lemma('chiefly.r.01.chiefly')\", 7)])\n",
      "collecting tokens for  cells\n",
      "indices:    {4097, 3587, 3589, 3258, 4105, 4114, 15891, 3991, 15895, 15896, 15932, 3522, 15906, 15907, 15909, 31023, 15925, 4152, 3257, 15930, 15931, 3260, 3261, 3518, 32703, 3520, 3521, 3265, 3267, 15940, 15941, 3525, 3266, 3272, 3528, 3273, 3531, 3657, 3655, 3534, 3535, 3536, 4179, 4180, 4181, 4184, 3289, 4185, 11355, 3292, 11353, 3288, 3295, 3296, 27231, 4186, 4068, 4199, 4200, 11369, 3946, 11370, 27243, 4077, 4078, 4082, 2553}\n",
      "dict_items([(\"Lemma('cell.n.01.cell')\", 26), (\"Lemma('cell.n.02.cell')\", 26)])\n",
      "collecting tokens for  standing\n",
      "indices:    {22538, 17043, 21909, 24598, 2078, 26142, 6687, 32931, 37028, 9509, 12715, 7226, 1983, 9152, 36037, 18246, 7497, 7113, 36686, 9943, 2018, 11377, 2686}\n",
      "dict_items([(\"Lemma('stand.v.01.stand')\", 14), (\"Lemma('standing.n.01.standing')\", 1), (\"Lemma('standing.s.01.standing')\", 1), (\"Lemma('stand.v.03.stand')\", 2), (\"Lemma('stand.v.02.stand')\", 1)])\n",
      "collecting tokens for  enjoying\n",
      "indices:    {5953, 8141, 33999, 24567, 30039, 4666, 18523, 830}\n",
      "dict_items([(\"Lemma('enjoy.v.01.enjoy')\", 6), (\"Lemma('delight.v.02.enjoy')\", 1), (\"Lemma('enjoy.v.02.enjoy')\", 1)])\n",
      "collecting tokens for  slug\n",
      "indices:    {29061, 23336, 29064, 33999, 18643, 8116, 18652, 29053}\n",
      "dict_items([(\"Lemma('bullet.n.01.slug')\", 2), (\"Lemma('slug.v.01.slug')\", 1)])\n",
      "collecting tokens for  rourke\n",
      "indices:    {33928}\n",
      "dict_items([])\n",
      "collecting tokens for  eight\n",
      "indices:    {30013}\n",
      "dict_items([])\n",
      "collecting tokens for  conclusion\n",
      "indices:    {16387, 16388, 15239, 3721, 26378, 15241, 30089, 26389, 13976, 32411, 16029, 12204, 20656, 4913, 4919, 16185, 16186, 16187, 446, 32212, 3925, 32983, 27878, 22631, 4584, 3837, 1513, 1514, 15726, 32886, 3065, 25978, 12284, 16893, 14335}\n",
      "dict_items([(\"Lemma('ending.n.04.conclusion')\", 1), (\"Lemma('decision.n.02.conclusion')\", 18), (\"Lemma('conclusion.n.05.conclusion')\", 1), (\"Lemma('conclusion.n.02.conclusion')\", 2), (\"Lemma('stopping_point.n.01.conclusion')\", 1)])\n",
      "collecting tokens for  admitted\n",
      "indices:    {13446, 23176, 21754, 13451, 34457, 21657, 34590, 15777, 25384, 22962, 3251, 21172, 18489, 21438, 20160, 25793, 5318, 10751, 33100, 21325, 23167, 32214, 34527, 21345, 21218, 30946, 36582, 15336, 22892, 22893, 1398, 25978, 34559}\n",
      "dict_items([(\"Lemma('admit.v.01.admit')\", 25), (\"Lemma('admit.v.02.admit')\", 7), (\"Lemma('admit.v.03.admit')\", 1)])\n",
      "collecting tokens for  valid\n",
      "indices:    {11298, 25732, 21354, 4363, 4301, 2286, 13621, 25978, 31099}\n",
      "dict_items([(\"Lemma('valid.a.01.valid')\", 5)])\n",
      "collecting tokens for  historians\n",
      "indices:    {12346}\n",
      "dict_items([(\"Lemma('historian.n.01.historian')\", 1)])\n",
      "collecting tokens for  alike\n",
      "indices:    {23430, 1255, 28840, 1577, 34984, 16014, 27121, 24211, 23030, 25978, 27772, 3709, 23967}\n",
      "dict_items([(\"Lemma('alike.r.01.alike')\", 2), (\"Lemma('alike.a.01.alike')\", 2)])\n",
      "collecting tokens for  &\n",
      "indices:    {18055, 35977, 18060, 9997, 36116, 35095, 10141, 10151, 26548, 18997, 18879, 19008, 33344, 17994, 16587, 10189, 18768, 10064, 10192, 16852, 34261, 32982, 10084, 9064, 19949, 24307, 25978}\n",
      "dict_items([])\n",
      "collecting tokens for  nonsense\n",
      "indices:    {1193, 12682, 10825, 26862, 22291, 6777, 10778, 10779}\n",
      "dict_items([(\"Lemma('nonsense.n.01.nonsense')\", 5), (\"Lemma('nonsense.s.01.nonsense')\", 1)])\n",
      "collecting tokens for  music\n",
      "indices:    {6793, 22539, 26384, 1179, 24742, 26796, 31660, 26797, 1718, 1728, 11212, 27980, 26062, 14548, 2646, 11108, 26472, 31593, 25331, 26867, 6771, 23542, 26871, 26360}\n",
      "dict_items([(\"Lemma('music.n.01.music')\", 9)])\n",
      "collecting tokens for  mature\n",
      "indices:    {3713, 22146, 30729, 1932, 30734, 22548, 1697, 26786, 677, 27691, 11437, 22726, 11213, 26576, 11225, 13534, 13535, 11231, 20845, 28150, 4600, 34681, 3707}\n",
      "dict_items([(\"Lemma('mature.v.01.mature')\", 4), (\"Lemma('mature.s.02.mature')\", 4), (\"Lemma('mature.a.01.mature')\", 4), (\"Lemma('mature.a.03.mature')\", 1)])\n",
      "collecting tokens for  profile\n",
      "indices:    {3863}\n",
      "dict_items([(\"Lemma('profile.n.01.profile')\", 1)])\n",
      "collecting tokens for  attitude\n",
      "indices:    {27648, 28683, 13325, 14369, 2096, 22581, 36930, 2638, 2127, 15438, 34388, 25200, 22667, 32403, 17044, 25243, 25244, 5277, 5278, 4270, 4273, 14513, 1215, 30400, 16088, 17633, 4847, 27895, 5880, 16124, 12030, 4865, 4879, 8464, 791, 4891, 4892, 4893, 4894, 4897, 32033, 29998, 24883, 25403, 14652, 2366, 25410, 2375, 13655, 13660, 14686, 14688, 14189, 24433, 28018, 24434, 24437, 13190, 28551, 13194, 28556, 28557, 25999, 15782, 15279, 2480, 34737, 2486, 31676, 24509, 1471, 16323, 9155, 2501, 33227, 13263, 11732, 11225}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('attitude.n.01.attitude')\", 26), (\"Lemma('attitude.n.03.attitude')\", 1), (\"Lemma('position.n.04.attitude')\", 1)])\n",
      "collecting tokens for  hot\n",
      "indices:    {20999, 29073, 30110, 24991, 25763, 19115, 555, 14643, 28852, 74, 35150, 29407, 2273, 2535, 7401, 12793, 30454, 2934, 29433}\n",
      "dict_items([(\"Lemma('hot.a.01.hot')\", 6), (\"Lemma('hot.a.03.hot')\", 1), (\"Lemma('hot_war.n.01.hot_war')\", 1)])\n",
      "collecting tokens for  water\n",
      "indices:    {12162, 9995, 32525, 142, 30480, 147, 31510, 35490, 8867, 31398, 28711, 27048, 36138, 26550, 26558, 1859, 31560, 28627, 10469, 1644, 7158}\n",
      "dict_items([(\"Lemma('body_of_water.n.01.water')\", 1), (\"Lemma('water.n.01.water')\", 5)])\n",
      "collecting tokens for  cooling\n",
      "indices:    {1700, 30185, 30122, 30089, 30157, 2863, 30128, 2865, 30098, 30131, 30163, 30166}\n",
      "dict_items([(\"Lemma('cooling.n.01.cooling')\", 3)])\n",
      "collecting tokens for  reality\n",
      "indices:    {25603, 28139, 6907}\n",
      "dict_items([(\"Lemma('world.n.03.reality')\", 1)])\n",
      "collecting tokens for  confusion\n",
      "indices:    {1219, 18853, 7045, 31176, 9802, 12331, 12209, 16082, 7956, 23318, 23256, 17019}\n",
      "dict_items([(\"Lemma('confusion.n.02.confusion')\", 4), (\"Lemma('confusion.n.01.confusion')\", 5)])\n",
      "collecting tokens for  paradox\n",
      "indices:    {2306, 28140, 5391, 27696, 22769, 27700, 22708, 5205}\n",
      "dict_items([(\"Lemma('paradox.n.01.paradox')\", 3)])\n",
      "collecting tokens for  grip\n",
      "indices:    {5888, 418, 27459, 1254, 36615, 1544, 36122, 28140, 6926, 1553, 1555, 1557, 18840, 17434, 1277}\n",
      "dict_items([(\"Lemma('clasp.n.02.grip')\", 7), (\"Lemma('bag.n.06.grip')\", 1), (\"Lemma('handle.n.01.grip')\", 1)])\n",
      "collecting tokens for  originated\n",
      "indices:    {11042, 5253, 18694, 23848, 21833, 28140, 14413, 19341, 3317, 28695, 21113, 32667}\n",
      "dict_items([(\"Lemma('originate.v.01.originate')\", 6), (\"Lemma('originate.v.02.originate')\", 2)])\n",
      "collecting tokens for  fourth\n",
      "indices:    {385, 392, 4744, 36883, 14611, 9634, 29356, 15552, 15811, 1744, 6489, 19034, 27609, 27615, 3302, 12390, 8807, 375, 17406}\n",
      "dict_items([(\"Lemma('fourth.s.01.fourth')\", 13), (\"Lemma('fourth.n.01.fourth')\", 1)])\n",
      "collecting tokens for  b.\n",
      "indices:    {32860}\n",
      "dict_items([])\n",
      "collecting tokens for  c.\n",
      "indices:    {29039}\n",
      "dict_items([])\n",
      "collecting tokens for  basically\n",
      "indices:    {4642, 21955, 16100, 4967, 24200, 22443, 28140, 4907, 29231, 5295, 20434, 14228, 27125, 26075, 3199, 28095}\n",
      "dict_items([(\"Lemma('basically.r.01.basically')\", 7)])\n",
      "collecting tokens for  device\n",
      "indices:    {2432, 33540, 33541, 28934, 33542, 5384, 20749, 2446, 10641, 33554, 28828, 34721, 15147, 5549, 10670, 817, 14776, 2235, 15675, 33469, 2237, 2239, 2248, 2249, 33481, 26960, 722, 2389, 3544, 2266, 7135, 12255, 2282, 28140, 2285, 2287, 33523, 31349, 5370, 31483, 5373}\n",
      "dict_items([(\"Lemma('device.n.01.device')\", 22), (\"Lemma('device.n.03.device')\", 2), (\"Lemma('device.n.02.device')\", 1)])\n",
      "collecting tokens for  nor\n",
      "indices:    {8036, 30763, 36013, 13490, 24148, 3797, 13558, 11702, 5238, 24887, 25439}\n",
      "dict_items([])\n",
      "collecting tokens for  sensitive\n",
      "indices:    {2432, 31105, 3332, 13573, 1158, 3333, 31116, 33165, 20626, 3348, 3992, 2841, 30233, 3353, 9380, 31271, 3242, 31147, 27308, 31152, 22705, 3378, 7604, 14644, 31160, 27705, 26556, 26940, 4929, 13763, 11333, 5586, 23897, 27103, 14820, 31081, 26091, 31090, 26486, 31099, 23037}\n",
      "dict_items([(\"Lemma('sensitive.a.02.sensitive')\", 7), (\"Lemma('sensitive.a.01.sensitive')\", 12)])\n",
      "collecting tokens for  emotions\n",
      "indices:    {14623, 14624, 4258, 6821, 6825, 14633, 27308, 4271, 31152, 4274, 4276, 4278, 5691, 7357, 4678, 7751, 11080, 8520, 8657, 8658, 4819, 31586, 15847, 15850, 30830, 4211}\n",
      "dict_items([(\"Lemma('emotion.n.01.emotion')\", 22)])\n",
      "collecting tokens for  immigration\n",
      "indices:    {28000, 24089, 13778, 28056}\n",
      "dict_items([(\"Lemma('immigration.n.01.immigration')\", 1)])\n",
      "collecting tokens for  lips\n",
      "indices:    {9600, 36736, 19969, 8832, 34820, 28289, 12804, 8842, 18955, 18324, 34965, 33663, 18970, 10907, 9634, 18853, 35110, 10921, 17838, 35124, 7220, 10936, 10937, 6338, 6979, 17863, 26951, 7240, 7242, 7759, 8527, 18898, 18900, 19157, 12890, 19163, 36830, 34401, 36196, 8420, 9702, 8423, 28395, 8817, 5618, 17651, 19827, 17916, 18941, 27775}\n",
      "dict_items([(\"Lemma('lip.n.01.lip')\", 26)])\n",
      "collecting tokens for  rage\n",
      "indices:    {24192, 2692, 28552, 2686, 27308, 32078, 36463, 17424, 8920, 12893, 19390, 2687}\n",
      "dict_items([(\"Lemma('rage.n.03.rage')\", 1), (\"Lemma('fury.n.01.rage')\", 5)])\n",
      "collecting tokens for  parker\n",
      "indices:    {20980}\n",
      "dict_items([])\n",
      "collecting tokens for  catholics\n",
      "indices:    {12268}\n",
      "dict_items([(\"Lemma('catholic.n.01.Catholic')\", 1)])\n",
      "collecting tokens for  voting\n",
      "indices:    {4792, 4804, 4774, 21927}\n",
      "dict_items([(\"Lemma('vote.n.01.voting')\", 1)])\n",
      "collecting tokens for  bishop\n",
      "indices:    {9995}\n",
      "dict_items([])\n",
      "collecting tokens for  tells\n",
      "indices:    {6021, 30219, 24715, 27025, 4885, 34198, 27043, 805, 27308, 31412, 26937, 10811, 11073, 15172, 2130, 1878, 14298, 21981, 20958, 4835, 13809, 11512}\n",
      "dict_items([(\"Lemma('tell.v.02.tell')\", 5), (\"Lemma('state.v.01.tell')\", 8), (\"Lemma('tell.v.03.tell')\", 7), (\"Lemma('order.v.01.tell')\", 2)])\n",
      "collecting tokens for  3\n",
      "indices:    {21514, 30221, 3088, 4113, 3090, 3091, 28180, 4118, 29722, 28188, 1565, 14878, 4127, 4129, 28195, 4132, 28204, 4141, 14894, 28211, 21044, 12342, 58, 570, 22588, 28221, 29757, 19519, 28225, 28234, 591, 21584, 597, 28248, 28760, 22113, 28257, 15459, 28771, 28260, 617, 15466, 28267, 28780, 3583, 11374, 619, 28784, 3695, 28268, 32377, 28794, 4095, 28292, 12422, 3208, 21641, 21134, 17556, 28824, 11931, 3741, 4253, 28831, 3744, 28833, 20638, 15005, 28832, 28844, 29869, 28845, 15023, 15027, 3764, 21172, 182, 180, 25779, 179, 3774, 11456, 193, 32973, 14033, 20177, 15571, 32466, 214, 215, 15066, 3803, 14046, 27871, 14050, 14057, 14059, 14061, 2798, 239, 240, 22254, 2802, 28913, 2808, 27906, 3331, 27395, 3845, 3846, 33027, 3848, 3849, 23305, 29963, 3851, 3850, 11530, 3855, 26384, 273, 29970, 25875, 2844, 29984, 2851, 16167, 4392, 4397, 16175, 3888, 3890, 33076, 4917, 29492, 16183, 3898, 4410, 3900, 16189, 4414, 24893, 22336, 16194, 4420, 2884, 20806, 3910, 11598, 2895, 3920, 21328, 2896, 1362, 11608, 29529, 29531, 29532, 15709, 22364, 2912, 352, 358, 359, 32614, 4460, 29039, 29040, 29041, 370, 21875, 5493, 18293, 26488, 21881, 14720, 24451, 27021, 5518, 33167, 27536, 3844, 28567, 29593, 2972, 14752, 29099, 28588, 28589, 27567, 21935, 33199, 28595, 29619, 961, 454, 458, 16331, 5580, 29645, 3534, 4047, 4048, 3537, 22995, 14809, 4061, 5087, 3553, 20963, 4072, 4073, 16362, 16363, 20975, 4083, 3572, 20986, 30207}\n",
      "dict_items([(\"Lemma('three.s.01.3')\", 26), (\"Lemma('three.n.01.3')\", 9), (\"Lemma('third.s.01.3rd')\", 1)])\n",
      "collecting tokens for  hansen\n",
      "indices:    {217}\n",
      "dict_items([(\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  checked\n",
      "indices:    {34187, 30861, 29199, 32409, 9881, 34204, 7198, 17187, 28843, 8245, 16954, 15803, 8514, 215, 17112, 8281, 1885, 17505, 34023, 11751, 11632, 22011, 36988}\n",
      "dict_items([(\"Lemma('check.v.01.check')\", 7), (\"Lemma('see.v.10.check')\", 1), (\"Lemma('check.v.02.check')\", 2), (\"Lemma('control.v.02.check')\", 1), (\"Lemma('check.v.06.check')\", 1), (\"Lemma('check.v.05.check')\", 1), (\"Lemma('check.v.07.check')\", 1)])\n",
      "collecting tokens for  close\n",
      "indices:    {27521, 28722, 29047}\n",
      "dict_items([])\n",
      "collecting tokens for  200\n",
      "indices:    {11524, 12424, 32265, 24590, 24977, 21522, 29339, 11550, 1439, 29088, 10659, 13996, 2860, 4145, 22194, 25395, 822, 25399, 27069, 20160, 3648, 21189, 30150, 25675, 3278, 29136, 21841, 28496, 3283, 215, 21721, 20448, 12513, 21732, 20839, 14825, 28528, 13041, 23032}\n",
      "dict_items([])\n",
      "collecting tokens for  pounds\n",
      "indices:    {12416, 12417, 29066, 11551, 5151, 2211, 11556, 11568, 29108, 11584, 11587, 215, 216, 28505, 2274, 2275, 34660, 7522, 3431, 30446, 23032, 1529, 31482, 1534}\n",
      "dict_items([(\"Lemma('pound.n.01.pound')\", 15), (\"Lemma('british_pound.n.01.pound')\", 2)])\n",
      "collecting tokens for  lighter\n",
      "indices:    {12835, 9719, 35367, 1581, 215, 30104, 35770, 22461}\n",
      "dict_items([(\"Lemma('light.a.05.light')\", 1), (\"Lemma('light.a.01.light')\", 2), (\"Lemma('light.a.02.light')\", 1)])\n",
      "collecting tokens for  reporting\n",
      "indices:    {14756, 25927, 32552, 21516, 12813, 3244, 12268, 32565, 1205, 215, 25915}\n",
      "dict_items([(\"Lemma('report.v.05.report')\", 1), (\"Lemma('report.v.02.report')\", 3), (\"Lemma('report.v.03.report')\", 1), (\"Lemma('coverage.n.03.reporting')\", 1), (\"Lemma('report.v.01.report')\", 1)])\n",
      "collecting tokens for  spring\n",
      "indices:    {29105, 31100}\n",
      "dict_items([])\n",
      "collecting tokens for  wanted\n",
      "indices:    {36865, 18433, 35844, 12811, 20492, 33279, 19482, 33306, 19488, 22567, 36903, 18474, 19498, 45, 8238, 30256, 12852, 22586, 12347, 8251, 8254, 26691, 9287, 9289, 8266, 6220, 33357, 1614, 22608, 19543, 34393, 9307, 8284, 19038, 36449, 8291, 33380, 12393, 17002, 10862, 17007, 10863, 10865, 17010, 17011, 18548, 20599, 14457, 19069, 25214, 35968, 20100, 37002, 27282, 7315, 36508, 12445, 9886, 16031, 30882, 675, 676, 7335, 28332, 30893, 36529, 33461, 37051, 16575, 16576, 23233, 13515, 36557, 31965, 21217, 17122, 23265, 23268, 17127, 24297, 19690, 33515, 30958, 6898, 33526, 30976, 33543, 778, 17679, 13071, 23313, 24854, 23319, 23321, 19228, 10015, 31522, 21794, 17710, 19763, 20788, 36153, 35135, 28992, 8520, 36168, 22352, 10582, 19294, 4961, 36709, 12646, 8040, 21368, 28671, 21381, 35216, 36243, 8087, 16792, 36249, 15774, 17825, 6570, 7089, 17846, 7608, 34234, 30141, 18366, 16837, 36807, 17352, 17351, 36811, 5069, 31694, 18898, 36822, 33243, 5085, 16867, 36837, 8166, 10228, 35322, 5116, 36862, 35839}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('desire.v.01.want')\", 26), (\"Lemma('want.v.02.want')\", 5), (\"Lemma('want.v.03.want')\", 1)])\n",
      "collecting tokens for  winds\n",
      "indices:    {5963, 27051, 22300, 10231}\n",
      "dict_items([(\"Lemma('wind.n.01.wind')\", 2)])\n",
      "collecting tokens for  highly\n",
      "indices:    {3460, 3204, 28169, 25355, 13455, 3217, 20626, 3218, 12949, 20507, 11039, 3234, 23843, 25762, 30758, 31275, 29868, 2097, 29490, 13617, 18302, 1205, 12342, 12343, 26678, 29109, 16314, 11713, 25671, 11079, 13256, 13259, 26188, 3411, 23379, 14422, 32215, 25689, 5465, 32473, 14553, 26846, 15711, 15714, 2404, 36068, 22119, 15721, 16237, 10733, 15728, 2929, 3954, 25587, 11511, 3836, 15870}\n",
      "dict_items([(\"Lemma('highly.r.01.highly')\", 1)])\n",
      "collecting tokens for  desirable\n",
      "indices:    {16129, 15496, 30097, 4242, 23954, 12059, 15644, 800, 11810, 30079, 2098, 22584, 1848, 31033, 26046, 7877, 25811, 22614, 31193, 1884, 25444, 1895, 24178, 12147, 1911, 1914, 2043, 14207}\n",
      "dict_items([(\"Lemma('desirable.a.01.desirable')\", 16)])\n",
      "collecting tokens for  recreation\n",
      "indices:    {25217, 1889, 1859, 11909, 1830, 1862, 15174, 1865, 11881, 24039, 1836, 1839, 1813, 1847, 1880, 32506, 28637, 1823}\n",
      "dict_items([(\"Lemma('diversion.n.01.recreation')\", 13)])\n",
      "collecting tokens for  stevie\n",
      "indices:    {6405}\n",
      "dict_items([(\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  shouting\n",
      "indices:    {35585, 35717, 28422, 6925, 143, 35601, 26648, 19866, 23964, 8990, 6047, 31394, 35490, 6953, 19889, 11195, 6342, 5837, 24659, 35552, 6885, 8698}\n",
      "dict_items([(\"Lemma('shout.v.01.shout')\", 8), (\"Lemma('cheering.n.01.shouting')\", 2), (\"Lemma('yelling.n.01.shouting')\", 1), (\"Lemma('shout.v.02.shout')\", 10)])\n",
      "collecting tokens for  threw\n",
      "indices:    {23186, 34579, 26772, 8341, 10899, 7831, 19867, 34460, 8355, 17575, 9003, 18219, 10552, 36540, 18237, 6208, 202, 33613, 207, 27475, 19796, 10969, 605, 5088, 12897, 35942, 9704, 5101, 24302, 36850, 19570, 19830, 6905, 34175}\n",
      "dict_items([(\"Lemma('throw.v.01.throw')\", 17), (\"Lemma('bewilder.v.02.throw')\", 1), (\"Lemma('throw.v.02.throw')\", 2), (\"Lemma('give.v.07.throw')\", 1), (\"Lemma('shed.v.01.throw')\", 1), (\"Lemma('discard.v.01.throw_out')\", 1), (\"Lemma('throw.v.06.throw')\", 1), (\"Lemma('advance.v.02.throw_out')\", 1), (\"Lemma('project.v.10.throw')\", 1), (\"Lemma('hold.v.03.throw')\", 1)])\n",
      "collecting tokens for  smart\n",
      "indices:    {5602, 9026, 12004, 9253, 18435, 8937, 14449, 37140, 16565, 16504, 36540, 9021, 33662}\n",
      "dict_items([(\"Lemma('smart.a.01.smart')\", 5), (\"Lemma('fresh.s.12.smart')\", 2), (\"Lemma('chic.s.01.smart')\", 1)])\n",
      "collecting tokens for  wide\n",
      "indices:    {34821, 19210, 35348, 1557, 18966, 18714, 10655, 4398, 21811, 1983, 28362, 35537, 11352, 26077, 3177, 30700, 30831, 5231, 17522, 26867, 19570}\n",
      "dict_items([(\"Lemma('wide.a.01.wide')\", 5), (\"Lemma('wide.r.02.wide')\", 1), (\"Lemma('across-the-board.s.01.wide')\", 2), (\"Lemma('wide.r.01.wide')\", 3), (\"Lemma('wide-eyed.s.02.wide')\", 1)])\n",
      "collecting tokens for  street\n",
      "indices:    {34029, 7822, 17926}\n",
      "dict_items([])\n",
      "collecting tokens for  officers\n",
      "indices:    {12609, 12595, 5275, 20975}\n",
      "dict_items([(\"Lemma('officeholder.n.01.officer')\", 1), (\"Lemma('military_officer.n.01.officer')\", 2)])\n",
      "collecting tokens for  ballistic\n",
      "indices:    {14827}\n",
      "dict_items([])\n",
      "collecting tokens for  missile\n",
      "indices:    {28521, 14827, 28513}\n",
      "dict_items([])\n",
      "collecting tokens for  successful\n",
      "indices:    {15765, 37142, 14999, 15784, 15785, 4778, 37167, 5424, 14772, 11061, 28603, 21821, 14536, 13256, 25547, 13268, 1240, 22755, 4195, 22374, 14312, 26729, 24429, 9331, 11896, 32890, 11387, 14334}\n",
      "dict_items([(\"Lemma('successful.a.01.successful')\", 18)])\n",
      "collecting tokens for  quickly\n",
      "indices:    {18946, 19842, 35076, 17548, 18963, 22935, 16279, 19877, 2607, 31290, 9789, 36287, 31679, 26695, 16845, 27854, 19919, 15186, 18519, 15832, 30173, 31071, 12896, 30049, 9961, 11512}\n",
      "dict_items([(\"Lemma('quickly.r.01.quickly')\", 7), (\"Lemma('promptly.r.01.quickly')\", 9)])\n",
      "collecting tokens for  ran\n",
      "indices:    {25604, 21511, 36367, 7187, 36374, 1059, 6187, 23090, 35383, 6208, 12876, 12878, 6734, 6223, 35924, 18519, 10328, 35419, 18528, 35941, 2672, 8818, 19061, 19063, 7810, 7811, 17539, 7817, 19085, 18583, 24731, 13468, 31392, 8865, 31394, 31397, 18093, 18099, 34996, 18153, 5868, 19181, 6390, 18680, 20738, 13062, 264, 7950, 21264, 10002, 24345, 22299, 6952, 36139, 8499, 6466, 324, 36688, 18258, 19794, 6491, 12636, 9054, 353, 16738, 33638, 8557, 18286, 29042, 31612, 10108, 19837, 10640, 6558, 5041, 12734, 17389, 9201, 36852, 9212}\n",
      "dict_items([(\"Lemma('run.v.01.run')\", 26), (\"Lemma('prevail.v.03.run')\", 1), (\"Lemma('run.v.03.run')\", 7), (\"Lemma('run.v.21.run')\", 1), (\"Lemma('operate.v.01.run')\", 2), (\"Lemma('run.v.05.run')\", 2), (\"Lemma('run.v.14.run')\", 1), (\"Lemma('function.v.01.run')\", 1), (\"Lemma('run.v.06.run')\", 1), (\"Lemma('run.v.29.run')\", 1), (\"Lemma('range.v.01.run')\", 1), (\"Lemma('guide.v.05.run')\", 2), (\"Lemma('run.v.15.run')\", 1), (\"Lemma('chase_away.v.01.run_off')\", 1)])\n",
      "collecting tokens for  trouble\n",
      "indices:    {20096, 12162, 1541, 12933, 20233, 16527, 13969, 16785, 12689, 19601, 13717, 13208, 24865, 18474, 35374, 7992, 16954, 27202, 8393, 5706, 89, 16475, 16476, 988, 7657, 8191, 19825, 17010, 34935, 12408, 18170, 36475, 383}\n",
      "dict_items([(\"Lemma('fuss.n.02.trouble')\", 8), (\"Lemma('trouble.n.04.trouble')\", 4), (\"Lemma('trouble.n.01.trouble')\", 7), (\"Lemma('trouble.n.03.trouble')\", 3)])\n",
      "collecting tokens for  bill\n",
      "indices:    {10618, 142, 24970}\n",
      "dict_items([(\"Lemma('person.n.01.person')\", 1), (\"Lemma('bill.n.01.bill')\", 1)])\n",
      "collecting tokens for  experiments\n",
      "indices:    {31136, 5026, 31106, 32071, 21705, 26827, 4237, 11406, 3278, 3279, 11508, 3260}\n",
      "dict_items([(\"Lemma('experiment.n.01.experiment')\", 3), (\"Lemma('experiment.n.03.experiment')\", 1), (\"Lemma('experiment.n.02.experiment')\", 3)])\n",
      "collecting tokens for  bullets\n",
      "indices:    {5058, 12614, 35435, 12891, 30268}\n",
      "dict_items([(\"Lemma('bullet.n.01.bullet')\", 3)])\n",
      "collecting tokens for  placed\n",
      "indices:    {27664, 3088, 22554, 36890, 29222, 31275, 11308, 18480, 11826, 1079, 16442, 23620, 35413, 14426, 11358, 29792, 13922, 4202, 28272, 9328, 32370, 25204, 8825, 31354, 8829, 11402, 26251, 21646, 2709, 13980, 8865, 32929, 32931, 13993, 34991, 29873, 9394, 23218, 5816, 19131, 28863, 32963, 25286, 714, 28879, 26833, 5848, 12000, 15074, 25326, 5360, 20724, 1783, 14073, 31481, 27897, 15102, 14080, 20749, 5402, 31014, 31016, 32563, 4925, 30040, 2911, 29024, 15731, 20341, 36736, 28032, 29059, 25475, 24970, 19342, 33679, 18832, 2960, 32673, 22434, 31139, 28065, 28581, 28589, 28590, 1968, 19378, 32179, 16318, 14785, 19905, 32714, 1997, 28624, 3540, 5078, 31190, 22490, 12772, 21484, 15353, 15356}\n",
      "dict_items([(\"Lemma('put.v.01.place')\", 26), (\"Lemma('locate.v.03.place')\", 1), (\"Lemma('rate.v.01.place')\", 2), (\"Lemma('place.v.02.place')\", 8), (\"Lemma('place.v.05.place')\", 1), (\"Lemma('target.v.01.place')\", 1), (\"Lemma('place.v.11.place')\", 1), (\"Lemma('place.v.06.place')\", 2), (\"Lemma('identify.v.01.place')\", 1)])\n",
      "collecting tokens for  bull\n",
      "indices:    {29059, 9705, 26859, 10317, 561, 6675, 30555, 12028, 1725}\n",
      "dict_items([(\"Lemma('bull.n.01.bull')\", 1), (\"Lemma('bull.v.01.bull')\", 1), (\"Lemma('bull.n.02.bull')\", 1), (\"Lemma('bullshit.n.01.bull')\", 1)])\n",
      "collecting tokens for  yards\n",
      "indices:    {288, 353, 354, 290, 356, 355, 5090, 9633, 289, 6090, 20940, 33776, 27956, 29078, 18297, 18716, 7935}\n",
      "dict_items([(\"Lemma('yard.n.01.yard')\", 10), (\"Lemma('yard.n.02.yard')\", 2), (\"Lemma('yard.n.03.yard')\", 1)])\n",
      "collecting tokens for  stray\n",
      "indices:    {13824, 29059, 23689, 8748, 16590, 6063, 7887, 35963}\n",
      "dict_items([(\"Lemma('roll.v.12.stray')\", 2), (\"Lemma('isolated.s.01.stray')\", 2), (\"Lemma('stray.n.01.stray')\", 1)])\n",
      "collecting tokens for  cutting\n",
      "indices:    {22689, 4131, 28835, 28837, 29766, 28839, 29830, 29898, 29899, 29066, 29902, 29904, 17904, 22836, 20662, 11388}\n",
      "dict_items([(\"Lemma('cut.v.01.cut')\", 4), (\"Lemma('interrupt.v.01.cut_off')\", 1), (\"Lemma('cut.n.17.cutting')\", 1)])\n",
      "collecting tokens for  fingers\n",
      "indices:    {13572, 18822, 8075, 10510, 8211, 9491, 27927, 34074, 8604, 8609, 6436, 8356, 26790, 9136, 8887, 7101, 6976, 36420, 10571, 17100, 30801, 29906, 1618, 31828, 2005, 24533, 10592, 31843, 30693, 8422, 18917, 18408, 19566, 26607, 34929, 5622, 18425, 29563, 9852}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('finger.n.01.finger')\", 26)])\n",
      "collecting tokens for  maybe\n",
      "indices:    {34217}\n",
      "dict_items([])\n",
      "collecting tokens for  alexander\n",
      "indices:    {20669}\n",
      "dict_items([])\n",
      "collecting tokens for  answer\n",
      "indices:    {13313, 13827, 25098, 23050, 31252, 5656, 19997, 35873, 6691, 6711, 15421, 15422, 15434, 20042, 34894, 15971, 15981, 5230, 5231, 15984, 14962, 22642, 11893, 34434, 31364, 10387, 18068, 7317, 23705, 32417, 13474, 6827, 13999, 27323, 24774, 18640, 13021, 22758, 1259, 28915, 14583, 22775, 23811, 21767, 2312, 24330, 779, 4875, 4890, 16172, 21813, 4919, 4920, 27964, 18750, 6976, 28481, 24899, 4932, 8007, 10568, 10579, 25939, 33623, 30554, 17760, 30565, 16742, 24935, 10087, 19305, 12653, 9581, 8048, 19826, 31090, 8058, 17801, 24466, 33687, 33689, 30629, 25511, 25522, 12216, 11196, 27582, 21954, 10695, 20423, 33752, 16856, 985, 15331, 24549, 15334, 9191, 11241, 5100, 32237, 2557}\n",
      "dict_items([(\"Lemma('solution.n.02.answer')\", 15), (\"Lemma('answer.v.01.answer')\", 20), (\"Lemma('answer.v.03.answer')\", 3), (\"Lemma('answer.n.03.answer')\", 9), (\"Lemma('answer.n.01.answer')\", 21), (\"Lemma('answer.v.05.answer')\", 1), (\"Lemma('answer.v.04.answer')\", 3), (\"Lemma('answer.v.02.answer')\", 1)])\n",
      "collecting tokens for  properly\n",
      "indices:    {21384, 5388, 5265, 1690, 26267, 18716, 2842, 2334, 24991, 25381, 29222, 1704, 12200, 32297, 14649, 25018, 29373, 28861, 25022, 28736, 25025, 17989, 721, 723, 14178, 30181, 25581, 12270, 20085, 17782, 32630}\n",
      "dict_items([(\"Lemma('properly.r.01.properly')\", 15)])\n",
      "collecting tokens for  gradually\n",
      "indices:    {2592, 24675, 20293, 15852, 11278, 24183, 33084, 6045, 10590}\n",
      "dict_items([(\"Lemma('gradually.r.01.gradually')\", 5)])\n",
      "collecting tokens for  rhythmic\n",
      "indices:    {26432, 24353, 26441, 34090, 34734, 14552}\n",
      "dict_items([(\"Lemma('rhythmical.a.01.rhythmic')\", 1)])\n",
      "collecting tokens for  emphasis\n",
      "indices:    {25608, 16399, 5011, 16405, 27542, 5656, 27548, 31905, 22434, 27554, 28065, 32934, 690, 23218, 23096, 32568, 16314, 20281, 16318, 12222, 1734, 32714, 26571, 14667, 1867, 26957, 27214, 13387, 32977, 1362, 472, 1501, 16355, 31847, 15463, 31977, 26220, 14060, 2294, 1783, 14840, 4602, 1787, 24189, 2302}\n",
      "dict_items([(\"Lemma('emphasis.n.01.emphasis')\", 18), (\"Lemma('vehemence.n.01.emphasis')\", 5), (\"Lemma('emphasis.n.03.emphasis')\", 1)])\n",
      "collecting tokens for  slightly\n",
      "indices:    {11296, 35556, 29640, 22063, 32439, 8504, 29881, 3903}\n",
      "dict_items([(\"Lemma('slightly.r.01.slightly')\", 3)])\n",
      "collecting tokens for  modified\n",
      "indices:    {31905, 21731, 14819, 14087, 4009, 3004, 3058, 32978, 31290, 14138}\n",
      "dict_items([(\"Lemma('modified.a.01.modified')\", 1), (\"Lemma('modify.v.01.modify')\", 7), (\"Lemma('limited.s.04.modified')\", 1)])\n",
      "collecting tokens for  transferred\n",
      "indices:    {26505, 20363, 12812, 31905, 33059, 2857, 33068, 2864, 2865, 5172, 10688, 2885, 2888, 34251, 32332, 32337, 8025, 3035, 32361, 3562}\n",
      "dict_items([(\"Lemma('transfer.v.04.transfer')\", 3), (\"Lemma('transfer.v.01.transfer')\", 5), (\"Lemma('transplant.v.01.transfer')\", 6), (\"Lemma('transfer.v.02.transfer')\", 5), (\"Lemma('transfer.v.05.transfer')\", 1)])\n",
      "collecting tokens for  become\n",
      "indices:    {21003, 3084, 23571, 11283, 13333, 14358, 25109, 27670, 3606, 30746, 4630, 16409, 23575, 4641, 23586, 27684, 34343, 31271, 33319, 31275, 31788, 27692, 24622, 13872, 23600, 51, 3636, 13364, 31286, 564, 20024, 31802, 6203, 1597, 8253, 22592, 20035, 8260, 13383, 3656, 31820, 20045, 10833, 36948, 32340, 20052, 11863, 28249, 32346, 33370, 10845, 24160, 6752, 1634, 13922, 23651, 6755, 9318, 22626, 10856, 26730, 26732, 26228, 32373, 31348, 31866, 13946, 29821, 30333, 25725, 1664, 6783, 8324, 27780, 26758, 12936, 28301, 3213, 28815, 5776, 15509, 1687, 32922, 34458, 15516, 26269, 6814, 27293, 27292, 31905, 13983, 27291, 1695, 1193, 25257, 15531, 27307, 22701, 11949, 26796, 29872, 20658, 36022, 12984, 14009, 12472, 6843, 14524, 1215, 24773, 12498, 28883, 27863, 16090, 13028, 12517, 2793, 26858, 27369, 22764, 3311, 8431, 22770, 1275, 25339, 2300, 6907, 12543, 2303, 23807, 25349, 12040, 17162, 5388, 1806, 5391, 29970, 10514, 5398, 12056, 5402, 12059, 1310, 5407, 2335, 20255, 29988, 12068, 20776, 27128, 1325, 25393, 1331, 4919, 15164, 27641, 32064, 32065, 19781, 31046, 1861, 25422, 335, 25433, 24922, 33115, 20315, 24925, 24418, 25445, 31078, 31077, 35688, 30703, 4975, 25969, 12147, 4982, 11638, 4984, 9590, 29558, 13174, 13693, 33153, 31618, 14212, 15236, 7046, 26502, 904, 2444, 34702, 31633, 22932, 31637, 20374, 14229, 30106, 1952, 28577, 23459, 31654, 22443, 15788, 11693, 30635, 20395, 18868, 1976, 7612, 29628, 15806, 1471, 1472, 1479, 3016, 21962, 17356, 11724, 15824, 10707, 23510, 28631, 31192, 24535, 34778, 32220, 27616, 23522, 996, 13797, 20456, 16361, 15849, 30699, 15851, 33272, 31213, 26095, 1008, 4586, 15858, 3570, 3060, 15861, 15859, 15863, 27640, 4601, 5618, 31228}\n",
      "dict_items([(\"Lemma('become.v.02.become')\", 26), (\"Lemma('become.v.01.become')\", 26), (\"Lemma('become.v.03.become')\", 2)])\n",
      "collecting tokens for  arms\n",
      "indices:    {907, 29965, 25488, 29072, 2070, 31390, 31394, 9132, 31281, 6450, 25269, 35131, 33213, 17600, 1989, 6218, 13003, 27473, 6355, 10068, 33236, 11872, 7648, 33890, 23650, 9578, 7021, 36718, 35311, 29042, 19570, 14971, 8573}\n",
      "dict_items([(\"Lemma('arm.n.01.arm')\", 12), (\"Lemma('weaponry.n.01.arms')\", 2)])\n",
      "collecting tokens for  goes\n",
      "indices:    {27904, 29186, 22786, 260, 1020, 30227, 24084, 2708, 28700, 18077, 11424, 29473, 30242, 37, 27045, 15398, 10412, 30636, 13487, 24248, 29120, 14657, 35452, 14532, 14023, 713, 14153, 23500, 31308, 22732, 13391, 27857, 24786, 24147, 34515, 12762, 15359, 6749, 28258, 3685, 742, 13413, 34662, 29031, 30442, 24810, 32239, 29429, 19062, 3191, 26108, 24447}\n",
      "dict_items([(\"Lemma('run.v.05.go')\", 6), (\"Lemma('run.v.03.go')\", 5), (\"Lemma('die.v.01.go')\", 1), (\"Lemma('travel.v.01.go')\", 7), (\"Lemma('go_far.v.02.go_deep')\", 1), (\"Lemma('continue.v.01.go_on')\", 1), (\"Lemma('go.v.02.go')\", 1), (\"Lemma('descend.v.01.go_down')\", 1)])\n",
      "collecting tokens for  completion\n",
      "indices:    {3911}\n",
      "dict_items([])\n",
      "collecting tokens for  mark\n",
      "indices:    {853}\n",
      "dict_items([])\n",
      "collecting tokens for  silent\n",
      "indices:    {6787, 8079, 19988, 10262, 17048, 5912, 10527, 35873, 22435, 18084, 8870, 6057, 31276, 11059, 9653, 8509, 28103, 35015, 8905, 17611, 35293, 7903, 2409, 7017, 35820, 15853, 7407, 5877, 33782, 36856, 5628, 7293}\n",
      "dict_items([(\"Lemma('silent.s.01.silent')\", 16), (\"Lemma('mum.s.01.silent')\", 5)])\n",
      "collecting tokens for  pace\n",
      "indices:    {4997, 26893, 26512, 15507, 1176, 28956, 6941, 34333, 15391, 4642, 21922, 32677, 28966, 28971, 26668, 28981, 28984, 13373, 8905, 9930, 36828, 20575, 17760, 29025, 30818, 30816, 20837, 29034, 26734, 33142, 247, 35195, 31231}\n",
      "dict_items([(\"Lemma('footstep.n.03.pace')\", 2), (\"Lemma('pace.n.03.pace')\", 4), (\"Lemma('pace.n.01.pace')\", 4), (\"Lemma('pace.v.01.pace')\", 1), (\"Lemma('pace.v.02.pace')\", 3)])\n",
      "collecting tokens for  dirty\n",
      "indices:    {34698, 6035, 17018, 18489, 6586}\n",
      "dict_items([(\"Lemma('dirty.a.02.dirty')\", 2), (\"Lemma('dirty.a.01.dirty')\", 1), (\"Lemma('dirty.s.03.dirty')\", 1)])\n",
      "collecting tokens for  coming\n",
      "indices:    {19460, 33541, 1670, 7047, 19846, 7045, 20106, 6536, 9996, 14991, 33809, 22162, 21014, 20379, 18845, 25759, 22049, 25378, 10147, 23457, 13601, 26534, 19879, 20902, 1449, 21802, 936, 25004, 20658, 822, 27640, 6584, 28986, 6331, 21817, 23101, 21950, 29374, 319, 23672, 9661, 10822, 31433, 33482, 23883, 35153, 17491, 33365, 6104, 35673, 10330, 33885, 14941, 7775, 34273, 15846, 9191, 24552, 27497, 27498, 17255, 28393, 12410, 14958, 111, 31082, 17778, 27635, 33270, 36582, 9208, 10362, 8827, 7549}\n",
      "dict_items([(\"Lemma('come.v.01.come')\", 21), (\"Lemma('arrive.v.01.come')\", 9), (\"Lemma('approaching.s.01.coming')\", 1), (\"Lemma('come.v.04.come')\", 1), (\"Lemma('come.v.03.come')\", 3), (\"Lemma('come.v.09.come')\", 2), (\"Lemma('fall.v.04.come')\", 1), (\"Lemma('come.v.05.come')\", 1), (\"Lemma('approach.n.02.coming')\", 1), (\"Lemma('advent.n.01.coming')\", 1), (\"Lemma('come.v.16.come')\", 1)])\n",
      "collecting tokens for  sudden\n",
      "indices:    {2176, 34566, 397, 12060, 17056, 8865, 34093, 35248, 22205, 16968, 8905, 33482, 2647, 34778, 19419, 30062, 18170, 17019, 7804, 893}\n",
      "dict_items([(\"Lemma('sudden.a.01.sudden')\", 13)])\n",
      "collecting tokens for  instant\n",
      "indices:    {6919, 8843, 31373, 34461, 5410, 17574, 31402, 17707, 7100, 8508, 8905, 33866, 34764, 9807, 17746, 25556, 9174, 7003, 12892, 9181, 2654, 33764, 31341, 13550, 9327, 33791}\n",
      "dict_items([(\"Lemma('blink_of_an_eye.n.01.instant')\", 10), (\"Lemma('moment.n.01.instant')\", 7)])\n",
      "collecting tokens for  ground\n",
      "indices:    {31488, 14721, 8581, 8711, 34569, 35594, 30476, 16524, 34573, 18834, 8594, 6932, 23317, 15122, 35988, 21660, 20252, 31390, 33695, 23328, 23330, 18723, 31396, 13604, 31397, 28964, 18348, 25775, 35248, 15154, 23091, 30004, 23863, 27831, 18361, 6331, 30523, 31293, 12476, 3654, 10317, 10449, 6998, 6999, 31576, 26840, 14042, 34522, 35294, 3679, 9311, 29536, 35806, 35556, 11108, 15206, 30438, 10470, 13546, 12779, 1898, 10603, 7530, 8687, 30576, 34033, 12784, 8691, 499, 6645, 30582, 7927, 21242, 31487}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('crunch.v.02.grind')\", 2), (\"Lemma('land.n.04.ground')\", 24), (\"Lemma('earth.n.02.ground')\", 4), (\"Lemma('grate.v.04.grind')\", 2)])\n",
      "collecting tokens for  constructed\n",
      "indices:    {15104, 5121, 30215, 29973, 3863, 25116, 14751, 29856, 29863, 3888, 15665, 9394, 29373, 14845, 29379, 32709, 3913, 16205, 4432, 14804, 15210, 15211, 15100, 5501, 26494}\n",
      "dict_items([(\"Lemma('construct.v.01.construct')\", 18), (\"Lemma('manufacture.v.01.construct')\", 3)])\n",
      "collecting tokens for  concrete\n",
      "indices:    {15137, 3719, 15208, 31882, 5418, 15119, 15087, 15089, 22611, 15092, 1236, 15094, 10552, 9145, 15103}\n",
      "dict_items([(\"Lemma('concrete.a.01.concrete')\", 2), (\"Lemma('concrete.n.01.concrete')\", 8)])\n",
      "collecting tokens for  floors\n",
      "indices:    {22144, 7618, 7619, 30695, 15210, 17579, 15473, 11409, 30195, 3446}\n",
      "dict_items([(\"Lemma('floor.n.02.floor')\", 2), (\"Lemma('floor.n.03.floor')\", 1), (\"Lemma('floor.n.01.floor')\", 3)])\n",
      "collecting tokens for  fallout\n",
      "indices:    {15108, 15111, 15115, 21775, 15120, 24977, 15124, 25376, 25378, 25386, 25130, 25262, 20911, 25393, 15158, 25398, 25401, 15163, 25404, 25407, 25410, 25413, 15202, 15205, 15210, 15212, 25071, 25075, 15095}\n",
      "dict_items([(\"Lemma('fallout.n.01.fallout')\", 10)])\n",
      "collecting tokens for  protection\n",
      "indices:    {15108, 23943, 15115, 15120, 24978, 15124, 23194, 8224, 34976, 30753, 25126, 25383, 28710, 28458, 25130, 32688, 18353, 15281, 25140, 19381, 15157, 25142, 7354, 15163, 25916, 23619, 35524, 12108, 12241, 1623, 15204, 35814, 15209, 15210, 15211, 15212, 22767, 15089, 15091, 22776, 9850, 12156, 2559}\n",
      "dict_items([(\"Lemma('protection.n.01.protection')\", 18), (\"Lemma('protective_covering.n.01.protection')\", 3), (\"Lemma('security.n.02.protection')\", 3)])\n",
      "collecting tokens for  ordinary\n",
      "indices:    {4515, 13637, 4549, 7306, 34027, 12718, 22574, 31536, 4561, 721, 6161, 21780, 12758, 4568, 30490}\n",
      "dict_items([(\"Lemma('ordinary.a.01.ordinary')\", 10)])\n",
      "collecting tokens for  basement\n",
      "indices:    {15137, 15205, 15206, 8327, 34216, 15207, 30125, 15183, 30127, 15154, 15124, 12663}\n",
      "dict_items([(\"Lemma('basement.n.01.basement')\", 9)])\n",
      "collecting tokens for  dwelling\n",
      "indices:    {28256, 15648, 15202, 14021, 15210, 15211, 5133, 14702, 2640, 5169}\n",
      "dict_items([(\"Lemma('dwelling.n.01.dwelling')\", 6), (\"Lemma('dwell_on.v.01.dwell_on')\", 1), (\"Lemma('brood.v.01.dwell')\", 1), (\"Lemma('dwell.v.02.dwell')\", 1)])\n",
      "collecting tokens for  film\n",
      "indices:    {33152, 23553, 6914, 2441, 25996, 26253, 2446, 26637, 2448, 3213, 14482, 1047, 9881, 26522, 34842, 21275, 37156, 37160, 11052, 37166, 20919, 324, 11082, 1105, 1106, 23550, 1111, 14550, 2396, 2400, 14819, 26227, 2420, 2423, 1019, 2430, 1023}\n",
      "dict_items([(\"Lemma('film.n.04.film')\", 3), (\"Lemma('film.v.01.film')\", 1), (\"Lemma('movie.n.01.film')\", 13), (\"Lemma('film.n.02.film')\", 5)])\n",
      "collecting tokens for  released\n",
      "indices:    {9601, 31368, 21268, 28437, 37154, 25378, 5037, 29887, 29888, 21702, 21461, 21336, 15717, 10601, 20330, 35314, 18930, 3955, 3959, 3960, 26619, 30077}\n",
      "dict_items([(\"Lemma('secrete.v.01.release')\", 3), (\"Lemma('publish.v.02.release')\", 3), (\"Lemma('let_go_of.v.01.release')\", 6), (\"Lemma('free.v.01.release')\", 3), (\"Lemma('free.v.05.release')\", 1), (\"Lemma('exhaust.v.05.release')\", 1), (\"Lemma('turn.v.08.release')\", 1)])\n",
      "collecting tokens for  forgotten\n",
      "indices:    {11104, 1380, 7428, 36319, 26027, 18064, 34321, 10420, 1302, 27094, 30106, 1151}\n",
      "dict_items([(\"Lemma('forget.v.01.forget')\", 7), (\"Lemma('forget.v.03.forget')\", 2)])\n",
      "collecting tokens for  increases\n",
      "indices:    {15489, 32556, 11534}\n",
      "dict_items([(\"Lemma('increase.v.02.increase')\", 1), (\"Lemma('increase.v.01.increase')\", 1), (\"Lemma('increase.n.02.increase')\", 1)])\n",
      "collecting tokens for  adjacent\n",
      "indices:    {24450, 36965, 5385, 2953, 4491, 4112, 4081, 4564, 33045}\n",
      "dict_items([(\"Lemma('adjacent.s.02.adjacent')\", 2), (\"Lemma('adjacent.s.01.adjacent')\", 4)])\n",
      "collecting tokens for  p\n",
      "indices:    {14023, 4564, 29039}\n",
      "dict_items([])\n",
      "collecting tokens for  silence\n",
      "indices:    {9187, 35203, 1060, 33554, 13587, 36025}\n",
      "dict_items([(\"Lemma('silence.n.02.silence')\", 3)])\n",
      "collecting tokens for  taste\n",
      "indices:    {12039, 1707, 16685, 27407, 26419, 26361, 30394, 31578}\n",
      "dict_items([(\"Lemma('taste.n.01.taste')\", 2), (\"Lemma('taste.n.04.taste')\", 1), (\"Lemma('taste.v.01.taste')\", 1), (\"Lemma('sample.v.01.taste')\", 1)])\n",
      "collecting tokens for  mama\n",
      "indices:    {9304}\n",
      "dict_items([(\"Lemma('ma.n.01.mama')\", 1)])\n",
      "collecting tokens for  riverside\n",
      "indices:    {19892}\n",
      "dict_items([(\"Lemma('location.n.01.location')\", 1)])\n",
      "collecting tokens for  pitcher\n",
      "indices:    {23072, 19874, 227, 19878, 19880, 19883, 588, 427, 19885, 7857, 24468, 19864, 19867}\n",
      "dict_items([(\"Lemma('pitcher.n.02.pitcher')\", 1), (\"Lemma('pitcher.n.01.pitcher')\", 9)])\n",
      "collecting tokens for  ball\n",
      "indices:    {288, 22979, 19907, 6570, 555, 18540, 24463, 20913, 19793, 19796, 661, 405, 343, 19867, 348, 9661}\n",
      "dict_items([(\"Lemma('ball.n.01.ball')\", 9), (\"Lemma('ball.n.06.ball')\", 1)])\n",
      "collecting tokens for  petitioner\n",
      "indices:    {15296}\n",
      "dict_items([(\"Lemma('petitioner.n.01.petitioner')\", 1)])\n",
      "collecting tokens for  entitled\n",
      "indices:    {26113, 26116, 13830, 26119, 15369, 26121, 24203, 14863, 15376, 15638, 11801, 15643, 14877, 14878, 6943, 14881, 22051, 5284, 14761, 31661, 24882, 14899, 15294, 15296, 11857, 27220, 25817, 22106, 11483, 5598, 26463, 1378, 26979, 25063, 32360, 26345, 15593, 32496, 1393, 881, 32758, 32504, 32763, 27261}\n",
      "dict_items([(\"Lemma('entitle.v.01.entitle')\", 13), (\"Lemma('entitle.v.02.entitle')\", 6), (\"Lemma('entitled.s.01.entitled')\", 11)])\n",
      "collecting tokens for  inspect\n",
      "indices:    {15296, 12734, 10955, 11004, 13086, 1823}\n",
      "dict_items([(\"Lemma('inspect.v.01.inspect')\", 5), (\"Lemma('visit.v.04.inspect')\", 1)])\n",
      "collecting tokens for  fbi\n",
      "indices:    {23327}\n",
      "dict_items([])\n",
      "collecting tokens for  proceedings\n",
      "indices:    {5279, 34757, 15303, 15369, 14858, 26379, 15246, 26261, 26615, 21178, 15292, 36989, 20159}\n",
      "dict_items([(\"Lemma('proceeding.n.01.proceedings')\", 5), (\"Lemma('proceeding.n.01.proceeding')\", 1)])\n",
      "collecting tokens for  hearing\n",
      "indices:    {15360, 15362, 15364, 21252, 19974, 15366, 137, 15242, 31116, 7695, 14864, 14863, 19734, 19494, 19495, 20787, 15289, 15292, 15294, 15296, 15303, 15304, 21962, 21963, 21323, 27979, 16088, 18905, 91, 15324, 26975, 20707, 9188, 21605, 1384, 15336, 24177, 21489, 15350, 15357}\n",
      "dict_items([(\"Lemma('hear.v.03.hear')\", 3), (\"Lemma('hearing.n.01.hearing')\", 7), (\"Lemma('hearing.n.02.hearing')\", 3), (\"Lemma('hear.v.01.hear')\", 10)])\n",
      "collecting tokens for  frightened\n",
      "indices:    {13024, 5472, 19202, 35588, 33669, 6245, 18439, 9608, 36682, 6346, 26539, 8045, 18190, 33583, 12371, 12407, 36030}\n",
      "dict_items([(\"Lemma('frighten.v.01.frighten')\", 2)])\n",
      "collecting tokens for  gaze\n",
      "indices:    {18852, 2119, 5031, 16524, 18029, 33583, 9360, 34962, 5781, 19416, 9179, 8446}\n",
      "dict_items([(\"Lemma('gaze.n.01.gaze')\", 6), (\"Lemma('gaze.v.01.gaze')\", 4)])\n",
      "collecting tokens for  counter\n",
      "indices:    {36483, 25604, 17676, 33679, 18320, 35737, 35741, 35746, 33700, 35756, 33581, 33583, 14255, 820, 35644, 12989, 35656, 7113, 9423, 33490, 35667, 35668, 33624, 35677, 33632, 34019, 35695, 11632, 35698}\n",
      "dict_items([(\"Lemma('anticipate.v.02.counter')\", 1), (\"Lemma('counter.n.01.counter')\", 3), (\"Lemma('counter.r.01.counter')\", 1), (\"Lemma('antagonistic.s.01.counter')\", 2), (\"Lemma('buffet.n.01.counter')\", 1)])\n",
      "collecting tokens for  began\n",
      "indices:    {11268, 30215, 30217, 7694, 10257, 18450, 1530, 18963, 35352, 36891, 18461, 12843, 36907, 30256, 8753, 10806, 30775, 12854, 5176, 30778, 16954, 21575, 30280, 10825, 35402, 22091, 10832, 26717, 35426, 15459, 33890, 7791, 31863, 24184, 30330, 35457, 23682, 4737, 9348, 13442, 7302, 35462, 7823, 23696, 26767, 31379, 23191, 6303, 6305, 35490, 28327, 5800, 9384, 9400, 30401, 10946, 7876, 4804, 4806, 30407, 12492, 7888, 30417, 14550, 11993, 18139, 29919, 6883, 31973, 5866, 9451, 9452, 5358, 23791, 5359, 26865, 13552, 31985, 28404, 25332, 2806, 6902, 26872, 21234, 26874, 12034, 32515, 28418, 32003, 35591, 12043, 12044, 16655, 20753, 28435, 9214, 33562, 16156, 7964, 5408, 35104, 21281, 19235, 6437, 21797, 23335, 19752, 23339, 18732, 14125, 33583, 9525, 5431, 18232, 10555, 22845, 22850, 6981, 21319, 33097, 25418, 18253, 30542, 18255, 22349, 35153, 21837, 2389, 21846, 21847, 17245, 21853, 21855, 17760, 19806, 1378, 17763, 35169, 27493, 19814, 21862, 33128, 16232, 30566, 24427, 34667, 33127, 31598, 23919, 22384, 31601, 22385, 33136, 20854, 31608, 31614, 7550, 33154, 35205, 19848, 8585, 31630, 28049, 17298, 8595, 8594, 9110, 22934, 6045, 6560, 21409, 10656, 6566, 5030, 17832, 22955, 22956, 22957, 19884, 9649, 35252, 8118, 5046, 16824, 22969, 21946, 12219, 18872, 16833, 27075, 5059, 12228, 1483, 21455, 15830, 7641, 23514, 5595, 5594, 477, 482, 29155, 34283, 29165, 17392, 35313, 26608, 32766, 19449, 25082, 8702}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('get_down.v.07.begin')\", 26), (\"Lemma('begin.v.02.begin')\", 14), (\"Lemma('begin.v.03.begin')\", 13), (\"Lemma('begin.v.04.begin')\", 1)])\n",
      "collecting tokens for  registered\n",
      "indices:    {23714, 33026, 25062, 43, 21099, 1392, 15312, 28690, 33491, 32308, 2742, 32439, 32440}\n",
      "dict_items([(\"Lemma('register.v.01.register')\", 5), (\"Lemma('file.v.01.register')\", 4), (\"Lemma('register.v.03.register')\", 1)])\n",
      "collecting tokens for  meanwhile\n",
      "indices:    {56, 21375, 22984, 31960}\n",
      "dict_items([(\"Lemma('meanwhile.r.01.meanwhile')\", 1)])\n",
      "collecting tokens for  congo\n",
      "indices:    {23240}\n",
      "dict_items([])\n",
      "collecting tokens for  sending\n",
      "indices:    {24137, 30874, 14027, 12613}\n",
      "dict_items([(\"Lemma('sending.n.01.sending')\", 2), (\"Lemma('transport.v.04.send')\", 1)])\n",
      "collecting tokens for  lumumba\n",
      "indices:    {23240}\n",
      "dict_items([])\n",
      "collecting tokens for  equipment\n",
      "indices:    {11905, 15489, 1542, 11910, 30089, 15756, 29712, 23442, 10260, 29461, 5145, 28699, 28701, 32413, 30623, 21282, 17827, 30116, 30121, 26027, 6956, 21550, 21297, 12978, 32179, 2739, 34741, 13242, 12091, 5178, 16316, 2753, 9799, 30410, 3404, 21199, 12112, 23761, 12114, 21843, 23764, 15186, 21206, 11351, 21847, 12761, 20315, 21853, 21856, 21857, 21986, 32353, 29539, 11749, 11622, 21862, 21992, 22761, 21865, 20066, 21989, 21993, 21870, 27121, 22005, 22006, 1784, 11898}\n",
      "dict_items([(\"Lemma('equipment.n.01.equipment')\", 26)])\n",
      "collecting tokens for  wars\n",
      "indices:    {23617, 32067, 26052, 35526, 2535, 25768, 2537, 7800, 26189, 27129, 31279, 19607, 4728, 23929, 5212, 23743}\n",
      "dict_items([(\"Lemma('war.n.02.war')\", 1), (\"Lemma('war.n.01.war')\", 4)])\n",
      "collecting tokens for  technicians\n",
      "indices:    {32751}\n",
      "dict_items([])\n",
      "collecting tokens for  threatening\n",
      "indices:    {32898, 1155, 18181, 23558, 25738, 18317, 20751, 7696, 21396, 33940, 14231, 26917, 34600, 26177, 5832, 27469, 13664, 23269, 13669, 33263, 27504, 21749}\n",
      "dict_items([(\"Lemma('baleful.s.02.threatening')\", 2), (\"Lemma('threaten.v.02.threaten')\", 8), (\"Lemma('endanger.v.01.threaten')\", 3), (\"Lemma('threaten.v.03.threaten')\", 2)])\n",
      "collecting tokens for  occasion\n",
      "indices:    {26628, 17925, 27144, 34831, 37138, 29983, 6442, 5303, 21306, 26173, 14014, 1727, 6852, 22600, 25930, 32209, 14931, 6868, 14932, 32214, 17879, 14938, 26716, 1250, 23269, 12645, 32240, 35699, 29944, 20858, 28157, 1151}\n",
      "dict_items([(\"Lemma('juncture.n.01.occasion')\", 6), (\"Lemma('occasion.n.03.occasion')\", 3), (\"Lemma('affair.n.03.occasion')\", 3)])\n",
      "collecting tokens for  openly\n",
      "indices:    {17931, 23947, 19343, 5649, 8472, 25752, 18211, 25763, 27303, 7721, 12976, 11445, 30775, 27704, 8250, 31810, 31822, 31825, 27862, 26849, 23269, 13036, 7407, 31988, 12667, 6140}\n",
      "dict_items([(\"Lemma('openly.r.01.openly')\", 13)])\n",
      "collecting tokens for  brooks\n",
      "indices:    {230}\n",
      "dict_items([])\n",
      "collecting tokens for  robinson\n",
      "indices:    {230}\n",
      "dict_items([])\n",
      "collecting tokens for  january\n",
      "indices:    {27266}\n",
      "dict_items([])\n",
      "collecting tokens for  1942\n",
      "indices:    {32323, 32326, 26024, 20585, 32266, 5203, 14934, 7964, 12223}\n",
      "dict_items([])\n",
      "collecting tokens for  organize\n",
      "indices:    {4737, 20325, 24158, 4751, 20304, 19572, 24693, 33013, 15704, 1244, 15869, 11902, 12223}\n",
      "dict_items([(\"Lemma('form.v.01.organize')\", 4), (\"Lemma('organize.v.04.organize')\", 2), (\"Lemma('mastermind.v.01.organize')\", 2), (\"Lemma('organize.v.02.organize')\", 3), (\"Lemma('unionize.v.02.organize')\", 1), (\"Lemma('organize.v.05.organize')\", 1)])\n",
      "collecting tokens for  eleven\n",
      "indices:    {32423, 25775, 16789, 14999, 27322}\n",
      "dict_items([(\"Lemma('eleven.s.01.eleven')\", 2)])\n",
      "collecting tokens for  spread\n",
      "indices:    {23981, 9423, 13329, 13043, 29531}\n",
      "dict_items([(\"Lemma('spread.n.01.spread')\", 1), (\"Lemma('spread.v.01.spread')\", 1), (\"Lemma('spread.v.03.spread')\", 1)])\n",
      "collecting tokens for  throughout\n",
      "indices:    {14048, 29729, 13059, 4996, 1125, 11718, 7653, 31528, 3657, 29835, 24057, 12206, 27760, 32628, 21557, 14838, 12921, 14748}\n",
      "dict_items([])\n",
      "collecting tokens for  nations\n",
      "indices:    {22595, 32648, 23852, 32685, 25081, 23918, 27732, 27737}\n",
      "dict_items([])\n",
      "collecting tokens for  attended\n",
      "indices:    {21379, 13065, 13196, 24723, 9365, 24350, 1439, 44, 21048, 12223, 11201, 21059, 22350, 2131, 32852, 20700, 6751, 32480, 25953, 20584, 25961, 20586, 33130, 1389, 22517, 506, 28539}\n",
      "dict_items([(\"Lemma('attend.v.01.attend')\", 26), (\"Lemma('attend.v.05.attend')\", 1)])\n",
      "collecting tokens for  representatives\n",
      "indices:    {142}\n",
      "dict_items([])\n",
      "collecting tokens for  organs\n",
      "indices:    {22627, 10279, 11406, 22738, 10098, 11413, 14167, 11803, 13660, 12223}\n",
      "dict_items([(\"Lemma('organ.n.01.organ')\", 4), (\"Lemma('organ.n.02.organ')\", 1)])\n",
      "collecting tokens for  including\n",
      "indices:    {26114, 516, 32267, 30221, 14864, 11282, 32302, 15426, 19522, 11338, 15438, 11862, 6745, 20059, 14942, 23648, 22627, 2150, 103, 14957, 4207, 4211, 11892, 24692, 24694, 15476, 25721, 29307, 3195, 11902, 32901, 36998, 4743, 31368, 24201, 3205, 32904, 25740, 23182, 656, 22163, 25751, 22168, 26779, 5275, 2717, 2736, 177, 25782, 16057, 17599, 711, 21706, 2766, 32474, 23262, 736, 225, 26340, 12516, 26858, 26862, 15598, 23281, 33016, 12027, 21759, 20227, 33028, 23301, 13066, 273, 32532, 29979, 16156, 21287, 5417, 11056, 22331, 25414, 15180, 14673, 22868, 22357, 23894, 14690, 21862, 33130, 22384, 26994, 15225, 21379, 27015, 2445, 14734, 3991, 33185, 21417, 12223, 20946, 5084, 12261, 27635, 14836, 1013, 6134, 16376, 7676, 26110}\n",
      "dict_items([(\"Lemma('include.v.01.include')\", 26), (\"Lemma('admit.v.03.include')\", 4), (\"Lemma('include.v.02.include')\", 11), (\"Lemma('include.v.03.include')\", 3)])\n",
      "collecting tokens for  minister\n",
      "indices:    {27290, 13076, 1430}\n",
      "dict_items([(\"Lemma('curate.n.01.minister')\", 1)])\n",
      "collecting tokens for  interior\n",
      "indices:    {4487, 35433, 4489, 14766, 18354, 4499, 2044, 2045}\n",
      "dict_items([(\"Lemma('inside.n.01.interior')\", 4)])\n",
      "collecting tokens for  justice\n",
      "indices:    {15296, 25036}\n",
      "dict_items([])\n",
      "collecting tokens for  stores\n",
      "indices:    {28416, 11661, 6031, 34328, 27175, 27176, 25005, 22063, 25014, 5452, 5454, 2382, 5465, 24026, 3424, 5475, 5477, 6117, 30964, 20341, 20732}\n",
      "dict_items([(\"Lemma('shop.n.01.store')\", 5)])\n",
      "collecting tokens for  downtown\n",
      "indices:    {23427, 21139, 21143, 34204, 5417, 21451, 5456, 21462, 5463, 5465, 5468, 5469, 5472, 5473, 6114, 5475, 36961, 24427, 23670, 23672, 12667, 17404}\n",
      "dict_items([(\"Lemma('business_district.n.01.downtown')\", 6), (\"Lemma('downtown.a.01.downtown')\", 6)])\n",
      "collecting tokens for  store\n",
      "indices:    {5466, 20059, 28711, 3655}\n",
      "dict_items([(\"Lemma('store.n.02.store')\", 1), (\"Lemma('shop.n.01.store')\", 1)])\n",
      "collecting tokens for  relative\n",
      "indices:    {2849, 14757, 23372, 3405, 3310, 25530, 28668}\n",
      "dict_items([(\"Lemma('relative.a.01.relative')\", 3), (\"Lemma('proportional.s.01.relative')\", 1)])\n",
      "collecting tokens for  suburban\n",
      "indices:    {21260, 12173, 21780, 15646, 1315, 22075, 5439, 13259, 37069, 5455, 13392, 5458, 5461, 5464, 12122, 5468, 5469, 11996, 5472, 5473, 5476, 5477, 5478, 9582, 26479, 5488, 13300, 30964}\n",
      "dict_items([(\"Lemma('suburban.a.01.suburban')\", 22)])\n",
      "collecting tokens for  branch\n",
      "indices:    {498, 1663}\n",
      "dict_items([(\"Lemma('branch.n.02.branch')\", 1)])\n",
      "collecting tokens for  sells\n",
      "indices:    {23072, 1760, 21862, 27175, 29387, 13229, 5455, 22001, 21842, 2232, 13533}\n",
      "dict_items([(\"Lemma('sell.v.02.sell')\", 3), (\"Lemma('sell.v.01.sell')\", 6), (\"Lemma('deal.v.06.sell')\", 2)])\n",
      "collecting tokens for  dry\n",
      "indices:    {34944, 31489, 29188, 29700, 35214, 37138, 31379, 34965, 10391, 30104, 5144, 13084, 13606, 31273, 31402, 29611, 29617, 25650, 11314, 11317, 16693, 29498, 12733, 29636, 1861, 36678, 19276, 5455, 7119, 19280, 36051, 29652, 19283, 9045, 5720, 29657, 29662, 3682, 5477, 36069, 29799, 34156, 19183, 10226, 33908, 30075, 29566}\n",
      "dict_items([(\"Lemma('dry.v.02.dry')\", 6), (\"Lemma('dry.a.01.dry')\", 11), (\"Lemma('dry.v.01.dry')\", 3), (\"Lemma('dry.s.02.dry')\", 1)])\n",
      "collecting tokens for  following\n",
      "indices:    {28711, 3279, 31027, 18615, 12890, 21180, 33374}\n",
      "dict_items([(\"Lemma('follow.v.01.follow')\", 3)])\n",
      "collecting tokens for  signs\n",
      "indices:    {4738, 34179, 24074, 34187, 5006, 35996, 17693, 17310, 1055, 9632, 21025, 18723, 5031, 4266, 27194, 11966, 35269, 23623, 28617, 29386, 32845, 16846, 13519, 29399, 24797, 4832, 25314, 20454, 25323, 21871, 4207, 24437}\n",
      "dict_items([(\"Lemma('sign.n.06.sign')\", 1), (\"Lemma('sign.n.01.sign')\", 9), (\"Lemma('sign.n.02.sign')\", 1), (\"Lemma('signboard.n.01.sign')\", 1), (\"Lemma('sign.v.02.sign')\", 1), (\"Lemma('signal.n.01.sign')\", 1)])\n",
      "collecting tokens for  greatest\n",
      "indices:    {10746, 14023}\n",
      "dict_items([(\"Lemma('great.s.02.great')\", 1)])\n",
      "collecting tokens for  collections\n",
      "indices:    {26784, 22691, 23145, 32554, 25229, 29399, 22139, 21630}\n",
      "dict_items([])\n",
      "collecting tokens for  array\n",
      "indices:    {31872, 5248, 11648, 14315, 24598, 29399, 29464, 21146}\n",
      "dict_items([(\"Lemma('array.n.01.array')\", 3)])\n",
      "collecting tokens for  silver\n",
      "indices:    {7392, 13121, 26008, 36679, 5032, 22072, 30506, 13132, 34095, 8848, 3249, 3250, 9523, 30359, 29272, 5692, 19550}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('silver.s.01.silver')\", 3), (\"Lemma('silver.n.01.silver')\", 1), (\"Lemma('flatware.n.02.silver')\", 1), (\"Lemma('silver.s.02.silver')\", 1)])\n",
      "collecting tokens for  dinner\n",
      "indices:    {10976, 21602, 1187, 6756, 22311, 2441, 10701, 16878, 20975, 6745, 27665, 37138, 629, 1113}\n",
      "dict_items([(\"Lemma('dinner.n.01.dinner')\", 7), (\"Lemma('dinner.n.02.dinner')\", 1)])\n",
      "collecting tokens for  refuse\n",
      "indices:    {17152, 9282, 35139, 25190, 5478, 33678, 28287, 6833, 5878, 1334, 27257, 25339, 25087}\n",
      "dict_items([(\"Lemma('refuse.v.01.refuse')\", 6), (\"Lemma('refuse.v.02.refuse')\", 5), (\"Lemma('defy.v.02.refuse')\", 1), (\"Lemma('garbage.n.01.refuse')\", 1)])\n",
      "collecting tokens for  beliefs\n",
      "indices:    {7904, 4705, 12289, 4674, 20825, 4713, 4683, 25367, 30770, 20819, 28564, 20820, 5783, 2328, 2297, 27545, 23867, 14078}\n",
      "dict_items([(\"Lemma('belief.n.01.belief')\", 4)])\n",
      "collecting tokens for  9\n",
      "indices:    {15618, 22407, 22408, 25225, 649, 27537, 3347, 24727, 28829, 2845, 15263, 15141, 16167, 296, 25003, 22956, 22446, 27567, 16176, 22448, 1074, 28211, 22959, 942, 12599, 15037, 22975, 3775, 25793, 22977, 22335, 22978, 11588, 22982, 13894, 3784, 20168, 587, 28875, 13261, 29517, 15312, 23638, 26328, 22616, 22749, 21091, 29924, 1636, 22374, 504, 13034, 15600, 21105, 26997, 15096, 15103}\n",
      "dict_items([(\"Lemma('nine.s.01.9')\", 13), (\"Lemma('ninth.n.01.ninth')\", 1), (\"Lemma('nine.n.01.9')\", 6)])\n",
      "collecting tokens for  body\n",
      "indices:    {34176, 7552, 22403, 17924, 11525, 23945, 34827, 34833, 11411, 27927, 2201, 16668, 34591, 12577, 2211, 32035, 35622, 10667, 11568, 1335, 4921, 1983, 11584, 1857, 6337, 2114, 32197, 31173, 25669, 8776, 29001, 23115, 8524, 27852, 32207, 8528, 1617, 28627, 4948, 4692, 11606, 6998, 25686, 26201, 15196, 21212, 5856, 7648, 4962, 865, 14055, 31464, 7530, 10603, 30828, 4845, 8814, 2799, 5104, 23788, 7794, 34035, 31864, 11386, 11260}\n",
      "dict_items([(\"Lemma('body.n.01.body')\", 24), (\"Lemma('torso.n.01.body')\", 3), (\"Lemma('consistency.n.01.body')\", 2), (\"Lemma('body.n.02.body')\", 2)])\n",
      "collecting tokens for  cromwell\n",
      "indices:    {19441}\n",
      "dict_items([(\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  large\n",
      "indices:    {24164, 27559, 26761, 17199, 11119, 28529, 28498, 25400, 7416, 24026, 29692, 767}\n",
      "dict_items([(\"Lemma('large.a.01.large')\", 4)])\n",
      "collecting tokens for  making\n",
      "indices:    {9729, 9731, 30734, 9747, 5145, 19485, 3614, 4640, 30241, 7715, 14886, 30760, 14890, 46, 28719, 29230, 8753, 26677, 30777, 30269, 9790, 13378, 30282, 23119, 1106, 23642, 26716, 23135, 26720, 27745, 21090, 7268, 102, 31339, 24178, 9849, 21630, 36993, 22661, 29830, 24711, 28814, 10895, 20640, 17582, 5297, 23734, 15549, 5319, 30924, 14032, 22737, 22736, 7379, 36570, 3293, 733, 14062, 11505, 31993, 4858, 13051, 15099, 23805, 4876, 30995, 6938, 24863, 36132, 18741, 33085, 17726, 32070, 4940, 21324, 4435, 21847, 31071, 21856, 28002, 5475, 34148, 9575, 36201, 13676, 31105, 7554, 14211, 24451, 6023, 23945, 12170, 6539, 29580, 21907, 35735, 21404, 14237, 16284, 32159, 20384, 32164, 34736, 15281, 949, 18870, 20405, 26038, 17347, 24014, 12239, 30675, 20956, 28642, 31211, 10742, 29179, 15359}\n",
      "dict_items([(\"Lemma('make.v.03.make')\", 20), (\"Lemma('make.v.02.make')\", 22), (\"Lemma('produce.v.02.make')\", 5), (\"Lemma('make.v.01.make')\", 26), (\"Lemma('draw.v.04.make')\", 3), (\"Lemma('stool.v.04.make')\", 1), (\"Lemma('induce.v.02.make')\", 2), (\"Lemma('make.v.19.make')\", 1), (\"Lemma('take.v.27.make')\", 1), (\"Lemma('make.v.08.make')\", 2), (\"Lemma('cause.v.01.make')\", 3), (\"Lemma('construct.v.01.make')\", 1), (\"Lemma('lay_down.v.01.make')\", 1), (\"Lemma('devising.n.01.making')\", 4), (\"Lemma('reach.v.07.make')\", 1), (\"Lemma('make.v.24.make')\", 1), (\"Lemma('have.v.17.make')\", 1)])\n",
      "collecting tokens for  direct\n",
      "indices:    {15493, 21906, 22681, 25753, 13978, 14623, 4650, 14251, 25903, 14773, 27711, 16323, 4292, 24899, 12872, 2895, 4192, 14050, 15726, 11509, 3702, 21242, 3324}\n",
      "dict_items([(\"Lemma('direct.v.01.direct')\", 1), (\"Lemma('direct.s.02.direct')\", 4), (\"Lemma('lead.v.01.direct')\", 1), (\"Lemma('direct.a.01.direct')\", 7), (\"Lemma('direct.a.03.direct')\", 1), (\"Lemma('conduct.v.02.direct')\", 1)])\n",
      "collecting tokens for  clearly\n",
      "indices:    {25441, 22786, 16865, 28157, 25893, 16137, 8811, 10606, 30831, 4976, 8381, 27130, 31101, 25439}\n",
      "dict_items([(\"Lemma('intelligibly.r.01.clearly')\", 2), (\"Lemma('clearly.r.01.clearly')\", 3), (\"Lemma('distinctly.r.01.clearly')\", 1)])\n",
      "collecting tokens for  distinctions\n",
      "indices:    {31904, 16129, 32994, 2371, 16041, 15818, 30838, 27801}\n",
      "dict_items([(\"Lemma('distinction.n.04.distinction')\", 2), (\"Lemma('differentiation.n.01.distinction')\", 2)])\n",
      "collecting tokens for  graph\n",
      "indices:    {4545, 4515, 4550, 4552, 4559, 4562, 4531, 2964, 4505, 4506, 4507, 4572, 4509, 15710}\n",
      "dict_items([(\"Lemma('graph.n.01.graph')\", 14)])\n",
      "collecting tokens for  achievement\n",
      "indices:    {15657, 21570, 14772}\n",
      "dict_items([(\"Lemma('accomplishment.n.01.achievement')\", 2)])\n",
      "collecting tokens for  scores\n",
      "indices:    {23648, 12289, 15712, 15685, 5157, 15657, 15697}\n",
      "dict_items([(\"Lemma('tons.n.01.scores')\", 2), (\"Lemma('mark.n.01.score')\", 4)])\n",
      "collecting tokens for  pacific\n",
      "indices:    {12706}\n",
      "dict_items([(\"Lemma('pacific.n.01.Pacific')\", 1)])\n",
      "collecting tokens for  northwest\n",
      "indices:    {21508, 23605}\n",
      "dict_items([])\n",
      "collecting tokens for  warsaw\n",
      "indices:    {7920}\n",
      "dict_items([(\"Lemma('warszawa.n.01.Warsaw')\", 1)])\n",
      "collecting tokens for  twice\n",
      "indices:    {23757}\n",
      "dict_items([])\n",
      "collecting tokens for  damned\n",
      "indices:    {31444, 34046}\n",
      "dict_items([])\n",
      "collecting tokens for  wall\n",
      "indices:    {7822}\n",
      "dict_items([])\n",
      "collecting tokens for  pope\n",
      "indices:    {25857}\n",
      "dict_items([])\n",
      "collecting tokens for  23\n",
      "indices:    {27266, 21635, 27013, 901, 21514, 29324, 27031, 28188, 27037, 27038, 27039, 27040, 929, 926, 32675, 22180, 27041, 26787, 28199, 32688, 21937, 4148, 15098, 27451, 4029, 22334, 32319, 20161, 5313, 21316, 3781, 20168, 20169, 5194, 20171, 3791, 3920, 21328, 25684, 25685, 3926, 24288, 23906, 12773, 11884, 622, 26991, 12912, 25457, 21874, 26998, 29690, 3451}\n",
      "dict_items([(\"Lemma('twenty-three.s.01.23')\", 8), (\"Lemma('twenty-three.n.01.23')\", 1)])\n",
      "collecting tokens for  council\n",
      "indices:    {24168}\n",
      "dict_items([])\n",
      "collecting tokens for  unity\n",
      "indices:    {10592, 1283, 1316, 20268, 1363}\n",
      "dict_items([(\"Lemma('integrity.n.01.unity')\", 3)])\n",
      "collecting tokens for  enthusiasm\n",
      "indices:    {4873, 34200, 31644, 22689, 10152, 42, 37037, 31678, 26949, 24649, 28499, 13268, 24533, 26218, 25457, 23284, 25461, 4598, 14078}\n",
      "dict_items([(\"Lemma('enthusiasm.n.03.enthusiasm')\", 3), (\"Lemma('exuberance.n.02.enthusiasm')\", 2), (\"Lemma('enthusiasm.n.01.enthusiasm')\", 1)])\n",
      "collecting tokens for  catholic\n",
      "indices:    {1385}\n",
      "dict_items([(\"Lemma('catholic.a.01.Catholic')\", 1)])\n",
      "collecting tokens for  protestant\n",
      "indices:    {1425}\n",
      "dict_items([(\"Lemma('protestant.a.01.Protestant')\", 1)])\n",
      "collecting tokens for  immediate\n",
      "indices:    {32896, 24193, 15490, 20227, 36997, 20614, 21637, 2312, 14599, 32906, 18699, 29070, 31889, 9362, 21395, 27796, 27797, 9747, 20376, 27545, 28062, 31263, 33056, 20261, 2091, 23086, 14382, 5042, 30009, 20412, 32192, 24055, 21958, 25548, 26966, 11352, 4316, 14174, 4958, 1248, 28131, 32228, 5223, 32875, 14956, 33259, 16751, 16635, 25457, 497, 10100, 15862, 15991, 22009, 22011, 32892, 25725, 32895}\n",
      "dict_items([(\"Lemma('immediate.s.04.immediate')\", 2), (\"Lemma('contiguous.s.01.immediate')\", 6), (\"Lemma('immediate.a.03.immediate')\", 3)])\n",
      "collecting tokens for  pleasure\n",
      "indices:    {6657, 2693, 13831, 7688, 27401, 28681, 13198, 28688, 24345, 18596, 14629, 32037, 28711, 36140, 11182, 31665, 34866, 9396, 11445, 27318, 11959, 1718, 11197, 31935, 11200, 11970, 34371, 7877, 34895, 11985, 30804, 28633, 35551, 31586, 34917, 10601, 30826, 22385, 23156, 13561}\n",
      "dict_items([(\"Lemma('pleasure.n.01.pleasure')\", 16), (\"Lemma('joy.n.02.pleasure')\", 3)])\n",
      "collecting tokens for  participate\n",
      "indices:    {22373, 25833, 27850, 31339, 26735, 14736, 14737, 32657, 27414, 14525, 31320, 25110, 30395, 32253}\n",
      "dict_items([(\"Lemma('participate.v.01.participate')\", 13), (\"Lemma('enter.v.02.participate')\", 1)])\n",
      "collecting tokens for  tribute\n",
      "indices:    {25346, 8355, 21922, 26405, 32011, 10554, 22512, 26128, 22546, 14931, 32628, 26709, 21495, 32247, 14938, 30939, 32253, 32222}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('tribute.n.01.tribute')\", 4)])\n",
      "collecting tokens for  speaker\n",
      "indices:    {32202}\n",
      "dict_items([])\n",
      "collecting tokens for  conjugate\n",
      "indices:    {4129, 4162, 4163, 4165, 4166, 4169, 4172, 4174, 4177, 4158}\n",
      "dict_items([(\"Lemma('conjugate_solution.n.01.conjugate')\", 10)])\n",
      "collecting tokens for  healthy\n",
      "indices:    {1674, 26635, 1934, 30484, 14231, 4125, 4126, 1604, 4165, 14923, 4175, 27728, 14163, 14164, 14167, 27100, 4192, 4193, 4194, 26598, 32873, 11885, 1906, 8569}\n",
      "dict_items([(\"Lemma('healthy.a.01.healthy')\", 14), (\"Lemma('healthy.s.02.healthy')\", 3), (\"Lemma('healthy.s.03.healthy')\", 1)])\n",
      "collecting tokens for  crown\n",
      "indices:    {4194, 21042, 4125, 2518, 4155, 28028, 4157}\n",
      "dict_items([(\"Lemma('crown.n.01.Crown')\", 1), (\"Lemma('crown.v.02.crown')\", 1)])\n",
      "collecting tokens for  clover\n",
      "indices:    {4192, 4193, 4194, 4132, 4165, 4198, 4164, 4175, 4149, 4151, 4126, 4125, 4158}\n",
      "dict_items([])\n",
      "collecting tokens for  tissues\n",
      "indices:    {4192, 4196, 4165, 3814, 3815, 4199, 36361, 36363, 19660, 36397, 4182, 4189}\n",
      "dict_items([(\"Lemma('tissue.n.01.tissue')\", 7), (\"Lemma('tissue.n.02.tissue')\", 1)])\n",
      "collecting tokens for  stained\n",
      "indices:    {4153, 4192, 3554, 3556, 3557, 18983, 10600, 4145, 4184, 11353, 4155, 4188, 4191}\n",
      "dict_items([(\"Lemma('stained.a.01.stained')\", 3), (\"Lemma('stain.v.01.stain')\", 8), (\"Lemma('stain.v.02.stain')\", 1), (\"Lemma('stained.s.02.stained')\", 1)])\n",
      "collecting tokens for  faint\n",
      "indices:    {7048, 27321, 10956, 18598}\n",
      "dict_items([(\"Lemma('faint.s.01.faint')\", 2), (\"Lemma('faint.s.03.faint')\", 1)])\n",
      "collecting tokens for  green\n",
      "indices:    {480, 7840, 19490, 11322, 6376, 13421, 22930, 29365, 4153, 4154, 23935}\n",
      "dict_items([(\"Lemma('green.s.01.green')\", 4)])\n",
      "collecting tokens for  easily\n",
      "indices:    {24448, 14464, 33670, 4102, 6280, 25354, 31114, 26252, 26253, 6027, 25483, 16147, 30075, 1427, 27671, 36637, 541, 31135, 7455, 30115, 25510, 24745, 1578, 26154, 15404, 28841, 27689, 29999, 1586, 18738, 4789, 15285, 19639, 8889, 29755, 23615, 29249, 3138, 26946, 29124, 4165, 29900, 30156, 4940, 28626, 16211, 32214, 4951, 26202, 30811, 23388, 8286, 26719, 14046, 11106, 30178, 28644, 4324, 16101, 6119, 4201, 28652, 14573, 23667, 24052, 31605, 26870, 16118, 29818, 34683, 30076}\n",
      "dict_items([(\"Lemma('easily.r.01.easily')\", 26), (\"Lemma('easily.r.02.easily')\", 3)])\n",
      "collecting tokens for  bright\n",
      "indices:    {13572, 36748, 21146, 26530, 26531, 11300, 2855, 36014, 33333, 4156, 31420, 26558, 36799, 7369, 12622, 29782, 3415, 16995, 5606, 27499, 31596, 14452, 1659, 17407}\n",
      "dict_items([(\"Lemma('bright.s.03.bright')\", 1), (\"Lemma('bright.a.01.bright')\", 5), (\"Lemma('bright.s.02.bright')\", 4), (\"Lemma('bright.s.04.bright')\", 1)])\n",
      "collecting tokens for  specific\n",
      "indices:    {33162, 3467, 5003, 16143, 15252, 23708, 5032, 4148, 1207, 16440, 4153, 4921, 11727, 4177, 31586, 2660, 4198, 29287, 32871, 3436, 32495, 32880, 24698, 31358}\n",
      "dict_items([(\"Lemma('specific.a.01.specific')\", 12), (\"Lemma('specific.s.02.specific')\", 3)])\n",
      "collecting tokens for  staining\n",
      "indices:    {4125, 4156, 4157, 4160, 4161, 4162, 4163, 4165, 4166, 4167, 4170, 4172, 4173, 4174, 4175, 4177, 4179, 4182, 4184, 4190, 4193, 4194, 4195, 4196, 4197, 4198, 4199}\n",
      "dict_items([(\"Lemma('staining.n.02.staining')\", 8), (\"Lemma('staining.n.01.staining')\", 19)])\n",
      "collecting tokens for  lord\n",
      "indices:    {27459, 30013}\n",
      "dict_items([])\n",
      "collecting tokens for  steering\n",
      "indices:    {19936, 17921, 21731, 32874, 34189, 34033, 33142, 33149}\n",
      "dict_items([(\"Lemma('steer.v.02.steer')\", 1), (\"Lemma('guide.v.03.steer')\", 1)])\n",
      "collecting tokens for  wheel\n",
      "indices:    {35970, 19282, 21434, 19230, 28671}\n",
      "dict_items([(\"Lemma('wheel.n.01.wheel')\", 2)])\n",
      "collecting tokens for  vacation\n",
      "indices:    {29824, 29825, 11777, 29316, 29319, 29325, 29326, 21006, 29332, 9241, 31642, 11929, 11935, 11936, 11942, 11944, 25010, 25012, 5685, 1205, 29241, 8890, 29244, 29246, 29248, 29252, 21575, 11854, 11855, 11856, 11857, 11858, 29267, 12130, 29295, 29297, 24694, 29820, 11774, 29311}\n",
      "dict_items([(\"Lemma('vacation.n.01.vacation')\", 16), (\"Lemma('vacation.v.01.vacation')\", 1)])\n",
      "collecting tokens for  shorter\n",
      "indices:    {835, 2600, 29736, 36686, 946}\n",
      "dict_items([(\"Lemma('short.a.01.short')\", 2), (\"Lemma('short.a.02.short')\", 1)])\n",
      "collecting tokens for  ultimate\n",
      "indices:    {27912, 31244, 23824, 10257, 31889, 8849, 921, 666, 32026, 12956, 14106, 16422, 15277, 4661, 23093, 14653, 34109, 23615, 27967, 30274, 12997, 21958, 4689, 4692, 4693, 27738, 4702, 9953, 31715, 3684, 3690, 2028, 15343, 12917, 24694, 26102, 4728, 27903}\n",
      "dict_items([(\"Lemma('ultimate.s.02.ultimate')\", 5), (\"Lemma('ultimate.a.01.ultimate')\", 17)])\n",
      "collecting tokens for  demand\n",
      "indices:    {27264, 27266, 20228, 16646, 13319, 24968, 35977, 12049, 11922, 22803, 21792, 16290, 23716, 16292, 1958, 6312, 1321, 21802, 22827, 32556, 22701, 11821, 16304, 5553, 26035, 1332, 14261, 1333, 2100, 24886, 11700, 22712, 11708, 1348, 26053, 22726, 27261, 1352, 1353, 23501, 22862, 16338, 2642, 1362, 16340, 16343, 11865, 31067, 32733, 32734, 22622, 37088, 29921, 22628, 25445, 22122, 2412, 21997, 25453, 25072, 22769, 2035, 24692, 4597, 24694, 27637, 22008, 11893, 24054, 16379, 892, 3829, 33022, 29183}\n",
      "dict_items([(\"Lemma('need.n.01.demand')\", 1), (\"Lemma('demand.n.04.demand')\", 3), (\"Lemma('necessitate.v.01.demand')\", 6), (\"Lemma('requirement.n.01.demand')\", 1), (\"Lemma('demand.n.01.demand')\", 13), (\"Lemma('demand.v.01.demand')\", 9), (\"Lemma('demand.n.02.demand')\", 8), (\"Lemma('demand.v.03.demand')\", 4)])\n",
      "collecting tokens for  cell\n",
      "indices:    {3072, 35849, 23184, 15890, 3090, 15892, 15894, 15895, 15896, 15900, 15901, 15906, 25120, 3616, 36897, 15907, 15908, 15909, 15910, 15911, 15912, 15913, 15146, 36907, 15916, 15918, 36914, 15925, 15928, 35779, 3523, 3269, 15942, 3271, 15944, 15941, 15943, 21335, 11354, 3293, 3553, 3554, 3300, 3301, 11500, 24694, 24700, 3070}\n",
      "dict_items([(\"Lemma('cell.n.01.cell')\", 26), (\"Lemma('cell.n.02.cell')\", 4), (\"Lemma('cell.n.03.cell')\", 1)])\n",
      "collecting tokens for  occupants\n",
      "indices:    {34053, 21445, 17543, 15214, 25075, 17556, 24693, 24694, 11097}\n",
      "dict_items([(\"Lemma('resident.n.01.occupant')\", 4)])\n",
      "collecting tokens for  fringe\n",
      "indices:    {24352, 21889, 24388, 24394, 9710, 7827, 11796, 11797, 24694, 11799, 24692, 24345, 28635, 17405, 11806, 12191}\n",
      "dict_items([(\"Lemma('periphery.n.01.fringe')\", 4), (\"Lemma('outskirt.n.01.fringe')\", 1)])\n",
      "collecting tokens for  benefits\n",
      "indices:    {25735, 11796, 11797, 16277, 30100, 11802, 11807, 11811, 11816, 11817, 11818, 22061, 4781, 11573, 576, 11346, 11732, 20181, 11735, 11736, 11737, 11738, 20185, 24030, 27365, 28142, 4594, 24692, 24694, 14205}\n",
      "dict_items([(\"Lemma('benefit.n.01.benefit')\", 11), (\"Lemma('benefit.n.02.benefit')\", 7), (\"Lemma('benefit.v.02.benefit')\", 1)])\n",
      "collecting tokens for  ideas\n",
      "indices:    {14593, 28165, 14343, 31244, 14606, 14351, 19471, 26513, 14365, 21923, 15397, 15400, 14634, 15796, 11189, 26174, 14656, 20293, 14679, 30427, 14685, 28125, 2655, 14691, 26087, 15850, 14314, 14329, 31870, 14719}\n",
      "dict_items([(\"Lemma('idea.n.01.idea')\", 20)])\n",
      "collecting tokens for  necessarily\n",
      "indices:    {1028, 32772, 14226, 23828, 32404, 30997, 5271, 30234, 26017, 2594, 37031, 32811, 25644, 2478, 28852, 32821, 28733, 31166, 14420, 26458, 32987, 11484, 32228, 14311, 32616, 32237, 27886, 12146, 2429}\n",
      "dict_items([(\"Lemma('inevitably.r.01.necessarily')\", 4), (\"Lemma('necessarily.r.01.necessarily')\", 5), (\"Lemma('necessarily.r.03.necessarily')\", 1)])\n",
      "collecting tokens for  volunteers\n",
      "indices:    {5252, 22042, 32628}\n",
      "dict_items([(\"Lemma('volunteer.n.02.volunteer')\", 1)])\n",
      "collecting tokens for  go\n",
      "indices:    {7520, 18476, 36335, 31356, 10269, 20319}\n",
      "dict_items([(\"Lemma('travel.v.01.go')\", 1)])\n",
      "collecting tokens for  separate\n",
      "indices:    {31360, 31368, 13458, 13460, 8860, 31223, 20140, 22061, 9906, 12217, 3002, 29499, 30139, 32957, 15936, 2113, 2628, 2117, 30413, 28877, 31709, 18014, 32992, 3557, 11367, 15595, 14829, 20849, 28530, 13303, 27509, 33014, 36983, 25081, 5243, 6909, 1663}\n",
      "dict_items([(\"Lemma('separate.a.01.separate')\", 14), (\"Lemma('separate.v.01.separate')\", 4), (\"Lemma('divide.v.01.separate')\", 1), (\"Lemma('separate.v.07.separate')\", 1)])\n",
      "collecting tokens for  ways\n",
      "indices:    {32130, 33032, 17420, 22284, 14097, 25755, 10141, 2333, 4125, 28451, 11182, 27439, 15792, 20536, 15812, 4933, 12237, 25039, 32978, 27989, 10712, 14681, 27996, 32479, 28003, 7910, 4711, 630, 25209}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('manner.n.01.way')\", 8), (\"Lemma('ways.n.01.ways')\", 1), (\"Lemma('way.n.10.way')\", 1), (\"Lemma('means.n.01.way')\", 4)])\n",
      "collecting tokens for  willing\n",
      "indices:    {32001, 23300, 16903, 33166, 917, 24601, 27420, 2332, 31519, 13728, 32160, 12835, 24877, 2097, 20529, 23603, 25139, 35641, 9402, 18234, 27452, 24256, 24004, 14404, 30281, 24270, 27899, 976, 20305, 12629, 25174, 20311, 24280, 20823, 36954, 25819, 24281, 12383, 20319, 994, 12131, 995, 24933, 16361, 14697, 874, 13936, 27889, 14576, 116, 25591, 16379, 27133}\n",
      "dict_items([(\"Lemma('willing.a.01.willing')\", 20), (\"Lemma('volition.n.02.willing')\", 1)])\n",
      "collecting tokens for  join\n",
      "indices:    {21696, 13124, 16409, 14023, 25817, 20795, 13310, 29599}\n",
      "dict_items([(\"Lemma('join.v.02.join')\", 1), (\"Lemma('join.v.03.join')\", 1), (\"Lemma('join.v.01.join')\", 6)])\n",
      "collecting tokens for  except\n",
      "indices:    {13305, 9668, 316, 15022}\n",
      "dict_items([])\n",
      "collecting tokens for  fashion\n",
      "indices:    {36992, 20883, 32823, 6871, 26622}\n",
      "dict_items([(\"Lemma('fashion.n.02.fashion')\", 1)])\n",
      "collecting tokens for  evangelism\n",
      "indices:    {28065, 13348, 27574, 27575}\n",
      "dict_items([])\n",
      "collecting tokens for  congregational\n",
      "indices:    {28067, 13348}\n",
      "dict_items([(\"Lemma('congregational.a.01.congregational')\", 1)])\n",
      "collecting tokens for  carefully\n",
      "indices:    {11577, 9430}\n",
      "dict_items([(\"Lemma('carefully.r.01.carefully')\", 2)])\n",
      "collecting tokens for  studied\n",
      "indices:    {20352, 20354, 34949, 5, 14474, 36746, 9996, 23695, 7314, 24723, 19606, 11670, 2331, 1947, 26781, 7588, 164, 13352, 19627, 27181, 9517, 7982, 6064, 11440, 18367, 11201, 2499, 36676, 1862, 26311, 22089, 3403, 10318, 2895, 11345, 15953, 17873, 3797, 24314, 36955, 35675, 4189, 14685, 6752, 14689, 3942, 7143, 14573, 32622, 15727, 35824, 4465, 5744, 3066, 23165, 19582, 895}\n",
      "dict_items([(\"Lemma('study.v.05.study')\", 2), (\"Lemma('analyze.v.01.study')\", 26), (\"Lemma('study.v.02.study')\", 9), (\"Lemma('study.v.03.study')\", 8), (\"Lemma('learn.v.04.study')\", 5)])\n",
      "collecting tokens for  illuminated\n",
      "indices:    {13352, 30377, 35677, 5773, 13487, 2705, 3253, 3256, 3290, 29403, 3293, 3295}\n",
      "dict_items([(\"Lemma('light.v.01.illuminate')\", 7), (\"Lemma('clear.v.10.illuminate')\", 3)])\n",
      "collecting tokens for  wagner\n",
      "indices:    {20477}\n",
      "dict_items([])\n",
      "collecting tokens for  collective\n",
      "indices:    {27267, 22788, 22789, 22790, 22792, 28043, 13836, 22800, 2584, 22809, 12187, 21553, 2615, 11065, 12247, 11096, 4706, 31206, 31214, 32878, 28016, 22392, 24058}\n",
      "dict_items([(\"Lemma('corporate.s.03.collective')\", 7), (\"Lemma('collective.n.01.collective')\", 1)])\n",
      "collecting tokens for  bargaining\n",
      "indices:    {22788, 23749, 22790, 22789, 22792, 16376, 22636, 22800, 21553, 20760, 22809, 34362, 21631}\n",
      "dict_items([(\"Lemma('bargaining.n.01.bargaining')\", 1)])\n",
      "collecting tokens for  johnson\n",
      "indices:    {32198}\n",
      "dict_items([])\n",
      "collecting tokens for  son\n",
      "indices:    {30976, 28244, 27263}\n",
      "dict_items([])\n",
      "collecting tokens for  dill\n",
      "indices:    {35818}\n",
      "dict_items([])\n",
      "collecting tokens for  everything\n",
      "indices:    {8755, 25542}\n",
      "dict_items([])\n",
      "collecting tokens for  yourself\n",
      "indices:    {28291, 6787, 30086, 29447, 10120, 19467, 19596, 30093, 18189, 33294, 21904, 12817, 35479, 19097, 17434, 1819, 19488, 6177, 8754, 25524, 36791, 30012, 36288, 1600, 20032, 33603, 9284, 30667, 9676, 30672, 24400, 8401, 9684, 9687, 34008, 30168, 9437, 13150, 19559, 35304, 19561, 28649, 29425, 30066, 5879, 29820, 12158}\n",
      "dict_items([])\n",
      "collecting tokens for  locate\n",
      "indices:    {4960, 4911, 2736, 12143, 18230, 28799}\n",
      "dict_items([(\"Lemma('settle.v.04.locate')\", 1), (\"Lemma('situate.v.01.locate')\", 3), (\"Lemma('locate.v.01.locate')\", 2)])\n",
      "collecting tokens for  positions\n",
      "indices:    {3072, 2051, 20235, 15757, 3087, 3088, 24216, 6939, 25504, 32929, 4777, 3114, 14005, 9654, 28856, 28731, 22722, 12867, 23242, 20812, 13264, 1360, 31952, 20561, 30804, 15327, 3556, 30568, 28781, 13169, 23290, 28796}\n",
      "dict_items([(\"Lemma('position.n.01.position')\", 7), (\"Lemma('position.n.03.position')\", 2), (\"Lemma('status.n.01.position')\", 1), (\"Lemma('position.n.06.position')\", 3), (\"Lemma('military_position.n.01.position')\", 1), (\"Lemma('position.n.07.position')\", 1), (\"Lemma('position.n.09.position')\", 1)])\n",
      "collecting tokens for  fig.\n",
      "indices:    {29940, 15077}\n",
      "dict_items([(\"Lemma('figure.n.01.fig')\", 1)])\n",
      "collecting tokens for  drill\n",
      "indices:    {28809}\n",
      "dict_items([(\"Lemma('bore.v.02.drill')\", 1)])\n",
      "collecting tokens for  no.\n",
      "indices:    {24712}\n",
      "dict_items([])\n",
      "collecting tokens for  match\n",
      "indices:    {35840, 31366, 15882, 9997, 34715, 15902, 15907, 33957, 18342, 11687, 22950, 34215, 15927, 18362, 18364, 26692, 18378, 19279, 23759, 26844, 22500, 878, 27125, 3702, 28796}\n",
      "dict_items([(\"Lemma('match.n.01.match')\", 4), (\"Lemma('match.v.01.match')\", 9), (\"Lemma('equal.v.02.match')\", 3), (\"Lemma('match.v.02.match')\", 2), (\"Lemma('match.v.05.match')\", 1), (\"Lemma('match.n.03.match')\", 1), (\"Lemma('match.v.03.match')\", 1), (\"Lemma('match.n.04.match')\", 1)])\n",
      "collecting tokens for  corresponding\n",
      "indices:    {31873, 32776, 4497, 32916, 4500, 4502, 1312, 4513, 3237, 4518, 27950, 16177, 16178, 3889, 3892, 3893, 4548, 33093, 4562, 3797, 4950, 12759, 22743, 4569, 4568, 3292, 11362, 21230, 28796, 3070}\n",
      "dict_items([(\"Lemma('correspond.v.03.correspond')\", 2), (\"Lemma('corresponding.s.01.corresponding')\", 9), (\"Lemma('corresponding.s.02.corresponding')\", 7), (\"Lemma('equate.v.02.correspond')\", 2), (\"Lemma('match.v.01.correspond')\", 1), (\"Lemma('comparable.s.02.corresponding')\", 1)])\n",
      "collecting tokens for  holes\n",
      "indices:    {22912, 8802, 13028, 28775, 22906, 28826}\n",
      "dict_items([(\"Lemma('hole.n.03.hole')\", 1)])\n",
      "collecting tokens for  tore\n",
      "indices:    {20740, 35429, 33577, 6281, 35436, 36205, 5102, 34062, 7028, 35637}\n",
      "dict_items([(\"Lemma('tear.v.03.tear')\", 1), (\"Lemma('tear.v.01.tear')\", 8), (\"Lemma('tear.v.02.tear')\", 1)])\n",
      "collecting tokens for  1952\n",
      "indices:    {14720, 3981, 14114, 33060, 33062, 4011, 4015, 30409, 15312, 15315, 15316, 3671, 31194, 23130, 4188, 12251, 12769, 15331, 24815, 24184, 15356}\n",
      "dict_items([])\n",
      "collecting tokens for  remembered\n",
      "indices:    {13570, 34183, 33800, 1034, 3468, 2190, 8081, 35986, 22932, 34837, 21654, 2326, 35224, 9497, 18973, 28062, 35230, 8861, 29982, 14114, 16807, 13737, 16813, 28077, 4271, 17584, 7604, 7735, 16824, 14523, 31932, 30783, 36419, 36423, 16840, 30796, 34765, 13644, 28623, 33488, 37076, 7893, 7125, 32212, 7896, 17749, 26331, 29915, 7773, 34908, 16607, 9700, 5220, 16487, 19055, 7152, 34292, 34295, 7162}\n",
      "dict_items([(\"Lemma('remember.v.01.remember')\", 26), (\"Lemma('remember.v.02.remember')\", 8), (\"Lemma('remember.v.03.remember')\", 4), (\"Lemma('remember.v.04.remember')\", 1)])\n",
      "collecting tokens for  g.\n",
      "indices:    {23621}\n",
      "dict_items([])\n",
      "collecting tokens for  o.\n",
      "indices:    {168}\n",
      "dict_items([])\n",
      "collecting tokens for  popular\n",
      "indices:    {5140}\n",
      "dict_items([])\n",
      "collecting tokens for  leadership\n",
      "indices:    {27136, 24325, 12933, 14215, 27144, 24073, 24072, 14221, 14222, 20239, 31632, 27156, 15382, 20378, 32154, 14107, 28065, 14116, 679, 20522, 25902, 14254, 28078, 26037, 20789, 37051, 20415, 20300, 7894, 27611, 15456, 11881, 27115, 27117, 23665, 31732, 27126, 27128, 27130, 27131}\n",
      "dict_items([(\"Lemma('leadership.n.02.leadership')\", 2), (\"Lemma('leadership.n.04.leadership')\", 3), (\"Lemma('leadership.n.01.leadership')\", 5), (\"Lemma('leadership.n.03.leadership')\", 2)])\n",
      "collecting tokens for  sponsor\n",
      "indices:    {26729}\n",
      "dict_items([])\n",
      "collecting tokens for  responsibility\n",
      "indices:    {25485, 14223, 25490, 31253, 20374, 2070, 21528, 14230, 22681, 15003, 24095, 12320, 33056, 33057, 33059, 33060, 24997, 23590, 24999, 15400, 4779, 15407, 27824, 15408, 22706, 24115, 19377, 25137, 32568, 30399, 32448, 25026, 32323, 32324, 12101, 22726, 22728, 31177, 33227, 32331, 27852, 31182, 27856, 31185, 32338, 20309, 31195, 31198, 21087, 23648, 23522, 25443, 24165, 31205, 31207, 31211, 31213, 31214, 31215, 11760, 33011, 32501, 12917, 25466, 32127}\n",
      "dict_items([(\"Lemma('duty.n.01.responsibility')\", 10), (\"Lemma('province.n.02.responsibility')\", 1), (\"Lemma('responsibility.n.03.responsibility')\", 1)])\n",
      "collecting tokens for  advertising\n",
      "indices:    {26754, 11656, 11664, 28311, 23703, 23705, 25242, 10655, 11684, 11686, 2095, 19513, 25152, 37059, 22090, 19019, 28362, 32465, 32468, 19032, 22750, 6000, 11633}\n",
      "dict_items([(\"Lemma('ad.n.01.advertising')\", 5), (\"Lemma('advertising.n.02.advertising')\", 4)])\n",
      "collecting tokens for  therapist\n",
      "indices:    {30240, 15841, 30242, 30241, 30245, 30248, 15849, 15851, 30252, 15853, 15854, 15823, 30254, 30257, 15858, 30263, 30235, 30237}\n",
      "dict_items([(\"Lemma('therapist.n.01.therapist')\", 7)])\n",
      "collecting tokens for  sufficiently\n",
      "indices:    {26243, 22276, 27783, 2951, 4234, 3992, 11163, 32924, 23972, 11437, 4527, 2684, 11716, 32582, 9929, 33226, 2762, 15437, 3152, 15838, 33248, 3297, 22882, 32618, 2795, 15854, 2032, 15858, 17907, 32761, 4348, 4990}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('sufficiently.r.01.sufficiently')\", 21)])\n",
      "collecting tokens for  ask\n",
      "indices:    {25446, 34857, 31690, 13099, 31689, 7563, 5744, 20433, 17012, 20212, 26104, 33337, 1213, 36734}\n",
      "dict_items([(\"Lemma('ask.v.01.ask')\", 6), (\"Lemma('ask.v.03.ask')\", 1), (\"Lemma('ask.v.02.ask')\", 7)])\n",
      "collecting tokens for  farewell\n",
      "indices:    {19264, 26976, 26165, 32025, 9180}\n",
      "dict_items([(\"Lemma('farewell.n.01.farewell')\", 1)])\n",
      "collecting tokens for  rises\n",
      "indices:    {16352, 29849, 16356, 909, 26158, 4976, 32025}\n",
      "dict_items([(\"Lemma('rise.v.02.rise')\", 3), (\"Lemma('rise.v.16.rise')\", 1), (\"Lemma('surface.v.01.rise')\", 1), (\"Lemma('heighten.v.01.rise')\", 1)])\n",
      "collecting tokens for  monument\n",
      "indices:    {25152, 13830, 5077, 22422, 29974, 6397, 862}\n",
      "dict_items([(\"Lemma('memorial.n.03.monument')\", 4)])\n",
      "collecting tokens for  miami\n",
      "indices:    {34027}\n",
      "dict_items([])\n",
      "collecting tokens for  enterprises\n",
      "indices:    {12128, 2721, 12138, 22763, 4589, 14223, 23889, 12115, 14204}\n",
      "dict_items([(\"Lemma('enterprise.n.02.enterprise')\", 3), (\"Lemma('enterprise.n.01.enterprise')\", 3)])\n",
      "collecting tokens for  noise\n",
      "indices:    {34309, 2829, 22293, 9368, 25629, 26403, 6692, 6696, 29998, 31150, 27439, 5820, 1099, 6731, 6739, 8920, 35933, 13023, 8932, 5482, 15981, 15984, 18802, 30200, 2812}\n",
      "dict_items([(\"Lemma('noise.n.02.noise')\", 1), (\"Lemma('noise.n.01.noise')\", 12)])\n",
      "collecting tokens for  office\n",
      "indices:    {24218, 24148}\n",
      "dict_items([])\n",
      "collecting tokens for  hague\n",
      "indices:    {35926}\n",
      "dict_items([])\n",
      "collecting tokens for  swung\n",
      "indices:    {31373, 34579, 35349, 18454, 8854, 19230, 24353, 35237, 33960, 18604, 35764, 7220, 23351, 26424, 35770, 36290, 23749, 18374, 22857, 10570, 36171, 31437, 31438, 2387, 19286, 9178, 35933, 34141, 13542, 34153, 31724, 8559, 34032, 10355, 35572, 6902, 35193, 15868}\n",
      "dict_items([(\"Lemma('swing.v.01.swing')\", 23), (\"Lemma('swing.v.04.swing')\", 3), (\"Lemma('swing.v.02.swing')\", 7), (\"Lemma('swing.v.08.swing')\", 1), (\"Lemma('swing_around.v.01.swing_around')\", 1), (\"Lemma('swing.v.05.swing')\", 2), (\"Lemma('dangle.v.01.swing')\", 1)])\n",
      "collecting tokens for  entrance\n",
      "indices:    {33409, 9351, 29194, 15116, 15119, 15123, 33431, 15132, 1054, 15137, 29350, 29352, 31530, 29355, 36651, 30765, 26803, 6076, 29374, 14538, 29389, 29393, 27476, 3412, 13655, 15072, 27745, 5088, 26979, 34153, 21242}\n",
      "dict_items([(\"Lemma('entrance.n.01.entrance')\", 6), (\"Lemma('entrance.n.02.entrance')\", 3), (\"Lemma('entrance.n.03.entrance')\", 2)])\n",
      "collecting tokens for  outer\n",
      "indices:    {34208, 23297, 17001, 11145, 27564, 34319, 29552, 27378, 25077, 27388}\n",
      "dict_items([(\"Lemma('outer.a.01.outer')\", 2)])\n",
      "collecting tokens for  room\n",
      "indices:    {5088, 444, 6172}\n",
      "dict_items([(\"Lemma('room.n.01.room')\", 2)])\n",
      "collecting tokens for  arm\n",
      "indices:    {35843, 18957, 6926, 33586, 29077, 8604, 8611, 33575, 31915, 1967, 31282, 23091, 8244, 1973, 29878, 33207, 36408, 6325, 33206, 36411, 3260, 36029, 33216, 36032, 19264, 8779, 5838, 33240, 33241, 18142, 34783, 9188, 24297, 5995, 8940, 35053, 18414, 375}\n",
      "dict_items([(\"Lemma('arm.n.01.arm')\", 17), (\"Lemma('arm.n.02.arm')\", 1)])\n",
      "collecting tokens for  consciously\n",
      "indices:    {31874, 32228, 2149, 27812, 8859, 17338, 33243, 26460}\n",
      "dict_items([(\"Lemma('consciously.r.01.consciously')\", 3)])\n",
      "collecting tokens for  intense\n",
      "indices:    {15704, 2308, 11620, 2218, 32980, 26840}\n",
      "dict_items([(\"Lemma('intense.a.01.intense')\", 4)])\n",
      "collecting tokens for  expressions\n",
      "indices:    {14624, 14666, 9389, 7549, 22715, 14685}\n",
      "dict_items([(\"Lemma('expression.n.02.expression')\", 1), (\"Lemma('expression.n.01.expression')\", 2), (\"Lemma('expression.n.03.expression')\", 2)])\n",
      "collecting tokens for  singing\n",
      "indices:    {26240, 26248, 26506, 7694, 36497, 26386, 22293, 918, 7203, 7204, 1191, 12844, 34733, 7215, 26295, 26304, 26308, 26310, 26225}\n",
      "dict_items([(\"Lemma('sing.v.02.sing')\", 9), (\"Lemma('sing.v.01.sing')\", 1), (\"Lemma('singing.n.01.singing')\", 1)])\n",
      "collecting tokens for  bring\n",
      "indices:    {907, 30732, 921, 8476, 15390, 30241, 1316, 2597, 21160, 27690, 29484, 20654, 9780, 29240, 30268, 29504, 6336, 28226, 23747, 19395, 27848, 8272, 13648, 11346, 12499, 30549, 14040, 10457, 8540, 11484, 21092, 20712, 14959, 497, 26359, 14712, 12027, 15230}\n",
      "dict_items([(\"Lemma('lower.v.01.bring_down')\", 1), (\"Lemma('bring.v.02.bring')\", 12), (\"Lemma('lend.v.01.bring')\", 2), (\"Lemma('bring.v.01.bring')\", 9), (\"Lemma('bring.v.03.bring')\", 1)])\n",
      "collecting tokens for  warmth\n",
      "indices:    {22145, 36998, 22156, 31644, 35244, 19254, 24376, 27333, 8902, 19786, 26705, 10590, 7263, 26979, 26084, 34793, 24560, 22138, 2559}\n",
      "dict_items([(\"Lemma('heat.n.03.warmth')\", 4), (\"Lemma('warmheartedness.n.01.warmth')\", 1), (\"Lemma('warmth.n.03.warmth')\", 1)])\n",
      "collecting tokens for  dining\n",
      "indices:    {22112, 16673, 11105, 24580, 7461, 29157, 22309, 18120, 37028, 7440, 11441, 12657, 23024, 20979, 36630, 8827}\n",
      "dict_items([(\"Lemma('dine.v.01.dine')\", 3)])\n",
      "collecting tokens for  golden\n",
      "indices:    {18849, 21666, 22092, 13581, 37054}\n",
      "dict_items([(\"Lemma('aureate.s.02.golden')\", 2)])\n",
      "collecting tokens for  orange\n",
      "indices:    {3609, 11322, 6475, 5606}\n",
      "dict_items([(\"Lemma('orange.n.02.orange')\", 2), (\"Lemma('orange.s.01.orange')\", 1)])\n",
      "collecting tokens for  tones\n",
      "indices:    {22151, 16104, 14476, 22156, 26990, 19343, 16087, 26008, 33658, 7003, 700, 6045, 13655}\n",
      "dict_items([(\"Lemma('tone.n.02.tone')\", 2), (\"Lemma('tone.n.01.tone')\", 2), (\"Lemma('note.n.03.tone')\", 1), (\"Lemma('timbre.n.01.tone')\", 2), (\"Lemma('shade.n.02.tone')\", 1)])\n",
      "collecting tokens for  fabrics\n",
      "indices:    {3171, 15236, 3173, 22151, 22152, 5031, 22156, 22159, 3184, 694, 3229}\n",
      "dict_items([(\"Lemma('fabric.n.01.fabric')\", 7)])\n",
      "collecting tokens for  saddle\n",
      "indices:    {9345, 6922, 7694, 35193, 7850, 18604, 35372, 18095, 10418, 35250, 35380, 29111, 29116, 18116, 18120, 35148, 35151, 18639, 6891, 35182, 10355, 6905}\n",
      "dict_items([(\"Lemma('saddle.n.01.saddle')\", 12), (\"Lemma('saddle.v.01.saddle')\", 1)])\n",
      "collecting tokens for  delayed\n",
      "indices:    {7776, 22883, 5083, 35610, 3901, 18604, 2378, 235, 28979, 3923, 3903, 3864, 22746, 3866, 25053, 3870, 11647}\n",
      "dict_items([(\"Lemma('delay.v.02.delay')\", 3), (\"Lemma('delay.v.01.delay')\", 6), (\"Lemma('stay.v.06.delay')\", 1)])\n",
      "collecting tokens for  overcast\n",
      "indices:    {7330, 18758, 18797, 18832, 17680, 30576, 18707, 18836, 30581}\n",
      "dict_items([(\"Lemma('cloudiness.n.01.overcast')\", 6), (\"Lemma('cloud-covered.s.01.overcast')\", 1)])\n",
      "collecting tokens for  solid\n",
      "indices:    {14954, 8875, 3468, 26062, 34574, 4987}\n",
      "dict_items([(\"Lemma('solid.s.01.solid')\", 1), (\"Lemma('solid.s.04.solid')\", 1), (\"Lemma('hearty.s.02.solid')\", 1)])\n",
      "collecting tokens for  fun\n",
      "indices:    {28546, 28549, 37094, 21061, 14472, 19017, 26315, 11948, 11885, 11953, 34613, 1078, 30391, 29497, 22074, 11933}\n",
      "dict_items([(\"Lemma('fun.n.01.fun')\", 4)])\n",
      "collecting tokens for  fascinating\n",
      "indices:    {29344, 11042, 24451, 1191, 1192, 1064, 34698, 1771, 26219, 24310, 24217, 26555, 26204, 14717, 13951}\n",
      "dict_items([(\"Lemma('absorbing.s.01.fascinating')\", 7)])\n",
      "collecting tokens for  angels\n",
      "indices:    {33368, 34441}\n",
      "dict_items([])\n",
      "collecting tokens for  politics\n",
      "indices:    {24192, 27801, 24837, 4744, 26671, 32240, 26678, 14103, 14201, 24826, 22395, 6012, 4797}\n",
      "dict_items([(\"Lemma('politics.n.01.politics')\", 4)])\n",
      "collecting tokens for  handled\n",
      "indices:    {15745, 33158, 4359, 32269, 20367, 669, 34079, 1192, 4913, 14389, 19513, 19132, 4926, 15433, 23249, 17362, 23897, 32862, 32355, 15460, 11109, 35943, 20085, 21493}\n",
      "dict_items([(\"Lemma('manage.v.02.handle')\", 10), (\"Lemma('treat.v.01.handle')\", 7), (\"Lemma('cover.v.05.handle')\", 3), (\"Lemma('handled.a.01.handled')\", 1), (\"Lemma('handle.v.04.handle')\", 2), (\"Lemma('wield.v.02.handle')\", 1)])\n",
      "collecting tokens for  bond\n",
      "indices:    {3074, 5129, 3083, 3088, 26531, 23590, 52, 55, 57, 20805, 23878, 20679, 21578, 20693, 20696, 12645, 4716, 20462, 3055, 3054, 3061, 3063, 3065, 3067, 3068}\n",
      "dict_items([(\"Lemma('bond.n.02.bond')\", 4), (\"Lemma('chemical_bond.n.01.bond')\", 9), (\"Lemma('bail.n.01.bond')\", 1), (\"Lemma('alliance.n.02.bond')\", 1)])\n",
      "collecting tokens for  cast\n",
      "indices:    {22400, 13575, 31497, 26505, 1161, 24852, 26516, 2326, 37148, 1180, 26142, 1183, 11044, 27047, 1192, 34345, 14383, 1072, 1203, 1204, 26296, 14651, 25541, 24019, 15832, 12507, 33375, 31455, 15329, 1123, 4453, 1137, 1139, 26871, 10104, 33401, 35194}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('cast.n.01.cast')\", 9), (\"Lemma('project.v.10.cast')\", 7), (\"Lemma('cast_about.v.01.cast_around')\", 1), (\"Lemma('cast.v.03.cast')\", 2), (\"Lemma('cast.v.02.cast')\", 1), (\"Lemma('discard.v.01.cast_aside')\", 1), (\"Lemma('hurl.v.01.cast')\", 1)])\n",
      "collecting tokens for  clever\n",
      "indices:    {14432, 26468, 25638, 8459, 29040, 29041, 26362, 11229}\n",
      "dict_items([(\"Lemma('cagey.s.01.clever')\", 1), (\"Lemma('apt.s.03.clever')\", 1)])\n",
      "collecting tokens for  lyrics\n",
      "indices:    {26501, 9957, 26503, 1192, 1160, 1163, 26510, 6610, 26514, 26515, 14548, 14552, 1179, 31582}\n",
      "dict_items([(\"Lemma('lyric.n.01.lyric')\", 7)])\n",
      "collecting tokens for  perfect\n",
      "indices:    {2178, 12816, 35856, 1050, 31772, 668, 24990, 18720, 37036, 10284, 1460, 30007, 13882, 34748, 4675, 17735, 27468, 33869, 13902, 34129, 3666, 31578, 22494, 3041, 27362, 1762, 28272, 18809, 31995, 1791}\n",
      "dict_items([(\"Lemma('perfect.a.01.perfect')\", 14)])\n",
      "collecting tokens for  clarity\n",
      "indices:    {1192, 24745, 31538, 13490, 10677, 14267, 14268, 14272, 26947, 1734, 3528, 26314, 11217, 11218, 4823, 19419, 11236, 9190, 11242, 11243, 18932}\n",
      "dict_items([(\"Lemma('clarity.n.01.clarity')\", 16), (\"Lemma('clearness.n.02.clarity')\", 1)])\n",
      "collecting tokens for  surrender\n",
      "indices:    {9155, 25732, 25765, 21929, 5099, 1275, 5040, 26195, 27829, 2517, 26197, 27833, 27835, 26527}\n",
      "dict_items([(\"Lemma('giving_up.n.01.surrender')\", 1), (\"Lemma('surrender.v.01.surrender')\", 4), (\"Lemma('surrender.v.02.surrender')\", 1), (\"Lemma('resignation.n.01.surrender')\", 1)])\n",
      "collecting tokens for  warfare\n",
      "indices:    {12693, 14233, 21274, 12964, 25775, 27833, 27836, 3393, 3396, 25159, 30280, 25161, 23753, 25420, 25949, 25956, 25959, 15463, 14185, 14062, 12911, 14063, 15470}\n",
      "dict_items([(\"Lemma('war.n.01.warfare')\", 8), (\"Lemma('war.n.03.warfare')\", 1)])\n",
      "collecting tokens for  followed\n",
      "indices:    {12800, 21508, 15877, 1543, 28177, 34325, 22550, 17432, 23584, 1060, 27688, 13362, 9779, 16437, 18495, 35393, 12866, 35401, 14418, 30291, 36948, 1621, 18536, 23660, 3696, 11890, 18547, 29812, 34433, 33410, 20611, 11395, 20612, 9350, 4748, 8846, 9360, 33936, 31383, 20121, 14495, 4264, 3241, 3240, 16043, 21166, 19122, 27833, 27329, 18627, 12483, 12485, 23752, 18636, 31437, 9936, 3793, 34518, 32470, 2270, 18145, 26342, 2807, 26875, 22781, 30977, 18177, 14091, 29965, 18192, 35092, 9521, 33585, 18227, 6966, 15161, 33096, 8521, 25417, 35145, 36181, 11112, 26986, 21361, 15218, 21372, 35206, 26503, 19847, 15248, 20377, 36767, 13734, 12710, 30633, 35245, 33711, 5554, 12732, 5056, 12225, 5066, 1995, 19917, 35798, 15324, 32228, 15333, 491, 22510, 32760}\n",
      "dict_items([(\"Lemma('comply.v.01.follow')\", 4), (\"Lemma('follow.v.06.follow')\", 12), (\"Lemma('postdate.v.01.follow')\", 22), (\"Lemma('follow.v.01.follow')\", 26), (\"Lemma('follow.v.07.follow')\", 1), (\"Lemma('adopt.v.01.follow')\", 3), (\"Lemma('follow.v.08.follow')\", 7), (\"Lemma('take_after.v.02.follow')\", 1), (\"Lemma('keep_up.v.04.follow')\", 1), (\"Lemma('follow.v.04.follow')\", 7), (\"Lemma('follow.v.10.follow')\", 4), (\"Lemma('succeed.v.02.follow')\", 1), (\"Lemma('follow.v.03.follow')\", 2), (\"Lemma('watch.v.02.follow')\", 2)])\n",
      "collecting tokens for  resistance\n",
      "indices:    {11395, 16325, 16358, 5576, 16362, 16173, 14832, 15218, 21972, 11189, 11382, 11383, 27833, 34522, 14779, 23996}\n",
      "dict_items([(\"Lemma('resistance.n.02.resistance')\", 4), (\"Lemma('resistance.n.01.resistance')\", 5), (\"Lemma('electric_resistance.n.01.resistance')\", 1)])\n",
      "collecting tokens for  occupied\n",
      "indices:    {30725, 11145, 9880, 8480, 33957, 9387, 37165, 27833, 5051, 28096, 17737, 11209, 21834, 12239, 15185, 34260, 33904, 33521, 33524, 36729, 17406}\n",
      "dict_items([(\"Lemma('occupied.a.01.occupied')\", 2), (\"Lemma('occupy.v.02.occupy')\", 5), (\"Lemma('invade.v.01.occupy')\", 1), (\"Lemma('busy.v.01.occupy')\", 2), (\"Lemma('concern.v.02.occupy')\", 1)])\n",
      "collecting tokens for  peoples\n",
      "indices:    {31232, 31233, 12943, 15381, 16406, 12952, 12954, 12955, 2335, 20779, 32171, 27833, 13375, 31172, 11208, 31180, 31699, 27862, 31963, 10215, 26216, 4716, 10221, 11247, 4977, 13043, 4733}\n",
      "dict_items([(\"Lemma('people.n.01.people')\", 13), (\"Lemma('citizenry.n.01.people')\", 3)])\n",
      "collecting tokens for  diagnosis\n",
      "indices:    {24552, 31058, 2194, 2265, 32766}\n",
      "dict_items([(\"Lemma('diagnosis.n.01.diagnosis')\", 2)])\n",
      "collecting tokens for  training\n",
      "indices:    {15821, 32718, 32151, 4604, 26077}\n",
      "dict_items([(\"Lemma('training.n.01.training')\", 2)])\n",
      "collecting tokens for  validity\n",
      "indices:    {15809, 31876, 32518, 11087, 27760, 15793, 3349, 57}\n",
      "dict_items([(\"Lemma('validity.n.02.validity')\", 1), (\"Lemma('cogency.n.02.validity')\", 4)])\n",
      "collecting tokens for  housed\n",
      "indices:    {31524, 10534, 20870, 28425, 23148, 14444, 17584, 3634}\n",
      "dict_items([(\"Lemma('house.v.01.house')\", 6), (\"Lemma('house.v.02.house')\", 2)])\n",
      "collecting tokens for  mccormick\n",
      "indices:    {937}\n",
      "dict_items([])\n",
      "collecting tokens for  theater\n",
      "indices:    {20320, 937, 14292, 10645, 26775, 21275, 14524}\n",
      "dict_items([(\"Lemma('theater.n.01.theater')\", 3), (\"Lemma('dramaturgy.n.01.theater')\", 1)])\n",
      "collecting tokens for  prove\n",
      "indices:    {20870, 20234, 3723, 1291, 2190, 28178, 24087, 12439, 20249, 12318, 23841, 36002, 4514, 3753, 12208, 6192, 36147, 36148, 1205, 12220, 1217, 16196, 4294, 22345, 33612, 12621, 37073, 18515, 25428, 28628, 16214, 25559, 725, 2265, 26458, 23413, 4343, 22653}\n",
      "dict_items([(\"Lemma('prove.v.01.prove')\", 19), (\"Lemma('prove.v.02.prove')\", 13), (\"Lemma('testify.v.02.prove')\", 3), (\"Lemma('prove.v.04.prove')\", 3)])\n",
      "collecting tokens for  exciting\n",
      "indices:    {9601, 1154, 1153, 29316, 20870, 3729, 22938, 26395, 14623, 11689, 11691, 23728, 28355, 29252, 11205, 29255, 19537, 32214, 1754, 5598, 2027, 9584, 15735, 11384, 1660}\n",
      "dict_items([(\"Lemma('excite.v.01.excite')\", 1), (\"Lemma('exciting.a.01.exciting')\", 11), (\"Lemma('exciting.s.02.exciting')\", 3), (\"Lemma('stimulate.v.01.excite')\", 1)])\n",
      "collecting tokens for  evening\n",
      "indices:    {8192, 26241, 26625, 1025, 30080, 37002, 21260, 8208, 33938, 21139, 21140, 8216, 24346, 8091, 19614, 26656, 8353, 1185, 26401, 21668, 36005, 24358, 8358, 26666, 26795, 26413, 26416, 33976, 30013, 1726, 5313, 24261, 12998, 20039, 28360, 21583, 25936, 31571, 26708, 27605, 26709, 26072, 19034, 36445, 21087, 24673, 36065, 11105, 5734, 10984, 26473, 9835, 10481, 9586, 20978, 20980, 8183, 36985, 29946, 8827, 8828}\n",
      "dict_items([(\"Lemma('evening.n.01.evening')\", 21)])\n",
      "collecting tokens for  adds\n",
      "indices:    {26241, 30081, 25540, 20870, 30192, 24212, 15445, 1751, 26778, 24604}\n",
      "dict_items([(\"Lemma('lend.v.01.add')\", 3), (\"Lemma('add.v.02.add')\", 3), (\"Lemma('add.v.01.add')\", 3)])\n",
      "collecting tokens for  mrs.\n",
      "indices:    {22501}\n",
      "dict_items([])\n",
      "collecting tokens for  yesterday\n",
      "indices:    {608, 20485, 22502, 22501, 22504, 21353, 21611, 26636, 21644, 20493, 22525, 24145, 21693, 21657, 20477, 14942, 21375}\n",
      "dict_items([(\"Lemma('yesterday.n.01.yesterday')\", 2)])\n",
      "collecting tokens for  58\n",
      "indices:    {20161, 26629, 3816, 23305, 20169, 3821, 3833, 23004, 5535}\n",
      "dict_items([])\n",
      "collecting tokens for  unable\n",
      "indices:    {13952, 11265, 25985, 18449, 12700, 14239, 32674, 4906, 21679, 32431, 36274, 20158, 30528, 25921, 7618, 25925, 3831, 7292, 21972, 2134, 15574, 30938, 12892, 2784, 26081, 27109, 12008, 36200, 33132, 5487, 497, 7794, 1266, 34165, 32502, 35959, 3832, 3833, 3068}\n",
      "dict_items([(\"Lemma('unable.a.01.unable')\", 17), (\"Lemma('unable.s.02.unable')\", 4)])\n",
      "collecting tokens for  demonstrate\n",
      "indices:    {21752, 16146, 15651, 30886, 2984, 25663, 20416, 12233, 26957, 12237, 30418, 27091, 32865, 22387, 27251, 13688, 3833, 3835, 3836}\n",
      "dict_items([(\"Lemma('show.v.01.demonstrate')\", 10), (\"Lemma('prove.v.02.demonstrate')\", 5), (\"Lemma('attest.v.01.demonstrate')\", 1), (\"Lemma('demonstrate.v.04.demonstrate')\", 1)])\n",
      "collecting tokens for  existence\n",
      "indices:    {2304, 14599, 32264, 32266, 8850, 2322, 16275, 16277, 1306, 5147, 25500, 25501, 10782, 30631, 25897, 35760, 31922, 1463, 1464, 2234, 21440, 31174, 31816, 18250, 11211, 28363, 3409, 14034, 16211, 3797, 14422, 3835, 32101, 23785, 13674, 1515, 14828, 2412, 13675, 5225, 1513, 31217, 13810, 9580, 1269, 2678, 31223, 16379}\n",
      "dict_items([(\"Lemma('being.n.01.existence')\", 26)])\n",
      "collecting tokens for  methods\n",
      "indices:    {24001, 12323, 3993, 3526, 2728, 4010, 3565, 11409, 11217, 30483, 21461, 4374, 3992, 31129, 14554, 23484, 3871}\n",
      "dict_items([(\"Lemma('method.n.01.method')\", 12)])\n",
      "collecting tokens for  mcfeeley\n",
      "indices:    {7350}\n",
      "dict_items([(\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  parents\n",
      "indices:    {30976, 13156, 33673, 21129, 13204, 30492}\n",
      "dict_items([(\"Lemma('parent.n.01.parent')\", 2)])\n",
      "collecting tokens for  police\n",
      "indices:    {30945, 21635, 17285, 13031, 21194, 25230, 20337, 36884, 24441, 13973, 13976, 25, 11066, 16829}\n",
      "dict_items([(\"Lemma('police.n.01.police')\", 4)])\n",
      "collecting tokens for  half\n",
      "indices:    {17536, 6952, 10955, 34962, 26963, 5051}\n",
      "dict_items([(\"Lemma('one-half.n.01.half')\", 2), (\"Lemma('half.s.01.half')\", 1)])\n",
      "collecting tokens for  personal\n",
      "indices:    {2307, 32260, 23300, 25353, 32394, 31119, 14223, 27409, 27408, 34710, 32154, 32411, 22648, 32413, 25888, 25890, 28079, 14643, 26937, 25915, 21308, 22592, 28102, 18247, 24009, 27343, 13266, 13524, 9174, 15574, 21206, 32218, 13918, 14050, 28269, 13294, 28142, 28144, 21237, 32376, 32378, 13819, 33020}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('personal.a.01.personal')\", 9), (\"Lemma('personal.s.02.personal')\", 3)])\n",
      "collecting tokens for  discussions\n",
      "indices:    {3731, 27852}\n",
      "dict_items([(\"Lemma('discussion.n.01.discussion')\", 1)])\n",
      "collecting tokens for  participation\n",
      "indices:    {2076, 6046}\n",
      "dict_items([(\"Lemma('engagement.n.07.participation')\", 1)])\n",
      "collecting tokens for  extent\n",
      "indices:    {27274, 33167, 14739, 15000, 12956, 15773, 1310, 33183, 15264, 3361, 25506, 5404, 32933, 4775, 31912, 14639, 14895, 27697, 12467, 3892, 3893, 14390, 9782, 30008, 32954, 12220, 1853, 32192, 5188, 32583, 5449, 1354, 1225, 13260, 24525, 27726, 24527, 16458, 1232, 13385, 10707, 32340, 27989, 31056, 27991, 32988, 3293, 27998, 27775, 5471, 14946, 14690, 16356, 16357, 14949, 16358, 28003, 13291, 2796, 15858, 25074, 1909, 3574, 15735, 23030, 3190, 3199}\n",
      "dict_items([(\"Lemma('extent.n.01.extent')\", 23), (\"Lemma('extent.n.02.extent')\", 15)])\n",
      "collecting tokens for  doctors\n",
      "indices:    {27424, 27417, 25215, 21191}\n",
      "dict_items([])\n",
      "collecting tokens for  noted\n",
      "indices:    {15235, 27908, 12045, 21904, 24727, 3948, 27034, 17563, 3746, 33957, 16044, 22703, 21425, 32565, 4021, 3769, 3773, 29376, 31170, 14020, 3781, 7369, 3786, 27340, 3788, 11342, 3789, 12368, 3794, 3795, 33113, 380, 30940, 20191, 11231, 36963, 3812, 36965, 29285, 33127, 4713, 8811, 13804, 3820, 22253, 27247, 37103, 17144, 12527, 11507, 16371, 1909, 22258, 27765, 1912, 6521, 31099, 32892}\n",
      "dict_items([(\"Lemma('note.v.01.note')\", 24), (\"Lemma('note.v.03.note')\", 15), (\"Lemma('notice.v.02.note')\", 12), (\"Lemma('celebrated.s.01.noted')\", 3), (\"Lemma('note.v.04.note')\", 1)])\n",
      "collecting tokens for  curious\n",
      "indices:    {34694, 25735, 34696, 31880, 18438, 22675, 14622, 2591, 20641, 16673, 34734, 34750, 11455, 34752, 8261, 9675, 13901, 8527, 2640, 10962, 9686, 18007, 31837, 36317, 13406, 11114, 5997, 27247, 13935, 35697, 5875, 9847}\n",
      "dict_items([(\"Lemma('curious.s.01.curious')\", 9), (\"Lemma('curious.a.02.curious')\", 10)])\n",
      "collecting tokens for  stresses\n",
      "indices:    {3010, 30210, 32037, 31655, 14824, 16010, 16011, 30222, 27247, 26513, 24338, 16019, 30806, 30102, 20635, 32895, 30207}\n",
      "dict_items([(\"Lemma('stress.v.01.stress')\", 3), (\"Lemma('stress.n.01.stress')\", 3), (\"Lemma('stress.n.05.stress')\", 2)])\n",
      "collecting tokens for  nazi\n",
      "indices:    {12206}\n",
      "dict_items([(\"Lemma('nazi.n.01.Nazi')\", 1)])\n",
      "collecting tokens for  occupation\n",
      "indices:    {4928, 31744, 13698, 130, 16230, 31145, 7946, 22059, 22060, 27083, 27247, 27827, 19604, 26521, 31, 23678, 23679}\n",
      "dict_items([(\"Lemma('occupation.n.01.occupation')\", 4), (\"Lemma('occupation.n.04.occupation')\", 1), (\"Lemma('occupation.n.02.occupation')\", 1)])\n",
      "collecting tokens for  artery\n",
      "indices:    {3848, 3849, 3850, 3853, 29969, 27189, 3767, 3770, 3771, 3772, 3773, 3779, 3782, 3783, 3785, 3790, 3791, 3792, 27229, 4062, 3813, 3814, 27238, 27240, 3817, 27243, 3820, 27247, 3824, 3826, 3828, 3829, 3830, 3836}\n",
      "dict_items([(\"Lemma('artery.n.01.artery')\", 1)])\n",
      "collecting tokens for  disease\n",
      "indices:    {3458, 11531, 3596, 3470, 3477, 31129, 3481, 11546, 3484, 3492, 12083, 27189, 27191, 27194, 2623, 4672, 3394, 11075, 3398, 4040, 2637, 2638, 2639, 2256, 724, 14169, 2265, 27229, 32734, 2269, 27247, 25720}\n",
      "dict_items([(\"Lemma('disease.n.01.disease')\", 20)])\n",
      "collecting tokens for  dropping\n",
      "indices:    {5061, 3353, 20490, 36205, 8817, 18833, 29049, 34173}\n",
      "dict_items([(\"Lemma('drop.v.02.drop')\", 2), (\"Lemma('drop.v.03.drop')\", 1), (\"Lemma('drop.v.06.drop')\", 1), (\"Lemma('drop.v.01.drop')\", 2), (\"Lemma('drop.v.05.drop')\", 1), (\"Lemma('sink.v.01.drop')\", 1)])\n",
      "collecting tokens for  agree\n",
      "indices:    {3075, 23943, 31367, 21395, 663, 6807, 7074, 6820, 19368, 3371, 25388, 14127, 21679, 25394, 11703, 21452, 34380, 32204, 19023, 11983, 34390, 25174, 2520, 4829, 29921, 4450, 27109, 4454, 4455, 18280, 3059, 23287, 14459, 27134}\n",
      "dict_items([(\"Lemma('agree.v.02.agree')\", 8), (\"Lemma('agree.v.01.agree')\", 23), (\"Lemma('match.v.01.agree')\", 2), (\"Lemma('harmonize.v.01.agree')\", 1)])\n",
      "collecting tokens for  slavery\n",
      "indices:    {32001, 32008, 28049, 28050, 28052, 28053, 28054, 27288, 28057, 28063, 5281, 28065, 27812, 32050, 13763, 27470, 5332, 5336, 2520, 5340, 32994, 5352, 5353, 5354, 31848, 31988, 31989}\n",
      "dict_items([(\"Lemma('bondage.n.02.slavery')\", 8)])\n",
      "collecting tokens for  maintain\n",
      "indices:    {5505, 16898, 9225, 16399, 16400, 32016, 11666, 32015, 14735, 16149, 23573, 5402, 14750, 26782, 33056, 14766, 12207, 13366, 3767, 3768, 25014, 24888, 22075, 1468, 32957, 21828, 15045, 18504, 1105, 33233, 2520, 11742, 31969, 33003, 23666, 32502, 16374, 11768, 14207}\n",
      "dict_items([(\"Lemma('conserve.v.02.maintain')\", 16), (\"Lemma('keep.v.01.maintain')\", 13), (\"Lemma('wield.v.01.maintain')\", 2), (\"Lemma('assert.v.01.maintain')\", 2), (\"Lemma('sustain.v.04.maintain')\", 6)])\n",
      "collecting tokens for  northern\n",
      "indices:    {13265}\n",
      "dict_items([(\"Lemma('northern.a.01.northern')\", 1)])\n",
      "collecting tokens for  ended\n",
      "indices:    {9346, 33156, 33805, 143, 22931, 26517, 14107, 6049, 21794, 22954, 16823, 10555, 12608, 1600, 5585, 8918, 26333, 31713, 12515, 623, 13552, 23415, 23416}\n",
      "dict_items([(\"Lemma('end.v.02.end')\", 3), (\"Lemma('end.v.01.end')\", 13), (\"Lemma('end.v.03.end')\", 5)])\n",
      "collecting tokens for  virginia\n",
      "indices:    {14387}\n",
      "dict_items([(\"Lemma('virginia.n.01.Virginia')\", 1)])\n",
      "collecting tokens for  enable\n",
      "indices:    {25728, 25793, 26782, 25444, 13285, 11943, 33578, 3983, 4911, 25200, 14898, 35986, 16313, 15387, 2556, 16318}\n",
      "dict_items([(\"Lemma('enable.v.01.enable')\", 16)])\n",
      "collecting tokens for  keep\n",
      "indices:    {13447, 8204, 30033, 36083, 23605, 29407}\n",
      "dict_items([(\"Lemma('watch.v.02.keep_an_eye_on')\", 1), (\"Lemma('keep.v.01.keep')\", 3), (\"Lemma('exclude.v.02.keep_out')\", 1), (\"Lemma('keep.v.03.keep')\", 1)])\n",
      "collecting tokens for  touch\n",
      "indices:    {5763, 11140, 13572, 10118, 16519, 20486, 22281, 10122, 7179, 19207, 4493, 20104, 22287, 26897, 1556, 26901, 26005, 8087, 9113, 17433, 15387, 17563, 34334, 23331, 4905, 29316, 4908, 4909, 4911, 4913, 12209, 14643, 4917, 10553, 4923, 19645, 4926, 21952, 5696, 4930, 4931, 4929, 20933, 22471, 27720, 7113, 35151, 22864, 7119, 1746, 1618, 5849, 7003, 10588, 31965, 2654, 2015, 4958, 34783, 20836, 5860, 12649, 29419, 36589, 31088, 10865, 16500, 10491, 19836, 24701, 28671}\n",
      "dict_items([(\"Lemma('touch.n.01.touch')\", 8), (\"Lemma('touch.n.02.touch')\", 3), (\"Lemma('touch.v.02.touch')\", 3), (\"Lemma('touch.n.03.touch')\", 1), (\"Lemma('touch.v.01.touch')\", 13), (\"Lemma('contact.n.08.touch')\", 1), (\"Lemma('touch.v.05.touch')\", 2), (\"Lemma('affect.v.01.touch')\", 3), (\"Lemma('touch.v.07.touch')\", 1), (\"Lemma('touch.n.05.touch')\", 2), (\"Lemma('refer.v.02.touch_on')\", 1), (\"Lemma('touch.v.13.touch')\", 1), (\"Lemma('touch.v.11.touch')\", 1), (\"Lemma('equal.v.02.touch')\", 1), (\"Lemma('allude.v.01.touch')\", 1), (\"Lemma('touch.n.04.touch')\", 1), (\"Lemma('refer.v.02.touch')\", 1)])\n",
      "collecting tokens for  regularly\n",
      "indices:    {23104, 33122, 11678, 30084, 1765, 14761, 25353, 21810, 31638, 7030, 15387, 14526, 26974}\n",
      "dict_items([(\"Lemma('regularly.r.01.regularly')\", 6)])\n",
      "collecting tokens for  colleagues\n",
      "indices:    {15398, 15435, 26092, 27277, 14641, 32218, 27315, 24020, 20471, 4633, 5626, 15387, 15422}\n",
      "dict_items([(\"Lemma('colleague.n.01.colleague')\", 6), (\"Lemma('colleague.n.02.colleague')\", 1)])\n",
      "collecting tokens for  departments\n",
      "indices:    {11777, 15491, 24164, 6, 16295, 15435, 25228, 32503, 13, 25231, 25233, 14738, 32757, 32694, 24441, 15385, 15387}\n",
      "dict_items([(\"Lemma('department.n.01.department')\", 6)])\n",
      "collecting tokens for  performance\n",
      "indices:    {20484, 11271, 1032, 10258, 4638, 1058, 1067, 1071, 2611, 30811, 6246, 4600, 2666, 1136, 6769, 639, 24198, 26250, 6286, 6801, 6802, 9363, 9364, 6807, 6813, 15521, 23716, 26281, 9904, 26289, 26804, 26301, 6845, 1215, 1213, 20674, 9927, 20679, 1738, 25803, 31947, 31950, 31951, 20693, 1751, 1754, 28894, 29428, 1785, 1787, 15611, 15612, 26876, 1795, 1797, 1799, 1801, 26893, 26912, 26406, 11054, 11056, 11060, 11068, 4930, 11085, 26463, 15714, 15718, 4456, 15725, 26483, 15737, 26490, 22397, 20868, 32133, 12678, 20871, 28549, 31626, 25995, 25994, 10128, 914, 22418, 31638, 26012, 925, 24481, 33188, 428, 24497, 23995, 11199, 26563, 22991, 2025, 4592, 1016}\n",
      "dict_items([(\"Lemma('performance.n.02.performance')\", 15), (\"Lemma('performance.n.03.performance')\", 12), (\"Lemma('performance.n.01.performance')\", 24)])\n",
      "collecting tokens for  meaningless\n",
      "indices:    {34405, 32522, 428, 1357, 13618, 26707, 22388, 26421, 6203, 36892}\n",
      "dict_items([(\"Lemma('meaningless.a.01.meaningless')\", 4)])\n",
      "collecting tokens for  exhibition\n",
      "indices:    {26784, 32705, 21831, 26761, 21586, 179, 26770, 19574}\n",
      "dict_items([(\"Lemma('exhibition.n.01.exhibition')\", 1), (\"Lemma('exhibition.n.02.exhibition')\", 1)])\n",
      "collecting tokens for  game\n",
      "indices:    {23047, 3610, 11805, 34848, 33838, 17967, 595, 598, 11868, 11870, 11871, 626, 11902, 640, 647, 31370, 652, 653, 8334, 657, 658, 680, 16555, 2230, 183, 190, 211, 24796, 221, 24800, 22756, 232, 23798, 2303, 256, 34560, 268, 13581, 273, 275, 278, 24859, 290, 291, 2345, 297, 19756, 302, 36661, 313, 317, 319, 20803, 324, 327, 329, 330, 331, 335, 6481, 340, 342, 31574, 352, 19809, 355, 356, 361, 374, 887, 377, 29053, 22909, 24446, 385, 387, 388, 29074, 19865, 35231, 22951, 425, 22964, 19893, 443, 450, 451, 458, 22995, 488, 19955}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('game.n.04.game')\", 5), (\"Lemma('game.n.03.game')\", 9), (\"Lemma('game.n.01.game')\", 25), (\"Lemma('game.n.02.game')\", 21)])\n",
      "collecting tokens for  bears\n",
      "indices:    {444}\n",
      "dict_items([(\"Lemma('group.n.01.group')\", 1)])\n",
      "collecting tokens for  stadium\n",
      "indices:    {608}\n",
      "dict_items([])\n",
      "collecting tokens for  1951\n",
      "indices:    {3809, 15490, 4131, 30855, 21225, 26762, 428, 32332, 33037, 12271, 32336}\n",
      "dict_items([])\n",
      "collecting tokens for  quiet\n",
      "indices:    {34567, 26377, 17684, 26389, 29214, 25247, 25763, 27562, 23722, 14634, 19119, 23731, 24392, 25674, 81, 29267, 31328, 31330, 21738, 19306, 21740, 31599, 26227, 26228, 13555, 33271, 510, 17791}\n",
      "dict_items([(\"Lemma('quiet.a.02.quiet')\", 1), (\"Lemma('quiet.a.01.quiet')\", 4), (\"Lemma('silence.n.02.quiet')\", 1), (\"Lemma('hushed.s.01.quiet')\", 1)])\n",
      "collecting tokens for  painted\n",
      "indices:    {24194, 11270, 5385, 26762, 26764, 7836, 17055, 17073, 6078, 14403, 19527, 6088, 19531, 19536, 11094, 29405, 16478, 33890, 22500, 31591, 25704, 29808, 29810, 19572, 25721, 25722, 4991}\n",
      "dict_items([(\"Lemma('paint.v.02.paint')\", 7), (\"Lemma('paint.v.03.paint')\", 6), (\"Lemma('painted.s.02.painted')\", 1), (\"Lemma('paint.v.01.paint')\", 4), (\"Lemma('painted.a.01.painted')\", 2), (\"Lemma('suggest.v.05.paint_a_picture')\", 1)])\n",
      "collecting tokens for  cows\n",
      "indices:    {11590, 12775, 13609, 11594, 12073, 11601, 6931, 660, 11605, 11545, 11578}\n",
      "dict_items([(\"Lemma('cattle.n.01.cows')\", 4), (\"Lemma('cow.n.01.cow')\", 2), (\"Lemma('cow.n.02.cow')\", 1)])\n",
      "collecting tokens for  receiving\n",
      "indices:    {27679, 35689, 18314, 11339, 6156, 23629, 34450, 6581, 5558, 1466, 14012, 31613, 2878, 3327}\n",
      "dict_items([(\"Lemma('receive.v.02.receive')\", 4), (\"Lemma('experience.v.03.receive')\", 1), (\"Lemma('receive.v.01.receive')\", 6), (\"Lemma('pick_up.v.09.receive')\", 1), (\"Lemma('receive.v.05.receive')\", 1)])\n",
      "collecting tokens for  drug\n",
      "indices:    {11557, 34798, 34833, 2237, 11581, 4223}\n",
      "dict_items([(\"Lemma('drug.n.01.drug')\", 3)])\n",
      "collecting tokens for  officially\n",
      "indices:    {25602, 33155, 27266, 31978, 21707, 23275, 9775, 4687, 11569, 27890, 25622, 33978, 27899, 22013, 29342}\n",
      "dict_items([(\"Lemma('formally.r.01.officially')\", 1), (\"Lemma('officially.r.01.officially')\", 2)])\n",
      "collecting tokens for  tested\n",
      "indices:    {15749, 14343, 15753, 14348, 15760, 4241, 2962, 2960, 35474, 3989, 29078, 2970, 14364, 9900, 15534, 11569, 25652, 16190, 3526, 3527, 32714, 27339, 3542, 3549, 33249, 14821, 3558, 11623, 31717, 3564, 33263, 11632, 3579}\n",
      "dict_items([(\"Lemma('screen.v.01.test')\", 9), (\"Lemma('test.v.01.test')\", 16), (\"Lemma('tested.s.02.tested')\", 1), (\"Lemma('quiz.v.01.test')\", 3), (\"Lemma('tested.s.01.tested')\", 2)])\n",
      "collecting tokens for  breed\n",
      "indices:    {2337, 23562, 28592, 8693, 9335}\n",
      "dict_items([(\"Lemma('engender.v.01.breed')\", 1)])\n",
      "collecting tokens for  programs\n",
      "indices:    {16304}\n",
      "dict_items([(\"Lemma('plan.n.01.program')\", 1)])\n",
      "collecting tokens for  god\n",
      "indices:    {6045}\n",
      "dict_items([(\"Lemma('god.n.01.God')\", 1)])\n",
      "collecting tokens for  knows\n",
      "indices:    {24958, 7687, 12808, 11913, 14071, 28562, 5010, 5907, 5908, 1942, 24339, 5272, 25758, 11808, 29990, 551, 27185, 16947, 32438, 31543, 28984, 568, 24250, 5946, 14014, 15423, 31425, 11329, 15427, 31426, 25921, 19143, 2504, 13769, 34125, 2126, 21069, 24656, 1618, 723, 30295, 17626, 27103, 1504, 22241, 12005, 25582, 6640, 21490, 19958, 16631, 26110, 24959}\n",
      "dict_items([(\"Lemma('know.v.01.know')\", 26), (\"Lemma('know.v.02.know')\", 13), (\"Lemma('know.v.03.know')\", 2), (\"Lemma('know.v.04.know')\", 2)])\n",
      "collecting tokens for  charged\n",
      "indices:    {14722, 2, 25100, 25741, 7310, 35600, 3217, 3218, 3221, 3222, 27, 21541, 33829, 12837, 31272, 35624, 21674, 32430, 21303, 34105, 20154, 27963, 7613, 20669, 14786, 20167, 12876, 20689, 16340, 12893, 1383, 25966, 21487, 3193, 3194}\n",
      "dict_items([(\"Lemma('charge.v.08.charge')\", 2), (\"Lemma('charge.v.06.charge')\", 2), (\"Lemma('charge.v.02.charge')\", 7), (\"Lemma('charge.v.03.charge')\", 2), (\"Lemma('appoint.v.02.charge')\", 4), (\"Lemma('charged.a.01.charged')\", 5), (\"Lemma('charge.v.01.charge')\", 3), (\"Lemma('tear.v.03.charge')\", 4), (\"Lemma('charge.v.07.charge')\", 3), (\"Lemma('charged.s.02.charged')\", 1)])\n",
      "collecting tokens for  spontaneous\n",
      "indices:    {21378, 33187, 31908, 32035, 15815, 12648, 33226, 11214, 30813, 4789, 5205, 4887, 14653, 7613}\n",
      "dict_items([(\"Lemma('spontaneous.a.01.spontaneous')\", 8)])\n",
      "collecting tokens for  energy\n",
      "indices:    {2951, 11403, 27284, 5653, 3225, 32030, 15520, 15521, 3235, 32035, 25384, 2858, 3244, 2995, 4659, 2996, 2998, 3006, 2887, 26827, 15838, 3041, 33380, 14827, 5742, 3310, 11384, 36857}\n",
      "dict_items([(\"Lemma('energy.n.02.energy')\", 1), (\"Lemma('energy.n.01.energy')\", 10), (\"Lemma('energy.n.04.energy')\", 1), (\"Lemma('energy.n.03.energy')\", 1)])\n",
      "collecting tokens for  careful\n",
      "indices:    {31105, 36098, 35971, 35844, 25089, 14470, 25357, 16662, 17943, 5275, 13566, 27425, 35319, 26788, 32549, 14633, 29751, 29884, 7613, 10814, 19523, 13123, 29767, 6087, 28621, 26190, 33615, 29264, 22352, 19412, 8154, 23642, 7777, 4579, 11748, 25189, 17511, 30056, 32617, 16494, 9070, 35317, 4087, 23163, 27646, 35967}\n",
      "dict_items([(\"Lemma('careful.a.01.careful')\", 17), (\"Lemma('careful.s.02.careful')\", 2)])\n",
      "collecting tokens for  detailed\n",
      "indices:    {20561, 3730, 20317}\n",
      "dict_items([(\"Lemma('detail.v.02.detail')\", 1), (\"Lemma('detailed.s.01.detailed')\", 1)])\n",
      "collecting tokens for  wax\n",
      "indices:    {29881, 30695, 29545, 36205, 16667, 29654, 5655, 16664, 7609, 7611, 7613}\n",
      "dict_items([(\"Lemma('wax.n.01.wax')\", 6), (\"Lemma('wax.v.01.wax')\", 1)])\n",
      "collecting tokens for  glued\n",
      "indices:    {19969, 29720, 29722, 10523, 8865, 29730, 5412, 29861, 29734, 29735, 29742, 29744, 9654, 29751, 7613, 29774, 29805, 29807, 5364}\n",
      "dict_items([(\"Lemma('glued.s.01.glued')\", 2), (\"Lemma('glue.v.01.glue')\", 15), (\"Lemma('glue.v.02.glue')\", 2)])\n",
      "collecting tokens for  mere\n",
      "indices:    {14336, 18309, 3723, 27531, 24338, 27799, 14232, 7959, 36891, 17694, 27554, 31789, 2491, 7613, 1480, 12233, 3791, 36945, 4177, 13651, 4700, 8287, 15848, 22890, 9579, 14700, 15468, 31352, 3835}\n",
      "dict_items([(\"Lemma('mere.s.01.mere')\", 18), (\"Lemma('bare.s.06.mere')\", 2)])\n",
      "collecting tokens for  fellows\n",
      "indices:    {27712, 12606, 37060, 31400, 4651, 22769, 16758, 15454, 11103}\n",
      "dict_items([(\"Lemma('companion.n.01.fellow')\", 1), (\"Lemma('chap.n.01.fellow')\", 4)])\n",
      "collecting tokens for  shoes\n",
      "indices:    {7169, 6657, 2193, 17813, 19482, 23838, 34976, 35745, 11170, 12577, 36132, 36133, 10793, 685, 692, 22071, 9146, 37053, 10689, 705, 707, 16714, 19671, 11103, 19680, 7009, 29023, 30563, 36966, 6893, 36335, 33908}\n",
      "dict_items([(\"Lemma('shoe.n.01.shoe')\", 17), (\"Lemma('place.n.06.shoes')\", 1)])\n",
      "collecting tokens for  china\n",
      "indices:    {25528}\n",
      "dict_items([])\n",
      "collecting tokens for  ancient\n",
      "indices:    {12707, 25669, 26569, 31567, 10099, 27550}\n",
      "dict_items([(\"Lemma('ancient.s.01.ancient')\", 1)])\n",
      "collecting tokens for  tradition\n",
      "indices:    {1797, 5253, 5002, 5003, 11281, 24083, 2325, 2326, 26907, 25500, 12834, 25139, 11958, 14008, 26682, 31802, 1341, 1345, 1346, 1348, 11077, 14405, 21061, 26312, 14939, 32992, 32993, 11234, 28134, 28137, 32236, 1011, 4724, 26360, 12281, 12283, 26364}\n",
      "dict_items([(\"Lemma('tradition.n.01.tradition')\", 17), (\"Lemma('custom.n.02.tradition')\", 4)])\n",
      "collecting tokens for  heritage\n",
      "indices:    {1316, 32630}\n",
      "dict_items([(\"Lemma('heritage.n.01.heritage')\", 1)])\n",
      "collecting tokens for  creation\n",
      "indices:    {27904, 14080, 24704, 2435, 31884, 14228, 31900, 30749, 31907, 31908, 1326, 23225, 16442, 1724, 1470, 23619, 32329, 21706, 28235, 28237, 22734, 19030, 31831, 23514, 1509, 1516, 27118, 4722, 123, 27903}\n",
      "dict_items([(\"Lemma('creation.n.01.creation')\", 5), (\"Lemma('initiation.n.02.creation')\", 2), (\"Lemma('creation.n.02.creation')\", 2), (\"Lemma('creation.n.03.creation')\", 2), (\"Lemma('creation.n.05.Creation')\", 1)])\n",
      "collecting tokens for  cyclist\n",
      "indices:    {2692, 2694, 2699, 2669, 2703, 2683, 2684, 2687}\n",
      "dict_items([(\"Lemma('cyclist.n.01.cyclist')\", 8)])\n",
      "collecting tokens for  fellow\n",
      "indices:    {20353, 30723, 6020, 20101, 21000, 23310, 30608, 36369, 15766, 21375, 26397, 9629, 14240, 8226, 36899, 18595, 5925, 427, 1204, 5945, 32198, 22864, 2256, 34900, 11224, 31706, 21980, 16504, 15845, 11239, 31720, 26858, 12907, 14450, 25330, 12918, 22904, 2684, 37119}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('chap.n.01.fellow')\", 10), (\"Lemma('colleague.n.02.fellow')\", 1)])\n",
      "collecting tokens for  identified\n",
      "indices:    {10753, 3976, 21768, 21259, 21391, 36881, 29970, 20505, 17822, 21410, 23334, 1449, 18730, 21675, 15921, 22707, 7350, 15421, 12222, 4926, 21443, 2812, 7371, 36044, 14799, 2139, 1505, 3937, 4718, 4210, 3957, 19320, 29178, 2684}\n",
      "dict_items([(\"Lemma('identify.v.01.identify')\", 21), (\"Lemma('identify.v.03.identify')\", 1), (\"Lemma('name.v.02.identify')\", 6), (\"Lemma('identify.v.04.identify')\", 4), (\"Lemma('identify.v.06.identify')\", 1), (\"Lemma('identified.s.01.identified')\", 1)])\n",
      "collecting tokens for  simply\n",
      "indices:    {22688, 9186, 31800, 6405, 36202, 33521, 12952, 27901, 36218, 11036, 34941, 2142}\n",
      "dict_items([(\"Lemma('merely.r.01.simply')\", 5)])\n",
      "collecting tokens for  license\n",
      "indices:    {130, 32899, 23173, 33414, 18953, 14734, 21390, 33429, 33957, 27304, 14634, 2224, 33969, 31046, 33492, 33493, 33495, 33498, 20706, 30950, 20710, 2280, 36457, 20714, 20717, 14583, 2684, 22781}\n",
      "dict_items([(\"Lemma('license.n.01.license')\", 3), (\"Lemma('license.n.02.license')\", 2), (\"Lemma('license.v.01.license')\", 1)])\n",
      "collecting tokens for  piepsam\n",
      "indices:    {2710}\n",
      "dict_items([(\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  visit\n",
      "indices:    {29314, 29315, 23683, 11910, 29319, 21128, 27270, 13323, 29325, 25106, 8724, 7061, 29848, 24985, 29466, 31643, 24732, 36507, 1436, 5663, 933, 1830, 18347, 31020, 10797, 7087, 31664, 36529, 54, 31030, 9273, 7739, 27068, 24131, 29253, 5708, 24141, 333, 25292, 7630, 29269, 11480, 30297, 23131, 8284, 5981, 3676, 8286, 29280, 26977, 29281, 4450, 29276, 11108, 29303, 21609, 8298, 29304, 22382, 9582, 34800, 28400, 36594, 29299, 2163, 24819, 6772, 759, 31096, 29306, 36986, 24959}\n",
      "dict_items([(\"Lemma('travel_to.v.01.visit')\", 9), (\"Lemma('visit.n.02.visit')\", 7), (\"Lemma('visit.v.01.visit')\", 17), (\"Lemma('visit.n.03.visit')\", 4), (\"Lemma('visit.v.03.visit')\", 4), (\"Lemma('visit.n.01.visit')\", 9), (\"Lemma('visit.v.04.visit')\", 1), (\"Lemma('chew_the_fat.v.01.visit')\", 1)])\n",
      "collecting tokens for  abroad\n",
      "indices:    {23809, 24194, 24974, 21009, 15381, 26775, 24216, 27161, 13222, 22822, 24106, 15404, 15412, 15417, 30916, 32457, 9162, 32458, 11472, 15446, 22489, 25055, 13795, 14183, 13805, 22382, 14191, 14836, 36984, 12026, 32383}\n",
      "dict_items([(\"Lemma('abroad.r.01.abroad')\", 6), (\"Lemma('abroad.s.01.abroad')\", 5), (\"Lemma('overseas.r.02.abroad')\", 1)])\n",
      "collecting tokens for  santa\n",
      "indices:    {29176}\n",
      "dict_items([])\n",
      "collecting tokens for  orchestra\n",
      "indices:    {31593}\n",
      "dict_items([])\n",
      "collecting tokens for  rome\n",
      "indices:    {31674}\n",
      "dict_items([])\n",
      "collecting tokens for  learning\n",
      "indices:    {36490, 13324, 33165, 9996, 23058, 22679, 152, 11929, 12823, 19612, 15651, 22692, 27171, 6950, 26926, 21427, 21435, 37053, 15680, 833, 23621, 22354, 13277, 16221, 12641, 2019, 27621, 34406, 15719, 15718, 13166}\n",
      "dict_items([(\"Lemma('learn.v.01.learn')\", 13), (\"Lemma('learning.n.01.learning')\", 4), (\"Lemma('learn.v.02.learn')\", 4), (\"Lemma('learn.v.04.learn')\", 3), (\"Lemma('eruditeness.n.01.learning')\", 1)])\n",
      "collecting tokens for  shoe\n",
      "indices:    {10688, 7777, 19991, 29159, 1163, 13324, 9163, 686, 5172, 22071, 19675, 33695}\n",
      "dict_items([(\"Lemma('shoe.n.01.shoe')\", 5)])\n",
      "collecting tokens for  cabinet\n",
      "indices:    {30410, 31749}\n",
      "dict_items([])\n",
      "collecting tokens for  auto\n",
      "indices:    {29090, 13243, 23590, 29095, 16424, 21513, 29322, 18853, 13324, 29133, 24012, 29295, 29097, 23439, 21878, 29096, 27099}\n",
      "dict_items([(\"Lemma('car.n.01.auto')\", 1)])\n",
      "collecting tokens for  mechanics\n",
      "indices:    {11969, 27970, 25667, 32571, 3003, 26791, 11306, 13324, 6894, 22803, 23222, 13243, 3004, 3005}\n",
      "dict_items([(\"Lemma('mechanics.n.01.mechanics')\", 3), (\"Lemma('machinist.n.01.mechanic')\", 1), (\"Lemma('mechanism.n.02.mechanics')\", 2)])\n",
      "collecting tokens for  airplane\n",
      "indices:    {23330, 30537, 28683, 13324, 11085, 5899, 23353, 30587, 25053}\n",
      "dict_items([(\"Lemma('airplane.n.01.airplane')\", 2)])\n",
      "collecting tokens for  member\n",
      "indices:    {32207}\n",
      "dict_items([])\n",
      "collecting tokens for  native\n",
      "indices:    {26432, 29185, 21473, 21697, 30532, 33376, 31719, 10222, 25680, 13648, 33011, 11256, 23225}\n",
      "dict_items([(\"Lemma('native.a.01.native')\", 1)])\n",
      "collecting tokens for  diminished\n",
      "indices:    {33248, 1762, 24167, 12243, 4245, 4921, 15513, 4220, 15519}\n",
      "dict_items([(\"Lemma('decrease.v.01.diminish')\", 5), (\"Lemma('diminish.v.02.diminish')\", 1), (\"Lemma('diminished.s.01.diminished')\", 3)])\n",
      "collecting tokens for  respects\n",
      "indices:    {12544, 3841, 26627, 25734, 29066, 16397, 14478, 21903, 529, 5266, 4627, 31643, 5028, 13108, 2516, 31701, 29914, 24167, 31988, 25341}\n",
      "dict_items([(\"Lemma('respect.n.01.respect')\", 6), (\"Lemma('respects.n.01.respects')\", 3), (\"Lemma('respect.v.01.respect')\", 2)])\n",
      "collecting tokens for  retains\n",
      "indices:    {25120, 25058, 22309, 24167, 24170, 1650, 30394, 24766}\n",
      "dict_items([])\n",
      "collecting tokens for  assignment\n",
      "indices:    {11784, 32272, 32273, 32278, 33433, 32282, 14880, 32301, 11698, 15932, 32322, 13896, 22094, 593, 32338, 15965, 24167, 32363, 32364, 17646, 22900}\n",
      "dict_items([(\"Lemma('assignment.n.01.assignment')\", 5), (\"Lemma('assignment.n.02.assignment')\", 1), (\"Lemma('assignment.n.03.assignment')\", 2)])\n",
      "collecting tokens for  functions\n",
      "indices:    {4521, 4650, 32907, 24170, 21557, 27549, 4382}\n",
      "dict_items([(\"Lemma('function.n.02.function')\", 1), (\"Lemma('function.n.01.function')\", 2)])\n",
      "collecting tokens for  proud\n",
      "indices:    {21378, 25860, 32262, 28425, 24587, 9484, 25109, 28953, 9627, 31389, 36002, 31780, 6567, 679, 8366, 20398, 6396, 25015, 30021, 7881, 9174, 35930, 7517, 10335, 26849, 36066, 18276, 22884, 24933, 21099, 2540, 9586, 32243, 30834, 1404, 25727}\n",
      "dict_items([(\"Lemma('proud.a.01.proud')\", 12), (\"Lemma('gallant.s.03.proud')\", 1)])\n",
      "collecting tokens for  surprise\n",
      "indices:    {29056, 10885, 17674, 27531, 34699, 8336, 15761, 26643, 22424, 28441, 16922, 30242, 35875, 30372, 18598, 35756, 10414, 23984, 28475, 26431, 33219, 35786, 10315, 9164, 30667, 18382, 18257, 7505, 37082, 219, 28508, 33755, 22366, 6756, 20965, 6124, 17266, 22517, 21750, 36987}\n",
      "dict_items([(\"Lemma('surprise.n.01.surprise')\", 12), (\"Lemma('surprise.v.01.surprise')\", 4), (\"Lemma('surprise.n.02.surprise')\", 4)])\n",
      "collecting tokens for  laughed\n",
      "indices:    {19591, 8968, 11016, 10891, 7183, 36115, 10900, 10902, 30358, 18200, 9254, 36138, 37164, 34861, 19501, 6581, 5944, 18877, 17727, 9164, 36556, 16719, 9168, 36219, 10325, 8406, 8280, 9313, 6883, 8551, 9704, 9193, 17899, 9707, 5875, 35067, 36095}\n",
      "dict_items([(\"Lemma('laugh.v.01.laugh')\", 26)])\n",
      "collecting tokens for  expression\n",
      "indices:    {28034, 12542, 18691, 27527, 30984, 27530, 2321, 14610, 26901, 10519, 12315, 27548, 20126, 14712, 32039, 10287, 7607, 27708, 32062, 25282, 7364, 8134, 13383, 28025, 13386, 13642, 9164, 35021, 7123, 5211, 9180, 1376, 14690, 5603, 4472, 4709, 3046, 15847, 15848, 15850, 15852, 31086, 15856, 7537, 4849, 15859, 30837, 12534, 15864, 35065, 4350, 4348, 13693, 4990}\n",
      "dict_items([(\"Lemma('expression.n.03.expression')\", 9), (\"Lemma('expression.n.02.expression')\", 9), (\"Lemma('saying.n.01.expression')\", 5), (\"Lemma('expression.n.01.expression')\", 8), (\"Lemma('formula.n.01.expression')\", 4), (\"Lemma('formulation.n.03.expression')\", 3)])\n",
      "collecting tokens for  anyone\n",
      "indices:    {17360, 22338, 16742}\n",
      "dict_items([])\n",
      "collecting tokens for  else\n",
      "indices:    {16903, 34311, 19473, 26138, 17946, 19488, 10786, 5666, 25634, 23078, 19499, 19503, 20019, 9268, 18490, 33853, 30271, 16959, 20036, 24653, 27220, 16468, 30294, 2133, 11354, 27738, 31835, 24158, 12385, 2658, 10851, 10852, 3182, 33400, 16507, 13435, 1151, 6785, 27265, 24713, 13457, 18580, 14484, 34456, 10399, 20127, 19617, 14499, 14502, 7337, 35499, 5294, 6830, 35506, 31922, 11961, 18621, 14014, 26817, 26306, 26307, 19150, 17104, 25819, 19686, 26862, 33521, 14578, 14584, 5369, 5371, 35580, 11005, 17148, 16642, 36099, 37126, 16648, 6927, 19731, 24857, 16665, 23325, 17184, 17697, 27427, 10019, 10542, 13615, 14652, 27964, 26960, 20305, 9047, 16729, 21341, 14174, 30050, 36195, 35686, 7527, 14697, 18801, 26481, 1917, 31108, 28553, 6025, 31115, 23953, 22929, 26523, 31137, 33708, 31663, 18356, 31669, 12221, 9150, 8128, 33219, 19910, 25542, 27084, 9680, 23508, 36319, 2529, 6629, 9191, 15858, 24051, 8695, 10744, 17915, 6653}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([])\n",
      "collecting tokens for  candidates\n",
      "indices:    {12672, 25729, 4743, 4754, 20372, 24853, 24854, 1942, 24857, 24608, 23714, 20389, 24872, 4776, 4778, 26670, 47, 4783, 14641, 5301, 5303, 20409, 5306, 4805, 26699, 20812, 20817, 84, 20450, 20467, 15739}\n",
      "dict_items([(\"Lemma('campaigner.n.01.candidate')\", 13), (\"Lemma('candidate.n.02.candidate')\", 2)])\n",
      "collecting tokens for  manager\n",
      "indices:    {19846, 582, 5159, 19854, 5137, 5043, 33493, 15799, 15803, 19837}\n",
      "dict_items([(\"Lemma('coach.n.01.manager')\", 3), (\"Lemma('director.n.01.manager')\", 4)])\n",
      "collecting tokens for  controlling\n",
      "indices:    {14208, 12228, 25607, 12456, 31272, 30792, 15342, 23184, 27923, 11548, 346, 15804, 350, 4031}\n",
      "dict_items([(\"Lemma('control.v.02.control')\", 5), (\"Lemma('control.v.01.control')\", 6)])\n",
      "collecting tokens for  sessions\n",
      "indices:    {32483, 20645, 23950, 22357, 27606, 25495, 20445}\n",
      "dict_items([])\n",
      "collecting tokens for  lengthy\n",
      "indices:    {3170, 1034, 33168, 32177, 5427, 23893, 14454, 600, 15804}\n",
      "dict_items([(\"Lemma('drawn-out.s.01.lengthy')\", 6)])\n",
      "collecting tokens for  situations\n",
      "indices:    {32901, 15753, 27145, 15754, 15756, 21905, 23828, 2328, 2585, 15772, 16546, 15786, 15402, 15663, 15664, 34737, 33201, 16435, 15667, 16437, 1210, 33082, 15804, 28733, 15803, 4671, 16191, 4678, 28749, 22863, 16464, 12375, 11612, 27870, 33253, 33260, 33263}\n",
      "dict_items([(\"Lemma('situation.n.01.situation')\", 11), (\"Lemma('situation.n.02.situation')\", 12)])\n",
      "collecting tokens for  unexpectedly\n",
      "indices:    {28164, 16906, 8916, 15510, 8793, 16602, 11035, 15804}\n",
      "dict_items([(\"Lemma('by_chance.r.03.unexpectedly')\", 2), (\"Lemma('unexpectedly.r.01.unexpectedly')\", 5)])\n",
      "collecting tokens for  instructed\n",
      "indices:    {27584, 29603, 8005, 6406, 9863, 17640, 15664, 27601, 25788, 20796, 10679, 25019, 15804}\n",
      "dict_items([(\"Lemma('teach.v.01.instruct')\", 6), (\"Lemma('instruct.v.02.instruct')\", 7)])\n",
      "collecting tokens for  behave\n",
      "indices:    {19747, 1667, 14596, 2602, 34379, 4308, 8379, 15804}\n",
      "dict_items([(\"Lemma('act.v.02.behave')\", 5), (\"Lemma('behave.v.02.behave')\", 2), (\"Lemma('behave.v.03.behave')\", 1)])\n",
      "collecting tokens for  upset\n",
      "indices:    {28100, 774, 36872, 6027, 336, 16631, 10617, 10137, 15804, 1436}\n",
      "dict_items([(\"Lemma('upset.v.02.upset')\", 2), (\"Lemma('disturbance.n.02.upset')\", 1), (\"Lemma('disturb.v.01.upset')\", 2), (\"Lemma('upset.v.01.upset')\", 2), (\"Lemma('upset.s.03.upset')\", 1), (\"Lemma('disquieted.s.01.upset')\", 1), (\"Lemma('broken.s.08.upset')\", 1)])\n",
      "collecting tokens for  operate\n",
      "indices:    {14210, 16010, 14733, 32151, 14750, 14202, 32286, 21427, 32183, 29114, 15804, 24127, 29892, 29124, 5191, 2761, 25808, 26705, 36441, 16346, 31200, 11361, 4704, 1889, 22757, 20713, 28524, 34670, 23545, 20346, 16252, 14207}\n",
      "dict_items([(\"Lemma('operate.v.01.operate')\", 14), (\"Lemma('operate.v.03.operate')\", 4), (\"Lemma('function.v.01.operate')\", 13), (\"Lemma('manoeuver.v.03.operate')\", 1)])\n",
      "collecting tokens for  manner\n",
      "indices:    {1, 3078, 18950, 25094, 17937, 1554, 20, 26648, 16925, 11815, 11304, 1594, 8251, 1084, 4169, 29772, 32333, 2125, 24155, 32355, 8299, 11905, 4235, 3212, 22157, 3213, 1174, 26275, 23205, 30905, 30394, 33480, 7370, 34512, 27856, 4308, 28889, 1757, 33004, 28919, 22778, 12028, 24842, 28429, 12566, 28950, 1302, 11048, 23870, 4938, 15695, 24916, 24918, 15707, 3423, 30054, 28014, 28016, 7036, 32126, 14208, 15745, 36226, 8581, 20367, 26513, 14741, 26005, 22426, 28063, 13730, 2987, 13234, 15804, 9660, 26563, 3530, 16339, 31190, 8173, 4594, 17395, 9718, 8696}\n",
      "dict_items([(\"Lemma('manner.n.03.manner')\", 3), (\"Lemma('manner.n.01.manner')\", 26), (\"Lemma('manner.n.02.manner')\", 10)])\n",
      "collecting tokens for  previously\n",
      "indices:    {3251, 23757, 4207}\n",
      "dict_items([(\"Lemma('previously.r.01.previously')\", 2)])\n",
      "collecting tokens for  criticized\n",
      "indices:    {3811, 15788, 15789, 23822, 21200, 21433, 20218, 15804}\n",
      "dict_items([(\"Lemma('knock.v.06.criticize')\", 8)])\n",
      "collecting tokens for  cotton\n",
      "indices:    {21856, 13120, 21862, 262, 21870, 21847, 19160}\n",
      "dict_items([(\"Lemma('cotton.n.01.cotton')\", 2)])\n",
      "collecting tokens for  gin\n",
      "indices:    {21837}\n",
      "dict_items([])\n",
      "collecting tokens for  plant\n",
      "indices:    {1665, 5124, 14725, 5510, 5511, 11789, 5518, 1680, 23441, 16279, 5532, 24225, 21666, 21287, 1706, 2734, 24245, 5558, 5436, 24893, 9151, 32706, 5187, 28748, 32465, 5201, 4196, 25061, 1895, 21738, 11755, 11761, 12154, 11774}\n",
      "dict_items([(\"Lemma('plant.n.01.plant')\", 18), (\"Lemma('plant.v.01.plant')\", 1), (\"Lemma('plant.n.02.plant')\", 2)])\n",
      "collecting tokens for  neighborhood\n",
      "indices:    {35712, 33284, 9607, 7303, 35723, 24205, 36240, 13202, 17685, 17048, 13337, 24347, 13723, 9628, 4511, 4515, 4516, 3365, 4522, 4523, 10540, 13362, 4530, 31538, 4533, 20021, 4535, 36279, 3319, 4540, 7485, 25661, 36215, 4544, 27840, 24055, 21832, 30036, 27860, 30037, 12000, 9582, 25072, 13297, 17012, 20341, 12151, 15998}\n",
      "dict_items([(\"Lemma('vicinity.n.01.neighborhood')\", 21), (\"Lemma('neighborhood.n.02.neighborhood')\", 9)])\n",
      "collecting tokens for  safe\n",
      "indices:    {5254, 13580, 15383, 31257, 11162, 19610, 28702, 33186, 9379, 11043, 19367, 17580, 17581, 17582, 35247, 27185, 14260, 33716, 33844, 12982, 4660, 14392, 28731, 5820, 31549, 24893, 36423, 21832, 31176, 712, 36306, 36307, 6355, 8279, 15191, 8281, 16348, 29920, 12641, 18659, 31843, 33381, 12646, 26215, 30052, 8169, 7274, 12649, 30577, 12277, 30581}\n",
      "dict_items([(\"Lemma('safe.a.01.safe')\", 21), (\"Lemma('safe.n.01.safe')\", 6), (\"Lemma('safe.s.02.safe')\", 1)])\n",
      "collecting tokens for  countries\n",
      "indices:    {4608, 4615, 4617, 4618, 4620, 12303, 16403, 16410, 4638, 4643, 16437, 24630, 3637, 13882, 20552, 20554, 20555, 20556, 20559, 24153, 22624, 23649, 14951, 22647, 22648, 14985, 12943, 14992, 15504, 25769, 12970, 12985, 4793, 30398, 25279, 26310, 32469, 32471, 13536, 26347, 759, 28419, 20248, 20254, 33056, 20771, 20773, 20775, 20778, 20781, 20275, 21832, 32121, 32132, 32137, 32140, 32143, 32144, 20884, 24981, 14748, 32159, 32160, 32161, 32163, 32165, 23462, 23464, 32681, 23465, 23467, 23468, 32172, 32169, 23471, 32171, 23983, 23475, 32182, 32184, 32190, 23488, 32192, 32194, 12239, 12244, 12246, 36824, 4579, 4580, 12261, 4582, 27111, 27110, 4585, 4586, 4587, 4592, 4601, 4602}\n",
      "dict_items([(\"Lemma('state.n.04.country')\", 26), (\"Lemma('country.n.02.country')\", 2), (\"Lemma('nation.n.02.country')\", 1)])\n",
      "collecting tokens for  machinery\n",
      "indices:    {18948, 15385, 23453, 21283, 31270, 31150, 12081, 32179, 2739, 23483, 2753, 21827, 21830, 21832, 21835, 21836, 21842, 21843, 7895, 20059, 21981, 22622, 21859, 25956, 21990, 21991, 21992, 12137, 12138, 12139, 21996, 21997, 12140, 21864, 14064, 22000}\n",
      "dict_items([(\"Lemma('machinery.n.01.machinery')\", 11), (\"Lemma('machinery.n.02.machinery')\", 1)])\n",
      "collecting tokens for  contributions\n",
      "indices:    {21651, 8725, 21922, 22052, 29094, 28327, 11433, 23597, 21078, 32223, 25188, 21092, 17382, 20202, 20718, 31726, 24692, 32247, 21374}\n",
      "dict_items([(\"Lemma('contribution.n.02.contribution')\", 2), (\"Lemma('contribution.n.03.contribution')\", 1)])\n",
      "collecting tokens for  fixing\n",
      "indices:    {4805, 17382, 32550, 22409, 4142, 29427, 22804, 9269, 17917}\n",
      "dict_items([(\"Lemma('repair.v.01.fix')\", 2), (\"Lemma('cook.v.02.fix')\", 1), (\"Lemma('repair.n.01.fixing')\", 1), (\"Lemma('specify.v.02.fix')\", 2), (\"Lemma('fix.v.07.fix')\", 1)])\n",
      "collecting tokens for  scholarship\n",
      "indices:    {24736, 17351, 20202, 26187, 2347, 20204, 17328, 13268, 19582}\n",
      "dict_items([(\"Lemma('eruditeness.n.01.scholarship')\", 2), (\"Lemma('scholarship.n.01.scholarship')\", 3)])\n",
      "collecting tokens for  thirty\n",
      "indices:    {31552, 13601, 8226, 17380, 27653, 5861, 29932, 16909, 11278, 8339, 3738, 15252, 36340, 16791, 11160, 9146, 5787}\n",
      "dict_items([(\"Lemma('thirty.s.01.thirty')\", 10), (\"Lemma('thirty.n.01.thirty')\", 1)])\n",
      "collecting tokens for  thousand\n",
      "indices:    {12423, 6023, 32649, 35851, 25358, 7822, 8466, 32658, 1943, 17687, 10272, 20130, 32675, 5157, 29225, 2221, 32690, 28342, 11070, 3268, 8008, 17370, 17371, 17374, 10847, 17380, 7910, 8296, 29932, 17389, 13809, 13041, 34804, 14836, 20598, 32631, 37119}\n",
      "dict_items([(\"Lemma('thousand.s.01.thousand')\", 10), (\"Lemma('thousand.n.01.thousand')\", 2)])\n",
      "collecting tokens for  unfortunate\n",
      "indices:    {34720, 27553, 25985, 27715, 4994, 1025, 17382, 1130, 4779, 17356, 27727, 2387, 30996, 29013, 30552, 17341, 12504}\n",
      "dict_items([(\"Lemma('inauspicious.a.01.unfortunate')\", 3), (\"Lemma('unfortunate.a.01.unfortunate')\", 6)])\n",
      "collecting tokens for  johnston\n",
      "indices:    {21611}\n",
      "dict_items([])\n",
      "collecting tokens for  affair\n",
      "indices:    {24451, 2187, 20242, 12053, 26268, 12061, 5407, 21026, 10658, 12840, 14459, 30896, 16947, 7478, 36279, 6842, 17341, 20931, 17356, 21454, 18264, 11101, 1252, 17382, 22769, 22523}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('matter.n.01.affair')\", 8), (\"Lemma('affair.n.02.affair')\", 4), (\"Lemma('affair.n.03.affair')\", 4)])\n",
      "collecting tokens for  cholesterol\n",
      "indices:    {27235, 740, 27237, 743, 27239, 27240, 27244, 27245, 27184, 1714, 27250, 27186, 1716, 27191, 27256, 27230, 27231}\n",
      "dict_items([(\"Lemma('cholesterol.n.01.cholesterol')\", 4)])\n",
      "collecting tokens for  dr.\n",
      "indices:    {164}\n",
      "dict_items([])\n",
      "collecting tokens for  keys\n",
      "indices:    {16611, 27198}\n",
      "dict_items([(\"Lemma('key.n.01.key')\", 1)])\n",
      "collecting tokens for  mysterious\n",
      "indices:    {9601, 32035, 1256, 36424, 20041, 18219, 8109, 9390, 10543, 12367, 34833, 4659, 13942, 1278, 921, 2652, 6429, 27230}\n",
      "dict_items([(\"Lemma('cryptic.s.01.mysterious')\", 10), (\"Lemma('mysterious.s.02.mysterious')\", 4)])\n",
      "collecting tokens for  alcohol\n",
      "indices:    {33228}\n",
      "dict_items([])\n",
      "collecting tokens for  maid\n",
      "indices:    {9392, 29015}\n",
      "dict_items([(\"Lemma('maid.n.01.maid')\", 1)])\n",
      "collecting tokens for  fine\n",
      "indices:    {26761}\n",
      "dict_items([])\n",
      "collecting tokens for  registration\n",
      "indices:    {33088, 33025, 22337, 4739, 4, 4805, 4806, 33031, 4808, 33513, 32388, 33005, 4814, 33007, 32560, 33081, 33084, 33023}\n",
      "dict_items([(\"Lemma('registration.n.01.registration')\", 6)])\n",
      "collecting tokens for  continued\n",
      "indices:    {16898, 11277, 11278, 21524, 21527, 5146, 21532, 5154, 14908, 2630, 21575, 16464, 21585, 14420, 26708, 32859, 14941, 22624, 17511, 15465, 21099, 31865, 32900, 29342, 5282, 5283, 27812, 20654, 15536, 11441, 23730, 36020, 12472, 25277, 22206, 30916, 4806, 24264, 11467, 32460, 30925, 28363, 32461, 21201, 7378, 29393, 30425, 27867, 11496, 31988, 2304, 32024, 5405, 18727, 28465, 1330, 3891, 21307, 21309, 25425, 18773, 23894, 18775, 15716, 358, 10097, 18801, 3441, 2423, 7032, 12668, 7036, 7046, 2446, 21392, 10641, 1430, 10142, 20895, 18338, 5027, 18864, 4023, 4029, 4031, 33217, 31682, 18375, 17365, 32217, 4057, 32735, 12256, 10721, 2534, 32749, 36857}\n",
      "dict_items([(\"Lemma('continue.v.01.continue')\", 26), (\"Lemma('continue.v.02.continue')\", 15), (\"Lemma('continued.a.01.continued')\", 12), (\"Lemma('retain.v.02.continue')\", 2), (\"Lemma('continue.v.03.continue')\", 12), (\"Lemma('continue.v.06.continue')\", 1), (\"Lemma('proceed.v.02.continue')\", 2)])\n",
      "collecting tokens for  1960\n",
      "indices:    {32769, 22018, 515, 22017, 32767, 5129, 24616, 26667, 26672, 22065, 26677, 5181, 586, 20556, 23120, 597, 11871, 27744, 15472, 26738, 15477, 15478, 15483, 30843, 15490, 32391, 648, 15498, 15500, 20621, 15502, 15501, 15514, 23207, 32440, 32441, 32442, 23226, 32445, 32446, 32449, 21697, 4806, 15048, 15049, 15562, 32459, 32460, 15052, 15053, 32468, 213, 214, 32477, 30948, 23270, 13034, 21227, 32492, 23277, 24816, 21239, 256, 25856, 32515, 3334, 2823, 28427, 3339, 3341, 22283, 21267, 2840, 26929, 16183, 21815, 3387, 24892, 3388, 24896, 33091, 33110, 3930, 3933, 12135, 23400, 23404, 21874, 22899, 25972, 23415, 23418, 1916, 25469, 5504, 21894, 16268, 32656, 1426, 24479, 13727, 4002, 24483, 24494, 28593, 21937, 32696, 32697, 32698, 32702, 22992, 32722, 28630, 21976, 21977, 24025, 24028, 21985, 32762, 488, 21993, 32747, 32748, 23020, 32756, 22004, 32766, 32761, 22010, 32763, 32764, 22013, 27134, 22015}\n",
      "dict_items([])\n",
      "collecting tokens for  stem\n",
      "indices:    {29761, 16194, 29794, 12388, 16197, 4132, 4199, 29732, 13918, 4164, 29739, 16173, 16182, 29787, 16158}\n",
      "dict_items([(\"Lemma('root.n.03.stem')\", 5), (\"Lemma('stem.v.01.stem')\", 2), (\"Lemma('stalk.n.02.stem')\", 3)])\n",
      "collecting tokens for  root\n",
      "indices:    {4132, 12209, 12721, 25969, 16692, 30422, 30458, 24159}\n",
      "dict_items([(\"Lemma('beginning.n.04.root')\", 1), (\"Lemma('root.n.01.root')\", 1)])\n",
      "collecting tokens for  tumors\n",
      "indices:    {4132, 4167, 2216, 4199, 2217, 4176, 4182, 4151}\n",
      "dict_items([(\"Lemma('tumor.n.01.tumor')\", 8)])\n",
      "collecting tokens for  treated\n",
      "indices:    {7561, 5642, 15117, 36240, 16146, 24214, 20247, 33304, 18297, 22938, 5530, 4125, 4129, 35493, 23207, 2219, 28971, 21165, 4142, 4143, 26800, 35123, 4151, 4154, 4158, 16321, 4164, 21317, 21445, 16328, 4169, 30793, 22866, 4179, 2260, 21075, 5205, 26076, 1375, 4192, 4193, 4473, 21614, 3953, 5490, 13689, 26107, 21501}\n",
      "dict_items([(\"Lemma('treat.v.01.treat')\", 15), (\"Lemma('treat.v.03.treat')\", 7), (\"Lemma('treated.a.01.treated')\", 2), (\"Lemma('process.v.01.treat')\", 14), (\"Lemma('cover.v.05.treat')\", 4), (\"Lemma('treat.v.05.treat')\", 3)])\n",
      "collecting tokens for  solution\n",
      "indices:    {12225, 3274, 3249}\n",
      "dict_items([(\"Lemma('solution.n.01.solution')\", 2)])\n",
      "collecting tokens for  30\n",
      "indices:    {11265, 25107, 22553, 4126, 4135, 4136, 4137, 4139, 4140, 4142, 4144, 21558, 4151, 32310, 56, 29754, 21566, 4166, 4174, 21583, 27226, 25692, 30301, 25182, 26736, 26737, 15476, 30843, 13953, 11399, 29322, 11919, 3727, 30355, 663, 21657, 154, 21666, 25252, 25764, 3752, 20140, 25783, 2750, 11455, 12486, 15052, 15587, 21235, 24820, 20214, 23302, 15628, 23312, 26385, 3858, 26386, 30996, 11541, 32532, 32533, 32536, 32537, 32538, 32539, 32534, 11540, 288, 27425, 290, 23337, 28460, 28461, 22828, 819, 21822, 15172, 324, 25414, 21319, 25417, 32586, 29003, 20810, 25934, 31055, 32594, 32595, 3926, 2904, 32600, 32604, 32606, 13150, 22368, 29027, 29028, 32612, 32614, 22375, 28520, 22377, 29032, 28521, 21357, 29040, 5490, 32629, 20855, 18305, 27010, 22405, 29064, 20881, 20375, 27037, 929, 13227, 22446, 22447, 22448, 438, 443, 27074, 4034, 3525, 3535, 4049, 22998, 21975, 15320, 10713, 24036, 12773, 27110, 21489, 32756}\n",
      "dict_items([(\"Lemma('thirty.s.01.30')\", 26), (\"Lemma('thirty.n.01.30')\", 4), (\"Lemma('thirtieth.s.01.30th')\", 1)])\n",
      "collecting tokens for  washed\n",
      "indices:    {16641, 35862, 4128, 9640, 4139, 4140, 12715, 4144, 4151, 13760, 9410, 3522, 7880, 3531, 3536, 35921, 6866, 29395, 7646, 3168, 9058, 3556, 8054, 22909}\n",
      "dict_items([(\"Lemma('wash.v.02.wash')\", 5), (\"Lemma('wash.v.01.wash')\", 9), (\"Lemma('washed.s.01.washed')\", 2), (\"Lemma('wash.v.04.wash')\", 1), (\"Lemma('wash_down.v.01.wash_down')\", 1), (\"Lemma('wash.v.03.wash')\", 1)])\n",
      "collecting tokens for  saline\n",
      "indices:    {14721, 14722, 3587, 14724, 3589, 3590, 14727, 14737, 14738, 3996, 4140, 4151, 3513, 3515, 4158, 4159, 3522, 3525, 3526, 3527, 3529, 3530, 3531, 3536, 3542, 3550, 3558, 3559, 3562}\n",
      "dict_items([(\"Lemma('saline_solution.n.01.saline')\", 25)])\n",
      "collecting tokens for  pbs\n",
      "indices:    {4160}\n",
      "dict_items([(\"Lemma('phosphate_buffer_solution.n.01.PBS')\", 1)])\n",
      "collecting tokens for  background\n",
      "indices:    {16128, 28033, 24576, 11270, 2709, 14742, 28055, 34210, 14242, 32934, 35752, 3124, 14394, 4795, 3133, 11326, 15423, 13890, 24144, 17873, 32210, 31599, 33136, 32499, 17403}\n",
      "dict_items([(\"Lemma('background.n.01.background')\", 4), (\"Lemma('background.n.03.background')\", 4), (\"Lemma('background.n.04.background')\", 2), (\"Lemma('background.n.02.background')\", 2), (\"Lemma('background.n.05.background')\", 1)])\n",
      "collecting tokens for  beautiful\n",
      "indices:    {1603, 27459, 19525, 27461, 22073, 36208, 36083, 25686, 1848, 28025, 30686}\n",
      "dict_items([(\"Lemma('beautiful.a.01.beautiful')\", 3)])\n",
      "collecting tokens for  lacked\n",
      "indices:    {13154, 1795, 5828, 27748, 22281, 9838, 8818, 21365, 23229, 28511}\n",
      "dict_items([(\"Lemma('miss.v.06.lack')\", 10)])\n",
      "collecting tokens for  obtain\n",
      "indices:    {11265, 22414, 3094, 20888, 153, 11418, 20380, 3234, 4010, 3243, 43, 2995, 33084, 28606, 24896, 32454, 16201, 2377, 32591, 26965, 3290, 29406, 4574, 2784, 4198, 494, 20335, 29552, 16245, 23546, 13307}\n",
      "dict_items([(\"Lemma('obtain.v.01.obtain')\", 26), (\"Lemma('prevail.v.02.obtain')\", 1)])\n",
      "collecting tokens for  league\n",
      "indices:    {129, 498, 508}\n",
      "dict_items([])\n",
      "collecting tokens for  mamma\n",
      "indices:    {36168}\n",
      "dict_items([])\n",
      "collecting tokens for  generous\n",
      "indices:    {30180, 23143, 31400, 26891, 29741, 14478, 21437, 21650, 27479, 21655, 5275, 5309, 26398}\n",
      "dict_items([(\"Lemma('generous.s.03.generous')\", 1), (\"Lemma('generous.a.01.generous')\", 2)])\n",
      "collecting tokens for  whom\n",
      "indices:    {20354, 32260, 27141, 15761, 27411, 28052, 28307, 19350, 10138, 14875, 11163, 37025, 20898, 27425, 14712, 25509, 34597, 26539, 26412, 23725, 2350, 14640, 13747, 10548, 20150, 33978, 5437, 12479, 28607, 35779, 27460, 20293, 21445, 27459, 33228, 28111, 10833, 25553, 2261, 22870, 13783, 24920, 27096, 7771, 27487, 37112, 27488, 5346, 26598, 7145, 6763, 7534, 31090, 21490, 25333, 14454, 1144, 31097, 27514, 5243, 27133}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([])\n",
      "collecting tokens for  fell\n",
      "indices:    {8579, 35590, 29958, 18696, 6281, 8842, 18570, 1162, 14478, 34960, 23185, 13588, 9341, 7188, 27927, 22424, 31514, 19868, 541, 29342, 34592, 21536, 9120, 10405, 21671, 36392, 36137, 29358, 30896, 10417, 34099, 35254, 12214, 36029, 34110, 5056, 5063, 27465, 12877, 9806, 9171, 24021, 7126, 26714, 12891, 7772, 12509, 18912, 31201, 34786, 35044, 9188, 9190, 9702, 1509, 21737, 5098, 35433, 35052, 5357, 622, 8570, 34160, 36465, 26607, 14453, 29176, 19834, 22909}\n",
      "dict_items([(\"Lemma('descend.v.01.fall')\", 8), (\"Lemma('fall.v.01.fall')\", 15), (\"Lemma('fall.v.13.fall')\", 1), (\"Lemma('fall.v.14.fall')\", 2), (\"Lemma('fall.v.07.fall')\", 2), (\"Lemma('fall.v.03.fall')\", 9), (\"Lemma('fall.v.09.fall')\", 2), (\"Lemma('fell.v.01.fell')\", 1), (\"Lemma('precipitate.v.03.fall')\", 2)])\n",
      "collecting tokens for  love\n",
      "indices:    {24341, 792, 35226, 1191, 8365, 26550, 832, 31960, 24923, 30686, 2657, 31586, 9573, 2661, 24301, 14453, 32120, 11257, 12283, 26495}\n",
      "dict_items([(\"Lemma('love.v.03.love')\", 2), (\"Lemma('love.n.02.love')\", 1), (\"Lemma('love.n.01.love')\", 4), (\"Lemma('love.v.01.love')\", 1), (\"Lemma('love.v.02.love')\", 1)])\n",
      "collecting tokens for  papa\n",
      "indices:    {6397}\n",
      "dict_items([(\"Lemma('dad.n.01.papa')\", 1)])\n",
      "collecting tokens for  morris\n",
      "indices:    {14455}\n",
      "dict_items([(\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  jastrow\n",
      "indices:    {14447}\n",
      "dict_items([])\n",
      "collecting tokens for  szold\n",
      "indices:    {14468}\n",
      "dict_items([])\n",
      "collecting tokens for  obliged\n",
      "indices:    {9382, 9339, 12269, 14478, 23216, 33013, 8822, 14459, 27292, 12287}\n",
      "dict_items([(\"Lemma('compel.v.01.oblige')\", 4), (\"Lemma('oblige.v.02.oblige')\", 1)])\n",
      "collecting tokens for  henrietta\n",
      "indices:    {14455}\n",
      "dict_items([(\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  interested\n",
      "indices:    {22528, 25345, 30976, 4743, 28553, 33291, 31116, 5901, 14478, 24590, 16274, 14738, 20886, 20375, 33432, 9373, 20253, 1828, 26021, 23208, 5672, 22704, 12465, 2737, 15409, 37172, 15413, 21297, 24247, 10808, 2361, 5943, 9783, 23605, 24384, 32449, 22338, 28611, 32454, 23752, 22347, 32716, 14672, 27218, 22354, 20308, 25940, 23931, 27863, 15448, 25946, 36442, 32476, 13277, 4830, 24926, 32482, 25064, 31080, 4458, 14187, 32108, 11372, 22512, 5873, 11890, 31089, 14453, 36342, 10746, 31099, 20734, 30719}\n",
      "dict_items([(\"Lemma('interested.a.01.interested')\", 22), (\"Lemma('matter_to.v.01.interest')\", 1), (\"Lemma('interest.v.01.interest')\", 3), (\"Lemma('concern.v.02.interest')\", 2), (\"Lemma('concerned.s.02.interested')\", 1)])\n",
      "collecting tokens for  trustees\n",
      "indices:    {25093, 21693}\n",
      "dict_items([])\n",
      "collecting tokens for  friday\n",
      "indices:    {325}\n",
      "dict_items([(\"Lemma('friday.n.01.Friday')\", 1)])\n",
      "collecting tokens for  emory\n",
      "indices:    {21434}\n",
      "dict_items([])\n",
      "collecting tokens for  assumed\n",
      "indices:    {16387, 31619, 12036, 3334, 12933, 23945, 3082, 2827, 34700, 20491, 17549, 4243, 3479, 15003, 4261, 24102, 3881, 3370, 15661, 13999, 18232, 2810, 21435, 27841, 36930, 5059, 5830, 26827, 25547, 33361, 11476, 7638, 3030, 11998, 10847, 31201, 10982, 3302, 33005, 21360, 3959, 4602, 16892}\n",
      "dict_items([(\"Lemma('assume.v.01.assume')\", 24), (\"Lemma('assume.v.03.assume')\", 3), (\"Lemma('assume.v.02.assume')\", 10), (\"Lemma('assume.v.05.assume')\", 1), (\"Lemma('bear.v.06.assume')\", 3)])\n",
      "collecting tokens for  primary\n",
      "indices:    {20482, 2, 32900, 20485, 4360, 25099, 14991, 4374, 33046, 27554, 12323, 39, 20395, 20403, 23220, 15680, 27076, 32453, 31842, 20450, 14691, 20460, 12283}\n",
      "dict_items([(\"Lemma('chief.s.01.primary')\", 3), (\"Lemma('primary.a.01.primary')\", 4), (\"Lemma('primary.n.01.primary')\", 2)])\n",
      "collecting tokens for  commitment\n",
      "indices:    {27585, 27594, 27690, 1267, 26197, 13526, 22871, 21435}\n",
      "dict_items([(\"Lemma('committedness.n.01.commitment')\", 2)])\n",
      "collecting tokens for  dedication\n",
      "indices:    {14597, 27689, 23562, 35986, 7669, 26742, 22359, 22363, 13918}\n",
      "dict_items([(\"Lemma('dedication.n.01.dedication')\", 3)])\n",
      "collecting tokens for  excellence\n",
      "indices:    {13632, 28104, 22699, 22700, 22707, 21435, 21437, 26110, 28093}\n",
      "dict_items([(\"Lemma('excellence.n.01.excellence')\", 1)])\n",
      "collecting tokens for  higher\n",
      "indices:    {13568, 15757, 22685, 34208, 16169, 22698, 4657, 33075, 23225, 2236, 2109, 11581, 27202, 27203, 27334, 16328, 25928, 2008, 6751, 28139, 20719, 15219, 2931}\n",
      "dict_items([(\"Lemma('high.a.01.high')\", 6), (\"Lemma('high.a.02.high')\", 2), (\"Lemma('higher.s.01.higher')\", 3), (\"Lemma('eminent.s.01.high')\", 1)])\n",
      "collecting tokens for  approval\n",
      "indices:    {2049, 20226, 25095, 32137, 36362, 138, 22028, 14862, 25753, 4892, 32284, 14748, 36383, 15271, 22651, 20531, 14131, 26424, 14264, 21181, 25023, 30273, 26564, 712, 23880, 31190, 30935, 15358, 15321, 90, 2780, 15326, 24437, 22650, 13307, 24700, 24702, 4863}\n",
      "dict_items([(\"Lemma('approval.n.03.approval')\", 1), (\"Lemma('blessing.n.01.approval')\", 11), (\"Lemma('approval.n.02.approval')\", 3)])\n",
      "collecting tokens for  members\n",
      "indices:    {33376, 32992, 31554, 20771, 1316, 25093, 23876, 22501, 32202, 27692, 27852, 27633, 23252, 23348, 23605, 28766, 27999}\n",
      "dict_items([(\"Lemma('member.n.01.member')\", 1)])\n",
      "collecting tokens for  estimate\n",
      "indices:    {24164}\n",
      "dict_items([])\n",
      "collecting tokens for  shore\n",
      "indices:    {12706, 29316}\n",
      "dict_items([(\"Lemma('shore.n.01.shore')\", 1)])\n",
      "collecting tokens for  freed\n",
      "indices:    {31920, 3226, 35386, 25181}\n",
      "dict_items([(\"Lemma('rid.v.01.free')\", 1), (\"Lemma('free.v.01.free')\", 1)])\n",
      "collecting tokens for  slaves\n",
      "indices:    {32003, 32019, 32020, 28051, 28056, 28057, 7838, 12575, 5280, 12576, 32934, 13739, 13753, 26429, 13763, 13764, 5320, 14320, 7676}\n",
      "dict_items([(\"Lemma('slave.n.01.slave')\", 10), (\"Lemma('slave.n.02.slave')\", 1)])\n",
      "collecting tokens for  ships\n",
      "indices:    {14982, 32648, 30377, 15466, 18669, 36447, 21295, 34677, 7830, 25692, 2047}\n",
      "dict_items([(\"Lemma('ship.n.01.ship')\", 4)])\n",
      "collecting tokens for  waited\n",
      "indices:    {33475, 17603, 7846, 31379, 18132, 9717, 19511, 314, 35870}\n",
      "dict_items([(\"Lemma('wait.v.01.wait')\", 7), (\"Lemma('wait.v.02.wait')\", 1), (\"Lemma('wait.v.04.wait')\", 1)])\n",
      "collecting tokens for  bod\n",
      "indices:    {5490}\n",
      "dict_items([])\n",
      "collecting tokens for  raw\n",
      "indices:    {15424, 15456, 5539, 11322, 35943, 2728, 1242, 30478, 30484, 19157, 25529, 30490, 14365}\n",
      "dict_items([(\"Lemma('crude.s.06.raw')\", 1), (\"Lemma('raw.s.04.raw')\", 1), (\"Lemma('raw.s.06.raw')\", 1), (\"Lemma('natural.s.07.raw')\", 1), (\"Lemma('raw.s.02.raw')\", 1)])\n",
      "collecting tokens for  sewage\n",
      "indices:    {5507, 5124, 5510, 21626, 5128, 5129, 5130, 5516, 6030, 5520, 5521, 5531, 5534, 5539, 6060, 2349, 6091, 5587, 5589, 5590, 12156, 5488, 21625, 5498, 5499, 5500}\n",
      "dict_items([(\"Lemma('sewage.n.01.sewage')\", 17)])\n",
      "collecting tokens for  typical\n",
      "indices:    {2948, 27527, 23434, 32651, 2704, 26648, 5151, 15786, 3756, 15663, 31793, 27188, 2228, 20933, 28741, 21076, 2136, 11996, 3293, 12259, 26979, 1125, 4207, 32892}\n",
      "dict_items([(\"Lemma('typical.a.01.typical')\", 11), (\"Lemma('distinctive.s.01.typical')\", 2)])\n",
      "collecting tokens for  domestic\n",
      "indices:    {32478}\n",
      "dict_items([])\n",
      "collecting tokens for  subdivision\n",
      "indices:    {5498, 12173}\n",
      "dict_items([(\"Lemma('subdivision.n.02.subdivision')\", 1)])\n",
      "collecting tokens for  arthur\n",
      "indices:    {28078}\n",
      "dict_items([])\n",
      "collecting tokens for  gordon\n",
      "indices:    {20532}\n",
      "dict_items([])\n",
      "collecting tokens for  comes\n",
      "indices:    {14484}\n",
      "dict_items([])\n",
      "collecting tokens for  georgia\n",
      "indices:    {23605}\n",
      "dict_items([])\n",
      "collecting tokens for  rusk\n",
      "indices:    {32198}\n",
      "dict_items([])\n",
      "collecting tokens for  route\n",
      "indices:    {12353, 12403, 21644, 27006}\n",
      "dict_items([(\"Lemma('path.n.03.route')\", 2)])\n",
      "collecting tokens for  doubtless\n",
      "indices:    {23104, 11104, 11045, 23214, 31184, 19445, 23733, 8375, 36126, 23711}\n",
      "dict_items([(\"Lemma('undoubtedly.r.01.doubtless')\", 4)])\n",
      "collecting tokens for  emergency\n",
      "indices:    {32714, 5137, 25138, 25076, 15189}\n",
      "dict_items([(\"Lemma('emergency.n.01.emergency')\", 1), (\"Lemma('emergency.n.02.emergency')\", 1)])\n",
      "collecting tokens for  entry\n",
      "indices:    {28571, 10675, 23733, 15927, 36024, 15940, 16325, 16840, 15947, 15954, 25813, 469, 16347, 28894, 16353, 16354, 28900, 9331, 23160, 3455}\n",
      "dict_items([(\"Lemma('entry.n.01.entry')\", 4), (\"Lemma('entry.n.03.entry')\", 2), (\"Lemma('introduction.n.01.entry')\", 4), (\"Lemma('entrance.n.01.entry')\", 1), (\"Lemma('submission.n.01.entry')\", 1)])\n",
      "collecting tokens for  australian\n",
      "indices:    {31507}\n",
      "dict_items([])\n",
      "collecting tokens for  enemy\n",
      "indices:    {18817, 18783, 18825, 12884, 20319}\n",
      "dict_items([(\"Lemma('enemy.n.01.enemy')\", 3)])\n",
      "collecting tokens for  earthquake\n",
      "indices:    {12736, 12705, 12769, 12710, 12714, 35475, 12787, 12795, 12799}\n",
      "dict_items([(\"Lemma('earthquake.n.01.earthquake')\", 8)])\n",
      "collecting tokens for  village\n",
      "indices:    {8245, 5165, 28102, 13103}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('village.n.01.village')\", 3)])\n",
      "collecting tokens for  rachel\n",
      "indices:    {5701}\n",
      "dict_items([(\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  conceded\n",
      "indices:    {25538, 2155, 14476, 5293, 25390, 12310, 11259, 20572, 31999}\n",
      "dict_items([(\"Lemma('concede.v.01.concede')\", 6), (\"Lemma('concede.v.02.concede')\", 2), (\"Lemma('concede.v.03.concede')\", 1)])\n",
      "collecting tokens for  sitting\n",
      "indices:    {22875}\n",
      "dict_items([(\"Lemma('sit.v.01.sit')\", 1)])\n",
      "collecting tokens for  guitar\n",
      "indices:    {6561, 26917, 26423}\n",
      "dict_items([])\n",
      "collecting tokens for  march\n",
      "indices:    {22063}\n",
      "dict_items([])\n",
      "collecting tokens for  closely\n",
      "indices:    {22153, 21769, 28395, 29965, 36018, 13042, 4692, 14773, 15674}\n",
      "dict_items([(\"Lemma('closely.r.01.closely')\", 4)])\n",
      "collecting tokens for  individual\n",
      "indices:    {24192, 28675, 24970, 4119, 1560, 22686, 16420, 16173, 3758, 12206, 3888, 16182, 29888, 28996, 14149, 28102, 22344, 16085, 16086, 11613, 32223, 28003, 15721, 26987, 11894, 4727, 33016}\n",
      "dict_items([(\"Lemma('individual.a.01.individual')\", 8), (\"Lemma('individual.n.02.individual')\", 2), (\"Lemma('person.n.01.individual')\", 4), (\"Lemma('individual.s.02.individual')\", 1)])\n",
      "collecting tokens for  cases\n",
      "indices:    {3587, 26118, 32908, 22031, 13715, 15764, 4628, 26743, 12055, 32410, 31006, 3486, 12704, 21794, 10274, 32164, 12200, 32169, 13354, 15659, 29737, 32170, 20158, 174, 4017, 3634, 16178, 3124, 30774, 13241, 20154, 20155, 4281, 3645, 20157, 13247, 32704, 16320, 16194, 31294, 4164, 32581, 20166, 31815, 20168, 18887, 20170, 27211, 20167, 32723, 27860, 3197, 2134, 5463, 36440, 3284, 3575, 3291, 2144, 21989, 4198, 2281, 2796, 9325, 4717, 32878, 31733, 17143, 3576, 12025, 14714, 23421, 2302}\n",
      "dict_items([(\"Lemma('case.n.01.case')\", 25), (\"Lemma('event.n.02.case')\", 3), (\"Lemma('lawsuit.n.01.case')\", 2), (\"Lemma('case.n.10.case')\", 1), (\"Lemma('case.n.06.case')\", 1), (\"Lemma('case.n.11.case')\", 1), (\"Lemma('case.n.05.case')\", 2), (\"Lemma('subject.n.06.case')\", 1)])\n",
      "collecting tokens for  remarkably\n",
      "indices:    {1092, 27557, 26059, 14476, 1197, 20235, 26508, 37168, 14514, 15866, 9146, 4987, 3806, 3775}\n",
      "dict_items([(\"Lemma('unusually.r.01.remarkably')\", 9)])\n",
      "collecting tokens for  atmosphere\n",
      "indices:    {27651, 28040, 20232, 14476, 5648, 26391, 14234, 23582, 2976, 9632, 25378, 11300, 3109, 13607, 25384, 3372, 25261, 2864, 34484, 26676, 31157, 34744, 26938, 30395, 3389, 25661, 831, 2493, 3137, 25409, 11325, 22726, 27851, 36046, 26190, 2382, 20946, 3285, 24662, 2901, 26840, 25433, 22745, 34523, 16732, 3295, 25312, 20577, 1249, 12264, 14953, 25451, 2796, 19565, 28142, 8815, 3311, 15727, 2800, 24566, 34551, 30203}\n",
      "dict_items([(\"Lemma('atmosphere.n.01.atmosphere')\", 14), (\"Lemma('atmosphere.n.03.atmosphere')\", 6), (\"Lemma('atmosphere.n.04.atmosphere')\", 3), (\"Lemma('atmosphere.n.05.atmosphere')\", 2), (\"Lemma('standard_atmosphere.n.01.atmosphere')\", 4)])\n",
      "collecting tokens for  entirely\n",
      "indices:    {4487, 2184, 4489, 1809, 20247, 5016, 15773, 1311, 36515, 10283, 28467, 16309, 21304, 4544, 24513, 27985, 3158, 3671, 1003, 16380, 7407, 6255, 30834, 24949, 15865, 24828}\n",
      "dict_items([(\"Lemma('wholly.r.01.entirely')\", 17)])\n",
      "collecting tokens for  content\n",
      "indices:    {3328, 14476, 14604, 14479, 26514, 30483, 1302, 16283, 16165, 34726, 31143, 14768, 1714, 8242, 31926, 3390, 3391, 33095, 14666, 15825, 14677, 31191, 14680, 3166, 34400, 2401, 30057, 31083, 31217, 2552, 16122, 30206}\n",
      "dict_items([(\"Lemma('message.n.02.content')\", 8), (\"Lemma('capacity.n.03.content')\", 2), (\"Lemma('content.n.05.content')\", 1), (\"Lemma('content.v.01.content')\", 1), (\"Lemma('content.n.01.content')\", 2), (\"Lemma('content.v.02.content')\", 1), (\"Lemma('content.n.03.content')\", 3)])\n",
      "collecting tokens for  jewish\n",
      "indices:    {13151}\n",
      "dict_items([(\"Lemma('jewish.a.01.Jewish')\", 1)])\n",
      "collecting tokens for  vaguely\n",
      "indices:    {18881, 2180, 36388, 16583, 14476, 18124, 16524, 34256, 9586, 16694, 13657, 2139, 23134}\n",
      "dict_items([(\"Lemma('vaguely.r.01.vaguely')\", 10)])\n",
      "collecting tokens for  steady\n",
      "indices:    {21890, 20100, 33541, 23434, 33803, 20619, 2198, 17561, 34331, 2973, 31395, 2980, 36655, 3001, 17722, 33467, 33469, 9286, 29900, 2814, 35539, 33750, 19549, 16223, 29025, 31331, 9835, 3315, 2302}\n",
      "dict_items([(\"Lemma('steady.a.01.steady')\", 9), (\"Lemma('steady.v.01.steady')\", 1)])\n",
      "collecting tokens for  humanity\n",
      "indices:    {1458, 25908, 14095}\n",
      "dict_items([])\n",
      "collecting tokens for  evident\n",
      "indices:    {24194, 19339, 30221, 4109, 25494, 32922, 3228, 13344, 5286, 9384, 5034, 32428, 13362, 1331, 16182, 14906, 1468, 13372, 16199, 32584, 25164, 16204, 33231, 17233, 17234, 27860, 3796, 28633, 27867, 1500, 4191, 26085, 19046, 14442, 30317, 32889, 1275, 32895}\n",
      "dict_items([(\"Lemma('apparent.s.01.evident')\", 22), (\"Lemma('discernible.s.03.evident')\", 1)])\n",
      "collecting tokens for  weapon\n",
      "indices:    {12810, 17931, 19345, 34068, 27924, 15510, 28439, 12824, 14112, 25506, 15525, 19371, 34094, 15535, 12849, 15538, 23093, 3396, 28485, 3398, 3400, 12237, 16212, 5852, 25453, 27897, 1275}\n",
      "dict_items([(\"Lemma('weapon.n.02.weapon')\", 1), (\"Lemma('weapon.n.01.weapon')\", 13)])\n",
      "collecting tokens for  designed\n",
      "indices:    {769, 12929, 5515, 1557, 32149, 31136, 15012, 30121, 28714, 29865, 32175, 21295, 27439, 21053, 23104, 705, 21573, 15054, 20192, 30181, 107, 3823, 22770, 21882, 7550}\n",
      "dict_items([(\"Lemma('plan.v.03.design')\", 14), (\"Lemma('design.v.03.design')\", 2), (\"Lemma('design.v.02.design')\", 6), (\"Lemma('design.v.04.design')\", 1)])\n",
      "collecting tokens for  whip\n",
      "indices:    {353, 5826, 19235, 12004, 5828, 1275, 339, 6902, 29176, 16507}\n",
      "dict_items([(\"Lemma('whip.n.01.whip')\", 2), (\"Lemma('flog.v.01.whip')\", 2), (\"Lemma('worst.v.01.whip')\", 2), (\"Lemma('whip.v.03.whip')\", 1)])\n",
      "collecting tokens for  yes\n",
      "indices:    {2262}\n",
      "dict_items([])\n",
      "collecting tokens for  thousands\n",
      "indices:    {34887, 25544, 11881, 14346, 12808, 8457, 11885, 20590, 526, 20343, 24210, 28307, 12755, 21493, 23253, 2228, 19771, 25277}\n",
      "dict_items([(\"Lemma('thousand.n.01.thousand')\", 9)])\n",
      "collecting tokens for  salt\n",
      "indices:    {22128, 18445}\n",
      "dict_items([(\"Lemma('salt.v.01.salt')\", 1), (\"Lemma('salt.n.02.salt')\", 1)])\n",
      "collecting tokens for  pan\n",
      "indices:    {29347, 10435, 21893, 22130, 1881, 34908}\n",
      "dict_items([(\"Lemma('pan.n.01.pan')\", 1), (\"Lemma('pan.v.02.pan')\", 1)])\n",
      "collecting tokens for  privilege\n",
      "indices:    {64, 23233, 27266, 15843, 69, 11272, 8378, 32255, 32205, 11284, 25017, 16218, 14942, 27359}\n",
      "dict_items([(\"Lemma('privilege.n.01.privilege')\", 6), (\"Lemma('prerogative.n.01.privilege')\", 2)])\n",
      "collecting tokens for  marked\n",
      "indices:    {3840, 11264, 4099, 2947, 28037, 34051, 4100, 32644, 34296, 15882, 15883, 4109, 29464, 30239, 28064, 13601, 4644, 21669, 12199, 1067, 16555, 34349, 30254, 15921, 30771, 4275, 1337, 3769, 32445, 30270, 24125, 16576, 4038, 29768, 29770, 25803, 14544, 82, 11476, 3796, 5847, 23511, 13657, 3803, 4059, 3805, 32859, 19422, 30555, 15714, 4069, 3557, 36453, 15077, 29673, 27757, 31342, 13039, 29677, 4721, 4079, 12667, 22520, 32763, 12668, 31229}\n",
      "dict_items([(\"Lemma('tag.v.01.mark')\", 7), (\"Lemma('distinguish.v.03.mark')\", 10), (\"Lemma('mark.v.02.mark')\", 5), (\"Lemma('marked.s.01.marked')\", 15), (\"Lemma('commemorate.v.01.mark')\", 4), (\"Lemma('notice.v.02.mark')\", 2), (\"Lemma('stigmatize.v.01.mark')\", 2), (\"Lemma('marked.s.02.marked')\", 2), (\"Lemma('marked.a.03.marked')\", 1), (\"Lemma('mark.v.05.mark')\", 1)])\n",
      "collecting tokens for  moscow\n",
      "indices:    {12198}\n",
      "dict_items([(\"Lemma('moscow.n.01.Moscow')\", 1)])\n",
      "collecting tokens for  stalin\n",
      "indices:    {26165}\n",
      "dict_items([])\n",
      "collecting tokens for  dictatorship\n",
      "indices:    {22776, 23651, 12199, 14103, 23661, 23957, 14102, 25623, 24184, 24093, 25727}\n",
      "dict_items([(\"Lemma('dictatorship.n.01.dictatorship')\", 3)])\n",
      "collecting tokens for  anti\n",
      "indices:    {3519, 14346, 3532, 14188, 435, 3509, 3577, 12986, 3582, 1375}\n",
      "dict_items([(\"Lemma('anti.a.01.anti')\", 4)])\n",
      "collecting tokens for  communism\n",
      "indices:    {23981, 5238, 12919}\n",
      "dict_items([(\"Lemma('communism.n.01.communism')\", 2)])\n",
      "collecting tokens for  lose\n",
      "indices:    {34946, 27522, 28431, 28432, 18063, 8336, 32023, 34072, 7065, 13337, 12953, 12952, 17696, 25012, 19381, 23097, 14394, 23747, 27388, 19666, 13651, 2258, 27226, 32091, 22876, 8923, 23902, 25823, 4576, 868, 31077, 4585, 19434, 24173, 32241, 24947, 15987, 31868}\n",
      "dict_items([(\"Lemma('lose.v.01.lose')\", 26), (\"Lemma('lose.v.03.lose')\", 1), (\"Lemma('lose.v.08.lose')\", 1), (\"Lemma('lose.v.02.lose')\", 3), (\"Lemma('lose.v.05.lose')\", 2), (\"Lemma('lose.v.07.lose')\", 1)])\n",
      "collecting tokens for  accepting\n",
      "indices:    {15776, 33250, 18245, 20677, 19720, 15725, 28269, 15727, 30265, 21425, 24144, 13101, 7065, 1308}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('accept.v.01.accept')\", 6), (\"Lemma('accepting.s.01.accepting')\", 2), (\"Lemma('accept.v.02.accept')\", 4), (\"Lemma('accept.v.07.accept')\", 1), (\"Lemma('accept.v.05.accept')\", 1)])\n",
      "collecting tokens for  challenge\n",
      "indices:    {28544, 15296, 24460, 15724, 32876, 25972, 22934, 25110}\n",
      "dict_items([(\"Lemma('challenge.v.04.challenge')\", 1), (\"Lemma('challenge.v.02.challenge')\", 1), (\"Lemma('challenge.n.01.challenge')\", 1), (\"Lemma('challenge.v.01.challenge')\", 3)])\n",
      "collecting tokens for  cigarette\n",
      "indices:    {17253, 35650, 35733, 26607}\n",
      "dict_items([(\"Lemma('cigarette.n.01.cigarette')\", 1)])\n",
      "collecting tokens for  tape\n",
      "indices:    {1090, 21544, 2223, 30256, 13455, 2962, 2961, 21522, 2966, 21943, 2968, 21529, 30235}\n",
      "dict_items([(\"Lemma('tape.n.02.tape')\", 1), (\"Lemma('tape.n.01.tape')\", 4)])\n",
      "collecting tokens for  notes\n",
      "indices:    {21188, 8178, 13427, 26969, 27549}\n",
      "dict_items([(\"Lemma('note.n.02.note')\", 1), (\"Lemma('note.n.01.note')\", 1), (\"Lemma('notice.v.02.note')\", 1)])\n",
      "collecting tokens for  absent\n",
      "indices:    {31104, 31107, 3845, 31110, 3847, 9990, 31113, 4872, 31111, 140, 4114, 8859, 30620, 14389, 33078, 1466, 14145, 4422, 3800, 11097, 31839, 36213, 22394, 33023}\n",
      "dict_items([(\"Lemma('absent.a.01.absent')\", 12), (\"Lemma('absent.v.01.absent')\", 1)])\n",
      "collecting tokens for  sitter\n",
      "indices:    {31104, 31107, 31108, 31110, 31111, 31113, 31116, 31120, 31121, 37013, 31134, 31137, 31139, 31147, 31154, 31169, 31083, 31090, 33651, 31093, 31099, 31101, 31102, 31103}\n",
      "dict_items([])\n",
      "collecting tokens for  fair\n",
      "indices:    {15266, 31588, 34359, 25214, 1497, 16173, 24690, 20883, 16182, 21175, 27257, 32378, 29015}\n",
      "dict_items([(\"Lemma('fair.a.01.fair')\", 2)])\n",
      "collecting tokens for  taking\n",
      "indices:    {32273, 31123, 20500, 35997, 27425, 25256, 20137, 35371, 5420, 19116, 9392, 1331, 2996, 26293, 10552, 22725, 20296, 29389, 17633, 14950, 18297, 2427}\n",
      "dict_items([(\"Lemma('take.v.06.take')\", 2), (\"Lemma('subscribe.v.05.take')\", 1), (\"Lemma('take.v.01.take')\", 4), (\"Lemma('take.v.04.take')\", 1), (\"Lemma('take_out.v.01.take_out')\", 1), (\"Lemma('bring.v.01.take')\", 1), (\"Lemma('consider.v.03.take')\", 1), (\"Lemma('lead.v.01.take')\", 1), (\"Lemma('take.v.24.take')\", 1), (\"Lemma('choose.v.01.take')\", 1), (\"Lemma('take.v.09.take')\", 1), (\"Lemma('fill.v.04.take')\", 1), (\"Lemma('gamble.v.01.take_a_chance')\", 1)])\n",
      "collecting tokens for  jobs\n",
      "indices:    {16257, 32259, 11780, 21000, 24074, 36107, 24076, 31631, 24471, 35096, 19610, 16285, 19357, 21669, 23975, 21162, 8234, 12075, 16301, 302, 25258, 16309, 11831, 19513, 23356, 32445, 23619, 19781, 20559, 20564, 21087, 11752, 12139, 24560, 30066, 12146, 21493, 24825, 21884}\n",
      "dict_items([(\"Lemma('occupation.n.01.job')\", 11), (\"Lemma('job.n.02.job')\", 5)])\n",
      "collecting tokens for  fragile\n",
      "indices:    {5953, 26404, 13575, 7273, 30765, 10574, 30767, 26354, 9979}\n",
      "dict_items([(\"Lemma('delicate.s.03.fragile')\", 3), (\"Lemma('fragile.s.02.fragile')\", 2)])\n",
      "collecting tokens for  westminster\n",
      "indices:    {28613}\n",
      "dict_items([])\n",
      "collecting tokens for  flowers\n",
      "indices:    {13120, 13121, 13572, 1604, 9503, 9575, 29288, 18855, 11146, 1611, 22253, 10098, 3603, 1658, 30716, 26398, 36319}\n",
      "dict_items([(\"Lemma('flower.n.01.flower')\", 8), (\"Lemma('flower.n.02.flower')\", 4)])\n",
      "collecting tokens for  shops\n",
      "indices:    {31562, 37067, 35723, 5452, 5165, 36340, 32630, 20343}\n",
      "dict_items([(\"Lemma('shop.n.01.shop')\", 1)])\n",
      "collecting tokens for  drawing\n",
      "indices:    {5024, 22723, 5030, 3080, 7615, 11434, 6539, 27852, 14067, 5363, 15477, 12502, 22170, 19615}\n",
      "dict_items([(\"Lemma('drawing.n.01.drawing')\", 4), (\"Lemma('drawing.n.03.drawing')\", 2), (\"Lemma('draw.v.10.draw')\", 1), (\"Lemma('trace.v.02.draw')\", 1), (\"Lemma('reap.v.02.draw')\", 1), (\"Lemma('draw_up.v.02.draw_up')\", 1)])\n",
      "collecting tokens for  passionate\n",
      "indices:    {5953, 13666, 26535, 27079, 26217, 26093, 11221, 2491}\n",
      "dict_items([(\"Lemma('passionate.a.01.passionate')\", 4)])\n",
      "collecting tokens for  breath\n",
      "indices:    {31878}\n",
      "dict_items([])\n",
      "collecting tokens for  wants\n",
      "indices:    {13826, 7426, 20998, 10128, 787, 790, 19479, 18333, 807, 27177, 11820, 35889, 23476, 27830, 9917, 25155, 24534, 34263, 24279, 9046, 31835, 16476, 862, 5475, 24933, 26735, 30454, 24957}\n",
      "dict_items([(\"Lemma('desire.v.01.want')\", 26)])\n",
      "collecting tokens for  tomorrow\n",
      "indices:    {8365}\n",
      "dict_items([(\"Lemma('tomorrow.n.01.tomorrow')\", 1)])\n",
      "collecting tokens for  partner\n",
      "indices:    {21763, 22920, 12046, 12055, 544, 26273, 12064, 23211, 21809, 17339, 11964, 19132, 34762, 34766, 11983, 34772, 32097, 20456, 22399}\n",
      "dict_items([(\"Lemma('spouse.n.01.partner')\", 5), (\"Lemma('collaborator.n.03.partner')\", 3)])\n",
      "collecting tokens for  hopefully\n",
      "indices:    {22896}\n",
      "dict_items([])\n",
      "collecting tokens for  uniform\n",
      "indices:    {32544, 2848, 32546, 7299, 22275, 32547, 32742, 32551, 32549, 35812, 20942, 12241, 17588, 33077, 32568, 5275, 1789}\n",
      "dict_items([(\"Lemma('uniform.a.01.uniform')\", 1), (\"Lemma('consistent.s.04.uniform')\", 1), (\"Lemma('uniform.n.01.uniform')\", 4)])\n",
      "collecting tokens for  worth\n",
      "indices:    {142}\n",
      "dict_items([])\n",
      "collecting tokens for  rabbit\n",
      "indices:    {4865, 3459, 4868, 34531, 6087, 4840, 4842, 4206, 17973, 21596, 4831}\n",
      "dict_items([(\"Lemma('rabbit.n.01.rabbit')\", 6)])\n",
      "collecting tokens for  lighted\n",
      "indices:    {14080, 35424, 5088, 5987, 8804, 17253, 8389, 5095, 34052, 17545, 8748, 35406, 24398, 13876, 18005, 34040, 18107, 35644}\n",
      "dict_items([(\"Lemma('light_up.v.05.light')\", 5), (\"Lemma('lighted.a.01.lighted')\", 4), (\"Lemma('illuminated.s.01.lighted')\", 4), (\"Lemma('light.v.01.light')\", 2)])\n",
      "collecting tokens for  dying\n",
      "indices:    {9204, 853, 11119}\n",
      "dict_items([(\"Lemma('die.v.01.die')\", 1), (\"Lemma('dying.a.01.dying')\", 1)])\n",
      "collecting tokens for  christ\n",
      "indices:    {28039}\n",
      "dict_items([])\n",
      "collecting tokens for  enter\n",
      "indices:    {34178, 31749, 14730, 23178, 3214, 35985, 14866, 15763, 16410, 17055, 17056, 29347, 40, 14761, 27689, 28202, 44, 11439, 25141, 31030, 28597, 13241, 21562, 28605, 7230, 6847, 32193, 3269, 4294, 28231, 24266, 1741, 22605, 24912, 5600, 23906, 16354, 15600, 32880, 24947, 15741}\n",
      "dict_items([(\"Lemma('enter.v.02.enter')\", 8), (\"Lemma('enter.v.01.enter')\", 22), (\"Lemma('enroll.v.01.enter')\", 7), (\"Lemma('figure.v.02.enter')\", 2), (\"Lemma('record.v.01.enter')\", 2)])\n",
      "collecting tokens for  contracts\n",
      "indices:    {37088, 24864, 2050, 26819, 11075, 25344, 104, 14730, 21227, 21230, 32344, 2745, 14748, 57}\n",
      "dict_items([(\"Lemma('contract.n.02.contract')\", 2), (\"Lemma('shrink.v.04.contract')\", 1), (\"Lemma('contract.v.04.contract')\", 1), (\"Lemma('contract.n.01.contract')\", 3), (\"Lemma('sign.v.04.contract')\", 1)])\n",
      "collecting tokens for  educational\n",
      "indices:    {32719}\n",
      "dict_items([])\n",
      "collecting tokens for  institutions\n",
      "indices:    {27840, 12228, 32146, 23666, 27702, 13303, 23577, 16316, 27711}\n",
      "dict_items([(\"Lemma('institution.n.01.institution')\", 3)])\n",
      "collecting tokens for  organizations\n",
      "indices:    {23973}\n",
      "dict_items([])\n",
      "collecting tokens for  engineering\n",
      "indices:    {20676, 14725, 25030, 20679, 25031, 33126, 1803, 29968, 21232, 24597, 1783, 29943}\n",
      "dict_items([(\"Lemma('engineering.n.02.engineering')\", 1), (\"Lemma('technology.n.01.engineering')\", 2)])\n",
      "collecting tokens for  firms\n",
      "indices:    {21762, 14730, 15504, 14738, 21918, 23710, 23457, 21796, 2729, 2730, 21803, 2736, 32181, 11574, 2743, 32444, 28350, 2751, 21823, 32447, 21824, 28355, 21573, 22343, 32457, 21577, 20683, 849, 16339, 36441, 2783, 97, 16373, 21883, 21884}\n",
      "dict_items([(\"Lemma('firm.n.01.firm')\", 11)])\n",
      "collecting tokens for  confronted\n",
      "indices:    {19207, 17932, 14477, 17423, 5395, 5012, 32175, 2610, 4283, 35264, 4672, 15429, 32328, 22603, 23508, 17750, 27864, 9698, 9699, 1253, 25202}\n",
      "dict_items([(\"Lemma('confront.v.01.confront')\", 10), (\"Lemma('confront.v.02.confront')\", 7), (\"Lemma('confront.v.03.confront')\", 3), (\"Lemma('confront.v.04.confront')\", 1)])\n",
      "collecting tokens for  loan\n",
      "indices:    {2761, 22412, 20432, 145, 21781, 32730}\n",
      "dict_items([(\"Lemma('loan.n.01.loan')\", 2)])\n",
      "collecting tokens for  existed\n",
      "indices:    {37126, 28678, 30733, 5397, 5273, 15002, 14106, 24603, 14369, 30501, 182, 23610, 25662, 5567, 28097, 14403, 14409, 30412, 31182, 5967, 1363, 34391, 1375, 3812, 9444, 4976, 7675, 27262}\n",
      "dict_items([(\"Lemma('exist.v.01.exist')\", 26), (\"Lemma('exist.v.02.exist')\", 1)])\n",
      "collecting tokens for  losses\n",
      "indices:    {15621, 37126, 15623, 775, 18313, 11534, 18319, 11537, 21907, 11545, 11546, 7712, 15274, 14900, 12093, 20286, 11582, 21318, 32335, 593, 2913, 8806, 2925}\n",
      "dict_items([(\"Lemma('loss.n.02.loss')\", 2), (\"Lemma('loss.n.06.loss')\", 1), (\"Lemma('loss.n.01.loss')\", 6), (\"Lemma('losings.n.01.losses')\", 6), (\"Lemma('personnel_casualty.n.01.loss')\", 1), (\"Lemma('loss.n.03.loss')\", 1)])\n",
      "collecting tokens for  refer\n",
      "indices:    {10711, 31166, 10661, 25817, 1223, 12234, 33198, 22709, 30262, 15991, 24984, 22297, 4506, 1244, 32920, 32894}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('refer.v.03.refer')\", 4), (\"Lemma('refer.v.02.refer')\", 7), (\"Lemma('mention.v.01.refer')\", 3), (\"Lemma('consult.v.02.refer')\", 1), (\"Lemma('refer.v.04.refer')\", 1)])\n",
      "collecting tokens for  organization\n",
      "indices:    {24148}\n",
      "dict_items([])\n",
      "collecting tokens for  owns\n",
      "indices:    {2787, 32265, 22731, 19470, 29042, 22707, 22708, 22741, 22709, 33146}\n",
      "dict_items([(\"Lemma('own.v.01.own')\", 10)])\n",
      "collecting tokens for  awareness\n",
      "indices:    {20376, 5032, 4907, 31533, 4913, 26548, 22709, 11449, 14398, 2377, 4686, 13652, 32860, 32861, 7773, 4958, 31847, 33257, 1780, 2678, 27900}\n",
      "dict_items([(\"Lemma('awareness.n.01.awareness')\", 10), (\"Lemma('awareness.n.02.awareness')\", 2)])\n",
      "collecting tokens for  tension\n",
      "indices:    {24640, 29889, 5856, 12259, 25572, 13442, 29888, 17923, 14633, 20234, 3195, 32909, 1585, 34171, 3030, 28923, 32956, 29885}\n",
      "dict_items([(\"Lemma('tension.n.02.tension')\", 2), (\"Lemma('tension.n.01.tension')\", 3), (\"Lemma('tension.n.03.tension')\", 1)])\n",
      "collecting tokens for  're\n",
      "indices:    {18432, 19970, 36357, 33286, 7685, 6666, 7690, 24588, 17422, 36373, 23063, 11800, 11801, 9243, 35869, 36894, 24607, 36893, 9757, 17950, 23070, 35367, 33323, 35371, 5679, 29744, 18483, 9269, 5685, 11831, 568, 18488, 18493, 7744, 9281, 35392, 18499, 18497, 10309, 29255, 10311, 16970, 16983, 9822, 5728, 30304, 614, 29800, 24682, 114, 30323, 29812, 33920, 26242, 9860, 16517, 24711, 16009, 19597, 33421, 33423, 10896, 20112, 10901, 9878, 10395, 668, 669, 18078, 33436, 9885, 7324, 17058, 10909, 9896, 11945, 11946, 11948, 33456, 18611, 28340, 33972, 28341, 17079, 35512, 10937, 9914, 33987, 9924, 35011, 34502, 34503, 36554, 34506, 17098, 17623, 37079, 37081, 8410, 33499, 37080, 19675, 36571, 6886, 6887, 35047, 10988, 25327, 36592, 33521, 18163, 12020, 19189, 24311, 19193, 19194, 35578, 36604, 35069, 36615, 27401, 37130, 35086, 8983, 19736, 9508, 24356, 23846, 12069, 296, 16681, 24877, 36147, 35125, 17719, 33593, 36164, 24388, 17733, 24398, 36687, 18768, 36183, 9561, 10588, 18782, 35167, 18789, 18790, 9061, 19817, 29044, 13688, 16762, 10108, 9603, 11143, 21903, 21904, 21905, 13719, 13720, 6552, 18332, 30108, 35232, 19875, 34212, 11174, 11175, 31150, 8113, 17842, 435, 17844, 24500, 17850, 29115, 20924, 9658, 8638, 19907, 22980, 33732, 7620, 10184, 19913, 28621, 9677, 9680, 34258, 20946, 35796, 19932, 19933, 6623, 18400, 33249, 18402, 15843, 15844, 19941, 34790, 20448, 18399, 30185, 34276, 30189, 22000, 35826, 18422, 30201, 6654}\n",
      "dict_items([(\"Lemma('be.v.08.be')\", 1), (\"Lemma('be.v.01.be')\", 26), (\"Lemma('be.v.02.be')\", 15), (\"Lemma('be.v.03.be')\", 9)])\n",
      "collecting tokens for  principles\n",
      "indices:    {27196}\n",
      "dict_items([])\n",
      "collecting tokens for  discouraged\n",
      "indices:    {32864, 33120, 22561, 30479, 30704, 30480, 28340, 26036, 23225, 22557, 13214, 2367}\n",
      "dict_items([(\"Lemma('discourage.v.02.discourage')\", 1), (\"Lemma('deter.v.01.discourage')\", 6), (\"Lemma('demoralized.s.01.discouraged')\", 1)])\n",
      "collecting tokens for  busy\n",
      "indices:    {23558, 658, 17684, 33429, 20118, 33685, 11033, 17701, 27050, 16043, 8490, 26286, 8366, 7472, 29497, 26177, 9413, 9160, 15177, 16970, 32210, 20051, 18011, 11099, 18526, 18016, 16609, 8298, 10221, 9843, 25076, 21749, 8310, 33526, 7034, 34685}\n",
      "dict_items([(\"Lemma('busy.s.02.busy')\", 1), (\"Lemma('busy.a.01.busy')\", 21), (\"Lemma('busy.s.04.busy')\", 1), (\"Lemma('interfering.s.01.busy')\", 1)])\n",
      "collecting tokens for  placing\n",
      "indices:    {31920, 28458}\n",
      "dict_items([(\"Lemma('locate.v.03.place')\", 1), (\"Lemma('set.v.09.place')\", 1)])\n",
      "collecting tokens for  real\n",
      "indices:    {9473, 4481, 19075, 27521, 34566, 15756, 31887, 19217, 14492, 21537, 31265, 25890, 22693, 1191, 10024, 11691, 26412, 16048, 26295, 5948, 17859, 27844, 2247, 1227, 23116, 22347, 19533, 20950, 1367, 13144, 6104, 6871, 33368, 33369, 29023, 9583, 1266, 1267, 16120, 2169, 27898, 32381, 14334}\n",
      "dict_items([(\"Lemma('real.a.01.real')\", 11), (\"Lemma('real.a.02.real')\", 6), (\"Lemma('very.r.01.real')\", 1), (\"Lemma('real.s.04.real')\", 1)])\n",
      "collecting tokens for  specified\n",
      "indices:    {15044, 14885, 24157, 22023, 2790, 20299, 3404, 3469, 32430, 15277, 29713, 21300, 28469, 33016, 14041, 15261}\n",
      "dict_items([(\"Lemma('specified.a.01.specified')\", 6), (\"Lemma('stipulate.v.01.specify')\", 2), (\"Lemma('specify.v.02.specify')\", 1)])\n",
      "collecting tokens for  ordered\n",
      "indices:    {19842, 27525, 21253, 21388, 21392, 3088, 3090, 5265, 27544, 15261, 12451, 23847, 7079, 5929, 4651, 32430, 4658, 18229, 20026, 23105, 26051, 15944, 23166, 8396, 21328, 35539, 12500, 12503, 15321, 30431, 8546, 36707, 357, 15333, 4711, 30440, 17646, 33007, 23283, 5107, 33525, 23159, 18174}\n",
      "dict_items([(\"Lemma('order.v.02.order')\", 8), (\"Lemma('order.v.01.order')\", 22), (\"Lemma('order.v.03.order')\", 4), (\"Lemma('regulate.v.02.order')\", 2), (\"Lemma('ordered.a.01.ordered')\", 3)])\n",
      "collecting tokens for  financial\n",
      "indices:    {32130, 13187, 15236, 31748, 17403, 7304, 30089, 24970, 32527, 32149, 22940, 14752, 32546, 23587, 4645, 14245, 32552, 23597, 32430, 28078, 21427, 22579, 16311, 16314, 16318, 13759, 21955, 21956, 32579, 23877, 28355, 32456, 21961, 21962, 2761, 32462, 24910, 15054, 32593, 23509, 2389, 2391, 20315, 13150, 2783, 37088, 23522, 15460, 25188, 25191, 32617, 32618, 11882, 32621, 32878, 32622, 11760, 32624, 32370, 16238, 37108, 32373, 32625, 17401, 22779, 12668}\n",
      "dict_items([(\"Lemma('fiscal.a.01.financial')\", 22)])\n",
      "collecting tokens for  consideration\n",
      "indices:    {24832, 28933, 16136, 4878, 14866, 4755, 37148, 3229, 3484, 24996, 15145, 26680, 14266, 24126, 16191, 24128, 4929, 28612, 14278, 24518, 14025, 11722, 14926, 3919, 25042, 15455, 1760, 8673, 3426, 27884, 32622, 12272, 15228}\n",
      "dict_items([(\"Lemma('consideration.n.01.consideration')\", 16), (\"Lemma('circumstance.n.03.consideration')\", 4), (\"Lemma('consideration.n.04.consideration')\", 1)])\n",
      "collecting tokens for  suggestion\n",
      "indices:    {1417, 20363, 24207, 5777, 16025, 9243, 8478, 23329, 3748, 17325, 693, 24889, 27706, 21182, 25152, 33218, 33220, 27975, 23496, 5321, 16088, 26459, 25062, 4858, 25068, 2554}\n",
      "dict_items([(\"Lemma('suggestion.n.02.suggestion')\", 5), (\"Lemma('suggestion.n.01.suggestion')\", 6), (\"Lemma('trace.n.01.suggestion')\", 1)])\n",
      "collecting tokens for  tip\n",
      "indices:    {23937, 17825, 17826, 7172, 11940, 27953, 22450, 3928, 33555, 7825, 3893, 3896, 12665, 8478, 2015}\n",
      "dict_items([(\"Lemma('gratuity.n.01.tip')\", 2), (\"Lemma('tip.v.01.tip')\", 2), (\"Lemma('tip.n.01.tip')\", 5), (\"Lemma('tip.n.03.tip')\", 2)])\n",
      "collecting tokens for  colonel\n",
      "indices:    {7738}\n",
      "dict_items([])\n",
      "collecting tokens for  slip\n",
      "indices:    {22436, 10661, 29639, 29641, 24076, 29676, 29648, 2612, 29599, 3641, 29658, 29629, 29886, 8478}\n",
      "dict_items([(\"Lemma('slip.v.05.slip')\", 1), (\"Lemma('steal.v.02.slip')\", 1), (\"Lemma('slip.n.02.slip')\", 1), (\"Lemma('slip.v.04.slip')\", 1), (\"Lemma('faux_pas.n.01.slip')\", 1)])\n",
      "collecting tokens for  folded\n",
      "indices:    {7009, 5412, 17413, 19754, 17740, 5655, 9528, 8478}\n",
      "dict_items([(\"Lemma('fold.v.01.fold')\", 3), (\"Lemma('fold.v.01.fold_up')\", 1)])\n",
      "collecting tokens for  thrust\n",
      "indices:    {5376, 18562, 7363, 5379, 835, 16612, 25419, 32140, 35372, 35761, 14325, 918, 17754, 17596, 36061, 8478, 16670}\n",
      "dict_items([(\"Lemma('force.v.04.thrust')\", 1), (\"Lemma('thrust.v.02.thrust')\", 3), (\"Lemma('stab.n.02.thrust')\", 1), (\"Lemma('push.n.02.thrust')\", 1), (\"Lemma('thrust.v.01.thrust')\", 8), (\"Lemma('lunge.v.01.thrust')\", 1)])\n",
      "collecting tokens for  belt\n",
      "indices:    {29893, 5577, 27049, 22667, 7857, 34483, 29885}\n",
      "dict_items([(\"Lemma('belt.n.01.belt')\", 1), (\"Lemma('belt.n.02.belt')\", 1)])\n",
      "collecting tokens for  gentleman\n",
      "indices:    {10744, 26594, 36884, 887}\n",
      "dict_items([(\"Lemma('gentleman.n.01.gentleman')\", 2)])\n",
      "collecting tokens for  joy\n",
      "indices:    {26258, 28307, 9749, 8344, 9778, 30005, 11959, 11963, 4668, 27586, 7877, 8520, 842, 10958, 27356, 19549, 7148, 26093, 25332, 25463, 7032, 26234}\n",
      "dict_items([(\"Lemma('joy.n.01.joy')\", 11), (\"Lemma('joy.n.02.joy')\", 2)])\n",
      "collecting tokens for  having\n",
      "indices:    {9668, 10621, 33232, 33236, 11036, 35997, 13759}\n",
      "dict_items([(\"Lemma('experience.v.03.have')\", 1), (\"Lemma('have.v.01.have')\", 2)])\n",
      "collecting tokens for  learned\n",
      "indices:    {36886, 3095, 9245, 2089, 2611, 56, 27709, 33343, 12355, 2634, 1611, 25684, 5205, 25688, 6746, 6747, 5212, 6753, 2669, 26234, 14468, 14471, 4261, 11433, 11434, 11436, 5293, 4788, 30900, 29365, 27337, 2254, 2261, 27353, 30433, 6900, 2303, 37119, 14596, 19205, 776, 29986, 23334, 6951, 21804, 10030, 2355, 25927, 24905, 4945, 35670, 25952, 25955, 30573, 5998, 18290, 31604, 31611, 21375, 29060, 12677, 21896, 11150, 400, 9621, 20381, 1949, 2467, 15782, 24487, 10150, 27049, 10163, 31669, 31159, 8156, 24551, 2027, 12789, 1530}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('learn.v.01.learn')\", 26), (\"Lemma('learn.v.02.learn')\", 26), (\"Lemma('erudite.s.01.learned')\", 6), (\"Lemma('learned_reaction.n.01.learned_reaction')\", 1), (\"Lemma('knowing.s.04.learned')\", 3), (\"Lemma('memorize.v.01.learn')\", 2)])\n",
      "collecting tokens for  dancing\n",
      "indices:    {26871, 20964, 26471, 1191, 9837, 31502, 36303, 19771, 6962, 25682, 22398, 22165, 11222, 7511, 24376, 25659, 36414}\n",
      "dict_items([(\"Lemma('dancing.n.01.dancing')\", 2), (\"Lemma('dance.v.01.dance')\", 3), (\"Lemma('dance.v.02.dance')\", 2)])\n",
      "collecting tokens for  concluded\n",
      "indices:    {31747, 1802, 8342, 12953, 23193, 2973, 3999, 3747, 8355, 26787, 34348, 20289, 27596, 15311, 5337, 20574, 27615, 15329, 26466, 27873, 3686, 3711}\n",
      "dict_items([(\"Lemma('reason.v.01.conclude')\", 15), (\"Lemma('conclude.v.02.conclude')\", 6)])\n",
      "collecting tokens for  claims\n",
      "indices:    {21408, 24609, 15303, 14888, 32394, 2700, 14860, 1772, 16463, 11633, 16146, 26836, 15288, 15289, 17498, 24030, 2783}\n",
      "dict_items([(\"Lemma('claim.n.01.claim')\", 3), (\"Lemma('title.n.07.claim')\", 1), (\"Lemma('claim.v.01.claim')\", 6), (\"Lemma('claim.n.04.claim')\", 1), (\"Lemma('claim.n.03.claim')\", 1), (\"Lemma('claim.v.03.claim')\", 1)])\n",
      "collecting tokens for  controlled\n",
      "indices:    {13059, 4237, 26898, 12700, 31391, 14625, 4771, 1704, 32297, 27312, 33201, 23476, 22850, 28098, 34759, 714, 23756, 15311, 15695, 26321, 32862, 11871, 21731, 19171, 2025, 15218, 35699, 2553, 12796}\n",
      "dict_items([(\"Lemma('control.v.01.control')\", 8), (\"Lemma('operate.v.03.control')\", 5), (\"Lemma('control.v.02.control')\", 3), (\"Lemma('controlled.a.01.controlled')\", 6)])\n",
      "collecting tokens for  gonzales\n",
      "indices:    {15342}\n",
      "dict_items([])\n",
      "collecting tokens for  v.\n",
      "indices:    {21696, 15281, 15342}\n",
      "dict_items([])\n",
      "collecting tokens for  1955\n",
      "indices:    {20358, 23054, 2834, 277, 21781, 25123, 33062, 4014, 4152, 33090, 22596, 33093, 15311, 15322, 3933, 3305, 11882, 3311, 3952, 3315, 15867, 2812}\n",
      "dict_items([])\n",
      "collecting tokens for  judgment\n",
      "indices:    {11488, 20416, 27875, 28261, 24902, 26087, 5352, 11495, 15242, 32366, 25043, 25495, 12027, 22047}\n",
      "dict_items([(\"Lemma('judgment.n.01.judgment')\", 3), (\"Lemma('judgment.n.02.judgment')\", 1), (\"Lemma('judgment.n.03.judgment')\", 1)])\n",
      "collecting tokens for  ritual\n",
      "indices:    {23169, 28168, 2583, 2587, 2590, 32039, 2605, 2613, 28085, 28086, 28088, 32055, 2632, 7116, 28119, 28120, 34406, 32112, 29171, 27646}\n",
      "dict_items([(\"Lemma('ritual.n.02.ritual')\", 3), (\"Lemma('ritual.n.01.ritual')\", 4)])\n",
      "collecting tokens for  consists\n",
      "indices:    {32516, 28168, 2959, 15889, 4500, 13846, 25367, 24223, 4393, 29873, 4401, 11321, 14783, 4415, 14785, 32836, 32840, 713, 32722, 10836, 12757, 4449, 2408, 29929, 29930, 2157, 21233, 4466, 13819, 3199}\n",
      "dict_items([(\"Lemma('dwell.v.02.consist')\", 1)])\n",
      "collecting tokens for  spiritual\n",
      "indices:    {36225, 27649, 5250, 5252, 27397, 28167, 28168, 27400, 28170, 31885, 28178, 23571, 36626, 27683, 27691, 13614, 10286, 4656, 35759, 32052, 4664, 27580, 28349, 31166, 28351, 30400, 24258, 28356, 27590, 27593, 1229, 14160, 27346, 26845, 28157, 28386, 26085, 14570, 31084, 14710, 28156, 27645, 27647}\n",
      "dict_items([(\"Lemma('religious.s.01.spiritual')\", 7), (\"Lemma('spiritual.s.02.spiritual')\", 1), (\"Lemma('spiritual.s.03.spiritual')\", 1)])\n",
      "collecting tokens for  beings\n",
      "indices:    {14214, 28167, 28168, 28170, 12955, 10152, 8232, 30765, 1459, 28084, 25397, 26548, 14643, 27453, 7359, 1229, 13401, 3808, 24161, 14692, 1252, 7534, 12918, 18935, 24831}\n",
      "dict_items([(\"Lemma('organism.n.01.being')\", 2)])\n",
      "collecting tokens for  struck\n",
      "indices:    {21632, 9348, 19332, 23047, 34061, 35343, 7959, 26393, 29210, 21660, 22812, 26145, 22818, 35489, 22820, 12713, 28971, 21164, 12339, 1206, 24119, 6972, 34749, 7102, 1726, 6332, 13763, 1732, 22982, 11079, 6214, 34891, 22348, 36941, 17360, 13395, 35416, 30301, 31459, 35427, 25574, 21479, 21480, 35430, 6377, 21483, 21612, 22510, 2930}\n",
      "dict_items([(\"Lemma('strike.v.05.strike')\", 4), (\"Lemma('hit.v.05.strike')\", 3), (\"Lemma('hit.v.02.strike')\", 7), (\"Lemma('strike.v.01.strike')\", 9), (\"Lemma('affect.v.05.strike')\", 10), (\"Lemma('strike.v.10.strike')\", 2), (\"Lemma('strike.v.11.strike')\", 1), (\"Lemma('strike.v.07.strike')\", 1), (\"Lemma('fall_upon.v.01.strike')\", 1), (\"Lemma('strike.v.04.strike')\", 1)])\n",
      "collecting tokens for  muzzle\n",
      "indices:    {35427, 5096, 6472, 29069, 5837, 35343, 35347, 29108, 11866, 12541}\n",
      "dict_items([(\"Lemma('gun_muzzle.n.01.muzzle')\", 2), (\"Lemma('muzzle.n.02.muzzle')\", 2)])\n",
      "collecting tokens for  pistol\n",
      "indices:    {17664, 17928, 21164, 35376, 6196, 23349, 18491, 6208, 35270, 19527, 77, 18389, 34027, 12654, 18415, 5104, 35442, 11892, 18420, 35327}\n",
      "dict_items([(\"Lemma('pistol.n.01.pistol')\", 13)])\n",
      "collecting tokens for  remained\n",
      "indices:    {27267, 31623, 29192, 35975, 23690, 30344, 9995, 18191, 2450, 2324, 17560, 20633, 4760, 21277, 4767, 22816, 18720, 19746, 8866, 36134, 5543, 36519, 4905, 4907, 7340, 18731, 11438, 29359, 28076, 25393, 7345, 11059, 12341, 26550, 12987, 7612, 14525, 8509, 26878, 32321, 36930, 7365, 6341, 7367, 34757, 12490, 4045, 12367, 26322, 23253, 2134, 1111, 21720, 2395, 35293, 12509, 478, 12384, 24675, 37093, 12517, 33256, 21357, 9838, 35695, 35570, 31987, 21364, 31480, 31998}\n",
      "dict_items([(\"Lemma('stay.v.01.remain')\", 26), (\"Lemma('stay.v.04.remain')\", 16), (\"Lemma('remain.v.03.remain')\", 11), (\"Lemma('persist.v.03.remain')\", 4)])\n",
      "collecting tokens for  artist\n",
      "indices:    {2054, 26761, 31889, 13461, 11289, 26908, 11294, 11296, 11298, 26147, 13618, 13623, 11325, 13637, 11334, 13640, 26960, 26715, 2652, 2659, 1127, 26601, 1129, 19568, 21105, 19571, 1143}\n",
      "dict_items([(\"Lemma('artist.n.01.artist')\", 19)])\n",
      "collecting tokens for  potential\n",
      "indices:    {2434, 19343, 27537, 2450, 32147, 24853, 3479, 21276, 13981, 22685, 2728, 2993, 25393, 32435, 2995, 2996, 2998, 25534, 25407, 3394, 22725, 13254, 12230, 27847, 13258, 11344, 12240, 27859, 3802, 16219, 16353, 32865, 10216, 4585, 3177, 11884, 13676, 3310, 13947}\n",
      "dict_items([(\"Lemma('likely.s.03.potential')\", 6), (\"Lemma('potential.a.01.potential')\", 7), (\"Lemma('potential.n.01.potential')\", 8)])\n",
      "collecting tokens for  art\n",
      "indices:    {28161, 5895, 13452, 5394, 26770, 31508, 2709, 13463, 13464, 2463, 32044, 13621, 2102, 2112, 26304, 11332, 2117, 14679, 23140, 2660, 2418, 23542, 28159}\n",
      "dict_items([(\"Lemma('art.n.01.art')\", 7), (\"Lemma('art.n.02.art')\", 4)])\n",
      "collecting tokens for  parked\n",
      "indices:    {33411, 33413, 17542, 33927, 33417, 17682, 13587, 33812, 33956, 33958, 33833, 33961, 33966, 7342, 19120, 7348, 33473, 33474, 33986, 21193, 13011, 21331, 27096, 34024, 34154, 34028, 19056}\n",
      "dict_items([(\"Lemma('park.v.01.park')\", 9), (\"Lemma('park.v.02.park')\", 3), (\"Lemma('parked.a.01.parked')\", 5)])\n",
      "collecting tokens for  remark\n",
      "indices:    {30211, 4868, 20388, 20390, 4838, 4839, 30461, 9382, 4875, 26124, 4872, 4870, 24975, 20402, 4857, 6877}\n",
      "dict_items([(\"Lemma('remark.n.01.remark')\", 9), (\"Lemma('note.v.01.remark')\", 1)])\n",
      "collecting tokens for  suffering\n",
      "indices:    {4868, 4875, 12558, 4759, 4888, 4891, 5038, 2223, 4674, 28102, 28368, 2256, 596, 5076, 2261, 7127, 2264, 27353, 7129, 2644, 5212, 2654, 2271, 7142, 5352, 2666, 8682, 4846, 4852, 2678, 4857, 4858, 4859, 4860, 24831}\n",
      "dict_items([(\"Lemma('suffering.n.02.suffering')\", 7), (\"Lemma('suffer.v.01.suffer')\", 4), (\"Lemma('distress.n.01.suffering')\", 3), (\"Lemma('agony.n.02.suffering')\", 10), (\"Lemma('suffer.v.02.suffer')\", 4), (\"Lemma('suffering.s.01.suffering')\", 1), (\"Lemma('miserable.s.01.suffering')\", 1), (\"Lemma('suffering.n.04.suffering')\", 1), (\"Lemma('suffer.v.06.suffer')\", 1), (\"Lemma('hurt.v.06.suffer')\", 1)])\n",
      "collecting tokens for  presumably\n",
      "indices:    {17250, 869, 2597, 33197, 27086, 14002, 13170, 14398, 34297, 24220, 17182, 16191}\n",
      "dict_items([(\"Lemma('presumably.r.01.presumably')\", 8)])\n",
      "collecting tokens for  plainly\n",
      "indices:    {24611, 4868, 36343, 15546, 7594, 25355, 13527, 6966, 8887, 4889, 12570, 17598, 4287}\n",
      "dict_items([(\"Lemma('obviously.r.01.plainly')\", 10)])\n",
      "collecting tokens for  remarks\n",
      "indices:    {4868, 26122, 32916, 20500, 29210, 12061, 4255, 37153, 12595, 26037, 32823, 26043, 21180, 4542, 24896, 4545, 5314, 5315, 24131, 32199, 12234, 8779, 11483, 5341, 14943, 5344, 36585, 1389, 22509, 25973, 19702, 1399, 14838, 28541}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('note.v.01.remark')\", 3), (\"Lemma('remark.n.01.remark')\", 17)])\n",
      "collecting tokens for  usually\n",
      "indices:    {23776, 12742, 11692, 19532, 12143, 16304, 635, 16124, 11613, 30046}\n",
      "dict_items([(\"Lemma('normally.r.01.usually')\", 8)])\n",
      "collecting tokens for  express\n",
      "indices:    {4868, 21384, 4877, 13198, 4883, 27413, 23840, 11042, 35752, 14258, 16178, 25523, 8894, 21319, 32202, 32078, 32212, 8150, 13654, 32125, 32094, 2655, 4839, 25202, 25205, 4853, 23671, 23672, 26108, 9597}\n",
      "dict_items([(\"Lemma('express.v.01.express')\", 14), (\"Lemma('express.v.02.express')\", 8), (\"Lemma('express.s.01.express')\", 1), (\"Lemma('express.r.01.express')\", 1), (\"Lemma('carry.v.04.express')\", 1)])\n",
      "collecting tokens for  backed\n",
      "indices:    {34190, 17423, 11664, 30868, 36766, 14111, 18467, 18469, 34087, 24615, 34089, 35245, 24506, 23751, 7370, 33868, 35155, 10461, 34141, 35421, 8940, 34163, 20219}\n",
      "dict_items([(\"Lemma('back.v.01.back')\", 2), (\"Lemma('back.v.02.back')\", 3), (\"Lemma('second.v.01.back')\", 2), (\"Lemma('back.v.04.back')\", 3)])\n",
      "collecting tokens for  fence\n",
      "indices:    {34948, 34955, 34956, 34959, 13584, 22419, 19490, 33840, 33841, 18226, 33842, 29366, 33848, 31419, 33852, 194, 24262, 10569, 33868, 19796, 11608, 7133, 11615, 18913, 26868, 373, 26879}\n",
      "dict_items([(\"Lemma('fence.n.01.fence')\", 9)])\n",
      "collecting tokens for  brush\n",
      "indices:    {29409, 721, 30074, 5053, 29534}\n",
      "dict_items([(\"Lemma('brush.v.03.brush')\", 2), (\"Lemma('brush.n.01.brush')\", 1), (\"Lemma('brush.v.01.brush')\", 1)])\n",
      "collecting tokens for  passed\n",
      "indices:    {25089, 35334, 22025, 31753, 33812, 28189, 22046, 4125, 9249, 4130, 23588, 2088, 1065, 20523, 33328, 4149, 28219, 4157, 65, 4163, 70, 4169, 33868, 28237, 24662, 4193, 4194, 28261, 2153, 17001, 108, 12401, 119, 124, 126, 24198, 23692, 142, 143, 35472, 14998, 35992, 35995, 24219, 33957, 9381, 5799, 9385, 9388, 3245, 11436, 8374, 5307, 3265, 9926, 5831, 14031, 24785, 33494, 20191, 5348, 15079, 23273, 36590, 23281, 7412, 6390, 6902, 13561, 27898, 24326, 6920, 25865, 17676, 6925, 13592, 18200, 12568, 20764, 6948, 11046, 11054, 19264, 23363, 34116, 23365, 18247, 36683, 36716, 36721, 35704, 14719, 35200, 35204, 29064, 35726, 18320, 19349, 17825, 36778, 9643, 12216, 5050, 16826, 8639, 18881, 35267, 5064, 33746, 35795, 9177, 23515, 9695, 27118, 27119, 36343}\n",
      "dict_items([(\"Lemma('travel_by.v.01.pass')\", 17), (\"Lemma('pass.v.01.pass')\", 10), (\"Lemma('pass.v.18.pass')\", 1), (\"Lemma('spend.v.01.pass')\", 2), (\"Lemma('pass.v.05.pass')\", 8), (\"Lemma('legislate.v.01.pass')\", 18), (\"Lemma('pass.v.09.pass')\", 3), (\"Lemma('elapse.v.01.pass')\", 12), (\"Lemma('pass.v.07.pass')\", 5), (\"Lemma('guide.v.05.pass')\", 2), (\"Lemma('evanesce.v.01.pass')\", 1), (\"Lemma('pass_through.v.02.pass_through')\", 1), (\"Lemma('pass_off.v.02.pass_off')\", 1), (\"Lemma('travel_by.v.01.pass_by')\", 1), (\"Lemma('pass.v.14.pass')\", 1), (\"Lemma('pass.v.16.pass')\", 1), (\"Lemma('pass.v.05.pass_on')\", 1), (\"Lemma('happen.v.01.pass')\", 1)])\n",
      "collecting tokens for  wire\n",
      "indices:    {33852, 11508, 32446}\n",
      "dict_items([])\n",
      "collecting tokens for  parlor\n",
      "indices:    {5888, 13952, 5890, 23170, 7754, 22282, 27663, 8815, 18193, 8337, 8691, 10102, 8247, 7740}\n",
      "dict_items([(\"Lemma('parlor.n.01.parlor')\", 8), (\"Lemma('living_room.n.01.parlor')\", 1)])\n",
      "collecting tokens for  cool\n",
      "indices:    {32065, 30146, 13090, 18855, 30013}\n",
      "dict_items([(\"Lemma('cool.a.01.cool')\", 1)])\n",
      "collecting tokens for  coward\n",
      "indices:    {18489, 22092}\n",
      "dict_items([(\"Lemma('coward.n.01.coward')\", 1)])\n",
      "collecting tokens for  tracks\n",
      "indices:    {18266, 30590}\n",
      "dict_items([(\"Lemma('path.n.04.track')\", 1)])\n",
      "collecting tokens for  pennsylvania\n",
      "indices:    {6405}\n",
      "dict_items([(\"Lemma('pennsylvania.n.01.Pennsylvania')\", 1)])\n",
      "collecting tokens for  underground\n",
      "indices:    {29058, 131, 5178, 15139, 32043, 15117, 29390, 15119, 24980, 26198, 34330, 20603, 12797, 15099}\n",
      "dict_items([(\"Lemma('belowground.s.01.underground')\", 7)])\n",
      "collecting tokens for  selected\n",
      "indices:    {10242, 4774, 14844, 21148, 12189}\n",
      "dict_items([(\"Lemma('choose.v.01.select')\", 4), (\"Lemma('selected.a.01.selected')\", 1)])\n",
      "collecting tokens for  visited\n",
      "indices:    {25216, 23170, 20488, 2192, 8850, 24727, 11035, 19617, 2215, 10796, 2222, 23983, 27577, 21947, 18619, 13116, 14528, 27715, 36807, 26575, 18514, 32474, 23131, 2274, 5865, 35689, 36983, 24827}\n",
      "dict_items([(\"Lemma('visit.v.04.visit')\", 4), (\"Lemma('travel_to.v.01.visit')\", 10), (\"Lemma('visit.v.03.visit')\", 6), (\"Lemma('visit.v.01.visit')\", 6), (\"Lemma('inflict.v.01.visit')\", 2)])\n",
      "collecting tokens for  brooklyn\n",
      "indices:    {21698}\n",
      "dict_items([])\n",
      "collecting tokens for  newark\n",
      "indices:    {25110}\n",
      "dict_items([])\n",
      "collecting tokens for  elizabeth\n",
      "indices:    {5174}\n",
      "dict_items([])\n",
      "collecting tokens for  boston\n",
      "indices:    {5160}\n",
      "dict_items([(\"Lemma('boston.n.01.Boston')\", 1)])\n",
      "collecting tokens for  pioneer\n",
      "indices:    {25139, 3347}\n",
      "dict_items([])\n",
      "collecting tokens for  poverty\n",
      "indices:    {32097, 5956, 36142, 36239, 25902, 6030, 6002, 7892, 25560, 12634, 25720, 36125}\n",
      "dict_items([(\"Lemma('poverty.n.01.poverty')\", 5)])\n",
      "collecting tokens for  frontier\n",
      "indices:    {28010, 25395, 12027}\n",
      "dict_items([])\n",
      "collecting tokens for  slack\n",
      "indices:    {22354}\n",
      "dict_items([])\n",
      "collecting tokens for  morality\n",
      "indices:    {32025, 25373, 12317, 22047, 16417, 16433, 16440, 16446, 16450, 16452, 6983, 25420, 25422, 12629, 14422, 36311, 14425, 13919, 28006, 14589}\n",
      "dict_items([(\"Lemma('morality.n.01.morality')\", 8), (\"Lemma('ethical_motive.n.01.morality')\", 5)])\n",
      "collecting tokens for  regions\n",
      "indices:    {32696, 3874, 29288, 25061}\n",
      "dict_items([(\"Lemma('area.n.03.region')\", 1)])\n",
      "collecting tokens for  complement\n",
      "indices:    {14977, 2401, 12225, 15972, 3877, 15974, 16039, 15975, 15978, 16043, 15979, 15982, 32142, 12855, 16024, 16026, 16027, 37055}\n",
      "dict_items([(\"Lemma('complement.n.01.complement')\", 11), (\"Lemma('complement.v.01.complement')\", 2), (\"Lemma('complement.n.02.complement')\", 1), (\"Lemma('complement.n.04.complement')\", 1), (\"Lemma('complement.n.03.complement')\", 1)])\n",
      "collecting tokens for  linguist\n",
      "indices:    {30240, 10209, 30244, 15976, 15977, 15978, 30218, 10186, 10191, 30263, 16060, 30207}\n",
      "dict_items([(\"Lemma('linguist.n.01.linguist')\", 7)])\n",
      "collecting tokens for  infinite\n",
      "indices:    {28129, 26945, 24333, 2158, 2159, 15417, 4669}\n",
      "dict_items([(\"Lemma('infinite.a.01.infinite')\", 4)])\n",
      "collecting tokens for  wisdom\n",
      "indices:    {752, 34920, 21919, 14280}\n",
      "dict_items([(\"Lemma('wisdom.n.01.wisdom')\", 1), (\"Lemma('wisdom.n.03.wisdom')\", 1)])\n",
      "collecting tokens for  memory\n",
      "indices:    {9807, 13586, 9010, 7605, 13558}\n",
      "dict_items([(\"Lemma('memory.n.01.memory')\", 2), (\"Lemma('memory.n.02.memory')\", 3)])\n",
      "collecting tokens for  load\n",
      "indices:    {5517, 29070, 29071, 29074, 13591, 5528, 18586, 29467, 12702, 12834, 12835, 5541, 33832, 170, 18738, 28469, 4408, 193, 24517, 30156, 10317, 3668, 35414, 33122, 34917, 2919, 20200, 30192, 23415}\n",
      "dict_items([(\"Lemma('load.n.01.load')\", 8), (\"Lemma('load.n.04.load')\", 1), (\"Lemma('load.n.05.load')\", 1), (\"Lemma('load.n.02.load')\", 1), (\"Lemma('cargo.n.01.load')\", 1)])\n",
      "collecting tokens for  ready\n",
      "indices:    {31266, 25700, 18216, 32648, 12856, 23752, 12943, 25072, 17360, 19962, 10003, 36820, 56, 18234, 20127}\n",
      "dict_items([(\"Lemma('ready.a.01.ready')\", 9)])\n",
      "collecting tokens for  carry\n",
      "indices:    {128, 17529, 8578, 19842, 19844, 29445, 17666, 33154, 21893, 19335, 10506, 14733, 29968, 10258, 20882, 23316, 30486, 15386, 13851, 15004, 20250, 10268, 14748, 12834, 12835, 24484, 1827, 8102, 5411, 24872, 32169, 10027, 20653, 23730, 14898, 28468, 1083, 22847, 10559, 10561, 14016, 11455, 16198, 2764, 34131, 12118, 86, 1629, 20447, 14185, 18666, 2155, 22635, 12653, 28526, 14959, 7540, 20853, 7545, 32893, 12927}\n",
      "dict_items([(\"Lemma('carry.v.02.carry')\", 7), (\"Lemma('transport.v.02.carry')\", 14), (\"Lemma('carry.v.12.carry')\", 1), (\"Lemma('carry.v.05.carry')\", 2), (\"Lemma('impart.v.03.carry')\", 3), (\"Lemma('hold.v.14.carry')\", 3), (\"Lemma('carry.v.11.carry')\", 1), (\"Lemma('carry.v.04.carry')\", 4), (\"Lemma('carry_through.v.01.carry_out')\", 1), (\"Lemma('carry.v.10.carry')\", 1), (\"Lemma('hold.v.11.carry')\", 2), (\"Lemma('carry.v.08.carry')\", 1)])\n",
      "collecting tokens for  troop\n",
      "indices:    {21099, 12831, 2679}\n",
      "dict_items([(\"Lemma('troop.n.01.troop')\", 1)])\n",
      "collecting tokens for  regiment\n",
      "indices:    {12805, 12831}\n",
      "dict_items([(\"Lemma('regiment.n.01.regiment')\", 1)])\n",
      "collecting tokens for  juet\n",
      "indices:    {12445}\n",
      "dict_items([(\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  francis\n",
      "indices:    {22501}\n",
      "dict_items([])\n",
      "collecting tokens for  hudson\n",
      "indices:    {7840}\n",
      "dict_items([(\"Lemma('hudson.n.01.Hudson')\", 1)])\n",
      "collecting tokens for  enemies\n",
      "indices:    {28421, 3596, 12945, 25748, 12442, 12449, 12196, 24625, 12215, 27465, 30281, 21705, 30285, 6998, 10204, 27502, 27504, 883, 37110, 28407}\n",
      "dict_items([(\"Lemma('enemy.n.03.enemy')\", 2), (\"Lemma('enemy.n.02.enemy')\", 6), (\"Lemma('enemy.n.01.enemy')\", 1)])\n",
      "collecting tokens for  roman\n",
      "indices:    {12304}\n",
      "dict_items([])\n",
      "collecting tokens for  lower\n",
      "indices:    {25122}\n",
      "dict_items([])\n",
      "collecting tokens for  via\n",
      "indices:    {20958, 4229, 26951, 5032, 23749, 12522, 19692, 687, 20946, 3794, 5142, 4216, 27036, 29981, 4222}\n",
      "dict_items([])\n",
      "collecting tokens for  gardens\n",
      "indices:    {30418, 25659, 30420, 31527}\n",
      "dict_items([])\n",
      "collecting tokens for  particles\n",
      "indices:    {3334, 3209, 3340, 3345, 3348, 3221, 3222, 3351, 17305, 3225, 31010, 3368, 3369, 3115, 3116, 25390, 27958, 5564, 27975, 27977, 3403, 3404, 3409, 3410, 36051, 3412, 3420, 3422, 3427, 3429, 31078, 3303, 3433, 3307, 3310, 3311, 3823, 3192, 3193, 3195, 3199}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('atom.n.02.particle')\", 23), (\"Lemma('particle.n.02.particle')\", 11)])\n",
      "collecting tokens for  maximum\n",
      "indices:    {2817, 11399, 1799, 23561, 2569, 22284, 5521, 1810, 21267, 21522, 30097, 30483, 3732, 145, 15010, 3747, 2980, 3752, 11306, 11819, 14771, 29875, 16313, 21692, 3007, 15040, 9793, 1217, 11584, 15044, 11461, 18758, 15052, 2765, 2766, 5581, 32464, 5583, 3029, 20566, 20696, 5593, 3707, 31201, 3685, 23527, 3433, 3692, 3693, 3694, 30193, 3700, 2808, 3451}\n",
      "dict_items([(\"Lemma('maximal.a.01.maximum')\", 26), (\"Lemma('utmost.n.01.maximum')\", 1), (\"Lemma('maximum.n.01.maximum')\", 8)])\n",
      "collecting tokens for  detected\n",
      "indices:    {3590, 3433, 3337, 11404, 3757, 3119, 3572, 3573, 3348, 3576, 2812}\n",
      "dict_items([(\"Lemma('detected.a.01.detected')\", 2), (\"Lemma('detect.v.01.detect')\", 8)])\n",
      "collecting tokens for  compelled\n",
      "indices:    {6336, 2657, 25442, 1507, 16164, 31781, 20258, 25448, 2665, 8681, 30284, 15281, 24914, 5075, 13977}\n",
      "dict_items([(\"Lemma('compel.v.01.compel')\", 7)])\n",
      "collecting tokens for  urbanization\n",
      "indices:    {31781, 31787, 31852, 31791, 31792, 32982, 31831}\n",
      "dict_items([])\n",
      "collecting tokens for  dramatic\n",
      "indices:    {27266, 20230, 25355, 25469, 8080, 24592, 13843, 26643, 26901, 32157, 22941, 1570, 31781, 26791, 13482, 683, 8109, 16431, 26034, 26677, 30774, 27574, 26297, 22716, 26564, 27080, 1100, 16464, 22999, 33367, 36952, 31706, 13273, 1246, 11231, 2657, 612, 24036, 7526, 32875, 32237, 8433, 1277}\n",
      "dict_items([(\"Lemma('dramatic.a.01.dramatic')\", 12), (\"Lemma('dramatic.s.02.dramatic')\", 4)])\n",
      "collecting tokens for  overwhelming\n",
      "indices:    {12324, 30823, 28648, 4907, 12941, 13615, 26963, 15221, 29237, 28441, 1310}\n",
      "dict_items([(\"Lemma('overpowering.s.01.overwhelming')\", 6)])\n",
      "collecting tokens for  effects\n",
      "indices:    {23680, 24960, 4228, 15237, 4229, 11657, 4234, 27787, 15242, 4879, 27792, 25494, 26135, 3224, 4759, 25366, 19094, 3228, 14621, 11036, 25888, 31781, 4773, 25386, 25390, 16431, 25391, 3118, 3122, 31794, 2868, 2991, 25400, 25402, 1082, 32700, 27837, 32191, 3265, 1090, 28102, 2890, 3020, 9679, 3279, 21075, 26965, 14422, 11991, 3424, 3297, 3043, 28003, 3305, 1770, 3051, 26986, 3049, 3050, 3313, 3058, 3057, 1779, 12786, 24182, 1783, 2418, 4730}\n",
      "dict_items([(\"Lemma('consequence.n.01.effect')\", 26), (\"Lemma('effect.n.03.effect')\", 3)])\n",
      "collecting tokens for  culture\n",
      "indices:    {2489, 4988, 13534, 30225}\n",
      "dict_items([(\"Lemma('culture.n.01.culture')\", 2), (\"Lemma('acculturation.n.02.culture')\", 1)])\n",
      "collecting tokens for  utterly\n",
      "indices:    {13825, 27913, 28445, 35998, 28063, 5411, 31781, 1446, 30759, 19754, 6060, 33849, 14651, 27342, 33358, 33762, 15460, 37106, 22388}\n",
      "dict_items([(\"Lemma('absolutely.r.01.utterly')\", 6)])\n",
      "collecting tokens for  ignored\n",
      "indices:    {20226, 36760, 2456, 31781, 24108, 7348, 19128, 2107, 16187, 4796, 26687, 8898, 10495, 8522, 18250, 5080, 16986, 34522, 16097, 18289, 32376, 10105, 8447}\n",
      "dict_items([(\"Lemma('ignore.v.01.ignore')\", 11), (\"Lemma('dismiss.v.01.ignore')\", 6), (\"Lemma('ignore.v.03.ignore')\", 5), (\"Lemma('neglect.v.04.ignore')\", 1)])\n",
      "collecting tokens for  bulk\n",
      "indices:    {14816, 34468, 31781, 25767, 32170, 23563, 7341, 12431, 11674, 15220, 23546, 24219, 4797, 14815}\n",
      "dict_items([(\"Lemma('majority.n.01.bulk')\", 5), (\"Lemma('bulk.n.02.bulk')\", 1)])\n",
      "collecting tokens for  truck\n",
      "indices:    {33792, 18946, 18948, 18950, 903, 35723, 18955, 19470, 25233, 18679, 25255, 807, 5425, 20407, 4408, 5433, 24248, 24253, 18883, 33864, 18890, 18891, 34891, 18897, 18906, 17503, 18914, 18916, 33767, 18925, 23540, 18935, 18943}\n",
      "dict_items([(\"Lemma('truck.n.01.truck')\", 17)])\n",
      "collecting tokens for  similarity\n",
      "indices:    {15846, 34985, 18892, 16108, 16182, 7609, 11484, 14078}\n",
      "dict_items([(\"Lemma('similarity.n.01.similarity')\", 7)])\n",
      "collecting tokens for  ford\n",
      "indices:    {33820}\n",
      "dict_items([])\n",
      "collecting tokens for  gift\n",
      "indices:    {37123, 25481, 26761, 28307, 12308, 19478, 13852, 22315, 17582, 30649, 29115, 19647, 20927, 28239, 22492, 102, 26086, 1515, 877, 26093, 28269}\n",
      "dict_items([(\"Lemma('endowment.n.01.gift')\", 2), (\"Lemma('giving.n.01.gift')\", 2), (\"Lemma('gift.n.01.gift')\", 4)])\n",
      "collecting tokens for  color\n",
      "indices:    {10531, 3652, 5030, 25702, 4937, 2378, 11371, 174, 34479, 24562, 28661, 19094, 24567, 1013, 37054}\n",
      "dict_items([(\"Lemma('color.n.01.color')\", 6), (\"Lemma('color.v.01.color')\", 1), (\"Lemma('color.n.03.color')\", 1), (\"Lemma('color.a.01.color')\", 1), (\"Lemma('color.n.04.color')\", 1)])\n",
      "collecting tokens for  imagery\n",
      "indices:    {2148, 13804, 4941, 31153, 31827, 30741, 4949, 31161}\n",
      "dict_items([(\"Lemma('imagination.n.02.imagery')\", 4)])\n",
      "collecting tokens for  greatly\n",
      "indices:    {1410, 25735, 31624, 1166, 15507, 3220, 21656, 15513, 2073, 26778, 30750, 1824, 24358, 32552, 21289, 11818, 4651, 32168, 16184, 1085, 4158, 4159, 33088, 25283, 23243, 30799, 24914, 1368, 4193, 24164, 26474, 22635, 13804, 4205, 24945, 14452, 24440, 3193, 3707}\n",
      "dict_items([(\"Lemma('greatly.r.01.greatly')\", 20)])\n",
      "collecting tokens for  paris\n",
      "indices:    {10777}\n",
      "dict_items([])\n",
      "collecting tokens for  drive\n",
      "indices:    {27459, 29316}\n",
      "dict_items([(\"Lemma('force.v.06.drive')\", 1)])\n",
      "collecting tokens for  putting\n",
      "indices:    {27394, 30244, 14023, 26415, 32628, 36436, 24441, 15964}\n",
      "dict_items([(\"Lemma('put.v.02.put')\", 3), (\"Lemma('put.v.04.put')\", 2)])\n",
      "collecting tokens for  switch\n",
      "indices:    {21898, 34445, 34460, 17573, 10025, 33838, 28721, 10034, 31802, 28731, 28735, 28737, 11715, 588, 31190, 35678, 35679, 9192, 17004, 35699}\n",
      "dict_items([(\"Lemma('substitution.n.01.switch')\", 1), (\"Lemma('switch.n.01.switch')\", 3), (\"Lemma('switch_over.v.01.switch')\", 1)])\n",
      "collecting tokens for  pressing\n",
      "indices:    {10592, 30338, 20997, 6633, 37065, 714, 4656, 29648, 5780, 9662}\n",
      "dict_items([(\"Lemma('press.v.01.press')\", 5), (\"Lemma('pressing.s.01.pressing')\", 1), (\"Lemma('stub_out.v.01.press_out')\", 1), (\"Lemma('weigh.v.05.press')\", 1)])\n",
      "collecting tokens for  reverse\n",
      "indices:    {26819, 11172, 26820, 17004, 31309, 30577, 4850, 27794, 31892, 27829, 29559, 1594, 4031}\n",
      "dict_items([(\"Lemma('change_by_reversal.v.01.reverse')\", 3), (\"Lemma('rearward.s.02.reverse')\", 1), (\"Lemma('reverse.n.02.reverse')\", 1), (\"Lemma('turn_back.v.05.reverse')\", 5), (\"Lemma('reverse.n.01.reverse')\", 1), (\"Lemma('overrule.v.01.reverse')\", 1)])\n",
      "collecting tokens for  vast\n",
      "indices:    {11648, 14690, 21699, 27526, 27980, 29395, 12980, 19571}\n",
      "dict_items([(\"Lemma('huge.s.01.vast')\", 4)])\n",
      "collecting tokens for  shaking\n",
      "indices:    {10913, 6472, 22511, 8783, 14289, 35153, 19705, 34171}\n",
      "dict_items([(\"Lemma('shake.v.02.shake')\", 2), (\"Lemma('shaking.n.01.shaking')\", 1), (\"Lemma('shake.v.01.shake')\", 2), (\"Lemma('judder.v.01.shake')\", 1)])\n",
      "collecting tokens for  research\n",
      "indices:    {2728, 5490}\n",
      "dict_items([(\"Lemma('research.n.01.research')\", 2)])\n",
      "collecting tokens for  wondered\n",
      "indices:    {30336, 19713, 13061, 18694, 34824, 18705, 16790, 35749, 36011, 8749, 1198, 30514, 17722, 8379, 36541, 8388, 36682, 37069, 19663, 18640, 2129, 28624, 7123, 7124, 7892, 16852, 33365, 34897, 16866, 6498, 18022, 9958, 9195, 7917, 34800, 18033, 19711}\n",
      "dict_items([(\"Lemma('wonder.v.01.wonder')\", 24), (\"Lemma('wonder.v.02.wonder')\", 13)])\n",
      "collecting tokens for  neutral\n",
      "indices:    {4128, 23749, 23751, 13640, 7721, 22634, 22667, 20254, 27855, 13647, 5650, 3417, 23739, 13661, 22622}\n",
      "dict_items([(\"Lemma('impersonal.s.02.neutral')\", 3), (\"Lemma('neutral.s.03.neutral')\", 2), (\"Lemma('inert.s.02.neutral')\", 1)])\n",
      "collecting tokens for  moral\n",
      "indices:    {27905, 8464, 12306, 25495, 27801, 22775, 13731, 12323, 28093, 13759, 28100, 968, 36309, 28121, 5212, 11100, 27869, 25439, 1257, 13929, 25451, 28013, 31989, 12279}\n",
      "dict_items([(\"Lemma('moral.a.01.moral')\", 2), (\"Lemma('moral.n.01.moral')\", 1)])\n",
      "collecting tokens for  joseph\n",
      "indices:    {14447}\n",
      "dict_items([])\n",
      "collecting tokens for  maria\n",
      "indices:    {26914}\n",
      "dict_items([])\n",
      "collecting tokens for  meet\n",
      "indices:    {14721, 33154, 36867, 32772, 27653, 33914, 33923, 2056, 14596, 21771, 9613, 32782, 16786, 20371, 21399, 13719, 2714, 26399, 8351, 21924, 32679, 32810, 18860, 1837, 36143, 24626, 16307, 20153, 31290, 24893, 24382, 14014, 31939, 10693, 19785, 970, 20941, 14542, 334, 23506, 13395, 27604, 13397, 24918, 23259, 2779, 24795, 1117, 20192, 13409, 14049, 20962, 20193, 20455, 8809, 19565, 36976, 21105, 246, 11770, 17019, 252, 254, 31103}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('meet.v.10.meet')\", 4), (\"Lemma('meet.v.04.meet')\", 7), (\"Lemma('meet.v.05.meet')\", 6), (\"Lemma('meet.v.09.meet')\", 3), (\"Lemma('converge.v.01.meet')\", 3), (\"Lemma('meet.v.02.meet')\", 12), (\"Lemma('meet.v.08.meet')\", 5), (\"Lemma('meet.v.06.meet')\", 5), (\"Lemma('meet.v.01.meet')\", 10), (\"Lemma('meet.v.07.meet')\", 3), (\"Lemma('meet.n.01.meet')\", 3)])\n",
      "collecting tokens for  survive\n",
      "indices:    {29184, 24196, 2568, 24980, 13337, 13340, 27806, 27171, 24743, 36137, 23980, 25264, 2359, 28475, 28476, 11989, 21205, 24161, 5220, 33000, 14314, 25326, 6900}\n",
      "dict_items([(\"Lemma('survive.v.01.survive')\", 15), (\"Lemma('exist.v.02.survive')\", 3), (\"Lemma('survive.v.02.survive')\", 5)])\n",
      "collecting tokens for  stress\n",
      "indices:    {25088, 11797, 30234, 4636, 13342, 26157, 15963, 15964, 32862, 15969, 15972, 32869, 15974, 15973, 15975, 15977, 32875, 15980, 15979, 15982, 15983, 31854, 32881, 15985, 15987, 4206, 15990, 15992, 15994, 15995, 15996, 15998, 15999, 26752, 16000, 16002, 16003, 16004, 16001, 16006, 16007, 16008, 16009, 16012, 16014, 16015, 16016, 16018, 16020, 16022, 16023, 16024, 16027, 16028, 16029, 16030, 16033, 16034, 16035, 16039, 16040, 13993, 16041, 16042, 11989, 26341, 12043, 24337, 11541, 13620, 11605, 31067, 15724, 31084, 15731, 28025, 30089, 27542, 16283, 16287, 26021, 25544, 6096}\n",
      "dict_items([(\"Lemma('stress.n.01.stress')\", 26), (\"Lemma('stress.n.04.stress')\", 2), (\"Lemma('stress.v.01.stress')\", 9), (\"Lemma('tension.n.01.stress')\", 4), (\"Lemma('stress.n.03.stress')\", 3)])\n",
      "collecting tokens for  declares\n",
      "indices:    {1443, 26826, 23946, 11980, 30828, 32047, 11989, 20344, 12062}\n",
      "dict_items([(\"Lemma('declare.v.01.declare')\", 8), (\"Lemma('declare.v.04.declare')\", 1)])\n",
      "collecting tokens for  wait\n",
      "indices:    {5140}\n",
      "dict_items([])\n",
      "collecting tokens for  minute\n",
      "indices:    {9216, 2817, 34112, 34691, 15140, 901, 198, 5987, 22504, 1546, 31850, 36112, 17077, 6902, 35415, 37112, 18717}\n",
      "dict_items([(\"Lemma('minute.n.01.minute')\", 9)])\n",
      "collecting tokens for  over-all\n",
      "indices:    {20640, 1, 27105, 15814, 1799, 24490, 12938, 12268, 8333, 32621, 14065, 1586, 15763, 4693, 11093, 26938, 26493, 3230}\n",
      "dict_items([(\"Lemma('overall.s.01.overall')\", 8), (\"Lemma('overall.s.02.overall')\", 4)])\n",
      "collecting tokens for  impression\n",
      "indices:    {20243, 13336, 25501, 20510, 35747, 23332, 26789, 23722, 31020, 10159, 25912, 26938, 14267, 11328, 4046, 26965, 8311, 36698, 8292, 23140, 13671, 22632, 29552, 36336, 2166, 25975}\n",
      "dict_items([(\"Lemma('impression.n.01.impression')\", 5), (\"Lemma('impression.n.02.impression')\", 4)])\n",
      "collecting tokens for  sansom\n",
      "indices:    {26935}\n",
      "dict_items([])\n",
      "collecting tokens for  compounded\n",
      "indices:    {24112, 27697, 10615, 24824, 2169, 26938, 28029, 34682}\n",
      "dict_items([(\"Lemma('compound.v.02.compound')\", 3), (\"Lemma('intensify.v.02.compound')\", 4)])\n",
      "collecting tokens for  visual\n",
      "indices:    {2176, 32711, 30567, 4935, 4941, 34734, 32720, 4945, 4946, 4948, 31925, 4949, 4950, 2136, 2393, 3387, 4958}\n",
      "dict_items([(\"Lemma('ocular.a.02.visual')\", 12)])\n",
      "collecting tokens for  details\n",
      "indices:    {25347, 29572, 14726, 3081, 5002, 1806, 2706, 13586, 2586, 21275, 5277, 31270, 2602, 11306, 31153, 20023, 16056, 26553, 26938, 19515, 26684, 31166, 19519, 64, 4803, 15814, 10695, 32456, 4936, 28744, 2132, 34392, 30176, 15076, 32106, 16750, 26479, 2671, 16751, 113, 25589}\n",
      "dict_items([(\"Lemma('detail.n.01.detail')\", 17), (\"Lemma('detail.n.03.detail')\", 1), (\"Lemma('detail.n.02.detail')\", 5), (\"Lemma('details.n.01.details')\", 2)])\n",
      "collecting tokens for  mixture\n",
      "indices:    {29188, 3616, 4133, 11304, 29487, 3254, 3255, 26550, 26938, 3529, 3531, 3150, 27479, 29531, 1249, 7522, 7530, 30443, 26867}\n",
      "dict_items([(\"Lemma('mixture.n.01.mixture')\", 8), (\"Lemma('assortment.n.01.mixture')\", 2), (\"Lemma('concoction.n.01.mixture')\", 1)])\n",
      "collecting tokens for  architecture\n",
      "indices:    {20676, 5001, 31530, 9170, 2098, 5014, 26938, 2044, 22206}\n",
      "dict_items([(\"Lemma('architecture.n.01.architecture')\", 3), (\"Lemma('architecture.n.02.architecture')\", 1), (\"Lemma('architecture.n.03.architecture')\", 1)])\n",
      "collecting tokens for  scenery\n",
      "indices:    {27042, 26466, 22402, 30396, 1198, 29303, 1848, 26938, 1179, 6268, 29149}\n",
      "dict_items([(\"Lemma('scenery.n.02.scenery')\", 1), (\"Lemma('scenery.n.01.scenery')\", 3)])\n",
      "collecting tokens for  lights\n",
      "indices:    {8704, 30080, 29317, 7693, 33555, 16796, 27933, 30332, 31269, 30374, 33961, 19121, 10034, 11315, 11326, 11078, 33480, 5194, 13004, 21332, 25303, 8919, 11358, 7008, 11364, 31334, 377, 19179, 9963, 7021, 35699, 10484, 25204, 14452, 4728, 31865, 8828, 30333}\n",
      "dict_items([(\"Lemma('light.n.02.light')\", 12), (\"Lemma('light.n.08.light')\", 1), (\"Lemma('light.n.07.light')\", 2), (\"Lemma('light.n.09.light')\", 1), (\"Lemma('luminosity.n.01.light')\", 1)])\n",
      "collecting tokens for  shadows\n",
      "indices:    {13600, 7875, 26659, 23333, 4999, 35402, 11371, 35249, 14323, 36054, 6392, 8857, 26938, 36061}\n",
      "dict_items([(\"Lemma('shadow.n.01.shadow')\", 4), (\"Lemma('darkness.n.02.shadow')\", 1), (\"Lemma('apparition.n.03.shadow')\", 2)])\n",
      "collecting tokens for  prone\n",
      "indices:    {31010, 4582, 31783, 13928, 17865, 22727, 22674, 24338, 13235, 31957, 25141, 2011, 13181}\n",
      "dict_items([(\"Lemma('prone.s.02.prone')\", 2)])\n",
      "collecting tokens for  plenty\n",
      "indices:    {14988}\n",
      "dict_items([(\"Lemma('enough.r.01.plenty')\", 1)])\n",
      "collecting tokens for  trio\n",
      "indices:    {26434, 23308, 22294}\n",
      "dict_items([])\n",
      "collecting tokens for  shared\n",
      "indices:    {30210, 3849, 35849, 12297, 16396, 23184, 22801, 14358, 14488, 25377, 22948, 32680, 25898, 27820, 26550, 13753, 4683, 16339, 19541, 7771, 863, 4578, 30834, 32502, 32374, 16378, 637, 26623}\n",
      "dict_items([(\"Lemma('share.v.01.share')\", 12), (\"Lemma('share.v.04.share')\", 2), (\"Lemma('partake.v.02.share')\", 4), (\"Lemma('share.v.02.share')\", 6), (\"Lemma('shared.a.01.shared')\", 2)])\n",
      "collecting tokens for  honors\n",
      "indices:    {21603, 21571, 25641, 22089, 22096, 11282, 21589, 1943, 11447, 11262}\n",
      "dict_items([(\"Lemma('award.n.02.honor')\", 3), (\"Lemma('honor.v.01.honor')\", 1)])\n",
      "collecting tokens for  introduced\n",
      "indices:    {24704, 29189, 1544, 5521, 29080, 30878, 2975, 29090, 21925, 26790, 33071, 7600, 1075, 21315, 29123, 22595, 4423, 14536, 29130, 2635, 23373, 28109, 27862, 20445, 1247, 30051, 5604, 105, 11883, 16236, 20462, 4604, 22139, 28540, 637, 24446}\n",
      "dict_items([(\"Lemma('introduce.v.01.introduce')\", 14), (\"Lemma('introduce.v.02.introduce')\", 9), (\"Lemma('introduce.v.05.introduce')\", 1), (\"Lemma('insert.v.02.introduce')\", 5), (\"Lemma('introduce.v.08.introduce')\", 1), (\"Lemma('introduce.v.07.introduce')\", 1), (\"Lemma('bring_in.v.01.introduce')\", 5)])\n",
      "collecting tokens for  bob\n",
      "indices:    {30536}\n",
      "dict_items([])\n",
      "collecting tokens for  sports\n",
      "indices:    {11880, 403}\n",
      "dict_items([])\n",
      "collecting tokens for  sharply\n",
      "indices:    {27012, 36365, 5009, 31505, 25367, 2075, 20514, 15523, 5545, 10154, 22834, 31154, 26548, 1466, 9532, 19265, 16579, 198, 18636, 15827, 36829, 1252, 16745, 23404, 8817, 35698, 243, 4980, 24191}\n",
      "dict_items([(\"Lemma('aggressively.r.01.sharply')\", 12), (\"Lemma('sharply.r.03.sharply')\", 2), (\"Lemma('sharply.r.02.sharply')\", 3)])\n",
      "collecting tokens for  runs\n",
      "indices:    {258, 2968, 665, 667, 24861, 27297, 31273, 682, 24491, 26286, 430, 437, 183, 24504, 442, 12602, 27836, 32058, 191, 30147, 11075, 11849, 3275, 22991, 22992, 22994, 22995, 213, 23000, 23001, 23003, 23005, 23007, 23009, 14051, 612, 23012, 614, 2023, 24806, 23018, 23021, 370}\n",
      "dict_items([(\"Lemma('test.n.05.run')\", 3), (\"Lemma('run.v.05.run')\", 2), (\"Lemma('gamble.v.01.run_a_risk')\", 2), (\"Lemma('run.v.01.run')\", 1), (\"Lemma('run.n.01.run')\", 5), (\"Lemma('tend.v.01.run')\", 1), (\"Lemma('run.v.13.run')\", 1), (\"Lemma('run.v.06.run')\", 1), (\"Lemma('operate.v.01.run')\", 1)])\n",
      "collecting tokens for  listen\n",
      "indices:    {19907, 17846}\n",
      "dict_items([(\"Lemma('listen.v.01.listen')\", 1)])\n",
      "collecting tokens for  difficulty\n",
      "indices:    {3715, 13316, 37002, 30347, 30859, 9997, 1940, 3234, 26660, 16297, 28458, 16299, 15404, 11444, 20023, 30265, 4925, 31807, 23488, 4033, 7363, 32579, 28101, 14023, 7112, 16076, 1231, 32848, 30801, 4434, 3279, 23764, 22741, 15702, 27993, 23517, 11488, 33250, 30823, 1773, 4592, 16113, 2930, 14067, 12400, 15736, 15739, 7676, 13309}\n",
      "dict_items([(\"Lemma('trouble.n.04.difficulty')\", 15), (\"Lemma('difficulty.n.02.difficulty')\", 10), (\"Lemma('difficulty.n.03.difficulty')\", 2), (\"Lemma('difficulty.n.04.difficulty')\", 4)])\n",
      "collecting tokens for  overcome\n",
      "indices:    {28609, 16068, 32679, 22568, 2537, 22951, 6763, 651, 9390, 34735, 24527, 5873, 12241, 21428, 792, 23996, 23517}\n",
      "dict_items([(\"Lemma('overwhelm.v.01.overcome')\", 5), (\"Lemma('overcome.v.02.overcome')\", 8), (\"Lemma('get_the_better_of.v.01.overcome')\", 4)])\n",
      "collecting tokens for  clear\n",
      "indices:    {8704, 25088, 32781, 18446, 7696, 14362, 25632, 4647, 12327, 32810, 30763, 8236, 20524, 26672, 34352, 28721, 17459, 22580, 32823, 28728, 28731, 28732, 36412, 12363, 31820, 21585, 22613, 35415, 10337, 31332, 14949, 17006, 7281, 21625, 27775, 5248, 27263, 3717, 34437, 27783, 34438, 30347, 30350, 13470, 16035, 32421, 13480, 16043, 26796, 16046, 14519, 33465, 27837, 12990, 14531, 33482, 24269, 22738, 26323, 26839, 13528, 4313, 31961, 4318, 31971, 3813, 4846, 8943, 31993, 26882, 33541, 37131, 14604, 27919, 20241, 33554, 14101, 5398, 19224, 5914, 16159, 27940, 3883, 31534, 19248, 34102, 1846, 27131, 32569, 4929, 20292, 34119, 1355, 23374, 23886, 3921, 32088, 13659, 22876, 3937, 12641, 13676, 23917, 3950, 19311, 29552, 33137, 36716, 1399, 4472, 4996, 19338, 32147, 18835, 27033, 17308, 32164, 22950, 30120, 2474, 26028, 29614, 35248, 12212, 12226, 4547, 32194, 26057, 26061, 6098, 25042, 19924, 9175, 27096, 23517, 15844, 10726, 4585, 7149, 36336, 9720, 4601, 26618, 29691, 27133, 4095}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('clear.a.04.clear')\", 4), (\"Lemma('clear.a.01.clear')\", 26), (\"Lemma('clear.s.03.clear')\", 3), (\"Lemma('unclutter.v.01.clear')\", 4), (\"Lemma('authorize.v.01.clear')\", 1), (\"Lemma('clear.v.10.clear')\", 1), (\"Lemma('clean.s.03.clear')\", 1), (\"Lemma('clear.r.01.clear')\", 3), (\"Lemma('clear.v.02.clear')\", 3), (\"Lemma('clear.s.05.clear')\", 1), (\"Lemma('clear.s.09.clear')\", 1), (\"Lemma('clear.s.08.clear')\", 1), (\"Lemma('clear.v.05.clear')\", 1)])\n",
      "collecting tokens for  fit\n",
      "indices:    {22144, 2688, 28800, 2694, 30984, 30985, 15243, 16395, 9995, 13, 16401, 17433, 27548, 1952, 36897, 1954, 31012, 29476, 37158, 29608, 28843, 13357, 13358, 9008, 36276, 12597, 12598, 2357, 1338, 17341, 29890, 11075, 15431, 16206, 14543, 35793, 31060, 23805, 27866, 987, 29659, 23517, 2147, 2669, 15088, 7408, 19827, 6901, 24061, 31999}\n",
      "dict_items([(\"Lemma('match.v.01.fit')\", 2), (\"Lemma('fit.n.01.fit')\", 3), (\"Lemma('meet.v.05.fit')\", 3), (\"Lemma('fit.v.04.fit')\", 4), (\"Lemma('suit.v.01.fit')\", 7), (\"Lemma('fit.s.02.fit')\", 3), (\"Lemma('fit.v.02.fit')\", 6), (\"Lemma('fit.a.03.fit')\", 3), (\"Lemma('fit.v.07.fit')\", 1), (\"Lemma('paroxysm.n.01.fit')\", 2), (\"Lemma('fit.a.01.fit')\", 3)])\n",
      "collecting tokens for  bridge\n",
      "indices:    {31547, 11395, 29925, 29965, 5485, 2008, 29979}\n",
      "dict_items([(\"Lemma('bridge.n.03.bridge')\", 1), (\"Lemma('bridge.n.02.bridge')\", 1)])\n",
      "collecting tokens for  survived\n",
      "indices:    {31521, 27526, 12905, 1772, 34350, 29966, 34679, 8862}\n",
      "dict_items([(\"Lemma('survive.v.01.survive')\", 4), (\"Lemma('survive.v.02.survive')\", 2), (\"Lemma('exist.v.02.survive')\", 2)])\n",
      "collecting tokens for  natural\n",
      "indices:    {3456, 30475, 16895, 5648, 5265, 25105, 1819, 25501, 27685, 8235, 32051, 697, 27834, 4672, 2630, 21705, 11979, 14416, 29267, 24039, 1513, 5235, 27252, 31223, 18297, 3455}\n",
      "dict_items([(\"Lemma('natural.a.01.natural')\", 5), (\"Lemma('natural.a.02.natural')\", 4), (\"Lemma('natural.a.03.natural')\", 2), (\"Lemma('natural.s.04.natural')\", 1)])\n",
      "collecting tokens for  hazards\n",
      "indices:    {27090}\n",
      "dict_items([])\n",
      "collecting tokens for  injuries\n",
      "indices:    {21632, 32706, 14755, 452, 585, 1998, 29966, 29013, 1941, 24952, 4923}\n",
      "dict_items([(\"Lemma('injury.n.02.injury')\", 2), (\"Lemma('injury.n.01.injury')\", 4)])\n",
      "collecting tokens for  golf\n",
      "indices:    {8698}\n",
      "dict_items([])\n",
      "collecting tokens for  champions\n",
      "indices:    {609, 31970, 516, 586, 31658, 336, 22965, 1564, 222}\n",
      "dict_items([(\"Lemma('champion.n.01.champion')\", 6), (\"Lemma('champion.v.01.champion')\", 1)])\n",
      "collecting tokens for  academic\n",
      "indices:    {23174, 30215, 2188, 30221, 23181, 23183, 23827, 20136, 11434, 22705, 2099, 2100, 2101, 2102, 22711, 22714, 22716, 2111, 15682, 2118, 22727, 13261, 11470, 22735, 13268, 11476, 13275, 13277, 11235, 13284, 33130, 13292, 26093, 15724, 13294, 13808, 33138, 13170, 28411}\n",
      "dict_items([(\"Lemma('academic.a.01.academic')\", 18), (\"Lemma('academic.s.03.academic')\", 1), (\"Lemma('academic.s.02.academic')\", 2)])\n",
      "collecting tokens for  solve\n",
      "indices:    {14240, 28323, 32964, 24644, 32395, 14348, 173, 338, 25139, 11636, 30485, 24981, 26808, 30011, 2111, 14174, 25279}\n",
      "dict_items([(\"Lemma('solve.v.01.solve')\", 17)])\n",
      "collecting tokens for  abuse\n",
      "indices:    {24096, 37120, 20165, 25927, 32300, 37137, 25940, 26550, 27031, 30970}\n",
      "dict_items([(\"Lemma('mistreat.v.01.abuse')\", 1), (\"Lemma('pervert.v.03.abuse')\", 1)])\n",
      "collecting tokens for  confidence\n",
      "indices:    {32899, 20483, 28040, 14348, 27279, 9619, 12828, 25138, 26175, 23625, 17358, 31699, 17366, 23771, 8285, 99, 17513, 25972, 22773, 629, 30968, 27133}\n",
      "dict_items([(\"Lemma('assurance.n.01.confidence')\", 3), (\"Lemma('confidence.n.02.confidence')\", 3), (\"Lemma('confidence.n.03.confidence')\", 1)])\n",
      "collecting tokens for  familiar\n",
      "indices:    {7936, 35970, 25347, 31492, 12548, 2183, 10634, 26379, 17037, 15758, 11408, 28561, 29072, 14073, 10649, 34331, 18971, 23840, 30754, 14115, 6393, 13609, 14634, 10670, 28336, 24752, 16435, 28087, 16056, 1211, 26939, 16833, 8388, 26437, 2126, 22737, 13139, 11348, 6247, 11112, 27882, 15723, 4333, 26870, 9337}\n",
      "dict_items([(\"Lemma('familiar.a.01.familiar')\", 21), (\"Lemma('conversant.s.01.familiar')\", 1), (\"Lemma('familiar.a.02.familiar')\", 1)])\n",
      "collecting tokens for  odor\n",
      "indices:    {31490, 16643, 31492, 35588, 13574, 33485, 31503, 5586, 16955, 27453}\n",
      "dict_items([(\"Lemma('olfactory_property.n.01.odor')\", 3), (\"Lemma('smell.n.01.odor')\", 1)])\n",
      "collecting tokens for  aborigines\n",
      "indices:    {31490, 31492, 31434, 31435, 12459, 31498, 31378, 31453}\n",
      "dict_items([(\"Lemma('native.n.01.aborigine')\", 1)])\n",
      "collecting tokens for  pathet\n",
      "indices:    {20284}\n",
      "dict_items([])\n",
      "collecting tokens for  lao\n",
      "indices:    {20284}\n",
      "dict_items([])\n",
      "collecting tokens for  stiffened\n",
      "indices:    {7553, 8129, 18404, 17662, 16721, 36922, 13054, 6975}\n",
      "dict_items([(\"Lemma('stiffen.v.01.stiffen')\", 7), (\"Lemma('stiffen.v.02.stiffen')\", 1)])\n",
      "collecting tokens for  veterans\n",
      "indices:    {24964, 24965, 6477, 24950, 24952, 1178, 6397}\n",
      "dict_items([(\"Lemma('veteran.n.02.veteran')\", 1), (\"Lemma('veteran.n.03.veteran')\", 1)])\n",
      "collecting tokens for  neighboring\n",
      "indices:    {23649, 24900, 2532, 3078, 11782, 4936, 20253, 27979, 27949, 30414, 27567, 24014, 24913, 14452, 27958, 22843, 30077, 13054}\n",
      "dict_items([])\n",
      "collecting tokens for  supplied\n",
      "indices:    {21248, 16652, 23826, 23442, 30237, 26280, 17836, 27316, 5439, 12355, 15942, 32459, 12128, 27243, 2797, 32751, 15220, 31350, 13054}\n",
      "dict_items([(\"Lemma('supply.v.01.supply')\", 15), (\"Lemma('issue.v.02.supply')\", 1), (\"Lemma('provide.v.02.supply')\", 1), (\"Lemma('add.v.02.supply')\", 1)])\n",
      "collecting tokens for  piece\n",
      "indices:    {29185, 7170, 18948, 24069, 29712, 1557, 29729, 29730, 26660, 29732, 29734, 29735, 21560, 22074, 29754, 8253, 26186, 1104, 9299, 3668, 28758, 2647, 28761, 28764, 29802, 28783, 15995, 22141, 28812, 6798, 24211, 28823, 28829, 28833, 28844, 17069, 17068, 1721, 6841, 29881, 29907, 29909, 6873, 7385, 6875, 6880, 25318, 32487, 25326, 11505, 26354, 25331, 5364, 6901, 29943, 5385, 14091, 26385, 29974, 7459, 5412, 25896, 11049, 11051, 1835, 14126, 25906, 11067, 11070, 22847, 27966, 17735, 4938, 14675, 852, 19284, 24920, 5986, 26469, 5991, 14697, 12140, 29551, 29559, 29566, 2953, 18830, 29588, 26005, 29589, 29591, 29598, 29599, 29602, 7592, 11189, 14785, 27597, 7633, 29655, 27607, 30690, 18407, 22504, 26091, 18943}\n",
      "dict_items([(\"Lemma('piece.n.01.piece')\", 11), (\"Lemma('part.n.03.piece')\", 5), (\"Lemma('piece.n.02.piece')\", 10), (\"Lemma('musical_composition.n.01.piece')\", 7), (\"Lemma('objet_d'art.n.01.piece')\", 1), (\"Lemma('patch.v.01.piece')\", 1), (\"Lemma('piece.n.05.piece')\", 3), (\"Lemma('piece.n.06.piece')\", 2), (\"Lemma('piece.n.09.piece')\", 1), (\"Lemma('piece.n.08.piece')\", 1)])\n",
      "collecting tokens for  plaster\n",
      "indices:    {8929, 11044, 29606, 9575, 11051, 29627, 31071}\n",
      "dict_items([(\"Lemma('plaster_of_paris.n.01.plaster')\", 1), (\"Lemma('plaster.n.01.plaster')\", 1)])\n",
      "collecting tokens for  bat\n",
      "indices:    {230, 24488, 19881, 19884, 656, 26130, 35347, 19828, 405, 22995, 29559, 440, 19865, 18557}\n",
      "dict_items([(\"Lemma('bat.v.01.bat')\", 5), (\"Lemma('bat.n.02.bat')\", 1)])\n",
      "collecting tokens for  thank\n",
      "indices:    {32689, 36306}\n",
      "dict_items([(\"Lemma('thank.v.01.thank')\", 2)])\n",
      "collecting tokens for  column\n",
      "indices:    {1378, 29382, 4198, 3505, 2872, 11859, 3540, 16179, 20919, 25944, 29881, 21946, 3550}\n",
      "dict_items([(\"Lemma('column.n.04.column')\", 1), (\"Lemma('column.n.02.column')\", 3), (\"Lemma('column.n.03.column')\", 1), (\"Lemma('column.n.05.column')\", 1), (\"Lemma('column.n.01.column')\", 1)])\n",
      "collecting tokens for  blocks\n",
      "indices:    {35715, 9229, 2959, 2961, 2962, 2966, 29336, 2973, 29731, 37029, 12456, 10542, 33466, 29377, 35779, 858, 15073, 15075, 29796, 15079, 15080, 15082, 15083, 15087, 15088, 15089, 15091, 15095, 15100}\n",
      "dict_items([(\"Lemma('block.n.01.block')\", 17), (\"Lemma('block.n.03.block')\", 1), (\"Lemma('block.n.04.block')\", 1), (\"Lemma('block.n.02.block')\", 1)])\n",
      "collecting tokens for  meant\n",
      "indices:    {27264, 17792, 36224, 24835, 24583, 19464, 34826, 4875, 34443, 5900, 4877, 31115, 37008, 17553, 34706, 29202, 31122, 34325, 662, 6806, 17689, 34841, 32411, 34461, 19615, 35235, 31140, 6567, 25384, 25898, 35114, 28714, 27314, 31541, 19511, 17980, 33724, 23230, 28094, 9536, 7361, 33473, 1220, 10438, 8647, 4940, 23245, 13644, 10319, 15828, 28119, 19288, 19292, 34782, 13024, 30560, 10342, 4858, 10346, 36459, 14698, 35309, 35692, 36464, 4849, 10352, 10740, 4855, 17914, 33279}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('entail.v.01.mean')\", 11), (\"Lemma('intend.v.01.mean')\", 16), (\"Lemma('mean.v.01.mean')\", 26), (\"Lemma('mean.v.05.mean')\", 4), (\"Lemma('mean.v.03.mean')\", 7)])\n",
      "collecting tokens for  exclusive\n",
      "indices:    {17127, 20940, 34092, 1360, 20433, 11283, 36125, 15261, 3166}\n",
      "dict_items([(\"Lemma('exclusive.s.01.exclusive')\", 4)])\n",
      "collecting tokens for  sensed\n",
      "indices:    {5858, 17923, 5860, 4965, 35644, 6567, 36044, 35960, 33178, 36956, 9853, 9951}\n",
      "dict_items([(\"Lemma('feel.v.03.sense')\", 12)])\n",
      "collecting tokens for  educated\n",
      "indices:    {2498, 6567, 1228, 23566, 29934, 25272, 30833, 23570, 25684, 2100, 36984, 27865, 6141}\n",
      "dict_items([(\"Lemma('educated.a.01.educated')\", 5), (\"Lemma('train.v.01.educate')\", 1), (\"Lemma('educate.v.03.educate')\", 1), (\"Lemma('educate.v.01.educate')\", 4)])\n",
      "collecting tokens for  cuts\n",
      "indices:    {21633, 23175, 2441, 24209, 12448, 21153, 6567, 6568, 21165, 4538, 29766, 11846, 29898, 2266, 31199, 29417, 21486, 29565, 8318}\n",
      "dict_items([(\"Lemma('cut.v.01.cut')\", 2), (\"Lemma('reduce.v.01.cut')\", 1)])\n",
      "collecting tokens for  folks\n",
      "indices:    {13734, 6567, 19494, 36457, 19211, 334, 113, 36273, 30710, 36279}\n",
      "dict_items([(\"Lemma('folk.n.01.folk')\", 3), (\"Lemma('family.n.04.folk')\", 1)])\n",
      "collecting tokens for  rough\n",
      "indices:    {15745, 13060, 18696, 20618, 18699, 9627, 29854, 12451, 28835, 17961, 7593, 3116, 11312, 32311, 7612, 4925, 29898, 29775, 29776, 30159, 2131, 8670, 12640, 5856, 3690, 13419, 18675, 3446}\n",
      "dict_items([(\"Lemma('rough.a.01.rough')\", 13), (\"Lemma('rough.s.02.rough')\", 2), (\"Lemma('pugnacious.s.02.rough')\", 1), (\"Lemma('boisterous.s.03.rough')\", 1), (\"Lemma('approximate.s.01.rough')\", 2), (\"Lemma('grating.s.01.rough')\", 1)])\n",
      "collecting tokens for  correlation\n",
      "indices:    {3690, 3692, 3757, 3918, 3282, 2101, 16182, 5527, 3707, 15677, 32734}\n",
      "dict_items([(\"Lemma('correlation_coefficient.n.01.correlation')\", 2), (\"Lemma('correlation.n.01.correlation')\", 8)])\n",
      "collecting tokens for  initial\n",
      "indices:    {26113, 5025, 14245, 33222, 24744, 22601, 3786, 15531, 5323, 25836, 4022, 31902, 24030}\n",
      "dict_items([(\"Lemma('initial.s.01.initial')\", 6)])\n",
      "collecting tokens for  lengths\n",
      "indices:    {29440, 1576, 3690, 2796, 13357, 2829, 2798, 2831, 2860, 29019, 2833, 2804, 3730, 28823, 2842, 35611, 28797, 2815}\n",
      "dict_items([(\"Lemma('length.n.01.length')\", 4)])\n",
      "collecting tokens for  starting\n",
      "indices:    {1970, 3538, 28915, 23704, 25727}\n",
      "dict_items([(\"Lemma('get_down.v.07.start')\", 3), (\"Lemma('begin.v.02.start')\", 1)])\n",
      "collecting tokens for  smallest\n",
      "indices:    {33795, 3684, 3368, 3690, 22474, 3692, 9325, 23502, 3348, 3703, 5145, 27966}\n",
      "dict_items([])\n",
      "collecting tokens for  ending\n",
      "indices:    {5004, 30226, 32534, 10656, 34210, 13862, 23591, 15547, 15548, 25299, 2521, 24026, 24029, 24030, 32606, 15968, 22754, 23397, 3690, 618, 23406, 23409, 21756}\n",
      "dict_items([(\"Lemma('end.v.01.end')\", 13), (\"Lemma('end.v.03.end')\", 3), (\"Lemma('end.v.02.end')\", 4), (\"Lemma('termination.n.05.ending')\", 1)])\n",
      "collecting tokens for  largest\n",
      "indices:    {24201, 26377, 3724, 3726, 1680, 21907, 6171, 2077, 12319, 22950, 32551, 35497, 24109, 46, 32431, 31795, 23358, 2878, 25541, 20421, 21321, 12362, 23502, 21966, 3935, 10850, 3690, 106, 24813, 13295, 21495, 26740, 15220, 6390, 12918, 26741, 12917, 3701, 16253, 35839}\n",
      "dict_items([(\"Lemma('large.a.01.large')\", 3)])\n",
      "collecting tokens for  anaconda\n",
      "indices:    {3749, 23211, 3692, 3693, 3726, 3697, 3706, 3739, 3743}\n",
      "dict_items([(\"Lemma('anaconda.n.01.anaconda')\", 8)])\n",
      "collecting tokens for  appears\n",
      "indices:    {24449, 23683, 23428, 2693, 13446, 15364, 3082, 4748, 4749, 3089, 3986, 32918, 3865, 25242, 20635, 12955, 2329, 13978, 11295, 3235, 3236, 20525, 2487, 2624, 3777, 13894, 4425, 25034, 32333, 27725, 4433, 852, 27861, 32982, 5207, 3032, 1630, 3806, 14946, 3939, 31843, 33254, 14183, 13162, 3947, 2667, 14704, 29936, 24434, 883, 25971, 13428, 3699, 5239, 12026, 30462}\n",
      "dict_items([(\"Lemma('appear.v.02.appear')\", 11), (\"Lemma('look.v.02.appear')\", 26), (\"Lemma('appear.v.03.appear')\", 4), (\"Lemma('appear.v.04.appear')\", 5), (\"Lemma('appear.v.05.appear')\", 1)])\n",
      "collecting tokens for  countless\n",
      "indices:    {17599, 23649, 359, 22096, 912, 496, 24051, 2165, 36120, 31423}\n",
      "dict_items([(\"Lemma('countless.s.01.countless')\", 5)])\n",
      "collecting tokens for  died\n",
      "indices:    {21509, 21514, 5899, 6926, 27158, 17303, 31128, 16665, 8860, 24993, 17314, 31395, 30843, 21548, 8236, 7214, 13871, 33326, 33324, 34226, 21555, 14518, 23864, 31422, 31423, 31424, 13505, 26050, 35905, 19780, 27076, 11465, 15562, 1487, 7120, 36305, 6996, 6997, 18261, 21463, 7770, 4059, 9947, 21468, 10715, 25697, 21473, 2275, 865, 30950, 2279, 4968, 36200, 34668, 26606, 21359, 10225, 21361, 21362, 10230, 9207, 16635, 30845}\n",
      "dict_items([(\"Lemma('die.v.01.die')\", 26)])\n",
      "collecting tokens for  palace\n",
      "indices:    {29395, 26871}\n",
      "dict_items([])\n",
      "collecting tokens for  continue\n",
      "indices:    {32000, 32001, 11652, 26758, 4616, 32397, 28559, 16, 11664, 2068, 1301, 23574, 25238, 3862, 22809, 26137, 16925, 13984, 20257, 1314, 31523, 804, 31782, 11175, 5416, 25384, 2475, 22317, 15150, 1325, 32688, 2609, 1329, 21427, 23288, 15541, 32689, 27319, 16060, 11708, 446, 576, 11074, 13763, 21059, 27331, 26307, 963, 23627, 26957, 32081, 2515, 16211, 1493, 14933, 5462, 24918, 33370, 32480, 7910, 11626, 1392, 24560, 30196, 32501, 19444, 21879, 29557, 32502, 7290, 25077}\n",
      "dict_items([(\"Lemma('continue.v.03.continue')\", 5), (\"Lemma('continue.v.01.continue')\", 26), (\"Lemma('continue.v.02.continue')\", 9), (\"Lemma('proceed.v.02.continue')\", 1)])\n",
      "collecting tokens for  growth\n",
      "indices:    {21937, 24057, 3911}\n",
      "dict_items([(\"Lemma('growth.n.01.growth')\", 1)])\n",
      "collecting tokens for  conscience\n",
      "indices:    {14592, 27265, 14594, 23203, 12330, 27275, 5264, 8018, 26707, 14516, 27320, 25437, 14590}\n",
      "dict_items([(\"Lemma('conscience.n.02.conscience')\", 3), (\"Lemma('conscience.n.01.conscience')\", 4)])\n",
      "collecting tokens for  strategic\n",
      "indices:    {23362}\n",
      "dict_items([])\n",
      "collecting tokens for  cdc\n",
      "indices:    {24598}\n",
      "dict_items([])\n",
      "collecting tokens for  games\n",
      "indices:    {11908, 1927, 13581, 398, 275, 31384, 288, 289, 34613, 1078, 444, 334, 22995, 23008, 23009, 23014, 23015, 751, 252, 9599}\n",
      "dict_items([(\"Lemma('game.n.01.game')\", 4), (\"Lemma('game.n.03.game')\", 3), (\"Lemma('game.n.02.game')\", 2)])\n",
      "collecting tokens for  1927\n",
      "indices:    {23005, 26497, 31621, 30535, 680, 23000, 30539, 30512, 30513, 14517, 11191, 12344, 23001, 23003, 30557, 23007}\n",
      "dict_items([])\n",
      "collecting tokens for  ruth\n",
      "indices:    {22252}\n",
      "dict_items([])\n",
      "collecting tokens for  35\n",
      "indices:    {23303, 24723, 3740, 26399, 28960, 21415, 27175, 29105, 18869, 11194, 28991, 29124, 33094, 20166, 22476, 29008, 32336, 29009, 29012, 32469, 29015, 23007, 20838, 2408, 3560, 29040, 27511, 20474}\n",
      "dict_items([])\n",
      "collecting tokens for  purpose\n",
      "indices:    {14602, 10523, 29983, 3871, 22820, 12970, 26415, 24369, 2744, 3393, 15055, 10453, 32479, 24690, 756, 11256, 12283, 11260, 8703}\n",
      "dict_items([(\"Lemma('purpose.n.01.purpose')\", 7), (\"Lemma('function.n.02.purpose')\", 6)])\n",
      "collecting tokens for  governments\n",
      "indices:    {32162}\n",
      "dict_items([])\n",
      "collecting tokens for  authority\n",
      "indices:    {20728, 24164, 24148}\n",
      "dict_items([])\n",
      "collecting tokens for  taxes\n",
      "indices:    {24899, 32529, 32563, 32374, 15576, 15582}\n",
      "dict_items([(\"Lemma('tax.n.01.tax')\", 1)])\n",
      "collecting tokens for  sue\n",
      "indices:    {1156}\n",
      "dict_items([])\n",
      "collecting tokens for  exercise\n",
      "indices:    {23811, 14596, 1543, 13191, 22793, 1548, 32526, 1551, 1552, 1553, 1559, 1560, 11802, 16417, 30500, 1575, 1577, 31532, 1583, 1584, 1589, 14265, 1594, 1597, 1982, 36543, 27208, 12104, 34383, 5351, 5739, 27758, 25841, 25842, 28148, 5623, 27900, 1534}\n",
      "dict_items([(\"Lemma('exercise.n.01.exercise')\", 17), (\"Lemma('practice.v.01.exercise')\", 4), (\"Lemma('exert.v.01.exercise')\", 6), (\"Lemma('exercise.v.03.exercise')\", 1), (\"Lemma('exercise.n.03.exercise')\", 1), (\"Lemma('use.n.01.exercise')\", 2), (\"Lemma('exercise.v.04.exercise')\", 1)])\n",
      "collecting tokens for  normal\n",
      "indices:    {10880, 4240, 6547, 6548, 7318, 30999, 2972, 15657, 3758, 1716, 3511, 4921, 33210, 4929, 33221, 4041, 3811, 28137, 33260, 3054, 4085}\n",
      "dict_items([(\"Lemma('normal.a.01.normal')\", 15)])\n",
      "collecting tokens for  corporate\n",
      "indices:    {21440, 15266, 14211, 16426, 9994, 14221, 32526, 14196, 22039, 22777}\n",
      "dict_items([(\"Lemma('corporate.a.01.corporate')\", 4), (\"Lemma('bodied.s.02.corporate')\", 2)])\n",
      "collecting tokens for  powers\n",
      "indices:    {27137, 34339, 24164, 31717, 23752, 24170, 9994, 15722, 11117, 28142, 32015, 24018, 9362, 35799, 23676, 28157}\n",
      "dict_items([(\"Lemma('ability.n.02.power')\", 2), (\"Lemma('power.n.05.power')\", 1), (\"Lemma('exponent.n.03.power')\", 1)])\n",
      "collecting tokens for  couple\n",
      "indices:    {10656, 17793, 11938, 25950, 14444, 10701, 9455, 26419, 34964, 17432, 444, 12061, 10654}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('couple.n.02.couple')\", 3), (\"Lemma('couple.n.01.couple')\", 2), (\"Lemma('couple.n.04.couple')\", 1)])\n",
      "collecting tokens for  males\n",
      "indices:    {3653, 3625, 20715, 3628, 33005, 13167, 3633, 33179, 3705, 33018, 32923, 33020, 33181, 1214}\n",
      "dict_items([(\"Lemma('male.n.02.male')\", 3), (\"Lemma('male.n.01.male')\", 4)])\n",
      "collecting tokens for  comedy\n",
      "indices:    {10752, 10690, 37090, 25638, 26572, 10832, 5205, 1173, 10805, 1213, 10749}\n",
      "dict_items([(\"Lemma('comedy.n.01.comedy')\", 5), (\"Lemma('drollery.n.01.comedy')\", 2)])\n",
      "collecting tokens for  jim\n",
      "indices:    {22995}\n",
      "dict_items([])\n",
      "collecting tokens for  frank\n",
      "indices:    {12676}\n",
      "dict_items([(\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  places\n",
      "indices:    {9984, 26881, 2050, 27012, 2693, 7943, 17800, 33032, 34189, 142, 3599, 17659, 27923, 11923, 147, 1942, 34681, 8858, 36379, 29212, 34976, 23458, 31524, 13221, 29481, 31532, 8367, 1585, 29362, 6963, 28855, 29242, 26939, 25021, 13249, 35010, 35910, 6477, 10701, 10449, 18514, 4691, 29267, 1878, 28888, 3674, 8923, 29276, 3677, 9310, 11873, 26466, 26467, 10468, 22115, 9081, 2021, 6118, 24042, 27883, 15212, 27117, 24053, 32630, 11897, 33787, 19324, 13566, 36479}\n",
      "dict_items([(\"Lemma('place.n.04.place')\", 6), (\"Lemma('topographic_point.n.01.place')\", 14), (\"Lemma('seat.n.01.place')\", 1), (\"Lemma('place.n.02.place')\", 6), (\"Lemma('put.v.01.place')\", 4), (\"Lemma('place.v.05.place')\", 1), (\"Lemma('target.v.01.place')\", 1), (\"Lemma('position.n.01.place')\", 1), (\"Lemma('rate.v.01.place')\", 1), (\"Lemma('position.n.06.place')\", 1)])\n",
      "collecting tokens for  shoot\n",
      "indices:    {2438, 12552, 34962, 26388, 5911, 12593, 27955, 29247, 18240, 2495, 976, 11897, 26834, 6487, 11868, 11873, 35554, 12641, 5092, 29286, 29287, 18808, 12665}\n",
      "dict_items([(\"Lemma('shoot.v.02.shoot')\", 7), (\"Lemma('film.v.01.shoot')\", 4), (\"Lemma('blast.v.07.shoot')\", 5), (\"Lemma('dart.v.02.shoot')\", 1), (\"Lemma('shoot.v.01.shoot')\", 1), (\"Lemma('photograph.v.01.shoot')\", 1)])\n",
      "collecting tokens for  encourage\n",
      "indices:    {33121, 11802, 16238, 4599}\n",
      "dict_items([(\"Lemma('promote.v.01.encourage')\", 3), (\"Lemma('encourage.v.02.encourage')\", 1)])\n",
      "collecting tokens for  managed\n",
      "indices:    {12128, 11873, 26306, 21732, 1190, 9383, 30027, 12812, 25208, 18444, 23791, 34064, 30417, 26513, 35347, 16922, 7320, 37050}\n",
      "dict_items([(\"Lemma('pull_off.v.03.manage')\", 12), (\"Lemma('cope.v.01.manage')\", 2), (\"Lemma('wangle.v.01.manage')\", 1), (\"Lemma('oversee.v.01.manage')\", 2)])\n",
      "collecting tokens for  shooting\n",
      "indices:    {11881, 29073, 18811, 12572}\n",
      "dict_items([(\"Lemma('blast.v.07.shoot')\", 2), (\"Lemma('shooting.n.01.shooting')\", 1)])\n",
      "collecting tokens for  preserves\n",
      "indices:    {11873, 32996, 24037, 11902, 26923, 13558, 11870, 11871}\n",
      "dict_items([(\"Lemma('continue.v.03.preserve')\", 1), (\"Lemma('conserve.v.02.preserve')\", 2)])\n",
      "collecting tokens for  imagine\n",
      "indices:    {10937, 36314, 27946}\n",
      "dict_items([(\"Lemma('imagine.v.01.imagine')\", 3)])\n",
      "collecting tokens for  classical\n",
      "indices:    {26721, 20546, 23651, 3459, 24742, 34734, 22385, 13618, 28117, 13622, 11191, 26360, 22073}\n",
      "dict_items([(\"Lemma('classical.a.01.classical')\", 2), (\"Lemma('authoritative.s.02.classical')\", 1)])\n",
      "collecting tokens for  initially\n",
      "indices:    {13675, 5565}\n",
      "dict_items([(\"Lemma('initially.r.01.initially')\", 2)])\n",
      "collecting tokens for  distinct\n",
      "indices:    {9357, 1296, 4370, 4117, 2970, 15905, 15906, 25399, 4281, 14267, 32957, 1086, 1088, 4292, 10695, 4297, 4305, 850, 17747, 2777, 13659, 13411, 33003, 13676, 15858, 32244, 4980, 16379, 32509}\n",
      "dict_items([(\"Lemma('distinct.s.01.distinct')\", 13), (\"Lemma('distinct.a.02.distinct')\", 10), (\"Lemma('discrete.s.01.distinct')\", 1)])\n",
      "collecting tokens for  objects\n",
      "indices:    {4960, 2144, 7520, 4935, 31882, 812, 25852, 3190, 24567, 14615, 17308, 31485}\n",
      "dict_items([(\"Lemma('object.n.01.object')\", 8)])\n",
      "collecting tokens for  located\n",
      "indices:    {31488, 16259, 13321, 5513, 11793, 3091, 32423, 5418, 12460, 30125, 16316, 33474, 21828, 27207, 32330, 714, 28748, 2770, 32473, 22492, 14957, 20602}\n",
      "dict_items([(\"Lemma('located.s.01.located')\", 8), (\"Lemma('locate.v.01.locate')\", 2), (\"Lemma('situate.v.01.locate')\", 2), (\"Lemma('locate.v.03.locate')\", 1), (\"Lemma('settle.v.04.locate')\", 2)])\n",
      "collecting tokens for  movements\n",
      "indices:    {35971, 28035, 31899, 9388, 31924, 31927, 31933, 9791, 4936, 4940, 4948, 30804, 11478, 26458, 26077, 31332, 26980, 14702, 12783, 26487}\n",
      "dict_items([(\"Lemma('movement.n.03.movement')\", 4), (\"Lemma('motion.n.03.movement')\", 2), (\"Lemma('campaign.n.02.movement')\", 2)])\n",
      "collecting tokens for  changes\n",
      "indices:    {20484, 11654, 20233, 4115, 5524, 33046, 4249, 20764, 4278, 4279, 31805, 31176, 15055, 3538, 26197, 11862, 3039, 20328, 31850, 4463, 24175, 22258, 33020}\n",
      "dict_items([(\"Lemma('change.n.01.change')\", 4), (\"Lemma('change.n.04.change')\", 1), (\"Lemma('change.n.06.change')\", 1), (\"Lemma('change.n.02.change')\", 4)])\n",
      "collecting tokens for  funeral\n",
      "indices:    {21369, 25214, 21566}\n",
      "dict_items([])\n",
      "collecting tokens for  chain\n",
      "indices:    {20259, 29890, 29955, 15906}\n",
      "dict_items([(\"Lemma('chain.n.01.chain')\", 1)])\n",
      "collecting tokens for  griffith\n",
      "indices:    {17512}\n",
      "dict_items([(\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  vote\n",
      "indices:    {20224, 23297, 2567, 135, 5129, 21641, 24844, 20365, 20366, 20367, 20368, 25621, 150, 23831, 20377, 2077, 15261, 20643, 15269, 23209, 32426, 44, 20525, 23726, 15277, 23729, 21554, 20529, 15797, 15798, 63, 65, 23874, 67, 23365, 20806, 20167, 4810, 4811, 23756, 22861, 25554, 17366, 4823, 24823, 24162, 4452, 25188, 25191, 23912, 24169, 23914, 22887, 5484, 24813, 20460, 25069, 24817, 24178, 22899, 24820, 24819, 20599, 20600, 37118}\n",
      "dict_items([(\"Lemma('vote.n.01.vote')\", 7), (\"Lemma('vote.v.02.vote')\", 7), (\"Lemma('vote.v.01.vote')\", 9), (\"Lemma('right_to_vote.n.01.vote')\", 1), (\"Lemma('vote.n.02.vote')\", 2)])\n",
      "collecting tokens for  decided\n",
      "indices:    {34307, 34310, 14854, 22535, 12811, 20492, 1531, 23584, 22562, 24120, 33340, 24645, 8262, 17484, 31309, 598, 32354, 20579, 14439, 17000, 9840, 18548, 30330, 12412, 134, 33929, 34442, 22666, 24724, 26262, 8345, 37019, 15516, 27808, 678, 11439, 7868, 12480, 4800, 2261, 23254, 8921, 12507, 23260, 22749, 13076, 13078, 23832, 21281, 6948, 33573, 27944, 22828, 25392, 818, 32056, 23362, 34116, 20806, 22856, 26955, 8531, 22867, 22869, 33110, 30554, 22365, 5989, 5996, 880, 35703, 34177, 20871, 30090, 21396, 34196, 4009, 34731, 5048, 20422, 15305, 21452, 5070, 5598, 17398, 25081, 5115, 20477}\n",
      "dict_items([(\"Lemma('decide.v.01.decide')\", 26), (\"Lemma('decide.v.03.decide')\", 4), (\"Lemma('decide.v.02.decide')\", 1)])\n",
      "collecting tokens for  voters\n",
      "indices:    {3, 139, 23597}\n",
      "dict_items([(\"Lemma('voter.n.01.voter')\", 2)])\n",
      "collecting tokens for  prefer\n",
      "indices:    {32257, 16257, 134, 7578, 3614, 13728, 22268, 3752, 11312, 20806, 30794, 11219, 11232, 31976, 6891, 17263, 2552, 4601, 15740}\n",
      "dict_items([(\"Lemma('choose.v.02.prefer')\", 7), (\"Lemma('prefer.v.01.prefer')\", 12)])\n",
      "collecting tokens for  junior\n",
      "indices:    {21375}\n",
      "dict_items([])\n",
      "collecting tokens for  high\n",
      "indices:    {13252, 15012, 31624, 23981, 5489, 3575, 6045, 21375}\n",
      "dict_items([(\"Lemma('high.a.01.high')\", 3), (\"Lemma('high.a.04.high')\", 1)])\n",
      "collecting tokens for  d\n",
      "indices:    {4345}\n",
      "dict_items([])\n",
      "collecting tokens for  pertinent\n",
      "indices:    {23715, 14053, 31173, 27719, 14121, 25293, 3838, 14735, 11762, 32530, 28821, 20313, 15229, 11230}\n",
      "dict_items([(\"Lemma('pertinent.s.01.pertinent')\", 5), (\"Lemma('apposite.s.01.pertinent')\", 2)])\n",
      "collecting tokens for  mission\n",
      "indices:    {13346, 32648, 8298, 1325, 13359, 8336, 35986, 22687}\n",
      "dict_items([(\"Lemma('mission.n.04.mission')\", 1), (\"Lemma('mission.n.03.mission')\", 1), (\"Lemma('mission.n.01.mission')\", 3)])\n",
      "collecting tokens for  rank\n",
      "indices:    {6913, 17635, 6916, 32931, 32035, 20483, 15400, 12553, 20227, 31727, 22705, 13812, 14036, 14038, 8501, 14037, 2075}\n",
      "dict_items([(\"Lemma('rank.n.02.rank')\", 5), (\"Lemma('rank.s.01.rank')\", 1), (\"Lemma('rank.n.01.rank')\", 2), (\"Lemma('social_station.n.01.rank')\", 1)])\n",
      "collecting tokens for  bundle\n",
      "indices:    {32802, 30562, 16612, 8709, 30214, 21079, 21092, 32809, 16945, 32823, 32822, 21078, 35417, 32825}\n",
      "dict_items([(\"Lemma('bundle.v.01.bundle')\", 1), (\"Lemma('package.n.01.bundle')\", 2), (\"Lemma('bundle.n.02.bundle')\", 1)])\n",
      "collecting tokens for  slept\n",
      "indices:    {16641, 7444, 5652, 35094, 7319, 7447, 34587, 34590, 34592, 7073, 7847, 7852, 35546, 7774, 8163, 11111, 8936, 7017, 35198}\n",
      "dict_items([(\"Lemma('sleep.v.01.sleep')\", 19)])\n",
      "collecting tokens for  stiff\n",
      "indices:    {8225, 18146, 8577, 8229, 8876, 35181, 17100, 27378, 35251, 596, 8532, 10748, 24540, 34111}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('stiff.s.01.stiff')\", 2), (\"Lemma('stiff.n.01.stiff')\", 2), (\"Lemma('starchy.s.02.stiff')\", 1), (\"Lemma('stiff.s.02.stiff')\", 1)])\n",
      "collecting tokens for  calculated\n",
      "indices:    {32768, 2954, 2957, 19862, 27927, 27942, 27943, 3368, 30630, 2989, 5551, 26816, 3009, 3018, 3276, 5581, 3030, 4954, 3301, 3561, 3311, 30583, 2941}\n",
      "dict_items([(\"Lemma('calculate.v.01.calculate')\", 16), (\"Lemma('calculate.v.02.calculate')\", 3)])\n",
      "collecting tokens for  peas\n",
      "indices:    {27941, 12486, 27943, 27945, 27946, 27948, 27949, 27950, 12533, 16694, 30424, 36990}\n",
      "dict_items([(\"Lemma('pea.n.01.pea')\", 3)])\n",
      "collecting tokens for  fill\n",
      "indices:    {35490, 29586, 30365}\n",
      "dict_items([(\"Lemma('fill.v.01.fill')\", 3)])\n",
      "collecting tokens for  household\n",
      "indices:    {27808, 36994, 5476, 26854, 27943, 17288, 1146, 36071, 3149, 3151, 3153, 23026, 21078, 10137, 21370, 26331, 13119}\n",
      "dict_items([(\"Lemma('family.n.01.household')\", 7)])\n",
      "collecting tokens for  billion\n",
      "indices:    {22016, 22017, 22018, 25477, 25481, 15498, 25484, 25486, 25487, 15516, 21918, 21920, 23843, 27943, 22063, 22064, 23987, 22067, 23990, 23361, 26818, 26819, 23366, 25038, 21968, 20181, 20183, 28506, 15477, 15483, 22015}\n",
      "dict_items([(\"Lemma('billion.s.01.billion')\", 3), (\"Lemma('billion.n.01.billion')\", 1)])\n",
      "collecting tokens for  cellar\n",
      "indices:    {21024, 21021, 20069, 29222, 27943, 20071, 20106, 17290, 17292, 20109, 16692, 20086, 30422, 20121, 30458, 13565}\n",
      "dict_items([(\"Lemma('basement.n.01.cellar')\", 9)])\n",
      "collecting tokens for  attic\n",
      "indices:    {30202, 30125, 4983}\n",
      "dict_items([(\"Lemma('attic.a.01.Attic')\", 1)])\n",
      "collecting tokens for  houses\n",
      "indices:    {10531, 8870, 27946, 13229, 5169, 23542, 18297, 5275}\n",
      "dict_items([(\"Lemma('house.n.01.house')\", 5), (\"Lemma('house.v.01.house')\", 1)])\n",
      "collecting tokens for  buildings\n",
      "indices:    {17537, 35460, 22536, 28425, 35722, 17545, 35469, 2062, 17549, 35860, 12182, 36123, 31521, 31522, 7971, 31523, 17828, 27943, 27944, 29354, 3499, 31530, 5420, 35449, 9144, 30396, 29247, 5056, 35393, 29379, 29258, 35403, 35404, 5072, 23761, 29396, 21076, 29403, 29275, 29280, 3424, 5091, 1892, 29286, 15208, 15209, 15212, 14444, 10478, 2031, 21233, 20594, 28530, 20596, 3445, 36728, 36729, 1915, 17535}\n",
      "dict_items([(\"Lemma('building.n.01.building')\", 22)])\n",
      "collecting tokens for  assign\n",
      "indices:    {14496, 1029, 1286, 14860, 27632, 20318, 4945, 4982, 32283, 16091, 32285, 3230}\n",
      "dict_items([(\"Lemma('assign.v.02.assign')\", 2), (\"Lemma('impute.v.01.assign')\", 4), (\"Lemma('delegate.v.02.assign')\", 3), (\"Lemma('assign.v.04.assign')\", 3)])\n",
      "collecting tokens for  series\n",
      "indices:    {3868}\n",
      "dict_items([(\"Lemma('series.n.01.series')\", 1)])\n",
      "collecting tokens for  dorset\n",
      "indices:    {5169}\n",
      "dict_items([(\"Lemma('location.n.01.location')\", 1)])\n",
      "collecting tokens for  exchange\n",
      "indices:    {3236, 12620, 32719, 3280, 3251, 22648}\n",
      "dict_items([(\"Lemma('exchange.n.01.exchange')\", 3), (\"Lemma('exchange.n.03.exchange')\", 1)])\n",
      "collecting tokens for  easier\n",
      "indices:    {1674, 16908, 24467, 30103, 24473, 34083, 30756, 34603, 11316, 29752, 29114, 23998, 5182, 1990, 31822, 30799, 6225, 36306, 8531, 1619, 32980, 31703, 5468, 5470, 31070, 27360, 23016, 30189, 26222, 30190, 5234, 12147, 2552, 18427, 28670}\n",
      "dict_items([(\"Lemma('easy.a.01.easy')\", 13), (\"Lemma('easy.s.02.easy')\", 1)])\n",
      "collecting tokens for  extended\n",
      "indices:    {31744, 28672, 22786, 22163, 34074, 15907, 13357, 5168, 5169, 2999, 22329, 25148, 5182, 5823, 33090, 5575, 1991, 17096, 35656, 14031, 1361, 19156, 2517, 16212, 20192, 15969, 12514, 13543, 23656, 16233, 34154, 35691, 35821, 16367, 2032, 23412, 31871}\n",
      "dict_items([(\"Lemma('drawn-out.s.01.extended')\", 4), (\"Lemma('exsert.v.01.extend')\", 3), (\"Lemma('widen.v.04.extend')\", 9), (\"Lemma('extend.v.04.extend')\", 4), (\"Lemma('extend.v.06.extend')\", 2), (\"Lemma('run.v.03.extend')\", 6), (\"Lemma('cover.v.03.extend')\", 2), (\"Lemma('stretch.v.02.extend')\", 1)])\n",
      "collecting tokens for  graduated\n",
      "indices:    {34754, 21223, 22089, 21136, 14096, 28921, 23162, 28926}\n",
      "dict_items([(\"Lemma('graduate.v.02.graduate')\", 3), (\"Lemma('graduate.v.01.graduate')\", 2)])\n",
      "collecting tokens for  attending\n",
      "indices:    {14455, 22338, 19542, 21919}\n",
      "dict_items([(\"Lemma('attend.v.01.attend')\", 4)])\n",
      "collecting tokens for  mass.\n",
      "indices:    {22509}\n",
      "dict_items([])\n",
      "collecting tokens for  concentration\n",
      "indices:    {3205, 3206, 1035, 3340, 1552, 7954, 31378, 3992, 25379, 4006, 4010, 21420, 4781, 16432, 3378, 2999, 31159, 3385, 12859, 32700, 5580, 5587, 3284, 3930, 3550, 3297, 7271, 3560, 4202, 36843, 3308, 3953, 3188, 3573, 24182, 3576, 3965}\n",
      "dict_items([(\"Lemma('concentration.n.06.concentration')\", 1), (\"Lemma('concentration.n.02.concentration')\", 4), (\"Lemma('concentration.n.01.concentration')\", 17), (\"Lemma('concentration.n.04.concentration')\", 2), (\"Lemma('concentration.n.05.concentration')\", 2), (\"Lemma('concentration.n.03.concentration')\", 3)])\n",
      "collecting tokens for  medium\n",
      "indices:    {1024, 31109, 31111, 28426, 11282, 29088, 35744, 31137, 26660, 15654, 31143, 31149, 2865, 15539, 15540, 34744, 24888, 31161, 31163, 24895, 31169, 31103, 26957, 16207, 17877, 3159, 15705, 3930, 11226, 32862, 31079, 31083, 10097, 2162, 31093, 31096, 31097, 31101, 31102, 11263}\n",
      "dict_items([(\"Lemma('average.s.04.medium')\", 5), (\"Lemma('medium.n.03.medium')\", 2), (\"Lemma('medium.n.02.medium')\", 2), (\"Lemma('medium.n.01.medium')\", 5), (\"Lemma('culture_medium.n.01.medium')\", 1)])\n",
      "collecting tokens for  absence\n",
      "indices:    {8828, 12929, 32390, 32135, 20233, 3084, 3089, 25747, 6296, 4770, 1318, 15911, 4906, 13868, 30769, 4913, 4802, 33222, 10695, 4167, 16328, 26954, 13645, 13268, 33237, 4949, 8919, 3930, 1499, 32860, 3933, 15456, 9191, 36969, 30826, 3948, 3059, 13300, 23795, 14454, 3834, 1788, 35197}\n",
      "dict_items([(\"Lemma('absence.n.01.absence')\", 23), (\"Lemma('absence.n.02.absence')\", 7)])\n",
      "collecting tokens for  eyes\n",
      "indices:    {6407, 13575, 12809, 16524, 19471, 13586, 20627, 7830, 10523, 35612, 7584, 8871, 33333, 23605, 19767, 9145, 34112, 7105, 32196, 5959, 10958, 31567, 7635, 36052, 25686, 12641, 16995, 28395, 36716, 13432, 9852, 9215}\n",
      "dict_items([(\"Lemma('eye.n.01.eye')\", 20)])\n",
      "collecting tokens for  ears\n",
      "indices:    {27014, 25738, 1164, 20883, 9625, 14489, 9369, 9633, 9380, 9389, 35503, 14004, 2356, 8245, 26947, 2005, 17241, 13402, 18905, 11232, 27746, 26341, 17646, 25722, 30589}\n",
      "dict_items([(\"Lemma('ear.n.01.ear')\", 9), (\"Lemma('auricle.n.02.ear')\", 3), (\"Lemma('ear.n.02.ear')\", 3)])\n",
      "collecting tokens for  birthday\n",
      "indices:    {11843, 20968, 14442, 7787, 9775, 6383, 9521, 11028, 22197, 32664, 22649, 762, 17371}\n",
      "dict_items([(\"Lemma('birthday.n.01.birthday')\", 8), (\"Lemma('birthday.n.02.birthday')\", 1)])\n",
      "collecting tokens for  standpoint\n",
      "indices:    {11688, 1130, 1741, 20592, 1778, 11635, 31992, 541}\n",
      "dict_items([(\"Lemma('point_of_view.n.01.standpoint')\", 6)])\n",
      "collecting tokens for  ben\n",
      "indices:    {12206}\n",
      "dict_items([])\n",
      "collecting tokens for  hogan\n",
      "indices:    {18153}\n",
      "dict_items([])\n",
      "collecting tokens for  evil\n",
      "indices:    {27782, 27783, 12295, 27786, 27787, 27788, 27793, 13074, 27795, 27796, 27794, 35990, 4889, 10779, 541, 1278, 27810, 27811, 4900, 17573, 36134, 6441, 27820, 27823, 26292, 26942, 6977, 4674, 32067, 1493, 26197, 36060, 1252, 1254, 4858, 4840, 5354, 11115, 25453, 4852, 4853, 17018, 1274, 27134}\n",
      "dict_items([(\"Lemma('evil.a.01.evil')\", 9), (\"Lemma('evil.n.03.evil')\", 3), (\"Lemma('evil.n.02.evil')\", 2), (\"Lemma('evil.s.02.evil')\", 1), (\"Lemma('evil.n.01.evil')\", 5)])\n",
      "collecting tokens for  scored\n",
      "indices:    {288, 29569, 389, 32445, 29639, 28586, 524, 15692, 15694, 29629, 29648, 18737, 29525, 570, 541}\n",
      "dict_items([(\"Lemma('score.v.03.score')\", 2), (\"Lemma('score.v.01.score')\", 8), (\"Lemma('score.v.02.score')\", 1)])\n",
      "collecting tokens for  texas\n",
      "indices:    {142}\n",
      "dict_items([(\"Lemma('texas.n.01.Texas')\", 1)])\n",
      "collecting tokens for  mutual\n",
      "indices:    {23072, 28449, 30210, 20229, 998, 10235, 12264, 12283, 23211, 32397, 21937, 27802, 12315, 26204, 11963, 27295}\n",
      "dict_items([(\"Lemma('common.s.03.mutual')\", 2)])\n",
      "collecting tokens for  sought\n",
      "indices:    {35202, 12291, 31759, 19222, 31770, 2331, 35996, 4762, 7074, 28072, 28074, 16427, 23856, 21299, 16439, 63, 27843, 27844, 1605, 27849, 27851, 7759, 36818, 12372, 17114, 5853, 32222, 7549, 22883, 13027, 5226, 497, 24436, 4853, 15350, 125}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('seek_out.v.01.seek_out')\", 1), (\"Lemma('try.v.01.seek')\", 13), (\"Lemma('seek.v.01.seek')\", 7), (\"Lemma('search.v.01.seek')\", 11), (\"Lemma('sought.a.01.sought')\", 1)])\n",
      "collecting tokens for  bear\n",
      "indices:    {1185, 30211, 27848, 17258, 26829, 1104, 14426}\n",
      "dict_items([(\"Lemma('digest.v.03.bear')\", 2), (\"Lemma('bear.v.01.bear')\", 2), (\"Lemma('hold.v.11.bear')\", 1)])\n",
      "collecting tokens for  question\n",
      "indices:    {33659, 10628, 22667, 26636, 25613, 5656, 35870, 24357, 16172, 23981, 13751, 2112, 24899, 1359, 5075, 36309, 2141, 25439, 22626, 5481, 115, 26747}\n",
      "dict_items([(\"Lemma('question.v.01.question')\", 1), (\"Lemma('question.n.02.question')\", 6), (\"Lemma('question.n.01.question')\", 3)])\n",
      "collecting tokens for  discrimination\n",
      "indices:    {27904, 14984, 28452, 2470, 169, 171, 14638, 174, 27841, 27851, 13265, 15717, 15719, 20457, 15722, 27887, 15860, 24436, 27898}\n",
      "dict_items([(\"Lemma('discrimination.n.01.discrimination')\", 6), (\"Lemma('discrimination.n.02.discrimination')\", 5)])\n",
      "collecting tokens for  housing\n",
      "indices:    {27840, 20517, 32525, 27886, 21971}\n",
      "dict_items([])\n",
      "collecting tokens for  locking\n",
      "indices:    {28814, 28817, 28820, 36122, 28829, 16670, 28832, 9381, 30759, 29874, 28722, 28724, 28725, 28726, 28727, 28729, 28730, 29885, 28743, 28768, 28770, 16613, 28773, 28787, 29555, 28791, 28795}\n",
      "dict_items([(\"Lemma('lock.v.01.lock')\", 3), (\"Lemma('engage.v.10.lock')\", 2), (\"Lemma('lock.v.03.lock')\", 1), (\"Lemma('lock_in.v.02.lock_up')\", 1)])\n",
      "collecting tokens for  gives\n",
      "indices:    {29697, 19469, 30739, 1563, 11806, 28705, 30759, 22572, 30767, 23601, 25138, 34358, 4670, 4671, 14910, 11842, 1095, 4690, 14422, 4695, 4696, 28761, 6756, 24198, 31889, 24722, 3736, 28826, 31907, 24232, 31917, 23729, 5815, 1721, 5317, 31430, 19147, 1759, 34531, 14055, 27370, 28907, 5371, 31483, 23809, 1283, 24836, 24329, 1293, 15124, 28440, 1824, 20779, 26415, 11056, 16179, 13621, 13633, 12099, 12102, 25930, 2380, 13137, 27493, 27500, 27516, 31109, 2955, 29069, 2967, 26529, 31141, 29099, 13747, 14260, 2997, 21430, 14283, 27616, 27621, 13798, 30700, 32240, 15857, 1017, 2558}\n",
      "dict_items([(\"Lemma('yield.v.01.give')\", 26), (\"Lemma('give.v.09.give')\", 3), (\"Lemma('give.v.10.give')\", 1), (\"Lemma('give.v.01.give')\", 26), (\"Lemma('give.v.03.give')\", 5), (\"Lemma('establish.v.05.give')\", 6), (\"Lemma('hold.v.03.give')\", 3), (\"Lemma('give.v.05.give')\", 1), (\"Lemma('give.v.08.give')\", 1), (\"Lemma('give.v.21.give')\", 1), (\"Lemma('give.v.04.give')\", 3), (\"Lemma('render.v.04.give')\", 2), (\"Lemma('pass.v.05.give')\", 1), (\"Lemma('give.v.14.give')\", 1)])\n",
      "collecting tokens for  privacy\n",
      "indices:    {19200, 34571, 30758}\n",
      "dict_items([(\"Lemma('privacy.n.02.privacy')\", 1)])\n",
      "collecting tokens for  location\n",
      "indices:    {15883, 15900, 32416, 32417, 28457, 32425, 32427, 5165, 2734, 30007, 36938, 32465, 5586, 5465, 11616, 5473, 28514, 11375, 12145, 2931, 1909, 32380}\n",
      "dict_items([(\"Lemma('location.n.01.location')\", 10), (\"Lemma('localization.n.01.location')\", 1), (\"Lemma('placement.n.03.location')\", 1)])\n",
      "collecting tokens for  equally\n",
      "indices:    {34438, 31719, 1066, 26124, 31727, 12624, 31699, 1430, 22875, 26077, 26398, 26111}\n",
      "dict_items([(\"Lemma('equally.r.01.equally')\", 2), (\"Lemma('evenly.r.01.equally')\", 1)])\n",
      "collecting tokens for  fulfillment\n",
      "indices:    {21441, 30759, 30824, 4809, 30827, 11985, 4595, 25367, 4664, 4670}\n",
      "dict_items([(\"Lemma('fulfillment.n.01.fulfillment')\", 3), (\"Lemma('fulfillment.n.02.fulfillment')\", 2)])\n",
      "collecting tokens for  secrets\n",
      "indices:    {21280, 7361, 21281, 21252, 21255, 21257, 21260, 21266, 31348, 35992, 21272, 21273, 23772, 21277, 21247}\n",
      "dict_items([(\"Lemma('secret.n.01.secret')\", 1)])\n",
      "collecting tokens for  handed\n",
      "indices:    {7427, 6149, 30484, 21404, 8477, 21277, 555, 37036, 36780, 21296, 33460, 9162, 21708, 8909, 1486, 26193, 5842, 20309, 27607, 35680, 35299, 19172, 35305, 26360, 22782, 35327}\n",
      "dict_items([(\"Lemma('pass.v.05.hand')\", 18)])\n",
      "collecting tokens for  ring\n",
      "indices:    {28545, 28549, 28554, 11403, 7830, 28569, 28574, 26530, 26531, 22182, 21297, 26558, 34624, 4177, 19550, 30945, 24290, 29675, 25331, 26228, 21247}\n",
      "dict_items([(\"Lemma('resound.v.01.ring')\", 1), (\"Lemma('ring.n.02.ring')\", 2), (\"Lemma('ring.v.01.ring')\", 1), (\"Lemma('hoop.n.02.ring')\", 1)])\n",
      "collecting tokens for  broken\n",
      "indices:    {35201, 29827, 23690, 36490, 13322, 3468, 22929, 8082, 16664, 17563, 21277, 28446, 29343, 20131, 28970, 7598, 19246, 30515, 35636, 25782, 6208, 9154, 35198, 5830, 10569, 14410, 29898, 5072, 32082, 9174, 13271, 25561, 36954, 24287, 29023, 15972, 15973, 34406, 23014, 12392, 30576, 10481, 9977, 2170, 6907, 4222, 36479}\n",
      "dict_items([(\"Lemma('break.v.22.break')\", 1), (\"Lemma('break_in.v.06.break')\", 1), (\"Lemma('break.v.05.break')\", 4), (\"Lemma('broken.a.01.broken')\", 12), (\"Lemma('interrupt.v.04.break')\", 4), (\"Lemma('break.v.03.break')\", 2), (\"Lemma('break.v.04.break')\", 1), (\"Lemma('broken.s.03.broken')\", 1), (\"Lemma('break_in.v.01.break')\", 1), (\"Lemma('break.v.10.break')\", 1)])\n",
      "collecting tokens for  rarely\n",
      "indices:    {26753, 12563, 31005, 1566, 12194, 32162, 31655, 2345, 26158, 12718, 30772, 26937, 26685, 8264, 14414, 9806, 11988, 27221, 4184, 26724, 18289, 15990, 32124, 15997}\n",
      "dict_items([(\"Lemma('rarely.r.01.rarely')\", 13)])\n",
      "collecting tokens for  spoke\n",
      "indices:    {24320, 12417, 24834, 36229, 35336, 18699, 20493, 10000, 28561, 31507, 5912, 31644, 18594, 36388, 8869, 35750, 27303, 20389, 25509, 34346, 20772, 17711, 25521, 20403, 13748, 27319, 8887, 30266, 17729, 13000, 30922, 30923, 35659, 8650, 24144, 34897, 19413, 9175, 30935, 5336, 33626, 27354, 19161, 5340, 10210, 10211, 34788, 7525, 5346, 10851, 10212, 23779, 36458, 10219, 8420, 10221, 19439, 37106, 33654, 13047, 15868}\n",
      "dict_items([(\"Lemma('talk.v.02.speak')\", 19), (\"Lemma('speak.v.03.speak')\", 10), (\"Lemma('talk.v.01.speak')\", 16), (\"Lemma('address.v.02.speak')\", 8), (\"Lemma('spoke.n.01.spoke')\", 1), (\"Lemma('speak_for.v.01.speak_for')\", 1)])\n",
      "collecting tokens for  ace\n",
      "indices:    {4425, 23122, 4394, 4439}\n",
      "dict_items([(\"Lemma('one.n.01.ace')\", 3)])\n",
      "collecting tokens for  widow\n",
      "indices:    {26761, 25646}\n",
      "dict_items([])\n",
      "collecting tokens for  skyros\n",
      "indices:    {16524}\n",
      "dict_items([])\n",
      "collecting tokens for  pushing\n",
      "indices:    {36667, 23108, 17339, 21990, 1543, 23812, 25413, 35245, 30546, 17655, 30104, 27067, 7900}\n",
      "dict_items([(\"Lemma('push.v.02.push')\", 1), (\"Lemma('push.n.01.pushing')\", 1), (\"Lemma('advertise.v.02.push')\", 3), (\"Lemma('push.v.01.push')\", 4), (\"Lemma('push.v.06.push')\", 1)])\n",
      "collecting tokens for  pitch\n",
      "indices:    {16104, 9787, 16087}\n",
      "dict_items([(\"Lemma('pitch.n.05.pitch')\", 1), (\"Lemma('pitch.n.01.pitch')\", 2)])\n",
      "collecting tokens for  throat\n",
      "indices:    {35847, 8716, 35214, 27284, 9110, 8609, 16675, 35107, 9126, 10793, 9389, 34095, 34746, 707, 709, 7111, 12875, 17613, 36051, 19924, 19157, 36055, 19163, 36706, 34535, 16617, 9069, 8943, 17655}\n",
      "dict_items([(\"Lemma('throat.n.01.throat')\", 16), (\"Lemma('throat.n.03.throat')\", 2), (\"Lemma('throat.n.02.throat')\", 1)])\n",
      "collecting tokens for  resolution\n",
      "indices:    {32643, 23812, 14610, 2836, 14749, 14752, 15417, 25018, 22844, 25022, 62, 64, 66, 69, 70, 72, 22889, 20331, 20332, 23282, 20342, 20343}\n",
      "dict_items([(\"Lemma('resolution.n.01.resolution')\", 7), (\"Lemma('resolving_power.n.01.resolution')\", 1), (\"Lemma('resolution.n.04.resolution')\", 1)])\n",
      "collecting tokens for  senate\n",
      "indices:    {23788}\n",
      "dict_items([])\n",
      "collecting tokens for  29\n",
      "indices:    {27010, 29323, 3735, 27036, 20893, 27037, 20768, 26784, 11936, 16167, 1965, 15152, 15154, 28216, 25659, 30270, 65, 28993, 5574, 20168, 3920, 23120, 20819, 16234, 24943, 3442, 23028, 32630, 22649, 27003, 12668}\n",
      "dict_items([(\"Lemma('twenty-nine.s.01.29')\", 6), (\"Lemma('twenty-nine.n.01.29')\", 4)])\n",
      "collecting tokens for  5\n",
      "indices:    {22532, 524, 15375, 4116, 3093, 14871, 22552, 14873, 4121, 24605, 28190, 28202, 14891, 28204, 14892, 28206, 4142, 22064, 28213, 4159, 28223, 65, 13894, 28234, 28238, 28246, 28760, 28771, 28262, 622, 29295, 21622, 28806, 21639, 653, 656, 14996, 11419, 11931, 28829, 3744, 29869, 179, 30901, 2232, 2766, 32975, 214, 3286, 15076, 20709, 2790, 2791, 2279, 20715, 240, 30964, 247, 25856, 258, 11525, 26886, 11528, 28937, 11530, 15633, 3858, 4387, 15140, 3366, 16168, 28972, 3377, 21815, 11586, 22340, 3908, 3910, 3909, 3913, 3914, 25934, 3921, 29524, 4439, 3929, 22364, 30046, 29536, 353, 358, 1385, 16235, 4460, 3438, 29039, 4464, 3442, 5500, 4479, 384, 390, 3976, 27533, 27534, 22415, 22414, 27536, 20881, 27542, 21399, 27544, 32665, 27548, 33195, 27567, 22447, 27061, 32182, 29116, 961, 22977, 962, 964, 451, 454, 11719, 32199, 453, 459, 22988, 3542, 5081, 3550, 21993, 21994, 16368, 14838, 22006, 29692}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('five.s.01.5')\", 26), (\"Lemma('five.n.01.5')\", 4)])\n",
      "collecting tokens for  trig\n",
      "indices:    {5909}\n",
      "dict_items([(\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  drew\n",
      "indices:    {6393}\n",
      "dict_items([])\n",
      "collecting tokens for  knife\n",
      "indices:    {6209, 29594, 35524, 19327}\n",
      "dict_items([(\"Lemma('knife.n.02.knife')\", 1), (\"Lemma('knife.n.01.knife')\", 1)])\n",
      "collecting tokens for  fractions\n",
      "indices:    {4163, 3550, 4198, 3559, 3562, 3276, 3564, 28910, 28909, 3579, 4190, 3519}\n",
      "dict_items([(\"Lemma('fraction.n.01.fraction')\", 10)])\n",
      "collecting tokens for  converted\n",
      "indices:    {14849, 3938, 13987, 21929, 21418, 3979, 28075, 30415, 29360, 30448, 28914, 10707, 28884, 28949, 32051, 3035, 989, 28927}\n",
      "dict_items([(\"Lemma('convert.v.03.convert')\", 2), (\"Lemma('convert.v.02.convert')\", 4), (\"Lemma('convert.v.01.convert')\", 7), (\"Lemma('change.v.06.convert')\", 3), (\"Lemma('convert.v.05.convert')\", 1)])\n",
      "collecting tokens for  becomes\n",
      "indices:    {16385, 30211, 31236, 24325, 12050, 25363, 13460, 28951, 13976, 11929, 2586, 12955, 30105, 25630, 25631, 25632, 16158, 26142, 15908, 32934, 1191, 10744, 13481, 4910, 31791, 13618, 22708, 11061, 13366, 26554, 13372, 3065, 11074, 11080, 3912, 14028, 24782, 2687, 11991, 14937, 24923, 1500, 2141, 13280, 11489, 16355, 23908, 24421, 22758, 15718, 22761, 24042, 11115, 13674, 22378, 24177, 28914, 26360, 12921, 5375}\n",
      "dict_items([(\"Lemma('become.v.01.become')\", 26), (\"Lemma('become.v.02.become')\", 26), (\"Lemma('become.v.03.become')\", 2)])\n",
      "collecting tokens for  horses\n",
      "indices:    {35329, 35587, 35588, 28678, 2695, 35334, 35209, 36230, 18184, 29199, 18194, 29205, 13591, 35352, 35611, 29212, 29979, 9630, 18594, 35238, 13608, 35503, 35249, 35379, 7732, 35251, 18356, 35386, 18363, 36670, 35396, 35146, 35148, 10446, 7630, 5072, 7632, 35541, 35287, 10457, 35807, 35296, 35811, 35300, 35557, 29037, 29038, 29040, 243, 29175, 7800, 35194, 9980, 35839}\n",
      "dict_items([(\"Lemma('horse.n.01.horse')\", 18)])\n",
      "collecting tokens for  circle\n",
      "indices:    {10912, 4481, 33474, 18786, 33986, 11433, 30026, 19566, 12368, 14480, 32114, 35539, 2353, 13271, 16410}\n",
      "dict_items([(\"Lemma('circle.n.01.circle')\", 3), (\"Lemma('lap.n.05.circle')\", 1), (\"Lemma('set.n.05.circle')\", 3), (\"Lemma('circle.v.02.circle')\", 1)])\n",
      "collecting tokens for  burning\n",
      "indices:    {8705, 27525, 27526, 28295, 10247, 7693, 31379, 7700, 2711, 21673, 2864, 28465, 2866, 2873, 2876, 2877, 29899, 2894, 2895, 7635, 19162, 9189, 13800, 19180, 1261, 7665, 9586, 7794, 19189, 35447, 18041, 35194, 30332}\n",
      "dict_items([(\"Lemma('burn.v.07.burn')\", 1), (\"Lemma('burning.n.01.burning')\", 1), (\"Lemma('burn.v.01.burn')\", 2), (\"Lemma('burn.v.03.burn')\", 6), (\"Lemma('burn.v.02.burn')\", 3), (\"Lemma('bite.v.02.burn')\", 2)])\n",
      "collecting tokens for  darkness\n",
      "indices:    {35203, 35205, 6150, 12039, 35208, 10379, 6173, 2590, 17445, 13480, 13481, 27562, 18091, 10028, 19247, 18359, 24376, 30649, 28089, 10299, 35645, 8385, 6212, 8518, 35151, 8658, 27493, 7910, 9191, 27496, 35691, 7280, 35194}\n",
      "dict_items([(\"Lemma('dark.n.01.darkness')\", 16), (\"Lemma('iniquity.n.01.darkness')\", 2), (\"Lemma('darkness.n.02.darkness')\", 1)])\n",
      "collecting tokens for  part-time\n",
      "indices:    {13242, 12162, 12103, 12168, 11752, 12138, 11783, 12109, 16317, 12112, 20307, 12086, 24825, 12122, 12090, 11773, 12127}\n",
      "dict_items([(\"Lemma('part-time.a.01.part-time')\", 15)])\n",
      "collecting tokens for  farmers\n",
      "indices:    {22000, 12162, 5861}\n",
      "dict_items([(\"Lemma('farmer.n.01.farmer')\", 2)])\n",
      "collecting tokens for  supplies\n",
      "indices:    {5948, 21206, 3783}\n",
      "dict_items([(\"Lemma('issue.v.02.supply')\", 1)])\n",
      "collecting tokens for  full-time\n",
      "indices:    {11783, 11784, 12168, 22539, 14496, 18208, 33068, 12081, 23607, 12088, 12090, 13244, 20304, 20308, 20309, 15319, 20311, 20315, 12126, 20324, 30066, 27384}\n",
      "dict_items([(\"Lemma('full-time.a.01.full-time')\", 10), (\"Lemma('full-time.r.01.full-time')\", 1)])\n",
      "collecting tokens for  smaller\n",
      "indices:    {15489, 18948, 3333, 11401, 29580, 11410, 30099, 17688, 30497, 31528, 28714, 15660, 27966, 3647, 31554, 29379, 23363, 16197, 27227, 3421, 1634, 15975, 16104, 7017, 15209, 759, 3436, 13296, 2929, 16116, 34679}\n",
      "dict_items([(\"Lemma('smaller.s.01.smaller')\", 17), (\"Lemma('small.a.01.small')\", 3)])\n",
      "collecting tokens for  constant\n",
      "indices:    {11905, 23042, 27536, 28950, 29976, 2841, 792, 2852, 5543, 13351, 4393, 3370, 27818, 2993, 11315, 3509, 26041, 20666, 16191, 31424, 15811, 27207, 8913, 30038, 11862, 35926, 28891, 14812, 3035, 23265, 19428, 5733, 28902, 3047, 30056, 28903, 2666, 23531, 2926, 3824, 16369, 8828}\n",
      "dict_items([(\"Lemma('changeless.s.02.constant')\", 14), (\"Lemma('constant.a.02.constant')\", 2), (\"Lemma('constant.n.01.constant')\", 2)])\n",
      "collecting tokens for  downward\n",
      "indices:    {19233, 1483, 15052, 1548, 34095, 30801, 4277, 1563, 27835}\n",
      "dict_items([(\"Lemma('down.r.01.downward')\", 2), (\"Lemma('downward.s.02.downward')\", 1)])\n",
      "collecting tokens for  burst\n",
      "indices:    {13572, 27270, 18952, 21513, 11403, 11404, 18828, 29075, 12058, 35615, 19233, 36260, 36138, 11179, 30636, 15159, 7355, 36413, 12875, 24396, 35150, 33743, 32847, 14461}\n",
      "dict_items([(\"Lemma('break.v.09.burst')\", 4), (\"Lemma('burst.v.01.burst')\", 6), (\"Lemma('explode.v.02.burst')\", 3), (\"Lemma('explosion.n.02.burst')\", 4), (\"Lemma('burst.v.04.burst')\", 2), (\"Lemma('burst.n.03.burst')\", 1), (\"Lemma('fusillade.n.01.burst')\", 1)])\n",
      "collecting tokens for  black\n",
      "indices:    {18438, 6037, 3609, 11322, 6042}\n",
      "dict_items([(\"Lemma('black.a.02.black')\", 1), (\"Lemma('black.n.01.black')\", 1)])\n",
      "collecting tokens for  clients\n",
      "indices:    {2049, 32488, 11625, 27887, 2069, 21304, 29177, 15003, 21278, 21311}\n",
      "dict_items([(\"Lemma('client.n.01.client')\", 3), (\"Lemma('customer.n.01.client')\", 1)])\n",
      "collecting tokens for  furniture\n",
      "indices:    {2048, 22497, 21026, 24581, 37031, 30695, 22279, 19527, 23024, 17686, 2071, 22489, 22138, 22140, 22493, 17407}\n",
      "dict_items([(\"Lemma('furniture.n.01.furniture')\", 4)])\n",
      "collecting tokens for  companies\n",
      "indices:    {15235, 23439, 15261, 8483, 935, 15277, 11701, 21821, 21823, 21828, 21573, 11722, 5200, 11622, 21991, 15216, 22387, 15225, 16381, 16383}\n",
      "dict_items([(\"Lemma('company.n.01.company')\", 10), (\"Lemma('company.n.02.company')\", 1), (\"Lemma('company.n.04.company')\", 1)])\n",
      "collecting tokens for  proper\n",
      "indices:    {25212, 12934, 24072, 1306, 28703, 28832, 14886, 29607, 17704, 2858, 20405, 28086, 13629, 28100, 11600, 4561, 31068, 30304, 20066, 996, 3180, 28781, 32380}\n",
      "dict_items([(\"Lemma('proper.s.04.proper')\", 1), (\"Lemma('proper.a.01.proper')\", 9)])\n",
      "collecting tokens for  actual\n",
      "indices:    {4804, 15723, 907, 16078, 32303, 16206, 5363, 14707, 1236, 16182, 4950, 32571, 34908}\n",
      "dict_items([(\"Lemma('actual.a.01.actual')\", 7), (\"Lemma('actual.s.02.actual')\", 2), (\"Lemma('actual.s.04.actual')\", 1)])\n",
      "collecting tokens for  budget\n",
      "indices:    {15490, 25092, 25477, 25478, 25479, 25480, 21898, 21515, 25482, 15501, 21918, 23584, 32546, 15530, 20531, 15541, 23606, 23990, 23358, 25152, 23618, 23363, 965, 23625, 23628, 11341, 32462, 23502, 23504, 27612, 25186, 25189, 25190, 24168, 24169, 15465, 28652, 110, 24176, 24177, 32624, 20215, 32505, 32507}\n",
      "dict_items([(\"Lemma('budget.n.01.budget')\", 4), (\"Lemma('budget.n.02.budget')\", 3)])\n",
      "collecting tokens for  800\n",
      "indices:    {21920, 21313, 4994, 4963, 5026, 20839, 21919, 29706, 29708, 4973, 4975, 4976, 4978, 15635, 4982, 4986, 21918, 29695}\n",
      "dict_items([])\n",
      "collecting tokens for  peter\n",
      "indices:    {7784}\n",
      "dict_items([(\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  peterson\n",
      "indices:    {3541}\n",
      "dict_items([(\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  camera\n",
      "indices:    {11360, 18785, 29288, 18891, 21936, 5904, 29267, 11422}\n",
      "dict_items([(\"Lemma('camera.n.01.camera')\", 3), (\"Lemma('television_camera.n.01.camera')\", 1)])\n",
      "collecting tokens for  address\n",
      "indices:    {15905, 15910, 14312, 27275, 24144, 34897, 32882, 33491, 14453, 20150, 8151, 14456, 15901}\n",
      "dict_items([(\"Lemma('address.v.01.address')\", 1), (\"Lemma('address.n.01.address')\", 3), (\"Lemma('address.n.02.address')\", 1), (\"Lemma('address.n.03.address')\", 1)])\n",
      "collecting tokens for  marketing\n",
      "indices:    {11620, 11720, 21882, 2749, 21919}\n",
      "dict_items([(\"Lemma('selling.n.01.marketing')\", 3)])\n",
      "collecting tokens for  touched\n",
      "indices:    {35843, 9862, 35468, 34189, 26905, 23325, 23203, 33328, 17717, 35385, 11711, 8512, 5055, 17731, 8775, 9417, 33103, 6480, 34132, 31839, 31714, 16740, 7285, 7165, 17022}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('touch.v.01.touch')\", 11), (\"Lemma('touch.v.07.touch')\", 1), (\"Lemma('touch.v.03.touch')\", 3), (\"Lemma('touch.v.05.touch')\", 1), (\"Lemma('touch.v.02.touch')\", 1)])\n",
      "collecting tokens for  crazy\n",
      "indices:    {10752, 10756, 19981, 6289, 6931, 2581, 8087, 8089, 33568, 23841, 6821, 7594, 16939, 33972, 36792, 19907, 34905, 17756, 35166, 20960, 1534}\n",
      "dict_items([(\"Lemma('brainsick.s.01.crazy')\", 9), (\"Lemma('crazy.s.02.crazy')\", 2), (\"Lemma('crazy.s.03.crazy')\", 1)])\n",
      "collecting tokens for  turns\n",
      "indices:    {14474, 13966, 13725, 15136, 6821, 27046, 26917, 31917, 26674, 35513, 21826, 11085, 27735, 1112, 26330, 9692, 21853, 15457, 2657, 1127, 18793, 30441, 13426, 13555, 4724, 16124, 5375}\n",
      "dict_items([(\"Lemma('turn.n.04.turn')\", 2), (\"Lemma('turn.v.01.turn')\", 2), (\"Lemma('bend.n.01.turn')\", 1), (\"Lemma('depend_on.v.01.turn_on')\", 1), (\"Lemma('become.v.02.turn')\", 1), (\"Lemma('turn.v.04.turn')\", 1)])\n",
      "collecting tokens for  belgians\n",
      "indices:    {23225}\n",
      "dict_items([])\n",
      "collecting tokens for  independence\n",
      "indices:    {14153}\n",
      "dict_items([])\n",
      "collecting tokens for  specialists\n",
      "indices:    {2721, 2727, 24074, 2731, 10187, 26573, 1611, 2736, 1105, 14066, 14064, 32472, 11099, 27868, 222}\n",
      "dict_items([(\"Lemma('specialist.n.01.specialist')\", 11)])\n",
      "collecting tokens for  available\n",
      "indices:    {14850, 24578, 15, 9747, 15895, 14363, 15907, 28711, 14894, 23602, 12342, 15424, 5185, 15940, 29258, 8285, 27748, 27749, 32878, 29294, 2160, 29819, 31871, 32903, 3211, 29839, 24721, 3220, 29844, 9882, 27804, 2717, 2716, 26783, 2724, 2727, 2728, 32937, 25258, 15531, 686, 15537, 24245, 2749, 2750, 28350, 2751, 2753, 29894, 2769, 2805, 32502, 764, 14594, 2824, 30477, 30478, 25873, 1816, 1818, 1837, 15149, 2865, 32562, 1842, 15163, 1853, 1872, 11611, 20323, 5475, 1894, 12135, 3437, 30575, 23418, 16250, 12156, 32134, 23945, 29072, 14741, 14232, 29084, 14748, 16292, 16293, 19372, 29102, 25006, 16304, 28082, 32183, 29112, 11708, 25022, 25041, 32730, 23522, 15850, 28653, 23546, 14844}\n",
      "dict_items([(\"Lemma('available.a.01.available')\", 26)])\n",
      "collecting tokens for  sba\n",
      "indices:    {2761}\n",
      "dict_items([])\n",
      "collecting tokens for  regional\n",
      "indices:    {24039, 32503, 32525, 2326, 2743, 31805}\n",
      "dict_items([(\"Lemma('regional.a.01.regional')\", 1), (\"Lemma('regional.s.02.regional')\", 1)])\n",
      "collecting tokens for  offices\n",
      "indices:    {33057, 2727, 7, 21772, 2736, 2769, 31315, 3445, 17337, 5306, 36123, 20830, 36127}\n",
      "dict_items([(\"Lemma('function.n.03.office')\", 1), (\"Lemma('agency.n.01.office')\", 4), (\"Lemma('office.n.01.office')\", 1)])\n",
      "collecting tokens for  concerns\n",
      "indices:    {23936, 29955, 15236, 2722, 11044, 2727, 2731, 13612, 2735, 2736, 2737, 2738, 2739, 2741, 2742, 2744, 2746, 2752, 32449, 24915, 32473, 27229, 1249, 14700, 32493, 20855}\n",
      "dict_items([(\"Lemma('concern.n.02.concern')\", 1), (\"Lemma('refer.v.02.concern')\", 3), (\"Lemma('concern.v.02.concern')\", 1), (\"Lemma('business.n.01.concern')\", 2), (\"Lemma('concern.n.01.concern')\", 2)])\n",
      "collecting tokens for  sam\n",
      "indices:    {32242}\n",
      "dict_items([])\n",
      "collecting tokens for  rayburn\n",
      "indices:    {32242}\n",
      "dict_items([])\n",
      "collecting tokens for  legislative\n",
      "indices:    {23945, 138, 28684, 24845, 21523, 28695, 21530, 32284, 4645, 12328, 16432, 22853, 32199, 32205, 25037, 25039, 25042, 32214, 23514, 4830, 23778, 15460, 20333}\n",
      "dict_items([(\"Lemma('legislative.a.01.legislative')\", 3), (\"Lemma('legislative.a.02.legislative')\", 3)])\n",
      "collecting tokens for  pages\n",
      "indices:    {29824, 14176, 26945, 12260, 25830, 969, 12142, 37102, 27087, 28304, 15123, 12115, 37013, 15098, 32252, 14461, 9598}\n",
      "dict_items([(\"Lemma('page.n.01.page')\", 9)])\n",
      "collecting tokens for  characterized\n",
      "indices:    {13379, 16324, 2693, 31178, 30986, 14552, 4590, 21871, 4600, 26298, 3775}\n",
      "dict_items([(\"Lemma('characterize.v.02.characterize')\", 5), (\"Lemma('qualify.v.06.characterize')\", 6)])\n",
      "collecting tokens for  chin\n",
      "indices:    {17602, 23778, 9058, 2021, 36359, 23624, 7850, 1965, 1970, 1971, 19188, 8053, 34035, 10584, 17596}\n",
      "dict_items([(\"Lemma('chin.n.01.chin')\", 9), (\"Lemma('chin.v.01.chin')\", 1)])\n",
      "collecting tokens for  upper\n",
      "indices:    {2512, 23788, 18309, 7878}\n",
      "dict_items([])\n",
      "collecting tokens for  teeth\n",
      "indices:    {8832, 30976, 36237, 8974, 30991, 30993, 30995, 30484, 30997, 31000, 10905, 31002, 31003, 36765, 31010, 31011, 31020, 31025, 27063, 31031, 33720, 34233, 31034, 31033, 31040, 10953, 14155, 716, 721, 723, 31060, 31065, 18905, 7774, 31071, 31077, 31078, 9707, 9708, 18930, 18933, 7927, 14970, 22908}\n",
      "dict_items([(\"Lemma('tooth.n.02.tooth')\", 1), (\"Lemma('tooth.n.01.tooth')\", 13), (\"Lemma('tooth.n.04.tooth')\", 1)])\n",
      "collecting tokens for  network\n",
      "indices:    {14208, 11656, 21017, 1051, 7331, 13992, 13993, 7338, 31017, 14005, 446, 14018, 14032, 14049, 33381, 14056, 14057, 14060, 14061, 14066, 3444, 32885, 26746}\n",
      "dict_items([(\"Lemma('network.n.01.network')\", 14), (\"Lemma('network.n.02.network')\", 3), (\"Lemma('net.n.06.network')\", 1)])\n",
      "collecting tokens for  intact\n",
      "indices:    {29315, 34180, 23368, 4905, 3946, 22927, 9172, 14005, 3935, 12920, 4921, 14719}\n",
      "dict_items([(\"Lemma('intact.s.02.intact')\", 1), (\"Lemma('integral.s.02.intact')\", 5)])\n",
      "collecting tokens for  regardless\n",
      "indices:    {20032, 28928, 15707, 15012}\n",
      "dict_items([(\"Lemma('regardless.r.01.regardless')\", 2)])\n",
      "collecting tokens for  motions\n",
      "indices:    {2592, 24353, 9833, 3051, 429, 20848, 20849, 20850, 31281, 14005, 4949, 4955, 17917, 8126}\n",
      "dict_items([(\"Lemma('gesture.n.02.motion')\", 2), (\"Lemma('motion.n.03.motion')\", 1), (\"Lemma('movement.n.03.motion')\", 2), (\"Lemma('motion.n.06.motion')\", 1)])\n",
      "collecting tokens for  net\n",
      "indices:    {27681, 22689, 23399, 2858, 24172, 14061, 22291, 14067, 12181, 27128, 12186, 27678}\n",
      "dict_items([(\"Lemma('net.a.01.net')\", 3), (\"Lemma('internet.n.01.net')\", 2)])\n",
      "collecting tokens for  pass\n",
      "indices:    {32800, 20515, 10596, 13508, 4198, 11175, 20522, 9835, 32784, 18739, 36788, 5016, 1080, 33822, 22047}\n",
      "dict_items([(\"Lemma('legislate.v.01.pass')\", 2), (\"Lemma('run.v.03.pass')\", 2), (\"Lemma('pass.n.04.pass')\", 1), (\"Lemma('travel_by.v.01.pass')\", 1), (\"Lemma('pass_through.v.02.pass_through')\", 1), (\"Lemma('pass.v.01.pass')\", 3), (\"Lemma('refuse.v.02.pass_up')\", 1)])\n",
      "collecting tokens for  approaching\n",
      "indices:    {18947, 14980, 21388, 16399, 33808, 11027, 30365, 18858, 2606, 2607, 24369, 8901, 9684, 28636, 33890, 23270, 10096, 29040, 31348, 18933}\n",
      "dict_items([(\"Lemma('approach.v.04.approach')\", 2), (\"Lemma('border_on.v.01.approach')\", 3), (\"Lemma('approach.v.01.approach')\", 11)])\n",
      "collecting tokens for  violent\n",
      "indices:    {31904, 2176, 14178, 34659, 5380, 33286, 6822, 8198, 21481, 26571, 11214, 10096, 12693, 23800, 30907, 35836, 22909, 13051}\n",
      "dict_items([(\"Lemma('violent.a.01.violent')\", 7), (\"Lemma('violent.s.02.violent')\", 1), (\"Lemma('violent.s.03.violent')\", 1)])\n",
      "collecting tokens for  adjust\n",
      "indices:    {21729, 33028, 15782, 12793, 32599, 24560, 27924, 30804, 1590, 11255, 32600, 10265, 14554, 31031}\n",
      "dict_items([(\"Lemma('adjust.v.01.adjust')\", 5), (\"Lemma('adjust.v.03.adjust')\", 4), (\"Lemma('align.v.01.adjust')\", 1)])\n",
      "collecting tokens for  swiftly\n",
      "indices:    {18530, 10213, 14950, 10172, 17741, 33998, 18738, 33590, 7738, 6588}\n",
      "dict_items([(\"Lemma('swiftly.r.01.swiftly')\", 8)])\n",
      "collecting tokens for  changing\n",
      "indices:    {12782, 15470, 8751}\n",
      "dict_items([(\"Lemma('change.v.02.change')\", 1), (\"Lemma('change.v.05.change')\", 1), (\"Lemma('changing.s.01.changing')\", 1)])\n",
      "collecting tokens for  losing\n",
      "indices:    {23940, 1799, 24460, 32020, 13334, 27679, 12191, 418, 20649, 31790, 30768, 10298, 24010, 24138, 211, 5599, 22881, 34290, 11255, 636, 27391}\n",
      "dict_items([(\"Lemma('lose.v.01.lose')\", 12), (\"Lemma('lose.v.02.lose')\", 4), (\"Lemma('fall_back.v.04.lose')\", 1), (\"Lemma('misplace.v.01.lose')\", 1)])\n",
      "collecting tokens for  powerful\n",
      "indices:    {18560, 31490, 12292, 26757, 14596, 28295, 14984, 18697, 28426, 21260, 34829, 24208, 16401, 36369, 27541, 5280, 34428, 30895, 28086, 451, 839, 28103, 27976, 25159, 35921, 26834, 28499, 11220, 28498, 17878, 30807, 23767, 12633, 22874, 5212, 15838, 27874, 16355, 4708, 32233, 34798, 9714, 33524, 14709, 7796, 27897, 4732}\n",
      "dict_items([(\"Lemma('powerful.a.01.powerful')\", 15), (\"Lemma('knock-down.s.01.powerful')\", 1), (\"Lemma('potent.s.01.powerful')\", 2), (\"Lemma('brawny.s.01.powerful')\", 1)])\n",
      "collecting tokens for  surrounded\n",
      "indices:    {13956, 20616, 23342, 5106, 979, 29396, 9848, 23519}\n",
      "dict_items([(\"Lemma('surround.v.01.surround')\", 2), (\"Lemma('surrounded.s.01.surrounded')\", 1), (\"Lemma('besiege.v.01.surround')\", 1)])\n",
      "collecting tokens for  examined\n",
      "indices:    {7360, 20804, 33029, 3524, 11657, 3531, 19278, 18639, 4145, 11635, 10100, 11669, 5753, 4124, 17309}\n",
      "dict_items([(\"Lemma('probe.v.01.examine')\", 2), (\"Lemma('analyze.v.01.examine')\", 5), (\"Lemma('examine.v.02.examine')\", 7)])\n",
      "collecting tokens for  inquiries\n",
      "indices:    {33088, 21953, 33027, 33028, 33029, 2246, 33059, 21802, 33009, 22641, 32468, 33076, 9620, 32470, 9240, 33013}\n",
      "dict_items([(\"Lemma('question.n.01.inquiry')\", 3)])\n",
      "collecting tokens for  officials\n",
      "indices:    {20181, 32478}\n",
      "dict_items([])\n",
      "collecting tokens for  supposedly\n",
      "indices:    {33027, 33029, 2089, 22282, 3279, 2198, 23800, 30969, 1375}\n",
      "dict_items([(\"Lemma('purportedly.r.01.supposedly')\", 4)])\n",
      "collecting tokens for  representative\n",
      "indices:    {20485, 27343, 31223, 23767, 27259}\n",
      "dict_items([])\n",
      "collecting tokens for  cousin\n",
      "indices:    {35885, 6263}\n",
      "dict_items([])\n",
      "collecting tokens for  brilliant\n",
      "indices:    {31749, 14473, 27276, 36755, 13844, 8471, 24472, 31517, 21921, 30370, 26914, 289, 26662, 26026, 11185, 23090, 11187, 26675, 11189, 19774, 11198, 11205, 1098, 4181, 32215, 5213, 11231, 33379, 1005, 13806, 12912, 11248, 27002, 2431}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('brilliant.s.01.brilliant')\", 10), (\"Lemma('brilliant.s.03.brilliant')\", 1), (\"Lemma('brainy.s.01.brilliant')\", 6), (\"Lemma('brilliant.s.05.brilliant')\", 1), (\"Lemma('bright.s.08.brilliant')\", 1)])\n",
      "collecting tokens for  hurt\n",
      "indices:    {10350, 13071, 19635, 10388, 22558, 12154, 33436, 7518}\n",
      "dict_items([(\"Lemma('hurt.v.05.hurt')\", 1), (\"Lemma('pain.v.02.hurt')\", 1), (\"Lemma('ache.v.03.hurt')\", 1), (\"Lemma('hurt.v.04.hurt')\", 1)])\n",
      "collecting tokens for  implications\n",
      "indices:    {27584, 31268, 11653, 16326, 13638, 15783, 13642, 16331, 27884, 1355, 11665, 24213, 17750, 4792, 14335, 11101, 11647}\n",
      "dict_items([(\"Lemma('significance.n.02.implication')\", 5), (\"Lemma('deduction.n.03.implication')\", 8)])\n",
      "collecting tokens for  previous\n",
      "indices:    {7303, 3594, 33162, 18, 35986, 5269, 8470, 15254, 5403, 668, 27165, 5019, 2587, 7330, 20259, 29356, 7342, 33076, 11444, 437, 21180, 12225, 9668, 7366, 25417, 22986, 21965, 2126, 15821, 11346, 32851, 12375, 32473, 91, 16364, 22894, 21875, 758, 33143, 27129, 24956}\n",
      "dict_items([(\"Lemma('former.s.03.previous')\", 10)])\n",
      "collecting tokens for  reports\n",
      "indices:    {15456, 33093, 27174, 3338, 3065, 3739, 20477}\n",
      "dict_items([(\"Lemma('report.v.02.report')\", 1), (\"Lemma('report.n.01.report')\", 4)])\n",
      "collecting tokens for  strongly\n",
      "indices:    {24577, 1798, 1415, 21895, 1544, 1552, 3216, 3218, 3220, 24213, 33947, 37033, 20143, 30771, 8501, 29238, 5314, 11974, 31182, 18269, 32616, 12779, 25198, 13807, 15473, 35704, 3194}\n",
      "dict_items([(\"Lemma('strongly.r.01.strongly')\", 15)])\n",
      "collecting tokens for  extreme\n",
      "indices:    {27264, 36997, 26118, 28170, 1036, 2832, 26388, 11541, 3736, 11036, 26656, 1317, 5290, 5291, 28458, 14001, 30773, 2494, 4928, 12615, 2642, 23512, 11992, 4445, 14046, 15071, 13796, 16228, 28265, 5355, 31342, 14063, 28529, 19572, 28532, 15988, 28152, 1913}\n",
      "dict_items([(\"Lemma('extreme.s.01.extreme')\", 14), (\"Lemma('extreme_point.n.01.extreme')\", 1), (\"Lemma('extreme.s.02.extreme')\", 4), (\"Lemma('extreme.n.01.extreme')\", 2), (\"Lemma('extreme.s.03.extreme')\", 2), (\"Lemma('extreme.s.04.extreme')\", 1)])\n",
      "collecting tokens for  measures\n",
      "indices:    {32256, 15489, 27525, 28042, 25486, 25488, 24213, 26005, 22805, 2712, 2714, 5275, 32161, 32300, 31277, 32186, 12224, 24640, 12226, 23757, 30441, 28012, 23281, 8433, 17141, 27895, 16250, 11391}\n",
      "dict_items([(\"Lemma('measurement.n.01.measure')\", 2), (\"Lemma('measure.n.01.measure')\", 4), (\"Lemma('measure.v.01.measure')\", 1), (\"Lemma('meter.n.03.measure')\", 1), (\"Lemma('measure.v.04.measure')\", 1)])\n",
      "collecting tokens for  photograph\n",
      "indices:    {19555, 9539, 29669, 7410, 36884, 3029}\n",
      "dict_items([(\"Lemma('photograph.n.01.photograph')\", 4)])\n",
      "collecting tokens for  barco\n",
      "indices:    {36889}\n",
      "dict_items([])\n",
      "collecting tokens for  facilities\n",
      "indices:    {5507, 15494, 15495, 5128, 16264, 21001, 11782, 14732, 14733, 14734, 13325, 16276, 11925, 29464, 15001, 26008, 36124, 21021, 28702, 10659, 28711, 28716, 20528, 27057, 24243, 2741, 2742, 16311, 32183, 2744, 2746, 4667, 16315, 21441, 2753, 11715, 21828, 32706, 32330, 24907, 32352, 15189, 11734, 27615, 1888, 30561, 32354, 23522, 23652, 28642, 11622, 16231, 21863, 11753, 21092, 11759, 12272, 11893, 20214, 36597, 20216, 5500, 12157}\n",
      "dict_items([(\"Lemma('facility.n.01.facility')\", 26)])\n",
      "collecting tokens for  accommodate\n",
      "indices:    {28640, 24066, 10659, 28708, 15906, 29865, 15282, 31060, 27254, 27160, 9786}\n",
      "dict_items([(\"Lemma('suit.v.01.accommodate')\", 5), (\"Lemma('accommodate.v.03.accommodate')\", 2), (\"Lemma('adapt.v.01.accommodate')\", 3), (\"Lemma('accommodate.v.04.accommodate')\", 1)])\n",
      "collecting tokens for  radio\n",
      "indices:    {27748, 27048, 2158, 2833, 2842, 31294}\n",
      "dict_items([(\"Lemma('radio.n.01.radio')\", 1)])\n",
      "collecting tokens for  stations\n",
      "indices:    {25944, 21413, 26727, 31368, 26734, 23762, 25939, 25204, 23704, 26747, 26748, 26749, 23710}\n",
      "dict_items([])\n",
      "collecting tokens for  design\n",
      "indices:    {22153, 29602, 33102, 31591}\n",
      "dict_items([(\"Lemma('design.v.02.design')\", 1)])\n",
      "collecting tokens for  hull\n",
      "indices:    {2271}\n",
      "dict_items([])\n",
      "collecting tokens for  honored\n",
      "indices:    {22369, 513, 23681, 21668, 483, 21886, 10632, 14014, 25361, 21491, 628, 22068, 20471, 21881, 14491, 27038, 32255}\n",
      "dict_items([(\"Lemma('honor.v.01.honor')\", 11), (\"Lemma('respect.v.02.honor')\", 1), (\"Lemma('esteemed.s.01.honored')\", 3)])\n",
      "collecting tokens for  night\n",
      "indices:    {35826, 18002}\n",
      "dict_items([(\"Lemma('night.n.01.night')\", 1)])\n",
      "collecting tokens for  incidentally\n",
      "indices:    {5016, 24970, 33127}\n",
      "dict_items([(\"Lemma('incidentally.r.02.incidentally')\", 1)])\n",
      "collecting tokens for  felix\n",
      "indices:    {9785}\n",
      "dict_items([(\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  hard\n",
      "indices:    {19282, 5140, 325}\n",
      "dict_items([(\"Lemma('hard.r.01.hard')\", 1), (\"Lemma('hard.r.02.hard')\", 1)])\n",
      "collecting tokens for  violation\n",
      "indices:    {128, 5347, 22807, 15238, 15302, 15304, 14251, 29998, 31759, 2224, 1015, 15289, 15226, 20156, 14941}\n",
      "dict_items([(\"Lemma('misdemeanor.n.01.violation')\", 6), (\"Lemma('violation.n.02.violation')\", 2), (\"Lemma('trespass.n.02.violation')\", 2), (\"Lemma('irreverence.n.02.violation')\", 1)])\n",
      "collecting tokens for  treaty\n",
      "indices:    {24656, 32714, 34438}\n",
      "dict_items([])\n",
      "collecting tokens for  terms\n",
      "indices:    {28929, 23810, 31114, 14602, 25998, 12948, 3350, 15382, 12186, 1307, 27804, 32028, 16671, 11039, 31909, 27818, 4012, 31791, 31279, 29875, 2995, 27703, 6841, 23481, 2753, 11331, 16323, 23877, 1221, 16455, 1219, 16456, 31820, 16206, 4431, 26448, 34386, 12502, 5463, 32856, 27862, 29921, 10209, 32353, 31717, 35304, 31084, 33261, 32494, 32880, 6897, 32242, 15731, 32888, 14078}\n",
      "dict_items([(\"Lemma('term.n.01.term')\", 8), (\"Lemma('term.v.01.term')\", 2), (\"Lemma('term.n.04.term')\", 1), (\"Lemma('condition.n.07.term')\", 3), (\"Lemma('footing.n.01.terms')\", 1)])\n",
      "collecting tokens for  april\n",
      "indices:    {22063}\n",
      "dict_items([])\n",
      "collecting tokens for  carved\n",
      "indices:    {1570, 36420, 7429, 31484, 14185, 29551, 29300, 20472, 698, 1564, 31485, 29375}\n",
      "dict_items([(\"Lemma('carve.v.01.carve')\", 6), (\"Lemma('carved.a.01.carved')\", 2)])\n",
      "collecting tokens for  elephants\n",
      "indices:    {23200, 25228, 11252, 26805, 30709, 20472, 26843, 13116}\n",
      "dict_items([(\"Lemma('elephant.n.01.elephant')\", 2)])\n",
      "collecting tokens for  committee\n",
      "indices:    {22501, 22874, 24821}\n",
      "dict_items([])\n",
      "collecting tokens for  youths\n",
      "indices:    {21316, 21319, 21320, 21322, 11884, 24051, 14452, 11897}\n",
      "dict_items([(\"Lemma('young_person.n.01.youth')\", 3)])\n",
      "collecting tokens for  fled\n",
      "indices:    {13952, 12897, 6176, 6213, 22205, 28392, 29193, 21322, 17482, 14091, 842, 35245, 6232, 6204, 24093}\n",
      "dict_items([(\"Lemma('flee.v.01.flee')\", 15)])\n",
      "collecting tokens for  palm\n",
      "indices:    {28164, 517, 25662}\n",
      "dict_items([])\n",
      "collecting tokens for  compass\n",
      "indices:    {15426, 30508, 11245, 11503, 31440, 30575, 36019, 11508, 30581, 12405, 31447}\n",
      "dict_items([(\"Lemma('compass.n.01.compass')\", 3), (\"Lemma('scope.n.01.compass')\", 2)])\n",
      "collecting tokens for  presumed\n",
      "indices:    {16384, 2981, 21256, 3977, 28149, 32951, 14456, 13945, 10139, 16383}\n",
      "dict_items([(\"Lemma('assume.v.01.presume')\", 7)])\n",
      "collecting tokens for  plunged\n",
      "indices:    {6240, 9954, 27493, 18886, 18662, 5097, 36139, 7213, 6926, 36752, 6835, 18741, 13945, 894}\n",
      "dict_items([(\"Lemma('dive.v.01.plunge')\", 4), (\"Lemma('plunge.v.05.plunge')\", 1), (\"Lemma('plunge.v.04.plunge')\", 3), (\"Lemma('immerse.v.01.plunge')\", 5), (\"Lemma('plunge.v.03.plunge')\", 1)])\n",
      "collecting tokens for  grave\n",
      "indices:    {25984, 4866, 22660, 27781, 13830, 27783, 27790, 27793, 12306, 13945, 26520, 12188, 8232, 8879, 23610, 31699, 5077, 23772, 36319, 23653, 22640, 17529, 4607}\n",
      "dict_items([(\"Lemma('grave.n.02.grave')\", 3), (\"Lemma('grave.s.01.grave')\", 1), (\"Lemma('grave.n.01.grave')\", 4), (\"Lemma('dangerous.s.02.grave')\", 2)])\n",
      "collecting tokens for  fatal\n",
      "indices:    {2688, 22624, 2265, 2692, 11247, 32017, 850, 23858, 13845, 2710, 25559, 32024, 13945, 13979, 22712}\n",
      "dict_items([(\"Lemma('fateful.s.01.fatal')\", 4), (\"Lemma('fatal.a.01.fatal')\", 5)])\n",
      "collecting tokens for  alex\n",
      "indices:    {9392}\n",
      "dict_items([(\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  persuade\n",
      "indices:    {32192, 23329, 643, 20774, 9383, 22812, 13176, 25754, 12443, 20220}\n",
      "dict_items([(\"Lemma('carry.v.23.persuade')\", 7), (\"Lemma('persuade.v.02.persuade')\", 3)])\n",
      "collecting tokens for  morgan\n",
      "indices:    {35013}\n",
      "dict_items([])\n",
      "collecting tokens for  returned\n",
      "indices:    {13827, 9989, 30343, 21127, 18184, 11275, 35724, 14481, 12690, 18709, 13591, 31640, 279, 24727, 23962, 14752, 290, 21539, 12836, 21542, 26025, 12587, 17579, 18349, 34991, 37169, 26802, 18611, 9397, 20151, 313, 14526, 19393, 28359, 11466, 22090, 25163, 17749, 7894, 21335, 34135, 33625, 10717, 14430, 34019, 31716, 20067, 11494, 7678, 30310, 6633, 34148, 17643, 34155, 9582, 5102, 20974, 8431, 9587, 7669, 21622, 23286, 22261, 33405, 31486}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('return.v.01.return')\", 26), (\"Lemma('return.v.06.return')\", 1), (\"Lemma('render.v.07.return')\", 3), (\"Lemma('retort.v.01.return')\", 2), (\"Lemma('render.v.05.return')\", 1), (\"Lemma('return.v.07.return')\", 2), (\"Lemma('revert.v.01.return')\", 1), (\"Lemma('refund.v.01.return')\", 1), (\"Lemma('return.v.05.return')\", 2)])\n",
      "collecting tokens for  kitchen\n",
      "indices:    {36096, 29191, 5642, 29451, 21260, 8845, 37003, 37008, 17810, 34968, 9243, 20123, 7331, 17571, 27941, 16678, 1701, 36136, 22309, 7592, 17067, 36139, 37028, 34983, 34991, 16687, 20137, 36149, 10807, 7736, 7354, 9404, 9408, 10946, 26951, 7756, 30413, 22605, 19664, 37075, 17749, 15190, 8921, 7386, 8794, 30428, 8925, 17246, 30431, 16736, 8289, 7392, 30435, 24292, 21213, 9186, 30439, 9192, 16742, 10986, 36331, 9579, 6378, 16746, 35053, 23024, 16881, 29427, 29428, 30199, 36987, 29180, 8958}\n",
      "dict_items([(\"Lemma('kitchen.n.01.kitchen')\", 26)])\n",
      "collecting tokens for  poured\n",
      "indices:    {15075, 17924, 22564, 24679, 35549, 9097, 8426, 34430, 7037, 34991, 12562, 36212, 32852, 19290, 35387, 28925, 19838, 7967}\n",
      "dict_items([(\"Lemma('pour.v.02.pour')\", 5), (\"Lemma('decant.v.01.pour')\", 5), (\"Lemma('pour.v.01.pour')\", 4), (\"Lemma('pour.v.04.pour')\", 1)])\n",
      "collecting tokens for  copper\n",
      "indices:    {23211, 11500, 22159, 30127, 29400, 12190}\n",
      "dict_items([(\"Lemma('copper.n.01.copper')\", 2)])\n",
      "collecting tokens for  stove\n",
      "indices:    {803, 9189, 29160, 36139, 35917, 36078, 34991, 36112, 21364, 5333, 36150, 29465, 7387}\n",
      "dict_items([(\"Lemma('stove.n.01.stove')\", 2), (\"Lemma('stove.n.02.stove')\", 1)])\n",
      "collecting tokens for  i'm\n",
      "indices:    {6853}\n",
      "dict_items([])\n",
      "collecting tokens for  lucky\n",
      "indices:    {28642, 29027, 21794, 19268, 9291, 33903, 36431, 13305, 12831}\n",
      "dict_items([(\"Lemma('lucky.s.01.lucky')\", 4)])\n",
      "collecting tokens for  lublin\n",
      "indices:    {7956}\n",
      "dict_items([(\"Lemma('location.n.01.location')\", 1)])\n",
      "collecting tokens for  reaching\n",
      "indices:    {23872, 15078, 26729, 13359, 15055, 14971, 29501, 18495}\n",
      "dict_items([(\"Lemma('reach.v.03.reach')\", 2), (\"Lemma('reach.v.04.reach')\", 2), (\"Lemma('reach.v.02.reach')\", 2), (\"Lemma('achieve.v.01.reach')\", 1), (\"Lemma('reach.v.01.reach')\", 1)])\n",
      "collecting tokens for  stone\n",
      "indices:    {21635}\n",
      "dict_items([])\n",
      "collecting tokens for  looks\n",
      "indices:    {10627, 8329, 2317, 2707, 24598, 1559, 21018, 1564, 28957, 28958, 13727, 24988, 18591, 24865, 11172, 28964, 28968, 13356, 29104, 2353, 31409, 32564, 26934, 23479, 20410, 28987, 28986, 17853, 24507, 31551, 29249, 24514, 23111, 22857, 19146, 26825, 29005, 334, 30031, 22482, 3668, 17876, 29014, 2007, 26710, 24289, 4578, 29025, 29031, 13554, 34547, 5365, 30967, 23032, 35066, 7035, 9470}\n",
      "dict_items([(\"Lemma('look.v.02.look')\", 26), (\"Lemma('look.v.01.look')\", 3), (\"Lemma('look.n.03.look')\", 1), (\"Lemma('expression.n.01.look')\", 1), (\"Lemma('expect.v.03.look')\", 1)])\n",
      "collecting tokens for  oriental\n",
      "indices:    {25669}\n",
      "dict_items([])\n",
      "collecting tokens for  gold\n",
      "indices:    {24576, 31322, 517, 16511}\n",
      "dict_items([])\n",
      "collecting tokens for  colored\n",
      "indices:    {14081, 29572, 13575, 27018, 10511, 2198, 22168, 13725, 31269, 11181, 5937, 5939, 21430, 6071, 5440, 6082, 8132, 29394, 5332, 6104, 19683, 29158, 29671, 6118, 6127, 3823, 24564, 6135, 13561, 6140}\n",
      "dict_items([(\"Lemma('colored.a.01.colored')\", 9), (\"Lemma('colored.s.02.colored')\", 11), (\"Lemma('color.v.01.color')\", 2), (\"Lemma('color.v.03.color')\", 1)])\n",
      "collecting tokens for  tile\n",
      "indices:    {31552, 21026, 31523, 29381, 22025, 31561, 31549, 31517, 31531, 29394, 31509, 31510, 30685, 30686}\n",
      "dict_items([])\n",
      "collecting tokens for  fountain\n",
      "indices:    {29389}\n",
      "dict_items([])\n",
      "collecting tokens for  pools\n",
      "indices:    {2753, 30046, 30051, 31557, 30054, 30055, 35560, 29989, 29990, 21022, 21023}\n",
      "dict_items([(\"Lemma('consortium.n.01.pool')\", 1)])\n",
      "collecting tokens for  shallow\n",
      "indices:    {30051, 5060, 25637, 30054, 12427, 12723, 12725, 3545, 8572}\n",
      "dict_items([(\"Lemma('shallow.a.01.shallow')\", 6)])\n",
      "collecting tokens for  steps\n",
      "indices:    {4737, 8577, 25348, 34054, 7047, 35209, 17547, 17423, 5652, 17044, 24089, 34077, 35997, 13601, 5026, 12066, 10532, 8740, 15016, 34090, 35245, 21428, 20789, 32184, 32188, 27711, 29378, 15813, 10565, 20296, 31560, 30540, 18127, 28880, 25300, 18517, 18519, 35161, 23259, 12766, 7265, 31077, 20326, 18534, 7016, 17512, 7781, 19702, 36730}\n",
      "dict_items([(\"Lemma('footstep.n.03.step')\", 4), (\"Lemma('stairs.n.01.steps')\", 13), (\"Lemma('measure.n.01.step')\", 5), (\"Lemma('step.n.03.step')\", 1)])\n",
      "collecting tokens for  benefit\n",
      "indices:    {30979, 24325, 1932, 11788, 6286, 22032, 147, 22042, 11805, 11680, 26021, 11831, 1337, 24771, 17351, 14921, 34635, 14171, 28635, 1643, 11763, 32504, 4604, 14207}\n",
      "dict_items([(\"Lemma('benefit.n.02.benefit')\", 4), (\"Lemma('benefit.n.01.benefit')\", 2), (\"Lemma('profit.v.01.benefit')\", 8), (\"Lemma('benefit.v.02.benefit')\", 2), (\"Lemma('benefit.n.03.benefit')\", 1)])\n",
      "collecting tokens for  safety\n",
      "indices:    {25353, 21386, 17036, 28695, 31258, 28699, 28700, 28701, 28703, 14757, 1707, 33586, 29113, 30011, 23617, 31304, 5847, 20962, 29675, 11762}\n",
      "dict_items([(\"Lemma('safety.n.01.safety')\", 4), (\"Lemma('guard.n.03.safety')\", 1)])\n",
      "collecting tokens for  ladder\n",
      "indices:    {19330, 30051, 34308, 5958, 22155, 25804, 8557, 34289, 8499, 8504, 34522, 26842}\n",
      "dict_items([(\"Lemma('ladder.n.01.ladder')\", 5)])\n",
      "collecting tokens for  ceremonies\n",
      "indices:    {28130, 28265, 27403, 632, 491, 20591, 1040, 32629, 22327, 22360, 2618, 13118, 2591}\n",
      "dict_items([(\"Lemma('ceremony.n.01.ceremony')\", 3), (\"Lemma('ceremony.n.03.ceremony')\", 1)])\n",
      "collecting tokens for  departure\n",
      "indices:    {5799, 26412, 26477, 495, 27281, 9175, 32629, 7351, 9176, 28093}\n",
      "dict_items([(\"Lemma('departure.n.01.departure')\", 5)])\n",
      "collecting tokens for  grounds\n",
      "indices:    {29477}\n",
      "dict_items([])\n",
      "collecting tokens for  providence\n",
      "indices:    {20317}\n",
      "dict_items([])\n",
      "collecting tokens for  considerable\n",
      "indices:    {4740, 14852, 31748, 33160, 3210, 27531, 33036, 21521, 25236, 3861, 14364, 3613, 4639, 26406, 2471, 32174, 34735, 30771, 3765, 30775, 16057, 28475, 23616, 27841, 32451, 13764, 16458, 6092, 32333, 1359, 27857, 23762, 15955, 1233, 7637, 16214, 16345, 3164, 26588, 3165, 27748, 27877, 1385, 23663, 7408, 32495, 28924, 5119}\n",
      "dict_items([(\"Lemma('considerable.a.01.considerable')\", 24)])\n",
      "collecting tokens for  glance\n",
      "indices:    {19331, 7437, 17549, 36750, 19343, 18588, 18592, 24865, 13989, 11181, 27697, 8896, 17739, 31439, 34518, 34522, 14183, 33640, 33513, 10602, 10985, 17392, 17648, 19572, 6006, 17401, 29307}\n",
      "dict_items([(\"Lemma('glance.n.01.glance')\", 13), (\"Lemma('glance.v.01.glance')\", 7)])\n",
      "collecting tokens for  biggest\n",
      "indices:    {23104, 27011, 3684, 12742, 20775, 23439, 24604}\n",
      "dict_items([])\n",
      "collecting tokens for  belonged\n",
      "indices:    {36896, 1345, 8260, 36965, 19686, 23111, 35975, 12842, 10602, 7210, 2642, 8372}\n",
      "dict_items([(\"Lemma('belong.v.02.belong')\", 1), (\"Lemma('belong.v.01.belong')\", 1)])\n",
      "collecting tokens for  brother\n",
      "indices:    {9994, 5643, 9995, 12561, 8210, 29972, 26917, 35115, 28078, 11440, 21044, 21172, 8886, 13501, 13505, 8900, 28997, 8663, 10072, 18393, 10075, 5088, 8681, 26090, 24688, 14454, 26231, 14456}\n",
      "dict_items([(\"Lemma('brother.n.01.brother')\", 14), (\"Lemma('brother.n.02.brother')\", 1)])\n",
      "collecting tokens for  outdoor\n",
      "indices:    {11872, 25157, 11877, 11914, 30160, 11953, 11863}\n",
      "dict_items([(\"Lemma('outdoor.a.01.outdoor')\", 3), (\"Lemma('outdoor.a.02.outdoor')\", 1)])\n",
      "collecting tokens for  dozen\n",
      "indices:    {29440, 17536, 19333, 24462, 6931, 29973, 11930, 539, 3610, 11168, 36131, 549, 30257, 7345, 17977, 30523, 25659, 7485, 23744, 35910, 20039, 18250, 8397, 35919, 16594, 27096, 23001, 8030, 21598, 35297, 24289, 5220, 10470, 31335, 1769, 34154, 33899, 35441, 29428, 11126, 12663, 20856}\n",
      "dict_items([(\"Lemma('twelve.n.01.dozen')\", 14), (\"Lemma('twelve.s.01.dozen')\", 3)])\n",
      "collecting tokens for  trips\n",
      "indices:    {27011, 21006, 656, 11280, 14480, 30104, 10921, 5675, 36270, 9162, 14426, 30560, 29155, 30574, 28655, 30578, 29428, 11764, 14454, 23037}\n",
      "dict_items([(\"Lemma('trip.n.01.trip')\", 9)])\n",
      "collecting tokens for  invite\n",
      "indices:    {27633, 36978}\n",
      "dict_items([(\"Lemma('invite.v.02.invite')\", 1), (\"Lemma('invite.v.04.invite')\", 1)])\n",
      "collecting tokens for  wrath\n",
      "indices:    {2372, 6444, 9197, 7700, 28279, 27515, 28094}\n",
      "dict_items([(\"Lemma('wrath.n.01.wrath')\", 3)])\n",
      "collecting tokens for  swept\n",
      "indices:    {35206, 13589, 2325, 35613, 12194, 26275, 21418, 12716, 31407, 22580, 19253, 2365, 14403, 6474, 10571, 36042, 19281, 1241, 25818, 9951, 21600, 28899, 1255, 17517, 17522, 17395, 2303}\n",
      "dict_items([(\"Lemma('brush.v.04.sweep')\", 7), (\"Lemma('espouse.v.03.sweep_up')\", 1), (\"Lemma('sweep.v.02.sweep')\", 3), (\"Lemma('cross.v.05.sweep')\", 2), (\"Lemma('sweep.v.06.sweep')\", 1), (\"Lemma('embroil.v.01.sweep')\", 2), (\"Lemma('sweep.v.03.sweep')\", 1), (\"Lemma('sweep.v.07.sweep')\", 1)])\n",
      "collecting tokens for  sentiment\n",
      "indices:    {28055, 26052, 27751, 5353, 24043, 6892, 7884, 32909, 8212, 2518, 2359, 24120, 17432, 32156, 2365, 27295}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('sentiment.n.01.sentiment')\", 6), (\"Lemma('opinion.n.01.sentiment')\", 2)])\n",
      "collecting tokens for  america\n",
      "indices:    {13534}\n",
      "dict_items([(\"Lemma('united_states.n.01.America')\", 1)])\n",
      "collecting tokens for  contained\n",
      "indices:    {4098, 17411, 30339, 11398, 25735, 11145, 4111, 15504, 4116, 35732, 11414, 3095, 2969, 4121, 32544, 15277, 15921, 3513, 12217, 12219, 3514, 21181, 11460, 26436, 3146, 3404, 23245, 25808, 35412, 3546, 4188, 14813, 4066, 24675, 10219, 4077, 4078, 11503, 15472, 32497, 4082, 4083, 15860, 29941, 4086, 31349, 4088, 32757, 4090}\n",
      "dict_items([(\"Lemma('incorporate.v.02.contain')\", 26), (\"Lemma('hold.v.11.contain')\", 13)])\n",
      "collecting tokens for  prominent\n",
      "indices:    {32898, 7561, 30987, 28044, 4111, 22546, 4116, 25493, 4121, 4770, 2083, 28075, 28096, 19781, 30536, 32463, 25440, 21856, 19554, 31593, 18538, 492, 4077, 10736, 9840, 14323, 15989, 15991, 12282, 15995}\n",
      "dict_items([(\"Lemma('outstanding.s.02.prominent')\", 11), (\"Lemma('big.s.05.prominent')\", 7)])\n",
      "collecting tokens for  distributed\n",
      "indices:    {899, 4200, 10984, 32745, 32715, 32490, 32717, 21579, 5203, 4116, 25909, 32341, 29694, 32728, 32729, 26291, 32732, 2942}\n",
      "dict_items([(\"Lemma('spread.v.01.distribute')\", 5), (\"Lemma('distribute.v.01.distribute')\", 8), (\"Lemma('distribute.v.04.distribute')\", 1), (\"Lemma('circulate.v.02.distribute')\", 1), (\"Lemma('distribute.v.03.distribute')\", 1)])\n",
      "collecting tokens for  figs.\n",
      "indices:    {3793, 15141, 28741}\n",
      "dict_items([(\"Lemma('figure.n.01.fig')\", 2)])\n",
      "collecting tokens for  crowded\n",
      "indices:    {8578, 36739, 34690, 18181, 18182, 6034, 36639, 19888, 27057, 12728, 17599, 1860, 5445, 36038, 18503, 34271, 32353, 17123, 6500, 7526, 871, 35688, 6505, 14445, 5869, 18168, 29694}\n",
      "dict_items([(\"Lemma('crowded.a.01.crowded')\", 11), (\"Lemma('crowd.v.02.crowd')\", 2), (\"Lemma('herd.v.01.crowd')\", 3), (\"Lemma('crowd.v.03.crowd')\", 2)])\n",
      "collecting tokens for  odd\n",
      "indices:    {26368, 4483, 4492, 24590, 27540, 13848, 13602, 13603, 27564, 27566, 2359, 25664, 27074, 4546, 4548, 31430, 37069, 4558, 13775, 4560, 31440, 4559, 9696, 26337, 29152, 17123, 26084, 14565, 25580, 1005, 36079, 8432, 26737}\n",
      "dict_items([(\"Lemma('odd.s.03.odd')\", 3), (\"Lemma('odd.a.01.odd')\", 7), (\"Lemma('odd.s.02.odd')\", 6), (\"Lemma('curious.s.01.odd')\", 1)])\n",
      "collecting tokens for  distant\n",
      "indices:    {36995, 37133, 31375, 5904, 31121, 18204, 9629, 17820, 26400, 31137, 1849, 18624, 18627, 28748, 28749, 28750, 18256, 15828, 26197, 33879, 20055, 2654, 5472, 17123, 23524, 9579, 17906, 3449, 12923, 25725, 13311}\n",
      "dict_items([(\"Lemma('distant.a.01.distant')\", 16), (\"Lemma('distant.a.02.distant')\", 2)])\n",
      "collecting tokens for  rain\n",
      "indices:    {31395, 19300, 31398, 18184, 2611, 7188, 26393, 31386}\n",
      "dict_items([(\"Lemma('rain.n.01.rain')\", 2), (\"Lemma('rain.n.02.rain')\", 1)])\n",
      "collecting tokens for  worse\n",
      "indices:    {25410, 4035, 36963, 5442, 17032, 33704, 21962, 36142, 27438, 23507, 2261, 13622, 20510, 12217, 12378, 10074, 31966, 29727}\n",
      "dict_items([(\"Lemma('worse.a.01.worse')\", 6), (\"Lemma('worse.n.01.worse')\", 1)])\n",
      "collecting tokens for  july\n",
      "indices:    {25359}\n",
      "dict_items([])\n",
      "collecting tokens for  sign\n",
      "indices:    {128, 9985, 22406, 27654, 28552, 24456, 778, 17164, 21008, 20762, 33949, 21022, 17055, 18207, 12190, 19616, 9892, 29349, 2342, 47, 27440, 19251, 23606, 24630, 19259, 13508, 23365, 28870, 11335, 18760, 11977, 11336, 10573, 21459, 29139, 15574, 1878, 34393, 17882, 8285, 24029, 737, 19689, 5865, 30826, 22769, 7153, 7155, 3193, 5372}\n",
      "dict_items([(\"Lemma('sign.v.02.sign')\", 5), (\"Lemma('sign.v.04.sign_up')\", 1), (\"Lemma('sign.n.02.sign')\", 4), (\"Lemma('sign.v.03.sign')\", 3), (\"Lemma('sign.n.01.sign')\", 8), (\"Lemma('signboard.n.01.sign')\", 2), (\"Lemma('sign.v.01.sign')\", 3), (\"Lemma('sign.n.09.sign')\", 1), (\"Lemma('sign_of_the_zodiac.n.01.sign')\", 2), (\"Lemma('signal.n.01.sign')\", 3), (\"Lemma('polarity.n.02.sign')\", 1)])\n",
      "collecting tokens for  workbench\n",
      "indices:    {20073, 20109, 20112, 20082, 20084, 20085, 20089, 20060}\n",
      "dict_items([(\"Lemma('workbench.n.01.workbench')\", 8)])\n",
      "collecting tokens for  eggs\n",
      "indices:    {29187, 7302, 19468, 12560, 9361, 9372, 30493, 3618, 3619, 27173, 27175, 3625, 3628, 27183, 3632, 13107, 16694, 7485, 11582, 9411, 30412, 30293, 19292, 34908, 21598, 12383, 29150, 27245, 9326, 29181}\n",
      "dict_items([(\"Lemma('egg.n.01.egg')\", 9), (\"Lemma('egg.n.02.eggs')\", 6), (\"Lemma('egg.n.02.egg')\", 1)])\n",
      "collecting tokens for  treats\n",
      "indices:    {34272, 30492, 31846, 24521, 3726, 16144, 11601, 1010, 16018, 24535, 35228, 11519}\n",
      "dict_items([(\"Lemma('process.v.01.treat')\", 1), (\"Lemma('cover.v.05.treat')\", 2), (\"Lemma('treat.v.03.treat')\", 3), (\"Lemma('treat.v.01.treat')\", 5)])\n",
      "collecting tokens for  bearded\n",
      "indices:    {28394, 36427, 28395, 26925, 11950, 6351, 975, 1010, 7827}\n",
      "dict_items([(\"Lemma('bearded.s.01.bearded')\", 4), (\"Lemma('beard.v.01.beard')\", 1)])\n",
      "collecting tokens for  tangible\n",
      "indices:    {32385, 32393, 32394, 32396, 32431, 25200, 1010, 20499, 32403, 16286, 32378, 32377, 36122, 25725, 32382}\n",
      "dict_items([(\"Lemma('tangible.a.01.tangible')\", 1), (\"Lemma('real.s.04.tangible')\", 1)])\n",
      "collecting tokens for  affection\n",
      "indices:    {5473, 27265, 1188, 6439, 32218, 1010, 7698, 11283, 36533, 26554, 12315}\n",
      "dict_items([(\"Lemma('affection.n.01.affection')\", 6)])\n",
      "collecting tokens for  disappeared\n",
      "indices:    {26502, 16654, 28047, 6290, 7955, 28057, 2592, 31522, 2085, 33832, 5673, 9388, 13616, 10803, 3137, 19267, 2633, 5842, 14044, 30941, 5596, 13024, 17512, 3313, 13948, 6141}\n",
      "dict_items([(\"Lemma('disappear.v.01.disappear')\", 26)])\n",
      "collecting tokens for  forever\n",
      "indices:    {19498, 5419, 29228, 36143, 19381, 27318, 441, 11067, 34887, 7116, 27343, 11090, 24277, 8152, 26844, 6111, 34918, 2421, 22524, 34814}\n",
      "dict_items([(\"Lemma('everlastingly.r.01.forever')\", 9), (\"Lemma('constantly.r.02.forever')\", 1)])\n",
      "collecting tokens for  james\n",
      "indices:    {142}\n",
      "dict_items([])\n",
      "collecting tokens for  studying\n",
      "indices:    {14304, 25026, 23429, 19560, 3277, 14452, 14070, 19578}\n",
      "dict_items([(\"Lemma('analyze.v.01.study')\", 7), (\"Lemma('learn.v.04.study')\", 1)])\n",
      "collecting tokens for  further\n",
      "indices:    {4192, 23427, 4164, 3923, 3421, 26975}\n",
      "dict_items([(\"Lemma('further.r.01.further')\", 3), (\"Lemma('further.s.01.further')\", 1)])\n",
      "collecting tokens for  improvement\n",
      "indices:    {1600, 32487, 23432, 24476, 16054, 24028}\n",
      "dict_items([(\"Lemma('improvement.n.03.improvement')\", 1), (\"Lemma('improvement.n.01.improvement')\", 1)])\n",
      "collecting tokens for  turnpike\n",
      "indices:    {27946, 23427}\n",
      "dict_items([])\n",
      "collecting tokens for  try\n",
      "indices:    {1663}\n",
      "dict_items([(\"Lemma('try.v.01.try')\", 1)])\n",
      "collecting tokens for  baseball\n",
      "indices:    {486, 1928, 23081, 489, 491, 652, 1966, 27921, 23093, 19959, 23000, 24703}\n",
      "dict_items([(\"Lemma('baseball.n.01.baseball')\", 4), (\"Lemma('baseball.n.02.baseball')\", 1)])\n",
      "collecting tokens for  smiled\n",
      "indices:    {34817, 34822, 19079, 33677, 10511, 34840, 16539, 7584, 18977, 19105, 36388, 25514, 25516, 34222, 25518, 10159, 36786, 6195, 9524, 9909, 37045, 19387, 34876, 24380, 36286, 8899, 34885, 10319, 17617, 33748, 34518, 17624, 16472, 8032, 36583, 10731, 19819, 6381, 5741, 19827, 36723, 33397, 36341, 8313, 8830, 5887}\n",
      "dict_items([(\"Lemma('smile.v.01.smile')\", 26)])\n",
      "collecting tokens for  remote\n",
      "indices:    {3328, 9601, 30217, 34827, 29836, 22545, 27793, 9365, 34840, 30754, 2595, 26530, 4775, 16187, 16315, 14651, 3388, 16219, 16221, 34917, 24049, 12921}\n",
      "dict_items([(\"Lemma('outback.s.01.remote')\", 1), (\"Lemma('outside.s.08.remote')\", 4), (\"Lemma('distant.s.05.remote')\", 4), (\"Lemma('distant.s.04.remote')\", 3)])\n",
      "collecting tokens for  happiness\n",
      "indices:    {34817, 7361, 13128, 19786, 32016, 13150, 34897, 31989, 34902, 34840, 34906, 8094}\n",
      "dict_items([(\"Lemma('happiness.n.01.happiness')\", 3), (\"Lemma('happiness.n.02.happiness')\", 2)])\n",
      "collecting tokens for  stretched\n",
      "indices:    {5762, 5763, 8706, 34840, 1948, 10526, 17573, 7974, 12458, 34232, 1985, 33861, 18505, 18898, 19155, 37086, 35038, 25702, 17639, 14822, 33781, 18934, 11382, 11256, 31868}\n",
      "dict_items([(\"Lemma('stretch.v.01.stretch')\", 7), (\"Lemma('stretch.v.02.stretch')\", 5), (\"Lemma('unfold.v.03.stretch_out')\", 1), (\"Lemma('stretched.s.01.stretched')\", 3), (\"Lemma('stretch.v.07.stretch')\", 1), (\"Lemma('stretch.v.04.stretch')\", 2), (\"Lemma('elongate.v.01.stretch')\", 1), (\"Lemma('unfold.v.03.stretch')\", 2)])\n",
      "collecting tokens for  capacity\n",
      "indices:    {32134, 5497, 4617, 12044, 23566, 5646, 12944, 27153, 23574, 34840, 4633, 21664, 15009, 15651, 5540, 36136, 937, 2730, 4907, 14632, 23983, 23985, 29875, 29876, 29877, 4930, 1475, 834, 1480, 5576, 15049, 1483, 30155, 33227, 3577, 29898, 30416, 17365, 30169, 3163, 11753, 20206, 30575, 3568, 15219, 3572, 14070, 3575, 12920, 22649, 31230, 3583}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('capability.n.02.capacity')\", 7), (\"Lemma('capacity.n.01.capacity')\", 14), (\"Lemma('capacity.n.03.capacity')\", 6), (\"Lemma('capacity.n.04.capacity')\", 3), (\"Lemma('capacity.n.05.capacity')\", 1)])\n",
      "collecting tokens for  eye\n",
      "indices:    {11360, 13954, 19075, 10585, 20332, 37051, 36112, 30033, 14418, 7641, 13978, 30555}\n",
      "dict_items([(\"Lemma('eye.n.01.eye')\", 4)])\n",
      "collecting tokens for  description\n",
      "indices:    {15872, 12559, 16152, 10273, 26030, 22703, 29237, 26935, 29242, 15934, 15943, 26315, 15952, 2642, 20438, 21215, 3454, 29941, 15742}\n",
      "dict_items([(\"Lemma('description.n.01.description')\", 9)])\n",
      "collecting tokens for  anatomical\n",
      "indices:    {3840, 3842, 10660, 10666, 10670, 10673, 3409, 30803, 11419}\n",
      "dict_items([(\"Lemma('anatomic.a.01.anatomical')\", 7), (\"Lemma('anatomical_reference.n.01.anatomical')\", 1)])\n",
      "collecting tokens for  thick\n",
      "indices:    {3846, 8198, 29579, 9487, 9232, 9247, 9248, 34208, 28836, 29607, 1706, 12462, 26927, 9648, 26933, 19125, 7349, 12857, 33852, 3775, 5058, 36419, 36037, 19146, 36044, 13009, 4184, 19673, 19160, 19035, 12509, 11230, 7905, 36963, 16612, 10982, 36326, 4199, 15209, 19178, 14822, 10483, 8052, 15091, 5622, 9596, 7551}\n",
      "dict_items([(\"Lemma('midst.n.01.thick')\", 1), (\"Lemma('thick.a.01.thick')\", 23), (\"Lemma('slurred.s.01.thick')\", 1), (\"Lemma('thick.s.02.thick')\", 5), (\"Lemma('thick.a.03.thick')\", 4)])\n",
      "collecting tokens for  hospitals\n",
      "indices:    {12256, 20193, 12260, 24964, 14312, 20209, 24950, 9207, 32733, 25215}\n",
      "dict_items([(\"Lemma('hospital.n.01.hospital')\", 4)])\n",
      "collecting tokens for  patients\n",
      "indices:    {4241, 4243, 27417, 27418, 27425, 31015, 4008, 4009, 10799, 1715, 31052, 722, 23635, 32723, 36442, 27360, 15845, 2279, 2282, 15857, 15858, 33267, 15860, 33270, 24951}\n",
      "dict_items([(\"Lemma('patient.n.01.patient')\", 13)])\n",
      "collecting tokens for  additional\n",
      "indices:    {23362, 4164, 14245, 23629, 16018, 15539, 32375, 33017, 11898, 15485}\n",
      "dict_items([])\n",
      "collecting tokens for  gained\n",
      "indices:    {31232, 9352, 23826, 26002, 25367, 3229, 1056, 290, 1828, 5285, 25904, 21936, 11444, 35254, 14392, 5177, 835, 1091, 2634, 27730, 13783, 31962, 21724, 23903, 23906, 5858, 26860, 15221, 12795, 31999}\n",
      "dict_items([(\"Lemma('profit.v.01.gain')\", 4), (\"Lemma('derive.v.02.gain')\", 13), (\"Lemma('advance.v.12.gain')\", 1), (\"Lemma('reach.v.01.gain')\", 2), (\"Lemma('gain.v.05.gain')\", 2), (\"Lemma('gain.v.07.gain')\", 1), (\"Lemma('acquire.v.05.gain')\", 6), (\"Lemma('gain.v.08.gain')\", 1)])\n",
      "collecting tokens for  supply\n",
      "indices:    {14721, 14210, 15489, 3848, 22793, 23696, 15504, 27936, 3621, 13095, 27177, 17580, 36527, 26040, 2753, 30402, 11589, 12870, 3784, 3785, 12489, 35404, 12494, 3794, 4825, 30431, 29791, 7010, 25445, 1767, 3817, 12524, 33011, 15093, 12159}\n",
      "dict_items([(\"Lemma('supply.v.01.supply')\", 11), (\"Lemma('supply.n.01.supply')\", 12), (\"Lemma('provision.n.02.supply')\", 2)])\n",
      "collecting tokens for  delegates\n",
      "indices:    {21701, 21705, 31210, 21226, 23830, 23835, 25500, 23838}\n",
      "dict_items([])\n",
      "collecting tokens for  forthcoming\n",
      "indices:    {20832, 31648, 27782, 25643, 24140, 25966, 28337, 27794, 22650}\n",
      "dict_items([])\n",
      "collecting tokens for  scheduled\n",
      "indices:    {32512, 24195, 18695, 32521, 2186, 24589, 657, 27412, 29336, 20377, 17566, 36511, 15531, 9904, 27064, 23868, 20799, 20166, 20809, 20171, 21453, 20180, 85, 26974, 20832, 25056, 224, 22248, 22380, 10093, 21362}\n",
      "dict_items([(\"Lemma('schedule.v.01.schedule')\", 19), (\"Lemma('schedule.v.02.schedule')\", 6), (\"Lemma('scheduled.a.01.scheduled')\", 1)])\n",
      "collecting tokens for  metal\n",
      "indices:    {30052, 11109, 27920, 14772, 24695, 29083, 33852, 20733}\n",
      "dict_items([(\"Lemma('metallic_element.n.01.metal')\", 2)])\n",
      "collecting tokens for  strip\n",
      "indices:    {29152, 21730, 22436, 29637, 18693, 29639, 18699, 29645, 5837, 22864, 6745, 30362, 29787, 29788, 29533, 22430, 8605}\n",
      "dict_items([(\"Lemma('strip.n.01.strip')\", 2), (\"Lemma('airstrip.n.01.strip')\", 2), (\"Lemma('deprive.v.01.strip')\", 2)])\n",
      "collecting tokens for  coal\n",
      "indices:    {25120, 23490, 23492, 23493, 36134, 23494, 23496, 14761, 23498, 23499, 34448, 29501}\n",
      "dict_items([(\"Lemma('coal.n.01.coal')\", 1)])\n",
      "collecting tokens for  peaceful\n",
      "indices:    {2308, 13117}\n",
      "dict_items([(\"Lemma('peaceful.a.01.peaceful')\", 2)])\n",
      "collecting tokens for  coexistence\n",
      "indices:    {25767, 2159, 25745, 25747, 25748, 27127, 23836, 25758}\n",
      "dict_items([(\"Lemma('coexistence.n.01.coexistence')\", 1)])\n",
      "collecting tokens for  armed\n",
      "indices:    {15489, 18418}\n",
      "dict_items([(\"Lemma('armed.a.01.armed')\", 1)])\n",
      "collecting tokens for  peace\n",
      "indices:    {22042, 12620, 25181, 25198}\n",
      "dict_items([(\"Lemma('peace.n.02.peace')\", 1)])\n",
      "collecting tokens for  everywhere\n",
      "indices:    {12784, 4988}\n",
      "dict_items([(\"Lemma('everywhere.r.01.everywhere')\", 2)])\n",
      "collecting tokens for  wood\n",
      "indices:    {29577, 22158, 19606, 27926, 29083, 25120, 29864, 24361, 19372, 10542, 34099, 8501, 29752, 698, 4925, 34109, 19520, 29902, 19283, 29907, 29910, 35160, 7385, 35035, 29661, 18016, 30690, 6371, 30692, 11109, 29802, 5359, 28658, 7795, 7156, 7158, 29818, 7807}\n",
      "dict_items([(\"Lemma('wood.n.01.wood')\", 14), (\"Lemma('forest.n.01.wood')\", 2)])\n",
      "collecting tokens for  hill\n",
      "indices:    {21129}\n",
      "dict_items([])\n",
      "collecting tokens for  rising\n",
      "indices:    {18849, 24996, 19241, 7221, 23382, 10555, 33213}\n",
      "dict_items([(\"Lemma('rise.v.01.rise')\", 3)])\n",
      "collecting tokens for  cemetery\n",
      "indices:    {6405}\n",
      "dict_items([])\n",
      "collecting tokens for  weakness\n",
      "indices:    {36226, 34307, 18435, 20484, 14088, 22665, 22671, 16280, 16281, 5659, 27804, 28458, 10030, 4016, 4017, 4018, 4019, 5688, 14011, 4030, 4033, 4034, 4035, 4037, 4050, 4051, 4052, 32850, 4056, 4057, 8155, 8285, 34284, 23535}\n",
      "dict_items([(\"Lemma('failing.n.01.weakness')\", 21), (\"Lemma('helplessness.n.01.weakness')\", 2), (\"Lemma('weakness.n.03.weakness')\", 1)])\n",
      "collecting tokens for  definite\n",
      "indices:    {32385, 22563, 25348, 9605, 4646, 33703, 22153, 32522, 34542, 13584, 9171, 3733, 30037, 14198, 35997, 3614}\n",
      "dict_items([(\"Lemma('definite.a.01.definite')\", 7)])\n",
      "collecting tokens for  covers\n",
      "indices:    {30721, 20994, 20995, 24580, 22289, 1690, 5674, 19244, 30765, 3379, 23091, 30006, 26681, 19517, 8126, 5695, 14414, 8921, 8929, 11373, 10741, 8954, 5372}\n",
      "dict_items([(\"Lemma('cover.v.03.cover')\", 2), (\"Lemma('blanket.n.01.cover')\", 7), (\"Lemma('screen.n.04.cover')\", 1), (\"Lemma('binding.n.05.cover')\", 1), (\"Lemma('cover.v.01.cover')\", 1), (\"Lemma('cover.v.05.cover')\", 1), (\"Lemma('cover.v.12.cover')\", 1), (\"Lemma('embrace.v.01.cover')\", 4), (\"Lemma('report.v.05.cover')\", 1), (\"Lemma('cover.v.02.cover')\", 1)])\n",
      "collecting tokens for  hunting\n",
      "indices:    {11269, 11270, 11278, 29080, 21657, 21660, 29111, 20029, 11205, 1873, 11862, 35545, 14426, 1882, 11867, 9308, 9309, 11881, 11884, 11890, 11893, 29178, 11902}\n",
      "dict_items([(\"Lemma('hunt.n.08.hunting')\", 13), (\"Lemma('hunt.n.07.hunting')\", 1), (\"Lemma('hunt.v.01.hunt')\", 1)])\n",
      "collecting tokens for  uncle\n",
      "indices:    {8811, 10947}\n",
      "dict_items([(\"Lemma('uncle.n.01.uncle')\", 1)])\n",
      "collecting tokens for  lovely\n",
      "indices:    {34305, 26979, 20932, 34697, 26379, 37138, 26419}\n",
      "dict_items([])\n",
      "collecting tokens for  abandon\n",
      "indices:    {14112, 13984, 28291, 25475, 2605, 17039, 30390, 1302, 17055}\n",
      "dict_items([(\"Lemma('abandon.v.01.abandon')\", 4), (\"Lemma('abandon.v.02.abandon')\", 2), (\"Lemma('abandon.v.04.abandon')\", 2), (\"Lemma('vacate.v.02.abandon')\", 1)])\n",
      "collecting tokens for  theatre\n",
      "indices:    {12681, 26957, 10800, 1777, 11061, 26519}\n",
      "dict_items([(\"Lemma('dramaturgy.n.01.theatre')\", 1), (\"Lemma('theater.n.01.theatre')\", 3)])\n",
      "collecting tokens for  dance\n",
      "indices:    {26976, 26979, 31907, 9701, 1924, 31530, 34090, 491, 31570, 2611, 26867, 25686, 10713, 27034, 26909, 1918}\n",
      "dict_items([(\"Lemma('dance.n.02.dance')\", 2), (\"Lemma('dance.n.01.dance')\", 3), (\"Lemma('dance.v.01.dance')\", 1), (\"Lemma('dance.v.02.dance')\", 1)])\n",
      "collecting tokens for  willie\n",
      "indices:    {22995}\n",
      "dict_items([])\n",
      "collecting tokens for  barnes\n",
      "indices:    {23137}\n",
      "dict_items([])\n",
      "collecting tokens for  count\n",
      "indices:    {19104, 37120, 22530, 900, 3439, 16179, 13558, 15799, 11453}\n",
      "dict_items([(\"Lemma('count.v.01.count')\", 5), (\"Lemma('count.n.01.count')\", 1)])\n",
      "collecting tokens for  loans\n",
      "indices:    {22016, 2753, 21761, 21769, 2769}\n",
      "dict_items([(\"Lemma('loan.n.01.loan')\", 1)])\n",
      "collecting tokens for  alone\n",
      "indices:    {26114, 4611, 36870, 27142, 19464, 5641, 3595, 36875, 12304, 30234, 3610, 35358, 1566, 1571, 5161, 17461, 29237, 26168, 4153, 14907, 3648, 10821, 20554, 33358, 16974, 11345, 17495, 19032, 6236, 19039, 1120, 15969, 18020, 14949, 5221, 28269, 19568, 33905, 2679, 13963, 1165, 3228, 33438, 11430, 19632, 36022, 17591, 17593, 19641, 17595, 1729, 7363, 9412, 20178, 3798, 27350, 33499, 13570, 12036, 9995, 26380, 20237, 13583, 1299, 18199, 24349, 5415, 16168, 1833, 4926, 13631, 8521, 1353, 1886, 30560, 34666, 19822, 1393, 32625, 35188, 35189, 22392, 35198, 16258, 15752, 9609, 9610, 9617, 1447, 1448, 13737, 30124, 12206, 26548, 33717, 30138, 23994, 10173, 30150, 1992, 32205, 23004, 3037, 15839, 9191, 33769, 1523, 2549, 10744, 5631}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('alone.r.02.alone')\", 23), (\"Lemma('alone.s.02.alone')\", 3), (\"Lemma('entirely.r.02.alone')\", 26), (\"Lemma('alone.s.01.alone')\", 14), (\"Lemma('alone.s.03.alone')\", 1)])\n",
      "collecting tokens for  writer\n",
      "indices:    {2363, 403, 33102, 865}\n",
      "dict_items([(\"Lemma('writer.n.01.writer')\", 2)])\n",
      "collecting tokens for  effectively\n",
      "indices:    {33121, 12994, 27651, 6570, 174, 27895, 11575, 4606}\n",
      "dict_items([(\"Lemma('efficaciously.r.01.effectively')\", 4), (\"Lemma('effectively.r.02.effectively')\", 1)])\n",
      "collecting tokens for  students\n",
      "indices:    {21505, 13204, 33102, 21375}\n",
      "dict_items([(\"Lemma('student.n.01.student')\", 1)])\n",
      "collecting tokens for  functional\n",
      "indices:    {736, 4261, 22149, 33097, 33099, 32939, 32749, 33103, 4273, 3829, 33110, 32952, 32954}\n",
      "dict_items([(\"Lemma('functional.a.01.functional')\", 3), (\"Lemma('functional.a.02.functional')\", 1)])\n",
      "collecting tokens for  classes\n",
      "indices:    {28584, 16181}\n",
      "dict_items([(\"Lemma('class.n.01.class')\", 1)])\n",
      "collecting tokens for  earth\n",
      "indices:    {1458, 1663, 3310, 36039}\n",
      "dict_items([(\"Lemma('land.n.04.earth')\", 1), (\"Lemma('earth.n.02.earth')\", 1), (\"Lemma('earth.n.01.Earth')\", 1)])\n",
      "collecting tokens for  mighty\n",
      "indices:    {35008, 36291, 18251, 11692, 25267, 11252, 35381, 20222}\n",
      "dict_items([(\"Lemma('mighty.r.01.mighty')\", 2), (\"Lemma('mighty.s.01.mighty')\", 1)])\n",
      "collecting tokens for  megaton\n",
      "indices:    {835, 25764, 25414, 25416, 817, 20946, 819, 821, 822}\n",
      "dict_items([])\n",
      "collecting tokens for  bombs\n",
      "indices:    {814, 30339, 18697, 27922, 2579, 27923, 2580, 27927, 30370, 25261, 25262, 30383, 18736, 817, 25264, 30387, 819, 25265, 822, 818, 25269, 18738, 25276, 30268, 25278, 25280, 25161, 25165, 30289, 20946, 30318, 18673, 30325, 30330}\n",
      "dict_items([(\"Lemma('bomb.n.01.bomb')\", 7)])\n",
      "collecting tokens for  peasants\n",
      "indices:    {7891, 7919}\n",
      "dict_items([(\"Lemma('peasant.n.01.peasant')\", 2)])\n",
      "collecting tokens for  explanations\n",
      "indices:    {10626, 2626, 2627, 4674, 2570, 784, 19441, 14035, 29396, 35477, 2582, 9240, 34650, 26843}\n",
      "dict_items([(\"Lemma('explanation.n.02.explanation')\", 2), (\"Lemma('explanation.n.01.explanation')\", 8)])\n",
      "collecting tokens for  explained\n",
      "indices:    {22529, 10626, 21000, 9354, 22540, 20365, 7566, 27534, 20366, 15249, 10772, 2196, 9880, 9241, 27800, 15772, 287, 15775, 35743, 34210, 6176, 2982, 7593, 20782, 2866, 17330, 19764, 21426, 36659, 19767, 10680, 33214, 322, 13763, 4931, 34375, 10696, 36687, 22992, 27263, 22227, 36563, 15572, 33237, 4821, 36691, 343, 33244, 18278, 8298, 13040, 22774, 2809, 29946, 15739, 36988, 12414, 15231}\n",
      "dict_items([(\"Lemma('explain.v.01.explain')\", 26), (\"Lemma('explain.v.02.explain')\", 6), (\"Lemma('excuse.v.03.explain')\", 1)])\n",
      "collecting tokens for  leaving\n",
      "indices:    {37138, 853, 25439}\n",
      "dict_items([(\"Lemma('leave.v.02.leave')\", 2), (\"Lemma('leave.v.01.leave')\", 1)])\n",
      "collecting tokens for  bit\n",
      "indices:    {9747, 18451, 1560, 1561, 26650, 36379, 9245, 19501, 9783, 25661, 1598, 17476, 80, 10837, 89, 609, 10347, 1135, 26239, 1157, 10889, 14482, 10909, 1183, 17069, 7857, 29366, 29878, 10936, 33462, 26302, 29902, 33487, 29909, 29912, 26331, 10465, 10985, 16108, 749, 19189, 17659, 36098, 33551, 24336, 8466, 6930, 23834, 29471, 29986, 29989, 23846, 11052, 24390, 2376, 35660, 1359, 23386, 29038, 30584, 18808, 22907, 10626, 10668, 34233, 13763, 6092, 13775, 20953, 15842, 17380, 9713, 29170, 9715, 21494, 1020, 29181}\n",
      "dict_items([(\"Lemma('bite.v.03.bite')\", 1), (\"Lemma('bit.n.02.bit')\", 3), (\"Lemma('bite.v.01.bite')\", 2), (\"Lemma('spot.n.10.bit')\", 6), (\"Lemma('moment.n.02.bit')\", 1), (\"Lemma('bit.n.05.bit')\", 1), (\"Lemma('bite.n.01.bite')\", 1), (\"Lemma('piece.n.05.bit')\", 1)])\n",
      "collecting tokens for  bitter\n",
      "indices:    {12256, 23810, 14437, 22601, 10858, 4748, 16941, 20236, 8946, 17203, 14643, 23410, 887, 7032, 12380, 20479}\n",
      "dict_items([(\"Lemma('acrimonious.s.01.bitter')\", 5), (\"Lemma('acerb.s.02.bitter')\", 1), (\"Lemma('bitter.s.02.bitter')\", 4)])\n",
      "collecting tokens for  naked\n",
      "indices:    {35561, 8370, 34911, 19527}\n",
      "dict_items([(\"Lemma('bare.s.01.naked')\", 2)])\n",
      "collecting tokens for  span\n",
      "indices:    {3918}\n",
      "dict_items([(\"Lemma('span.n.01.span')\", 1)])\n",
      "collecting tokens for  anyway\n",
      "indices:    {9890, 19046, 20648, 18601, 6730, 36626, 36308, 17885}\n",
      "dict_items([(\"Lemma('anyhow.r.01.anyway')\", 5)])\n",
      "collecting tokens for  insisted\n",
      "indices:    {23686, 35725, 11661, 142, 6801, 27282, 21527, 34475, 36150, 31673, 10683, 6972, 14529, 1347, 14533, 12613, 12614, 30925, 20699, 31967, 37089, 36071, 23148, 36982, 25081, 16126}\n",
      "dict_items([(\"Lemma('insist.v.01.insist')\", 23), (\"Lemma('importune.v.01.insist')\", 3)])\n",
      "collecting tokens for  hope\n",
      "indices:    {33369, 19394, 16862, 6126}\n",
      "dict_items([(\"Lemma('hope.n.01.hope')\", 1), (\"Lemma('hope.n.02.hope')\", 1), (\"Lemma('hope.v.02.hope')\", 1)])\n",
      "collecting tokens for  heater\n",
      "indices:    {7489, 36136, 25224, 30571, 30191, 36150, 36151, 15193, 36153, 15195, 34332}\n",
      "dict_items([(\"Lemma('heater.n.01.heater')\", 1)])\n",
      "collecting tokens for  spectators\n",
      "indices:    {704, 380}\n",
      "dict_items([(\"Lemma('spectator.n.01.spectator')\", 1), (\"Lemma('spectator_pump.n.01.spectator')\", 1)])\n",
      "collecting tokens for  seats\n",
      "indices:    {23906, 20590, 2385, 26868, 22230, 29750, 29817, 10714, 20604, 23103}\n",
      "dict_items([(\"Lemma('seat.n.04.seat')\", 1), (\"Lemma('seat.n.01.seat')\", 1)])\n",
      "collecting tokens for  opposite\n",
      "indices:    {34040, 17536, 29574, 6921, 2191, 29587, 536, 13978, 26532, 13605, 19511, 29368, 33219, 12619, 33613, 26830, 29389, 26829, 33109, 26583, 5209, 30307, 13423, 16111, 7154, 11384, 31993}\n",
      "dict_items([(\"Lemma('opposition.n.04.opposite')\", 1), (\"Lemma('opposite.s.01.opposite')\", 5), (\"Lemma('opposite.a.02.opposite')\", 2), (\"Lemma('antonym.n.01.opposite')\", 1), (\"Lemma('opposite.s.03.opposite')\", 1), (\"Lemma('opposite.s.05.opposite')\", 1)])\n",
      "collecting tokens for  45\n",
      "indices:    {28801, 22533, 25224, 28937, 15497, 29580, 22541, 27537, 28567, 28571, 29090, 29095, 29624, 2750, 3007, 21312, 324, 17604, 3015, 22371, 22372, 23912, 21229, 20463, 21622, 374}\n",
      "dict_items([])\n",
      "collecting tokens for  .22\n",
      "indices:    {29090, 29122, 29092, 29093, 29095, 29097, 29100, 29071, 29073, 29138, 29076, 21209, 29118}\n",
      "dict_items([])\n",
      "collecting tokens for  magazine\n",
      "indices:    {12043, 29940, 10694}\n",
      "dict_items([(\"Lemma('magazine.n.01.magazine')\", 1)])\n",
      "collecting tokens for  holds\n",
      "indices:    {22665, 20489, 32907, 12301, 14353, 28318, 162, 5797, 30387, 29887, 26817, 24258, 26822, 30151, 25689, 22874, 13280, 26095, 29169, 25205, 13558, 26999, 2424, 14585, 4863}\n",
      "dict_items([(\"Lemma('keep.v.01.hold')\", 3), (\"Lemma('hold.v.03.hold')\", 1), (\"Lemma('retain.v.03.hold')\", 1), (\"Lemma('have.v.01.hold')\", 5), (\"Lemma('deem.v.01.hold')\", 2), (\"Lemma('restrain.v.03.hold')\", 1), (\"Lemma('hold.v.17.hold')\", 1), (\"Lemma('harbor.v.01.hold')\", 3), (\"Lemma('prevail.v.02.hold')\", 1), (\"Lemma('hold.v.10.hold')\", 1)])\n",
      "collecting tokens for  rifles\n",
      "indices:    {903, 8598, 29080, 8602, 29082, 23326, 29087, 29092, 35494, 29095, 21415, 7849, 17584, 25781, 25782, 35402, 35410, 29403, 35427, 8561}\n",
      "dict_items([(\"Lemma('rifle.n.01.rifle')\", 6)])\n",
      "collecting tokens for  oak\n",
      "indices:    {21443}\n",
      "dict_items([])\n",
      "collecting tokens for  lodge\n",
      "indices:    {3030}\n",
      "dict_items([(\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  district\n",
      "indices:    {21205, 22874, 20685}\n",
      "dict_items([])\n",
      "collecting tokens for  attracted\n",
      "indices:    {32482, 11203, 23652, 35812, 34982, 11175, 20812, 32109, 14479, 5332, 14836, 28149, 17558, 3194, 24124, 20509}\n",
      "dict_items([(\"Lemma('attract.v.01.attract')\", 9), (\"Lemma('attract.v.02.attract')\", 4)])\n",
      "collecting tokens for  shelter\n",
      "indices:    {15106, 15108, 35208, 15112, 15115, 15117, 15118, 15119, 15120, 15121, 15122, 15123, 15124, 15126, 15127, 15136, 15137, 15139, 15143, 15146, 15150, 15152, 27442, 30516, 15156, 15168, 27840, 15171, 7113, 12107, 15183, 15184, 15185, 15186, 15187, 21972, 15188, 15191, 15194, 15195, 15072, 15077, 15078, 15208, 15082, 15211, 8683, 8685, 25071, 15087, 25073, 21233, 25075, 25076, 15095, 15096, 15097, 15099}\n",
      "dict_items([(\"Lemma('shelter.n.01.shelter')\", 26), (\"Lemma('shelter.v.01.shelter')\", 1), (\"Lemma('shelter.n.02.shelter')\", 1)])\n",
      "collecting tokens for  explaining\n",
      "indices:    {16321, 21793, 2150, 31592, 34472, 33136, 4821, 26807, 9369, 34047}\n",
      "dict_items([(\"Lemma('explain.v.01.explain')\", 9), (\"Lemma('excuse.v.03.explain')\", 1)])\n",
      "collecting tokens for  cops\n",
      "indices:    {33989, 9675, 34027, 17007, 17167, 2449, 19888, 12690, 16495, 17012, 9780, 16978, 17020, 19517, 34047}\n",
      "dict_items([(\"Lemma('bull.n.05.cop')\", 12)])\n",
      "collecting tokens for  dollar\n",
      "indices:    {21602, 11816, 17866, 13132, 27311, 19582}\n",
      "dict_items([(\"Lemma('dollar.n.02.dollar')\", 2), (\"Lemma('dollar.n.01.dollar')\", 1)])\n",
      "collecting tokens for  houston\n",
      "indices:    {23323}\n",
      "dict_items([])\n",
      "collecting tokens for  democratic\n",
      "indices:    {23649, 20484}\n",
      "dict_items([])\n",
      "collecting tokens for  newspaper\n",
      "indices:    {2307, 7302, 14346, 10647, 10651, 36123, 13727, 10656, 10657, 10660, 7974, 34216, 13229, 30894, 13231, 30718, 34232, 14137, 21434, 14653, 36929, 36937, 20044, 32463, 14931, 14932, 13398, 34263, 24187, 1378, 24675, 9188, 28396, 12268, 2670, 1392, 27379, 27387, 33278}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('newspaper.n.01.newspaper')\", 17), (\"Lemma('newspaper.n.02.newspaper')\", 4)])\n",
      "collecting tokens for  daily\n",
      "indices:    {21824, 11521, 11936, 22373, 11558, 3335, 36071, 5157, 32453, 23563, 15756, 12782, 25331, 28093, 16571, 5308, 4029, 23807}\n",
      "dict_items([(\"Lemma('daily.r.01.daily')\", 3), (\"Lemma('daily_variation.n.01.daily_variation')\", 1)])\n",
      "collecting tokens for  post\n",
      "indices:    {24218, 21643}\n",
      "dict_items([])\n",
      "collecting tokens for  stated\n",
      "indices:    {3701, 32494, 16406}\n",
      "dict_items([(\"Lemma('state.v.01.state')\", 2), (\"Lemma('submit.v.02.state')\", 1)])\n",
      "collecting tokens for  murderer\n",
      "indices:    {5280, 12641, 36898, 17318, 17288, 17129, 17324, 34606, 13967, 17136, 36944, 35830, 36918, 12218}\n",
      "dict_items([(\"Lemma('murderer.n.01.murderer')\", 9)])\n",
      "collecting tokens for  blood\n",
      "indices:    {11392, 6913, 35588, 3850, 11411, 35604, 30102, 3992, 7962, 10360, 36510, 36898, 10402, 4007, 34088, 4009, 4010, 6317, 3504, 30771, 3508, 4020, 1716, 8120, 7101, 23231, 18243, 3784, 36426, 3537, 3793, 3799, 22488, 17370, 7645, 22878, 2272, 28263, 18407, 3816, 3566, 12911, 14320, 27250, 11380, 11384, 27515, 11388, 11391}\n",
      "dict_items([(\"Lemma('blood.n.01.blood')\", 24), (\"Lemma('lineage.n.01.blood')\", 1)])\n",
      "collecting tokens for  associates\n",
      "indices:    {30475, 22502}\n",
      "dict_items([])\n",
      "collecting tokens for  assistance\n",
      "indices:    {32130, 32134, 32135, 13, 4628, 32164, 32170, 2733, 32177, 11442, 15417, 32454, 2761, 32860, 2783, 4580, 32357, 11499, 16241, 32502, 32507}\n",
      "dict_items([(\"Lemma('aid.n.01.assistance')\", 2), (\"Lemma('aid.n.02.assistance')\", 8)])\n",
      "collecting tokens for  republicans\n",
      "indices:    {20450}\n",
      "dict_items([])\n",
      "collecting tokens for  400\n",
      "indices:    {11402, 29708, 15244, 24724, 27548, 23197, 21794, 13097, 11312, 30387, 21577, 457, 4051, 12511, 21858, 12791, 12793, 21371, 29436}\n",
      "dict_items([])\n",
      "collecting tokens for  cost\n",
      "indices:    {35968, 24966, 7, 15114, 32267, 24970, 29709, 17166, 12174, 5136, 12175, 25101, 15125, 538, 15516, 14748, 11936, 11809, 11684, 172, 32556, 5425, 27316, 12086, 1337, 23742, 20671, 19522, 31045, 30151, 5960, 21972, 15485, 5463, 32760, 16345, 20186, 16346, 32348, 12121, 11735, 11615, 5466, 25176, 23523, 5478, 11751, 12137, 12139, 107, 20204, 32367, 1904, 16369, 28669, 8191, 29172, 5489, 11766, 32502, 16248, 16372, 30714, 29947, 12157, 13182, 16383}\n",
      "dict_items([(\"Lemma('cost.v.02.cost')\", 7), (\"Lemma('cost.n.01.cost')\", 24), (\"Lemma('cost.v.01.cost')\", 8), (\"Lemma('monetary_value.n.01.cost')\", 4), (\"Lemma('price.n.03.cost')\", 2)])\n",
      "collecting tokens for  bottom\n",
      "indices:    {8065, 29890, 34052, 15397, 29574, 31558, 3655, 12872, 3142, 29772, 6030, 29746, 17747, 31570, 30074, 7676, 29629}\n",
      "dict_items([(\"Lemma('bottom.n.01.bottom')\", 4), (\"Lemma('bottom.n.02.bottom')\", 2)])\n",
      "collecting tokens for  sink\n",
      "indices:    {14528, 16833, 9411, 5575, 20137, 10603, 29708, 9452, 9422, 18608, 37008, 22962, 30035, 10807, 29816, 3035, 13436}\n",
      "dict_items([(\"Lemma('sink.v.01.sink')\", 1), (\"Lemma('sink.n.01.sink')\", 4), (\"Lemma('sink.v.02.sink')\", 2), (\"Lemma('bury.v.05.sink')\", 1), (\"Lemma('sink.v.04.sink')\", 1)])\n",
      "collecting tokens for  hardware\n",
      "indices:    {20059}\n",
      "dict_items([])\n",
      "collecting tokens for  trained\n",
      "indices:    {19332, 900, 903, 11784, 14345, 30218, 32146, 4627, 2582, 6807, 15766, 15001, 16282, 2331, 1948, 31389, 16290, 4387, 25258, 33068, 11186, 23222, 32183, 1919, 15675, 34748, 36671, 25025, 28993, 25538, 8260, 7618, 26444, 23249, 34387, 21206, 12386, 25834, 29040, 29041, 32628, 14070, 29175, 11260, 1917, 16255}\n",
      "dict_items([(\"Lemma('trained.a.01.trained')\", 8), (\"Lemma('prepare.v.05.train')\", 5), (\"Lemma('train.v.01.train')\", 8), (\"Lemma('discipline.v.01.train')\", 4), (\"Lemma('train.v.02.train')\", 5), (\"Lemma('educate.v.03.train')\", 1)])\n",
      "collecting tokens for  gibson\n",
      "indices:    {1174}\n",
      "dict_items([])\n",
      "collecting tokens for  reported\n",
      "indices:    {20480, 20482, 22019, 21510, 21512, 12810, 3101, 20511, 25123, 4133, 36902, 21542, 20518, 21547, 22062, 24626, 3138, 5189, 24133, 30282, 26728, 22638, 9839, 21617, 14966, 32892, 32893, 32896, 24712, 137, 3749, 17582, 174, 21175, 21688, 27321, 2244, 2246, 11473, 26852, 21227, 21228, 20718, 2804, 12532, 27382, 12536, 23801, 20227, 9991, 13074, 33047, 12572, 27425, 33079, 22329, 25403, 24901, 838, 25414, 20810, 24911, 20303, 23890, 23894, 23898, 1393, 10105, 19329, 33156, 33158, 12684, 34705, 19345, 33173, 21911, 33177, 1439, 2976, 10656, 10151, 21416, 21418, 10669, 5041, 4017, 27587, 25030, 12745, 14800, 25053, 36829, 15327, 15328, 12773, 33256, 14830, 20478}\n",
      "dict_items([(\"Lemma('report.v.04.report')\", 4), (\"Lemma('report.v.01.report')\", 26), (\"Lemma('report.v.03.report')\", 4), (\"Lemma('report.v.02.report')\", 26), (\"Lemma('report.v.06.report')\", 1), (\"Lemma('reported.a.01.reported')\", 2)])\n",
      "collecting tokens for  feeds\n",
      "indices:    {11395, 11556, 2888, 11560, 23691, 2350, 11696, 20273, 1439}\n",
      "dict_items([(\"Lemma('feed.v.04.feed')\", 2), (\"Lemma('feed.v.05.feed')\", 1), (\"Lemma('feed.v.06.feed')\", 1), (\"Lemma('feed.n.01.feed')\", 1), (\"Lemma('feed.v.03.feed')\", 1)])\n",
      "collecting tokens for  statistics\n",
      "indices:    {608, 33057, 14756, 33060, 33055, 33061, 24009, 1392, 33013, 33051, 33084, 351}\n",
      "dict_items([(\"Lemma('statistic.n.01.statistic')\", 4)])\n",
      "collecting tokens for  increasing\n",
      "indices:    {4499, 20379, 25652}\n",
      "dict_items([(\"Lemma('increasing.a.01.increasing')\", 1), (\"Lemma('increase.v.02.increase')\", 1)])\n",
      "collecting tokens for  numbers\n",
      "indices:    {16289, 4354, 33955, 28868, 12804, 15489, 3177, 16298, 22249, 24218, 30194, 28915, 36660, 33494, 15799, 22298, 32957, 28863}\n",
      "dict_items([(\"Lemma('number.n.01.number')\", 4), (\"Lemma('number.n.02.number')\", 1)])\n",
      "collecting tokens for  irish\n",
      "indices:    {12641}\n",
      "dict_items([(\"Lemma('irish.a.01.Irish')\", 1)])\n",
      "collecting tokens for  news\n",
      "indices:    {26753, 10667, 25238}\n",
      "dict_items([(\"Lemma('news.n.02.news')\", 1)])\n",
      "collecting tokens for  allow\n",
      "indices:    {7040, 21376, 2836, 29078, 13464, 13471, 28839, 29607, 8110, 28849, 3766, 13244, 29628, 29633, 30404, 15183, 18640, 14417, 30425, 16351, 30048, 33252, 8037, 16356, 22889, 32761, 34939}\n",
      "dict_items([(\"Lemma('permit.v.01.allow')\", 11), (\"Lemma('let.v.01.allow')\", 11), (\"Lemma('allow.v.03.allow')\", 2), (\"Lemma('leave.v.06.allow_for')\", 2), (\"Lemma('allow.v.06.allow')\", 1)])\n",
      "collecting tokens for  priest\n",
      "indices:    {13408, 2179, 1390, 1427, 1430, 2170, 2172, 2173, 2175, 1439}\n",
      "dict_items([(\"Lemma('priest.n.02.priest')\", 5), (\"Lemma('priest.n.01.priest')\", 5)])\n",
      "collecting tokens for  requested\n",
      "indices:    {23361, 14147, 27270, 1439, 8300, 15470, 24884, 33147, 23359}\n",
      "dict_items([(\"Lemma('request.v.02.request')\", 4), (\"Lemma('request.v.01.request')\", 4)])\n",
      "collecting tokens for  secondary\n",
      "indices:    {14210, 32900, 27789, 16015, 1439, 543, 27554, 23223, 3775, 3777, 25542, 14673, 14803, 14808, 3424, 3426, 11881, 12283, 32894}\n",
      "dict_items([(\"Lemma('secondary.a.01.secondary')\", 11)])\n",
      "collecting tokens for  masters\n",
      "indices:    {521}\n",
      "dict_items([])\n",
      "collecting tokens for  startling\n",
      "indices:    {33761, 9699, 31972, 29127, 2123, 23097, 1487, 34425, 31794, 9684, 11092, 26133, 2137, 6843, 2140, 32893, 1439}\n",
      "dict_items([(\"Lemma('startling.s.01.startling')\", 9)])\n",
      "collecting tokens for  respectable\n",
      "indices:    {17122, 8194, 6085, 27110, 4807, 12229, 1422, 23248, 13778, 5332, 11285, 31732, 26520, 13180, 28125, 13950, 1439}\n",
      "dict_items([(\"Lemma('goodly.s.01.respectable')\", 2), (\"Lemma('respectable.a.01.respectable')\", 5), (\"Lemma('estimable.s.02.respectable')\", 5)])\n",
      "collecting tokens for  operation\n",
      "indices:    {12704, 7969, 14915, 20356, 32453, 11751, 23530, 22700, 32749, 14959, 23376, 12113, 23761, 15412, 5463, 32472, 30393, 25}\n",
      "dict_items([(\"Lemma('operation.n.01.operation')\", 1), (\"Lemma('operation.n.05.operation')\", 1), (\"Lemma('operation.n.03.operation')\", 3), (\"Lemma('operation.n.02.operation')\", 3)])\n",
      "collecting tokens for  constitute\n",
      "indices:    {3777, 4708, 32171, 13675, 3373, 14618, 15920, 15858, 25973, 23670, 14711, 27738, 29051, 16382, 1439}\n",
      "dict_items([(\"Lemma('constitute.v.01.constitute')\", 15)])\n",
      "collecting tokens for  one-third\n",
      "indices:    {3139, 15654, 13843, 21972, 27577, 24125, 1439}\n",
      "dict_items([(\"Lemma('one-third.n.01.one-third')\", 4)])\n",
      "collecting tokens for  generation\n",
      "indices:    {32120, 32106}\n",
      "dict_items([])\n",
      "collecting tokens for  mass\n",
      "indices:    {10481}\n",
      "dict_items([(\"Lemma('mass.n.04.Mass')\", 1)])\n",
      "collecting tokens for  suffered\n",
      "indices:    {21632, 21633, 20741, 14470, 647, 12694, 6038, 923, 6824, 27180, 13614, 24750, 27184, 4024, 4928, 13377, 328, 2255, 19666, 16594, 19291, 36443, 31457, 15714, 4834, 15844, 37113, 21480, 5352, 13035, 15728, 21361, 27126, 4857}\n",
      "dict_items([(\"Lemma('suffer.v.02.suffer')\", 12), (\"Lemma('suffer.v.05.suffer')\", 3), (\"Lemma('digest.v.03.suffer')\", 5), (\"Lemma('suffer.v.01.suffer')\", 7), (\"Lemma('suffer.v.03.suffer')\", 5), (\"Lemma('suffer.v.08.suffer')\", 1)])\n",
      "collecting tokens for  arrested\n",
      "indices:    {21475, 21476, 21539, 23172, 21416, 21257, 21673, 21419, 5036, 21546, 12681, 21777, 36851, 21301, 25782, 28280, 21275}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('collar.v.01.arrest')\", 17)])\n",
      "collecting tokens for  submarine\n",
      "indices:    {21250, 21251, 21257, 21291, 21292, 11407, 23326, 28501, 182, 31262, 21247}\n",
      "dict_items([(\"Lemma('submarine.n.01.submarine')\", 1)])\n",
      "collecting tokens for  christmas\n",
      "indices:    {29047}\n",
      "dict_items([])\n",
      "collecting tokens for  testified\n",
      "indices:    {21315, 18214, 21257, 21961, 21297, 21754, 22045, 21247}\n",
      "dict_items([(\"Lemma('testify.v.01.testify')\", 8)])\n",
      "collecting tokens for  surprisingly\n",
      "indices:    {36640, 14055, 35528, 29099, 12047, 7281, 24626, 3761, 5617, 16184, 2461}\n",
      "dict_items([(\"Lemma('surprisingly.r.01.surprisingly')\", 5), (\"Lemma('amazingly.r.01.surprisingly')\", 2)])\n",
      "collecting tokens for  stories\n",
      "indices:    {7959}\n",
      "dict_items([(\"Lemma('narrative.n.01.story')\", 1)])\n",
      "collecting tokens for  citizen\n",
      "indices:    {27168, 11202, 2307, 37095, 25387, 1932, 23565, 34027, 32016, 9681, 5328, 12242, 25840, 14294, 24150, 34682, 24220}\n",
      "dict_items([(\"Lemma('citizen.n.01.citizen')\", 6)])\n",
      "collecting tokens for  television\n",
      "indices:    {1024, 37059, 11108, 19525, 15846, 31294, 2158, 31794, 1431, 986, 11165, 2423, 2047}\n",
      "dict_items([(\"Lemma('television.n.01.television')\", 6), (\"Lemma('television_receiver.n.01.television')\", 1)])\n",
      "collecting tokens for  screen\n",
      "indices:    {26254, 9882, 11418, 30875, 24092, 30874, 24608, 10533, 37164, 308, 22068, 25790, 19007, 25925, 3271, 9674, 2378, 2380, 12877, 11084, 24396, 3302, 21479, 2409, 1005, 10483, 2430}\n",
      "dict_items([(\"Lemma('screen.n.01.screen')\", 4), (\"Lemma('screen.n.03.screen')\", 2), (\"Lemma('screen.v.01.screen')\", 2), (\"Lemma('screen.n.04.screen')\", 2), (\"Lemma('blind.n.03.screen')\", 1), (\"Lemma('screen.v.02.screen')\", 2)])\n",
      "collecting tokens for  reporters\n",
      "indices:    {36929, 24131, 5157, 7336, 5896, 21754, 25928, 20492, 20494, 24111, 9818, 30847}\n",
      "dict_items([(\"Lemma('reporter.n.01.reporter')\", 4)])\n",
      "collecting tokens for  seeing\n",
      "indices:    {9248, 36992, 18339, 35715, 31431, 4935, 23021, 4206, 34324, 29979, 34431}\n",
      "dict_items([(\"Lemma('see.v.01.see')\", 9), (\"Lemma('understand.v.02.see')\", 1), (\"Lemma('see.v.10.see')\", 1)])\n",
      "collecting tokens for  exhibited\n",
      "indices:    {1346, 964, 28646, 5319, 3574, 21593, 22204, 3517}\n",
      "dict_items([(\"Lemma('expose.v.03.exhibit')\", 5), (\"Lemma('exhibit.v.01.exhibit')\", 2), (\"Lemma('show.v.01.exhibit')\", 1)])\n",
      "collecting tokens for  gallery\n",
      "indices:    {22539, 25700}\n",
      "dict_items([])\n",
      "collecting tokens for  nov.\n",
      "indices:    {27061}\n",
      "dict_items([])\n",
      "collecting tokens for  languages\n",
      "indices:    {14466, 16138, 9996, 16155, 16157, 16158, 24738, 16172, 20528, 22450, 16183, 16058, 16063, 16196, 16199, 16206, 16081, 16213, 16094, 16095, 14177, 10209, 24931, 26347, 757, 23542, 16124}\n",
      "dict_items([(\"Lemma('speech.n.02.language')\", 2), (\"Lemma('language.n.01.language')\", 16)])\n",
      "collecting tokens for  analysis\n",
      "indices:    {14088, 4735, 15763, 15764, 16154, 3100, 30237, 3102, 33057, 3108, 15783, 15784, 2476, 4653, 3887, 23601, 33079, 25911, 15803, 15934, 16063, 15813, 15686, 32969, 15689, 16076, 26189, 16077, 32592, 17873, 15696, 3925, 5463, 32984, 31967, 16097, 15842, 15973, 5478, 32105, 26090, 32497, 15730, 16114, 15734, 24060, 32509, 24062, 3327}\n",
      "dict_items([(\"Lemma('analysis.n.01.analysis')\", 26), (\"Lemma('analysis.n.02.analysis')\", 4)])\n",
      "collecting tokens for  skilled\n",
      "indices:    {16258, 7939, 11267, 16273, 16274, 23445, 30233, 4641, 16301, 16307, 11828, 32183, 16314, 10592, 16230, 30570, 16237, 887, 16254, 16255}\n",
      "dict_items([(\"Lemma('skilled.a.01.skilled')\", 11), (\"Lemma('skilled_worker.n.01.skilled_worker')\", 1)])\n",
      "collecting tokens for  chance\n",
      "indices:    {34178, 19075, 32902, 22921, 24845, 19085, 19217, 24475, 6056, 35371, 26415, 18223, 28603, 24779, 31953, 33494, 20069, 21094, 18664, 16490, 36972, 4845, 10352, 6899, 20342, 19831, 13432, 34428}\n",
      "dict_items([(\"Lemma('casual.s.04.chance')\", 1), (\"Lemma('opportunity.n.01.chance')\", 9), (\"Lemma('luck.n.02.chance')\", 1), (\"Lemma('gamble.v.01.chance')\", 1)])\n",
      "collecting tokens for  finds\n",
      "indices:    {16130, 25733, 12938, 912, 13969, 12050, 27801, 12059, 11294, 30497, 31141, 13991, 13735, 13739, 13869, 13239, 31934, 21952, 30153, 13770, 27217, 32087, 2522, 27869, 14685, 15841, 15848, 24811, 26860, 26989, 26222, 36977, 15859, 3067, 4988}\n",
      "dict_items([(\"Lemma('discover.v.03.find')\", 1), (\"Lemma('detect.v.01.find')\", 7), (\"Lemma('find.v.05.find')\", 9), (\"Lemma('determine.v.01.find')\", 2), (\"Lemma('witness.v.02.find')\", 7), (\"Lemma('find.v.13.find')\", 1), (\"Lemma('find.v.01.find')\", 4), (\"Lemma('rule.v.04.find')\", 1)])\n",
      "collecting tokens for  enables\n",
      "indices:    {4704, 32548, 13287, 33000, 27271, 23442, 23545, 31934}\n",
      "dict_items([(\"Lemma('enable.v.01.enable')\", 8)])\n",
      "collecting tokens for  create\n",
      "indices:    {22496, 25826, 28611, 30793, 8298, 22793, 14221, 27958, 8311, 3486}\n",
      "dict_items([(\"Lemma('make.v.03.create')\", 10)])\n",
      "collecting tokens for  imagination\n",
      "indices:    {19723, 16654, 22290, 30738, 19094, 30743, 30745, 30748, 11804, 11678, 25633, 9900, 27952, 13619, 11443, 25656, 31934, 27838, 32064, 11329, 25673, 13645, 2643, 14676, 11093, 1236, 33366, 13653, 1242, 11227, 16219, 26844, 25436, 17760, 30819, 26211, 1767, 7276, 13808, 9585, 27378, 24051, 4212, 5237}\n",
      "dict_items([(\"Lemma('resource.n.03.imagination')\", 4), (\"Lemma('imagination.n.01.imagination')\", 15), (\"Lemma('imagination.n.02.imagination')\", 6)])\n",
      "collecting tokens for  pure\n",
      "indices:    {3234, 32035, 28132, 10788, 31976, 3240, 2222, 31887, 31856, 1718, 23542, 13624, 13625, 12410, 2363, 14488, 19550, 12159}\n",
      "dict_items([(\"Lemma('pure.a.01.pure')\", 11)])\n",
      "collecting tokens for  role\n",
      "indices:    {32261, 32271, 26639, 15378, 26642, 13343, 30240, 1059, 24611, 24102, 24103, 3624, 31806, 13382, 31818, 22092, 20558, 13392, 31825, 27233, 1131, 32365, 4209, 4212, 26232, 26238, 19072, 26243, 14469, 4746, 5266, 3230, 4255, 1190, 13993, 15530, 6837, 9397, 4279, 26297, 1212, 26301, 11967, 27846, 27847, 11979, 11982, 27858, 21715, 27872, 27884, 37115, 14592, 23300, 2323, 37147, 37153, 28471, 13630, 13633, 24897, 11080, 4954, 4956, 12282, 16240, 22397, 3978, 3980, 15759, 15761, 15762, 14228, 34749, 26574, 24019, 31190, 7127, 7129, 26588, 26599, 31719, 31721, 31729, 12787, 4602, 14332}\n",
      "dict_items([(\"Lemma('character.n.04.role')\", 6), (\"Lemma('function.n.03.role')\", 26), (\"Lemma('function.n.02.role')\", 6), (\"Lemma('role.n.04.role')\", 3)])\n",
      "collecting tokens for  formulation\n",
      "indices:    {3168, 3169, 32129, 3173, 3180, 15386, 3230}\n",
      "dict_items([(\"Lemma('formulation.n.01.formulation')\", 5), (\"Lemma('conceptualization.n.01.formulation')\", 1)])\n",
      "collecting tokens for  indeed\n",
      "indices:    {23225}\n",
      "dict_items([])\n",
      "collecting tokens for  roles\n",
      "indices:    {11991, 37036, 2316, 32942, 1007, 15470, 20954, 36883, 32949, 32950, 32951, 27869, 22073, 27162, 30747, 27900, 2621, 15806}\n",
      "dict_items([(\"Lemma('function.n.03.role')\", 4), (\"Lemma('character.n.04.role')\", 1), (\"Lemma('role.n.04.role')\", 1)])\n",
      "collecting tokens for  builder\n",
      "indices:    {24034, 29935, 3152, 3151, 3219, 30168, 30169, 1530, 1659, 20733}\n",
      "dict_items([(\"Lemma('builder.n.01.builder')\", 3)])\n",
      "collecting tokens for  agent\n",
      "indices:    {3460, 12165, 3462, 3466, 27787, 3467, 3468, 3218, 3219, 3230, 21631, 3486, 8225, 3489, 3496, 5168, 21553, 23345, 34356, 8250, 5179, 21314, 3401, 27855, 3407, 3281, 22354, 11733, 27861, 30053, 3455, 3176, 3180, 12787, 3198, 3199}\n",
      "dict_items([(\"Lemma('agent.n.01.agent')\", 12), (\"Lemma('agent.n.04.agent')\", 1), (\"Lemma('agent.n.02.agent')\", 1), (\"Lemma('agent.n.03.agent')\", 1)])\n",
      "collecting tokens for  numerous\n",
      "indices:    {11269, 5001, 1422, 31635, 11284, 33173, 27161, 3230, 24736, 2721, 12197, 13608, 22954, 26925, 26684, 25917, 3776, 26953, 29901, 2895, 30930, 32725, 11479, 2391, 4954, 12250, 2654, 16107, 23659, 11503, 12785, 22389, 32377}\n",
      "dict_items([(\"Lemma('numerous.s.01.numerous')\", 18)])\n",
      "collecting tokens for  commercial\n",
      "indices:    {11274, 5132, 767, 2324, 14488, 15261, 3230, 2338, 31529, 2986, 2987, 2347, 2350, 11694, 2352, 4786, 2354, 32434, 24888, 2363, 23763, 11871, 2784, 1765, 2917, 20583, 2918, 29675, 15212, 20592, 11252, 16251, 26750, 2047}\n",
      "dict_items([(\"Lemma('commercial.a.01.commercial')\", 22), (\"Lemma('commercial.a.02.commercial')\", 2)])\n",
      "collecting tokens for  organic\n",
      "indices:    {30472, 3218, 3219, 3223, 5528, 3998, 5540, 4923, 32067, 30407, 3273, 3274, 5591, 26459, 3166, 30440, 3179, 1644, 5489, 3187, 5494}\n",
      "dict_items([(\"Lemma('organic.a.01.organic')\", 15)])\n",
      "collecting tokens for  closing\n",
      "indices:    {21890, 23683, 30723, 34314, 34319, 35092, 26005, 28566, 26650, 8990, 24225, 24240, 18746, 25661, 14783, 14784, 23747, 13380, 17604, 18760, 850, 13912, 23003, 9949, 27746}\n",
      "dict_items([(\"Lemma('closing.a.01.closing')\", 3), (\"Lemma('close.v.01.close')\", 1), (\"Lemma('close_in.v.01.close_in')\", 2), (\"Lemma('close_up.v.01.close')\", 2), (\"Lemma('close.v.02.close')\", 4), (\"Lemma('shutting.n.01.closing')\", 2)])\n",
      "collecting tokens for  wished\n",
      "indices:    {31617, 14465, 9604, 33804, 28558, 16656, 1938, 28566, 36248, 2460, 16668, 7710, 16552, 9403, 36802, 13763, 16450, 36421, 13128, 23241, 8267, 31692, 8909, 30924, 35661, 6224, 32212, 18775, 13783, 10461, 18023, 10217, 8298, 8442, 23029, 19322, 35710}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('wish.v.02.wish')\", 8), (\"Lemma('wish.v.05.wish')\", 1), (\"Lemma('wish.v.01.wish')\", 15), (\"Lemma('wish.v.04.wish')\", 4), (\"Lemma('wish.v.03.wish')\", 2)])\n",
      "collecting tokens for  juniors\n",
      "indices:    {28613}\n",
      "dict_items([])\n",
      "collecting tokens for  tendency\n",
      "indices:    {3714, 27553, 16420, 22053, 4773, 20264, 31791, 16310, 14646, 3266, 26313, 22863, 26197, 29910, 15964, 15965, 10851, 27236, 26217, 3307, 13675, 5357, 2667, 17391, 27888, 4721, 32883, 32117, 16120, 3193, 26749, 4222}\n",
      "dict_items([(\"Lemma('tendency.n.03.tendency')\", 4), (\"Lemma('inclination.n.01.tendency')\", 9), (\"Lemma('leaning.n.01.tendency')\", 5)])\n",
      "collecting tokens for  workers\n",
      "indices:    {16258, 11779, 20359, 21767, 21768, 10123, 30614, 11801, 15648, 3628, 28332, 16301, 23602, 16309, 3638, 11834, 15675, 3644, 11842, 20421, 20172, 854, 21206, 22747, 22750, 16230, 25063, 24700, 3065, 13180, 21630, 28415}\n",
      "dict_items([(\"Lemma('worker.n.01.worker')\", 9), (\"Lemma('worker.n.03.worker')\", 3), (\"Lemma('proletarian.n.01.worker')\", 2)])\n",
      "collecting tokens for  gay\n",
      "indices:    {21029, 20550, 13702, 14472, 9837, 36304, 10003, 5207, 10814}\n",
      "dict_items([(\"Lemma('gay.s.02.gay')\", 2), (\"Lemma('cheery.s.01.gay')\", 2), (\"Lemma('gay.s.05.gay')\", 1)])\n",
      "collecting tokens for  witty\n",
      "indices:    {26465, 1125, 26185, 11183, 10609, 11221, 26171, 11229}\n",
      "dict_items([(\"Lemma('witty.s.01.witty')\", 5)])\n",
      "collecting tokens for  capable\n",
      "indices:    {27425, 26791, 3464, 25069, 31737}\n",
      "dict_items([(\"Lemma('capable.a.01.capable')\", 1)])\n",
      "collecting tokens for  musician\n",
      "indices:    {26785, 31874, 1032, 6765, 11186, 31891, 26420, 22548, 26264, 21563, 31612}\n",
      "dict_items([(\"Lemma('musician.n.01.musician')\", 2), (\"Lemma('musician.n.02.musician')\", 1)])\n",
      "collecting tokens for  essentially\n",
      "indices:    {16396}\n",
      "dict_items([(\"Lemma('basically.r.01.essentially')\", 1)])\n",
      "collecting tokens for  intimate\n",
      "indices:    {26080, 11969, 16806, 26761, 6394, 16843, 26684, 19630, 37039, 19633, 27346, 13843, 26670, 9398, 6842, 36826, 1724}\n",
      "dict_items([(\"Lemma('intimate.s.01.intimate')\", 4), (\"Lemma('cozy.s.02.intimate')\", 1), (\"Lemma('familiar.s.04.intimate')\", 1)])\n",
      "collecting tokens for  requirement\n",
      "indices:    {20547, 16227, 3817, 11743, 12779, 1710, 28687, 156, 31218, 21438, 15356, 13213, 32158, 127}\n",
      "dict_items([(\"Lemma('requirement.n.01.requirement')\", 2), (\"Lemma('prerequisite.n.01.requirement')\", 5), (\"Lemma('necessity.n.02.requirement')\", 2)])\n",
      "collecting tokens for  somebody\n",
      "indices:    {16648, 6418}\n",
      "dict_items([])\n",
      "collecting tokens for  suit\n",
      "indices:    {15238, 19464, 8340, 11669, 9625, 26, 5276, 22813, 22812, 35744, 9514, 57, 22972, 29888, 29514, 7883, 20683, 28755, 34519, 24797, 1374, 7518, 10720, 30564, 19688, 35819, 13421, 19067, 15231}\n",
      "dict_items([(\"Lemma('suit.n.01.suit')\", 10), (\"Lemma('lawsuit.n.01.suit')\", 3), (\"Lemma('suit.v.02.suit')\", 1), (\"Lemma('suit.v.01.suit')\", 3), (\"Lemma('befit.v.01.suit')\", 1)])\n",
      "collecting tokens for  wondering\n",
      "indices:    {18688, 36418, 19460, 2119, 36199, 775, 6536, 11051, 34988, 36110, 17711, 19825, 25749, 16983, 10330, 29115}\n",
      "dict_items([(\"Lemma('wonder.v.01.wonder')\", 9), (\"Lemma('wonder.v.02.wonder')\", 7)])\n",
      "collecting tokens for  grinned\n",
      "indices:    {34720, 7555, 17862, 30507, 33420, 19128, 17711, 36783, 36815, 33460, 7382, 7384, 33657, 6685}\n",
      "dict_items([(\"Lemma('grin.v.01.grin')\", 14)])\n",
      "collecting tokens for  lightly\n",
      "indices:    {29826, 25736, 24214, 16031, 5542, 16039, 16813, 17711, 15285, 1593, 18881, 17226, 33103, 29525, 29530, 31839, 5731, 7396, 22131, 34036, 35963, 29566, 20095}\n",
      "dict_items([(\"Lemma('lightly.r.05.lightly')\", 2), (\"Lemma('lightly.r.02.lightly')\", 2), (\"Lemma('lightly.r.01.lightly')\", 4), (\"Lemma('lightly.r.03.lightly')\", 2), (\"Lemma('lightly.r.04.lightly')\", 2)])\n",
      "collecting tokens for  serves\n",
      "indices:    {31525, 26598, 23527, 11783, 2729, 8777, 13934, 26415, 29968, 13392, 14609, 22101, 32088, 11295, 13372, 11293, 31678, 29535}\n",
      "dict_items([(\"Lemma('serve.v.05.serve')\", 1), (\"Lemma('serve.v.01.serve')\", 6), (\"Lemma('serve.v.03.serve')\", 5), (\"Lemma('serve.v.07.serve')\", 1), (\"Lemma('service.v.01.serve')\", 2), (\"Lemma('serve.v.02.serve')\", 2), (\"Lemma('serve.v.10.serve')\", 1)])\n",
      "collecting tokens for  focus\n",
      "indices:    {14594, 12934, 18951, 16015, 5904, 18450, 16280, 4764, 25506, 22953, 16299, 31917, 27953, 16306, 4913, 31154, 26300, 11326, 36036, 16327, 4937, 4939, 9683, 32875, 2031, 33135, 4978, 34807}\n",
      "dict_items([(\"Lemma('focus.n.01.focus')\", 6), (\"Lemma('focus.n.02.focus')\", 3), (\"Lemma('concentrate.v.02.focus')\", 4), (\"Lemma('focus.n.03.focus')\", 2), (\"Lemma('concenter.v.01.focus')\", 1), (\"Lemma('focus.v.02.focus')\", 3)])\n",
      "collecting tokens for  relationship\n",
      "indices:    {25601, 15236, 24072, 12041, 27534, 16015, 3855, 15250, 32915, 14231, 3352, 12957, 16415, 30240, 25890, 32937, 11482, 15279, 15281, 4657, 3379, 15283, 15284, 3767, 3768, 30266, 11964, 26429, 32704, 3780, 34887, 15688, 30921, 30794, 11980, 21326, 11983, 1108, 3413, 32084, 32087, 11991, 27865, 24154, 27867, 26459, 3037, 27229, 15574, 12000, 32865, 8160, 14690, 11878, 13935, 32892, 11505, 11507, 7543, 4600, 15482, 12667, 14076, 16125, 32895}\n",
      "dict_items([(\"Lemma('relationship.n.01.relationship')\", 21), (\"Lemma('relationship.n.02.relationship')\", 9), (\"Lemma('relationship.n.03.relationship')\", 6)])\n",
      "collecting tokens for  successor\n",
      "indices:    {225, 24007, 25481, 31721, 20491, 5198, 24145, 14934}\n",
      "dict_items([(\"Lemma('successor.n.01.successor')\", 2), (\"Lemma('successor.n.02.successor')\", 1)])\n",
      "collecting tokens for  colonial\n",
      "indices:    {22284}\n",
      "dict_items([])\n",
      "collecting tokens for  temptation\n",
      "indices:    {14368, 14434, 25475, 12292, 12293, 28007, 36315, 36316, 26270}\n",
      "dict_items([(\"Lemma('temptation.n.01.temptation')\", 4)])\n",
      "collecting tokens for  sin\n",
      "indices:    {28041, 2707, 26901, 25367, 6425, 28189, 1321, 12330, 12331, 28209, 28212, 28214, 27197, 1471, 28228, 27343, 27345, 1489, 1493, 1494, 27861, 1497, 24282, 1499, 36315, 1500, 1501, 1503, 24281, 5212, 1506, 27496, 1512, 1515, 27504, 12536, 28286}\n",
      "dict_items([(\"Lemma('sin.n.02.sin')\", 5), (\"Lemma('sin.n.01.sin')\", 12), (\"Lemma('sin.v.01.sin')\", 2)])\n",
      "collecting tokens for  arrive\n",
      "indices:    {12773, 20903, 1832, 22248, 21063, 2183, 10092, 4909, 30029, 21775, 35730, 28915, 30039, 29208, 20858, 13534}\n",
      "dict_items([(\"Lemma('arrive.v.01.arrive')\", 9)])\n",
      "collecting tokens for  spatial\n",
      "indices:    {31909, 31946, 4907, 4908, 4913, 4958, 3326}\n",
      "dict_items([(\"Lemma('spatial.a.01.spatial')\", 5)])\n",
      "collecting tokens for  images\n",
      "indices:    {16802, 2403, 2374, 2155, 7276, 13646, 7567, 36014, 13647, 13649, 32787, 31859, 7032, 7773}\n",
      "dict_items([(\"Lemma('image.n.01.image')\", 8), (\"Lemma('picture.n.01.image')\", 2)])\n",
      "collecting tokens for  rolled\n",
      "indices:    {29568, 6402, 29574, 29579, 9876, 29593, 29594, 8608, 19490, 7845, 8870, 13991, 35629, 34478, 23344, 6457, 13115, 34110, 6731, 21712, 19794, 10068, 6357, 23766, 18005, 19035, 10589, 7020, 29550, 35438, 34172, 7038}\n",
      "dict_items([(\"Lemma('wheel.v.03.roll')\", 9), (\"Lemma('roll.v.01.roll')\", 6), (\"Lemma('roll.v.07.roll')\", 1), (\"Lemma('roll.v.09.roll')\", 1), (\"Lemma('roll.v.08.roll')\", 1), (\"Lemma('roll.v.03.roll')\", 1), (\"Lemma('roll_out.v.01.roll')\", 4)])\n",
      "collecting tokens for  roberts\n",
      "indices:    {34130}\n",
      "dict_items([])\n",
      "collecting tokens for  edge\n",
      "indices:    {6274, 28805, 22278, 2437, 28806, 5385, 7179, 13944, 18187, 28830, 22689, 13476, 13609, 34986, 5676, 8497, 7220, 5431, 11320, 26553, 29624, 23869, 5821, 8639, 36415, 1216, 22982, 1094, 35656, 29641, 5962, 29899, 36940, 31568, 1107, 9311, 9312, 15073, 30050, 28771, 15075, 11616, 23010, 12391, 11623, 28777, 19175, 34155, 13419, 29681, 34162, 19057, 34163, 29557, 17784, 2938, 34172}\n",
      "dict_items([(\"Lemma('edge.n.01.edge')\", 19), (\"Lemma('edge.n.03.edge')\", 4), (\"Lemma('edge.n.05.edge')\", 2), (\"Lemma('edge.n.04.edge')\", 2), (\"Lemma('boundary.n.02.edge')\", 3), (\"Lemma('edge.n.06.edge')\", 1)])\n",
      "collecting tokens for  x-ray\n",
      "indices:    {3117, 3070, 3071}\n",
      "dict_items([(\"Lemma('x_ray.n.01.X_ray')\", 3)])\n",
      "collecting tokens for  films\n",
      "indices:    {3872, 3873, 23552, 22435, 1101, 26255, 26517, 37142, 2391, 2392, 33145, 28703, 23550, 33151}\n",
      "dict_items([(\"Lemma('movie.n.01.film')\", 3), (\"Lemma('film.n.03.film')\", 2)])\n",
      "collecting tokens for  liquor\n",
      "indices:    {37122, 21763, 21767, 12295, 21769, 35211, 5524, 23709, 5918, 29218, 27433, 32050, 5555, 5560, 5562, 6076, 5569, 5572, 27210, 9547, 80, 12499, 18270, 36963, 30948, 9841, 34039, 8184, 30844}\n",
      "dict_items([(\"Lemma('liquor.n.01.liquor')\", 9), (\"Lemma('liquor.n.02.liquor')\", 6)])\n",
      "collecting tokens for  torrio\n",
      "indices:    {12676}\n",
      "dict_items([(\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  patience\n",
      "indices:    {14688, 4644, 27293, 20777, 18153, 23979, 13836, 17660, 12693, 24277, 17048, 10298, 10108, 27325}\n",
      "dict_items([(\"Lemma('patience.n.01.patience')\", 9)])\n",
      "collecting tokens for  cause\n",
      "indices:    {2564, 12933, 27143, 32648, 25353, 15242, 30732, 2832, 31764, 3352, 30077, 28069, 25128, 26158, 23225, 2618, 17216, 4674, 15299, 22725, 1479, 11082, 1231, 16082, 15574, 11226, 30811, 3818, 27114, 13675, 25200, 27250, 29565}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('cause.v.01.cause')\", 10), (\"Lemma('cause.n.02.cause')\", 3), (\"Lemma('induce.v.02.cause')\", 5), (\"Lemma('cause.n.01.cause')\", 3), (\"Lemma('causal_agent.n.01.cause')\", 1), (\"Lemma('lawsuit.n.01.cause')\", 1), (\"Lemma('lawsuit.n.01.case')\", 1), (\"Lemma('campaign.n.02.cause')\", 1)])\n",
      "collecting tokens for  disaster\n",
      "indices:    {11140, 24203, 12693, 31257, 36133, 2602, 37162, 30512, 25137, 17075, 12339, 25139, 20790, 2630, 26960, 12756, 12768, 2658, 30316, 12787}\n",
      "dict_items([(\"Lemma('calamity.n.01.disaster')\", 5), (\"Lemma('catastrophe.n.02.disaster')\", 5)])\n",
      "collecting tokens for  o\n",
      "indices:    {13601, 12676}\n",
      "dict_items([])\n",
      "collecting tokens for  banion\n",
      "indices:    {12676}\n",
      "dict_items([])\n",
      "collecting tokens for  attorney\n",
      "indices:    {25036}\n",
      "dict_items([])\n",
      "collecting tokens for  dwight\n",
      "indices:    {23792}\n",
      "dict_items([])\n",
      "collecting tokens for  behalf\n",
      "indices:    {14883, 5349, 32870, 4679, 20713, 22747, 25551, 25871, 20851, 25332, 15574, 24919, 37146, 14875, 21372, 14878, 24187}\n",
      "dict_items([(\"Lemma('behalf.n.01.behalf')\", 4), (\"Lemma('behalf.n.02.behalf')\", 2)])\n",
      "collecting tokens for  philip\n",
      "indices:    {27816}\n",
      "dict_items([])\n",
      "collecting tokens for  argued\n",
      "indices:    {34435, 14596, 23175, 22665, 139, 23953, 14103, 29980, 36128, 26147, 15274, 16308, 21179, 20161, 15298, 15299, 6855, 13384, 13383, 25443, 104, 13289, 29167, 20851, 13689, 27260}\n",
      "dict_items([(\"Lemma('argue.v.02.argue')\", 6), (\"Lemma('argue.v.01.argue')\", 20)])\n",
      "collecting tokens for  powell\n",
      "indices:    {18250}\n",
      "dict_items([])\n",
      "collecting tokens for  declared\n",
      "indices:    {23680, 23300, 21900, 12045, 22799, 32402, 25746, 22802, 20373, 28051, 25623, 12307, 18585, 281, 21402, 12316, 12314, 25499, 14230, 31511, 32029, 12322, 25389, 21679, 23987, 12218, 8125, 20290, 12482, 20549, 14973, 20295, 20681, 18505, 6104, 9309, 98, 34915, 31972, 37095, 24826, 25197, 12271, 20851, 20852, 17914, 24828, 8701}\n",
      "dict_items([(\"Lemma('announce.v.02.declare')\", 11), (\"Lemma('declare.v.01.declare')\", 19), (\"Lemma('declare.v.03.declare')\", 8), (\"Lemma('declare.v.04.declare')\", 5), (\"Lemma('declared.a.01.declared')\", 1)])\n",
      "collecting tokens for  decide\n",
      "indices:    {32134, 31307, 20620, 30703, 28466, 29461, 15545, 31068, 36190}\n",
      "dict_items([(\"Lemma('decide.v.01.decide')\", 9)])\n",
      "collecting tokens for  constitution\n",
      "indices:    {31771}\n",
      "dict_items([])\n",
      "collecting tokens for  compact\n",
      "indices:    {31968, 16161, 31970, 28962, 22249, 29005, 32276, 17917, 32350}\n",
      "dict_items([(\"Lemma('compact.n.01.compact')\", 1)])\n",
      "collecting tokens for  sovereign\n",
      "indices:    {32000, 32006, 32009, 32010, 31243, 32015, 32017, 16409, 16413, 16418, 7081, 16426, 16444, 16445, 31172, 31180, 31964, 31968, 31970, 31996, 31998}\n",
      "dict_items([(\"Lemma('sovereign.n.01.sovereign')\", 2), (\"Lemma('autonomous.s.01.sovereign')\", 4), (\"Lemma('sovereign.s.02.sovereign')\", 1)])\n",
      "collecting tokens for  retained\n",
      "indices:    {31968, 33056, 13949, 9670, 3246, 24144, 179, 32340, 17365, 3254, 20343, 26136, 31001, 15962, 31003, 7773}\n",
      "dict_items([(\"Lemma('retain.v.02.retain')\", 1), (\"Lemma('retain.v.01.retain')\", 1), (\"Lemma('retain.v.03.retain')\", 1), (\"Lemma('retained.s.01.retained')\", 1)])\n",
      "collecting tokens for  secede\n",
      "indices:    {31968, 31970, 23268, 31972, 31978, 31984, 31985, 31987, 31998, 31999}\n",
      "dict_items([(\"Lemma('secede.v.01.secede')\", 10)])\n",
      "collecting tokens for  nobody\n",
      "indices:    {34456}\n",
      "dict_items([])\n",
      "collecting tokens for  quick\n",
      "indices:    {22541, 36242, 9363, 17815, 6690, 8866, 6183, 7595, 18609, 33971, 25143, 16569, 19513, 8896, 7495, 15816, 24417, 31332, 22631, 10985, 32876, 30575, 5621, 9461}\n",
      "dict_items([(\"Lemma('quick.s.01.quick')\", 7), (\"Lemma('quick.s.06.quick')\", 1), (\"Lemma('flying.s.02.quick')\", 3), (\"Lemma('promptly.r.01.quick')\", 3), (\"Lemma('agile.s.01.quick')\", 1)])\n",
      "collecting tokens for  phillips\n",
      "indices:    {28075}\n",
      "dict_items([])\n",
      "collecting tokens for  razor\n",
      "indices:    {34142, 34104, 710, 34183, 34184, 34092, 717, 7856, 7857, 34067, 1812, 7864, 17689, 34106, 34078}\n",
      "dict_items([(\"Lemma('razor.n.01.razor')\", 5)])\n",
      "collecting tokens for  spanish\n",
      "indices:    {18905}\n",
      "dict_items([(\"Lemma('spanish.n.01.Spanish')\", 1)])\n",
      "collecting tokens for  welcome\n",
      "indices:    {18115, 26979, 20997, 24393, 25226, 24106, 36273, 22515, 2070, 37049, 22874, 11199}\n",
      "dict_items([(\"Lemma('welcome.v.01.welcome')\", 2), (\"Lemma('welcome.v.02.welcome')\", 1), (\"Lemma('welcome.a.01.welcome')\", 1)])\n",
      "collecting tokens for  sewer\n",
      "indices:    {737, 5121, 22021, 5126, 1191, 20381, 5118}\n",
      "dict_items([(\"Lemma('sewer.n.02.sewer')\", 1), (\"Lemma('sewer.n.01.sewer')\", 3)])\n",
      "collecting tokens for  maintenance\n",
      "indices:    {30291, 27885}\n",
      "dict_items([])\n",
      "collecting tokens for  division\n",
      "indices:    {32357, 2502, 32503}\n",
      "dict_items([(\"Lemma('division.n.05.division')\", 1)])\n",
      "collecting tokens for  responsible\n",
      "indices:    {30084, 3717, 35976, 25738, 32266, 26506, 17805, 24842, 20754, 25365, 8222, 25727, 1955, 28708, 4009, 813, 20270, 15409, 28086, 13753, 26554, 10171, 10173, 32705, 13893, 11079, 20558, 28663, 24919, 25312, 34657, 32126, 29027, 17633, 27237, 32357, 26985, 4586, 492, 12269, 33012, 4599, 21625, 24573, 33022, 31615}\n",
      "dict_items([(\"Lemma('responsible.a.01.responsible')\", 9), (\"Lemma('responsible.s.02.responsible')\", 1)])\n",
      "collecting tokens for  river\n",
      "indices:    {31560, 19241, 35811, 12366}\n",
      "dict_items([(\"Lemma('river.n.01.river')\", 1)])\n",
      "collecting tokens for  photographic\n",
      "indices:    {3360, 2146, 3366, 2150, 29295, 2896, 13651, 29243, 29277, 14782}\n",
      "dict_items([(\"Lemma('photographic.a.01.photographic')\", 7)])\n",
      "collecting tokens for  requirements\n",
      "indices:    {23426, 32130, 4613, 3462, 14984, 3465, 32137, 23436, 29838, 14739, 11670, 1815, 3228, 15261, 14877, 2082, 32297, 1837, 2863, 21425, 28595, 11830, 11703, 29243, 2877, 29888, 27717, 2758, 15047, 15945, 32458, 2761, 15052, 30157, 5582, 11857, 12114, 12115, 24276, 3416, 2779, 3165, 3166, 14049, 20193, 14821, 3176, 32616, 12650, 12651, 15470, 16751, 15217, 15220, 32373}\n",
      "dict_items([(\"Lemma('necessity.n.02.requirement')\", 15), (\"Lemma('requirement.n.01.requirement')\", 17), (\"Lemma('prerequisite.n.01.requirement')\", 6)])\n",
      "collecting tokens for  relating\n",
      "indices:    {29956, 27717, 32414, 31919, 15055, 14737, 31862, 14742, 2718}\n",
      "dict_items([(\"Lemma('refer.v.02.relate')\", 4), (\"Lemma('relate.v.04.relate')\", 1), (\"Lemma('associate.v.01.relate')\", 4)])\n",
      "collecting tokens for  insure\n",
      "indices:    {23360, 31201, 16161, 19141, 24901, 27717, 27525, 77, 32622, 31995, 2736, 5521, 28817, 23982, 14748, 15450, 25339, 31996}\n",
      "dict_items([(\"Lemma('guarantee.v.02.insure')\", 6), (\"Lemma('see.v.10.insure')\", 9), (\"Lemma('insure.v.04.insure')\", 1), (\"Lemma('cover.v.14.insure')\", 2)])\n",
      "collecting tokens for  intent\n",
      "indices:    {4963, 11493, 27717, 838, 5352, 23947, 17136, 2672, 18935, 5276}\n",
      "dict_items([(\"Lemma('intent.n.02.intent')\", 2), (\"Lemma('purpose.n.01.intent')\", 3)])\n",
      "collecting tokens for  driving\n",
      "indices:    {21385, 24462, 526, 21392, 23190, 21540, 1188, 13996, 8239, 20912, 11444, 21814, 33468, 5437, 7871, 9283, 27076, 33477, 8774, 21328, 29142, 858, 27102, 29023, 27104, 22241, 2146, 28642, 21611, 7794, 20725, 12927}\n",
      "dict_items([(\"Lemma('drive.v.01.drive')\", 13), (\"Lemma('drive.v.03.drive')\", 2), (\"Lemma('drive.v.02.drive')\", 4), (\"Lemma('drive.n.01.driving_force')\", 1), (\"Lemma('driving.s.01.driving')\", 2), (\"Lemma('force.v.06.drive')\", 1), (\"Lemma('repel.v.01.drive')\", 1)])\n",
      "collecting tokens for  yours\n",
      "indices:    {9889, 34467, 27364, 10403, 10694, 28295, 28296, 33929, 11177, 16939, 34348, 34379, 26096, 7768}\n",
      "dict_items([])\n",
      "collecting tokens for  beach\n",
      "indices:    {21127}\n",
      "dict_items([])\n",
      "collecting tokens for  significant\n",
      "indices:    {15970, 27394, 33188, 16131, 2824, 32202, 13165, 22894, 2640, 33200, 4722, 15700, 2326, 26775, 25342}\n",
      "dict_items([(\"Lemma('significant.a.01.significant')\", 6), (\"Lemma('significant.a.03.significant')\", 1)])\n",
      "collecting tokens for  factors\n",
      "indices:    {4988, 30229, 28902, 25575}\n",
      "dict_items([(\"Lemma('factor.n.01.factor')\", 1)])\n",
      "collecting tokens for  future\n",
      "indices:    {14721, 32906, 32907, 20236, 15, 27800, 22685, 21919, 15391, 16289, 16294, 25640, 32680, 1835, 32689, 27834, 16316, 33340, 5442, 28611, 4675, 25042, 11352, 1889, 31848, 14954, 32494, 31088, 22641, 888, 26747, 124, 23935}\n",
      "dict_items([(\"Lemma('future.n.01.future')\", 8), (\"Lemma('future.s.02.future')\", 3), (\"Lemma('future.a.01.future')\", 1)])\n",
      "collecting tokens for  civilization\n",
      "indices:    {27911, 5004, 5005, 5013, 24982, 16410, 26142, 5025, 14651, 32065, 4688, 14163, 2522, 1120, 32239, 12786, 2549, 14710, 2551, 34685, 4990, 2303}\n",
      "dict_items([(\"Lemma('civilization.n.01.civilization')\", 16)])\n",
      "collecting tokens for  intelligence\n",
      "indices:    {14242, 15657, 34759, 15687}\n",
      "dict_items([(\"Lemma('intelligence.n.01.intelligence')\", 1)])\n",
      "collecting tokens for  tests\n",
      "indices:    {25441, 3170, 25446, 25415, 3529, 25449, 15147, 25451, 25261, 4041, 4177, 34675, 25407, 25439, 25399, 4921, 23900, 12767}\n",
      "dict_items([(\"Lemma('trial.n.02.test')\", 5), (\"Lemma('test.n.05.test')\", 1)])\n",
      "collecting tokens for  adaptation\n",
      "indices:    {32880, 32959}\n",
      "dict_items([])\n",
      "collecting tokens for  index\n",
      "indices:    {22019, 10982, 15689, 714, 34673, 11000, 14842, 26782, 16188, 9182}\n",
      "dict_items([(\"Lemma('index.n.02.index')\", 1), (\"Lemma('index.v.01.index')\", 1), (\"Lemma('index.n.01.index')\", 1)])\n",
      "collecting tokens for  unusually\n",
      "indices:    {34944, 23401, 21515, 35820, 34673, 16210, 12056, 18520, 31615}\n",
      "dict_items([(\"Lemma('unusually.r.01.unusually')\", 3)])\n",
      "collecting tokens for  classic\n",
      "indices:    {10624, 9364, 26901, 13973, 11032, 27035, 26142, 19622, 1193, 2474, 23087, 27696, 30260, 11063, 22079, 26561, 26564, 13636, 26565, 13642, 26572, 29145, 1006, 13813, 26495}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('classic.n.02.classic')\", 1), (\"Lemma('authoritative.s.02.classic')\", 4), (\"Lemma('classic.n.01.classic')\", 1)])\n",
      "collecting tokens for  liberalism\n",
      "indices:    {25889, 27266, 14085}\n",
      "dict_items([(\"Lemma('liberalism.n.01.liberalism')\", 1)])\n",
      "collecting tokens for  democrats\n",
      "indices:    {23728}\n",
      "dict_items([])\n",
      "collecting tokens for  poles\n",
      "indices:    {7940}\n",
      "dict_items([(\"Lemma('pole.n.02.Pole')\", 1)])\n",
      "collecting tokens for  jefferson\n",
      "indices:    {31771}\n",
      "dict_items([])\n",
      "collecting tokens for  neither\n",
      "indices:    {13490, 24850}\n",
      "dict_items([])\n",
      "collecting tokens for  break\n",
      "indices:    {2176, 28801, 12549, 17290, 21005, 5005, 33037, 24337, 23704, 16667, 17567, 11809, 680, 31913, 35244, 22828, 29100, 3247, 29105, 9399, 3255, 14014, 13252, 15177, 17100, 1744, 32081, 6993, 211, 32853, 5463, 12504, 13273, 348, 33885, 29150, 9186, 12783, 24690, 10356, 30583, 6008}\n",
      "dict_items([(\"Lemma('break.v.02.break')\", 3), (\"Lemma('interrupt.v.04.break')\", 2), (\"Lemma('break.v.05.break')\", 1), (\"Lemma('break.v.04.break')\", 3), (\"Lemma('unwrap.v.02.break')\", 1), (\"Lemma('violate.v.01.break')\", 1), (\"Lemma('interruption.n.02.break')\", 2), (\"Lemma('rupture.n.02.break')\", 1), (\"Lemma('better.v.01.break')\", 1), (\"Lemma('break.v.09.break')\", 1), (\"Lemma('break.v.03.break')\", 1), (\"Lemma('break.v.07.break')\", 1), (\"Lemma('dampen.v.07.break')\", 1), (\"Lemma('break_in.v.06.break')\", 1), (\"Lemma('fail.v.04.break')\", 1), (\"Lemma('break.n.02.break')\", 1), (\"Lemma('transgress.v.01.break')\", 1)])\n",
      "collecting tokens for  agreed\n",
      "indices:    {32768, 29955, 9604, 14855, 30221, 20110, 20759, 6812, 30, 8357, 22567, 10023, 16427, 17323, 13100, 20268, 15223, 22840, 20792, 34361, 22843, 10683, 20797, 11202, 9539, 10949, 20678, 23885, 31693, 10703, 34896, 21456, 32724, 20822, 20568, 9307, 15836, 12252, 5599, 20578, 21354, 19435, 9579, 9840, 10230, 21111}\n",
      "dict_items([(\"Lemma('agree.v.01.agree')\", 26), (\"Lemma('agree.v.02.agree')\", 16)])\n",
      "collecting tokens for  interviews\n",
      "indices:    {32928, 30232, 22569, 20492, 30257, 32925, 33143, 32888, 32892, 30237}\n",
      "dict_items([])\n",
      "collecting tokens for  nearest\n",
      "indices:    {33025, 29837, 26129, 5792, 22567, 34487, 30519, 8639, 14016, 14017, 14019, 14020, 36420, 33613, 13646, 27346, 14036, 18521, 33753, 35420, 18528, 14059}\n",
      "dict_items([(\"Lemma('near.a.01.near')\", 11)])\n",
      "collecting tokens for  executive\n",
      "indices:    {24896, 21922, 21570, 24164, 28362, 75, 556, 20810, 21743, 15225}\n",
      "dict_items([(\"Lemma('executive.a.01.executive')\", 1)])\n",
      "collecting tokens for  funny\n",
      "indices:    {24707, 26979, 20106, 20107, 16556, 11025, 10930, 10810, 8117, 10870, 6266, 10811}\n",
      "dict_items([(\"Lemma('curious.s.01.funny')\", 4), (\"Lemma('amusing.s.02.funny')\", 3), (\"Lemma('fishy.s.02.funny')\", 2)])\n",
      "collecting tokens for  cooperative\n",
      "indices:    {24705, 14023, 13992, 16317, 14002, 2770, 2772, 2779, 14748, 13245, 2782}\n",
      "dict_items([(\"Lemma('cooperative.n.01.cooperative')\", 1), (\"Lemma('cooperative.a.02.cooperative')\", 3), (\"Lemma('concerted.s.01.cooperative')\", 5)])\n",
      "collecting tokens for  agencies\n",
      "indices:    {23557, 23946, 32907, 14738, 1818, 36123, 14748, 22565, 16294, 15410, 20532, 32453, 24903, 31053, 21082, 32738, 32356, 12260, 14187}\n",
      "dict_items([(\"Lemma('agency.n.01.agency')\", 6)])\n",
      "collecting tokens for  civilian\n",
      "indices:    {20993, 5256, 36490, 7950, 30353, 5908, 21403, 17691, 2732, 25136, 32698, 32704, 12224, 32712, 12498, 32724, 32746, 32755, 14970, 15487}\n",
      "dict_items([(\"Lemma('civilian.a.01.civilian')\", 8), (\"Lemma('civilian.n.01.civilian')\", 1)])\n",
      "collecting tokens for  audience\n",
      "indices:    {1032, 26645, 26648, 1052, 1055, 1065, 41, 43, 25663, 10826, 2644, 2651, 26722, 34403, 1125, 26727, 14440, 36970, 6252, 6262, 6266, 6267, 26748, 2687, 6274, 1164, 1169, 9364, 9365, 26262, 9881, 9891, 6312, 26794, 1198, 9918, 5312, 31939, 32462, 9934, 5332, 5341, 5343, 9951, 1247, 1251, 9958, 1254, 1258, 1261, 14580, 26868, 14584, 26873, 26877, 1277, 26377, 30475, 26386, 26389, 2329, 26394, 26397, 26398, 22304, 26410, 26415, 2355, 26424, 26426, 26428, 13638, 2385, 2389, 359, 2413, 22393, 2427, 26002, 12191, 6048, 6053, 6057, 6058, 431, 20402, 20409, 442, 13759, 26054, 11224, 22508, 22516, 22522}\n",
      "dict_items([(\"Lemma('audience.n.01.audience')\", 26), (\"Lemma('audience.n.02.audience')\", 8)])\n",
      "collecting tokens for  relaxed\n",
      "indices:    {33216, 1024, 34979, 35785, 26175, 5621, 24566, 30679, 34202, 36831}\n",
      "dict_items([(\"Lemma('relaxed.a.01.relaxed')\", 2), (\"Lemma('loosen.v.07.relax')\", 1), (\"Lemma('relax.v.01.relax')\", 2)])\n",
      "collecting tokens for  characteristic\n",
      "indices:    {32261, 4358, 2952, 33162, 4235, 1297, 13463, 6043, 5281, 12580, 33191, 3754, 4281, 4283, 4284, 4285, 4287, 1087, 14790, 32075, 13646, 2640, 5716, 4951, 2647, 26335, 14688, 28130, 32996, 32999, 14695, 2922, 363, 13677, 15857, 2930, 21237, 13302, 15863, 31224}\n",
      "dict_items([(\"Lemma('characteristic.a.01.characteristic')\", 21), (\"Lemma('characteristic.n.02.characteristic')\", 3), (\"Lemma('feature.n.01.characteristic')\", 6)])\n",
      "collecting tokens for  normally\n",
      "indices:    {15996, 16032, 12036, 23780, 31018, 16010, 3820, 9931, 16020, 35959, 3836, 3934}\n",
      "dict_items([(\"Lemma('normally.r.01.normally')\", 9)])\n",
      "collecting tokens for  speaking\n",
      "indices:    {20319}\n",
      "dict_items([(\"Lemma('talk.v.02.speak')\", 1)])\n",
      "collecting tokens for  private\n",
      "indices:    {21376, 13954, 37125, 29190, 24714, 11659, 24715, 4620, 13969, 13971, 21781, 13978, 5275, 13980, 14748, 26784, 20512, 23202, 32037, 11685, 12331, 1459, 20532, 26419, 24374, 12599, 15417, 20669, 25022, 12608, 13890, 12619, 23117, 31693, 15437, 13904, 22870, 13918, 25059, 9188, 6506, 11509, 16250, 16251}\n",
      "dict_items([(\"Lemma('private.a.01.private')\", 13), (\"Lemma('private.n.01.private')\", 2)])\n",
      "collecting tokens for  camp\n",
      "indices:    {12577, 11906, 11908, 34567, 34568, 34570, 36140, 22605, 8621, 35537, 12564, 16023, 16024, 7676, 8062}\n",
      "dict_items([(\"Lemma('camp.n.03.camp')\", 1), (\"Lemma('camp.n.01.camp')\", 4), (\"Lemma('camp.n.06.camp')\", 1)])\n",
      "collecting tokens for  guilty\n",
      "indices:    {30849, 14853, 14859, 21392, 20382, 25376, 9891, 5287, 36905, 24625, 15306, 10444, 21328, 21333, 3675, 16862, 8547, 2666, 28011, 19440}\n",
      "dict_items([(\"Lemma('guilty.a.01.guilty')\", 9)])\n",
      "collecting tokens for  urge\n",
      "indices:    {27627}\n",
      "dict_items([(\"Lemma('urge.v.01.urge')\", 1)])\n",
      "collecting tokens for  respected\n",
      "indices:    {8547, 4771, 13736, 6897, 20276, 15766, 32857, 7610, 6972}\n",
      "dict_items([(\"Lemma('respect.v.01.respect')\", 6), (\"Lemma('respect.v.02.respect')\", 1), (\"Lemma('respected.s.01.respected')\", 2)])\n",
      "collecting tokens for  command\n",
      "indices:    {17633, 23362, 14037, 35462}\n",
      "dict_items([(\"Lemma('command.n.01.command')\", 2)])\n",
      "collecting tokens for  principal\n",
      "indices:    {21376, 25603, 23237, 32453, 14891, 15596, 15597, 23117, 15598, 14892, 23954, 1397, 5240, 25950, 5599}\n",
      "dict_items([(\"Lemma('chief.s.01.principal')\", 5), (\"Lemma('principal.n.01.principal')\", 2)])\n",
      "collecting tokens for  element\n",
      "indices:    {20229, 2311, 25609, 1802, 32909, 26774, 32918, 32924, 32925, 11683, 15911, 15529, 26153, 31158, 32057, 14779, 14780, 14781, 1235, 24155, 18780, 23389, 15844, 2413, 31855, 2035, 19444}\n",
      "dict_items([(\"Lemma('component.n.03.element')\", 6), (\"Lemma('component.n.01.element')\", 8)])\n",
      "collecting tokens for  capability\n",
      "indices:    {28451, 15526, 15527, 15528, 15529, 28463, 28498, 25304, 28508}\n",
      "dict_items([(\"Lemma('capability.n.01.capability')\", 4)])\n",
      "collecting tokens for  giants\n",
      "indices:    {22995}\n",
      "dict_items([])\n",
      "collecting tokens for  recorded\n",
      "indices:    {2438, 3336, 21773, 5520, 2963, 3347, 3740, 37020, 29982, 8864, 12707, 15666, 5171, 14261, 1081, 15930, 24768, 24769, 1090, 24771, 15936, 34760, 27336, 1099, 16088, 1754, 26336, 12770, 3687, 747, 1776, 26481, 26610, 34675, 20597, 33020, 30207}\n",
      "dict_items([(\"Lemma('record.v.01.record')\", 23), (\"Lemma('read.v.08.record')\", 3), (\"Lemma('record.v.02.record')\", 8), (\"Lemma('recorded.a.01.recorded')\", 2)])\n",
      "collecting tokens for  reasonable\n",
      "indices:    {13697, 16644, 15238, 14854, 3081, 5517, 16653, 30223, 27791, 3088, 15507, 3987, 21, 15642, 15260, 2974, 35998, 33188, 28465, 2751, 2753, 3013, 11848, 2762, 3022, 11857, 23250, 25434, 29147, 2784, 2530, 16101, 3687, 7399, 25842, 2802, 24690, 17782, 12412, 15231}\n",
      "dict_items([(\"Lemma('fair.s.02.reasonable')\", 14), (\"Lemma('reasonable.a.01.reasonable')\", 16)])\n",
      "collecting tokens for  maturity\n",
      "indices:    {31852, 3868, 3911}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('maturity.n.02.maturity')\", 2)])\n",
      "collecting tokens for  conditions\n",
      "indices:    {32132, 25099, 16396, 30989, 16398, 3988, 33199, 2878, 4674, 28102, 16328, 22728, 30793, 27341, 33229, 3279, 5584, 3177, 12917, 12919, 12921, 21626, 12796}\n",
      "dict_items([(\"Lemma('condition.n.01.condition')\", 10), (\"Lemma('condition.n.02.condition')\", 2), (\"Lemma('circumstance.n.03.condition')\", 1)])\n",
      "collecting tokens for  mason\n",
      "indices:    {11268}\n",
      "dict_items([])\n",
      "collecting tokens for  earn\n",
      "indices:    {31684, 15557, 11272, 23467, 15691, 15693, 29710, 15631, 14193, 20883, 2552, 12607}\n",
      "dict_items([(\"Lemma('earn.v.02.earn')\", 7), (\"Lemma('gain.v.08.earn')\", 5)])\n",
      "collecting tokens for  devoting\n",
      "indices:    {15334, 11272, 26891, 32076, 15314, 15317, 15319, 15327}\n",
      "dict_items([(\"Lemma('give.v.18.devote')\", 7), (\"Lemma('give.v.10.devote')\", 1)])\n",
      "collecting tokens for  exclusively\n",
      "indices:    {32772, 4231, 11272, 14220, 32271, 25366, 2071, 32810, 31926, 16442, 6076, 14915, 32836, 33102, 26194, 33110, 26348, 25453, 26101, 22391}\n",
      "dict_items([(\"Lemma('entirely.r.02.exclusively')\", 7)])\n",
      "collecting tokens for  painting\n",
      "indices:    {5892, 24710, 2054, 31880, 16009, 26122, 11273, 7568, 26905, 19610, 26779, 11295, 11298, 37029, 17072, 11328, 32076, 17101, 26960, 19555, 2404, 30828, 19567, 25714, 5364, 25716}\n",
      "dict_items([(\"Lemma('paint.v.01.paint')\", 4), (\"Lemma('painting.n.04.painting')\", 1), (\"Lemma('painting.n.02.painting')\", 4), (\"Lemma('painting.n.03.painting')\", 3), (\"Lemma('paint.v.03.paint')\", 1), (\"Lemma('painting.n.01.painting')\", 3)])\n",
      "collecting tokens for  invasion\n",
      "indices:    {21409, 24172, 11091, 27894, 21722}\n",
      "dict_items([])\n",
      "collecting tokens for  begun\n",
      "indices:    {35203, 2439, 4617, 16651, 9229, 14481, 9368, 30331, 27548, 22438, 24359, 29356, 25779, 12475, 4031, 28226, 23367, 30286, 2003, 26708, 23509, 19802, 9180, 12894, 7263, 13024, 13280, 23139, 28644, 4968, 31725, 6767, 5366, 19449, 24443}\n",
      "dict_items([(\"Lemma('get_down.v.07.begin')\", 25), (\"Lemma('begin.v.02.begin')\", 5), (\"Lemma('begin.v.03.begin')\", 3)])\n",
      "collecting tokens for  roosevelt\n",
      "indices:    {29306}\n",
      "dict_items([])\n",
      "collecting tokens for  warning\n",
      "indices:    {12306, 31291, 20246, 15207}\n",
      "dict_items([(\"Lemma('admonition.n.01.warning')\", 1), (\"Lemma('warning.n.01.warning')\", 1)])\n",
      "collecting tokens for  poison\n",
      "indices:    {30272, 30274, 27261, 1706, 30062, 30286, 12217, 16669}\n",
      "dict_items([(\"Lemma('poison.v.01.poison')\", 1), (\"Lemma('poison.n.02.poison')\", 1), (\"Lemma('poison.n.01.poison')\", 2)])\n",
      "collecting tokens for  festival\n",
      "indices:    {14441, 26787, 20894}\n",
      "dict_items([(\"Lemma('festival.n.01.festival')\", 1)])\n",
      "collecting tokens for  categories\n",
      "indices:    {27554, 32452, 31146, 31147, 4428, 31132, 2476, 4813, 16176, 3185, 1232, 14803, 26804, 27252, 34520, 32377, 27548, 15007}\n",
      "dict_items([(\"Lemma('class.n.01.category')\", 6), (\"Lemma('category.n.02.category')\", 2)])\n",
      "collecting tokens for  cologne\n",
      "indices:    {31614}\n",
      "dict_items([])\n",
      "collecting tokens for  bonn\n",
      "indices:    {26786}\n",
      "dict_items([])\n",
      "collecting tokens for  hall\n",
      "indices:    {16410, 7738, 35677, 6879}\n",
      "dict_items([(\"Lemma('manor_hall.n.01.hall')\", 1), (\"Lemma('anteroom.n.01.hall')\", 1), (\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  anderson\n",
      "indices:    {33366}\n",
      "dict_items([])\n",
      "collecting tokens for  batista\n",
      "indices:    {28401}\n",
      "dict_items([])\n",
      "collecting tokens for  represented\n",
      "indices:    {3844, 13958, 13831, 2698, 2315, 27148, 33038, 21648, 21779, 21908, 5397, 21909, 3225, 24092, 16157, 33185, 11428, 15527, 15528, 4521, 1451, 27564, 15917, 27567, 1711, 27568, 31282, 4286, 1351, 13255, 15945, 1354, 1353, 1356, 1360, 3153, 1362, 15956, 11477, 26328, 33129, 9586, 14712, 31103}\n",
      "dict_items([(\"Lemma('represent.v.03.represent')\", 11), (\"Lemma('constitute.v.01.represent')\", 3), (\"Lemma('represent.v.01.represent')\", 12), (\"Lemma('represent.v.05.represent')\", 6), (\"Lemma('typify.v.02.represent')\", 7), (\"Lemma('exemplify.v.01.represent')\", 2), (\"Lemma('act.v.03.represent')\", 1), (\"Lemma('represent.v.04.represent')\", 1), (\"Lemma('represent.v.09.represent')\", 1)])\n",
      "collecting tokens for  oppose\n",
      "indices:    {20482, 22789, 12328, 31740, 20274, 115, 24949, 25178, 24092, 16381, 222, 2495}\n",
      "dict_items([(\"Lemma('fight.v.02.oppose')\", 6), (\"Lemma('oppose.v.01.oppose')\", 5), (\"Lemma('pit.v.01.oppose')\", 1)])\n",
      "collecting tokens for  accordingly\n",
      "indices:    {3922}\n",
      "dict_items([(\"Lemma('consequently.r.01.accordingly')\", 1)])\n",
      "collecting tokens for  33\n",
      "indices:    {21886, 20168, 29002, 3725, 3920, 21425, 21232, 15027, 29012, 14549, 15094, 3735, 1272, 2201, 28983, 29015}\n",
      "dict_items([])\n",
      "collecting tokens for  21\n",
      "indices:    {29953, 30849, 21635, 28807, 649, 21514, 5129, 23185, 3858, 3860, 32411, 16157, 929, 3887, 32690, 3891, 308, 3894, 951, 16183, 29122, 28995, 3907, 14790, 327, 20168, 14793, 12748, 32717, 3920, 20689, 21333, 23385, 23388, 24285, 30557, 15326, 13150, 11367, 20205, 15086, 23281, 626, 21875, 24820, 29041, 22004, 32631}\n",
      "dict_items([(\"Lemma('twenty-one.s.01.21')\", 12), (\"Lemma('twenty-one.n.01.21')\", 2)])\n",
      "collecting tokens for  13\n",
      "indices:    {28544, 20868, 16261, 264, 20745, 28171, 29713, 278, 28951, 22297, 24992, 22944, 32674, 3747, 22179, 20772, 29729, 39, 168, 24746, 22958, 22959, 28208, 28334, 23605, 15041, 451, 15044, 23756, 3920, 15315, 597, 5593, 3290, 27481, 21601, 3812, 21351, 21992, 33513, 3816, 28264, 620, 109, 20588, 20592, 627, 20860, 2813, 22911}\n",
      "dict_items([(\"Lemma('thirteen.s.01.13')\", 11), (\"Lemma('thirteenth.s.01.13th')\", 1)])\n",
      "collecting tokens for  32\n",
      "indices:    {5568, 24739, 5540, 26789, 13126, 13130, 29131, 29007, 3920, 29039, 3926, 27511, 26008, 27322, 28829, 2783}\n",
      "dict_items([])\n",
      "collecting tokens for  34\n",
      "indices:    {27407, 24727, 28954, 3867, 28958, 3880, 3888, 3890, 3900, 3907, 29895, 3915, 29006, 3920, 3921, 27860, 3925, 3927, 5592, 29015, 29018, 24288, 24692, 22909}\n",
      "dict_items([])\n",
      "collecting tokens for  22\n",
      "indices:    {27010, 32643, 32648, 137, 29324, 3725, 3341, 21517, 23190, 3735, 2840, 12313, 22554, 20891, 23581, 27038, 27037, 288, 929, 14753, 289, 16167, 21800, 16170, 20915, 29876, 21172, 3768, 313, 32319, 12481, 4034, 5322, 30539, 27340, 21834, 3920, 336, 15316, 213, 214, 22616, 24285, 224, 23906, 228, 22889, 22381, 25838, 29039, 21232, 29040, 22896, 5108, 15098}\n",
      "dict_items([(\"Lemma('twenty-two.s.01.22')\", 13), (\"Lemma('twenty-two.n.01.22')\", 4)])\n",
      "collecting tokens for  16\n",
      "indices:    {20736, 27395, 22406, 32262, 22412, 1936, 22545, 15634, 29713, 28182, 2969, 29593, 28827, 3740, 23581, 28829, 25883, 288, 29729, 16163, 4132, 548, 23334, 28583, 16167, 28585, 24618, 24746, 22959, 16176, 3121, 22961, 1715, 28591, 29877, 28598, 29619, 3130, 3517, 15550, 4031, 21568, 25794, 4036, 15558, 29129, 15563, 21579, 29134, 3791, 3920, 20820, 20825, 5596, 32608, 24677, 3559, 2409, 24048, 22517, 20983, 11385}\n",
      "dict_items([(\"Lemma('sixteen.n.01.16')\", 4), (\"Lemma('sixteen.s.01.16')\", 17)])\n",
      "collecting tokens for  schedule\n",
      "indices:    {23303, 29202, 15256, 27421, 30109, 680, 30760, 12073, 15662, 3896, 575, 30528, 20800, 24777, 15182, 3919, 3920, 21584, 32464, 3922, 3926, 3927, 12000, 23009, 29155, 23013, 31595, 21099, 20721, 32511}\n",
      "dict_items([(\"Lemma('schedule.n.02.schedule')\", 4), (\"Lemma('agenda.n.01.schedule')\", 9), (\"Lemma('schedule.v.01.schedule')\", 2)])\n",
      "collecting tokens for  onset\n",
      "indices:    {3923, 3918}\n",
      "dict_items([(\"Lemma('onset.n.01.onset')\", 2)])\n",
      "collecting tokens for  operating\n",
      "indices:    {15489, 31239, 23670, 32503, 15485}\n",
      "dict_items([(\"Lemma('function.v.01.operate')\", 2), (\"Lemma('operate.v.01.operate')\", 1)])\n",
      "collecting tokens for  red\n",
      "indices:    {18824, 13973}\n",
      "dict_items([(\"Lemma('red.s.01.red')\", 1)])\n",
      "collecting tokens for  cut\n",
      "indices:    {20193, 22887, 31531, 12524, 12620, 25006, 32815, 17361, 19795, 31510, 29594, 29753, 19962, 6683, 444, 28797, 28415}\n",
      "dict_items([(\"Lemma('cut_to_ribbons.v.01.cut_to_ribbons')\", 1), (\"Lemma('cut.n.01.cut')\", 1), (\"Lemma('cut.v.01.cut')\", 3), (\"Lemma('swerve.v.01.cut')\", 2), (\"Lemma('reduce.v.01.cut')\", 1)])\n",
      "collecting tokens for  autonomy\n",
      "indices:    {23521, 14703, 24176, 25815, 25816, 27770, 25820}\n",
      "dict_items([(\"Lemma('autonomy.n.01.autonomy')\", 1)])\n",
      "collecting tokens for  mayor\n",
      "indices:    {24164}\n",
      "dict_items([])\n",
      "collecting tokens for  department\n",
      "indices:    {13}\n",
      "dict_items([])\n",
      "collecting tokens for  snakes\n",
      "indices:    {3713, 3746, 3683, 3684, 3686, 3754, 3723, 3724, 10476, 3726, 3759, 3701, 3707, 3708}\n",
      "dict_items([(\"Lemma('snake.n.01.snake')\", 12)])\n",
      "collecting tokens for  /\n",
      "indices:    {29057, 27522, 1413, 30218, 11530, 32282, 5532, 5533, 16158, 5535, 32286, 5540, 5541, 29992, 16044, 5550, 16047, 32304, 3121, 5552, 16051, 3120, 5557, 5554, 30263, 3128, 6836, 5558, 29128, 14793, 29131, 5580, 32589, 5582, 5581, 3152, 3276, 5587, 5589, 3541, 5591, 6872, 5593, 5592, 5596, 11744, 3554, 3555, 14570, 25970, 11891, 5490, 5493, 11768, 30330, 30331, 32511}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([])\n",
      "collecting tokens for  value\n",
      "indices:    {32768, 22024, 22026, 16396, 14350, 22032, 11807, 27176, 22575, 27184, 3126, 3127, 3130, 3131, 4670, 27210, 30795, 4686, 22612, 4704, 32880, 32378, 3715, 22661, 32395, 26778, 15522, 4775, 15538, 4786, 32436, 32434, 32438, 32948, 4793, 30394, 4284, 23741, 27328, 22721, 13505, 4816, 14032, 28880, 23762, 12500, 4821, 732, 4829, 3302, 14605, 22799, 16144, 22803, 3861, 14619, 21276, 21278, 3362, 14628, 4907, 14636, 2864, 32055, 1847, 32057, 15163, 33085, 13629, 23872, 14660, 1865, 31050, 13648, 13649, 13651, 4436, 33107, 3925, 12121, 12125, 13663, 35683, 13670, 4456, 1908, 12154, 4475, 4479, 4480, 2434, 15753, 12172, 2956, 12176, 12179, 3479, 12186, 15265, 15266, 20388, 14245, 15274, 13740, 33200, 14773, 31162, 4546, 3010, 4547, 4548, 29135, 5586, 9174, 3031, 32727, 11739, 32733, 14310, 2038, 1531}\n",
      "dict_items([(\"Lemma('value.n.03.value')\", 10), (\"Lemma('value.n.01.value')\", 22), (\"Lemma('value.n.02.value')\", 26)])\n",
      "collecting tokens for  establishment\n",
      "indices:    {27523, 32904, 12938, 1035, 32267, 25469, 907, 14865, 4754, 22677, 14229, 3479, 24, 22679, 36528, 14897, 27698, 9142, 22845, 25024, 25025, 32456, 16207, 31185, 18517, 12504, 24038, 12264, 27754, 106, 27758, 16238, 32753, 20211, 124, 25725, 32895}\n",
      "dict_items([(\"Lemma('establishment.n.04.establishment')\", 1), (\"Lemma('constitution.n.02.establishment')\", 10), (\"Lemma('administration.n.02.establishment')\", 2), (\"Lemma('institution.n.01.establishment')\", 2), (\"Lemma('establishment.n.05.establishment')\", 1)])\n",
      "collecting tokens for  speak\n",
      "indices:    {32256, 5632, 13442, 14601, 22538, 14352, 10256, 28304, 31005, 27299, 31144, 10152, 809, 31147, 20011, 7595, 16174, 31279, 24744, 13617, 23730, 13888, 20801, 5698, 6981, 8135, 20808, 19401, 8523, 27341, 14672, 32210, 5715, 9174, 15832, 27611, 13788, 1502, 16479, 7903, 4964, 31084, 14445, 19439, 1267, 34297, 5242, 5886}\n",
      "dict_items([(\"Lemma('talk.v.02.speak')\", 17), (\"Lemma('address.v.02.speak')\", 2), (\"Lemma('talk.v.01.speak')\", 10), (\"Lemma('speak.v.03.speak')\", 3)])\n",
      "collecting tokens for  peculiar\n",
      "indices:    {23742, 34747, 9833, 16171, 36044, 9680, 11123, 22708, 16597, 13621, 16436, 25140, 22393, 12219, 13852, 5213, 14686, 13343}\n",
      "dict_items([(\"Lemma('curious.s.01.peculiar')\", 6), (\"Lemma('particular.s.01.peculiar')\", 6)])\n",
      "collecting tokens for  shelley\n",
      "indices:    {14687}\n",
      "dict_items([(\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  poems\n",
      "indices:    {2369, 5860, 13805, 31537, 13811, 14676, 13812, 13818, 14686, 4991}\n",
      "dict_items([(\"Lemma('poem.n.01.poem')\", 7)])\n",
      "collecting tokens for  describing\n",
      "indices:    {14686, 13634, 24746, 14698, 31116, 8913, 31093, 26521, 21406}\n",
      "dict_items([(\"Lemma('describe.v.01.describe')\", 7), (\"Lemma('trace.v.02.describe')\", 1), (\"Lemma('report.v.01.describe')\", 1)])\n",
      "collecting tokens for  contrasting\n",
      "indices:    {20514, 27012, 29671, 29677, 15503, 12244, 26008, 14686, 24191}\n",
      "dict_items([(\"Lemma('contrasting.s.01.contrasting')\", 1), (\"Lemma('contrast.v.01.contrast')\", 1), (\"Lemma('contrast.v.02.contrast')\", 3)])\n",
      "collecting tokens for  mode\n",
      "indices:    {31586, 31587, 31588, 13673, 15850, 33260, 13677, 29489, 3125, 13622, 15864, 1306, 5211, 14685, 14686, 33215}\n",
      "dict_items([(\"Lemma('manner.n.01.mode')\", 10)])\n",
      "collecting tokens for  deputy\n",
      "indices:    {17937, 18186, 17958}\n",
      "dict_items([(\"Lemma('deputy.n.01.deputy')\", 2)])\n",
      "collecting tokens for  sheriff\n",
      "indices:    {34208, 34211}\n",
      "dict_items([])\n",
      "collecting tokens for  posse\n",
      "indices:    {5091, 5093, 5066, 2445, 5070, 5071, 5106, 5109, 2425, 2426, 5086}\n",
      "dict_items([(\"Lemma('posse.n.01.posse')\", 11)])\n",
      "collecting tokens for  maxwell\n",
      "indices:    {26558}\n",
      "dict_items([])\n",
      "collecting tokens for  realized\n",
      "indices:    {16513, 33793, 27523, 13445, 7305, 31498, 5771, 32655, 6928, 2453, 36629, 19229, 17566, 22061, 30513, 22718, 35653, 11335, 19070, 33484, 11468, 15829, 5112, 15837, 35425, 34406, 36967, 30952, 31212, 17266, 31094, 16632, 13305, 35450, 7419, 15870, 36991}\n",
      "dict_items([(\"Lemma('recognize.v.02.realize')\", 17), (\"Lemma('understand.v.02.realize')\", 13), (\"Lemma('realize.v.03.realize')\", 4), (\"Lemma('gain.v.08.realize')\", 2)])\n",
      "collecting tokens for  opera\n",
      "indices:    {26975, 31622, 26791}\n",
      "dict_items([])\n",
      "collecting tokens for  closed\n",
      "indices:    {22532, 24073, 9231, 34831, 21007, 7699, 34328, 7202, 3618, 25637, 25639, 25642, 7740, 11328, 33364, 2134, 33374, 23137, 33385, 7791, 1140, 17548, 8846, 25755, 6813, 8879, 24241, 11961, 4284, 17596, 10430, 13525, 18136, 35547, 37086, 6879, 7396, 34030, 8434, 4354, 4357, 4358, 18183, 30984, 13580, 7440, 34584, 31005, 24354, 31012, 24872, 4907, 6961, 4913, 4915, 33587, 33593, 35142, 17738, 34132, 7000, 27481, 4960, 34148, 21363, 7539, 4481, 4484, 18822, 22925, 912, 9624, 8604, 25012, 4533, 4532, 4539, 16832, 961, 26563, 15840, 36321, 20963, 21490, 13305, 21503}\n",
      "dict_items([(\"Lemma('closed.a.04.closed')\", 3), (\"Lemma('close.v.01.close')\", 23), (\"Lemma('shut.a.01.closed')\", 6), (\"Lemma('close.v.02.close')\", 7), (\"Lemma('conclude.v.04.close')\", 1), (\"Lemma('closed.a.01.closed')\", 8), (\"Lemma('close_up.v.01.close')\", 10), (\"Lemma('close.v.04.close')\", 5), (\"Lemma('closed.s.05.closed')\", 1), (\"Lemma('closed.a.02.closed')\", 6)])\n",
      "collecting tokens for  doors\n",
      "indices:    {21824, 9186, 20131, 17604, 29830, 12104, 29865, 11179, 22579, 5461, 11478, 37047, 26808, 18553}\n",
      "dict_items([(\"Lemma('door.n.01.door')\", 3), (\"Lemma('door.n.03.door')\", 2), (\"Lemma('doorway.n.01.door')\", 1)])\n",
      "collecting tokens for  instances\n",
      "indices:    {3458, 32258, 32900, 2184, 14736, 31254, 32160, 4279, 31101, 3521, 26563, 28745, 2124, 28750, 15824, 21206, 4954, 15841, 14706, 20340, 11126, 23932, 11517, 13695}\n",
      "dict_items([(\"Lemma('case.n.01.instance')\", 11), (\"Lemma('example.n.01.instance')\", 2)])\n",
      "collecting tokens for  controls\n",
      "indices:    {32446}\n",
      "dict_items([])\n",
      "collecting tokens for  t\n",
      "indices:    {4345}\n",
      "dict_items([])\n",
      "collecting tokens for  charlie\n",
      "indices:    {8794}\n",
      "dict_items([(\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  lock\n",
      "indices:    {34321, 34070, 17562, 17563, 19507, 19508, 18357, 31034, 33725, 28735, 29888, 28738, 28742, 34259, 34263, 26217, 9581, 28785, 28789, 24701}\n",
      "dict_items([(\"Lemma('lock.n.01.lock')\", 5), (\"Lemma('engage.v.10.lock')\", 2), (\"Lemma('lock_in.v.02.lock_in')\", 1), (\"Lemma('lock.v.04.lock')\", 1), (\"Lemma('lock.v.01.lock')\", 1), (\"Lemma('lock.v.03.lock')\", 1)])\n",
      "collecting tokens for  hair\n",
      "indices:    {8197, 19482, 18459, 9246, 26142, 8738, 8229, 8744, 27194, 34876, 25686, 9303, 25690, 13413, 36968, 26217, 14453, 26236, 34976, 37033, 34985, 9393, 17588, 7349, 17589, 8888, 6333, 37054, 37056, 16578, 35522, 7880, 7882, 6865, 6869, 35038, 31457, 36068, 19178, 31473, 35592, 13581, 6433, 4390, 30503, 17703, 33593, 19262, 10569, 4430, 34139, 10600, 11114, 7019, 30069, 9596, 36748, 36753, 36763, 35744, 34208, 18853, 18855, 8104, 9665, 8130, 18886, 7111, 17875, 9171, 18905, 9181, 5604, 9191, 7146, 5612, 9709, 9710, 24562, 23031}\n",
      "dict_items([(\"Lemma('hair.n.01.hair')\", 26)])\n",
      "collecting tokens for  covered\n",
      "indices:    {14861, 2067, 14874, 14885, 14886, 4137, 4138, 14890, 14895, 34876, 19520, 36416, 29776, 11865, 19035, 25190, 26217, 19049, 32363, 8827, 36998, 19084, 35988, 27800, 29353, 23214, 5822, 29381, 20172, 24278, 18649, 8921, 29403, 29404, 29405, 29917, 13540, 35560, 30954, 15082, 13548, 29935, 20720, 29937, 15103, 10496, 15105, 6914, 35587, 31496, 6923, 29963, 29970, 29973, 18724, 36645, 27945, 27948, 16686, 8496, 33076, 31029, 32578, 15190, 1878, 1881, 7007, 2915, 3434, 36719, 3450, 3452, 2940, 3453, 29566, 7551, 33154, 34179, 5030, 12733, 5053, 7101, 18897, 29147, 12773, 4069, 34792, 5102}\n",
      "dict_items([(\"Lemma('cover.v.01.cover')\", 22), (\"Lemma('cover.v.03.cover')\", 9), (\"Lemma('covered.a.01.covered')\", 11), (\"Lemma('cover.v.05.cover')\", 5), (\"Lemma('cover.v.04.cover')\", 10), (\"Lemma('traverse.v.01.cover')\", 1), (\"Lemma('cover.v.02.cover')\", 11), (\"Lemma('embrace.v.01.cover')\", 2), (\"Lemma('cover.v.09.cover')\", 1)])\n",
      "collecting tokens for  forehead\n",
      "indices:    {16513, 5731, 13413, 26217, 10921, 9171, 31477, 35963}\n",
      "dict_items([(\"Lemma('brow.n.01.forehead')\", 5)])\n",
      "collecting tokens for  occasional\n",
      "indices:    {1569, 9188, 12844, 31000, 8476}\n",
      "dict_items([(\"Lemma('occasional.s.01.occasional')\", 4)])\n",
      "collecting tokens for  dull\n",
      "indices:    {13955, 5638, 13578, 31375, 9628, 21916, 22556, 37025, 11300, 22437, 27079, 6365, 26081, 18918, 26217, 18538, 17132, 7160, 29564, 13950}\n",
      "dict_items([(\"Lemma('dull.a.02.dull')\", 4), (\"Lemma('dull.s.03.dull')\", 1), (\"Lemma('dull.a.01.dull')\", 3), (\"Lemma('boring.s.01.dull')\", 2)])\n",
      "collecting tokens for  stare\n",
      "indices:    {9152, 20071, 26217, 10153, 16941, 13586, 5654, 11162, 10844}\n",
      "dict_items([(\"Lemma('stare.n.01.stare')\", 4), (\"Lemma('gaze.v.01.stare')\", 4)])\n",
      "collecting tokens for  behavior\n",
      "indices:    {14643, 16182, 16919, 32986, 33214}\n",
      "dict_items([(\"Lemma('behavior.n.02.behavior')\", 2), (\"Lemma('behavior.n.01.behavior')\", 1)])\n",
      "collecting tokens for  mistakes\n",
      "indices:    {28964, 21703, 28136, 26217, 24279, 26031, 15795, 29719, 25559, 23996, 15773, 21950}\n",
      "dict_items([(\"Lemma('mistake.n.01.mistake')\", 2), (\"Lemma('mistake.v.01.mistake')\", 1)])\n",
      "collecting tokens for  statesman\n",
      "indices:    {31712, 31777, 31177, 23114, 31179, 754, 27027, 32216, 32223}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('statesman.n.01.statesman')\", 1)])\n",
      "collecting tokens for  qualities\n",
      "indices:    {20992, 27147, 11660, 5005, 13482, 4908, 13614, 11184, 13617, 14643, 4921, 5445, 26441, 26187, 13647, 16211, 13524, 23771, 13660, 13661, 5351, 1768, 26217, 26599, 32240, 22392, 1020}\n",
      "dict_items([(\"Lemma('quality.n.03.quality')\", 3), (\"Lemma('quality.n.01.quality')\", 13), (\"Lemma('timbre.n.01.quality')\", 2)])\n",
      "collecting tokens for  brooding\n",
      "indices:    {5758, 35198, 3758, 526}\n",
      "dict_items([(\"Lemma('brood.v.01.brood')\", 1), (\"Lemma('brooding.n.01.brooding')\", 1), (\"Lemma('brooding.s.01.brooding')\", 1)])\n",
      "collecting tokens for  shot\n",
      "indices:    {18657, 17538, 5060, 17574, 25415, 29097, 25867, 18219, 5420, 523, 35629, 10667, 10676, 564, 29078, 21209, 17182}\n",
      "dict_items([(\"Lemma('stroke.n.01.shot')\", 2), (\"Lemma('shoot.v.02.shoot')\", 2), (\"Lemma('shooting.n.01.shot')\", 3), (\"Lemma('shoot.v.01.shoot')\", 1), (\"Lemma('shot.n.05.shot')\", 1)])\n",
      "collecting tokens for  straight\n",
      "indices:    {22917, 4489, 22410, 17044, 918, 12823, 919, 26142, 15135, 1441, 23330, 4390, 297, 4394, 17580, 302, 6323, 179, 1593, 18234, 35771, 18747, 33469, 25915, 28863, 3654, 7370, 4940, 30670, 22992, 33882, 29673, 31466, 36716, 19696, 10864, 36721, 9078, 29687, 9462, 2427, 18301}\n",
      "dict_items([(\"Lemma('straight.s.01.straight')\", 4), (\"Lemma('directly.r.01.straight')\", 7), (\"Lemma('straight.s.04.straight')\", 1), (\"Lemma('directly.r.04.straight')\", 2), (\"Lemma('straight.a.03.straight')\", 2), (\"Lemma('straight.a.02.straight')\", 3)])\n",
      "collecting tokens for  custom\n",
      "indices:    {34386, 2114, 29015}\n",
      "dict_items([(\"Lemma('custom.n.01.custom')\", 1)])\n",
      "collecting tokens for  fixed\n",
      "indices:    {32800, 31717, 36716, 20052, 6524, 8317}\n",
      "dict_items([(\"Lemma('pay_back.v.02.fix')\", 1), (\"Lemma('fix.v.06.fix')\", 1), (\"Lemma('repair.v.01.fix')\", 1), (\"Lemma('fixed.s.04.fixed')\", 1)])\n",
      "collecting tokens for  capture\n",
      "indices:    {3363, 26570, 12970, 23472, 14288, 24818, 25905, 14676, 5112, 27321, 2429, 12222}\n",
      "dict_items([(\"Lemma('capture.v.01.capture')\", 4), (\"Lemma('appropriate.v.02.capture')\", 1), (\"Lemma('capture.n.01.capture')\", 2), (\"Lemma('get.v.11.capture')\", 1), (\"Lemma('capture.v.02.capture')\", 2), (\"Lemma('capture.n.02.capture')\", 1), (\"Lemma('capture.v.06.capture')\", 1)])\n",
      "collecting tokens for  porter\n",
      "indices:    {2423}\n",
      "dict_items([(\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  standard\n",
      "indices:    {403, 27196, 29829}\n",
      "dict_items([])\n",
      "collecting tokens for  roughly\n",
      "indices:    {28931, 31223, 21815, 3208, 16040, 25417, 27560, 26446, 14671, 1392, 18193, 2512, 1690, 2808, 3897, 31482, 23835, 2429}\n",
      "dict_items([(\"Lemma('approximately.r.01.roughly')\", 9), (\"Lemma('roughly.r.03.roughly')\", 1)])\n",
      "collecting tokens for  seat\n",
      "indices:    {24580, 33670, 29704, 21009, 20626, 35603, 18843, 19485, 35746, 33957, 18855, 11179, 33970, 33716, 33718, 29750, 6335, 24640, 13123, 5957, 18887, 23114, 9167, 2001, 17234, 17236, 33621, 33364, 34144, 33894, 2022, 2025, 31338, 2026, 34028, 34030, 1777, 34034, 34039, 2429, 1791}\n",
      "dict_items([(\"Lemma('seat.n.01.seat')\", 7), (\"Lemma('seat.n.03.seat')\", 2), (\"Lemma('buttocks.n.01.seat')\", 4), (\"Lemma('seat.n.04.seat')\", 1), (\"Lemma('seat.n.05.seat')\", 1)])\n",
      "collecting tokens for  journey\n",
      "indices:    {12512, 26539, 8811, 31118, 35986, 11480, 26463}\n",
      "dict_items([(\"Lemma('journey.n.01.journey')\", 3)])\n",
      "collecting tokens for  winter\n",
      "indices:    {8442}\n",
      "dict_items([(\"Lemma('winter.n.01.winter')\", 1)])\n",
      "collecting tokens for  boats\n",
      "indices:    {32412}\n",
      "dict_items([])\n",
      "collecting tokens for  adopted\n",
      "indices:    {27776, 24195, 31236, 32397, 15256, 21656, 31777, 13986, 4014, 4015, 21425, 19765, 32055, 14029, 14031, 27860, 20821, 20820, 21207, 3676, 21216, 31713, 5351, 20331, 123, 1134, 27888, 14196, 27895, 22011}\n",
      "dict_items([(\"Lemma('adopt.v.02.adopt')\", 2), (\"Lemma('adopt.v.01.adopt')\", 22), (\"Lemma('adopted.a.01.adopted')\", 2), (\"Lemma('adopt.v.05.adopt')\", 1), (\"Lemma('assume.v.02.adopt')\", 1)])\n",
      "collecting tokens for  favorite\n",
      "indices:    {21656, 1694, 29472, 10660, 28069, 22310, 31655, 31664, 20921, 29114, 22078, 36670, 22080, 26431, 22083, 22086, 29388, 26449, 36196, 22386, 14586, 7035}\n",
      "dict_items([(\"Lemma('favorite.s.01.favorite')\", 1), (\"Lemma('darling.n.01.favorite')\", 1), (\"Lemma('favored.s.01.favorite')\", 1), (\"Lemma('favorite.n.01.favorite')\", 1)])\n",
      "collecting tokens for  quarters\n",
      "indices:    {34569, 28170, 12563, 36501, 21656, 29977, 36640, 12577, 10530, 7461, 12840, 29998, 24644, 34377, 12116, 23382, 15196, 863, 32353, 7671, 10488}\n",
      "dict_items([(\"Lemma('quarter.n.02.quarter')\", 2), (\"Lemma('one-fourth.n.01.quarter')\", 2), (\"Lemma('living_quarters.n.01.quarters')\", 6)])\n",
      "collecting tokens for  helping\n",
      "indices:    {20771}\n",
      "dict_items([(\"Lemma('help.v.01.help')\", 1)])\n",
      "collecting tokens for  strike\n",
      "indices:    {16323, 10853, 22821, 16359, 23497, 21899, 22799, 2929, 25586, 31313, 22748, 24690, 33663, 28441, 22716, 13655, 2652}\n",
      "dict_items([(\"Lemma('strike.v.04.strike')\", 3), (\"Lemma('affect.v.05.strike')\", 2), (\"Lemma('strike.v.01.strike')\", 1), (\"Lemma('strike.n.01.strike')\", 2), (\"Lemma('strike.v.07.strike')\", 1), (\"Lemma('strike.v.11.strike')\", 1)])\n",
      "collecting tokens for  continues\n",
      "indices:    {14851, 30999, 15897, 27802, 27803, 15903, 15135, 16287, 31525, 14246, 3621, 680, 31529, 15914, 12069, 15281, 3770, 25543, 11086, 5456, 23896, 13787, 32734, 5475, 2790, 16360, 15081, 25584, 2168, 32254}\n",
      "dict_items([(\"Lemma('continue.v.01.continue')\", 25), (\"Lemma('continue.v.02.continue')\", 3), (\"Lemma('continue.v.03.continue')\", 1), (\"Lemma('proceed.v.02.continue')\", 1)])\n",
      "collecting tokens for  pressure\n",
      "indices:    {23042, 31263, 25119, 11314, 30786, 24651, 24142, 20047, 23119, 35921, 30801, 18514, 24657, 30804, 19545, 22631, 22636, 11376, 11392, 11393, 13443, 11396, 11397, 11401, 11404, 20625, 11923, 2215, 23725, 14514, 20665, 3264, 27842, 27843, 27844, 3268, 29897, 29898, 29900, 25813, 27866, 730, 731, 3305, 3823, 3824, 3826, 18171, 20223, 34059, 28947, 13588, 20759, 31000, 14615, 29982, 3368, 297, 31018, 10030, 31023, 31022, 14816, 31031, 4921, 3386, 2875, 22851, 28510, 5472, 2917, 10092, 885, 24441, 23930, 30102, 11672, 2969, 12696, 2971, 2972, 2973, 2974, 2975, 2976, 2977, 13213, 10147, 2982, 2989, 16813, 2991, 26548, 2997, 14776, 3000, 2496, 3009, 33219, 3014, 3019, 3023, 3025, 12757, 25558, 3030, 22488, 16345, 3034, 13783, 14809, 16349, 3550, 3552, 14817, 14818, 16355, 14820, 25573, 3040, 3559, 16360, 16359, 3562, 23531, 3555, 14823, 14830, 16367, 16366, 18408, 14825, 3573, 16374, 25594}\n",
      "dict_items([(\"Lemma('pressure.n.02.pressure')\", 21), (\"Lemma('press.n.09.pressure')\", 4), (\"Lemma('pressure.n.01.pressure')\", 26), (\"Lemma('coerce.v.01.pressure')\", 1), (\"Lemma('imperativeness.n.01.pressure')\", 3), (\"Lemma('pressure.n.05.pressure')\", 1)])\n",
      "collecting tokens for  agreement\n",
      "indices:    {23823, 23824, 16403, 23829, 14748, 20765, 15261, 12062, 32420, 14888, 3381, 34358, 14778, 33724, 22844, 23872, 24263, 31691, 33363, 21844, 31958, 34391, 12502, 24696, 20579, 12268, 24695, 12280, 20734}\n",
      "dict_items([(\"Lemma('agreement.n.01.agreement')\", 3), (\"Lemma('agreement.n.03.agreement')\", 2), (\"Lemma('agreement.n.02.agreement')\", 2)])\n",
      "collecting tokens for  version\n",
      "indices:    {24740, 26405, 27044, 29128, 14078, 28943, 13906, 25939, 25236, 28661, 29109, 1812, 15539, 24764, 12606}\n",
      "dict_items([(\"Lemma('version.n.02.version')\", 4), (\"Lemma('version.n.01.version')\", 1)])\n",
      "collecting tokens for  link\n",
      "indices:    {20996, 27396, 12229, 15911, 16712, 11656, 8811, 36367, 36977, 16945, 13942, 13239, 30585, 31294}\n",
      "dict_items([(\"Lemma('associate.v.01.link')\", 2), (\"Lemma('link.n.01.link')\", 4), (\"Lemma('connect.v.01.link')\", 1), (\"Lemma('link.n.02.link')\", 3)])\n",
      "collecting tokens for  opium\n",
      "indices:    {16704, 16643, 16644, 16742, 16712, 16745, 16746, 16652, 16685, 16654, 16655, 16634, 16637, 16638}\n",
      "dict_items([(\"Lemma('opium.n.01.opium')\", 14)])\n",
      "collecting tokens for  cup\n",
      "indices:    {29536, 515, 20999, 7401, 7404, 16655, 8692, 33525, 29492, 11065, 16633, 6843, 29534}\n",
      "dict_items([(\"Lemma('cup.n.02.cup')\", 4), (\"Lemma('cup.n.01.cup')\", 3)])\n",
      "collecting tokens for  breaking\n",
      "indices:    {33295, 13202, 22555, 6942, 13216, 26402, 36133, 36905, 12462, 36662, 7231, 28993, 1350, 586, 21475, 15973, 21479, 13547, 10481, 12793}\n",
      "dict_items([(\"Lemma('breakage.n.03.breaking')\", 1), (\"Lemma('break.v.04.break')\", 1), (\"Lemma('transgress.v.01.break')\", 1), (\"Lemma('interrupt.v.04.break')\", 3), (\"Lemma('break.v.08.break')\", 1), (\"Lemma('fail.v.04.break')\", 1), (\"Lemma('break.v.05.break')\", 1), (\"Lemma('break.v.03.break')\", 1), (\"Lemma('break_in.v.01.break')\", 1), (\"Lemma('break.v.02.break')\", 1)])\n",
      "collecting tokens for  thunder\n",
      "indices:    {6462}\n",
      "dict_items([(\"Lemma('thunder.n.02.thunder')\", 1)])\n",
      "collecting tokens for  jerry\n",
      "indices:    {1179}\n",
      "dict_items([])\n",
      "collecting tokens for  kansas\n",
      "indices:    {26945}\n",
      "dict_items([])\n",
      "collecting tokens for  trap\n",
      "indices:    {26402, 13380, 29128, 32042, 29101, 29102, 3246, 29105, 25362, 30067, 30068, 11892, 4852, 22324, 7064}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('trap.n.01.trap')\", 2), (\"Lemma('trap.n.04.trap')\", 1), (\"Lemma('trap.n.02.trap')\", 1)])\n",
      "collecting tokens for  shock\n",
      "indices:    {6534, 1800, 30217, 4236, 30096, 18970, 16673, 27042, 34722, 25382, 7718, 4264, 7732, 17864, 18390, 12247, 30809, 4059, 12770, 27126, 30839}\n",
      "dict_items([(\"Lemma('daze.n.01.shock')\", 5), (\"Lemma('electric_shock.n.03.shock')\", 1), (\"Lemma('shock.n.05.shock')\", 1), (\"Lemma('shock.n.06.shock')\", 1), (\"Lemma('shock.n.04.shock')\", 1), (\"Lemma('shock.v.01.shock')\", 1)])\n",
      "collecting tokens for  generations\n",
      "indices:    {24705, 25380, 25382, 13613, 25390, 25262, 25396, 25397, 34486, 13750, 25424, 11863, 3674, 34916, 23785, 7786, 25452, 10094, 14330, 13566}\n",
      "dict_items([(\"Lemma('generation.n.03.generation')\", 3), (\"Lemma('coevals.n.01.generation')\", 3), (\"Lemma('generation.n.02.generation')\", 2)])\n",
      "collecting tokens for  legitimate\n",
      "indices:    {25382, 17929, 31212, 27276, 30030, 14222, 2228, 32405, 12310, 27801, 20671}\n",
      "dict_items([(\"Lemma('legitimate.s.02.legitimate')\", 1), (\"Lemma('lawful.s.04.legitimate')\", 1), (\"Lemma('legitimate.a.01.legitimate')\", 1), (\"Lemma('legitimate.s.03.legitimate')\", 1)])\n",
      "collecting tokens for  sermon\n",
      "indices:    {6053, 10706, 8370, 24760, 6044}\n",
      "dict_items([(\"Lemma('sermon.n.01.sermon')\", 4)])\n",
      "collecting tokens for  waiting\n",
      "indices:    {30304, 19079, 9994, 16818, 10548, 20052, 17044, 35544, 17534, 35900, 13310}\n",
      "dict_items([(\"Lemma('wait.v.02.wait')\", 2), (\"Lemma('wait.v.01.wait')\", 5), (\"Lemma('expect.v.03.wait')\", 2)])\n",
      "collecting tokens for  sheet\n",
      "indices:    {3077, 31375, 20239, 3088, 1044, 12566, 11293, 11297, 11301, 11302, 11697, 11314, 11313, 19515, 9796, 30406, 9803, 17740, 14542, 20056, 27613, 15742, 17641, 30954, 10219, 17646, 27630, 26750}\n",
      "dict_items([(\"Lemma('sheet.n.01.sheet')\", 2), (\"Lemma('sheet.n.02.sheet')\", 10), (\"Lemma('sheet.n.03.sheet')\", 2)])\n",
      "collecting tokens for  talents\n",
      "indices:    {27361, 31523, 1029, 14118, 11237, 11243, 11248, 24144, 1328, 23189, 661, 26233, 30939, 11357, 11263}\n",
      "dict_items([(\"Lemma('talent.n.02.talent')\", 3), (\"Lemma('endowment.n.01.talent')\", 6)])\n",
      "collecting tokens for  rug\n",
      "indices:    {31523, 5992, 12816, 17395, 36888, 35739, 24574, 24575}\n",
      "dict_items([(\"Lemma('rug.n.01.rug')\", 1)])\n",
      "collecting tokens for  poem\n",
      "indices:    {31523, 31587, 26531, 13798, 14634, 13875, 8437, 30742, 32092, 14680, 26268, 8381, 8446}\n",
      "dict_items([(\"Lemma('poem.n.01.poem')\", 6)])\n",
      "collecting tokens for  miniature\n",
      "indices:    {22496, 31523, 31591, 29101, 31535, 10519, 19515, 7965}\n",
      "dict_items([(\"Lemma('miniature.n.01.miniature')\", 1), (\"Lemma('miniature.n.02.miniature')\", 1), (\"Lemma('miniature.s.01.miniature')\", 1)])\n",
      "collecting tokens for  social\n",
      "indices:    {31808, 16420, 27848, 27592, 32939, 13329, 23542, 32986, 14364, 22525}\n",
      "dict_items([(\"Lemma('social.a.01.social')\", 2)])\n",
      "collecting tokens for  rise\n",
      "indices:    {16384, 9348, 31623, 8711, 8846, 34831, 30224, 29073, 30226, 8594, 14102, 21911, 3480, 1659, 2590, 2975, 35616, 31523, 36263, 22568, 36524, 13613, 21933, 2864, 13617, 11443, 31227, 12730, 31419, 33216, 24029, 4035, 29380, 26951, 27723, 27467, 5456, 14931, 20180, 12757, 11476, 13911, 2008, 28505, 3418, 33236, 13917, 32221, 8670, 16352, 33249, 11489, 23778, 21987, 2913, 16356, 23405, 30062, 12911, 3312, 27250, 3571, 8567, 14457, 8570, 22011, 28924, 2941, 2942, 4991}\n",
      "dict_items([(\"Lemma('rise.v.13.rise')\", 1), (\"Lemma('arise.v.03.rise')\", 7), (\"Lemma('get_up.v.02.rise')\", 1), (\"Lemma('rise.n.01.rise')\", 8), (\"Lemma('surface.v.01.rise')\", 1), (\"Lemma('rise.v.02.rise')\", 4), (\"Lemma('ascent.n.01.rise')\", 1), (\"Lemma('rise.v.01.rise')\", 8), (\"Lemma('rise.n.04.rise')\", 1), (\"Lemma('upgrade.n.04.rise')\", 1), (\"Lemma('rise.n.02.rise')\", 3), (\"Lemma('rise.v.04.rise')\", 3), (\"Lemma('rise.v.11.rise')\", 2), (\"Lemma('rebel.v.01.rise')\", 1), (\"Lemma('rise.v.12.rise')\", 2), (\"Lemma('wax.v.02.rise')\", 1), (\"Lemma('raise.n.01.rise')\", 1), (\"Lemma('heighten.v.01.rise')\", 1)])\n",
      "collecting tokens for  response\n",
      "indices:    {15393, 16356, 31205, 5224, 5656, 1242, 8748, 12044, 3824, 13617, 21650, 22356, 916, 20280, 1658, 21212, 23838}\n",
      "dict_items([(\"Lemma('reaction.n.03.response')\", 3), (\"Lemma('response.n.01.response')\", 6), (\"Lemma('reception.n.01.response')\", 1), (\"Lemma('answer.n.01.response')\", 1)])\n",
      "collecting tokens for  london\n",
      "indices:    {26945}\n",
      "dict_items([])\n",
      "collecting tokens for  favorable\n",
      "indices:    {24068, 4741, 15366, 1424, 23962, 25758, 11300, 22833, 12992, 22852, 24013, 30159, 22618, 14188, 33137, 22643, 118, 15352, 12796, 8445, 20478}\n",
      "dict_items([(\"Lemma('favorable.a.01.favorable')\", 3), (\"Lemma('golden.s.06.favorable')\", 1), (\"Lemma('favorable.a.02.favorable')\", 1)])\n",
      "collecting tokens for  le\n",
      "indices:    {7398}\n",
      "dict_items([])\n",
      "collecting tokens for  n.\n",
      "indices:    {5140}\n",
      "dict_items([])\n",
      "collecting tokens for  y.\n",
      "indices:    {30517}\n",
      "dict_items([])\n",
      "collecting tokens for  showing\n",
      "indices:    {2048, 28546, 2439, 28555, 33419, 22030, 15761, 1684, 19607, 36249, 26013, 1822, 11806, 1825, 28578, 20261, 15782, 28583, 28586, 28587, 28588, 28591, 14389, 33471, 22207, 35269, 12233, 20302, 15829, 33755, 15837, 12765, 15581, 18784, 14432, 26464, 21995, 5619, 28537, 14459, 4604, 34687}\n",
      "dict_items([(\"Lemma('prove.v.02.show')\", 4), (\"Lemma('display.n.02.showing')\", 1), (\"Lemma('show.v.01.show')\", 19), (\"Lemma('indicate.v.02.show')\", 3), (\"Lemma('screening.n.01.showing')\", 1), (\"Lemma('picture.v.02.show')\", 2), (\"Lemma('show.v.04.show')\", 3), (\"Lemma('show.v.08.show')\", 1), (\"Lemma('express.v.01.show')\", 1)])\n",
      "collecting tokens for  nd\n",
      "indices:    {32643, 22917, 32486, 32648, 28587, 22959, 22904, 25661, 30526}\n",
      "dict_items([])\n",
      "collecting tokens for  page\n",
      "indices:    {13739}\n",
      "dict_items([])\n",
      "collecting tokens for  bullet\n",
      "indices:    {13028, 8197, 18215, 29064, 7887, 29073, 18225, 35443, 35348, 32022, 35612}\n",
      "dict_items([(\"Lemma('bullet.n.01.bullet')\", 3)])\n",
      "collecting tokens for  nearer\n",
      "indices:    {19849, 16205, 35566, 2831, 29997, 27185, 27311, 5469, 1086, 5055}\n",
      "dict_items([(\"Lemma('near.a.01.near')\", 2)])\n",
      "collecting tokens for  leg\n",
      "indices:    {17600, 1580, 10638, 1583, 10639, 18895, 35474, 1591, 12637}\n",
      "dict_items([(\"Lemma('leg.n.01.leg')\", 6)])\n",
      "collecting tokens for  passing\n",
      "indices:    {36612, 21511, 11030, 12055, 33432, 34427, 19485, 288, 16802, 7460, 15277, 20659, 23870, 35267, 32195, 25157, 4177, 4178, 29396, 474, 20575, 15840, 353, 355, 2669, 1011, 17396, 27768, 10491, 7548}\n",
      "dict_items([(\"Lemma('pass_through.v.02.pass_through')\", 2), (\"Lemma('sink.v.03.pass')\", 1), (\"Lemma('travel_by.v.01.pass')\", 3), (\"Lemma('legislate.v.01.pass')\", 2), (\"Lemma('pass.n.03.passing')\", 4), (\"Lemma('passing.n.02.passing')\", 1), (\"Lemma('pass.v.05.pass')\", 1), (\"Lemma('pass.v.01.pass')\", 3), (\"Lemma('ephemeral.s.01.passing')\", 1)])\n",
      "collecting tokens for  shakespeare\n",
      "indices:    {8381}\n",
      "dict_items([(\"Lemma('shakespeare.n.01.Shakespeare')\", 1)])\n",
      "collecting tokens for  wednesday\n",
      "indices:    {325}\n",
      "dict_items([(\"Lemma('wednesday.n.01.Wednesday')\", 1)])\n",
      "collecting tokens for  opening\n",
      "indices:    {28930, 28931, 28932, 12677, 23427, 28935, 25991, 26503, 5767, 33676, 1164, 24718, 26257, 530, 1172, 17812, 22552, 18715, 927, 36641, 30249, 1322, 20915, 24244, 6836, 32563, 952, 21689, 21304, 21310, 31678, 14783, 14785, 21314, 12225, 14786, 26056, 3273, 12234, 3659, 20939, 3275, 12369, 348, 35549, 221, 1248, 20833, 12896, 20963, 20962, 36200, 2153, 14445, 27887, 26864, 34928, 22512, 20978, 23153, 26484, 20854, 28541}\n",
      "dict_items([(\"Lemma('opening.n.01.opening')\", 4), (\"Lemma('opening.a.01.opening')\", 8), (\"Lemma('open.v.02.open')\", 5), (\"Lemma('open.v.04.open')\", 2), (\"Lemma('opening.n.03.opening')\", 2), (\"Lemma('opening.n.05.opening')\", 1), (\"Lemma('opening.n.04.opening')\", 1), (\"Lemma('opening.n.02.opening')\", 2), (\"Lemma('open.v.01.open')\", 2), (\"Lemma('open.v.03.open')\", 3)])\n",
      "collecting tokens for  park\n",
      "indices:    {21127}\n",
      "dict_items([])\n",
      "collecting tokens for  moisture\n",
      "indices:    {7172, 29037, 30799, 30192, 3279, 1650, 36051, 11572, 3285, 11573, 7159}\n",
      "dict_items([(\"Lemma('moisture.n.01.moisture')\", 7)])\n",
      "collecting tokens for  cheeks\n",
      "indices:    {7172, 18917, 6984, 10953, 19504, 15826, 18807, 18970}\n",
      "dict_items([(\"Lemma('cheek.n.01.cheek')\", 8)])\n",
      "collecting tokens for  gathered\n",
      "indices:    {7172, 9865, 22546, 1043, 14108, 29980, 33824, 32678, 2223, 25783, 7352, 5066, 9675, 3405, 36943, 15186, 18016, 29152, 23145, 33769, 9460, 22522}\n",
      "dict_items([(\"Lemma('meet.v.07.gather')\", 6), (\"Lemma('gather.v.04.gather')\", 1), (\"Lemma('gather.v.01.gather')\", 8), (\"Lemma('accumulate.v.02.gather')\", 2)])\n",
      "collecting tokens for  nose\n",
      "indices:    {8578, 7172, 7173, 7174, 31495, 262, 8716, 7185, 7186, 7187, 1172, 7189, 33681, 10263, 7188, 18465, 18467, 6436, 34088, 18472, 7987, 8116, 7094, 8001, 18883, 36164, 17605, 18886, 36432, 3409, 9173, 16602, 31834, 19294, 35935, 8929, 36717, 16622, 33653, 30583, 18813}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('nose.n.01.nose')\", 25), (\"Lemma('nose.n.02.nose')\", 2), (\"Lemma('nose.v.02.nose')\", 1)])\n",
      "collecting tokens for  geometric\n",
      "indices:    {5035}\n",
      "dict_items([])\n",
      "collecting tokens for  assembly\n",
      "indices:    {25186}\n",
      "dict_items([])\n",
      "collecting tokens for  readings\n",
      "indices:    {31137, 2945, 2982, 1725, 34504, 30566, 31114, 14634, 27628, 27184, 31122, 31132, 31133}\n",
      "dict_items([(\"Lemma('reading.n.01.reading')\", 1), (\"Lemma('reading.n.02.reading')\", 1), (\"Lemma('reading.n.03.reading')\", 2)])\n",
      "collecting tokens for  fluid\n",
      "indices:    {2980, 2981, 3019, 3021, 4047, 2960, 2993, 2961, 3407, 14804, 35631, 30326, 22461, 34683, 2972, 893, 2974, 4095}\n",
      "dict_items([(\"Lemma('fluid.n.01.fluid')\", 13), (\"Lemma('fluid.s.01.fluid')\", 1)])\n",
      "collecting tokens for  apparatus\n",
      "indices:    {4226, 2820, 1926, 1927, 1557, 10263, 1947, 3356, 2977, 2981, 30255, 14775, 4924, 3133, 4930, 11469, 11471, 11473, 727, 3545, 3550, 3551, 14846}\n",
      "dict_items([(\"Lemma('apparatus.n.01.apparatus')\", 22)])\n",
      "collecting tokens for  eddie\n",
      "indices:    {29039}\n",
      "dict_items([])\n",
      "collecting tokens for  abruptly\n",
      "indices:    {4998, 18570, 19245, 19950, 8918, 5658, 5403, 9343}\n",
      "dict_items([(\"Lemma('abruptly.r.01.abruptly')\", 8)])\n",
      "collecting tokens for  immediately\n",
      "indices:    {31875, 34950, 32905, 25872, 12823, 30233, 25628, 22941, 9246, 3870, 159, 14629, 17958, 3880, 32554, 3372, 22828, 28079, 23217, 31027, 24374, 28602, 11451, 22972, 32315, 4926, 34879, 9280, 17345, 27585, 1091, 2372, 32584, 33226, 13644, 6096, 29392, 4950, 18904, 12762, 18268, 21215, 14431, 32865, 12258, 5475, 12771, 13286, 30438, 31598, 24178, 20979, 13427, 22005, 25206, 23159, 5371, 5116, 5886}\n",
      "dict_items([(\"Lemma('immediately.r.01.immediately')\", 25), (\"Lemma('immediately.r.02.immediately')\", 4)])\n",
      "collecting tokens for  rousseau\n",
      "indices:    {6853}\n",
      "dict_items([(\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  asks\n",
      "indices:    {24157, 6757, 36777, 28617, 20299, 1259, 32107, 6750, 27414, 31066, 16381, 23934}\n",
      "dict_items([(\"Lemma('ask.v.02.ask')\", 6), (\"Lemma('ask.v.01.ask')\", 6)])\n",
      "collecting tokens for  antenna\n",
      "indices:    {2848, 2855, 15144, 11402, 2845, 2836, 11421, 2846, 2847}\n",
      "dict_items([(\"Lemma('antenna.n.01.antenna')\", 9)])\n",
      "collecting tokens for  moon\n",
      "indices:    {31554, 2842, 2845, 12358}\n",
      "dict_items([(\"Lemma('moon.n.01.Moon')\", 2)])\n",
      "collecting tokens for  brightness\n",
      "indices:    {2848, 28391, 2855, 2830, 2835, 2836, 2839, 17019, 3326, 2847}\n",
      "dict_items([(\"Lemma('brightness.n.01.brightness')\", 8)])\n",
      "collecting tokens for  beam\n",
      "indices:    {15072, 2848, 3267, 2855, 5833, 4146, 2836, 30357, 29690, 21052, 2845, 2846, 34175}\n",
      "dict_items([(\"Lemma('radio_beam.n.01.beam')\", 5), (\"Lemma('beam.n.04.beam')\", 1), (\"Lemma('beam.n.02.beam')\", 1)])\n",
      "collecting tokens for  assuming\n",
      "indices:    {16181, 2855, 32861, 25415}\n",
      "dict_items([(\"Lemma('assume.v.01.assume')\", 3), (\"Lemma('assume.v.03.assume')\", 1)])\n",
      "collecting tokens for  sky\n",
      "indices:    {29317, 35206, 28679, 18695, 30348, 23694, 2575, 2202, 2847, 13600, 10787, 6695, 31531, 18092, 24366, 19504, 34480, 34481, 27955, 5813, 19771, 31420, 11326, 36417, 5833, 6474, 35536, 31569, 8913, 17873, 8919, 7770, 34138, 21726, 7776, 31585, 6498, 5859, 33769, 7020, 24561, 6387, 18677, 6647, 18681}\n",
      "dict_items([(\"Lemma('sky.n.01.sky')\", 26)])\n",
      "collecting tokens for  negligible\n",
      "indices:    {30151, 2951, 2859, 3020, 2829, 3028, 2971, 2847}\n",
      "dict_items([(\"Lemma('negligible.s.01.negligible')\", 7)])\n",
      "collecting tokens for  integration\n",
      "indices:    {2464, 32961, 31810, 13348, 24423, 13358, 24212, 21461, 13690, 32603, 26748, 13343}\n",
      "dict_items([(\"Lemma('integration.n.01.integration')\", 5)])\n",
      "collecting tokens for  diagram\n",
      "indices:    {27554, 28742, 27533, 27566, 27535, 34675, 14010, 11356, 2847}\n",
      "dict_items([(\"Lemma('diagram.n.01.diagram')\", 2)])\n",
      "collecting tokens for  materials\n",
      "indices:    {31872, 2052, 29829, 15112, 22024, 5384, 15114, 3218, 2325, 31897, 31898, 14365, 29823, 5029, 2728, 2986, 2987, 2733, 14382, 15156, 11257, 14400, 2753, 3402, 30412, 13654, 11610, 1767, 11248, 2809, 31871}\n",
      "dict_items([(\"Lemma('material.n.01.material')\", 13), (\"Lemma('material.n.02.material')\", 6), (\"Lemma('fabric.n.01.material')\", 2)])\n",
      "collecting tokens for  needed\n",
      "indices:    {35840, 8192, 15874, 2051, 2052, 16912, 10258, 5138, 4628, 23573, 23579, 10268, 25633, 8225, 5155, 3621, 1580, 25134, 24632, 23098, 23628, 34894, 23118, 28754, 7771, 9312, 608, 32878, 25199, 9839, 11383, 11895, 23673, 30850, 14980, 12942, 23183, 11920, 29852, 23713, 20642, 15012, 1703, 34472, 1704, 21163, 30891, 2733, 22702, 20653, 182, 23222, 16054, 9927, 14535, 10446, 23769, 7385, 28895, 20200, 7408, 22783, 1793, 5892, 2311, 2315, 21771, 19724, 1803, 21264, 1815, 2842, 1832, 32554, 300, 11052, 3886, 15149, 32562, 7988, 13623, 824, 4409, 22844, 18243, 15172, 19270, 32583, 18254, 33102, 32594, 27986, 20315, 22877, 1888, 25445, 9061, 24936, 12138, 29546, 12140, 1901, 14211, 12163, 29069, 21902, 23437, 14223, 14235, 14237, 19362, 16291, 15783, 18350, 33208, 24002, 34759, 21961, 31690, 4050, 986, 16867, 2024, 27125, 18935}\n",
      "dict_items([(\"Lemma('necessitate.v.01.need')\", 26), (\"Lemma('want.v.02.need')\", 26), (\"Lemma('needed.s.01.needed')\", 20)])\n",
      "collecting tokens for  build\n",
      "indices:    {1544, 27913, 15113, 29707, 11660, 1549, 13838, 29196, 29820, 10257, 24977, 19217, 31508, 23834, 20125, 20512, 20771, 20773, 30118, 20778, 20524, 36656, 15152, 2097, 2096, 24626, 28466, 12725, 24887, 9144, 12473, 15156, 2624, 20039, 28492, 20173, 28496, 26705, 17878, 15706, 5595, 30174, 29921, 29411, 25059, 30181, 20199, 28649, 5486, 25071, 29554, 33138, 23541, 34677, 28024, 20089, 15099, 2556}\n",
      "dict_items([(\"Lemma('build.v.03.build')\", 2), (\"Lemma('construct.v.01.build')\", 26), (\"Lemma('physique.n.01.build')\", 1), (\"Lemma('build_up.v.02.build')\", 4)])\n",
      "collecting tokens for  basic\n",
      "indices:    {23808, 32130, 22791, 1929, 14351, 26513, 4629, 30232, 15006, 5025, 16162, 12066, 34339, 20259, 21287, 27691, 23092, 30393, 31290, 28734, 24896, 27840, 1219, 31177, 3402, 25675, 26829, 16334, 25294, 16211, 20820, 16085, 31960, 16351, 29539, 16356, 16358, 15467, 13675, 14061, 27886, 2159, 32509, 16383}\n",
      "dict_items([(\"Lemma('basic.s.02.basic')\", 6), (\"Lemma('basic.a.01.basic')\", 13)])\n",
      "collecting tokens for  b\n",
      "indices:    {3582}\n",
      "dict_items([])\n",
      "collecting tokens for  machine\n",
      "indices:    {6401, 24706, 6026, 24588, 28816, 16272, 21523, 2197, 21526, 2198, 30104, 2199, 5787, 5788, 2205, 2210, 2211, 36132, 2215, 2216, 2217, 17580, 2229, 25782, 12863, 21185, 21186, 30147, 27971, 30149, 12998, 3399, 27970, 30156, 30158, 5841, 3153, 32466, 11348, 2260, 5846, 5845, 2264, 2395, 2272, 12140, 31853, 36078, 2163, 22003, 11765}\n",
      "dict_items([(\"Lemma('machine.n.01.machine')\", 17), (\"Lemma('machine.n.04.machine')\", 1), (\"Lemma('machine.n.02.machine')\", 1)])\n",
      "collecting tokens for  cure\n",
      "indices:    {31200, 4257, 16065, 2211, 12065, 2278, 2214, 34472, 14023, 16493, 5485, 14166, 2199, 2269, 2266, 24667, 2205}\n",
      "dict_items([(\"Lemma('bring_around.v.02.cure')\", 10), (\"Lemma('remedy.n.02.cure')\", 7)])\n",
      "collecting tokens for  cancer\n",
      "indices:    {2206}\n",
      "dict_items([(\"Lemma('cancer.n.01.cancer')\", 1)])\n",
      "collecting tokens for  eliminated\n",
      "indices:    {17536, 3138, 28489, 4173, 34702, 9679, 30448, 31952, 14227, 2995, 26198, 15512, 2043, 15356, 2588, 32990, 5183}\n",
      "dict_items([(\"Lemma('extinguish.v.04.eliminate')\", 12), (\"Lemma('obviate.v.01.eliminate')\", 3), (\"Lemma('rule_out.v.03.eliminate')\", 1), (\"Lemma('excrete.v.01.eliminate')\", 1)])\n",
      "collecting tokens for  toll\n",
      "indices:    {29921, 23432, 2249, 29962, 23378, 23382, 27229}\n",
      "dict_items([(\"Lemma('price.n.03.toll')\", 1)])\n",
      "collecting tokens for  joyce\n",
      "indices:    {17923}\n",
      "dict_items([(\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  thor\n",
      "indices:    {28969}\n",
      "dict_items([])\n",
      "collecting tokens for  detectives\n",
      "indices:    {21209, 12660}\n",
      "dict_items([])\n",
      "collecting tokens for  clothes\n",
      "indices:    {19040, 5088, 8194, 6756, 36071, 8751, 6745, 9425, 36791, 30675, 22073, 26773, 19990, 30199, 9529}\n",
      "dict_items([(\"Lemma('apparel.n.01.clothes')\", 9)])\n",
      "collecting tokens for  containing\n",
      "indices:    {14848, 3586, 33027, 22403, 3589, 20749, 27027, 11546, 4130, 22056, 11562, 32813, 3249, 16178, 3507, 5557, 3510, 3515, 11326, 32837, 21318, 3527, 3273, 33230, 35412, 3285, 3541, 29403, 5090, 4068, 20965, 3558, 3947, 10991, 19069, 15742}\n",
      "dict_items([(\"Lemma('incorporate.v.02.contain')\", 26), (\"Lemma('hold.v.11.contain')\", 8)])\n",
      "collecting tokens for  identification\n",
      "indices:    {27840, 22688, 18754, 2308, 2309, 16420, 16423, 22727, 2300, 33022, 27864, 33020, 33021, 3550, 22687}\n",
      "dict_items([(\"Lemma('designation.n.03.identification')\", 1)])\n",
      "collecting tokens for  gross\n",
      "indices:    {15617}\n",
      "dict_items([(\"Lemma('gross.a.01.gross')\", 1)])\n",
      "collecting tokens for  dress\n",
      "indices:    {36100, 36103, 35080, 13180, 36490, 5009, 26386, 22167, 9497, 24989, 21151, 34976, 21152, 36387, 24229, 11181, 6317, 13234, 13235, 6966, 16569, 29247, 22080, 16964, 22084, 26566, 5452, 7375, 10963, 36181, 11862, 36445, 13794, 28782, 31856, 1777, 28660, 7417, 23035, 9340}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('dress.v.01.dress')\", 6), (\"Lemma('dress.n.01.dress')\", 7), (\"Lemma('dress.v.03.dress')\", 1), (\"Lemma('dress.v.02.dress')\", 1), (\"Lemma('dress_up.v.02.dress_up')\", 1), (\"Lemma('preen.v.03.dress')\", 2), (\"Lemma('attire.n.01.dress')\", 3), (\"Lemma('dress.v.06.dress')\", 1)])\n",
      "collecting tokens for  proprietor\n",
      "indices:    {2240, 14210, 21028, 21194, 14221, 11470, 21169, 33747, 7349, 14229}\n",
      "dict_items([(\"Lemma('owner.n.01.proprietor')\", 6)])\n",
      "collecting tokens for  paid\n",
      "indices:    {17409, 14854, 14855, 14856, 14859, 8223, 23079, 23080, 14889, 14888, 36907, 23081, 59, 21572, 18504, 13898, 19539, 24151, 19551, 33377, 12903, 32361, 16492, 9324, 32368, 24178, 32377, 25214, 23173, 25735, 36499, 25235, 11931, 669, 22691, 2221, 22711, 2239, 2240, 18625, 20672, 2243, 22723, 25800, 25801, 5322, 22731, 25804, 20689, 15571, 20181, 20694, 20184, 13530, 22747, 12507, 15582, 15583, 15587, 15588, 20198, 2790, 239, 27384, 13055, 28416, 37122, 21767, 23304, 32011, 10508, 13581, 22803, 21779, 15642, 36128, 27439, 13108, 12096, 12097, 35652, 26977, 23415, 27515, 24962, 23952, 7061, 14744, 16793, 1436, 11679, 15264, 21922, 31664, 12735, 31177, 11736, 17370, 11742, 8166}\n",
      "dict_items([(\"Lemma('pay.v.01.pay')\", 26), (\"Lemma('yield.v.10.pay')\", 5), (\"Lemma('give.v.05.pay')\", 10), (\"Lemma('paid.a.01.paid')\", 2), (\"Lemma('pay_up.v.01.pay')\", 2), (\"Lemma('give.v.10.pay')\", 4), (\"Lemma('nonrecreational.s.01.paid')\", 1), (\"Lemma('pay.v.05.pay')\", 1), (\"Lemma('pay.v.09.pay')\", 1), (\"Lemma('pay.v.08.pay')\", 1)])\n",
      "collecting tokens for  fake\n",
      "indices:    {2240, 2244, 2377, 2250, 2286, 13966, 2231, 2237}\n",
      "dict_items([(\"Lemma('bogus.s.01.fake')\", 7), (\"Lemma('fake.n.01.fake')\", 1)])\n",
      "collecting tokens for  health\n",
      "indices:    {27425, 23366, 12104, 13128, 16235, 27180, 20216, 4604}\n",
      "dict_items([(\"Lemma('health.n.01.health')\", 3)])\n",
      "collecting tokens for  happens\n",
      "indices:    {23809, 20364, 15378, 2585, 13977, 1701, 15791, 22717, 10173, 4289, 13251, 22858, 24535, 31583, 32224, 13536, 19176, 27241, 2025, 16495, 30960, 5367}\n",
      "dict_items([(\"Lemma('happen.v.01.happen')\", 13), (\"Lemma('happen.v.04.happen')\", 2), (\"Lemma('happen.v.02.happen')\", 2), (\"Lemma('happen.v.03.happen')\", 4)])\n",
      "collecting tokens for  am\n",
      "indices:    {12546, 25079, 6853, 34456, 6703, 31123, 30612, 30965, 36179, 10810, 15539, 10746, 10909}\n",
      "dict_items([(\"Lemma('be.v.01.be')\", 2), (\"Lemma('be.v.03.be')\", 1), (\"Lemma('be.v.02.be')\", 1)])\n",
      "collecting tokens for  deeply\n",
      "indices:    {4994, 35847, 24327, 14601, 4111, 37143, 26396, 36261, 6822, 33328, 13500, 20414, 22978, 20297, 33357, 12243, 31829, 31576, 31833, 27483, 7772, 2652, 32224, 31081, 25711, 12784, 28020, 16634, 24319}\n",
      "dict_items([(\"Lemma('profoundly.r.01.deeply')\", 8), (\"Lemma('deeply.r.02.deeply')\", 2)])\n",
      "collecting tokens for  interests\n",
      "indices:    {9345, 4738, 15235, 24073, 16395, 14734, 25617, 15254, 14871, 1824, 2721, 13729, 23844, 23473, 22706, 1843, 1847, 15417, 1853, 16318, 23999, 12992, 13377, 27844, 12997, 31175, 2377, 31691, 15437, 13390, 27855, 14930, 1876, 29142, 32216, 27865, 32224, 32225, 11878, 1901, 25197, 26742, 15225, 26749, 31743}\n",
      "dict_items([(\"Lemma('interest.n.05.interest')\", 2), (\"Lemma('interest.n.03.interest')\", 6), (\"Lemma('interest.n.06.interest')\", 4), (\"Lemma('sake.n.01.interest')\", 9), (\"Lemma('interest.n.01.interest')\", 2), (\"Lemma('pastime.n.01.interest')\", 2), (\"Lemma('interest.n.04.interest')\", 1)])\n",
      "collecting tokens for  carroll\n",
      "indices:    {12872}\n",
      "dict_items([(\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  simultaneously\n",
      "indices:    {4604}\n",
      "dict_items([(\"Lemma('simultaneously.r.01.simultaneously')\", 1)])\n",
      "collecting tokens for  intensity\n",
      "indices:    {2816, 4225, 14849, 3075, 2820, 2824, 2827, 4877, 23574, 4247, 5659, 13852, 15136, 3236, 16421, 4266, 559, 15159, 31160, 7608, 11706, 1734, 3271, 32073, 26058, 11476, 3290, 3292, 35936, 3298, 3300, 3301, 15718, 3302, 2798, 27886, 2802, 1778, 2803, 2804, 32117, 31228}\n",
      "dict_items([(\"Lemma('intensity.n.01.intensity')\", 22), (\"Lemma('intensity.n.02.intensity')\", 12)])\n",
      "collecting tokens for  nights\n",
      "indices:    {25659, 26909, 35198, 36013}\n",
      "dict_items([])\n",
      "collecting tokens for  afterward\n",
      "indices:    {33169, 22823}\n",
      "dict_items([])\n",
      "collecting tokens for  imagined\n",
      "indices:    {7360, 9601, 35524, 16583, 35402, 36970, 908, 36045, 9588, 26356, 14582, 4886, 19448, 33365, 9204, 9245, 2174, 26303}\n",
      "dict_items([(\"Lemma('imagine.v.01.imagine')\", 12), (\"Lemma('think.v.02.imagine')\", 3)])\n",
      "collecting tokens for  obscure\n",
      "indices:    {4736, 25730, 2469, 4234, 2602, 11052, 31599, 9588, 26549, 10203, 14653}\n",
      "dict_items([(\"Lemma('obscure.s.01.obscure')\", 3), (\"Lemma('dark.s.08.obscure')\", 2), (\"Lemma('obscure.v.03.obscure')\", 2), (\"Lemma('confuse.v.05.obscure')\", 1)])\n",
      "collecting tokens for  painful\n",
      "indices:    {5958, 13831, 6824, 27305, 12300, 27022, 7119, 32592, 34802, 22899, 9588, 2644, 1559, 4057, 10362, 19419}\n",
      "dict_items([(\"Lemma('painful.a.01.painful')\", 10), (\"Lemma('afflictive.s.01.painful')\", 1)])\n",
      "collecting tokens for  awake\n",
      "indices:    {5792, 17057, 30110, 34053, 34821, 7847, 15176, 9822, 6362, 9588, 6296, 9017, 36762, 34941, 36318}\n",
      "dict_items([(\"Lemma('wake_up.v.02.awake')\", 1), (\"Lemma('awake.a.01.awake')\", 7)])\n",
      "collecting tokens for  shame\n",
      "indices:    {24082, 9588, 36277, 6966, 6934, 25269, 9307, 11100, 19389}\n",
      "dict_items([(\"Lemma('dishonor.v.01.shame')\", 1), (\"Lemma('shame.n.02.shame')\", 1), (\"Lemma('shame.n.01.shame')\", 3), (\"Lemma('pity.n.02.shame')\", 1)])\n",
      "collecting tokens for  sleep\n",
      "indices:    {4225, 4228, 4243, 7316, 12952, 34584, 12953, 30110, 9002, 10555, 33603, 19654, 9813, 7520, 35045, 7800, 29692, 34941, 19711}\n",
      "dict_items([(\"Lemma('sleep.n.01.sleep')\", 7), (\"Lemma('sleep.v.01.sleep')\", 7)])\n",
      "collecting tokens for  replaced\n",
      "indices:    {20487, 11784, 11783, 27016, 1928, 34190, 28814, 14097, 18850, 5162, 21687, 16453, 29771, 11769, 4049, 15957, 11866, 3198, 4063, 31071, 31202, 16996, 11500, 28781, 32752, 11767, 28792, 9337, 29950, 15999}\n",
      "dict_items([(\"Lemma('replace.v.01.replace')\", 12), (\"Lemma('supplant.v.01.replace')\", 8), (\"Lemma('replace.v.03.replace')\", 6), (\"Lemma('substitute.v.01.replace')\", 4)])\n",
      "collecting tokens for  surface\n",
      "indices:    {4096, 32771, 32774, 32784, 31251, 13355, 32814, 14383, 11312, 11313, 32820, 32821, 1099, 3153, 3155, 3157, 3160, 3164, 19036, 3165, 2667, 3180, 3181, 3179, 3183, 3190, 3192, 3194, 3195, 3196, 34430, 3209, 3215, 3220, 3221, 3222, 15513, 28839, 19124, 29881, 711, 2247, 3787, 3279, 26833, 26834, 26835, 34522, 5856, 29413, 2794, 3306, 2796, 5357, 2799, 5361, 5362, 13555, 31477, 28920, 28921, 2809, 2810, 28923, 28924, 5370, 5375, 15099, 5377, 5379, 15110, 5382, 5385, 5386, 5387, 2836, 2841, 5413, 19242, 28458, 29525, 11608, 3417, 4952, 2910, 2914, 2915, 2916, 12791, 26982, 2930, 2931, 2937, 29562, 2940, 5502, 2944, 2945, 14721, 2949, 5511, 2951, 34698, 2957, 5522, 5030, 5548, 5559, 7611, 3018, 5583, 12754, 12757, 12250, 14813, 26077, 4064, 14816, 4069, 28133, 29670, 29672, 28137, 4076, 1007, 4080, 12784, 12790, 33271, 12793}\n",
      "dict_items([(\"Lemma('surface.n.01.surface')\", 26), (\"Lemma('surface.n.02.surface')\", 24), (\"Lemma('surface.n.03.surface')\", 10), (\"Lemma('open.n.04.surface')\", 1), (\"Lemma('surface.a.01.surface')\", 1), (\"Lemma('surface.n.04.surface')\", 1)])\n",
      "collecting tokens for  unless\n",
      "indices:    {31362}\n",
      "dict_items([])\n",
      "collecting tokens for  tensions\n",
      "indices:    {27769, 30760, 27434, 11980, 22614, 30777, 14426}\n",
      "dict_items([(\"Lemma('tension.n.01.tension')\", 1)])\n",
      "collecting tokens for  phase\n",
      "indices:    {3232, 3233, 2849, 32516, 14916, 3236, 32714, 3274, 21069, 2159, 5394, 25110, 3287, 13846}\n",
      "dict_items([(\"Lemma('phase.n.01.phase')\", 4), (\"Lemma('phase.n.02.phase')\", 6)])\n",
      "collecting tokens for  reduced\n",
      "indices:    {15489, 2855, 28521, 2858, 107, 2925, 11726, 3986, 32563, 13464, 11165}\n",
      "dict_items([(\"Lemma('reduce.v.01.reduce')\", 5), (\"Lemma('decreased.a.01.reduced')\", 4), (\"Lemma('reduce.v.02.reduce')\", 1), (\"Lemma('reduced.s.02.reduced')\", 1)])\n",
      "collecting tokens for  physics\n",
      "indices:    {11468, 2611, 14836, 157, 7455}\n",
      "dict_items([(\"Lemma('physics.n.01.physics')\", 4)])\n",
      "collecting tokens for  exerted\n",
      "indices:    {2976, 3264, 33219, 3023, 28017, 32925, 27550}\n",
      "dict_items([(\"Lemma('wield.v.01.exert')\", 2), (\"Lemma('exert.v.03.exert')\", 1), (\"Lemma('exert.v.01.exert')\", 4)])\n",
      "collecting tokens for  drop\n",
      "indices:    {34946, 33930, 18705, 30226, 14229, 26528, 27680, 18342, 29863, 4137, 6698, 4140, 558, 24125, 5693, 23231, 3520, 24005, 24007, 33479, 1993, 3018, 17225, 3021, 80, 30289, 21461, 18780, 31324, 33116, 2272, 3824, 14320, 27250, 29046, 22903, 31737}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('drop.n.01.drop')\", 2), (\"Lemma('drop.v.05.drop')\", 1), (\"Lemma('drag.v.05.drop_behind')\", 1), (\"Lemma('drop.v.01.drop')\", 6), (\"Lemma('drop.v.08.drop')\", 1), (\"Lemma('drop.v.06.drop')\", 1), (\"Lemma('drop.n.03.drop')\", 1), (\"Lemma('drop.n.02.drop')\", 6), (\"Lemma('drop.v.03.drop')\", 2), (\"Lemma('drop.v.02.drop')\", 1), (\"Lemma('drop.v.07.drop')\", 1), (\"Lemma('sink.v.01.drop')\", 1), (\"Lemma('drop_back.v.01.drop_back')\", 1)])\n",
      "collecting tokens for  brief\n",
      "indices:    {32902, 12563, 27031, 13086, 12064, 33188, 31664, 24381, 26561, 15300, 25289, 16332, 29015, 26969, 13788, 31204, 32882, 4215, 9468}\n",
      "dict_items([(\"Lemma('brief.s.01.brief')\", 3), (\"Lemma('brief.s.02.brief')\", 3), (\"Lemma('brief.n.01.brief')\", 1)])\n",
      "collecting tokens for  defenses\n",
      "indices:    {27392, 6018, 30311, 35529, 32873, 28462, 28469, 33271, 34520, 15678}\n",
      "dict_items([(\"Lemma('defense_mechanism.n.01.defense')\", 1), (\"Lemma('defense.n.01.defense')\", 1)])\n",
      "collecting tokens for  indicated\n",
      "indices:    {21518, 22031, 30227, 3104, 3107, 3110, 3111, 14377, 13359, 2626, 12354, 36932, 15944, 14921, 15440, 32859, 21083, 608, 3171, 32873, 22639, 29814, 12919, 14459, 4240, 5266, 32410, 32412, 14494, 32415, 9386, 20143, 4274, 4792, 21690, 4795, 11461, 35529, 20681, 28876, 24274, 11482, 30940, 3292, 3294, 14059, 2798, 7410, 15605, 13578, 3363, 32567, 23359, 25414, 20807, 33115, 29543, 29547, 5492, 5495, 16253, 2945, 2949, 35717, 25999, 15253, 20376, 21401, 5528, 5531, 20379, 2975, 34720, 7084, 21429, 17334, 5560, 23995, 21949, 3017, 21450, 5582, 21461, 5592, 9180, 23535, 13818}\n",
      "dict_items([(\"Lemma('bespeak.v.01.indicate')\", 16), (\"Lemma('indicate.v.03.indicate')\", 26), (\"Lemma('indicate.v.02.indicate')\", 26), (\"Lemma('argue.v.03.indicate')\", 4), (\"Lemma('indicate.v.05.indicate')\", 3)])\n",
      "collecting tokens for  employed\n",
      "indices:    {27906, 14854, 4622, 25744, 21777, 23, 6943, 22051, 28072, 15016, 14382, 3248, 8369, 16049, 5174, 32183, 32571, 31864, 6082, 1219, 14408, 35529, 848, 15313, 15058, 3544, 12640, 14177, 27875, 20583, 25067, 31212, 3180, 37112, 11388, 32637}\n",
      "dict_items([(\"Lemma('hire.v.01.employ')\", 11), (\"Lemma('use.v.01.employ')\", 24), (\"Lemma('employed.a.01.employed')\", 1)])\n",
      "collecting tokens for  rule\n",
      "indices:    {24544, 32547, 20227, 31275, 16108, 25646, 2063, 22896, 27316, 15284, 22039, 446}\n",
      "dict_items([(\"Lemma('convention.n.02.rule')\", 1), (\"Lemma('rule.n.01.rule')\", 1)])\n",
      "collecting tokens for  harm\n",
      "indices:    {448, 5092, 26046, 10310, 19464, 36874, 31228, 15404, 28621, 32846, 18163, 27795, 24823, 34555, 17980, 36380, 25054}\n",
      "dict_items([(\"Lemma('injury.n.01.harm')\", 4), (\"Lemma('damage.n.03.harm')\", 1), (\"Lemma('damage.n.01.harm')\", 2), (\"Lemma('harm.v.01.harm')\", 1)])\n",
      "collecting tokens for  minor\n",
      "indices:    {28164, 26790, 15402, 34483, 27095, 508}\n",
      "dict_items([(\"Lemma('minor.a.01.minor')\", 1)])\n",
      "collecting tokens for  level\n",
      "indices:    {2060, 19471, 13328, 29717, 26652, 25116, 30236, 29728, 30242, 13356, 13357, 26158, 22063, 3122, 13363, 12855, 2104, 23619, 1099, 15452, 13917, 3166, 29792, 15465, 32374, 11895, 32892, 4220, 32894, 4226, 32900, 3721, 3722, 3724, 15500, 31886, 3726, 4240, 15507, 4249, 15010, 12965, 4774, 5803, 14002, 1716, 30395, 3772, 29376, 2244, 22728, 27859, 3795, 11477, 18647, 743, 16104, 3823, 3824, 21236, 37110, 28920, 11519, 3849, 11530, 11531, 11529, 33037, 21774, 2830, 21776, 15121, 11538, 15122, 17688, 3871, 3876, 11556, 11559, 11561, 3882, 19242, 19249, 20789, 2359, 18744, 20792, 3895, 20793, 11581, 31551, 13632, 1862, 31560, 12105, 11598, 15701, 15712, 15205, 20326, 28007, 1899, 21879, 34176, 32133, 33158, 31624, 3980, 3982, 18319, 21908, 21909, 32163, 4006, 33195, 33200, 27060, 28086, 11706, 448, 20421, 16340, 16343, 16347, 24027, 33247, 12261, 16357, 12264, 16367, 16370, 16371, 15859, 16372, 16376, 16380}\n",
      "dict_items([(\"Lemma('degree.n.02.level')\", 8), (\"Lemma('degree.n.01.level')\", 26), (\"Lemma('grade.n.02.level')\", 16), (\"Lemma('flat.s.01.level')\", 1), (\"Lemma('level.n.04.level')\", 5), (\"Lemma('level.s.02.level')\", 1), (\"Lemma('level.v.01.level')\", 1), (\"Lemma('level.s.04.level')\", 1)])\n",
      "collecting tokens for  joints\n",
      "indices:    {29731, 29867, 20687, 20688, 29715, 5622, 29720, 4921, 29722, 25661, 1023}\n",
      "dict_items([(\"Lemma('joint.n.01.joint')\", 2), (\"Lemma('joint.n.02.joint')\", 1)])\n",
      "collecting tokens for  cloth\n",
      "indices:    {5376, 7553, 26248, 29448, 29566, 3227, 24351, 29731, 33578, 29881, 8506, 4925, 29777, 29779, 7636, 5847, 29783, 29784, 29786, 29787, 30555, 3168, 29794, 29796, 3174, 36719, 5369, 8829, 5374, 7551}\n",
      "dict_items([(\"Lemma('fabric.n.01.cloth')\", 13)])\n",
      "collecting tokens for  nailed\n",
      "indices:    {312, 29731, 29796, 29861, 27014, 15078, 24472, 28280, 29722, 6655}\n",
      "dict_items([(\"Lemma('smash.v.01.nail')\", 1), (\"Lemma('nail.v.01.nail')\", 7), (\"Lemma('nail_down.v.01.nail_down')\", 1), (\"Lemma('collar.v.01.nail')\", 1)])\n",
      "collecting tokens for  terrible\n",
      "indices:    {37155, 35492, 6919, 30281, 4887, 32846, 1007, 28079, 13747, 27479, 35033, 24671, 7743}\n",
      "dict_items([(\"Lemma('awful.s.02.terrible')\", 2), (\"Lemma('atrocious.s.02.terrible')\", 1)])\n",
      "collecting tokens for  guy\n",
      "indices:    {19907, 19527, 20970, 19471, 19484, 23070}\n",
      "dict_items([(\"Lemma('guy.n.01.guy')\", 3)])\n",
      "collecting tokens for  operator\n",
      "indices:    {4352, 21763, 4355, 4363, 4366, 4367, 4375, 11169, 5155, 14761, 28719, 5174, 28728, 4280, 5179, 2235, 11069, 5181, 4286, 4293, 4296, 4299, 4319, 4326, 4330, 4331, 4334, 4335, 4337, 4339, 4340, 2424, 21753, 4348, 4349, 4351}\n",
      "dict_items([(\"Lemma('operator.n.01.operator')\", 15), (\"Lemma('operator.n.02.operator')\", 5), (\"Lemma('hustler.n.02.operator')\", 1)])\n",
      "collecting tokens for  angie\n",
      "indices:    {16524}\n",
      "dict_items([(\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  snow\n",
      "indices:    {25972, 8957, 21206, 34159}\n",
      "dict_items([(\"Lemma('snow.n.02.snow')\", 1)])\n",
      "collecting tokens for  crack\n",
      "indices:    {18624, 9793, 12866, 32102, 21737, 7699, 29556, 17235, 9045, 23160, 12859, 18204, 9368, 30686}\n",
      "dict_items([(\"Lemma('gap.n.03.crack')\", 2), (\"Lemma('break_through.v.01.crack')\", 1), (\"Lemma('crack.n.01.crack')\", 2), (\"Lemma('crack.n.04.crack')\", 1), (\"Lemma('crack.v.02.crack')\", 1), (\"Lemma('crack.v.04.crack')\", 1), (\"Lemma('crack.v.06.crack')\", 1), (\"Lemma('ace.s.01.crack')\", 2), (\"Lemma('crack.v.01.crack')\", 1)])\n",
      "collecting tokens for  joel\n",
      "indices:    {26185}\n",
      "dict_items([])\n",
      "collecting tokens for  letting\n",
      "indices:    {644, 35847, 16785, 7699, 26901, 27933, 23330, 33955, 12197, 1069, 10427, 33467, 1987, 30419, 22233, 33244, 9186, 34928, 19696, 19321, 26750}\n",
      "dict_items([(\"Lemma('let.v.01.let')\", 19)])\n",
      "collecting tokens for  snake\n",
      "indices:    {26177, 3715, 35907, 3685, 3707, 9070, 7699, 21016, 2235, 3739, 3709}\n",
      "dict_items([(\"Lemma('snake.n.01.snake')\", 6)])\n",
      "collecting tokens for  loose\n",
      "indices:    {7809, 12676, 35206, 10248, 14088, 9995, 29199, 12560, 18577, 7699, 18452, 13589, 30617, 16154, 19357, 31390, 26145, 6055, 936, 14382, 18480, 26162, 306, 2612, 32317, 23239, 30281, 1616, 24788, 35928, 348, 608, 28774, 18665, 35690, 29678, 35957, 28793, 31227, 29566}\n",
      "dict_items([(\"Lemma('free.s.09.loose')\", 1), (\"Lemma('loose.a.01.loose')\", 2), (\"Lemma('informal.s.02.loose')\", 1), (\"Lemma('loose.r.01.loose')\", 2), (\"Lemma('unleash.v.03.loose')\", 1), (\"Lemma('loose.s.02.loose')\", 2), (\"Lemma('lax.s.04.loose')\", 1), (\"Lemma('loose.a.03.loose')\", 1), (\"Lemma('free.v.01.loose')\", 1)])\n",
      "collecting tokens for  paced\n",
      "indices:    {8576, 28995, 36932, 36938, 28972, 10190, 8533, 28990}\n",
      "dict_items([(\"Lemma('pace.v.02.pace')\", 3), (\"Lemma('pace.v.01.pace')\", 3), (\"Lemma('pace.v.03.pace')\", 2)])\n",
      "collecting tokens for  staring\n",
      "indices:    {33794, 17028, 7653, 2119, 30953, 7021, 7790, 37009, 8533, 18966, 8087, 33753, 9181, 6431}\n",
      "dict_items([(\"Lemma('gaze.v.01.stare')\", 12), (\"Lemma('stare.v.02.stare')\", 1)])\n",
      "collecting tokens for  damp\n",
      "indices:    {7493}\n",
      "dict_items([(\"Lemma('damp.s.01.damp')\", 1)])\n",
      "collecting tokens for  baptized\n",
      "indices:    {28265, 24747, 24748, 24751, 1392, 24752, 24755, 8254}\n",
      "dict_items([(\"Lemma('baptize.v.01.baptize')\", 8)])\n",
      "collecting tokens for  moreover\n",
      "indices:    {22614}\n",
      "dict_items([])\n",
      "collecting tokens for  planes\n",
      "indices:    {23844, 5386, 18738, 18771, 5404, 11326}\n",
      "dict_items([(\"Lemma('plane.n.02.plane')\", 3), (\"Lemma('airplane.n.01.plane')\", 2)])\n",
      "collecting tokens for  tangent\n",
      "indices:    {32788, 32790, 32793, 32794, 4512, 32801, 32802, 32800, 4530, 4531, 4533, 4534, 4535, 4536, 4538, 4539, 4544, 4548, 4554, 4555, 4566}\n",
      "dict_items([(\"Lemma('tangent.n.01.tangent')\", 14)])\n",
      "collecting tokens for  intersections\n",
      "indices:    {4547, 4510, 32837, 32840, 32779, 4500, 32793, 4538, 4572, 32829, 32798, 32799}\n",
      "dict_items([(\"Lemma('intersection.n.01.intersection')\", 5)])\n",
      "collecting tokens for  tracing\n",
      "indices:    {21760, 36420, 33638, 4938, 4939, 4940, 16490, 4947, 4948, 4949, 4950, 4951, 4955, 4956, 26429}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('trace.v.02.trace')\", 2), (\"Lemma('trace.v.01.trace')\", 2), (\"Lemma('tracing.n.01.tracing')\", 9), (\"Lemma('hound.v.01.trace')\", 1), (\"Lemma('trace.v.03.trace')\", 1)])\n",
      "collecting tokens for  blues\n",
      "indices:    {26432}\n",
      "dict_items([])\n",
      "collecting tokens for  african\n",
      "indices:    {23851}\n",
      "dict_items([])\n",
      "collecting tokens for  roots\n",
      "indices:    {26861}\n",
      "dict_items([])\n",
      "collecting tokens for  stressed\n",
      "indices:    {4746, 22027, 22032, 16025, 16668, 16031, 16039, 4277, 1336, 26429, 22591, 32460, 32593, 6098, 22358, 20834, 11878, 12269, 4211}\n",
      "dict_items([(\"Lemma('stress.v.01.stress')\", 15), (\"Lemma('stress.v.02.stress')\", 3)])\n",
      "collecting tokens for  tennessee\n",
      "indices:    {29288}\n",
      "dict_items([])\n",
      "collecting tokens for  seven\n",
      "indices:    {15738, 35811, 12460}\n",
      "dict_items([(\"Lemma('seven.s.01.seven')\", 2)])\n",
      "collecting tokens for  assignments\n",
      "indices:    {32356, 22380, 31823, 22864, 1072, 17619, 26964, 30395}\n",
      "dict_items([(\"Lemma('assignment.n.01.assignment')\", 2)])\n",
      "collecting tokens for  none\n",
      "indices:    {32106, 13, 20593, 19540, 884, 13495, 6104, 17723, 22428, 18302}\n",
      "dict_items([])\n",
      "collecting tokens for  mankind\n",
      "indices:    {27783, 2568, 27913, 28042, 32664, 27807, 28320, 1446, 27836, 23871, 27839, 25667, 32195, 27080, 30281, 30283, 34382, 26964, 34388, 15449, 14171, 34396, 14435, 25332, 27384}\n",
      "dict_items([])\n",
      "collecting tokens for  ills\n",
      "indices:    {28035, 4676, 23720, 28040, 28043, 26964, 26197, 24667}\n",
      "dict_items([])\n",
      "collecting tokens for  risk\n",
      "indices:    {32898, 14211, 14985, 24460, 23963, 21022, 23583, 27811, 27812, 33573, 27813, 27816, 27818, 27820, 1324, 25390, 15279, 25392, 1329, 27829, 27189, 27836, 20287, 23746, 24004, 31740, 16981, 5079, 23389, 14051, 4585, 25200, 14578, 22780}\n",
      "dict_items([(\"Lemma('risk.n.02.risk')\", 2), (\"Lemma('hazard.n.01.risk')\", 3), (\"Lemma('risk.v.01.risk')\", 5), (\"Lemma('gamble.v.01.risk')\", 2)])\n",
      "collecting tokens for  instead\n",
      "indices:    {26569, 11508, 20119}\n",
      "dict_items([(\"Lemma('rather.r.01.instead')\", 1)])\n",
      "collecting tokens for  person\n",
      "indices:    {36004, 30917, 15012, 27079, 21490, 14643, 33586, 25528, 26873, 20319}\n",
      "dict_items([(\"Lemma('person.n.01.person')\", 2)])\n",
      "collecting tokens for  fiction\n",
      "indices:    {23809, 14602, 2448, 32026, 31782, 14630, 13879, 14397, 31805, 31819, 23500, 23504, 2390, 2391, 13912, 2392, 2394, 2395, 32094, 10847, 24675, 24677, 30701, 14578, 2163, 14330}\n",
      "dict_items([(\"Lemma('fiction.n.01.fiction')\", 13)])\n",
      "collecting tokens for  drama\n",
      "indices:    {14602, 26520, 25628, 26147, 14116, 26151, 1577, 14121, 13485, 24381, 22593, 22085, 13639, 10826, 26571, 26954, 26187, 36302, 1108, 26966, 14428, 8158, 13407, 2406, 14578, 1020, 31102}\n",
      "dict_items([(\"Lemma('play.n.01.drama')\", 7), (\"Lemma('drama.n.02.drama')\", 4), (\"Lemma('drama.n.03.drama')\", 2), (\"Lemma('drama.n.04.drama')\", 1)])\n",
      "collecting tokens for  window\n",
      "indices:    {13322, 26129, 18961, 26133, 26134, 5667, 6693, 33844, 7732, 16958, 10818, 23111, 8775, 9808, 18521, 8804, 16998, 7273, 34928, 17526, 17528, 9337, 17543, 16524, 8854, 33432, 30365, 17571, 17572, 30373, 29862, 17575, 33955, 17597, 18109, 3267, 3269, 10969, 6369, 17642, 7409, 13561, 5380, 9485, 7445, 17688, 6431, 9505, 9509, 10535, 36135, 8504, 5950, 5967, 27475, 11105, 6499, 36196, 36210, 17290, 17292, 33676, 36759, 33690, 18849, 18348, 9655, 9148, 14784, 18883, 18887, 9162, 18897, 9179, 5088, 36323, 18916, 33772, 8686, 6642, 33269}\n",
      "dict_items([(\"Lemma('window.n.01.window')\", 26), (\"Lemma('window.n.02.window')\", 4), (\"Lemma('window.n.03.window')\", 3)])\n",
      "collecting tokens for  sides\n",
      "indices:    {32015, 12698, 29597, 8870, 11313, 28725, 29624, 11833, 29626, 11066, 25277, 29630, 29629, 25921, 24388, 33860, 24392, 32202, 1744, 29656, 24410, 29658, 861, 29798, 30188, 7021, 36721, 891, 17662}\n",
      "dict_items([(\"Lemma('side.n.03.side')\", 2), (\"Lemma('side.n.01.side')\", 2), (\"Lemma('side.n.02.side')\", 2), (\"Lemma('side.n.06.side')\", 1), (\"Lemma('side.n.04.side')\", 2)])\n",
      "collecting tokens for  reached\n",
      "indices:    {7179, 29200, 22555, 16422, 18477, 22064, 12336, 36912, 33848, 14405, 35912, 35913, 24651, 26191, 18001, 32853, 35932, 20579, 3685, 24677, 18534, 12395, 19564, 7788, 11891, 9850, 35963, 7805, 20093, 21641, 35470, 31375, 3732, 661, 24217, 27293, 5278, 34974, 18594, 9380, 29349, 27301, 6825, 12487, 8397, 31438, 12495, 10963, 10964, 9942, 21212, 23262, 18658, 23780, 10474, 21243, 33540, 32012, 33037, 23822, 23829, 20760, 29978, 20765, 35614, 35619, 19242, 22830, 19248, 24369, 33586, 19251, 17717, 35638, 5437, 7492, 21320, 10579, 35681, 17764, 16742, 34151, 34162, 7549, 26498, 17797, 26502, 8581, 4498, 2963, 27543, 22937, 8604, 2973, 22944, 2980, 421, 36779, 14254, 23992, 5568, 12738, 5063, 35784, 18378, 974, 18386, 35800, 5084, 3037, 5087, 35807, 12265, 17388, 3060, 18420, 33782, 24567}\n",
      "dict_items([(\"Lemma('reach.v.02.reach')\", 17), (\"Lemma('reach.v.01.reach')\", 26), (\"Lemma('reach.v.07.reach')\", 5), (\"Lemma('reach.v.03.reach')\", 12), (\"Lemma('reach.v.04.reach')\", 6), (\"Lemma('achieve.v.01.reach')\", 10), (\"Lemma('reach.v.06.reach')\", 5), (\"Lemma('pass.v.05.reach')\", 1)])\n",
      "collecting tokens for  inaugural\n",
      "indices:    {13747}\n",
      "dict_items([(\"Lemma('inaugural_address.n.01.inaugural')\", 1)])\n",
      "collecting tokens for  devoted\n",
      "indices:    {32487}\n",
      "dict_items([])\n",
      "collecting tokens for  composer\n",
      "indices:    {26631, 6796, 25996, 26510, 26509, 31892, 31897, 31643, 1053, 26786, 26279, 6824, 11053, 11055, 11185, 26802, 11190, 6839, 6841, 6843, 6861, 11214, 14542, 26972, 26973, 26336, 14562, 14565, 14573, 6766, 11250, 6783}\n",
      "dict_items([(\"Lemma('composer.n.01.composer')\", 19)])\n",
      "collecting tokens for  transfer\n",
      "indices:    {24205, 12558, 5539, 9384, 3377, 2866, 12850, 2868, 2870, 2872, 2873, 2881, 5571, 5576, 20426, 5578, 5580, 5581, 5582, 1743, 5583, 26846, 2914, 28642, 17644, 25203, 5492, 5493, 27638, 27635}\n",
      "dict_items([(\"Lemma('transportation.n.02.transfer')\", 19), (\"Lemma('transmit.v.04.transfer')\", 1), (\"Lemma('transfer.v.06.transfer')\", 1), (\"Lemma('transfer.n.02.transfer')\", 1), (\"Lemma('transfer.v.02.transfer')\", 1), (\"Lemma('transfer.v.04.transfer')\", 2), (\"Lemma('transfer.n.03.transfer')\", 1)])\n",
      "collecting tokens for  mitchell\n",
      "indices:    {20399}\n",
      "dict_items([])\n",
      "collecting tokens for  glow\n",
      "indices:    {35650, 13539, 11497, 35470, 29040, 5948, 861}\n",
      "dict_items([(\"Lemma('freshness.n.03.glow')\", 2), (\"Lemma('glow.v.01.glow')\", 1)])\n",
      "collecting tokens for  readily\n",
      "indices:    {28940, 24333, 31122, 16276, 5525, 15255, 14363, 33182, 3231, 12075, 5548, 30767, 13619, 4153, 3899, 31184, 14676, 4949, 31831, 1368, 3291, 2143, 10859, 14060, 30587, 5244, 12285, 30206}\n",
      "dict_items([(\"Lemma('readily.r.01.readily')\", 19)])\n",
      "collecting tokens for  objective\n",
      "indices:    {12928, 31105, 16129, 32133, 12925, 1288, 23561, 26637, 31890, 30740, 32917, 33046, 2714, 5659, 25501, 23968, 15649, 3489, 21538, 15012, 31141, 5757, 25513, 5758, 25263, 13620, 25524, 25911, 2495, 12352, 22593, 16452, 25928, 15818, 14923, 11722, 32338, 14168, 27865, 14047, 14048, 14049, 12283, 33258, 32501, 12917, 31099, 12924, 12285, 12926, 12927}\n",
      "dict_items([(\"Lemma('objective.a.01.objective')\", 9), (\"Lemma('aim.n.02.objective')\", 19)])\n",
      "collecting tokens for  papers\n",
      "indices:    {11872, 23844, 16069, 21546, 3183, 8753, 24723, 16148, 17747, 17526, 14838, 7769, 31705, 16061}\n",
      "dict_items([(\"Lemma('newspaper.n.02.paper')\", 1), (\"Lemma('document.n.01.papers')\", 8), (\"Lemma('composition.n.08.paper')\", 1)])\n",
      "collecting tokens for  inventory\n",
      "indices:    {32512, 32515, 32518, 16104, 32521, 2744, 2741, 2742, 15672, 11324, 32509}\n",
      "dict_items([(\"Lemma('inventory.n.01.inventory')\", 4), (\"Lemma('armory.n.01.inventory')\", 1)])\n",
      "collecting tokens for  acquired\n",
      "indices:    {29985, 13217, 11173, 16199, 1757, 30089, 12650, 3466, 6764, 31665, 10644, 14229, 22490, 15229}\n",
      "dict_items([(\"Lemma('acquired.s.01.acquired')\", 1), (\"Lemma('get.v.01.acquire')\", 11), (\"Lemma('assume.v.03.acquire')\", 1)])\n",
      "collecting tokens for  can't\n",
      "indices:    {416, 801, 6018, 11173, 6124, 565, 283, 1661, 414, 415}\n",
      "dict_items([])\n",
      "collecting tokens for  styka\n",
      "indices:    {7982}\n",
      "dict_items([(\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  blew\n",
      "indices:    {8001, 8209, 18737, 7987, 17108, 35955, 33681}\n",
      "dict_items([(\"Lemma('blow.v.03.blow')\", 2), (\"Lemma('blow.v.01.blow')\", 2)])\n",
      "collecting tokens for  presses\n",
      "indices:    {24034, 29540, 29893, 28425, 29545, 29874, 29882, 29887}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([])\n",
      "collecting tokens for  fitted\n",
      "indices:    {22499, 28836, 5412, 26053, 5850, 5863, 12355, 30538, 4651, 2448, 7801, 29882, 9787, 20892}\n",
      "dict_items([(\"Lemma('suit.v.01.fit')\", 3), (\"Lemma('fit.v.02.fit')\", 3), (\"Lemma('equip.v.01.fit')\", 1), (\"Lemma('meet.v.05.fit')\", 1), (\"Lemma('fit.v.04.fit')\", 2), (\"Lemma('fit.v.05.fit')\", 1), (\"Lemma('equip.v.01.fit_out')\", 1)])\n",
      "collecting tokens for  sealed\n",
      "indices:    {3138, 34756, 36199, 29882, 3258, 13486, 31349, 3255, 3642, 3259, 3292}\n",
      "dict_items([(\"Lemma('seal.v.02.seal')\", 2), (\"Lemma('seal.v.01.seal')\", 1), (\"Lemma('seal.v.03.seal')\", 1)])\n",
      "collecting tokens for  quill\n",
      "indices:    {29873, 29874, 29881, 29882, 7611, 29887}\n",
      "dict_items([(\"Lemma('quill.n.01.quill')\", 1)])\n",
      "collecting tokens for  anybody\n",
      "indices:    {5796, 34629, 24711, 37065, 10921, 6540, 16652, 24046, 10287, 19470, 399, 25874, 24051, 31123, 16502, 36152, 19962, 5436}\n",
      "dict_items([])\n",
      "collecting tokens for  phone\n",
      "indices:    {36993, 36994, 36995, 23169, 36997, 37002, 7312, 33939, 5663, 8096, 17331, 33845, 33590, 33595, 9922, 9925, 35655, 8264, 16968, 82, 16980, 8277, 34007, 20092, 22884, 31338, 29036, 8178, 33909, 10742, 23292}\n",
      "dict_items([(\"Lemma('telephone.n.01.phone')\", 8), (\"Lemma('call.v.03.phone')\", 3)])\n",
      "collecting tokens for  mail\n",
      "indices:    {22408, 24218, 30517}\n",
      "dict_items([])\n",
      "collecting tokens for  dough\n",
      "indices:    {776, 8939, 2988, 29534, 9014, 29529, 29531, 29532, 29533, 20926}\n",
      "dict_items([(\"Lemma('dough.n.01.dough')\", 2), (\"Lemma('boodle.n.01.dough')\", 1)])\n",
      "collecting tokens for  splendid\n",
      "indices:    {31530, 29359, 339, 17366, 1016}\n",
      "dict_items([(\"Lemma('glorious.s.03.splendid')\", 3)])\n",
      "collecting tokens for  degree\n",
      "indices:    {30723, 12295, 31253, 25626, 2591, 2099, 25142, 2104, 2108, 2109, 4683, 27725, 15457, 24164, 11893, 27253, 15484, 28801, 2180, 3207, 31376, 27794, 4249, 11421, 157, 11422, 22687, 162, 163, 32932, 4778, 3243, 4276, 11447, 4281, 4285, 3774, 32959, 25796, 4294, 4295, 37067, 32463, 3800, 8412, 11485, 4327, 21224, 16113, 1778, 27895, 1784, 28411, 4379, 18716, 15644, 16182, 5433, 32080, 16210, 16217, 15708, 13669, 28006, 28007, 1898, 2413, 4974, 13679, 4977, 374, 5497, 13305, 34693, 12166, 30097, 16803, 20396, 12228, 10707, 20441, 13285, 13289, 13294, 12272, 28152, 34297, 507, 31230, 30207}\n",
      "dict_items([(\"Lemma('degree.n.01.degree')\", 22), (\"Lemma('degree.n.02.degree')\", 16), (\"Lemma('degree.n.05.degree')\", 6), (\"Lemma('degree.n.04.degree')\", 4), (\"Lemma('academic_degree.n.01.degree')\", 7), (\"Lemma('degree.n.06.degree')\", 1)])\n",
      "collecting tokens for  circumstance\n",
      "indices:    {11328, 2180, 27877, 15431, 36137, 4907, 3467, 17998, 8911, 26190, 2578}\n",
      "dict_items([(\"Lemma('circumstance.n.01.circumstance')\", 6), (\"Lemma('circumstance.n.03.circumstance')\", 1), (\"Lemma('context.n.02.circumstance')\", 1)])\n",
      "collecting tokens for  determines\n",
      "indices:    {2048, 2180, 15493, 14726, 4208, 31891, 4471, 16376, 12317}\n",
      "dict_items([(\"Lemma('determine.v.03.determine')\", 2), (\"Lemma('specify.v.02.determine')\", 2), (\"Lemma('determine.v.02.determine')\", 3), (\"Lemma('decide.v.01.determine')\", 1), (\"Lemma('determine.v.01.determine')\", 1)])\n",
      "collecting tokens for  dream\n",
      "indices:    {2176, 14572, 35983, 10581, 29015, 28025, 2141, 2142}\n",
      "dict_items([(\"Lemma('dream.n.01.dream')\", 4), (\"Lemma('dream.v.02.dream')\", 1)])\n",
      "collecting tokens for  fulfilled\n",
      "indices:    {2180, 31622, 1072, 2642, 212, 22900, 13815, 20250}\n",
      "dict_items([(\"Lemma('carry_through.v.01.fulfil')\", 2), (\"Lemma('carry_through.v.01.fulfill')\", 4), (\"Lemma('satisfy.v.01.fulfill')\", 1)])\n",
      "collecting tokens for  weird\n",
      "indices:    {2180, 2150, 13576, 2124, 2188, 19246, 33879, 6334}\n",
      "dict_items([(\"Lemma('eldritch.s.01.weird')\", 7)])\n",
      "collecting tokens for  cursed\n",
      "indices:    {19811, 5092, 18213, 9479, 18377, 35882, 7664, 33616, 28274, 9907}\n",
      "dict_items([(\"Lemma('curse.v.01.curse')\", 5), (\"Lemma('curse.v.02.curse')\", 4), (\"Lemma('curse.v.03.curse')\", 1)])\n",
      "collecting tokens for  threatened\n",
      "indices:    {13057, 25859, 23957, 27287, 20762, 29978, 35997, 18213, 18215, 15791, 32687, 5042, 23865, 193, 18883, 21446, 32847, 22865, 4576, 24035, 12665}\n",
      "dict_items([(\"Lemma('threaten.v.03.threaten')\", 3), (\"Lemma('threaten.v.02.threaten')\", 7), (\"Lemma('endanger.v.01.threaten')\", 8), (\"Lemma('threatened.s.01.threatened')\", 1)])\n",
      "collecting tokens for  ai\n",
      "indices:    {33600, 17889, 17898, 18428, 20118, 18391, 16505, 10588}\n",
      "dict_items([(\"Lemma('be.v.01.be')\", 2)])\n",
      "collecting tokens for  drink\n",
      "indices:    {33922, 7683, 5892, 17413, 7687, 18962, 18963, 8724, 8084, 23835, 18984, 8779, 31570, 19164, 36703, 35045, 33385, 29425, 8183, 33403}\n",
      "dict_items([(\"Lemma('drink.v.01.drink')\", 5), (\"Lemma('drink.v.02.drink')\", 2), (\"Lemma('drink.n.01.drink')\", 4), (\"Lemma('drink.n.02.drink')\", 2), (\"Lemma('beverage.n.01.drink')\", 1)])\n",
      "collecting tokens for  beer\n",
      "indices:    {12676, 18887, 12683, 12620, 36397, 18899, 17812, 18901, 29462, 23835, 12700, 18943}\n",
      "dict_items([(\"Lemma('beer.n.01.beer')\", 8)])\n",
      "collecting tokens for  plus\n",
      "indices:    {23392, 128, 23747, 4548, 3523, 28806, 30406, 30344, 3655, 4907, 10219, 29484, 10286, 1707, 4500, 26361, 29273, 11835}\n",
      "dict_items([])\n",
      "collecting tokens for  discussed\n",
      "indices:    {5120, 27521, 32772, 9610, 20236, 3224, 6942, 6048, 4001, 15776, 4007, 17319, 31279, 14001, 8883, 32949, 30775, 26811, 19645, 575, 21454, 12114, 1365, 11608, 2526, 14942, 3944, 14062, 12144, 14576, 24180, 5494, 23289, 2813}\n",
      "dict_items([(\"Lemma('discourse.v.01.discuss')\", 26), (\"Lemma('hash_out.v.01.discuss')\", 8)])\n",
      "collecting tokens for  russian\n",
      "indices:    {21271}\n",
      "dict_items([])\n",
      "collecting tokens for  restrictions\n",
      "indices:    {31877, 29836, 29841, 15250, 28691, 32292, 15660, 22446, 34738, 23474, 16443, 27845, 25926, 21706, 29262, 14044, 28900, 12779, 15472, 27249}\n",
      "dict_items([(\"Lemma('restriction.n.01.restriction')\", 4)])\n",
      "collecting tokens for  channel\n",
      "indices:    {11376, 28314, 14438, 22447}\n",
      "dict_items([(\"Lemma('channel.n.01.channel')\", 2)])\n",
      "collecting tokens for  whipped\n",
      "indices:    {29507, 35209, 18957, 24080, 10163, 533, 30362, 120, 29498, 35099}\n",
      "dict_items([(\"Lemma('flog.v.01.whip')\", 3), (\"Lemma('whip.v.03.whip')\", 1), (\"Lemma('worst.v.01.whip')\", 1), (\"Lemma('whip.v.04.whip')\", 1)])\n",
      "collecting tokens for  bills\n",
      "indices:    {21369, 334}\n",
      "dict_items([(\"Lemma('group.n.01.group')\", 1)])\n",
      "collecting tokens for  approved\n",
      "indices:    {14753, 12324, 106, 812, 23757, 52, 20728, 14909}\n",
      "dict_items([(\"Lemma('approve.v.01.approve')\", 6), (\"Lemma('approved.s.01.approved')\", 1)])\n",
      "collecting tokens for  committees\n",
      "indices:    {34688, 20039, 23945, 24598, 22878}\n",
      "dict_items([(\"Lemma('committee.n.01.committee')\", 1)])\n",
      "collecting tokens for  calendar\n",
      "indices:    {23426, 15532, 941, 14771, 32569, 15547, 15550, 15552, 15554, 15559, 15562, 32587, 32589, 32594, 32599, 32600, 15577, 120, 32610, 26988, 24177, 21112}\n",
      "dict_items([(\"Lemma('calendar.n.02.calendar')\", 1), (\"Lemma('calendar.n.01.calendar')\", 1)])\n",
      "collecting tokens for  wore\n",
      "indices:    {7169, 9478, 17287, 36490, 29197, 9625, 21150, 9504, 35745, 23333, 36133, 26919, 17575, 37033, 6185, 23343, 8369, 21041, 25781, 7738, 21053, 7416, 17867, 35660, 24783, 7375, 7124, 9437, 19550, 5602, 5604, 36453, 35812, 36714, 13422, 36719, 9710, 12529, 9585, 25715, 22520, 8697, 5755}\n",
      "dict_items([(\"Lemma('wear.v.01.wear')\", 26), (\"Lemma('wear.v.02.wear')\", 5), (\"Lemma('tire.v.02.wear_out')\", 1), (\"Lemma('wear.v.03.wear')\", 2)])\n",
      "collecting tokens for  wiped\n",
      "indices:    {12833, 23333, 10406, 5929, 34189, 17074, 35124, 247, 10360, 1273, 10714, 18587, 19644}\n",
      "dict_items([(\"Lemma('wipe.v.01.wipe')\", 5), (\"Lemma('wipe_off.v.01.wipe_off')\", 1)])\n",
      "collecting tokens for  franklin\n",
      "indices:    {24675}\n",
      "dict_items([])\n",
      "collecting tokens for  mountains\n",
      "indices:    {7712, 29288, 4442, 7674, 35518, 27519}\n",
      "dict_items([(\"Lemma('mountain.n.01.mountain')\", 3)])\n",
      "collecting tokens for  plane\n",
      "indices:    {4481, 18693, 5382, 32780, 32785, 32791, 4506, 5026, 23331, 5411, 32808, 32809, 23339, 23851, 32815, 23344, 23345, 28722, 23859, 23353, 23354, 30540, 30550, 235, 18668, 30575, 30585, 30590}\n",
      "dict_items([(\"Lemma('airplane.n.01.plane')\", 3), (\"Lemma('flat.s.01.plane')\", 1), (\"Lemma('plane.n.02.plane')\", 2), (\"Lemma('plane.n.03.plane')\", 1)])\n",
      "collecting tokens for  compartment\n",
      "indices:    {3616, 3618, 23333, 29702, 34025, 29423, 403, 3641, 3642}\n",
      "dict_items([(\"Lemma('compartment.n.01.compartment')\", 4), (\"Lemma('compartment.n.02.compartment')\", 1)])\n",
      "collecting tokens for  meal\n",
      "indices:    {15755, 29459, 1686, 29466, 30494, 29471, 35490, 7618, 35032, 35036, 19293, 1637, 8175, 33521, 29171, 35060, 35059, 9209, 8827}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('meal.n.01.meal')\", 7)])\n",
      "collecting tokens for  cried\n",
      "indices:    {6848, 36032, 10914, 9475, 20129, 27307, 25709, 6779, 9617, 26394, 19003}\n",
      "dict_items([(\"Lemma('shout.v.02.cry')\", 8), (\"Lemma('cry.v.02.cry')\", 1)])\n",
      "collecting tokens for  harmony\n",
      "indices:    {14633, 27754, 27981, 11217, 4724, 27541, 11958, 13044, 13049, 13050, 31613}\n",
      "dict_items([(\"Lemma('harmony.n.02.harmony')\", 1), (\"Lemma('harmony.n.01.harmony')\", 3), (\"Lemma('harmony.n.03.harmony')\", 1)])\n",
      "collecting tokens for  12\n",
      "indices:    {32768, 524, 13844, 29720, 28184, 29722, 28188, 540, 28190, 13856, 21547, 3119, 28208, 1080, 21563, 12861, 574, 13888, 29761, 1091, 28758, 28246, 28760, 28766, 28769, 28771, 28264, 21611, 28780, 622, 28787, 28798, 23678, 130, 20611, 25223, 20617, 32393, 29323, 153, 3747, 11437, 15044, 3277, 28882, 33491, 25817, 4327, 17643, 21232, 15613, 4363, 3857, 4371, 15126, 286, 27425, 23344, 16178, 11587, 25414, 333, 336, 23891, 28502, 28504, 29532, 29535, 29023, 354, 24420, 23397, 23914, 23406, 23407, 29040, 23409, 20847, 23415, 23416, 23426, 27017, 22410, 22414, 398, 928, 5031, 33192, 29097, 5035, 22958, 27061, 5558, 33207, 15288, 13241, 29122, 29125, 29129, 4042, 29131, 29133, 29134, 4047, 29136, 3547, 13276, 3562, 22506, 12271, 1529, 11775}\n",
      "dict_items([(\"Lemma('twelve.s.01.12')\", 21), (\"Lemma('twelve.n.01.12')\", 6)])\n",
      "collecting tokens for  al\n",
      "indices:    {34939}\n",
      "dict_items([])\n",
      "collecting tokens for  temple\n",
      "indices:    {29365, 13151}\n",
      "dict_items([(\"Lemma('temple.n.01.temple')\", 1)])\n",
      "collecting tokens for  dog\n",
      "indices:    {6658, 3844, 28549, 28554, 10518, 26775, 25113, 28841, 25142, 28603, 28611, 28626, 7380, 3799, 7385, 6497, 6498, 11111, 20714, 20715, 20716, 3823, 12532, 28533}\n",
      "dict_items([(\"Lemma('dog.n.01.dog')\", 10)])\n",
      "collecting tokens for  cat\n",
      "indices:    {3844, 19207, 24393, 7116, 9421, 6061, 30974}\n",
      "dict_items([(\"Lemma('cat.n.01.cat')\", 3)])\n",
      "collecting tokens for  sounds\n",
      "indices:    {12999, 10279, 17611, 34572, 19596, 31150, 30386, 1782, 33943, 35544, 36413, 13655}\n",
      "dict_items([(\"Lemma('sound.v.02.sound')\", 1), (\"Lemma('sound.n.02.sound')\", 2), (\"Lemma('sound.v.01.sound')\", 3), (\"Lemma('sound.n.03.sound')\", 1)])\n",
      "collecting tokens for  hank\n",
      "indices:    {334}\n",
      "dict_items([])\n",
      "collecting tokens for  finished\n",
      "indices:    {27777, 22022, 22024, 649, 22026, 2187, 22154, 22927, 28816, 16913, 1169, 36499, 33684, 16021, 17814, 21015, 26391, 29337, 16022, 22930, 22940, 33694, 22942, 28455, 9384, 11306, 19499, 29357, 17588, 5046, 33335, 6971, 16957, 19521, 9795, 7880, 9673, 10701, 30414, 19278, 18128, 17486, 34258, 17104, 35152, 12891, 29020, 25053, 8157, 24797, 19037, 12894, 10466, 19036, 29666, 8293, 7531, 35821, 12913, 35699, 9717, 35961, 10107, 21500, 253, 12415}\n",
      "dict_items([(\"Lemma('complete.v.01.finish')\", 26), (\"Lemma('finish_up.v.02.finish')\", 9), (\"Lemma('end.v.01.finish')\", 7), (\"Lemma('finish.v.04.finish')\", 2), (\"Lemma('finished.a.02.finished')\", 2), (\"Lemma('eat_up.v.01.finish')\", 2), (\"Lemma('finished.a.01.finished')\", 5)])\n",
      "collecting tokens for  wagon\n",
      "indices:    {24712, 33766}\n",
      "dict_items([])\n",
      "collecting tokens for  swimming\n",
      "indices:    {29985, 5570, 36545, 7489, 1534, 19271, 6408, 21022, 30059, 7500, 7503, 7504, 29298, 8693, 19035, 5565, 5566, 1535}\n",
      "dict_items([(\"Lemma('swim.v.01.swim')\", 4), (\"Lemma('swimming.n.01.swimming')\", 1)])\n",
      "collecting tokens for  tall\n",
      "indices:    {13121, 30533, 18309, 6984, 17258, 18283, 31371, 31470, 14063, 36431, 13079, 34040, 1529, 5949}\n",
      "dict_items([(\"Lemma('tall.a.01.tall')\", 9)])\n",
      "collecting tokens for  constitutional\n",
      "indices:    {24612, 25829, 31719, 14251, 27760, 113, 27257}\n",
      "dict_items([])\n",
      "collecting tokens for  joint\n",
      "indices:    {29795, 20810, 24052, 20692, 14749, 23678}\n",
      "dict_items([])\n",
      "collecting tokens for  session\n",
      "indices:    {21890, 15493, 2188, 20620, 24591, 22552, 24730, 24219, 21530, 14746, 22300, 286, 23587, 22822, 168, 23853, 20659, 20660, 52, 32441, 26427, 21180, 22598, 22600, 22601, 22354, 15827, 32214, 27609, 20571, 27612, 27615, 25192, 20328, 20332, 1141, 14838, 15863, 762}\n",
      "dict_items([(\"Lemma('session.n.01.session')\", 7), (\"Lemma('school_term.n.01.session')\", 2)])\n",
      "collecting tokens for  congress\n",
      "indices:    {23973}\n",
      "dict_items([])\n",
      "collecting tokens for  electoral\n",
      "indices:    {4768, 4769, 4738, 4772, 4805, 4773, 4743, 4750, 4754, 22899, 4793, 4798}\n",
      "dict_items([(\"Lemma('electoral.a.01.electoral')\", 11)])\n",
      "collecting tokens for  sufficient\n",
      "indices:    {28931, 25351, 4231, 16289, 21160, 13358, 12345, 835, 31684, 14793, 31689, 22862, 13776, 2785, 20193, 2020, 875, 3180, 22900}\n",
      "dict_items([(\"Lemma('sufficient.a.01.sufficient')\", 11)])\n",
      "collecting tokens for  declaration\n",
      "indices:    {14153}\n",
      "dict_items([])\n",
      "collecting tokens for  defeated\n",
      "indices:    {20805, 75, 19341, 8238, 20175, 22899, 26036, 22901, 24727}\n",
      "dict_items([(\"Lemma('get_the_better_of.v.01.defeat')\", 6), (\"Lemma('kill.v.02.defeat')\", 2)])\n",
      "collecting tokens for  tight\n",
      "indices:    {14977, 28805, 19467, 9231, 9121, 18739, 29886, 18510, 19284, 19288, 18522, 9053, 18910, 36445, 18797, 18798, 11118, 8817, 29682, 22899, 759, 13567}\n",
      "dict_items([(\"Lemma('fast.r.02.tight')\", 2), (\"Lemma('tight.a.01.tight')\", 9), (\"Lemma('tight.s.03.tight')\", 1), (\"Lemma('close.r.02.tight')\", 1), (\"Lemma('taut.s.01.tight')\", 2), (\"Lemma('mean.s.06.tight')\", 1), (\"Lemma('tight.s.06.tight')\", 1)])\n",
      "collecting tokens for  strips\n",
      "indices:    {3554, 3555, 5380, 1893, 7813, 29532, 5381, 3557, 9411, 3556, 35473, 29660}\n",
      "dict_items([(\"Lemma('strip.n.01.strip')\", 5), (\"Lemma('strip.n.02.strip')\", 4)])\n",
      "collecting tokens for  skin\n",
      "indices:    {8706, 7813, 31496, 31497, 16650, 31498, 34700, 9101, 34826, 13967, 18970, 1690, 3357, 34975, 9121, 1705, 6954, 1706, 1582, 35509, 31545, 7611, 37054, 37056, 36545, 36032, 14155, 36048, 10585, 35545, 36082}\n",
      "dict_items([(\"Lemma('skin.n.01.skin')\", 7), (\"Lemma('skin.n.02.skin')\", 2), (\"Lemma('skin.n.04.skin')\", 1), (\"Lemma('hide.n.02.skin')\", 2)])\n",
      "collecting tokens for  hung\n",
      "indices:    {35072, 5764, 7813, 17798, 24583, 13576, 9481, 20105, 17796, 37002, 28429, 36754, 2962, 9490, 16787, 17301, 5655, 6937, 31390, 37152, 19497, 9516, 10872, 18736, 7856, 6322, 13114, 9150, 14527, 9151, 9409, 5318, 35271, 18378, 6351, 35409, 35666, 35411, 7136, 19301, 23146, 33400, 13550, 31346, 12403, 28280, 34173, 33919}\n",
      "dict_items([(\"Lemma('hang.v.01.hang')\", 20), (\"Lemma('hang.v.02.hang')\", 7), (\"Lemma('hang.v.03.hang')\", 1), (\"Lemma('attend.v.05.hang')\", 1), (\"Lemma('hang.v.04.hang')\", 2), (\"Lemma('hang.v.05.hang')\", 3)])\n",
      "collecting tokens for  handsome\n",
      "indices:    {25994, 9484, 7790, 21076, 20921}\n",
      "dict_items([(\"Lemma('fine-looking.s.01.handsome')\", 2)])\n",
      "collecting tokens for  lady\n",
      "indices:    {34911}\n",
      "dict_items([])\n",
      "collecting tokens for  y\n",
      "indices:    {32120, 18865, 17228, 36390}\n",
      "dict_items([])\n",
      "collecting tokens for  du\n",
      "indices:    {15266, 15272, 12491, 25038, 15219, 15252, 15225}\n",
      "dict_items([])\n",
      "collecting tokens for  pont\n",
      "indices:    {15219}\n",
      "dict_items([])\n",
      "collecting tokens for  equal\n",
      "indices:    {3590, 27787, 2827, 1425, 27538, 1431, 10272, 15650, 11299, 15907, 3874, 8234, 28077, 29233, 16178, 12721, 3380, 16181, 11959, 9661, 8382, 33219, 3651, 3525, 14021, 8903, 4548, 12108, 26830, 9937, 3921, 24408, 31197, 3039, 29921, 1892, 31973, 31974, 31975, 20202, 30834, 16372, 31989, 21877, 5371, 32892, 22013}\n",
      "dict_items([(\"Lemma('equal.a.01.equal')\", 25), (\"Lemma('equal.v.01.equal')\", 4)])\n",
      "collecting tokens for  annual\n",
      "indices:    {130, 25092, 22406, 25351, 22409, 35977, 11787, 14217, 32529, 25492, 12181, 20248, 21145, 12186, 15259, 15265, 22179, 20772, 22070, 14905, 11718, 11341, 21709, 21583, 32336, 21973, 20181, 23516, 11869, 20446, 23391, 23392, 32480, 32740, 21093, 20710, 16232, 22376, 26729, 16237, 23406, 21105, 3699, 30964, 33013, 20982, 26999, 21881, 252, 32638, 30079}\n",
      "dict_items([(\"Lemma('annual.a.01.annual')\", 1)])\n",
      "collecting tokens for  distributions\n",
      "indices:    {22051, 33028, 15272, 15666, 4471, 4472, 4473, 15258}\n",
      "dict_items([(\"Lemma('distribution.n.03.distribution')\", 2), (\"Lemma('distribution.n.01.distribution')\", 2)])\n",
      "collecting tokens for  theorem\n",
      "indices:    {4363, 4485, 4374}\n",
      "dict_items([(\"Lemma('theorem.n.01.theorem')\", 3)])\n",
      "collecting tokens for  exists\n",
      "indices:    {4484, 1288, 23689, 2319, 3090, 12308, 13460, 16279, 1433, 15899, 25759, 13215, 12064, 4008, 34349, 4273, 10191, 2775, 31193, 29152, 11490, 14182, 3818, 4219, 14189, 4208, 32624, 1147}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('exist.v.01.exist')\", 25), (\"Lemma('exist.v.02.exist')\", 3)])\n",
      "collecting tokens for  bounded\n",
      "indices:    {4484, 4552, 4557, 20731, 9777, 7828, 31800, 8315}\n",
      "dict_items([(\"Lemma('jump.v.01.bound')\", 1), (\"Lemma('bounded.s.01.bounded')\", 3), (\"Lemma('bound.v.02.bound')\", 2), (\"Lemma('bounce.v.01.bound')\", 1)])\n",
      "collecting tokens for  approached\n",
      "indices:    {16354, 27716, 36716, 34029, 6397, 8890, 10715, 31453}\n",
      "dict_items([(\"Lemma('approach.v.01.approach')\", 6), (\"Lemma('set_about.v.01.approach')\", 1), (\"Lemma('approach.v.05.approach')\", 1)])\n",
      "collecting tokens for  exercised\n",
      "indices:    {31713, 15235, 9348, 15525, 28007, 1545, 31978, 1588, 33236, 5302, 4733, 27870, 3839}\n",
      "dict_items([(\"Lemma('exert.v.01.exercise')\", 5), (\"Lemma('practice.v.01.exercise')\", 5), (\"Lemma('exercise.v.03.exercise')\", 1), (\"Lemma('exercise.v.04.exercise')\", 2)])\n",
      "collecting tokens for  breast\n",
      "indices:    {9348, 35845, 10794, 19469, 22127, 22128, 35958, 15863, 22136, 27194, 7902}\n",
      "dict_items([(\"Lemma('breast.n.02.breast')\", 2), (\"Lemma('breast.n.01.breast')\", 3)])\n",
      "collecting tokens for  tommy\n",
      "indices:    {36481}\n",
      "dict_items([])\n",
      "collecting tokens for  herman\n",
      "indices:    {23000}\n",
      "dict_items([])\n",
      "collecting tokens for  melodies\n",
      "indices:    {26752, 26501, 6794, 6798, 26512, 26515, 6772, 1718, 11231}\n",
      "dict_items([(\"Lemma('tune.n.01.melody')\", 5)])\n",
      "collecting tokens for  humor\n",
      "indices:    {8197, 26136, 26137, 12190, 36519, 10409, 34729, 559, 9009, 27316, 22462, 1735, 9161, 10832, 20952, 13401, 14426, 14552, 2654, 10849, 26091, 19309, 12528, 12529, 26356, 26869, 10744, 10748, 10749, 12542}\n",
      "dict_items([(\"Lemma('wit.n.01.humor')\", 5), (\"Lemma('humor.n.02.humor')\", 6), (\"Lemma('temper.n.02.humor')\", 4)])\n",
      "collecting tokens for  tsunami\n",
      "indices:    {12723, 12715}\n",
      "dict_items([(\"Lemma('tsunami.n.01.tsunami')\", 2)])\n",
      "collecting tokens for  swollen\n",
      "indices:    {34088, 19274, 4110, 4111, 36240, 12753, 5618, 19283, 33653, 10588, 18398}\n",
      "dict_items([(\"Lemma('swell.v.03.swell')\", 1)])\n",
      "collecting tokens for  swallowed\n",
      "indices:    {16675, 36035, 11397, 25703, 8907, 12753, 34803, 36052, 36726, 13023}\n",
      "dict_items([(\"Lemma('swallow.v.01.swallow')\", 5), (\"Lemma('immerse.v.03.swallow')\", 2)])\n",
      "collecting tokens for  disturbance\n",
      "indices:    {4673, 17572, 2185, 17769, 21488, 12753, 17721, 5115, 4252}\n",
      "dict_items([(\"Lemma('disturbance.n.05.disturbance')\", 1), (\"Lemma('perturbation.n.03.disturbance')\", 3), (\"Lemma('disturbance.n.02.disturbance')\", 1), (\"Lemma('affray.n.02.disturbance')\", 1)])\n",
      "collecting tokens for  36\n",
      "indices:    {28995, 14979, 29028, 29027, 23912, 15659, 27390, 29423, 21583, 29009, 29015, 20439, 28248, 28954, 23355, 3740, 2782}\n",
      "dict_items([])\n",
      "collecting tokens for  sailing\n",
      "indices:    {12409, 32644, 30346, 12427, 24012, 8910, 12373, 26617, 20282, 27067}\n",
      "dict_items([(\"Lemma('seafaring.n.01.sailing')\", 2), (\"Lemma('sailing.n.02.sailing')\", 1), (\"Lemma('sweep.v.02.sail')\", 1), (\"Lemma('sail.v.01.sail')\", 1)])\n",
      "collecting tokens for  younger\n",
      "indices:    {25123, 20746, 16909, 28078, 14452, 11831, 14456}\n",
      "dict_items([(\"Lemma('young.a.01.young')\", 4)])\n",
      "collecting tokens for  rest\n",
      "indices:    {37120, 13827, 9222, 24328, 1546, 27275, 25483, 8077, 13586, 31763, 25749, 22937, 27550, 15135, 24614, 22954, 36139, 36267, 35370, 16814, 18737, 29750, 1591, 24503, 30523, 6087, 15176, 7111, 10311, 27725, 27985, 21202, 27473, 32980, 9174, 34135, 33376, 11746, 9957, 14309, 9575, 5737, 36076, 881, 2931, 30585}\n",
      "dict_items([(\"Lemma('remainder.n.01.rest')\", 12), (\"Lemma('stay.v.01.rest')\", 1), (\"Lemma('rest.n.06.rest')\", 1), (\"Lemma('rest.v.01.rest')\", 2), (\"Lemma('rest.n.02.rest')\", 3), (\"Lemma('pillow.v.01.rest')\", 1), (\"Lemma('rest.v.03.rest')\", 1), (\"Lemma('rest.v.05.rest')\", 1)])\n",
      "collecting tokens for  readers\n",
      "indices:    {11408, 10774, 10649, 26138, 31780, 5293, 30255, 25912, 13882, 25915, 25921, 28354, 14404, 19524, 24646, 11341, 23504, 2134, 31831, 13785, 27868, 28385, 28386, 5222, 14439, 1384, 26106}\n",
      "dict_items([(\"Lemma('reader.n.01.reader')\", 4), (\"Lemma('subscriber.n.02.reader')\", 8)])\n",
      "collecting tokens for  items\n",
      "indices:    {32516, 31115, 13, 31119, 15504, 26000, 26779, 10667, 10669, 16179, 16180, 16182, 20025, 15035, 15803, 1878, 32742, 24168, 32765, 30718}\n",
      "dict_items([(\"Lemma('detail.n.01.item')\", 1), (\"Lemma('item.n.01.item')\", 2), (\"Lemma('item.n.03.item')\", 4), (\"Lemma('detail.n.02.item')\", 3)])\n",
      "collecting tokens for  appear\n",
      "indices:    {12288, 16386, 15877, 3081, 3091, 14880, 3626, 3627, 3650, 11337, 31821, 22609, 11352, 21610, 1651, 12916, 8310, 6784, 6274, 4741, 3208, 31881, 6796, 6818, 3237, 3238, 6828, 14011, 23742, 27345, 28881, 748, 24832, 28422, 3852, 5903, 30480, 6933, 3870, 37152, 3880, 28462, 25903, 28464, 3890, 11571, 3907, 20291, 14666, 33615, 26961, 3926, 25434, 33116, 21341, 2398, 3934, 15713, 5987, 4965, 26470, 3961, 7546, 3966, 15231, 3969, 21894, 11663, 3992, 10649, 4003, 5033, 36791, 31162, 3012, 24013, 11235}\n",
      "dict_items([(\"Lemma('appear.v.03.appear')\", 4), (\"Lemma('look.v.02.appear')\", 26), (\"Lemma('appear.v.02.appear')\", 26), (\"Lemma('appear.v.05.appear')\", 2), (\"Lemma('appear.v.04.appear')\", 2)])\n",
      "collecting tokens for  lists\n",
      "indices:    {16160, 23552, 8514, 16227, 16196, 8517, 25635, 23557, 9509, 27022, 7727, 4754, 10649, 32123, 23551, 23999}\n",
      "dict_items([(\"Lemma('list.n.01.list')\", 9), (\"Lemma('list.v.01.list')\", 3)])\n",
      "collecting tokens for  verbal\n",
      "indices:    {2184, 15852, 33214, 16151}\n",
      "dict_items([(\"Lemma('verbal.s.01.verbal')\", 2)])\n",
      "collecting tokens for  slips\n",
      "indices:    {31945, 31946, 30703, 30706, 10741, 10646, 10649, 13822}\n",
      "dict_items([(\"Lemma('faux_pas.n.01.slip')\", 3)])\n",
      "collecting tokens for  ad\n",
      "indices:    {20236, 10141, 16279}\n",
      "dict_items([])\n",
      "collecting tokens for  rent\n",
      "indices:    {12096, 17409, 8164, 12141, 12143, 10649, 27933, 19551}\n",
      "dict_items([(\"Lemma('rent.n.01.rent')\", 5), (\"Lemma('rent.v.01.rent')\", 2), (\"Lemma('hire_out.v.01.rent_out')\", 1)])\n",
      "collecting tokens for  concentrated\n",
      "indices:    {32897, 31368, 3337, 11276, 13336, 32169, 31147, 7604, 1588, 16315, 32958, 13770, 32463, 4183, 31710, 3550, 3552, 3553, 3555, 15847, 3559, 4199, 3562, 12785}\n",
      "dict_items([(\"Lemma('concentrated.s.03.concentrated')\", 2), (\"Lemma('concentrated.a.01.concentrated')\", 5), (\"Lemma('digest.v.07.concentrate')\", 1), (\"Lemma('centralize.v.01.concentrate')\", 3), (\"Lemma('concentrate.v.01.concentrate')\", 3), (\"Lemma('concentrated.s.02.concentrated')\", 5), (\"Lemma('concentrate.v.02.concentrate')\", 1)])\n",
      "collecting tokens for  samples\n",
      "indices:    {5536, 10662, 3526, 3529, 32720, 5523, 3509, 3511, 5529, 5530, 15741, 3262, 15647}\n",
      "dict_items([(\"Lemma('sample.n.01.sample')\", 9), (\"Lemma('sample_distribution.n.01.sample')\", 1)])\n",
      "collecting tokens for  r\n",
      "indices:    {4336, 3749, 4382}\n",
      "dict_items([])\n",
      "collecting tokens for  buffer\n",
      "indices:    {4128, 3553, 4130, 3588, 25190, 3566, 3538, 3539, 3540, 3542, 3546, 3581, 25566}\n",
      "dict_items([(\"Lemma('buffer.n.01.buffer')\", 6)])\n",
      "collecting tokens for  ph\n",
      "indices:    {3509}\n",
      "dict_items([(\"Lemma('ph.n.01.pH')\", 1)])\n",
      "collecting tokens for  mm\n",
      "indices:    {3553, 2850, 2851, 2833, 2834, 30387, 2836, 2840, 2841}\n",
      "dict_items([(\"Lemma('millimeter.n.01.mm')\", 7)])\n",
      "collecting tokens for  filter\n",
      "indices:    {3553, 4146, 4147, 30067, 5557, 4148}\n",
      "dict_items([(\"Lemma('filter.v.01.filter')\", 1), (\"Lemma('filter.n.01.filter')\", 3)])\n",
      "collecting tokens for  succession\n",
      "indices:    {35617, 16802, 24197, 26961, 32082, 18227, 13554, 1045, 20507, 27645}\n",
      "dict_items([(\"Lemma('sequence.n.02.succession')\", 2), (\"Lemma('succession.n.02.succession')\", 1), (\"Lemma('succession.n.03.succession')\", 1)])\n",
      "collecting tokens for  limp\n",
      "indices:    {6337, 36387, 36880, 8816, 18227, 19124, 34035, 8506}\n",
      "dict_items([(\"Lemma('limp.s.01.limp')\", 3)])\n",
      "collecting tokens for  huddled\n",
      "indices:    {7140, 7204, 7017, 6030, 36018, 18227, 36123, 26879}\n",
      "dict_items([(\"Lemma('huddle.v.02.huddle')\", 1), (\"Lemma('huddle.v.01.huddle')\", 3)])\n",
      "collecting tokens for  heading\n",
      "indices:    {9857, 35811, 21387, 18521, 34426, 35388}\n",
      "dict_items([(\"Lemma('heading.n.01.heading')\", 1), (\"Lemma('head.v.01.head')\", 5)])\n",
      "collecting tokens for  nevertheless\n",
      "indices:    {23935, 13151}\n",
      "dict_items([(\"Lemma('however.r.01.nevertheless')\", 1)])\n",
      "collecting tokens for  method\n",
      "indices:    {18308, 11405, 5393, 32020, 11413, 11416, 31896, 16154, 15644, 30888, 11307, 4142, 2991, 34739, 14772, 14773, 3126, 26807, 31929, 25919, 14784, 33089, 3908, 3525, 2886, 30152, 4169, 25928, 14796, 14798, 3279, 3280, 31953, 1362, 15701, 15062, 30166, 3541, 2521, 14941, 4191, 4192, 4850, 24180, 12278, 11382, 3702, 12286, 22783}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('method.n.01.method')\", 26)])\n",
      "collecting tokens for  sample\n",
      "indices:    {26304, 3523, 3142, 3143, 15687, 3144, 3146, 15657, 13149, 33070, 15662, 3540, 23670, 3095, 5530, 16157}\n",
      "dict_items([(\"Lemma('sample.n.01.sample')\", 8), (\"Lemma('sample_distribution.n.01.sample')\", 5)])\n",
      "collecting tokens for  molecular\n",
      "indices:    {2976, 3970, 2979, 3204, 2978, 3112, 14796, 2872, 3225, 2556}\n",
      "dict_items([(\"Lemma('molecular.a.01.molecular')\", 6)])\n",
      "collecting tokens for  bid\n",
      "indices:    {32453}\n",
      "dict_items([])\n",
      "collecting tokens for  sons\n",
      "indices:    {7798}\n",
      "dict_items([])\n",
      "collecting tokens for  listed\n",
      "indices:    {32, 32545, 2944, 35, 14057, 265, 3916, 22254, 11534, 25105, 2783, 36883, 11516, 5460, 14008, 11513, 17116, 31}\n",
      "dict_items([(\"Lemma('list.v.02.list')\", 9), (\"Lemma('list.v.01.list')\", 8), (\"Lemma('listed.a.01.listed')\", 1)])\n",
      "collecting tokens for  hughes\n",
      "indices:    {20685}\n",
      "dict_items([])\n",
      "collecting tokens for  600\n",
      "indices:    {18304, 30091, 15631, 29712, 15632, 15636, 15638, 12719, 16313, 27075, 11473, 20691, 30560, 26726, 2798, 29295, 22002, 246, 14843}\n",
      "dict_items([])\n",
      "collecting tokens for  lauren\n",
      "indices:    {33586}\n",
      "dict_items([])\n",
      "collecting tokens for  nod\n",
      "indices:    {23776, 35169, 18886, 30343, 36408, 17164, 19538, 16824, 30589}\n",
      "dict_items([(\"Lemma('nod.v.02.nod')\", 2), (\"Lemma('nod.v.01.nod')\", 1), (\"Lemma('nod.n.02.nod')\", 1)])\n",
      "collecting tokens for  connecticut\n",
      "indices:    {2472}\n",
      "dict_items([(\"Lemma('connecticut.n.01.Connecticut')\", 1)])\n",
      "collecting tokens for  critics\n",
      "indices:    {25697, 25698, 14661, 27334, 31783, 20234, 2449, 24953, 33372, 6783}\n",
      "dict_items([(\"Lemma('critic.n.01.critic')\", 2), (\"Lemma('critic.n.02.critic')\", 1)])\n",
      "collecting tokens for  literature\n",
      "indices:    {14593, 14596, 14597, 7568, 14609, 2322, 14617, 14632, 14633, 14636, 22445, 11438, 14645, 14654, 14663, 3026, 29791, 14708, 23542, 28151, 10744, 11257}\n",
      "dict_items([(\"Lemma('literature.n.01.literature')\", 15), (\"Lemma('literature.n.02.literature')\", 1)])\n",
      "collecting tokens for  civil\n",
      "indices:    {21286, 31567, 20785, 21275, 12574, 20319}\n",
      "dict_items([])\n",
      "collecting tokens for  metropolitan\n",
      "indices:    {5157, 27164, 24069}\n",
      "dict_items([(\"Lemma('metropolitan.a.01.metropolitan')\", 1)])\n",
      "collecting tokens for  saturday\n",
      "indices:    {12807}\n",
      "dict_items([(\"Lemma('saturday.n.01.Saturday')\", 1)])\n",
      "collecting tokens for  trials\n",
      "indices:    {4383, 4384, 29991, 12200, 4393, 4396, 4400, 4403, 4414, 4417, 4420, 4426, 4427, 4428, 4438, 4440, 4443, 1246, 4449, 3427, 14435, 4466, 20850, 4473, 4476}\n",
      "dict_items([(\"Lemma('test.n.05.trial')\", 19), (\"Lemma('trial.n.02.trial')\", 1)])\n",
      "collecting tokens for  carrying\n",
      "indices:    {27138, 15491, 29443, 29958, 14728, 32648, 37004, 2326, 21657, 5787, 9628, 9245, 25250, 21676, 30512, 817, 10290, 2611, 15413, 23734, 9655, 12476, 25285, 35910, 35270, 24517, 35397, 36685, 1233, 27986, 28888, 25304, 218, 9700, 14693, 17513, 17258, 17646, 17134, 33008, 8561, 34158, 12413, 6140, 15741, 11390}\n",
      "dict_items([(\"Lemma('transport.v.02.carry')\", 17), (\"Lemma('carry.v.02.carry')\", 8), (\"Lemma('carry.v.05.carry')\", 2), (\"Lemma('conduct.v.01.carry_on')\", 1), (\"Lemma('impart.v.03.carry')\", 1), (\"Lemma('hold.v.11.carry')\", 1), (\"Lemma('carry.v.04.carry')\", 1), (\"Lemma('carry.v.09.carry')\", 1), (\"Lemma('carry.v.08.carry')\", 1), (\"Lemma('hold.v.14.carry')\", 1)])\n",
      "collecting tokens for  hide\n",
      "indices:    {3715, 34596, 35203, 5670, 7207, 23945, 9354, 19018, 5036, 19661, 31850, 17039, 34602, 17137, 34922, 31251, 31859, 34581}\n",
      "dict_items([(\"Lemma('hide.v.01.hide')\", 14), (\"Lemma('hide.v.02.hide')\", 2), (\"Lemma('hide.n.01.hide')\", 1), (\"Lemma('hide.n.02.hide')\", 1)])\n",
      "collecting tokens for  repetition\n",
      "indices:    {26977, 7192, 24742, 16399, 15825, 1585, 26451, 10612, 30261, 18264, 36345, 2591}\n",
      "dict_items([(\"Lemma('repeat.n.01.repetition')\", 3), (\"Lemma('repetition.n.02.repetition')\", 3), (\"Lemma('repetition.n.03.repetition')\", 1)])\n",
      "collecting tokens for  engagement\n",
      "indices:    {29984, 26977, 25986, 20899, 21124, 36967, 937, 21134, 33295, 13232, 9840, 26071, 22296, 7709, 959}\n",
      "dict_items([(\"Lemma('date.n.03.engagement')\", 2), (\"Lemma('battle.n.01.engagement')\", 1), (\"Lemma('betrothal.n.01.engagement')\", 1), (\"Lemma('employment.n.03.engagement')\", 1)])\n",
      "collecting tokens for  everybody\n",
      "indices:    {16674, 26693, 8334, 6037, 15415, 2685, 36478}\n",
      "dict_items([])\n",
      "collecting tokens for  stanley\n",
      "indices:    {16919}\n",
      "dict_items([(\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  gilborn\n",
      "indices:    {16774}\n",
      "dict_items([(\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  oersted\n",
      "indices:    {11508}\n",
      "dict_items([(\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  essay\n",
      "indices:    {14369, 11458, 14084, 6759, 4791, 14103, 2655, 14672, 11446, 11447, 14680, 13626, 14367}\n",
      "dict_items([(\"Lemma('essay.n.01.essay')\", 13)])\n",
      "collecting tokens for  french\n",
      "indices:    {11322}\n",
      "dict_items([])\n",
      "collecting tokens for  submitted\n",
      "indices:    {11458, 28994, 5125, 5127, 15273, 2218, 23179, 17645, 27341, 20531, 4756, 15257, 15226, 29951}\n",
      "dict_items([(\"Lemma('submit.v.01.submit')\", 7), (\"Lemma('put_in.v.05.submit')\", 1), (\"Lemma('submit.v.03.submit')\", 2), (\"Lemma('present.v.04.submit')\", 2), (\"Lemma('submit.v.02.submit')\", 1), (\"Lemma('take.v.19.submit')\", 1)])\n",
      "collecting tokens for  prize\n",
      "indices:    {521, 11339, 19582, 24350}\n",
      "dict_items([(\"Lemma('prize.n.01.prize')\", 1)])\n",
      "collecting tokens for  king\n",
      "indices:    {29039}\n",
      "dict_items([])\n",
      "collecting tokens for  register\n",
      "indices:    {30562, 27654, 22248, 5865, 11696, 21169, 2744, 16058}\n",
      "dict_items([(\"Lemma('register.n.01.register')\", 2), (\"Lemma('register_language.n.01.register_language')\", 1)])\n",
      "collecting tokens for  builders\n",
      "indices:    {27842, 3177, 21971, 21973, 21974, 3224, 20734}\n",
      "dict_items([(\"Lemma('builder.n.01.builder')\", 2)])\n",
      "collecting tokens for  washing\n",
      "indices:    {3200, 7177, 3214, 36113, 3221, 30104, 3229, 36132, 7618, 4166, 4174, 3150, 3166, 11999, 3168, 3170, 3174, 26855, 3176, 3175, 10348, 36078, 3184, 3185, 3199}\n",
      "dict_items([(\"Lemma('wash.n.02.washing')\", 12), (\"Lemma('wash.v.03.wash')\", 5), (\"Lemma('wash.v.01.wash')\", 2), (\"Lemma('wash.v.02.wash')\", 1)])\n",
      "collecting tokens for  textiles\n",
      "indices:    {23488, 23459, 3176, 5032, 23469, 6029, 23470, 14993, 2098, 23473, 3166}\n",
      "dict_items([(\"Lemma('fabric.n.01.textile')\", 6)])\n",
      "collecting tokens for  schnabel\n",
      "indices:    {1730}\n",
      "dict_items([])\n",
      "collecting tokens for  superb\n",
      "indices:    {26085, 26664, 13848, 26093, 26382, 26416, 1201, 916, 14200, 1754, 27003, 13887}\n",
      "dict_items([(\"Lemma('brilliant.s.01.superb')\", 6)])\n",
      "collecting tokens for  quartet\n",
      "indices:    {30266}\n",
      "dict_items([])\n",
      "collecting tokens for  deal\n",
      "indices:    {21889, 28675, 12933, 33415, 4617, 1931, 13198, 12689, 17939, 16148, 1813, 3607, 16536, 33175, 1946, 27801, 16540, 16549, 33318, 23848, 34984, 37166, 174, 18228, 36022, 31544, 10938, 11197, 16198, 6986, 1611, 9294, 25806, 30800, 12112, 24530, 1235, 31567, 27094, 12126, 23647, 27360, 23903, 20580, 13671, 12648, 17257, 2663, 21864, 5484, 6894, 16495, 32880, 4596, 6134, 14712, 14590}\n",
      "dict_items([(\"Lemma('cope.v.01.deal')\", 4), (\"Lemma('deal.v.03.deal')\", 4), (\"Lemma('manage.v.02.deal')\", 1), (\"Lemma('consider.v.03.deal')\", 2), (\"Lemma('bargain.n.01.deal')\", 1), (\"Lemma('deal.n.01.deal')\", 4), (\"Lemma('deal.v.06.deal')\", 2), (\"Lemma('deal.v.08.deal')\", 1), (\"Lemma('cover.v.05.deal')\", 1)])\n",
      "collecting tokens for  filled\n",
      "indices:    {6158, 16913, 5649, 9244, 12829, 3616, 25650, 2612, 3144, 12374, 12901, 24677, 23655, 24681, 11382, 12407, 18556, 24192, 33938, 28307, 23187, 29333, 19607, 23195, 34986, 8370, 19130, 14533, 7877, 5837, 33490, 26323, 35543, 35544, 1754, 35035, 21724, 2268, 15073, 10466, 36066, 28391, 13031, 7401, 28394, 7404, 3823, 15089, 26868, 16634, 15101, 13565, 7935, 5891, 35588, 6923, 27405, 31510, 19237, 7975, 19240, 37165, 32047, 30004, 11608, 30558, 26464, 26476, 16275, 9110, 12704, 32677, 33192, 32682, 20922, 20437, 27613, 15839, 9201, 13811, 4085, 4091, 4095}\n",
      "dict_items([(\"Lemma('fill.v.01.fill')\", 26), (\"Lemma('meet.v.04.fill')\", 2), (\"Lemma('fill.v.09.fill')\", 1), (\"Lemma('fill.v.02.fill')\", 8), (\"Lemma('fill_up.v.04.fill')\", 1), (\"Lemma('filled.s.01.filled')\", 15), (\"Lemma('occupy.v.03.fill')\", 6), (\"Lemma('fill_in.v.01.fill_in')\", 2)])\n",
      "collecting tokens for  m\n",
      "indices:    {3098}\n",
      "dict_items([(\"Lemma('molarity.n.01.M')\", 1)])\n",
      "collecting tokens for  inc.\n",
      "indices:    {21833}\n",
      "dict_items([])\n",
      "collecting tokens for  columbus\n",
      "indices:    {21582}\n",
      "dict_items([])\n",
      "collecting tokens for  complex\n",
      "indices:    {21889, 3970, 32770, 2307, 32772, 14851, 4354, 8712, 25608, 11529, 32782, 31119, 4369, 32786, 4370, 32788, 11537, 24465, 15254, 15763, 11545, 16154, 5020, 25890, 4646, 4647, 31271, 23850, 32810, 11693, 22192, 23602, 32179, 14900, 11957, 32182, 23996, 4799, 16320, 32836, 32838, 15816, 22217, 21963, 22606, 16079, 12622, 15445, 15963, 14683, 16100, 15717, 27878, 22761, 3178, 4203, 12781, 4206, 27887, 15856, 30835, 16118, 11638, 31226}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('complex.a.01.complex')\", 26), (\"Lemma('complex.n.02.complex')\", 1), (\"Lemma('complex.n.01.complex')\", 6)])\n",
      "collecting tokens for  layers\n",
      "indices:    {29794, 3078, 3079, 15080, 3084, 23996, 19036}\n",
      "dict_items([(\"Lemma('layer.n.01.layer')\", 5)])\n",
      "collecting tokens for  traditional\n",
      "indices:    {26945, 24578}\n",
      "dict_items([])\n",
      "collecting tokens for  procedures\n",
      "indices:    {20999, 4237, 20366, 20369, 18, 4242, 2835, 4243, 4251, 4256, 23585, 32297, 9900, 33077, 33080, 31289, 15290, 30779, 23996, 32702, 4159, 2627, 16067, 15811, 30406, 2631, 15305, 3406, 5462, 27095, 14168, 16225, 3170, 3172, 22762, 33008, 15732, 887, 31355}\n",
      "dict_items([(\"Lemma('procedure.n.01.procedure')\", 16), (\"Lemma('operation.n.07.procedure')\", 6)])\n",
      "collecting tokens for  suspicious\n",
      "indices:    {22858, 28618, 16396, 19373, 35342, 9360, 19410, 31831, 23996}\n",
      "dict_items([(\"Lemma('fishy.s.02.suspicious')\", 1), (\"Lemma('leery.s.01.suspicious')\", 3)])\n",
      "collecting tokens for  fearful\n",
      "indices:    {12241, 32058, 33554, 12965}\n",
      "dict_items([])\n",
      "collecting tokens for  thread\n",
      "indices:    {29671, 29677, 29688, 12505, 17306}\n",
      "dict_items([(\"Lemma('thread.n.01.thread')\", 2), (\"Lemma('thread.v.02.thread')\", 1)])\n",
      "collecting tokens for  matching\n",
      "indices:    {22150, 14570, 7434, 28843, 15055, 20310}\n",
      "dict_items([(\"Lemma('match.v.05.match')\", 1), (\"Lemma('match.v.01.match')\", 1), (\"Lemma('match.v.02.match')\", 1), (\"Lemma('coordinated.s.03.matching')\", 1)])\n",
      "collecting tokens for  needle\n",
      "indices:    {34851, 35079, 35081, 29675, 34860, 29676, 29680, 15825, 11508, 11510, 29688, 30681, 34877, 34783}\n",
      "dict_items([(\"Lemma('needle.n.02.needle')\", 1)])\n",
      "collecting tokens for  limiting\n",
      "indices:    {16417, 16353, 16325, 27813, 23470, 23473, 3768, 23613}\n",
      "dict_items([(\"Lemma('confining.s.01.limiting')\", 3), (\"Lemma('restrict.v.03.limit')\", 2)])\n",
      "collecting tokens for  limited\n",
      "indices:    {31236, 11280, 23568, 16402, 12310, 16406, 31773, 22047, 12323, 1573, 1072, 16438, 16442, 23613, 16452, 26197, 34390, 5220, 15464, 32888, 21628, 11399, 32912, 32925, 3753, 1707, 174, 27831, 16059, 22722, 30917, 23239, 2247, 2256, 28369, 1757, 27876, 17640, 2803, 31990, 23809, 2820, 20238, 23823, 18727, 14121, 14122, 3885, 2355, 20287, 35653, 30043, 14172, 35676, 16225, 28514, 31590, 10097, 16241, 5497, 20346, 23935, 14209, 4995, 32134, 21895, 32135, 3478, 13213, 5027, 16291, 21430, 20409, 16315, 9679, 25042, 16347, 31207, 17907, 32248, 2041}\n",
      "dict_items([(\"Lemma('limited.a.01.limited')\", 25), (\"Lemma('circumscribed.s.01.limited')\", 3), (\"Lemma('restrict.v.03.limit')\", 11), (\"Lemma('limit.v.02.limit')\", 2), (\"Lemma('limited.s.03.limited')\", 3)])\n",
      "collecting tokens for  fight\n",
      "indices:    {7692, 19872, 28453, 35115, 7724, 12463, 20147, 36789, 19894, 17592, 27321, 5057, 22850, 5059, 25540, 13379, 23617, 19911, 26180, 12872, 8140, 34893, 18638, 20174, 19282, 22870, 91, 22748, 24036, 27113, 27114, 33899, 28400, 26231, 27129, 635, 20479}\n",
      "dict_items([(\"Lemma('fight.n.02.fight')\", 8), (\"Lemma('fight.v.02.fight')\", 8), (\"Lemma('competitiveness.n.01.fight')\", 1), (\"Lemma('contend.v.06.fight')\", 7), (\"Lemma('battle.n.01.fight')\", 1), (\"Lemma('crusade.v.01.fight')\", 1), (\"Lemma('fight.v.03.fight')\", 1)])\n",
      "collecting tokens for  besides\n",
      "indices:    {21092}\n",
      "dict_items([])\n",
      "collecting tokens for  stirring\n",
      "indices:    {7402, 7404, 29520, 9010, 36340, 7256, 7804}\n",
      "dict_items([(\"Lemma('stimulate.v.06.stir')\", 1), (\"Lemma('stir.v.01.stir')\", 3), (\"Lemma('stir.v.02.stir')\", 1), (\"Lemma('stirring.n.01.stirring')\", 1)])\n",
      "collecting tokens for  removed\n",
      "indices:    {3200, 35972, 22024, 31369, 5130, 1420, 28814, 28815, 7184, 2322, 2968, 6436, 3236, 33575, 36136, 16814, 5426, 13491, 33589, 26422, 30009, 13628, 31037, 10816, 4162, 27515, 13640, 9673, 14410, 32075, 6092, 3537, 25939, 1493, 19158, 3159, 1237, 9177, 27519, 30939, 6108, 21340, 740, 24165, 3173, 25832, 745, 34667, 28668, 24045, 35695, 24178, 32755, 30075, 19324, 3199}\n",
      "dict_items([(\"Lemma('remove.v.01.remove')\", 26), (\"Lemma('remove.v.05.remove')\", 3), (\"Lemma('get_rid_of.v.01.remove')\", 2), (\"Lemma('take_out.v.01.remove')\", 1), (\"Lemma('absent.v.01.remove')\", 1)])\n",
      "collecting tokens for  automobiles\n",
      "indices:    {28674, 32273, 32279, 32407, 9881, 32282, 32285, 25246, 25247, 32305, 32309, 32318, 32319, 32320, 32322, 32323, 4951, 32357, 12775}\n",
      "dict_items([(\"Lemma('car.n.01.automobile')\", 3)])\n",
      "collecting tokens for  employees\n",
      "indices:    {11776, 899, 900, 11781, 11780, 32263, 14860, 32273, 16274, 14230, 32283, 11805, 32285, 14239, 14240, 14881, 32289, 22691, 21156, 32290, 21158, 21159, 21160, 22827, 15278, 32305, 22711, 32312, 12472, 32315, 28348, 32318, 32321, 14915, 2760, 11850, 22731, 11852, 11733, 11735, 11737, 22750, 13281, 12516, 11749, 11757, 11759, 11763, 3445, 15611, 15612, 14205, 11774}\n",
      "dict_items([(\"Lemma('employee.n.01.employee')\", 26)])\n",
      "collecting tokens for  orioles\n",
      "indices:    {22995}\n",
      "dict_items([])\n",
      "collecting tokens for  performed\n",
      "indices:    {31618, 26005, 26520, 18716, 23582, 1182, 1183, 4651, 28460, 1581, 28464, 8368, 1586, 188, 11201, 26311, 3529, 31946, 1233, 2388, 6873, 26076, 31708, 22750, 26338, 26340, 14441, 2027, 15728, 9585}\n",
      "dict_items([(\"Lemma('perform.v.01.perform')\", 9), (\"Lemma('perform.v.03.perform')\", 10), (\"Lemma('perform.v.02.perform')\", 6)])\n",
      "collecting tokens for  plate\n",
      "indices:    {19832, 5035, 22995, 230}\n",
      "dict_items([(\"Lemma('plate.n.03.plate')\", 1), (\"Lemma('home_plate.n.01.plate')\", 1)])\n",
      "collecting tokens for  gathering\n",
      "indices:    {5345, 36421, 17445, 20421, 1254, 14761, 2121, 7530, 21453, 37008, 5332, 37141, 1046, 7354, 24347, 188, 9853}\n",
      "dict_items([(\"Lemma('assembly.n.06.gathering')\", 1), (\"Lemma('gather.v.01.gather')\", 6), (\"Lemma('gathering.n.01.gathering')\", 3), (\"Lemma('gather.n.02.gathering')\", 1)])\n",
      "collecting tokens for  latter\n",
      "indices:    {28039}\n",
      "dict_items([])\n",
      "collecting tokens for  attempted\n",
      "indices:    {27532, 21789, 22814, 32928, 36902, 17838, 21167, 17969, 25790, 34751, 31424, 13763, 3907, 26565, 16713, 2889, 26574, 21326, 33102, 11217, 22868, 35671, 26596, 16229, 35690}\n",
      "dict_items([(\"Lemma('undertake.v.01.attempt')\", 8), (\"Lemma('try.v.01.attempt')\", 15), (\"Lemma('attempted.s.01.attempted')\", 2)])\n",
      "collecting tokens for  glorious\n",
      "indices:    {31520, 10250, 26099, 19094}\n",
      "dict_items([(\"Lemma('glorious.a.01.glorious')\", 2)])\n",
      "collecting tokens for  short\n",
      "indices:    {35809, 3875, 3911, 34093, 9710, 30898, 31027, 17334, 5047, 13846, 10107, 14973}\n",
      "dict_items([(\"Lemma('short_bone.n.01.short_bone')\", 1), (\"Lemma('short.a.01.short')\", 2), (\"Lemma('short.a.03.short')\", 1), (\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  candidate\n",
      "indices:    {10242, 21642, 20492, 20388, 24615, 40, 23719, 39, 43, 44, 2104, 14137, 5305, 28987, 20417, 26691, 20421, 20423, 20424, 20167, 20430, 26707, 20436, 20453, 885, 22901, 10104}\n",
      "dict_items([(\"Lemma('campaigner.n.01.candidate')\", 7), (\"Lemma('candidate.n.02.candidate')\", 3)])\n",
      "collecting tokens for  lots\n",
      "indices:    {18764}\n",
      "dict_items([(\"Lemma('tons.n.01.lots')\", 1)])\n",
      "collecting tokens for  repeatedly\n",
      "indices:    {3168, 6337, 20162, 27266, 6214, 4392, 33836, 5101, 15505, 13365, 16405, 10104, 30235, 11997}\n",
      "dict_items([(\"Lemma('repeatedly.r.01.repeatedly')\", 10)])\n",
      "collecting tokens for  massive\n",
      "indices:    {12422, 8075, 35467, 5265, 24979, 7957, 33052, 21407, 25251, 14118, 21418, 29361, 1588, 23610, 28474, 32703, 12865, 35912, 28371, 8019, 32239, 26482, 34676, 9721}\n",
      "dict_items([(\"Lemma('massive.s.01.massive')\", 9)])\n",
      "collecting tokens for  emphasized\n",
      "indices:    {11716, 32901, 33064, 32616, 27753, 3183, 6099, 4276, 21525, 22645, 32028, 24345, 27546, 33180, 15454, 4639}\n",
      "dict_items([(\"Lemma('stress.v.01.emphasize')\", 14)])\n",
      "collecting tokens for  train\n",
      "indices:    {24712}\n",
      "dict_items([])\n",
      "collecting tokens for  employ\n",
      "indices:    {17370, 14178, 5027, 1260, 28467, 21525, 21529, 23930}\n",
      "dict_items([(\"Lemma('use.v.01.employ')\", 5), (\"Lemma('employment.n.01.employ')\", 1)])\n",
      "collecting tokens for  fulfill\n",
      "indices:    {2059, 22379, 24749, 25263, 11216, 14002, 21525, 11260}\n",
      "dict_items([(\"Lemma('carry_through.v.01.fulfill')\", 5), (\"Lemma('meet.v.04.fulfill')\", 2), (\"Lemma('satisfy.v.01.fulfill')\", 1)])\n",
      "collecting tokens for  personally\n",
      "indices:    {12675, 27654, 24723, 32662, 13728, 10657, 13730, 11681, 25904, 12218, 16063, 31304, 31948, 9173, 91, 2140, 12650, 14956, 1523, 35962, 33022}\n",
      "dict_items([(\"Lemma('personally.r.01.personally')\", 5), (\"Lemma('personally.r.02.personally')\", 3), (\"Lemma('personally.r.03.personally')\", 2), (\"Lemma('personally.r.05.personally')\", 1), (\"Lemma('personally.r.04.personally')\", 2)])\n",
      "collecting tokens for  events\n",
      "indices:    {21004, 32654, 34836, 27029, 15511, 13848, 15391, 13618, 14643, 14646, 29240, 12345, 30906, 33084, 18620, 13637, 34889, 2383, 33364, 28900, 31082, 8811, 11888, 21360, 14708, 11509, 13558, 11257, 32511}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('event.n.01.event')\", 15), (\"Lemma('event.n.02.event')\", 1)])\n",
      "collecting tokens for  guess\n",
      "indices:    {9094, 20112, 20116, 19352, 24475, 10401, 7464, 32681, 7465, 9264, 35764, 1207, 17339, 19643, 9917, 23615, 9919, 24009, 19789, 8271, 7378, 9427, 35026, 16723, 4955, 16988, 9564, 19164, 33897, 3694, 33903, 18161, 3318, 16502, 8184, 35066, 6269}\n",
      "dict_items([(\"Lemma('guess.v.02.guess')\", 3), (\"Lemma('estimate.v.01.guess')\", 5), (\"Lemma('think.v.02.guess')\", 23), (\"Lemma('guess.v.04.guess')\", 4), (\"Lemma('guess.n.02.guess')\", 1)])\n",
      "collecting tokens for  concepts\n",
      "indices:    {32010, 27532, 31253, 1304, 1307, 1310, 32681, 2476, 31799, 11208, 15818, 28108, 24918, 31959, 15868, 31966, 15858, 31220, 29052, 31997}\n",
      "dict_items([(\"Lemma('concept.n.01.concept')\", 8)])\n",
      "collecting tokens for  liberty\n",
      "indices:    {7798}\n",
      "dict_items([])\n",
      "collecting tokens for  freedom\n",
      "indices:    {32640, 25857, 20775, 27834, 28405, 23862, 25081, 27290}\n",
      "dict_items([])\n",
      "collecting tokens for  born\n",
      "indices:    {11267, 28179, 2463, 26785, 28202, 3755, 3758, 6062, 3762, 28212, 12472, 11453, 11072, 11334, 32071, 28232, 28233, 27343, 25685, 21465, 28265, 28268, 10744}\n",
      "dict_items([(\"Lemma('bear.v.05.bear')\", 1), (\"Lemma('born.a.01.born')\", 1), (\"Lemma('give_birth.v.01.bear')\", 5), (\"Lemma('be_born.v.01.be_born')\", 1)])\n",
      "collecting tokens for  phosphate\n",
      "indices:    {4128, 4130, 1637, 3559, 3151, 3154, 3224}\n",
      "dict_items([(\"Lemma('phosphate.n.01.phosphate')\", 7)])\n",
      "collecting tokens for  rock\n",
      "indices:    {7840, 6405}\n",
      "dict_items([(\"Lemma('rock.n.02.rock')\", 1)])\n",
      "collecting tokens for  bone\n",
      "indices:    {7557, 4102, 35472, 9874, 8605, 35616, 11425, 31017, 28969, 31022, 31023, 27953, 31025, 27958, 27063, 6333, 4031, 5954, 3911, 1637, 29418, 31472, 7794, 25597}\n",
      "dict_items([(\"Lemma('bone.n.02.bone')\", 2), (\"Lemma('bone.n.01.bone')\", 3)])\n",
      "collecting tokens for  hole\n",
      "indices:    {28809, 18234, 13132, 3654}\n",
      "dict_items([(\"Lemma('hole.n.01.hole')\", 2)])\n",
      "collecting tokens for  acknowledged\n",
      "indices:    {14880, 8449, 1400, 37065, 16428, 14639, 8530, 21652, 16408, 32733}\n",
      "dict_items([(\"Lemma('notice.v.04.acknowledge')\", 2), (\"Lemma('acknowledge.v.02.acknowledge')\", 3), (\"Lemma('admit.v.01.acknowledge')\", 1)])\n",
      "collecting tokens for  lead\n",
      "indices:    {13184, 18817, 31875, 31876, 391, 27145, 26505, 1291, 27786, 27662, 26002, 28694, 4247, 12825, 27802, 32153, 9881, 14365, 22943, 19362, 22948, 7333, 678, 27047, 34221, 14766, 29999, 16306, 27130, 35637, 25270, 13494, 21433, 22969, 13244, 3065, 36926, 18880, 14784, 13382, 15814, 3654, 32076, 1869, 14542, 460, 11473, 26707, 14547, 22870, 36955, 22368, 34785, 3043, 35811, 16229, 14054, 25447, 35559, 10217, 25446, 364, 2285, 25198, 26735, 24559, 241, 626, 9586, 11505, 27122, 11127, 27129, 25338, 4220}\n",
      "dict_items([(\"Lemma('lead.v.01.lead')\", 9), (\"Lemma('leave.v.07.lead')\", 12), (\"Lemma('head.v.02.lead')\", 6), (\"Lemma('lead.n.03.lead')\", 3), (\"Lemma('lead.n.05.lead')\", 1), (\"Lemma('lead.n.02.lead')\", 4), (\"Lemma('lead.v.03.lead')\", 7), (\"Lemma('lead.n.04.lead')\", 2), (\"Lemma('lead.v.04.lead')\", 2), (\"Lemma('conduct.v.02.lead')\", 4), (\"Lemma('lead.n.01.lead')\", 3), (\"Lemma('lead.v.05.lead')\", 2), (\"Lemma('lead.n.06.lead')\", 1)])\n",
      "collecting tokens for  cobb\n",
      "indices:    {18571}\n",
      "dict_items([(\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  gain\n",
      "indices:    {11521, 11522, 31746, 28418, 4610, 24326, 11532, 22034, 21907, 12051, 278, 22039, 2846, 11554, 20261, 1337, 13244, 24009, 21964, 20558, 30545, 33368, 24027, 4576, 14308, 11623, 19433, 30191, 33264, 21878, 27388, 11519}\n",
      "dict_items([(\"Lemma('derive.v.02.gain')\", 7), (\"Lemma('acquire.v.05.gain')\", 4), (\"Lemma('addition.n.03.gain')\", 5), (\"Lemma('amplification.n.02.gain')\", 2), (\"Lemma('profit.n.02.gain')\", 1), (\"Lemma('profit.v.01.gain')\", 3), (\"Lemma('advance.v.12.gain')\", 1)])\n",
      "collecting tokens for  feed\n",
      "indices:    {11521, 11523, 11525, 11530, 24331, 11532, 12942, 11534, 11538, 11542, 11544, 11545, 11546, 29212, 29981, 11549, 11551, 11553, 11554, 3620, 11430, 11560, 11564, 11571, 11574, 24248, 11578, 11585, 11588, 11589, 11595, 29899, 11596, 11598, 11600, 11602, 11603, 12117, 12118, 11610, 11616, 22116, 25327, 11511, 11516}\n",
      "dict_items([(\"Lemma('feed.n.01.feed')\", 17), (\"Lemma('feed.v.01.feed')\", 16), (\"Lemma('feed.v.05.feed')\", 1), (\"Lemma('feed.v.02.feed')\", 5), (\"Lemma('feed.v.07.feed')\", 1)])\n",
      "collecting tokens for  efficiency\n",
      "indices:    {11521, 7, 11532, 33037, 11534, 2066, 11795, 15773, 11554, 11564, 3376, 5428, 4927, 2879, 26696, 9800, 3276, 11519, 24164, 23527, 14316, 4597, 5496, 29055}\n",
      "dict_items([(\"Lemma('efficiency.n.02.efficiency')\", 7), (\"Lemma('efficiency.n.01.efficiency')\", 11)])\n",
      "collecting tokens for  grams\n",
      "indices:    {11584, 11522, 11586, 11524, 11523, 11587, 11529, 11532, 11533, 11568, 3093, 11544, 11546, 11550, 11551}\n",
      "dict_items([(\"Lemma('gram.n.01.gram')\", 15)])\n",
      "collecting tokens for  ton\n",
      "indices:    {11522, 11523, 23492, 19235, 23848, 11546, 11532, 11533, 30163, 30164, 11544, 24122, 11550}\n",
      "dict_items([(\"Lemma('short_ton.n.01.ton')\", 8)])\n",
      "collecting tokens for  tough\n",
      "indices:    {353, 23746, 23745, 12676, 30565, 3623, 23143, 36554, 8173, 26033, 18418, 34228, 23448, 2616, 29055}\n",
      "dict_items([(\"Lemma('tough.a.03.tough')\", 1), (\"Lemma('tough.a.01.tough')\", 4)])\n",
      "collecting tokens for  greeted\n",
      "indices:    {4899, 4900, 36731, 8387, 20391, 230, 24649, 9353, 7307, 35212, 22538, 7314, 34612, 5626, 7739, 36988}\n",
      "dict_items([(\"Lemma('greet.v.02.greet')\", 3), (\"Lemma('greet.v.01.greet')\", 9), (\"Lemma('greet.v.03.greet')\", 3), (\"Lemma('greet.v.04.greet')\", 1)])\n",
      "collecting tokens for  observation\n",
      "indices:    {26371, 13580, 11405, 26389, 2853, 4262, 4008, 14391, 14782, 11326, 26816, 3279, 26840, 10207, 28513, 14438, 13808, 3702, 10233}\n",
      "dict_items([(\"Lemma('observation.n.02.observation')\", 5), (\"Lemma('observation.n.01.observation')\", 5), (\"Lemma('notice.n.02.observation')\", 1), (\"Lemma('observation.n.03.observation')\", 1)])\n",
      "collecting tokens for  served\n",
      "indices:    {29184, 31745, 31232, 5122, 32262, 12808, 29211, 29217, 16442, 14909, 22597, 20585, 11891, 27768, 4728, 27770, 30849, 7302, 22670, 24216, 166, 4262, 4264, 167, 682, 12970, 4775, 13998, 22199, 22200, 27832, 30395, 12997, 25800, 18634, 22737, 5849, 29923, 23788, 23789, 23790, 30447, 30456, 30457, 30459, 30464, 30468, 2310, 32016, 32018, 37138, 8470, 32022, 29473, 20270, 11257, 29502, 5438, 23374, 12635, 2910, 12642, 9575, 15744, 15760, 14736, 27550, 21420, 34732, 10680, 19392, 4051, 32216, 5085, 25566, 11235, 31718, 23528, 2537, 29163, 10734, 8175, 31728, 32242, 20979, 32247, 22521, 20476}\n",
      "dict_items([(\"Lemma('serve.v.02.serve')\", 19), (\"Lemma('serve.v.06.serve')\", 11), (\"Lemma('serve.v.03.serve')\", 11), (\"Lemma('serve.v.10.serve')\", 1), (\"Lemma('serve.v.11.serve')\", 2), (\"Lemma('serve.v.05.serve')\", 11), (\"Lemma('serve.v.09.serve')\", 3), (\"Lemma('serve.v.01.serve')\", 16), (\"Lemma('serve.v.08.serve')\", 4), (\"Lemma('serve.v.07.serve')\", 3), (\"Lemma('service.v.01.serve')\", 5)])\n",
      "collecting tokens for  guide\n",
      "indices:    {16005, 28556, 30374, 4262, 16295, 29621, 12992, 36036, 33225, 28745, 22354, 24915, 31702, 4577, 20580, 3557, 22886, 26988, 24301, 31218, 9586, 32500, 4602, 32499, 17528, 30329, 32506, 29563}\n",
      "dict_items([(\"Lemma('lead.v.01.guide')\", 7), (\"Lemma('steer.v.01.guide')\", 4), (\"Lemma('guide.v.03.guide')\", 4), (\"Lemma('template.n.01.guide')\", 1)])\n",
      "collecting tokens for  achieve\n",
      "indices:    {14211, 22403, 4614, 7, 20358, 21001, 32145, 1810, 15382, 20254, 11298, 4262, 15667, 27573, 32054, 24888, 23749, 26566, 30799, 22358, 15704, 15713, 2156, 15724, 25199, 4591, 4593, 14580, 32119, 5241, 4606}\n",
      "dict_items([(\"Lemma('achieve.v.01.achieve')\", 26)])\n",
      "collecting tokens for  physiological\n",
      "indices:    {27179, 27180, 4278, 4246, 4215, 27227, 4220}\n",
      "dict_items([(\"Lemma('physiological.a.01.physiological')\", 4)])\n",
      "collecting tokens for  qualified\n",
      "indices:    {25025, 28610, 14877, 1827, 28613, 32743, 23176, 20201, 23159, 34763, 14668, 12919, 26926, 12849, 20311, 11707, 22717, 27807}\n",
      "dict_items([(\"Lemma('qualified.a.01.qualified')\", 2), (\"Lemma('qualify.v.01.qualify')\", 1), (\"Lemma('qualify.v.03.qualify')\", 1), (\"Lemma('certified.s.03.qualified')\", 1), (\"Lemma('qualified.a.02.qualified')\", 1), (\"Lemma('qualify.v.04.qualify')\", 1)])\n",
      "collecting tokens for  admission\n",
      "indices:    {24640, 4801, 23297, 23296, 20610, 23176, 14761, 2089, 4044, 21424, 24945, 4019, 27636, 21078, 4054, 24950, 4057, 13307}\n",
      "dict_items([(\"Lemma('admission.n.01.admission')\", 7), (\"Lemma('admission.n.02.admission')\", 1)])\n",
      "collecting tokens for  already\n",
      "indices:    {11654, 28297, 36111, 2070, 9624, 9881, 3609, 24609, 289, 20137, 32170, 9649, 7733, 27446, 29239, 33093, 36298, 23629, 31186, 27732, 36436, 36445, 14954, 12268, 13679, 1267, 25972, 23027, 21369}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('already.r.01.already')\", 13)])\n",
      "collecting tokens for  awkward\n",
      "indices:    {34176, 19615, 23718, 25736, 16523, 4816, 16467, 16543}\n",
      "dict_items([(\"Lemma('awkward.s.01.awkward')\", 5)])\n",
      "collecting tokens for  judgments\n",
      "indices:    {5345, 25506, 15809, 12329, 15243, 34382, 27902, 27859, 4819, 4883, 4821, 25042, 25497, 1373, 4638, 11263}\n",
      "dict_items([(\"Lemma('judgment.n.02.judgment')\", 3), (\"Lemma('judgment.n.01.judgment')\", 6), (\"Lemma('judgment.n.03.judgment')\", 1)])\n",
      "collecting tokens for  aware\n",
      "indices:    {14592, 21752, 32259, 2569, 28427, 11147, 6925, 18446, 1806, 6802, 27293, 17834, 14122, 14380, 14508, 13995, 23601, 35959, 12727, 35645, 15806, 27328, 26564, 27333, 15432, 8010, 33611, 18124, 11341, 31050, 37074, 18135, 24922, 5853, 13279, 15841, 11235, 9316, 9187, 9191, 30826, 34031, 22513, 15858, 28402, 27890, 11893, 13430, 31094, 24440, 36601, 11894}\n",
      "dict_items([(\"Lemma('aware.a.01.aware')\", 26)])\n",
      "collecting tokens for  allowing\n",
      "indices:    {14865, 24978, 27163, 27806, 12194, 29608, 21289, 5424, 26548, 13249, 14787, 21573, 32967, 15695, 20188, 22751, 4961, 3570, 25974, 12279, 24696, 22271}\n",
      "dict_items([(\"Lemma('allow.v.03.allow')\", 3), (\"Lemma('let.v.01.allow')\", 9), (\"Lemma('leave.v.06.allow')\", 1), (\"Lemma('permit.v.01.allow')\", 5), (\"Lemma('allow.v.04.allow')\", 1), (\"Lemma('allow.v.06.allow')\", 1)])\n",
      "collecting tokens for  velocity\n",
      "indices:    {29060, 3334, 10257, 29073, 2963, 3358, 3362, 3364, 2982, 2860, 12720, 3377, 12721, 14803, 2907, 3304, 1912, 31483, 29053, 2942, 11391}\n",
      "dict_items([(\"Lemma('speed.n.01.velocity')\", 16)])\n",
      "collecting tokens for  varies\n",
      "indices:    {17314, 3304, 4492, 4877, 4565, 3734, 27000, 2811}\n",
      "dict_items([(\"Lemma('change.v.03.vary')\", 5), (\"Lemma('deviate.v.02.vary')\", 2), (\"Lemma('vary.v.03.vary')\", 1)])\n",
      "collecting tokens for  particle\n",
      "indices:    {3456, 29858, 3304, 6633, 3305, 10283, 3386, 3117, 3050, 3408, 3413, 3350, 3192, 3194, 3355, 3421, 3326}\n",
      "dict_items([(\"Lemma('particle.n.02.particle')\", 6), (\"Lemma('atom.n.02.particle')\", 9), (\"Lemma('particle.n.03.particle')\", 1)])\n",
      "collecting tokens for  1000\n",
      "indices:    {128, 4994, 3341, 15119, 5540, 12714, 21419, 14891, 14893, 14894, 12718, 3117, 14892, 3253, 12863, 31044, 3525, 3524, 3531, 20706, 24677, 20839, 3304, 20204, 14830, 4975, 28527, 4976, 28669}\n",
      "dict_items([(\"Lemma('thousand.s.01.1000')\", 18)])\n",
      "collecting tokens for  diameter\n",
      "indices:    {4096, 2817, 11396, 11398, 2823, 28806, 24980, 2836, 29590, 29589, 2840, 2969, 2968, 2845, 3359, 2855, 3115, 29875, 3141, 3791, 3792, 2897, 3410, 29904, 2903, 28902, 14822, 3304, 4072, 28913, 4083, 2937, 4095}\n",
      "dict_items([(\"Lemma('diameter.n.01.diameter')\", 24), (\"Lemma('diameter.n.02.diameter')\", 1)])\n",
      "collecting tokens for  orbit\n",
      "indices:    {34466, 27394, 27399, 3304, 26951, 3337, 840, 31920, 28851, 12981, 31862, 19032, 3321, 12926}\n",
      "dict_items([(\"Lemma('scope.n.01.orbit')\", 1), (\"Lemma('orbit.n.01.orbit')\", 5), (\"Lemma('sphere.n.01.orbit')\", 1)])\n",
      "collecting tokens for  mars\n",
      "indices:    {31920}\n",
      "dict_items([])\n",
      "collecting tokens for  moved\n",
      "indices:    {7168, 34305, 35843, 35334, 7175, 9227, 6670, 29201, 24081, 5652, 29205, 7197, 19486, 11297, 5671, 18479, 13366, 28727, 15417, 34875, 25155, 11334, 5712, 593, 33876, 31829, 9310, 25694, 22114, 7786, 18551, 31864, 23682, 20105, 35978, 16524, 37012, 17563, 30876, 11421, 18590, 26789, 31912, 12976, 8882, 12467, 23732, 8896, 12994, 12996, 5829, 24262, 199, 17096, 30928, 34000, 18135, 19161, 30944, 7406, 29935, 22263, 18168, 12537, 31481, 250, 18683, 26873, 24319, 24848, 13589, 33557, 34073, 13600, 7458, 35110, 21800, 34090, 14123, 36139, 31023, 34095, 31025, 18738, 33590, 33596, 23358, 330, 34132, 17750, 18796, 27501, 367, 18292, 8566, 8571, 7548, 19845, 29064, 19850, 19339, 13195, 31127, 19864, 28569, 8092, 28581, 422, 35756, 7607, 18360, 6588, 7107, 18372, 35781, 26052, 34250, 6092, 18389, 32735, 33764, 7659, 496, 7166}\n",
      "dict_items([(\"Lemma('move.v.02.move')\", 19), (\"Lemma('move.v.04.move')\", 11), (\"Lemma('go.v.02.move')\", 6), (\"Lemma('travel.v.01.move')\", 26), (\"Lemma('move.v.03.move')\", 17), (\"Lemma('ascend.v.08.move_up')\", 1), (\"Lemma('affect.v.05.move')\", 2), (\"Lemma('be_active.v.01.move')\", 3), (\"Lemma('move.v.11.move')\", 2), (\"Lemma('act.v.01.move')\", 1), (\"Lemma('move.v.07.move')\", 1)])\n",
      "collecting tokens for  desk\n",
      "indices:    {17411, 36741, 36743, 34056, 31754, 28427, 12812, 28429, 24719, 15759, 8338, 12563, 7446, 36631, 24217, 35739, 34209, 7458, 35749, 17585, 8753, 12342, 17597, 9149, 17599, 34111, 9151, 19918, 16590, 16591, 17234, 19934, 23778, 17639, 33256, 35945, 18154, 33258, 22504, 18151, 17646, 36591, 17648, 21490, 17526}\n",
      "dict_items([(\"Lemma('desk.n.01.desk')\", 23)])\n",
      "collecting tokens for  touching\n",
      "indices:    {13568, 7458, 9315, 13885, 26247, 36205, 30253, 11119, 8695, 14397, 36318}\n",
      "dict_items([(\"Lemma('touch.v.01.touch')\", 4), (\"Lemma('touch.v.02.touch')\", 1), (\"Lemma('touch.v.08.touch')\", 2), (\"Lemma('affecting.s.01.touching')\", 2)])\n",
      "collecting tokens for  patrons\n",
      "indices:    {13026, 5895, 9963, 29164, 26961, 23537, 23508, 22103, 26911}\n",
      "dict_items([(\"Lemma('patron.n.01.patron')\", 3)])\n",
      "collecting tokens for  shade\n",
      "indices:    {31466, 13587, 30189, 30182}\n",
      "dict_items([(\"Lemma('shadow.v.02.shade')\", 1), (\"Lemma('shade.n.01.shade')\", 1)])\n",
      "collecting tokens for  boulder\n",
      "indices:    {15312}\n",
      "dict_items([])\n",
      "collecting tokens for  inevitable\n",
      "indices:    {32864, 2438, 2439, 11976, 998, 1513, 30890, 10156, 26381, 28462, 24015, 11154, 22584, 10202, 19420, 25758}\n",
      "dict_items([(\"Lemma('inevitable.a.01.inevitable')\", 5), (\"Lemma('inevitable.s.02.inevitable')\", 3), (\"Lemma('inevitable.n.01.inevitable')\", 1)])\n",
      "collecting tokens for  dominant\n",
      "indices:    {16001, 16454, 2759, 16010, 15979, 2667, 15985, 15992, 4634, 12924, 15964}\n",
      "dict_items([(\"Lemma('dominant.a.01.dominant')\", 11)])\n",
      "collecting tokens for  frankly\n",
      "indices:    {2530, 8411, 30670, 1400, 27259}\n",
      "dict_items([(\"Lemma('honestly.r.01.frankly')\", 3)])\n",
      "collecting tokens for  battle\n",
      "indices:    {24475, 12805, 13862, 23979, 7915, 26315, 20654, 20653, 22896, 20627, 12891, 14236, 20605}\n",
      "dict_items([(\"Lemma('battle.v.01.battle')\", 1), (\"Lemma('battle.n.01.battle')\", 2), (\"Lemma('struggle.n.01.battle')\", 1)])\n",
      "collecting tokens for  relevant\n",
      "indices:    {27885}\n",
      "dict_items([])\n",
      "collecting tokens for  data\n",
      "indices:    {14849, 3329, 3332, 33028, 5510, 3335, 3338, 3211, 14735, 3731, 3862, 5528, 5530, 2972, 4010, 15020, 3117, 27180, 3887, 25400, 33088, 3909, 15686, 15696, 3026, 13655, 27992, 14811, 3684, 17641, 13674, 3692, 14830, 3697, 3702, 3706, 14844, 3071}\n",
      "dict_items([(\"Lemma('data.n.01.data')\", 26), (\"Lemma('datum.n.01.datum')\", 2)])\n",
      "collecting tokens for  english\n",
      "indices:    {1436}\n",
      "dict_items([(\"Lemma('english.a.01.English')\", 1)])\n",
      "collecting tokens for  sovereignty\n",
      "indices:    {25857, 31237, 32008, 31240, 31242, 31243, 23948, 31245, 31244, 16399, 31248, 31249, 32016, 32019, 32146, 31958, 25819, 31963, 31966, 25828, 27109, 33138, 31220, 31989, 31997, 31999}\n",
      "dict_items([(\"Lemma('sovereignty.n.01.sovereignty')\", 1)])\n",
      "collecting tokens for  i.\n",
      "indices:    {21643}\n",
      "dict_items([])\n",
      "collecting tokens for  internal\n",
      "indices:    {15591}\n",
      "dict_items([])\n",
      "collecting tokens for  commands\n",
      "indices:    {31727, 27407, 14036, 14040, 26015}\n",
      "dict_items([(\"Lemma('command.n.01.command')\", 2), (\"Lemma('command.v.02.command')\", 1), (\"Lemma('command.v.03.command')\", 1)])\n",
      "collecting tokens for  listener\n",
      "indices:    {26753, 26723, 26725, 1807, 1811, 26963, 27158, 32057, 1788, 26719}\n",
      "dict_items([(\"Lemma('hearer.n.01.listener')\", 3)])\n",
      "collecting tokens for  revolution\n",
      "indices:    {12992}\n",
      "dict_items([(\"Lemma('revolution.n.02.revolution')\", 1)])\n",
      "collecting tokens for  duties\n",
      "indices:    {31170, 21090, 31619, 32311, 12036, 32458, 24171, 32495, 21360, 9363, 9204, 15317, 17365, 27607, 33013, 17628, 24157, 28093}\n",
      "dict_items([(\"Lemma('duty.n.01.duty')\", 3), (\"Lemma('duty.n.02.duty')\", 3)])\n",
      "collecting tokens for  perform\n",
      "indices:    {769, 22792, 19357, 26654, 12577, 31271, 4649, 4651, 27439, 26415, 27316, 1594, 2618, 15549, 28484, 31947, 20687, 31188, 24157, 28524, 20333, 31853, 28149, 26493}\n",
      "dict_items([(\"Lemma('perform.v.02.perform')\", 9), (\"Lemma('perform.v.01.perform')\", 8), (\"Lemma('perform.v.03.perform')\", 5), (\"Lemma('do.v.03.perform')\", 2)])\n",
      "collecting tokens for  flame\n",
      "indices:    {26984, 8426, 35467, 36205, 19789, 35423, 15198, 15199}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('fire.n.03.flame')\", 3)])\n",
      "collecting tokens for  sequence\n",
      "indices:    {15877, 2437, 2439, 2445, 31891, 31903, 16034, 16802, 5412, 4534, 32182, 3898, 31937, 31944, 15945, 3915, 15439, 31952, 2138, 29916, 11359, 13671, 11509}\n",
      "dict_items([(\"Lemma('sequence.n.02.sequence')\", 3), (\"Lemma('sequence.n.01.sequence')\", 9), (\"Lemma('sequence.n.03.sequence')\", 2), (\"Lemma('succession.n.03.sequence')\", 2)])\n",
      "collecting tokens for  begins\n",
      "indices:    {27797, 11286, 27801, 27035, 26527, 12065, 26531, 31914, 15412, 26679, 24248, 26815, 27585, 22341, 10826, 3915, 2686, 12241, 11986, 26963, 17237, 24406, 26204, 24797, 2398, 24419, 15460, 13925, 30438, 13930, 1515, 21746, 20596, 29429, 31606, 12790, 31867, 29310}\n",
      "dict_items([(\"Lemma('begin.v.02.begin')\", 14), (\"Lemma('get_down.v.07.begin')\", 21), (\"Lemma('begin.v.03.begin')\", 2)])\n",
      "collecting tokens for  earliest\n",
      "indices:    {3552, 27586, 27522, 11079, 3915, 34283, 27533, 28400, 4977, 30802, 20305, 9331, 11829, 14418, 30233, 14395}\n",
      "dict_items([(\"Lemma('early.a.01.early')\", 5), (\"Lemma('earlier.s.01.earliest')\", 2), (\"Lemma('soonest.r.01.earliest')\", 1)])\n",
      "collecting tokens for  statewide\n",
      "indices:    {24610, 32519, 24586, 32458, 32400, 32657, 24594, 21653, 20798, 32511}\n",
      "dict_items([])\n",
      "collecting tokens for  assessing\n",
      "indices:    {32418, 5225, 32397, 32398, 32399, 32400, 3919}\n",
      "dict_items([(\"Lemma('measure.v.04.assess')\", 4)])\n",
      "collecting tokens for  unit\n",
      "indices:    {4481, 31878, 12815, 5489, 33491, 339, 26742, 2326, 31870}\n",
      "dict_items([(\"Lemma('unit_of_measurement.n.01.unit')\", 1), (\"Lemma('unit.n.03.unit')\", 2), (\"Lemma('unit.n.02.unit')\", 1), (\"Lemma('unit.n.04.unit')\", 1)])\n",
      "collecting tokens for  eliminate\n",
      "indices:    {2593, 5509, 24168, 28489, 15242, 32625, 20626, 15730, 20, 25302, 22807, 15511, 20729, 3484, 11293}\n",
      "dict_items([(\"Lemma('obviate.v.01.eliminate')\", 2), (\"Lemma('extinguish.v.04.eliminate')\", 12), (\"Lemma('eliminate.v.03.eliminate')\", 1)])\n",
      "collecting tokens for  inherent\n",
      "indices:    {4738, 3394, 27558, 27272, 15850, 21899, 27532, 5004, 559, 32400, 32017, 32433, 12918, 16281, 32574}\n",
      "dict_items([(\"Lemma('built-in.s.01.inherent')\", 7)])\n",
      "collecting tokens for  feet\n",
      "indices:    {7168, 7169, 36358, 29704, 3593, 29204, 18453, 33817, 25116, 25119, 18464, 18467, 29225, 18484, 1079, 1592, 1591, 36922, 33848, 31293, 29758, 36414, 17987, 12890, 9311, 31328, 7264, 18529, 611, 19557, 36965, 36966, 14950, 35434, 3694, 35438, 3695, 31346, 3699, 12404, 30326, 10359, 7805, 7808, 12423, 12424, 18570, 3725, 34445, 34957, 3728, 34961, 34960, 21647, 34446, 29328, 3727, 10391, 10905, 30363, 33436, 3744, 3747, 3748, 17571, 19622, 3751, 3752, 31397, 10924, 684, 31407, 3763, 3764, 32443, 12476, 36030, 6335, 29376, 6337, 194, 24262, 206, 22227, 21724, 12509, 21725, 36064, 24805, 29930, 6379, 17132, 29932, 6382, 31470, 35052, 34036, 29942, 7416, 6907, 6397, 7422, 32513, 18177, 22274, 35074, 35591, 1800, 29961, 20748, 36114, 34579, 11029, 34069, 13591, 18203, 18715, 28955, 18718, 34080, 24353, 28963, 15140, 18727, 13608, 28969, 24362, 27945, 27948, 33581, 27949, 18215, 15155, 9013, 34102, 27957, 30010, 5949, 13123, 6984, 19273, 30539, 2380, 11086, 851, 19805, 30046, 7009, 30563, 1891, 34665, 34154, 34669, 28527, 28528, 36726, 28025, 19835, 30590, 34175, 34176, 7552, 29690, 29064, 27018, 22922, 27019, 11150, 8606, 12706, 23465, 12718, 29105, 12724, 27060, 1974, 12728, 12730, 5053, 1984, 4038, 7112, 457, 35276, 12749, 22990, 1999, 35791, 12748, 12754, 17880, 2008, 22494, 20450, 12773, 36327, 5097, 9714, 23032, 33786}\n",
      "dict_items([(\"Lemma('foot.n.01.foot')\", 26), (\"Lemma('foot.n.02.foot')\", 26), (\"Lemma('animal_foot.n.01.foot')\", 4), (\"Lemma('foundation.n.03.foot')\", 1), (\"Lemma('foot.n.06.foot')\", 1)])\n",
      "collecting tokens for  pour\n",
      "indices:    {23473, 33044, 27479, 16632, 28921, 12730, 33051, 7935}\n",
      "dict_items([(\"Lemma('pour.v.02.pour')\", 1), (\"Lemma('pour.v.05.pour')\", 1), (\"Lemma('pour.v.01.pour')\", 1), (\"Lemma('pour.v.04.pour')\", 1)])\n",
      "collecting tokens for  v\n",
      "indices:    {2919}\n",
      "dict_items([(\"Lemma('volt.n.01.V')\", 1)])\n",
      "collecting tokens for  shaped\n",
      "indices:    {484, 15109, 26790, 4937, 11243, 28939, 11244, 12730, 32272, 1490, 9786, 1690, 31482, 27134}\n",
      "dict_items([(\"Lemma('shaped.s.01.shaped')\", 4), (\"Lemma('shape.v.02.shape')\", 4), (\"Lemma('shape.v.03.shape')\", 1), (\"Lemma('determine.v.02.shape')\", 2)])\n",
      "collecting tokens for  harbor\n",
      "indices:    {19395, 27126}\n",
      "dict_items([(\"Lemma('seaport.n.01.harbor')\", 1)])\n",
      "collecting tokens for  proportions\n",
      "indices:    {15650, 37093, 33127, 14601, 27723, 34700, 14894, 30513, 3698, 33075, 32214, 30232, 12730}\n",
      "dict_items([(\"Lemma('proportion.n.01.proportion')\", 3), (\"Lemma('proportion.n.02.proportion')\", 2)])\n",
      "collecting tokens for  answers\n",
      "indices:    {27531, 6674, 34343, 31272, 15787, 23596, 1838, 26670, 15664, 24499, 1206, 1208, 8251, 15421, 2367, 4932, 27849, 31946, 31310, 15313, 27479, 28894, 7521, 17261, 14327, 13816}\n",
      "dict_items([(\"Lemma('answer.n.01.answer')\", 7), (\"Lemma('answer.n.03.answer')\", 2), (\"Lemma('answer.v.01.answer')\", 3), (\"Lemma('answer.v.03.answer')\", 1), (\"Lemma('solution.n.02.answer')\", 4)])\n",
      "collecting tokens for  manpower\n",
      "indices:    {25530, 31203, 11623, 32903, 16307, 11704, 9882, 16255}\n",
      "dict_items([(\"Lemma('work_force.n.01.manpower')\", 4)])\n",
      "collecting tokens for  columbia\n",
      "indices:    {25362}\n",
      "dict_items([])\n",
      "collecting tokens for  estimated\n",
      "indices:    {22017, 21766, 15500, 21775, 29947, 21778, 12181, 3991, 14999, 27417, 12186, 18205, 3365, 30630, 3367, 14245, 21163, 32434, 18228, 3127, 15552, 26818, 2243, 25415, 24138, 25038, 15571, 15572, 20181, 214, 3671, 14811, 28639, 12646, 26726, 15592, 15594, 111, 21616, 32754, 21235, 21876, 15477, 2936, 15483, 15485}\n",
      "dict_items([(\"Lemma('estimate.v.01.estimate')\", 21), (\"Lemma('calculate.v.02.estimate')\", 6)])\n",
      "collecting tokens for  formally\n",
      "indices:    {22307, 22502, 7374, 16410, 13244, 20383}\n",
      "dict_items([(\"Lemma('formally.r.02.formally')\", 1), (\"Lemma('formally.r.01.formally')\", 2)])\n",
      "collecting tokens for  wake\n",
      "indices:    {27170, 23811, 35396, 12549, 20038, 16071, 11112, 1257, 2182, 5160, 16588, 6352, 8949, 9015, 19705}\n",
      "dict_items([(\"Lemma('wake_up.v.02.wake')\", 2), (\"Lemma('aftermath.n.01.wake')\", 4), (\"Lemma('wake.v.01.wake')\", 2)])\n",
      "collecting tokens for  nine\n",
      "indices:    {20610, 16530, 32658, 17684, 23064, 21915, 430, 32690, 29108, 437, 21181, 23876, 13124, 25679, 20307, 31190, 3544, 20186, 32731, 8802, 32242}\n",
      "dict_items([(\"Lemma('nine.s.01.nine')\", 6), (\"Lemma('nine.n.01.nine')\", 1)])\n",
      "collecting tokens for  paused\n",
      "indices:    {34054, 6919, 34055, 36886, 17561, 2203, 35100, 17311, 33569, 18595, 17316, 19371, 18348, 8631, 17483, 16592, 18522, 19044, 16746, 22516, 36855, 33786}\n",
      "dict_items([(\"Lemma('pause.v.02.pause')\", 9), (\"Lemma('hesitate.v.02.pause')\", 13)])\n",
      "collecting tokens for  ship\n",
      "indices:    {32256, 30339, 34569, 34571, 12428, 30475, 5904, 26514, 7958, 21275, 12445, 21281, 10151, 36525, 30390, 19388, 12355, 34755, 12359, 34759, 19402, 10187, 12362, 12371, 10712, 3431, 10092, 34671, 30575, 12400, 34677, 12405}\n",
      "dict_items([(\"Lemma('ship.n.01.ship')\", 16), (\"Lemma('transport.v.04.ship')\", 2)])\n",
      "collecting tokens for  compare\n",
      "indices:    {11072, 3297, 2565, 31367, 4011, 1837, 32302, 32557, 30256, 2032, 32685, 723, 16144, 11221, 11483}\n",
      "dict_items([(\"Lemma('compare.v.01.compare')\", 9), (\"Lemma('compare.v.02.compare')\", 4), (\"Lemma('compare.v.03.compare')\", 2)])\n",
      "collecting tokens for  nineteenth-century\n",
      "indices:    {26624, 28000, 31242, 31179, 22796, 28019, 22804, 28056}\n",
      "dict_items([])\n",
      "collecting tokens for  congressman\n",
      "indices:    {20627}\n",
      "dict_items([])\n",
      "collecting tokens for  martin\n",
      "indices:    {20771}\n",
      "dict_items([])\n",
      "collecting tokens for  sept.\n",
      "indices:    {21784}\n",
      "dict_items([])\n",
      "collecting tokens for  anti-trust\n",
      "indices:    {22785, 22786, 22756, 22770, 25042, 22805, 22775, 22776, 16346, 22807, 22782}\n",
      "dict_items([(\"Lemma('antimonopoly.s.01.antitrust')\", 1)])\n",
      "collecting tokens for  legislation\n",
      "indices:    {20385, 25124, 169, 16463, 25043, 31190, 27898}\n",
      "dict_items([(\"Lemma('legislation.n.01.legislation')\", 2)])\n",
      "collecting tokens for  wages\n",
      "indices:    {6146, 16386, 22791, 22803, 22804, 15638, 15640, 22809, 15642, 23451, 21162, 6141, 12089, 16322, 31811, 15557, 23493, 15559, 16328, 1489, 11735, 16348, 22748, 1512, 28415, 16379, 21629, 6143}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('wage.n.01.wage')\", 15), (\"Lemma('wages.n.01.wages')\", 2)])\n",
      "collecting tokens for  preserve\n",
      "indices:    {5286, 10222, 27281, 37170, 1301, 31705}\n",
      "dict_items([(\"Lemma('conserve.v.02.preserve')\", 3), (\"Lemma('save.v.02.preserve')\", 1), (\"Lemma('continue.v.03.preserve')\", 1)])\n",
      "collecting tokens for  employer\n",
      "indices:    {25347, 15614, 10695, 31820, 25806, 20177, 22804, 13240, 11993, 16282, 7198}\n",
      "dict_items([(\"Lemma('employer.n.01.employer')\", 6)])\n",
      "collecting tokens for  employment\n",
      "indices:    {11265, 21893, 16272, 36123, 16286, 16288, 15784, 169, 171, 16300, 174, 16316, 8258, 13253, 20441, 13278, 31199, 31201, 11748, 16230, 6118, 12145, 13302, 26743, 13304, 16374, 21883, 33020, 13305}\n",
      "dict_items([(\"Lemma('employment.n.02.employment')\", 8), (\"Lemma('employment.n.03.employment')\", 6), (\"Lemma('employment.n.01.employment')\", 6), (\"Lemma('use.n.01.employment')\", 1)])\n",
      "collecting tokens for  requires\n",
      "indices:    {15872, 3074, 15874, 2308, 31368, 1931, 30989, 13328, 19350, 3872, 30753, 32546, 11059, 24756, 13621, 1720, 29240, 32826, 25402, 28609, 24004, 34379, 1361, 27602, 24148, 727, 5212, 30046, 30821, 23525, 16368, 1907, 11640, 30075, 11644, 29823}\n",
      "dict_items([(\"Lemma('necessitate.v.01.require')\", 26), (\"Lemma('command.v.02.require')\", 2), (\"Lemma('want.v.02.require')\", 2), (\"Lemma('ask.v.04.require')\", 3)])\n",
      "collecting tokens for  lowest\n",
      "indices:    {21988, 32357, 18319, 30735, 30226, 11059, 23096, 15705, 34110}\n",
      "dict_items([(\"Lemma('low.a.05.low')\", 1), (\"Lemma('low.a.01.low')\", 2)])\n",
      "collecting tokens for  barely\n",
      "indices:    {22274, 10761, 16651, 9868, 22924, 271, 36756, 8861, 31390, 31391, 33822, 32173, 11059, 20918, 22202, 8132, 8900, 31560, 8527, 5860, 34151, 27752}\n",
      "dict_items([(\"Lemma('barely.r.01.barely')\", 8), (\"Lemma('scantily.r.01.barely')\", 2)])\n",
      "collecting tokens for  n\n",
      "indices:    {4336}\n",
      "dict_items([])\n",
      "collecting tokens for  seconds\n",
      "indices:    {36995, 18452, 17820, 23090, 11059, 34611, 1971, 34100, 11064, 18750, 18367, 1987, 18761, 15831, 33768, 17770, 34163, 2164, 31475, 6911}\n",
      "dict_items([(\"Lemma('second.n.01.second')\", 11), (\"Lemma('moment.n.02.second')\", 2)])\n",
      "collecting tokens for  absurd\n",
      "indices:    {12409, 2308, 28005, 11059, 1304, 6329, 31739, 8380}\n",
      "dict_items([(\"Lemma('absurd.s.01.absurd')\", 5)])\n",
      "collecting tokens for  credit\n",
      "indices:    {33121, 28675, 2761, 14861, 1233, 2770, 11801, 21787, 24028}\n",
      "dict_items([(\"Lemma('recognition.n.03.credit')\", 2), (\"Lemma('credit.n.05.credit')\", 1), (\"Lemma('credit.n.03.credit')\", 1)])\n",
      "collecting tokens for  comments\n",
      "indices:    {24852, 16150, 14455, 1430, 21533, 12066, 12582, 12590, 31667, 15800, 12605, 21310, 26700, 33105, 24531, 20069, 26728, 33264, 31090, 14710, 14711, 29048, 11514}\n",
      "dict_items([(\"Lemma('remark.n.01.comment')\", 6), (\"Lemma('comment.n.02.comment')\", 5), (\"Lemma('comment.v.01.comment')\", 1)])\n",
      "collecting tokens for  citizens\n",
      "indices:    {32640, 32648, 169, 20363, 4813, 7822, 22799, 28465, 4754, 23956, 12472, 31993, 5275, 25022}\n",
      "dict_items([(\"Lemma('citizen.n.01.citizen')\", 5)])\n",
      "collecting tokens for  puerto\n",
      "indices:    {15022}\n",
      "dict_items([])\n",
      "collecting tokens for  rico\n",
      "indices:    {15022}\n",
      "dict_items([])\n",
      "collecting tokens for  allowed\n",
      "indices:    {1793, 14210, 13448, 15625, 15631, 14864, 2962, 1048, 36248, 30491, 15260, 23325, 1697, 32290, 5675, 4140, 47, 32303, 3251, 24757, 8247, 23483, 7612, 1085, 3260, 192, 3523, 3525, 4936, 30026, 5068, 29260, 29262, 5328, 3537, 12497, 3286, 2390, 8662, 15577, 15579, 15580, 27999, 4962, 25956, 14697, 25707, 22635, 15599, 22002, 20341, 28277, 33141, 28280, 20345, 25338, 30075, 2300}\n",
      "dict_items([(\"Lemma('allow.v.04.allow')\", 6), (\"Lemma('allow.v.03.allow')\", 8), (\"Lemma('let.v.01.allow')\", 23), (\"Lemma('permit.v.01.allow')\", 16), (\"Lemma('allow.v.06.allow')\", 1), (\"Lemma('leave.v.06.allow')\", 1)])\n",
      "collecting tokens for  extension\n",
      "indices:    {16270, 15568, 177, 12306, 15581, 16317}\n",
      "dict_items([(\"Lemma('extension.n.02.extension')\", 3), (\"Lemma('extension.n.01.extension')\", 2), (\"Lemma('propagation.n.01.extension')\", 1)])\n",
      "collecting tokens for  filing\n",
      "indices:    {15553, 21350, 2792, 15417, 15547, 15639, 20685, 15569, 22036, 15543, 15577, 15578, 15579, 15580, 15549, 15583}\n",
      "dict_items([(\"Lemma('filing.n.01.filing')\", 3), (\"Lemma('file.v.01.file')\", 13)])\n",
      "collecting tokens for  alternative\n",
      "indices:    {15493, 5255, 27791, 29851, 27804, 27805, 21531, 13986, 11683, 27812, 46, 20663, 1335, 1338, 15426, 14917, 20293, 1351, 1354, 1356, 1362, 14805, 23665, 15090, 12147}\n",
      "dict_items([(\"Lemma('option.n.02.alternative')\", 10), (\"Lemma('alternate.s.02.alternative')\", 4), (\"Lemma('alternative.s.02.alternative')\", 1)])\n",
      "collecting tokens for  typically\n",
      "indices:    {2252}\n",
      "dict_items([(\"Lemma('typically.r.01.typically')\", 1)])\n",
      "collecting tokens for  bultmann\n",
      "indices:    {1308}\n",
      "dict_items([(\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  ralph\n",
      "indices:    {21570}\n",
      "dict_items([])\n",
      "collecting tokens for  h.\n",
      "indices:    {21886}\n",
      "dict_items([])\n",
      "collecting tokens for  bowl\n",
      "indices:    {8065, 29586, 262, 31647}\n",
      "dict_items([])\n",
      "collecting tokens for  coach\n",
      "indices:    {635, 629, 334}\n",
      "dict_items([(\"Lemma('coach.n.01.coach')\", 2)])\n",
      "collecting tokens for  talking\n",
      "indices:    {13698, 16516, 23050, 27787, 11916, 33421, 7693, 27786, 5905, 12690, 36626, 25495, 10909, 23327, 11168, 13730, 20003, 30756, 18473, 19499, 20908, 1324, 2606, 7339, 23345, 36146, 23350, 9270, 34618, 9542, 12360, 34897, 18387, 9308, 16607, 20837, 25829, 7653, 16761, 18410, 2027, 25453, 18032, 36592, 31090, 36853, 24823, 28153, 29946, 24062}\n",
      "dict_items([(\"Lemma('talk.v.02.talk')\", 5), (\"Lemma('talk.v.01.talk')\", 21), (\"Lemma('spill.v.05.talk')\", 1), (\"Lemma('talk.n.01.talk')\", 1), (\"Lemma('speak.v.03.talk')\", 1)])\n",
      "collecting tokens for  furnished\n",
      "indices:    {15360, 15296, 33954, 15330, 20964, 12645, 15658, 15659, 15370, 14542, 15342, 19517, 14004, 17407, 29405, 2175}\n",
      "dict_items([(\"Lemma('furnished.a.01.furnished')\", 1), (\"Lemma('furnish.v.02.furnish')\", 1), (\"Lemma('supply.v.01.furnish')\", 12)])\n",
      "collecting tokens for  guests\n",
      "indices:    {8272, 27665, 21075, 21045, 22170, 14014}\n",
      "dict_items([(\"Lemma('guest.n.01.guest')\", 2)])\n",
      "collecting tokens for  oral\n",
      "indices:    {32696, 32992, 2326}\n",
      "dict_items([(\"Lemma('oral.s.01.oral')\", 1)])\n",
      "collecting tokens for  accurately\n",
      "indices:    {26560, 15844, 28934, 11721, 32362, 28939, 31116, 11116, 28457, 31145, 2128, 12625, 1716, 823, 32857, 15391, 15421, 31071}\n",
      "dict_items([(\"Lemma('accurately.r.01.accurately')\", 7), (\"Lemma('accurately.r.02.accurately')\", 2)])\n",
      "collecting tokens for  frequently\n",
      "indices:    {14709, 24578, 12268, 13973}\n",
      "dict_items([(\"Lemma('frequently.r.01.frequently')\", 3)])\n",
      "collecting tokens for  shapes\n",
      "indices:    {7441, 5402, 5403, 5020, 5404, 10653, 18850, 13348, 24624, 31923, 5828, 9797, 5830, 4939, 5846, 4956, 27869, 18784, 3050}\n",
      "dict_items([(\"Lemma('determine.v.02.shape')\", 1), (\"Lemma('shape.n.02.shape')\", 2), (\"Lemma('human_body.n.01.shape')\", 2), (\"Lemma('shape.n.01.shape')\", 9), (\"Lemma('shape.v.02.shape')\", 1), (\"Lemma('form.n.07.shape')\", 2)])\n",
      "collecting tokens for  profits\n",
      "indices:    {15264, 25347, 11659, 22035, 21461, 12695, 12696, 13753, 24125}\n",
      "dict_items([(\"Lemma('net_income.n.01.profits')\", 5)])\n",
      "collecting tokens for  slave\n",
      "indices:    {32001, 11235, 32005, 5287, 13689, 12618, 13753, 6287, 23571, 7765, 13749, 34905, 13756, 26430}\n",
      "dict_items([(\"Lemma('slave.n.01.slave')\", 7)])\n",
      "collecting tokens for  owners\n",
      "indices:    {6029, 21646, 17549, 21648, 5140, 5143, 2720, 12578, 27049, 21809, 25010, 2750, 575, 28611, 30025, 21450, 21451, 21462, 20716, 26748}\n",
      "dict_items([(\"Lemma('owner.n.01.owner')\", 5), (\"Lemma('owner.n.02.owner')\", 2)])\n",
      "collecting tokens for  fed\n",
      "indices:    {34434, 28170, 11531, 34833, 33433, 29216, 12832, 11558, 2857, 3626, 11567, 10546, 13116, 11581, 3644, 19398, 12617, 25548, 29905, 11605, 35543, 36069, 10470, 14446, 8563, 29178, 11519}\n",
      "dict_items([(\"Lemma('feed.v.04.feed')\", 2), (\"Lemma('feed.v.01.feed')\", 12), (\"Lemma('feed.v.03.feed')\", 3), (\"Lemma('feed.v.02.feed')\", 4), (\"Lemma('feed.v.05.feed')\", 1), (\"Lemma('feed.v.06.feed')\", 1)])\n",
      "collecting tokens for  forth\n",
      "indices:    {5256, 36746, 30732, 5005, 21006, 36753, 12562, 12434, 27797, 32661, 36764, 24353, 13218, 28323, 32292, 15014, 14586, 19756, 12211, 1331, 6838, 36151, 13753, 36153, 15035, 21447, 17352, 18505, 1095, 27979, 22604, 6605, 32078, 23375, 15056, 31440, 14297, 2779, 37086, 17760, 7786, 32875, 9840, 16370, 27379, 7412, 31989, 30585, 25082}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('away.r.01.forth')\", 2)])\n",
      "collecting tokens for  related\n",
      "indices:    {4619, 16430}\n",
      "dict_items([(\"Lemma('related.a.01.related')\", 1)])\n",
      "collecting tokens for  persistent\n",
      "indices:    {14401, 15846, 32903, 2634, 1163, 32844, 14607, 16271, 22387, 2516, 4699, 13566}\n",
      "dict_items([(\"Lemma('persistent.s.01.persistent')\", 8), (\"Lemma('haunting.s.01.persistent')\", 1)])\n",
      "collecting tokens for  desire\n",
      "indices:    {24838, 9991, 12042, 1930, 35213, 16014, 16271, 23569, 28178, 25110, 24731, 30876, 27554, 32039, 6824, 8237, 35759, 30256, 14002, 27572, 25021, 23615, 20417, 5699, 31814, 32199, 27213, 591, 12242, 7892, 1493, 5336, 26203, 36956, 30813, 24926, 2783, 13663, 13281, 5473, 9186, 5860, 30821, 27879, 7528, 8424, 7913, 23787, 26094, 14197, 21237, 759, 25976, 1529}\n",
      "dict_items([(\"Lemma('desire.v.01.desire')\", 8), (\"Lemma('desire.n.02.desire')\", 7), (\"Lemma('desire.n.01.desire')\", 14), (\"Lemma('desire.n.03.desire')\", 2)])\n",
      "collecting tokens for  attract\n",
      "indices:    {24896, 1857, 6306, 25059, 11710, 34437, 26854, 30080, 26829, 16271, 21585, 1844, 32149, 17142, 24058, 22750, 24894}\n",
      "dict_items([(\"Lemma('attract.v.01.attract')\", 10)])\n",
      "collecting tokens for  catch\n",
      "indices:    {17927, 34447, 13970, 9241, 1694, 1568, 1185, 35237, 35110, 14118, 34230, 18870, 10935, 29114, 3902, 36030, 18110, 25793, 34121, 9418, 13903, 2000, 5073, 29268, 13908, 35546, 33370, 16093, 36071, 13550, 12399, 26609, 34430}\n",
      "dict_items([(\"Lemma('get.v.11.catch')\", 3), (\"Lemma('catch.v.02.catch')\", 2), (\"Lemma('catch.v.09.catch')\", 2), (\"Lemma('catch.v.04.catch')\", 1), (\"Lemma('catch.v.01.catch')\", 4), (\"Lemma('catch.v.12.catch')\", 1), (\"Lemma('catch.v.18.catch')\", 1), (\"Lemma('overtake.v.01.catch')\", 1), (\"Lemma('catch.v.07.catch')\", 1), (\"Lemma('catch.n.01.catch')\", 1), (\"Lemma('catch.v.10.catch')\", 1), (\"Lemma('watch.v.03.catch')\", 1)])\n",
      "collecting tokens for  returning\n",
      "indices:    {11108, 36196}\n",
      "dict_items([(\"Lemma('return.v.01.return')\", 2)])\n",
      "collecting tokens for  lifted\n",
      "indices:    {18439, 8846, 13594, 12060, 8606, 34986, 35372, 34353, 26548, 24373, 7096, 35384, 36411, 36030, 1471, 29120, 8512, 19264, 23108, 10950, 24265, 8907, 18126, 6610, 18389, 12256, 29175, 9702, 18666, 18154, 35182, 34290, 35830, 11127, 33663}\n",
      "dict_items([(\"Lemma('raise.v.02.lift')\", 17), (\"Lemma('lift.v.02.lift')\", 6), (\"Lemma('revoke.v.02.lift')\", 2), (\"Lemma('lift.v.03.lift')\", 1), (\"Lemma('rise.v.01.lift')\", 1), (\"Lemma('raise.v.25.lift')\", 1), (\"Lemma('lift.v.05.lift')\", 2), (\"Lemma('pilfer.v.01.lift')\", 1)])\n",
      "collecting tokens for  herself\n",
      "indices:    {36872, 36874, 9232, 3612, 9246, 18974, 36383, 8740, 8765, 36418, 9284, 5715, 25691, 7263, 14434, 7269, 7276, 30840, 14458, 31867, 36988, 36863, 36990, 14464, 36488, 14480, 36498, 10899, 10900, 16555, 13487, 9398, 10941, 36030, 11979, 22235, 19679, 36071, 8433, 19699, 8440, 16637, 26371, 11014, 10505, 26901, 16672, 17196, 28992, 10580, 16746, 13163, 10616, 27029, 34198, 36251, 8094, 36263, 33708, 34733, 36786, 34749, 36287, 1479, 34760, 36297, 33232, 36310, 15830, 34776, 17881, 9181, 9182, 9183, 15840, 16864, 33250, 36835, 9193, 16884, 9206, 7671, 7670, 35325, 17919}\n",
      "dict_items([])\n",
      "collecting tokens for  happy\n",
      "indices:    {9729, 1521, 25362, 16862}\n",
      "dict_items([(\"Lemma('happy.a.01.happy')\", 1)])\n",
      "collecting tokens for  convertible\n",
      "indices:    {8774, 21930, 21931, 21932, 23026, 36888, 8734}\n",
      "dict_items([(\"Lemma('convertible.n.01.convertible')\", 2)])\n",
      "collecting tokens for  thinking\n",
      "indices:    {16513, 25475, 27525, 13452, 10764, 36113, 27924, 35222, 6167, 32406, 21402, 36254, 34335, 16801, 11686, 22951, 22952, 5037, 17071, 2481, 7615, 15423, 15427, 17988, 11004, 12614, 35015, 16590, 7886, 34386, 33364, 16854, 25816, 28130, 26086, 35309, 10735, 33136, 34545, 14576, 4723, 27257, 17402, 10236}\n",
      "dict_items([(\"Lemma('thinking.n.01.thinking')\", 8), (\"Lemma('think.v.03.think')\", 8), (\"Lemma('think.v.02.think')\", 5), (\"Lemma('remember.v.02.think_of')\", 1), (\"Lemma('think.v.05.think')\", 1)])\n",
      "collecting tokens for  stage\n",
      "indices:    {20619, 26251, 26384, 22161, 3732, 5013, 4630, 1812, 3610, 2458, 11035, 11036, 5151, 31912, 22700, 1072, 25651, 20532, 31032, 29501, 24902, 3911, 1224, 25547, 22092, 974, 26959, 3926, 30295, 11492, 3692, 6255, 26867, 6263, 9850, 380, 20734}\n",
      "dict_items([(\"Lemma('phase.n.01.stage')\", 6), (\"Lemma('stage.n.04.stage')\", 2), (\"Lemma('degree.n.02.stage')\", 4), (\"Lemma('stage.v.02.stage')\", 1), (\"Lemma('stagecoach.n.01.stage')\", 1), (\"Lemma('stage.n.03.stage')\", 5)])\n",
      "collecting tokens for  worker\n",
      "indices:    {32898, 11797, 23445, 15766, 11808, 8226, 3624, 3625, 12075, 11819, 26554, 11836, 15687, 20177, 11992, 32859, 5468, 12381, 32865, 32868, 31462, 32873, 32874, 32875, 32876, 32877, 32880, 13689}\n",
      "dict_items([(\"Lemma('worker.n.01.worker')\", 9)])\n",
      "collecting tokens for  client\n",
      "indices:    {32896, 27908, 2056, 2060, 21779, 22044, 12195, 20140, 20142, 13893, 13895, 27856, 27864, 27867, 32860, 32865, 32868, 32870, 9840, 32880, 32891}\n",
      "dict_items([(\"Lemma('client.n.01.client')\", 6)])\n",
      "collecting tokens for  uncertain\n",
      "indices:    {26689, 20518, 25736, 20617, 2602, 14156, 25582, 27792, 19378, 18067, 21970, 1268, 3350, 1044, 20633, 2173}\n",
      "dict_items([(\"Lemma('uncertain.a.02.uncertain')\", 3), (\"Lemma('uncertain.a.01.uncertain')\", 5)])\n",
      "collecting tokens for  dikkat\n",
      "indices:    {34823, 34851, 34872, 34875, 34876, 34878, 34879, 34890, 34892, 34894, 34895, 34896, 34897, 34902, 34905, 34906, 34782, 34784, 34785, 34922, 34809}\n",
      "dict_items([])\n",
      "collecting tokens for  planet\n",
      "indices:    {10178, 31235, 34564, 2812, 10152, 2826, 2828, 2796, 10094, 10157, 34800, 2799, 16814, 34551, 34488, 34905, 34522, 27836}\n",
      "dict_items([(\"Lemma('planet.n.01.planet')\", 9), (\"Lemma('satellite.n.02.planet')\", 1)])\n",
      "collecting tokens for  deduct\n",
      "indices:    {15617, 15619, 15620, 15623, 15611, 15605, 15606, 15609, 15642, 15643, 15612, 15614}\n",
      "dict_items([(\"Lemma('subtract.v.01.deduct')\", 12)])\n",
      "collecting tokens for  expenses\n",
      "indices:    {15752, 21780, 22037, 14873, 21156, 11941, 32303, 20660, 12102, 6096, 23763, 19541, 22748, 22750, 22751, 25187, 25190, 11757, 17389, 30196, 15606, 15607, 15609, 15611, 15612, 15614}\n",
      "dict_items([(\"Lemma('expense.n.01.expense')\", 13), (\"Lemma('expense.n.03.expense')\", 1)])\n",
      "collecting tokens for  meals\n",
      "indices:    {30480, 5275, 30109, 11937, 11940, 3620, 11954, 11848, 23632, 30422, 35542, 30939, 29149, 22109, 22114, 26855, 6891, 29424, 9205, 21370, 15611}\n",
      "dict_items([(\"Lemma('meal.n.01.meal')\", 9)])\n",
      "collecting tokens for  addition\n",
      "indices:    {32706, 164, 33160, 28876, 20204, 26959, 3280, 32529, 32051, 26771, 37108, 25142, 19032, 11387, 6876, 3935}\n",
      "dict_items([(\"Lemma('addition.n.02.addition')\", 1)])\n",
      "collecting tokens for  drinking\n",
      "indices:    {30480, 30052, 8191}\n",
      "dict_items([(\"Lemma('drinking.n.01.drinking')\", 1)])\n",
      "collecting tokens for  sanitation\n",
      "indices:    {24174}\n",
      "dict_items([])\n",
      "collecting tokens for  latest\n",
      "indices:    {24837, 26139, 29489, 29490, 24626, 31793, 5430, 2231, 29113, 20153, 29119, 20673, 11848, 29136, 26451, 14941, 26088, 14830, 28143, 29041}\n",
      "dict_items([(\"Lemma('up-to-the-minute.s.01.latest')\", 2)])\n",
      "collecting tokens for  bride\n",
      "indices:    {26247, 34217, 30762, 21037, 7789, 20880, 34296, 30809, 30778}\n",
      "dict_items([(\"Lemma('bride.n.01.bride')\", 1)])\n",
      "collecting tokens for  warm\n",
      "indices:    {1062, 10024, 10958, 36085, 29501}\n",
      "dict_items([(\"Lemma('warm.a.01.warm')\", 1), (\"Lemma('warm.a.02.warm')\", 1)])\n",
      "collecting tokens for  dusty\n",
      "indices:    {35970, 31497, 18857, 10478, 34191, 18900, 34871, 13113, 13561, 7452, 34911, 9151}\n",
      "dict_items([])\n",
      "collecting tokens for  ends\n",
      "indices:    {28800, 13572, 11654, 3208, 2312, 26889, 9995, 32536, 28825, 30617, 29598, 29599, 4258, 29866, 5296, 2229, 7862, 28730, 29638, 29639, 13896, 24136, 25927, 29647, 29648, 4689, 467, 4692, 28757, 4693, 4694, 4697, 29533, 7134, 4702, 16096, 13534, 7906, 30054, 10984, 21098, 4728, 11505, 13944, 12923}\n",
      "dict_items([(\"Lemma('goal.n.01.end')\", 13), (\"Lemma('end.n.01.end')\", 2), (\"Lemma('end.n.07.end')\", 2), (\"Lemma('end.n.08.end')\", 1), (\"Lemma('end.v.01.end')\", 5), (\"Lemma('end.n.09.end')\", 1), (\"Lemma('end.n.05.end')\", 1)])\n",
      "collecting tokens for  thickness\n",
      "indices:    {29568, 29729, 28930, 15075, 29574, 29608, 29547, 29740, 29713, 29554, 4146, 29619, 11384, 29593, 29598, 3263}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('thickness.n.01.thickness')\", 4)])\n",
      "collecting tokens for  30000\n",
      "indices:    {12646, 24038, 2221, 11924, 32341, 23606, 21498, 33053}\n",
      "dict_items([])\n",
      "collecting tokens for  acres\n",
      "indices:    {19490, 22115, 21372, 1001, 5417, 17165, 3672, 21500, 5502}\n",
      "dict_items([(\"Lemma('estate.n.02.acres')\", 2), (\"Lemma('acre.n.01.acre')\", 4)])\n",
      "collecting tokens for  cape\n",
      "indices:    {20150}\n",
      "dict_items([])\n",
      "collecting tokens for  resumed\n",
      "indices:    {26880, 19809, 12450, 25378, 4036, 11494, 22663, 37000, 21261, 31725, 10002, 21203, 22969}\n",
      "dict_items([(\"Lemma('resume.v.01.resume')\", 10), (\"Lemma('resume.v.03.resume')\", 2), (\"Lemma('resume.v.02.resume')\", 1)])\n",
      "collecting tokens for  believes\n",
      "indices:    {7, 20360, 22665, 21898, 20489, 27148, 30484, 2585, 24602, 30493, 25512, 31914, 28205, 21809, 26686, 30399, 26687, 26692, 1480, 13898, 20304, 28247, 27099, 20317, 7518, 27104, 2529, 1251, 10852, 28261, 10855, 27120, 27124, 32120, 25465}\n",
      "dict_items([(\"Lemma('believe.v.01.believe')\", 12), (\"Lemma('think.v.01.believe')\", 14), (\"Lemma('believe.v.04.believe')\", 2), (\"Lemma('believe.v.03.believe')\", 2)])\n",
      "collecting tokens for  greatness\n",
      "indices:    {10098}\n",
      "dict_items([])\n",
      "collecting tokens for  failure\n",
      "indices:    {33218, 27077, 12933, 20687, 28093, 24831}\n",
      "dict_items([(\"Lemma('failure.n.02.failure')\", 1)])\n",
      "collecting tokens for  hitler\n",
      "indices:    {12228}\n",
      "dict_items([(\"Lemma('hitler.n.01.Hitler')\", 1)])\n",
      "collecting tokens for  boy\n",
      "indices:    {11268, 6407, 20746, 18062, 31120, 18064, 34962, 34965, 149, 12189, 9634, 34983, 555, 30124, 14509, 12845, 3888, 17472, 13251, 30536, 35020, 10457, 21210, 10592, 13156, 17258, 8442, 17658}\n",
      "dict_items([(\"Lemma('boy.n.02.boy')\", 4), (\"Lemma('male_child.n.01.boy')\", 10), (\"Lemma('son.n.01.boy')\", 3)])\n",
      "collecting tokens for  asserted\n",
      "indices:    {4801, 15331, 31172, 25445, 2217, 15371, 31212, 31758, 31985, 4819, 32821, 21272, 13146}\n",
      "dict_items([(\"Lemma('assert.v.01.assert')\", 7), (\"Lemma('affirm.v.02.assert')\", 6)])\n",
      "collecting tokens for  jew\n",
      "indices:    {14292}\n",
      "dict_items([(\"Lemma('jew.n.01.Jew')\", 1)])\n",
      "collecting tokens for  implied\n",
      "indices:    {16453, 16039, 36457, 27351, 1324, 14060, 27315, 32948, 12951, 33209, 33213, 31967}\n",
      "dict_items([(\"Lemma('imply.v.01.imply')\", 4), (\"Lemma('imply.v.02.imply')\", 5)])\n",
      "collecting tokens for  vince\n",
      "indices:    {33663}\n",
      "dict_items([])\n",
      "collecting tokens for  dangerous\n",
      "indices:    {30339, 14917, 12237, 36814, 35951, 11983, 27185, 339, 14167, 12729, 18814}\n",
      "dict_items([(\"Lemma('dangerous.a.01.dangerous')\", 7)])\n",
      "collecting tokens for  days\n",
      "indices:    {30727, 17556, 29214, 8867, 11943, 2220, 36013, 31027, 28994, 15171, 31554, 24777, 11598, 15587, 5861, 20973, 36975, 8179, 9461}\n",
      "dict_items([(\"Lemma('day.n.02.day')\", 2), (\"Lemma('day.n.01.day')\", 8)])\n",
      "collecting tokens for  mention\n",
      "indices:    {19078, 26891, 25875, 34299, 7959, 18332, 27127, 20389, 6055, 11689, 20402, 21428, 14134, 55, 5307, 23163, 8891, 1342, 7743, 26048, 1344, 5187, 28373, 25944, 22247, 26088, 1127, 6122, 26219, 26611, 11892, 5878, 15990, 15867, 27775}\n",
      "dict_items([(\"Lemma('mention.v.01.mention')\", 10), (\"Lemma('mention.n.01.mention')\", 7), (\"Lemma('mention.v.03.mention')\", 3), (\"Lemma('citation.n.03.mention')\", 1), (\"Lemma('note.v.01.mention')\", 2)])\n",
      "collecting tokens for  liberals\n",
      "indices:    {25888, 2464, 2496, 2473, 14105, 14138, 14108}\n",
      "dict_items([(\"Lemma('liberal.n.01.liberal')\", 6)])\n",
      "collecting tokens for  promote\n",
      "indices:    {23554, 32130, 14724, 14224, 25875, 32661, 32161, 32674, 32164, 32165, 32934, 21437, 23999, 30916, 13906, 5336, 27737, 31837, 31211, 31995, 32126}\n",
      "dict_items([(\"Lemma('promote.v.01.promote')\", 20), (\"Lemma('advertise.v.02.promote')\", 1)])\n",
      "collecting tokens for  louis\n",
      "indices:    {26583}\n",
      "dict_items([])\n",
      "collecting tokens for  [\n",
      "indices:    {12546, 20228, 3078, 23046, 21259, 24973, 15374, 27407, 12560, 3087, 25875, 25852, 20885, 20883, 14616, 24994, 28194, 25890, 27813, 27814, 21287, 28202, 12587, 5296, 28209, 15284, 12597, 28214, 28215, 25016, 23095, 25914, 1466, 20922, 21309, 5309, 25405, 12609, 25794, 4930, 26052, 12612, 28230, 4550, 1479, 12614, 25034, 28237, 1486, 4559, 4561, 25811, 1493, 1494, 28247, 31831, 25817, 20950, 23259, 25947, 853, 20220, 31977, 4713, 15343, 12535, 21755, 27388, 15229, 20222}\n",
      "dict_items([])\n",
      "collecting tokens for  ]\n",
      "indices:    {12546, 20228, 3078, 23046, 21259, 24973, 15374, 27407, 12560, 3087, 25875, 25852, 20885, 20883, 14616, 24994, 28194, 25890, 27813, 27814, 21287, 28202, 12587, 5296, 28210, 15284, 12597, 28214, 28215, 25016, 23095, 25914, 1466, 20922, 21309, 5309, 25405, 12609, 25794, 4930, 26052, 12612, 28230, 4550, 1479, 12614, 25034, 28237, 1486, 4559, 4561, 25811, 1493, 1494, 28247, 31831, 25817, 853, 23259, 25947, 20220, 31977, 4713, 15343, 12535, 21755, 27388, 15229, 20222}\n",
      "dict_items([])\n",
      "collecting tokens for  analogy\n",
      "indices:    {2660, 14630, 1327, 2991, 25875, 14164, 28501, 3223, 3003, 11485}\n",
      "dict_items([(\"Lemma('analogy.n.02.analogy')\", 1), (\"Lemma('analogy.n.01.analogy')\", 1)])\n",
      "collecting tokens for  story\n",
      "indices:    {1378, 17698, 26371, 11108, 17733, 10531, 33800, 1454, 2640, 23858, 8019, 24703, 1878, 13016, 10777, 21212, 26525, 31711}\n",
      "dict_items([(\"Lemma('floor.n.02.story')\", 2), (\"Lemma('report.n.03.story')\", 1), (\"Lemma('narrative.n.01.story')\", 6), (\"Lemma('story.n.02.story')\", 2)])\n",
      "collecting tokens for  famous\n",
      "indices:    {26755, 1543, 1544, 13965, 2189, 28304, 21266, 29332, 23188, 26775, 2457, 29978, 27035, 22812, 32670, 30878, 3616, 12702, 13726, 26786, 25123, 12710, 1063, 24744, 29353, 31529, 34605, 26415, 31538, 36663, 29113, 9145, 29116, 29247, 10692, 6987, 23116, 10834, 2130, 24920, 29275, 25308, 22492, 29280, 1126, 6760, 29162, 26090, 29293, 29166, 14445, 29936, 20595, 36980, 1525, 29306, 1530, 25723}\n",
      "dict_items([(\"Lemma('celebrated.s.01.famous')\", 20)])\n",
      "collecting tokens for  daughters\n",
      "indices:    {18848, 21474, 26078, 13191, 3624, 8822, 22327, 22521, 13210, 22364, 22394}\n",
      "dict_items([(\"Lemma('daughter.n.01.daughter')\", 5)])\n",
      "collecting tokens for  podger\n",
      "indices:    {24396}\n",
      "dict_items([])\n",
      "collecting tokens for  displays\n",
      "indices:    {31554, 1082, 11909, 26982, 23559, 26088, 4969, 14186, 31153, 33432, 27002}\n",
      "dict_items([(\"Lemma('expose.v.03.display')\", 4), (\"Lemma('display.n.03.display')\", 1), (\"Lemma('display.n.02.display')\", 1)])\n",
      "collecting tokens for  carolina\n",
      "indices:    {19217}\n",
      "dict_items([(\"Lemma('location.n.01.location')\", 1)])\n",
      "collecting tokens for  proportion\n",
      "indices:    {32321, 16226, 28036, 15045, 28006, 34730, 3983, 16209, 3633, 25044, 2293, 25045, 4407, 7544, 2294, 27997, 32318}\n",
      "dict_items([(\"Lemma('symmetry.n.02.proportion')\", 1), (\"Lemma('proportion.n.01.proportion')\", 5), (\"Lemma('proportion.n.02.proportion')\", 2)])\n",
      "collecting tokens for  victory\n",
      "indices:    {29039}\n",
      "dict_items([])\n",
      "collecting tokens for  economic\n",
      "indices:    {20771, 13735, 2749, 13534, 24831}\n",
      "dict_items([(\"Lemma('economic.a.01.economic')\", 2)])\n",
      "collecting tokens for  distress\n",
      "indices:    {31200, 31203, 25891, 15717, 13511, 12680, 13513, 27048, 30800, 13521, 27510, 30811, 24831}\n",
      "dict_items([(\"Lemma('distress.n.01.distress')\", 4)])\n",
      "collecting tokens for  proposal\n",
      "indices:    {27138, 25091, 36871, 138, 25356, 143, 15252, 20638, 8351, 20639, 159, 15273, 27832, 20665, 25146, 12219, 14908, 21179, 830, 15417, 23876, 20431, 25807, 20305, 20559, 34386, 6107, 20193, 31203, 20714, 118, 16895}\n",
      "dict_items([(\"Lemma('proposal.n.01.proposal')\", 12), (\"Lemma('marriage_proposal.n.01.proposal')\", 1)])\n",
      "collecting tokens for  provision\n",
      "indices:    {15189}\n",
      "dict_items([(\"Lemma('provision.n.02.provision')\", 1)])\n",
      "collecting tokens for  unemployment\n",
      "indices:    {25824, 31203, 24004, 24067, 24005, 24007, 19759, 16309, 20406, 24823, 16312, 16374, 24122, 24029}\n",
      "dict_items([(\"Lemma('unemployment.n.01.unemployment')\", 3)])\n",
      "collecting tokens for  relief\n",
      "indices:    {34689, 11265, 27266, 22020, 773, 4860, 15241, 15242, 14091, 22027, 26379, 5392, 15249, 9617, 26130, 5396, 15254, 36123, 34460, 17054, 18721, 25257, 14633, 27434, 9389, 23986, 9396, 25035, 10444, 10956, 13520, 32855, 9945, 17626, 8283, 35548, 32866, 31203, 16355, 2290, 7542, 8183, 37112, 15225, 34170, 7292, 18941, 255}\n",
      "dict_items([(\"Lemma('relief.n.03.relief')\", 5), (\"Lemma('relief.n.02.relief')\", 6), (\"Lemma('easing.n.01.relief')\", 1), (\"Lemma('relief.n.01.relief')\", 9), (\"Lemma('stand-in.n.01.relief')\", 2), (\"Lemma('respite.n.04.relief')\", 1), (\"Lemma('relief.n.08.relief')\", 1), (\"Lemma('easing.n.02.relief')\", 1), (\"Lemma('relief.n.05.relief')\", 2)])\n",
      "collecting tokens for  taxation\n",
      "indices:    {25176, 25090, 91, 21430}\n",
      "dict_items([])\n",
      "collecting tokens for  signals\n",
      "indices:    {28550, 11411, 11412, 25889, 30250, 21300, 9910, 28732, 30786, 31428, 28741, 28746, 13660, 30817, 31334, 33523, 5109, 26746, 11388}\n",
      "dict_items([(\"Lemma('signal.n.01.signal')\", 5), (\"Lemma('bespeak.v.01.signal')\", 1)])\n",
      "collecting tokens for  expected\n",
      "indices:    {22017, 16900, 16903, 3083, 22031, 12819, 12821, 22551, 2075, 30238, 3103, 20515, 20516, 20518, 20520, 20521, 15408, 30768, 15410, 51, 15411, 53, 54, 49, 576, 24649, 16971, 20563, 26711, 27745, 118, 25214, 24192, 5770, 17550, 20625, 6294, 36511, 19620, 32935, 3242, 15532, 19119, 4784, 15537, 14002, 22194, 16048, 20664, 10428, 23741, 12483, 17614, 10447, 23759, 7378, 23773, 20708, 23781, 232, 2798, 10478, 24819, 2804, 33016, 20217, 37115, 12030, 1798, 14091, 2831, 2832, 20767, 3363, 2851, 21817, 3387, 23363, 23365, 22345, 15691, 15693, 334, 3919, 15702, 7005, 12129, 10603, 10604, 24429, 9068, 29040, 35702, 5499, 5500, 2942, 23427, 28550, 33161, 35725, 33167, 12178, 24980, 3988, 21912, 20379, 19357, 3487, 35743, 30113, 17824, 25504, 2988, 25004, 16301, 24495, 21951, 9668, 31690, 11214, 27091, 468, 3032, 472, 19422, 16355, 491, 20462, 9714, 22523, 3580}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('expect.v.01.expect')\", 26), (\"Lemma('ask.v.04.expect')\", 15), (\"Lemma('expect.v.03.expect')\", 3), (\"Lemma('expected.a.01.expected')\", 5)])\n",
      "collecting tokens for  inning\n",
      "indices:    {192, 258, 19811, 389, 19814, 391, 199, 453, 362, 230, 364, 19828, 19865}\n",
      "dict_items([(\"Lemma('inning.n.01.inning')\", 13)])\n",
      "collecting tokens for  deegan\n",
      "indices:    {19854}\n",
      "dict_items([(\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  teacher\n",
      "indices:    {28161, 36739, 31620, 14596, 36749, 1934, 36752, 27412, 27414, 152, 36761, 26524, 1954, 28069, 166, 23590, 13737, 2091, 21421, 2094, 13240, 6075, 22717, 1731, 1733, 1992, 73, 22089, 75, 22729, 11470, 13263, 2000, 24925, 13407, 5599, 2022, 7398, 2025, 15725, 9584, 16240, 25843, 4981}\n",
      "dict_items([(\"Lemma('teacher.n.01.teacher')\", 25), (\"Lemma('teacher.n.02.teacher')\", 1)])\n",
      "collecting tokens for  toast\n",
      "indices:    {20930, 29182, 7302, 26247, 37054, 29534}\n",
      "dict_items([(\"Lemma('toast.v.02.toast')\", 1), (\"Lemma('crispen.v.01.toast')\", 1), (\"Lemma('toast.n.01.toast')\", 1)])\n",
      "collecting tokens for  violence\n",
      "indices:    {1217, 12225, 30244, 12648, 5352, 26956, 9197, 10777, 13103, 26960, 82, 26226, 24440, 18169, 23806}\n",
      "dict_items([(\"Lemma('violence.n.01.violence')\", 8), (\"Lemma('violence.n.03.violence')\", 1)])\n",
      "collecting tokens for  stop\n",
      "indices:    {11913, 22293, 36633, 33817, 14233, 13086, 7079, 24488, 17579, 17730, 18883, 6851, 5957, 29382, 28745, 25804, 30543, 21332, 29407, 9062, 2686}\n",
      "dict_items([(\"Lemma('stop.v.03.stop')\", 6), (\"Lemma('stop.v.01.stop')\", 1), (\"Lemma('discontinue.v.01.stop')\", 4), (\"Lemma('stop.n.03.stop')\", 2), (\"Lemma('stop.v.04.stop')\", 1), (\"Lemma('stop.n.01.stop')\", 1)])\n",
      "collecting tokens for  processes\n",
      "indices:    {27905, 14724, 14725, 14727, 33163, 32909, 14734, 21523, 14741, 9366, 32922, 4252, 32924, 4254, 34591, 15392, 14748, 2729, 32938, 13613, 2479, 22704, 16438, 11705, 28861, 20164, 2888, 32969, 32970, 32977, 33106, 28888, 24412, 11357, 13662, 27871, 4576, 32734, 13670, 11622, 32232, 13675, 4212, 4216, 27900}\n",
      "dict_items([(\"Lemma('procedure.n.01.process')\", 14), (\"Lemma('process.n.02.process')\", 2)])\n",
      "collecting tokens for  mainland\n",
      "indices:    {25528}\n",
      "dict_items([])\n",
      "collecting tokens for  virtually\n",
      "indices:    {12035, 26504, 3720, 5006, 17936, 12304, 2453, 16408, 9882, 16412, 16416, 5024, 31658, 5430, 2618, 27195, 36038, 11087, 19032, 10851, 4070, 1129, 12015, 22897, 26360, 34555}\n",
      "dict_items([(\"Lemma('virtually.r.01.virtually')\", 2), (\"Lemma('about.r.07.virtually')\", 4)])\n",
      "collecting tokens for  aegean\n",
      "indices:    {4973}\n",
      "dict_items([(\"Lemma('aegean.n.01.Aegean')\", 1)])\n",
      "collecting tokens for  style\n",
      "indices:    {1025, 22402, 11266, 9478, 26503, 24584, 35335, 25997, 26893, 29199, 26767, 26897, 7442, 30226, 26513, 26005, 1046, 2709, 5019, 5020, 5021, 37022, 31389, 925, 13853, 13343, 30115, 26786, 26787, 5025, 26791, 30244, 5034, 34606, 1071, 1201, 29489, 32055, 11073, 1602, 9156, 708, 26950, 7367, 13386, 14666, 1740, 26188, 13388, 26443, 13387, 18891, 19533, 22995, 26448, 1756, 22493, 26213, 26088, 26090, 26604, 25712, 4978, 4980, 13813, 14456, 29945, 23037, 26622}\n",
      "dict_items([(\"Lemma('expressive_style.n.01.style')\", 5), (\"Lemma('manner.n.01.style')\", 22), (\"Lemma('style.n.03.style')\", 3), (\"Lemma('vogue.n.01.style')\", 2)])\n",
      "collecting tokens for  canada\n",
      "indices:    {20237}\n",
      "dict_items([])\n",
      "collecting tokens for  muffled\n",
      "indices:    {7011, 7203, 9257, 6186, 34059, 8553, 8527, 27321, 9241, 25722}\n",
      "dict_items([(\"Lemma('dull.s.03.muffled')\", 6), (\"Lemma('smother.v.03.muffle')\", 1), (\"Lemma('muffled.s.02.muffled')\", 1)])\n",
      "collecting tokens for  till\n",
      "indices:    {36999, 37012, 9717, 24283, 6462}\n",
      "dict_items([])\n",
      "collecting tokens for  calif.\n",
      "indices:    {21565}\n",
      "dict_items([])\n",
      "collecting tokens for  legend\n",
      "indices:    {18304, 26592, 11137, 23137, 14532, 31844, 2309, 13738, 13740, 34335, 2319, 31828, 31515, 2300, 27038, 18303}\n",
      "dict_items([(\"Lemma('legend.n.01.legend')\", 9)])\n",
      "collecting tokens for  mist\n",
      "indices:    {35248, 9187, 8918, 36239}\n",
      "dict_items([(\"Lemma('mist.n.01.mist')\", 2)])\n",
      "collecting tokens for  celebrated\n",
      "indices:    {8388, 32683, 34606, 1390, 912, 21135, 22197, 13786, 24734, 27038}\n",
      "dict_items([(\"Lemma('observe.v.06.celebrate')\", 6), (\"Lemma('lionize.v.01.celebrate')\", 2), (\"Lemma('celebrate.v.02.celebrate')\", 1)])\n",
      "collecting tokens for  falls\n",
      "indices:    {27006}\n",
      "dict_items([])\n",
      "collecting tokens for  tool\n",
      "indices:    {19468, 28702, 28835, 28844, 3885, 28846, 32175, 32176, 29872, 29875, 11828, 11316, 18243, 29892, 29894, 29896, 29898, 29899, 29900, 29906, 12646, 33639, 33646, 22770, 29564}\n",
      "dict_items([(\"Lemma('tool.n.01.tool')\", 3), (\"Lemma('instrument.n.02.tool')\", 2)])\n",
      "collecting tokens for  dealing\n",
      "indices:    {24001, 11332, 23205, 23332, 35879, 15763, 14643, 14623}\n",
      "dict_items([(\"Lemma('cover.v.05.deal')\", 3), (\"Lemma('deal.v.09.deal')\", 1), (\"Lemma('deal.v.08.deal')\", 1), (\"Lemma('deal.v.03.deal')\", 2), (\"Lemma('consider.v.03.deal')\", 1)])\n",
      "collecting tokens for  crises\n",
      "indices:    {4672, 32904, 25484, 33167, 32176, 32175, 32150, 4760, 20410, 13403}\n",
      "dict_items([(\"Lemma('crisis.n.02.crisis')\", 1), (\"Lemma('crisis.n.01.crisis')\", 2)])\n",
      "collecting tokens for  dialogue\n",
      "indices:    {10882, 1125, 2123, 25492, 1012, 1014, 10772, 25502, 30239}\n",
      "dict_items([(\"Lemma('dialogue.n.02.dialogue')\", 2), (\"Lemma('dialogue.n.03.dialogue')\", 1), (\"Lemma('dialogue.n.01.dialogue')\", 3)])\n",
      "collecting tokens for  myself\n",
      "indices:    {31936, 27341, 6897, 2130, 2489}\n",
      "dict_items([])\n",
      "collecting tokens for  chief\n",
      "indices:    {20312, 28065}\n",
      "dict_items([])\n",
      "collecting tokens for  bay\n",
      "indices:    {7840, 16481, 34027, 7830}\n",
      "dict_items([(\"Lemma('bay.n.01.bay')\", 2)])\n",
      "collecting tokens for  articles\n",
      "indices:    {3168, 14244, 25028, 1575, 33159, 33160, 31979, 12043, 26925, 1425, 1426, 29043, 32757, 1429, 25238, 4926, 32767}\n",
      "dict_items([(\"Lemma('article.n.01.article')\", 4), (\"Lemma('article.n.02.article')\", 3)])\n",
      "collecting tokens for  cult\n",
      "indices:    {32038, 1319, 25350, 25353, 27530, 25367, 12215, 10746, 32093, 27550}\n",
      "dict_items([(\"Lemma('fad.n.01.cult')\", 1), (\"Lemma('cult.n.01.cult')\", 1)])\n",
      "collecting tokens for  simplicity\n",
      "indices:    {22145, 22085, 3237, 26333, 2641, 2423, 14040, 32093}\n",
      "dict_items([(\"Lemma('simplicity.n.02.simplicity')\", 1), (\"Lemma('simplicity.n.01.simplicity')\", 3)])\n",
      "collecting tokens for  telephone\n",
      "indices:    {900, 20485, 28711, 22249, 8283, 84, 8149, 20150, 5176, 7419}\n",
      "dict_items([(\"Lemma('telephone.n.02.telephone')\", 1), (\"Lemma('telephone.n.01.telephone')\", 3)])\n",
      "collecting tokens for  interrupted\n",
      "indices:    {19330, 17282, 17667, 7047, 37001, 16777, 10601, 17295, 36470, 9366, 10584, 10107, 24029, 17694}\n",
      "dict_items([(\"Lemma('interrupt.v.02.interrupt')\", 4), (\"Lemma('interrupt.v.01.interrupt')\", 9), (\"Lemma('interrupt.v.03.interrupt')\", 1)])\n",
      "collecting tokens for  servant\n",
      "indices:    {27335, 26600, 13900, 13934, 13905, 24149, 13946, 15327}\n",
      "dict_items([(\"Lemma('servant.n.01.servant')\", 4)])\n",
      "collecting tokens for  strategy\n",
      "indices:    {13688, 11650, 24876, 15462}\n",
      "dict_items([(\"Lemma('scheme.n.01.strategy')\", 3)])\n",
      "collecting tokens for  master\n",
      "indices:    {1090, 163, 1731, 11267, 31961, 28164, 11108, 27459, 24619, 1040, 23089, 27031, 22489, 28154, 5367, 30013, 35678, 29023}\n",
      "dict_items([(\"Lemma('maestro.n.01.master')\", 3), (\"Lemma('master.n.06.master')\", 1), (\"Lemma('overcome.v.02.master')\", 1), (\"Lemma('master.v.01.master')\", 1)])\n",
      "collecting tokens for  sums\n",
      "indices:    {29921, 25219, 31750, 14890, 24909, 14898, 26196, 32567, 14748, 31290, 22747, 15004, 2239}\n",
      "dict_items([(\"Lemma('sum.n.01.sum')\", 5)])\n",
      "collecting tokens for  provisions\n",
      "indices:    {14858, 25482, 28688, 14870, 14746, 15259, 14748, 15004, 14882, 15012, 15013, 2089, 15277, 12334, 21427, 15227, 15302, 15047, 4812, 15054, 15055, 27888, 16635}\n",
      "dict_items([(\"Lemma('provision.n.01.provision')\", 18), (\"Lemma('commissariat.n.01.provisions')\", 1)])\n",
      "collecting tokens for  sensitivity\n",
      "indices:    {2820, 3364, 14794, 14797, 31598, 14638, 14640, 30802, 14642, 26676, 4245, 11094, 4919, 27283, 4921, 14589, 2846, 7583}\n",
      "dict_items([(\"Lemma('sensitivity.n.03.sensitivity')\", 3), (\"Lemma('sensitivity.n.01.sensitivity')\", 7), (\"Lemma('sensitivity.n.02.sensitivity')\", 4)])\n",
      "collecting tokens for  crucial\n",
      "indices:    {27280, 25488, 3732, 28446, 4255, 13347, 32686, 15794, 26041, 6844, 23869, 22594, 15431, 32977, 30802, 23900, 2656, 34401, 28518, 25578, 23284}\n",
      "dict_items([(\"Lemma('crucial.a.01.crucial')\", 6), (\"Lemma('crucial.s.02.crucial')\", 1)])\n",
      "collecting tokens for  intercourse\n",
      "indices:    {30757, 30823, 30825, 30762, 30767, 30802, 30804, 30780}\n",
      "dict_items([])\n",
      "collecting tokens for  garson\n",
      "indices:    {22073}\n",
      "dict_items([])\n",
      "collecting tokens for  los\n",
      "indices:    {25700}\n",
      "dict_items([])\n",
      "collecting tokens for  angeles\n",
      "indices:    {25700}\n",
      "dict_items([])\n",
      "collecting tokens for  mexico\n",
      "indices:    {12940}\n",
      "dict_items([(\"Lemma('mexico.n.01.Mexico')\", 1)])\n",
      "collecting tokens for  permanent\n",
      "indices:    {33024, 12938, 27020, 14996, 31002, 11418, 31223, 31016, 4660, 4662, 12219, 21185, 32706, 34755, 2776, 24666, 37090, 32741, 12911, 2159, 24177, 879, 2163, 13303, 2680, 31996, 25469}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('permanent.a.01.permanent')\", 13)])\n",
      "collecting tokens for  abandoned\n",
      "indices:    {26497, 31748, 35861, 31382, 1306, 17052, 7709, 21670, 30375, 24103, 13367, 21185, 30405, 25424, 90, 25956, 34153, 26222, 11253}\n",
      "dict_items([(\"Lemma('vacate.v.02.abandon')\", 5), (\"Lemma('abandon.v.05.abandon')\", 3), (\"Lemma('abandon.v.02.abandon')\", 3), (\"Lemma('abandon.v.01.abandon')\", 2), (\"Lemma('abandon.v.04.abandon')\", 1), (\"Lemma('abandoned.s.01.abandoned')\", 1)])\n",
      "collecting tokens for  dean\n",
      "indices:    {32198}\n",
      "dict_items([])\n",
      "collecting tokens for  kept\n",
      "indices:    {9227, 35342, 29209, 36892, 35359, 34336, 23076, 5157, 3622, 11828, 9801, 25678, 30801, 34904, 22105, 19546, 19547, 12380, 34909, 18017, 23138, 23137, 5228, 3700, 25718, 20601, 10876, 9859, 135, 25738, 24716, 24722, 2198, 7830, 10908, 10909, 33445, 19624, 21162, 3765, 2743, 6840, 29883, 1725, 4810, 21196, 30413, 25813, 18136, 31451, 23773, 36069, 36587, 19181, 17646, 27375, 23798, 33015, 249, 36095, 30465, 26370, 33541, 21255, 17161, 33553, 26397, 23841, 23331, 13609, 297, 19243, 34094, 22833, 19250, 10547, 17721, 20793, 13116, 29501, 13634, 32579, 15178, 13130, 15180, 31063, 18269, 30052, 12652, 34679, 1415, 35721, 6543, 19343, 17810, 11672, 9113, 36762, 15772, 10141, 9631, 7594, 7610, 12219, 1472, 16325, 36298, 9165, 9172, 3035, 5084, 9182, 5599, 35305, 29161, 29163, 2026, 11248, 21490, 5619, 7668, 34293, 9205, 30200, 35321, 25594, 35327}\n",
      "dict_items([(\"Lemma('keep.v.01.keep')\", 26), (\"Lemma('prevent.v.02.keep')\", 2), (\"Lemma('continue.v.01.keep')\", 20), (\"Lemma('keep.v.08.keep')\", 3), (\"Lemma('keep.v.07.keep')\", 4), (\"Lemma('keep.v.03.keep')\", 10), (\"Lemma('sustain.v.04.keep')\", 3), (\"Lemma('observe.v.09.keep')\", 4), (\"Lemma('observe.v.08.keep')\", 4), (\"Lemma('retain.v.02.keep')\", 1), (\"Lemma('observe.v.06.keep')\", 1), (\"Lemma('keep.v.09.keep')\", 1)])\n",
      "collecting tokens for  hero\n",
      "indices:    {26872, 13861, 543}\n",
      "dict_items([(\"Lemma('hero.n.01.hero')\", 2)])\n",
      "collecting tokens for  encounter\n",
      "indices:    {224, 17572, 3398, 26535, 30217, 20521, 2671, 5658, 6931, 10005, 5271, 22650, 26268, 4607}\n",
      "dict_items([(\"Lemma('meet.v.01.encounter')\", 4), (\"Lemma('meet.v.10.encounter')\", 1), (\"Lemma('brush.n.06.encounter')\", 3), (\"Lemma('encounter.n.03.encounter')\", 2), (\"Lemma('meeting.n.03.encounter')\", 1), (\"Lemma('run_into.v.01.encounter')\", 1)])\n",
      "collecting tokens for  albany\n",
      "indices:    {24855}\n",
      "dict_items([])\n",
      "collecting tokens for  surgeon\n",
      "indices:    {12257, 12613, 9582, 12398, 9587, 7860, 7643, 7644, 7646}\n",
      "dict_items([(\"Lemma('surgeon.n.01.surgeon')\", 9)])\n",
      "collecting tokens for  association\n",
      "indices:    {11936}\n",
      "dict_items([])\n",
      "collecting tokens for  wilson\n",
      "indices:    {10374}\n",
      "dict_items([(\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  grant\n",
      "indices:    {24970, 20204, 21582}\n",
      "dict_items([])\n",
      "collecting tokens for  florida\n",
      "indices:    {27073}\n",
      "dict_items([])\n",
      "collecting tokens for  medicine\n",
      "indices:    {27196}\n",
      "dict_items([])\n",
      "collecting tokens for  discover\n",
      "indices:    {30086, 16903, 19472, 29458, 2324, 29460, 3612, 32928, 27427, 27303, 28848, 5297, 1714, 14386, 31806, 4936, 13642, 18891, 14681, 5466, 28646, 11111, 5224, 4845, 6773, 22392}\n",
      "dict_items([(\"Lemma('discover.v.04.discover')\", 5), (\"Lemma('detect.v.01.discover')\", 6), (\"Lemma('learn.v.02.discover')\", 9), (\"Lemma('unwrap.v.02.discover')\", 1), (\"Lemma('discover.v.03.discover')\", 4), (\"Lemma('fall_upon.v.01.discover')\", 1)])\n",
      "collecting tokens for  reduce\n",
      "indices:    {11780, 11527, 7, 15116, 1804, 14609, 14998, 15511, 27416, 153, 11547, 15136, 21153, 24995, 5539, 23847, 21161, 170, 22827, 24490, 5420, 25137, 1714, 11575, 29880, 31290, 24896, 2881, 29889, 4161, 28490, 25038, 28880, 12631, 32354, 2914, 2915, 11749, 14819, 11754, 12523, 2926, 22769, 32881, 22770, 30196, 30197}\n",
      "dict_items([(\"Lemma('reduce.v.01.reduce')\", 26), (\"Lemma('reduce.v.04.reduce')\", 1), (\"Lemma('reduce.v.11.reduce')\", 1), (\"Lemma('reduce.v.02.reduce')\", 2)])\n",
      "collecting tokens for  aside\n",
      "indices:    {25439}\n",
      "dict_items([])\n",
      "collecting tokens for  jet\n",
      "indices:    {29071}\n",
      "dict_items([])\n",
      "collecting tokens for  developments\n",
      "indices:    {22629, 29127, 2728, 4630, 10876, 16413}\n",
      "dict_items([(\"Lemma('development.n.04.development')\", 2), (\"Lemma('development.n.01.development')\", 1), (\"Lemma('development.n.02.development')\", 1)])\n",
      "collecting tokens for  khrushchev\n",
      "indices:    {22592}\n",
      "dict_items([])\n",
      "collecting tokens for  mood\n",
      "indices:    {26752, 18021, 231, 233, 26251, 26892, 26158, 22159, 22638, 8468, 1045, 31094, 9397, 13400, 916, 10580, 26621}\n",
      "dict_items([(\"Lemma('climate.n.02.mood')\", 2), (\"Lemma('temper.n.02.mood')\", 6)])\n",
      "collecting tokens for  opinion\n",
      "indices:    {27278, 20368, 22801, 32404, 23707, 27295, 6943, 27297, 36514, 680, 4648, 3370, 32427, 32425, 29489, 20786, 435, 15284, 17339, 24891, 25915, 12996, 15301, 11990, 20310, 15832, 15448, 13272, 23259, 28379, 24408, 22614, 15456, 25443, 27886, 2031, 22894, 15863, 27896, 25338, 15231}\n",
      "dict_items([(\"Lemma('opinion.n.04.opinion')\", 1), (\"Lemma('opinion.n.02.opinion')\", 2), (\"Lemma('opinion.n.05.opinion')\", 1), (\"Lemma('opinion.n.01.opinion')\", 7), (\"Lemma('public_opinion.n.01.opinion')\", 3)])\n",
      "collecting tokens for  damage\n",
      "indices:    {773, 31369, 4904, 25390, 12467, 25396, 11575, 4928, 27201, 320, 3395, 21703, 27211, 5451, 8658, 344, 30425, 30810, 12776, 12777, 13034, 235, 28531, 18810}\n",
      "dict_items([(\"Lemma('damage.n.01.damage')\", 11), (\"Lemma('damage.v.01.damage')\", 4), (\"Lemma('damage.n.03.damage')\", 1), (\"Lemma('damage.n.02.damage')\", 1)])\n",
      "collecting tokens for  fifty\n",
      "indices:    {28640, 3431, 8807, 32715, 17581, 36369, 8497, 32434, 27316, 13748, 8153, 5053}\n",
      "dict_items([(\"Lemma('fifty.s.01.fifty')\", 6)])\n",
      "collecting tokens for  swiss\n",
      "indices:    {12507}\n",
      "dict_items([])\n",
      "collecting tokens for  mouth\n",
      "indices:    {8832, 11138, 17796, 5638, 36746, 8851, 10388, 37141, 9110, 5655, 33942, 17305, 30362, 11803, 25882, 9112, 17820, 31005, 9120, 6435, 9125, 31397, 31399, 10793, 34986, 11180, 17069, 31020, 9136, 34738, 12467, 18616, 7737, 10682, 5051, 26684, 10684, 33598, 19644, 10680, 22465, 12492, 36433, 17106, 36051, 16980, 33620, 24791, 19160, 36056, 4060, 17886, 10591, 10592, 19170, 33762, 20452, 6503, 7146, 13418, 35563, 8813, 5619, 8955, 19198}\n",
      "dict_items([(\"Lemma('mouth.n.02.mouth')\", 10), (\"Lemma('mouth.n.01.mouth')\", 26), (\"Lemma('mouth.n.04.mouth')\", 2), (\"Lemma('mouth.n.03.mouth')\", 2)])\n",
      "collecting tokens for  string\n",
      "indices:    {13120, 30509, 30964, 6775, 23935}\n",
      "dict_items([(\"Lemma('string.v.02.string')\", 1), (\"Lemma('string.n.01.string')\", 1)])\n",
      "collecting tokens for  pro\n",
      "indices:    {1739, 20940, 22924, 14894, 22287, 12921, 4796, 543}\n",
      "dict_items([(\"Lemma('pro.a.01.pro')\", 1), (\"Lemma('professional.n.02.pro')\", 1)])\n",
      "collecting tokens for  female\n",
      "indices:    {26371, 3652, 1156, 3654, 34697, 3755, 26412, 12043, 3758, 3638, 25142, 33179, 21599}\n",
      "dict_items([(\"Lemma('female.n.01.female')\", 5), (\"Lemma('female.a.01.female')\", 2)])\n",
      "collecting tokens for  inches\n",
      "indices:    {22272, 15105, 28930, 28928, 28937, 28948, 28951, 3735, 3737, 10647, 11291, 3740, 3738, 3739, 3744, 29736, 29099, 33836, 3755, 3758, 29746, 3763, 3764, 3253, 9523, 19908, 5064, 29778, 15103, 31487, 2005, 12631, 7389, 15072, 29411, 1636, 29802, 28909, 3694, 3695, 34288, 1647, 28913, 15091, 3699, 30195, 15100, 28926, 22271}\n",
      "dict_items([(\"Lemma('inch.n.01.inch')\", 26), (\"Lemma('column_inch.n.01.inch')\", 3)])\n",
      "collecting tokens for  supposed\n",
      "indices:    {27266, 25976, 5252, 27790, 31502, 19100, 1308, 36126, 17055, 9639, 2087, 7593, 937, 15787, 27439, 24243, 4922, 24510, 19136, 16964, 1604, 14534, 14407, 12106, 13776, 31828, 27862, 37081, 33241, 28124, 33249, 17892, 28135, 22125, 5749, 10230, 28152, 1018, 635, 26237}\n",
      "dict_items([(\"Lemma('suppose.v.01.suppose')\", 1), (\"Lemma('think.v.02.suppose')\", 4), (\"Lemma('speculate.v.01.suppose')\", 2), (\"Lemma('supposed.s.02.supposed')\", 1)])\n",
      "collecting tokens for  concerning\n",
      "indices:    {27905, 32322, 4929, 35686, 13865, 3402, 12268, 25293, 5294, 32847, 27886, 33202, 4754, 2296, 11514, 14431}\n",
      "dict_items([(\"Lemma('refer.v.02.concern')\", 13)])\n",
      "collecting tokens for  soap\n",
      "indices:    {19136, 33381, 36073, 3147, 19084, 3151, 7857, 19032, 19033, 19036}\n",
      "dict_items([(\"Lemma('soap.n.01.soap')\", 7)])\n",
      "collecting tokens for  angle\n",
      "indices:    {17537, 2822, 13576, 2826, 29580, 31385, 24474, 2845, 2846, 2849, 29877, 29624, 9787, 19136, 3008, 19141, 3030, 28759, 6494, 34040}\n",
      "dict_items([(\"Lemma('angle.v.01.angle')\", 1), (\"Lemma('angle.n.01.angle')\", 7), (\"Lemma('slant.n.01.angle')\", 2)])\n",
      "collecting tokens for  stuff\n",
      "indices:    {10788, 20069, 14505, 19051, 30965, 34039, 6778}\n",
      "dict_items([(\"Lemma('stuff.n.02.stuff')\", 2), (\"Lemma('stuff.n.04.stuff')\", 1), (\"Lemma('material.n.01.stuff')\", 1)])\n",
      "collecting tokens for  absolute\n",
      "indices:    {15108, 15115, 27022, 15120, 28442, 2846, 2080, 14881, 7330, 25888, 2849, 8110, 16445, 14803, 14805, 15703, 5083, 23902, 32225, 20195, 1767, 27133}\n",
      "dict_items([(\"Lemma('absolute.a.01.absolute')\", 9), (\"Lemma('absolute.s.02.absolute')\", 4), (\"Lemma('absolute.s.03.absolute')\", 1)])\n",
      "collecting tokens for  qualifications\n",
      "indices:    {2080, 24872, 35753, 4810, 2092, 22701, 27695, 22704, 886, 14007, 11707, 8253}\n",
      "dict_items([(\"Lemma('qualification.n.01.qualification')\", 6), (\"Lemma('qualification.n.02.qualification')\", 1)])\n",
      "collecting tokens for  membership\n",
      "indices:    {27617, 27585, 2082, 27654, 27687, 23560, 27688, 28013, 27602, 27608, 2076, 27678, 27679}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('membership.n.02.membership')\", 2)])\n",
      "collecting tokens for  enforced\n",
      "indices:    {2080, 14112, 98, 20228, 26696, 32936, 14984, 34571, 12300, 14634, 25232, 16432, 21204, 33077, 27895, 14043}\n",
      "dict_items([(\"Lemma('enforce.v.02.enforce')\", 6), (\"Lemma('enforce.v.01.enforce')\", 8), (\"Lemma('enforced.a.01.enforced')\", 1)])\n",
      "collecting tokens for  profession\n",
      "indices:    {14592, 22793, 24596, 2080, 13984, 2338, 33319, 5160, 2097, 22068, 22714, 21562, 34761, 25802, 32724, 19549, 12389, 23657, 13291, 6255, 34676, 30845}\n",
      "dict_items([(\"Lemma('profession.n.02.profession')\", 5), (\"Lemma('profession.n.01.profession')\", 5)])\n",
      "collecting tokens for  paul\n",
      "indices:    {5140}\n",
      "dict_items([])\n",
      "collecting tokens for  current\n",
      "indices:    {17924, 10810, 25915, 2716, 32507}\n",
      "dict_items([(\"Lemma('current.a.01.current')\", 1)])\n",
      "collecting tokens for  philharmonic\n",
      "indices:    {19571, 26259}\n",
      "dict_items([(\"Lemma('philharmonic.a.01.philharmonic')\", 1)])\n",
      "collecting tokens for  plays\n",
      "indices:    {36609, 259, 14472, 3980, 13455, 5266, 26642, 2457, 4255, 290, 14627, 25636, 34854, 13993, 25645, 559, 307, 36660, 13493, 13494, 27895, 11071, 26432, 5185, 26561, 7877, 13510, 26567, 26565, 26954, 11082, 10833, 13524, 24533, 13398, 13530, 27233, 26084, 1125, 27886, 13553, 26612, 16759, 6907, 26238}\n",
      "dict_items([(\"Lemma('play.v.12.play')\", 1), (\"Lemma('play.v.02.play')\", 9), (\"Lemma('play.v.06.play')\", 2), (\"Lemma('play.n.01.play')\", 9), (\"Lemma('play.v.01.play')\", 2), (\"Lemma('play.v.05.play')\", 1), (\"Lemma('play.n.03.play')\", 2), (\"Lemma('act.v.03.play')\", 4), (\"Lemma('play.v.07.play')\", 2), (\"Lemma('play.v.09.play')\", 1), (\"Lemma('maneuver.n.03.play')\", 1)])\n",
      "collecting tokens for  event\n",
      "indices:    {10240, 2438, 2439, 31880, 20871, 2184, 31883, 32908, 2445, 25371, 1436, 1438, 27808, 32674, 31910, 22054, 4905, 1451, 20785, 22194, 12211, 4787, 32561, 15286, 8245, 14646, 1338, 20924, 2120, 73, 11465, 6909, 1359, 2128, 8401, 1362, 21079, 14169, 17370, 14042, 20319, 32480, 20983, 14693, 17255, 3819, 27499, 2160, 26097, 21106, 21107, 4851, 21749, 245, 1527, 21112, 11509, 22779, 5373, 26366}\n",
      "dict_items([(\"Lemma('event.n.01.event')\", 24), (\"Lemma('event.n.02.event')\", 4)])\n",
      "collecting tokens for  fails\n",
      "indices:    {15195, 18307, 20324, 32101, 20646, 5351, 23953, 12051, 31643}\n",
      "dict_items([(\"Lemma('fail.v.01.fail')\", 6), (\"Lemma('fail.v.02.fail')\", 1), (\"Lemma('fail.v.04.fail')\", 2)])\n",
      "collecting tokens for  slow\n",
      "indices:    {24451, 16900, 24452, 35203, 21895, 7047, 24075, 8592, 23953, 9105, 5652, 17691, 2973, 6047, 24352, 24353, 35107, 19876, 5539, 24488, 32173, 24368, 26819, 26820, 24645, 25670, 26570, 207, 24406, 16472, 11866, 13276, 25693, 7777, 26979, 24678, 5734, 3688, 3306, 21740, 1011, 26484, 26485, 25589, 24056, 31481, 36347, 8575}\n",
      "dict_items([(\"Lemma('slow.a.01.slow')\", 15), (\"Lemma('slow.a.02.slow')\", 2), (\"Lemma('slow.v.03.slow_down')\", 1), (\"Lemma('dense.s.04.slow')\", 1), (\"Lemma('slowly.r.01.slow')\", 1)])\n",
      "collecting tokens for  governmental\n",
      "indices:    {2307, 14212, 20613, 4613, 24073, 4617, 23953, 33043, 16432, 24889, 16452, 31193, 31195, 25827, 32744, 31209, 32362, 32616, 14187, 14206}\n",
      "dict_items([])\n",
      "collecting tokens for  operations\n",
      "indices:    {32352, 26722, 14916, 15402, 21837, 15598, 5466}\n",
      "dict_items([(\"Lemma('operation.n.01.operation')\", 1)])\n",
      "collecting tokens for  roads\n",
      "indices:    {59, 5861}\n",
      "dict_items([(\"Lemma('road.n.01.road')\", 1)])\n",
      "collecting tokens for  suite\n",
      "indices:    {37138, 14572}\n",
      "dict_items([(\"Lemma('suite.n.01.suite')\", 1)])\n",
      "collecting tokens for  twenty-four\n",
      "indices:    {8010, 23251, 35924}\n",
      "dict_items([])\n",
      "collecting tokens for  unstructured\n",
      "indices:    {15713, 15714, 15658, 15727, 15728, 15698, 15700, 15702, 15704, 15705, 15646, 15711}\n",
      "dict_items([(\"Lemma('unstructured.a.01.unstructured')\", 12)])\n",
      "collecting tokens for  boys\n",
      "indices:    {31488, 17793, 7303, 36744, 31499, 3862, 13722, 3868, 1966, 13238, 12599, 26431, 3911, 36937, 31570, 9301, 22103, 29016, 31582, 36710, 8678, 21102, 14452, 22773, 11900}\n",
      "dict_items([(\"Lemma('male_child.n.01.boy')\", 9), (\"Lemma('boy.n.02.boy')\", 2), (\"Lemma('son.n.01.boy')\", 1)])\n",
      "collecting tokens for  eighth\n",
      "indices:    {26797}\n",
      "dict_items([])\n",
      "collecting tokens for  walk\n",
      "indices:    {35329, 28549, 34950, 20234, 19467, 11036, 6563, 8101, 24998, 19884, 8627, 5940, 16823, 187, 33735, 33737, 7753, 31562, 31566, 7630, 9554, 5849, 36954, 17884, 6880, 7266, 22243, 17892, 22244, 17895, 23017, 36842, 5747, 20596, 31477, 24702}\n",
      "dict_items([(\"Lemma('walk.v.01.walk')\", 18), (\"Lemma('walk.n.01.walk')\", 2), (\"Lemma('walk.n.03.walk')\", 1), (\"Lemma('walk.v.05.walk')\", 1), (\"Lemma('walk.n.04.walk')\", 2), (\"Lemma('base_on_balls.n.01.walk')\", 1)])\n",
      "collecting tokens for  stole\n",
      "indices:    {21616, 21169, 37138, 11124, 437, 184, 23194, 667, 7038}\n",
      "dict_items([(\"Lemma('steal.v.03.steal')\", 3), (\"Lemma('steal.v.01.steal')\", 5)])\n",
      "collecting tokens for  concern\n",
      "indices:    {5248, 7041, 26754, 7042, 14593, 25468, 24075, 36237, 18189, 5649, 15383, 15384, 2327, 14615, 15388, 12956, 26525, 11299, 27172, 25125, 2470, 34092, 25389, 20657, 2740, 2622, 576, 20672, 4674, 13636, 15814, 5703, 5319, 14409, 20681, 20690, 28627, 7125, 27097, 26586, 36441, 15452, 1248, 32352, 32866, 4580, 16870, 24039, 18025, 31849, 2539, 24939, 5227, 2412, 31855, 1263, 14065, 25460, 20341, 16374, 34300, 25469}\n",
      "dict_items([(\"Lemma('concern.n.04.concern')\", 1), (\"Lemma('concern.n.02.concern')\", 6), (\"Lemma('concern.v.02.concern')\", 4), (\"Lemma('concern.n.01.concern')\", 16), (\"Lemma('refer.v.02.concern')\", 6), (\"Lemma('concern.n.03.concern')\", 2)])\n",
      "collecting tokens for  remarque\n",
      "indices:    {27087}\n",
      "dict_items([])\n",
      "collecting tokens for  party\n",
      "indices:    {35809, 36961, 21092, 20810, 37138, 24821, 34359, 24831}\n",
      "dict_items([])\n",
      "collecting tokens for  opened\n",
      "indices:    {26116, 5638, 13322, 34831, 6165, 26656, 23585, 31779, 18487, 24635, 60, 9788, 16955, 16956, 9807, 33374, 25700, 14443, 9325, 17517, 36979, 1140, 31347, 18550, 11380, 18552, 17547, 33936, 658, 17559, 9368, 8346, 8356, 26789, 6313, 17066, 24751, 9394, 21685, 24758, 22201, 11450, 3272, 33992, 11478, 10969, 7392, 7393, 7394, 16611, 29925, 34025, 26873, 5886, 29960, 29972, 25882, 36127, 19238, 7974, 26413, 7474, 6970, 16713, 23371, 24396, 24402, 27475, 5461, 10584, 10591, 26979, 19301, 20838, 22385, 10098, 23414, 2432, 36746, 15757, 33681, 26519, 24471, 923, 18358, 17854, 5063, 21959, 19913, 26071, 7148, 1005, 14838, 9215}\n",
      "dict_items([(\"Lemma('open.v.01.open')\", 26), (\"Lemma('open.v.02.open')\", 19), (\"Lemma('open.v.03.open')\", 9), (\"Lemma('open.v.07.open_up')\", 1), (\"Lemma('open.v.06.open')\", 3), (\"Lemma('open.v.04.open')\", 9), (\"Lemma('open.a.01.open')\", 2), (\"Lemma('open.v.07.open')\", 1), (\"Lemma('open.a.05.opened')\", 1), (\"Lemma('unfold.v.04.open')\", 2), (\"Lemma('open.v.08.open')\", 1)])\n",
      "collecting tokens for  windows\n",
      "indices:    {22144, 28422, 29830, 35720, 17545, 18185, 35470, 9231, 17687, 18843, 30111, 29864, 29996, 15152, 15153, 18107, 33856, 16961, 9154, 16965, 27978, 983, 18520, 18526, 7775, 11106, 7394, 9187, 30181, 15206, 15846, 30566, 15207, 5606, 29294, 17522, 17524, 9205, 3446, 36728}\n",
      "dict_items([(\"Lemma('window.n.01.window')\", 21), (\"Lemma('window.n.02.window')\", 2)])\n",
      "collecting tokens for  rev.\n",
      "indices:    {20823}\n",
      "dict_items([])\n",
      "collecting tokens for  ceremony\n",
      "indices:    {21666, 483, 19205, 21221, 10712, 9359, 2131, 22549, 10231, 12664, 21051, 37020}\n",
      "dict_items([(\"Lemma('ceremony.n.01.ceremony')\", 4), (\"Lemma('ceremony.n.03.ceremony')\", 1), (\"Lemma('ceremony.n.02.ceremony')\", 1)])\n",
      "collecting tokens for  slaughter\n",
      "indices:    {26052, 36006, 264, 429, 11578, 17501}\n",
      "dict_items([(\"Lemma('slaughter.n.01.slaughter')\", 2), (\"Lemma('thrashing.n.01.slaughter')\", 1)])\n",
      "collecting tokens for  chapel\n",
      "indices:    {19721, 12515, 1395}\n",
      "dict_items([(\"Lemma('chapel.n.01.chapel')\", 2)])\n",
      "collecting tokens for  baptist\n",
      "indices:    {21466}\n",
      "dict_items([])\n",
      "collecting tokens for  owner\n",
      "indices:    {32384, 12550, 24710, 32393, 25100, 2062, 14742, 22044, 32417, 32422, 29990, 32423, 25002, 26540, 12084, 20538, 13754, 13756, 13755, 18366, 20544, 14533, 18376, 28623, 9690, 6755, 30060, 32380}\n",
      "dict_items([(\"Lemma('owner.n.01.owner')\", 8), (\"Lemma('owner.n.02.owner')\", 4)])\n",
      "collecting tokens for  relations\n",
      "indices:    {27753, 234, 27754, 9837, 31215, 48, 20628, 4215}\n",
      "dict_items([(\"Lemma('relation.n.01.relation')\", 1)])\n",
      "collecting tokens for  firm\n",
      "indices:    {21696, 1799, 15752, 22090, 4747, 21772, 14509, 23918, 22644, 15766}\n",
      "dict_items([(\"Lemma('firm.s.03.firm')\", 1), (\"Lemma('firm.n.01.firm')\", 3), (\"Lemma('firm.s.04.firm')\", 1)])\n",
      "collecting tokens for  owed\n",
      "indices:    {37093, 5320, 31179, 26603, 22034, 14420, 37108, 22044}\n",
      "dict_items([(\"Lemma('owe.v.01.owe')\", 6), (\"Lemma('owe.v.02.owe')\", 2)])\n",
      "collecting tokens for  income\n",
      "indices:    {15617, 15012, 15022, 22036, 22039}\n",
      "dict_items([(\"Lemma('income.n.01.income')\", 3)])\n",
      "collecting tokens for  payments\n",
      "indices:    {21761, 14886, 22055, 14891, 14892, 14861, 14894, 14766, 14768, 14767, 33020, 24029}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('payment.n.01.payment')\", 5), (\"Lemma('payment.n.02.payment')\", 3)])\n",
      "collecting tokens for  kicked\n",
      "indices:    {18371, 263, 34665, 298, 6925, 10671, 25103, 273, 274, 275, 35381, 6678, 22044}\n",
      "dict_items([(\"Lemma('kick.v.03.kick')\", 3), (\"Lemma('kick.v.01.kick')\", 6), (\"Lemma('kick.v.02.kick')\", 2)])\n",
      "collecting tokens for  ruled\n",
      "indices:    {17545, 21642, 20761, 4890, 22044, 22821, 18599, 22055, 27560, 22059, 557, 32814, 32820, 32821, 571, 23485, 20158, 8397, 208, 2532, 23014, 13034, 5243, 12028, 31102}\n",
      "dict_items([(\"Lemma('govern.v.03.rule')\", 5), (\"Lemma('rule.v.02.rule')\", 9), (\"Lemma('predominate.v.01.rule')\", 1), (\"Lemma('rule.v.04.rule')\", 1), (\"Lemma('ruled.s.01.ruled')\", 1)])\n",
      "collecting tokens for  dug\n",
      "indices:    {9504, 5954, 35524, 23174, 23087, 36529, 6998, 16664, 19257, 37082, 12859}\n",
      "dict_items([(\"Lemma('dig.v.01.dig')\", 2), (\"Lemma('dig.v.02.dig')\", 2)])\n",
      "collecting tokens for  steadily\n",
      "indices:    {26979, 14246, 18534, 13000, 33788, 33742, 33616, 11925, 29078, 8536, 30425, 12859, 30972, 32318}\n",
      "dict_items([(\"Lemma('steadily.r.01.steadily')\", 6)])\n",
      "collecting tokens for  troops\n",
      "indices:    {12885}\n",
      "dict_items([])\n",
      "collecting tokens for  capitalism\n",
      "indices:    {6689, 14201}\n",
      "dict_items([(\"Lemma('capitalism.n.01.capitalism')\", 2)])\n",
      "collecting tokens for  society\n",
      "indices:    {26761, 14596}\n",
      "dict_items([(\"Lemma('society.n.01.society')\", 1)])\n",
      "collecting tokens for  eisenhower\n",
      "indices:    {24970}\n",
      "dict_items([])\n",
      "collecting tokens for  speech\n",
      "indices:    {25730, 7300, 10628, 30215, 2187, 6283, 17677, 20494, 9359, 30226, 20244, 34841, 27299, 30244, 31014, 10279, 14508, 10289, 6580, 13108, 24117, 33720, 20409, 15417, 20800, 24649, 22859, 34891, 24655, 16081, 24658, 14418, 22106, 19553, 5346, 5348, 31332, 22886, 26861, 10222, 12530, 29944, 29945, 25726}\n",
      "dict_items([(\"Lemma('address.n.03.speech')\", 8), (\"Lemma('speech.n.02.speech')\", 7), (\"Lemma('manner_of_speaking.n.01.speech')\", 1), (\"Lemma('lecture.n.02.speech')\", 1)])\n",
      "collecting tokens for  elder\n",
      "indices:    {23314, 6093}\n",
      "dict_items([])\n",
      "collecting tokens for  heap\n",
      "indices:    {12192, 26854, 10952, 35433, 12618, 35442, 33461, 33495, 14328, 9337, 9470}\n",
      "dict_items([(\"Lemma('pile.n.01.heap')\", 4), (\"Lemma('batch.n.02.heap')\", 1)])\n",
      "collecting tokens for  contrast\n",
      "indices:    {5377, 9858, 34296, 16010, 16012, 27801, 14617, 12198, 7342, 4148, 1467, 3903, 703, 13635, 33246, 15712, 16108, 14712, 5371, 5240}\n",
      "dict_items([(\"Lemma('contrast.n.01.contrast')\", 7), (\"Lemma('contrast.n.02.contrast')\", 4), (\"Lemma('contrast.n.04.contrast')\", 2), (\"Lemma('contrast.v.01.contrast')\", 1), (\"Lemma('line.n.29.contrast')\", 1)])\n",
      "collecting tokens for  mcbride\n",
      "indices:    {17926}\n",
      "dict_items([])\n",
      "collecting tokens for  reception\n",
      "indices:    {21057, 5794, 483, 15143, 24106, 27659, 14095, 22550, 21046, 27609}\n",
      "dict_items([(\"Lemma('reception.n.01.reception')\", 1), (\"Lemma('reception.n.03.reception')\", 1)])\n",
      "collecting tokens for  climax\n",
      "indices:    {8704, 27652, 13862, 32073, 30826, 12043, 9586, 30903, 30814}\n",
      "dict_items([(\"Lemma('culminate.v.01.climax')\", 1), (\"Lemma('climax.n.01.climax')\", 2), (\"Lemma('orgasm.n.01.climax')\", 1), (\"Lemma('climax.n.02.climax')\", 1)])\n",
      "collecting tokens for  grown\n",
      "indices:    {11011, 25732, 8974, 7058, 36514, 24227, 14245, 3622, 10029, 17709, 9265, 34876, 34882, 36419, 27330, 5701, 17350, 21835, 28619, 27733, 16598, 31960, 30425, 4699, 16224, 26341, 9576, 25337, 36986, 35197}\n",
      "dict_items([(\"Lemma('grow.v.02.grow')\", 5), (\"Lemma('grow.v.07.grow')\", 3), (\"Lemma('turn.v.07.grow')\", 8), (\"Lemma('originate.v.01.grow')\", 1), (\"Lemma('grow.v.04.grow')\", 1), (\"Lemma('adult.s.01.grown')\", 2), (\"Lemma('grow.v.03.grow')\", 2), (\"Lemma('grow.v.08.grow')\", 1)])\n",
      "collecting tokens for  reckless\n",
      "indices:    {21385, 33871, 21392, 21328, 7697, 18426, 27452, 23807}\n",
      "dict_items([(\"Lemma('foolhardy.s.01.reckless')\", 2)])\n",
      "collecting tokens for  illustrate\n",
      "indices:    {14085, 4421, 36999, 26349, 22671, 32915, 4884, 1044, 14423, 24761, 13308, 3485, 4254, 15935}\n",
      "dict_items([(\"Lemma('exemplify.v.02.illustrate')\", 14)])\n",
      "collecting tokens for  retrieved\n",
      "indices:    {15872, 15938, 26499, 15944, 15883, 15884, 34068, 15934, 15935}\n",
      "dict_items([(\"Lemma('recover.v.01.retrieve')\", 9)])\n",
      "collecting tokens for  dictionary\n",
      "indices:    {15882}\n",
      "dict_items([(\"Lemma('dictionary.n.01.dictionary')\", 1)])\n",
      "collecting tokens for  attached\n",
      "indices:    {20108, 33429, 3357, 4391, 13997, 32948, 33338, 31035, 3260, 15935, 2117, 15565, 21711, 2897, 2899, 15956, 2914, 17134, 34289, 6772, 34423, 35704}\n",
      "dict_items([(\"Lemma('attach.v.02.attach')\", 3), (\"Lemma('attach.v.01.attach')\", 9), (\"Lemma('attach.v.03.attach')\", 1), (\"Lemma('affiliated.s.01.attached')\", 1)])\n",
      "collecting tokens for  text\n",
      "indices:    {15878, 15880, 15881, 15934, 15883, 15915, 15916, 15882, 25972, 1269, 15926, 25975, 15898, 27196, 26174, 14943}\n",
      "dict_items([(\"Lemma('text.n.01.text')\", 12)])\n",
      "collecting tokens for  aspect\n",
      "indices:    {2691, 4739, 30084, 4742, 24583, 5393, 33042, 29329, 29076, 30744, 23579, 32028, 36003, 22696, 22698, 34736, 14643, 26430, 31806, 15680, 28747, 33107, 11263, 26332, 16221, 16220, 11101, 27996, 15841, 15714, 15842, 1513, 4714, 14575, 22387, 25979, 14207}\n",
      "dict_items([(\"Lemma('aspect.n.02.aspect')\", 4), (\"Lemma('aspect.n.01.aspect')\", 12), (\"Lemma('view.n.02.aspect')\", 1)])\n",
      "collecting tokens for  obvious\n",
      "indices:    {7169, 32134, 27529, 30220, 26893, 32788, 29719, 22938, 2588, 24732, 12958, 22431, 28448, 1316, 16420, 14630, 26792, 3498, 3118, 32431, 22779, 2991, 9778, 14130, 16052, 3122, 32435, 22708, 9144, 22713, 17598, 9790, 17214, 30783, 33086, 30023, 14919, 26057, 28490, 30797, 35661, 25423, 1746, 16210, 27733, 16221, 26078, 35681, 23524, 1125, 26598, 32359, 5096, 16358, 15998, 24811, 14700, 31215, 1776, 377, 16122, 34683, 15996, 4350}\n",
      "dict_items([(\"Lemma('obvious.a.01.obvious')\", 23)])\n",
      "collecting tokens for  external\n",
      "indices:    {24148, 1236, 32141, 31215}\n",
      "dict_items([(\"Lemma('external.a.01.external')\", 1)])\n",
      "collecting tokens for  classification\n",
      "indices:    {32704, 12968, 15951, 15343, 15313, 15314, 24884, 15316, 15320, 3896, 16217, 2171, 16221, 15326}\n",
      "dict_items([(\"Lemma('categorization.n.03.classification')\", 7), (\"Lemma('classification.n.02.classification')\", 5)])\n",
      "collecting tokens for  athabascan\n",
      "indices:    {16157}\n",
      "dict_items([(\"Lemma('athapaskan.n.02.Athabascan')\", 1)])\n",
      "collecting tokens for  yokuts\n",
      "indices:    {16157}\n",
      "dict_items([(\"Lemma('mariposan.n.01.Yokuts')\", 1)])\n",
      "collecting tokens for  ardent\n",
      "indices:    {9995}\n",
      "dict_items([])\n",
      "collecting tokens for  nude\n",
      "indices:    {30828, 30886}\n",
      "dict_items([])\n",
      "collecting tokens for  honest\n",
      "indices:    {24327, 779, 13974, 30617, 17946, 1188, 8229, 2357, 37047, 20919, 1338, 8130, 5322, 19019, 32083, 33494, 20451, 28265, 15225, 27261}\n",
      "dict_items([(\"Lemma('honest.s.02.honest')\", 3), (\"Lemma('honest.a.01.honest')\", 6), (\"Lemma('dependable.s.02.honest')\", 1)])\n",
      "collecting tokens for  beauty\n",
      "indices:    {29039}\n",
      "dict_items([])\n",
      "collecting tokens for  mud\n",
      "indices:    {7168, 7554, 35845, 19467, 14350, 8590, 18195, 7195, 7841, 31522, 37028, 13606, 2214, 13608, 30377, 27051, 33848, 329, 7133, 37094, 18028, 8557, 18675, 13047, 33787, 7551}\n",
      "dict_items([(\"Lemma('mud.n.01.mud')\", 16)])\n",
      "collecting tokens for  prospect\n",
      "indices:    {22881, 7202, 24900, 28964, 23431, 28969, 5130, 15722, 16300, 11344, 23379, 20662, 8246, 26842, 24894, 23391}\n",
      "dict_items([(\"Lemma('prospect.n.01.prospect')\", 4), (\"Lemma('expectation.n.01.prospect')\", 2)])\n",
      "collecting tokens for  alien\n",
      "indices:    {25665, 8867, 15560, 34608, 13939, 36436, 6390, 36022, 34682, 26842, 14651, 34558, 6047}\n",
      "dict_items([(\"Lemma('alien.s.02.alien')\", 2), (\"Lemma('foreigner.n.01.alien')\", 1), (\"Lemma('alien.s.01.alien')\", 3)])\n",
      "collecting tokens for  vessel\n",
      "indices:    {22048, 8578, 10149, 3814, 3440, 3793, 10262, 11384, 10265, 11388, 34431}\n",
      "dict_items([(\"Lemma('vessel.n.01.vessel')\", 2), (\"Lemma('vessel.n.02.vessel')\", 5)])\n",
      "collecting tokens for  lung\n",
      "indices:    {3777, 3841, 4073, 3789, 3855, 11376, 3823, 11378, 2261, 14070, 3767, 3774}\n",
      "dict_items([(\"Lemma('lung.n.01.lung')\", 12)])\n",
      "collecting tokens for  geely\n",
      "indices:    {33973}\n",
      "dict_items([])\n",
      "collecting tokens for  harris\n",
      "indices:    {21890}\n",
      "dict_items([])\n",
      "collecting tokens for  maps\n",
      "indices:    {32513, 32514, 31329, 29201, 27569, 1819, 12348, 1822}\n",
      "dict_items([(\"Lemma('map.n.01.map')\", 3)])\n",
      "collecting tokens for  region\n",
      "indices:    {3205, 2823, 6030, 7822, 3738, 3875, 27049, 10676, 2743, 29240, 31805, 24406, 14808, 13792, 3571, 2931, 24053, 2934, 3575, 3321}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('region.n.01.region')\", 14), (\"Lemma('area.n.03.region')\", 1)])\n",
      "collecting tokens for  changed\n",
      "indices:    {6912, 30977, 5505, 22276, 27780, 4870, 13700, 31370, 28302, 24080, 29201, 21266, 34835, 32918, 34583, 27544, 11160, 31386, 5275, 29341, 27165, 29343, 25120, 15005, 13695, 33322, 9775, 7472, 9650, 33206, 20279, 3895, 31806, 15422, 2625, 20040, 5449, 14026, 11210, 34889, 9935, 16464, 30417, 30416, 11860, 6869, 1368, 22361, 24794, 24156, 36445, 12266, 19055, 5617, 36082, 2931, 31350, 32759, 34681, 29051, 22396, 6909, 27775}\n",
      "dict_items([(\"Lemma('change.v.02.change')\", 26), (\"Lemma('change.v.01.change')\", 21), (\"Lemma('change.v.03.change')\", 5), (\"Lemma('transfer.v.06.change')\", 1), (\"Lemma('changed.a.01.changed')\", 2), (\"Lemma('change.v.05.change')\", 3), (\"Lemma('exchange.v.01.change')\", 2), (\"Lemma('change.v.06.change')\", 1), (\"Lemma('changed.s.02.changed')\", 1)])\n",
      "collecting tokens for  burned\n",
      "indices:    {34049, 7044, 35588, 28169, 29201, 7058, 12188, 34975, 2219, 21677, 16941, 21170, 36152, 25275, 18109, 7758, 5072, 5201, 18771, 19157, 6998, 21343, 27239, 5099, 26607}\n",
      "dict_items([(\"Lemma('sunburn.v.01.burn')\", 1), (\"Lemma('burn.v.01.burn')\", 5), (\"Lemma('burn.v.03.burn')\", 1), (\"Lemma('burn.v.08.burn')\", 1), (\"Lemma('burn.v.02.burn')\", 4), (\"Lemma('bite.v.02.burn')\", 2), (\"Lemma('burn.v.07.burn')\", 1), (\"Lemma('burn.v.05.burn')\", 2)])\n",
      "collecting tokens for  elsewhere\n",
      "indices:    {14859, 7948, 25484, 29201, 16401, 16273, 11799, 31514, 2459, 16285, 22687, 13227, 26155, 16301, 24626, 16309, 25403, 22717, 25034, 4686, 2511, 3544, 14681, 22747, 27742, 31847, 23656, 27765}\n",
      "dict_items([(\"Lemma('elsewhere.r.01.elsewhere')\", 14)])\n",
      "collecting tokens for  names\n",
      "indices:    {34050, 7959, 31129, 24218, 669, 2462, 25908, 33974, 25659, 1342, 31167, 7360, 7368, 4431, 26704, 23133, 17375, 29921, 34920, 6000, 10610, 31097, 26749}\n",
      "dict_items([(\"Lemma('name.n.01.name')\", 9), (\"Lemma('name.n.02.name')\", 1)])\n",
      "collecting tokens for  owen\n",
      "indices:    {36673}\n",
      "dict_items([])\n",
      "collecting tokens for  shows\n",
      "indices:    {29953, 33538, 772, 773, 4999, 12300, 15121, 27153, 22420, 25109, 27931, 2972, 28957, 16157, 30879, 5536, 11425, 15008, 25761, 14372, 28575, 23850, 1198, 13233, 28594, 29363, 14643, 3895, 28602, 32315, 14397, 28606, 28991, 27968, 9921, 3905, 28613, 26699, 24653, 29007, 21584, 2389, 29271, 29021, 26206, 32351, 15584, 37089, 4320, 26334, 4452, 23397, 28646, 3301, 4455, 29669, 30823, 998, 2286, 26734, 23408, 4849, 28530, 15857, 4851, 3707, 26492, 28157, 26751}\n",
      "dict_items([(\"Lemma('prove.v.02.show')\", 10), (\"Lemma('show.v.01.show')\", 15), (\"Lemma('show.v.04.show')\", 2), (\"Lemma('testify.v.02.show')\", 10), (\"Lemma('show.n.01.show')\", 4), (\"Lemma('picture.v.02.show')\", 1), (\"Lemma('indicate.v.02.show')\", 3), (\"Lemma('read.v.08.show')\", 1)])\n",
      "collecting tokens for  laws\n",
      "indices:    {22785, 22786, 20332, 28685, 20337, 11484}\n",
      "dict_items([(\"Lemma('law.n.04.law')\", 1)])\n",
      "collecting tokens for  inspector\n",
      "indices:    {17345, 2282, 17402}\n",
      "dict_items([(\"Lemma('inspector.n.01.inspector')\", 2)])\n",
      "collecting tokens for  declined\n",
      "indices:    {17414, 28006, 7302, 20492, 22832, 21457, 21905, 29139, 18872, 21914, 12252}\n",
      "dict_items([(\"Lemma('worsen.v.01.decline')\", 2), (\"Lemma('refuse.v.02.decline')\", 4), (\"Lemma('decline.v.04.decline')\", 1), (\"Lemma('refuse.v.01.decline')\", 4)])\n",
      "collecting tokens for  experienced\n",
      "indices:    {33152, 23554, 8, 3721, 1288, 36491, 32904, 23183, 16273, 8723, 29973, 2072, 25498, 3234, 1827, 19319, 27767, 16058, 29126, 30407, 32207, 2256, 33232, 24531, 12373, 33238, 12380, 11620, 33132, 20845, 33135, 13808, 9204, 30839, 15737, 10623}\n",
      "dict_items([(\"Lemma('experience.v.03.experience')\", 2), (\"Lemma('experienced.a.01.experienced')\", 10), (\"Lemma('know.v.05.experience')\", 4), (\"Lemma('experience.v.01.experience')\", 8), (\"Lemma('feel.v.01.experience')\", 3)])\n",
      "collecting tokens for  continually\n",
      "indices:    {7313, 5781, 10651, 30749, 9633, 27307, 28848, 26561, 26822, 2125, 24781, 14672, 10833, 27859, 4951, 27875, 4712, 13416, 13686, 31350}\n",
      "dict_items([(\"Lemma('continually.r.01.continually')\", 11)])\n",
      "collecting tokens for  rendered\n",
      "indices:    {5378, 32454, 32743, 21671, 14854, 14859, 5392, 9777, 13618, 27859, 3827, 25333, 32561, 27896, 15642, 32888, 5373}\n",
      "dict_items([(\"Lemma('supply.v.01.render')\", 8), (\"Lemma('render.v.01.render')\", 6), (\"Lemma('render.v.04.render')\", 1), (\"Lemma('interpret.v.03.render')\", 2)])\n",
      "collecting tokens for  qualify\n",
      "indices:    {4420, 2758, 28614, 11819, 25648, 21810, 24947, 27859, 21972, 28595, 26457, 29050, 24893, 15614}\n",
      "dict_items([(\"Lemma('qualify.v.01.qualify')\", 12), (\"Lemma('qualify.v.02.qualify')\", 2)])\n",
      "collecting tokens for  springs\n",
      "indices:    {34210, 31021, 32861, 10470}\n",
      "dict_items([(\"Lemma('spring.n.03.spring')\", 1), (\"Lemma('form.v.03.spring')\", 1)])\n",
      "collecting tokens for  quaint\n",
      "indices:    {1248, 2529, 13025, 19459, 29248, 30887, 36464, 2356, 36887, 34203}\n",
      "dict_items([(\"Lemma('quaint.s.01.quaint')\", 2)])\n",
      "collecting tokens for  coast\n",
      "indices:    {124}\n",
      "dict_items([])\n",
      "collecting tokens for  tourist\n",
      "indices:    {29267, 29347}\n",
      "dict_items([])\n",
      "collecting tokens for  attractions\n",
      "indices:    {1888, 1890, 29989, 26503, 13648, 34203, 11484, 29278}\n",
      "dict_items([(\"Lemma('attraction.n.02.attraction')\", 2), (\"Lemma('attraction.n.01.attraction')\", 1)])\n",
      "collecting tokens for  banks\n",
      "indices:    {11904, 5440, 29698, 99, 19241, 16565}\n",
      "dict_items([(\"Lemma('depository_financial_institution.n.01.bank')\", 2), (\"Lemma('bank.n.03.bank')\", 1), (\"Lemma('bank.n.01.bank')\", 1), (\"Lemma('bank.v.01.bank')\", 1)])\n",
      "collecting tokens for  cooperatives\n",
      "indices:    {2779}\n",
      "dict_items([])\n",
      "collecting tokens for  farm\n",
      "indices:    {8870, 21993, 19217, 25554, 4604, 33820, 28415}\n",
      "dict_items([(\"Lemma('farm.n.01.farm')\", 1)])\n",
      "collecting tokens for  1933\n",
      "indices:    {27075, 32643, 22788, 31623, 12751, 33010, 2775, 2779}\n",
      "dict_items([])\n",
      "collecting tokens for  attitudes\n",
      "indices:    {13184, 7556, 28166, 33294, 8865, 4642, 4899, 13355, 15404, 16311, 16068, 12615, 2512, 32978, 27091, 27865, 15450, 27872, 28001, 32107, 26733, 11246, 30830, 11890, 33144, 2299, 14332, 27775}\n",
      "dict_items([(\"Lemma('attitude.n.01.attitude')\", 14), (\"Lemma('position.n.04.attitude')\", 2)])\n",
      "collecting tokens for  circumstances\n",
      "indices:    {11104, 2530, 4741, 4870, 20233, 37002, 30285, 15281, 13715, 7487}\n",
      "dict_items([(\"Lemma('context.n.02.circumstance')\", 1), (\"Lemma('circumstance.n.01.circumstance')\", 5)])\n",
      "collecting tokens for  stands\n",
      "indices:    {260, 2694, 24845, 29974, 25376, 9633, 19494, 19372, 17580, 37168, 1593, 20412, 13526, 15574, 13529, 869, 5221, 30439, 27109, 24806, 27115, 31853, 8687, 26360, 13947, 20605}\n",
      "dict_items([(\"Lemma('stand.v.02.stand')\", 6), (\"Lemma('stand.v.03.stand')\", 5), (\"Lemma('stand.v.06.stand')\", 2), (\"Lemma('stand.v.01.stand')\", 4), (\"Lemma('stand.n.04.stand')\", 1), (\"Lemma('stand.v.04.stand')\", 1)])\n",
      "collecting tokens for  honor\n",
      "indices:    {21570, 27269, 5320, 21034, 32240, 26871}\n",
      "dict_items([(\"Lemma('award.n.02.honor')\", 1)])\n",
      "collecting tokens for  item\n",
      "indices:    {34305, 31122, 7830, 16155, 26397, 16158, 10657, 31138, 31137, 15021, 15023, 15027, 55, 15672, 15417, 15034, 15033, 15035, 15037, 15039, 15040, 15041, 15042, 15044, 26194, 15060, 15062, 10712, 15064, 15066, 19036, 15070, 26987, 26611}\n",
      "dict_items([(\"Lemma('item.n.01.item')\", 19), (\"Lemma('item.n.03.item')\", 4), (\"Lemma('detail.n.02.item')\", 2), (\"Lemma('detail.n.01.item')\", 1)])\n",
      "collecting tokens for  50\n",
      "indices:    {21512, 22026, 3597, 4126, 21548, 32301, 4149, 60, 4164, 4168, 4172, 3150, 29265, 29778, 26727, 28778, 28791, 26744, 28802, 25735, 28809, 3727, 15002, 15003, 3748, 25764, 15021, 15022, 3253, 20155, 15052, 32469, 13021, 15070, 2272, 3810, 21737, 3821, 3822, 30959, 27382, 20214, 28416, 11523, 2822, 15623, 15116, 11533, 25358, 12568, 11544, 27418, 11546, 2844, 25375, 23334, 3372, 23344, 2865, 819, 11587, 835, 21318, 25414, 25416, 25423, 23890, 22359, 2904, 23899, 2920, 28526, 22383, 25970, 1398, 24964, 24980, 6037, 5528, 29105, 21937, 21939, 32195, 15302, 15317, 21984, 28649, 21994, 30197}\n",
      "dict_items([(\"Lemma('fifty.s.01.50')\", 26), (\"Lemma('fifty.n.01.50')\", 4)])\n",
      "collecting tokens for  70\n",
      "indices:    {14848, 29313, 26625, 24448, 24449, 11909, 25220, 20365, 3728, 11536, 11538, 16163, 22951, 21932, 11182, 20271, 27066, 11584, 22857, 20172, 3277, 26708, 26709, 32731, 15068, 15070, 21604, 23144}\n",
      "dict_items([(\"Lemma('seventy.s.01.70')\", 9), (\"Lemma('seventy.n.01.70')\", 1)])\n",
      "collecting tokens for  magnitude\n",
      "indices:    {3336, 23820, 27919, 15254, 27931, 3367, 14760, 3370, 3375, 3378, 3379, 3382, 3383, 12228, 16085, 3160, 3162, 3294, 3319, 16383}\n",
      "dict_items([(\"Lemma('magnitude.n.01.magnitude')\", 12), (\"Lemma('magnitude.n.03.magnitude')\", 1)])\n",
      "collecting tokens for  phases\n",
      "indices:    {32482, 32324, 25349, 3238, 14760, 11688, 21898, 3273, 32509, 27629, 11758, 3216, 26770, 2067, 2836, 27611, 28893, 11870}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('phase.n.02.phase')\", 3), (\"Lemma('phase.n.01.phase')\", 6)])\n",
      "collecting tokens for  mines\n",
      "indices:    {5804}\n",
      "dict_items([(\"Lemma('mine.n.02.mine')\", 1)])\n",
      "collecting tokens for  excluding\n",
      "indices:    {14755, 14760, 14761, 14764, 15501, 15502, 32525, 3858, 32434, 32407, 22874, 12318}\n",
      "dict_items([(\"Lemma('exclude.v.01.exclude')\", 10), (\"Lemma('exclude.v.03.exclude')\", 1), (\"Lemma('exclude.v.02.exclude')\", 1)])\n",
      "collecting tokens for  scope\n",
      "indices:    {9345, 11911, 22666, 32523, 1808, 13842, 33050, 30365, 15518, 15523, 16421, 14760, 16168, 32950, 4922, 15681, 969, 11221, 16219, 32225, 26212, 4214, 31871}\n",
      "dict_items([(\"Lemma('scope.n.01.scope')\", 15)])\n",
      "collecting tokens for  applicable\n",
      "indices:    {16322, 14244, 14760, 14815, 31115, 34733, 34382, 16401, 33009, 16433, 23828, 25082, 31135}\n",
      "dict_items([(\"Lemma('applicable.s.01.applicable')\", 6)])\n",
      "collecting tokens for  enforcement\n",
      "indices:    {20384, 23717, 14758, 14760, 25039, 20336, 15281, 15282, 20339, 28693, 20437, 25046, 4725, 25045}\n",
      "dict_items([(\"Lemma('enforcement.n.01.enforcement')\", 3)])\n",
      "collecting tokens for  interference\n",
      "indices:    {22821, 14989, 304, 16402, 850, 22803, 13684, 32146, 2812, 30813, 18366}\n",
      "dict_items([(\"Lemma('intervention.n.02.interference')\", 3), (\"Lemma('noise.n.03.interference')\", 1), (\"Lemma('hindrance.n.03.interference')\", 2), (\"Lemma('interference.n.04.interference')\", 1)])\n",
      "collecting tokens for  article\n",
      "indices:    {25186}\n",
      "dict_items([])\n",
      "collecting tokens for  artificial\n",
      "indices:    {10470, 26636, 3406, 14415, 15824, 22737, 5422, 22803, 26358, 12313, 2554, 28637, 36318}\n",
      "dict_items([(\"Lemma('artificial.a.01.artificial')\", 4), (\"Lemma('artificial.s.02.artificial')\", 2)])\n",
      "collecting tokens for  presents\n",
      "indices:    {11905, 3715, 24069, 1159, 20999, 26761, 27791, 29329, 26770, 1177, 16045, 1328, 2482, 1202, 1719, 16188, 9538, 27853, 16333, 1121, 31852, 1138, 14324, 25977}\n",
      "dict_items([(\"Lemma('present.v.05.present')\", 3), (\"Lemma('present.v.02.present')\", 6), (\"Lemma('give.v.08.present')\", 1), (\"Lemma('stage.v.01.present')\", 6), (\"Lemma('present.v.04.present')\", 1), (\"Lemma('show.v.01.present')\", 6), (\"Lemma('present.n.02.present')\", 1)])\n",
      "collecting tokens for  joe\n",
      "indices:    {9204}\n",
      "dict_items([])\n",
      "collecting tokens for  wells\n",
      "indices:    {28634, 19470, 22175}\n",
      "dict_items([])\n",
      "collecting tokens for  chewing\n",
      "indices:    {31013, 35435, 17676, 10317, 30484, 15422, 17087}\n",
      "dict_items([(\"Lemma('chew.v.01.chew')\", 2), (\"Lemma('chew_over.v.01.chew_over')\", 1)])\n",
      "collecting tokens for  food\n",
      "indices:    {11654, 30475, 30497, 31010, 27174, 4265, 34732, 23983, 23217, 30394, 3395, 21069, 25554, 27227, 3425, 24546, 5606, 33521, 27252}\n",
      "dict_items([(\"Lemma('food.n.01.food')\", 5)])\n",
      "collecting tokens for  burden\n",
      "indices:    {30338, 12547, 26506, 24970, 24335, 16, 15386, 24220, 31012, 24484, 13737, 25257, 12094, 27715, 25037, 26965, 25304, 25564, 22110, 26848, 36201, 32618, 11115, 5487, 34161}\n",
      "dict_items([(\"Lemma('burden.n.01.burden')\", 6), (\"Lemma('load.n.01.burden')\", 1)])\n",
      "collecting tokens for  locker\n",
      "indices:    {23072, 23044, 23048, 19913, 19914, 19151, 16569, 8698}\n",
      "dict_items([(\"Lemma('cabinet.n.03.locker')\", 4)])\n",
      "collecting tokens for  shut\n",
      "indices:    {33729, 17604, 18495, 13542, 11179, 31474, 9138, 19506, 17563, 30173, 8735}\n",
      "dict_items([(\"Lemma('shut.a.01.shut')\", 4), (\"Lemma('close.v.02.shut')\", 1), (\"Lemma('close.v.01.shut')\", 2)])\n",
      "collecting tokens for  spun\n",
      "indices:    {35428, 19113, 19914, 19820, 18834, 21332, 8598, 19800, 6334, 10527}\n",
      "dict_items([(\"Lemma('spin.v.01.spin')\", 6), (\"Lemma('spin.v.02.spin')\", 1)])\n",
      "collecting tokens for  sold\n",
      "indices:    {24710, 19214, 8466, 7198, 21791, 22048, 21798, 2214, 2217, 31530, 21803, 35887, 11824, 14515, 12853, 34231, 21305, 19516, 24636, 20933, 19530, 21835, 19532, 6104, 32729, 2268, 21982, 21983, 10337, 2278, 9319, 21992, 15088, 20340, 22004}\n",
      "dict_items([(\"Lemma('sell.v.01.sell')\", 26), (\"Lemma('sell.v.03.sell')\", 1), (\"Lemma('sell.v.02.sell')\", 2)])\n",
      "collecting tokens for  various\n",
      "indices:    {34691, 3416, 33093, 27433, 15402, 3609, 25231, 28855, 5560, 3065, 21242, 4604, 2749}\n",
      "dict_items([(\"Lemma('diverse.s.02.various')\", 2), (\"Lemma('assorted.s.02.various')\", 1), (\"Lemma('respective.s.01.various')\", 4)])\n",
      "collecting tokens for  sizes\n",
      "indices:    {29829, 3117, 15088, 24624, 28754, 5811, 3386, 3326}\n",
      "dict_items([(\"Lemma('size.n.01.size')\", 3), (\"Lemma('size.n.02.size')\", 2)])\n",
      "collecting tokens for  seldom\n",
      "indices:    {30081, 30620, 2334, 22687, 35756, 16556, 26417, 11963, 22716, 27210, 26187, 15825, 28501, 17879, 24538, 34534, 30823, 14059, 15088, 36982, 21369, 2298, 12027}\n",
      "dict_items([(\"Lemma('rarely.r.01.seldom')\", 9)])\n",
      "collecting tokens for  block\n",
      "indices:    {5380, 5381, 28934, 28933, 36101, 35721, 28941, 19858, 2969, 2975, 33952, 15137, 17827, 33956, 37029, 2980, 20649, 21165, 21169, 25012, 10170, 33467, 22721, 33985, 17602, 33475, 21189, 22218, 35787, 33483, 26829, 33998, 28750, 7376, 11356, 15072, 29795, 13546, 15211, 13550, 15088, 23152, 24178, 20596, 6389, 28661, 15092, 17535}\n",
      "dict_items([(\"Lemma('block.n.01.block')\", 9), (\"Lemma('block.n.02.block')\", 5), (\"Lemma('block.n.05.block')\", 1), (\"Lemma('barricade.v.01.block')\", 1), (\"Lemma('stop.v.03.block')\", 1)])\n",
      "collecting tokens for  shining\n",
      "indices:    {12577, 36646, 34318, 34831, 13264, 9809, 19570, 1011, 17717, 10581, 28631, 28028, 36095}\n",
      "dict_items([(\"Lemma('reflect.v.04.shine')\", 2), (\"Lemma('shine.v.02.shine')\", 3), (\"Lemma('shining.n.01.shining')\", 1), (\"Lemma('shining.s.01.shining')\", 1), (\"Lemma('glitter.v.01.shine')\", 1), (\"Lemma('glow.v.02.shine')\", 1)])\n",
      "collecting tokens for  dimly\n",
      "indices:    {17989}\n",
      "dict_items([(\"Lemma('dimly.r.01.dimly')\", 1)])\n",
      "collecting tokens for  charter\n",
      "indices:    {4751}\n",
      "dict_items([])\n",
      "collecting tokens for  textile\n",
      "indices:    {23461, 23481, 25852, 3165, 23487}\n",
      "dict_items([(\"Lemma('fabric.n.01.textile')\", 1)])\n",
      "collecting tokens for  imports\n",
      "indices:    {23488, 26178, 23459, 24580, 25636, 23464, 12522, 4622, 26324, 25652, 32150, 25655, 25823}\n",
      "dict_items([(\"Lemma('import.n.01.import')\", 2), (\"Lemma('import.v.01.import')\", 1)])\n",
      "collecting tokens for  arrest\n",
      "indices:    {16962, 21543, 20138, 9388, 19342, 19311, 21488, 5039, 20754, 25358, 21680, 19349, 21335, 36920, 36890, 5085, 15231}\n",
      "dict_items([(\"Lemma('apprehension.n.04.arrest')\", 4), (\"Lemma('catch.v.07.arrest')\", 1), (\"Lemma('check.v.18.arrest')\", 1), (\"Lemma('collar.v.01.arrest')\", 2)])\n",
      "collecting tokens for  sprawled\n",
      "indices:    {6336, 5603, 24292, 36358, 34185, 34123, 19342, 6351, 34524}\n",
      "dict_items([(\"Lemma('sprawl.v.01.sprawl')\", 3)])\n",
      "collecting tokens for  deck\n",
      "indices:    {26501, 30342, 19175, 19397, 1003, 18763, 29808, 17968, 19248}\n",
      "dict_items([(\"Lemma('deck.n.01.deck')\", 2), (\"Lemma('overdress.v.02.deck_out')\", 1), (\"Lemma('pack_of_cards.n.01.deck')\", 1)])\n",
      "collecting tokens for  terror\n",
      "indices:    {6907, 23253, 7959}\n",
      "dict_items([(\"Lemma('panic.n.01.terror')\", 2)])\n",
      "collecting tokens for  simms\n",
      "indices:    {21332}\n",
      "dict_items([])\n",
      "collecting tokens for  purdew\n",
      "indices:    {7157}\n",
      "dict_items([])\n",
      "collecting tokens for  adam\n",
      "indices:    {7184}\n",
      "dict_items([(\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  rep.\n",
      "indices:    {142}\n",
      "dict_items([])\n",
      "collecting tokens for  harry\n",
      "indices:    {21127}\n",
      "dict_items([])\n",
      "collecting tokens for  korean\n",
      "indices:    {12856}\n",
      "dict_items([])\n",
      "collecting tokens for  tonight\n",
      "indices:    {5768, 17700, 9949}\n",
      "dict_items([(\"Lemma('tonight.n.01.tonight')\", 1), (\"Lemma('tonight.r.01.tonight')\", 2)])\n",
      "collecting tokens for  doubtful\n",
      "indices:    {31137, 29416, 20104, 17549, 15535, 17329, 16403, 31987, 25753, 317, 18302, 5215}\n",
      "dict_items([(\"Lemma('doubtful.s.01.doubtful')\", 7), (\"Lemma('doubtful.s.02.doubtful')\", 1)])\n",
      "collecting tokens for  poll\n",
      "indices:    {24837, 134, 20807, 136, 20265, 2506, 2509, 21973}\n",
      "dict_items([(\"Lemma('poll.n.01.poll')\", 3)])\n",
      "collecting tokens for  majority\n",
      "indices:    {30979, 1796, 2183, 21641, 12297, 13708, 13710, 27282, 3608, 32537, 13213, 32929, 12324, 12325, 28071, 12328, 12327, 13356, 28717, 32559, 14130, 25021, 16063, 2496, 20421, 25158, 32586, 2508, 2509, 28494, 23902, 36963, 2533, 28009, 22890, 31210, 7788, 22894, 22895, 15218, 27768, 32377, 24831}\n",
      "dict_items([(\"Lemma('majority.n.01.majority')\", 16), (\"Lemma('majority.n.03.majority')\", 1), (\"Lemma('majority.n.02.majority')\", 3)])\n",
      "collecting tokens for  texans\n",
      "indices:    {339}\n",
      "dict_items([(\"Lemma('group.n.01.group')\", 1)])\n",
      "collecting tokens for  17\n",
      "indices:    {32641, 29960, 20745, 29323, 16269, 21391, 32656, 32657, 20761, 20763, 27163, 25123, 16167, 21799, 940, 12333, 5044, 3900, 26560, 26569, 26570, 23116, 27341, 28238, 15312, 3793, 3794, 342, 3926, 14940, 94, 15327, 28257, 12770, 26338, 32610, 21093, 25186, 622, 23032}\n",
      "dict_items([(\"Lemma('seventeenth.s.01.17th')\", 3), (\"Lemma('seventeen.s.01.17')\", 7), (\"Lemma('seventeen.n.01.17')\", 1)])\n",
      "collecting tokens for  elegance\n",
      "indices:    {13289, 26570, 26893, 26320, 29266, 18196, 26647, 14456, 29945}\n",
      "dict_items([(\"Lemma('elegance.n.01.elegance')\", 3)])\n",
      "collecting tokens for  prospects\n",
      "indices:    {26725, 4614, 22630, 21896, 17321, 4585, 2763, 21065, 22014, 23758, 27688, 21972, 9397, 24052, 12121, 22012, 21982}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('prospect.n.01.prospect')\", 5), (\"Lemma('candidate.n.02.prospect')\", 1)])\n",
      "collecting tokens for  tongue\n",
      "indices:    {30466, 2698, 35214, 10511, 36767, 24621, 6061, 10545, 8766, 36805, 17361, 36051, 10584, 10585, 10591, 10214, 10221, 36977, 29946, 4986}\n",
      "dict_items([(\"Lemma('natural_language.n.01.tongue')\", 3), (\"Lemma('tongue.n.01.tongue')\", 6)])\n",
      "collecting tokens for  delight\n",
      "indices:    {14474, 13578, 23190, 4888, 4889, 8866, 4902, 36520, 26426, 20029, 26564, 33231, 33233, 36946, 31572, 9575, 26098, 26871, 22269}\n",
      "dict_items([(\"Lemma('please.v.01.delight')\", 1), (\"Lemma('delight.n.01.delight')\", 8), (\"Lemma('delight.v.02.delight')\", 1)])\n",
      "collecting tokens for  killing\n",
      "indices:    {21345, 18247, 18409, 29053, 6897, 5042, 18264, 5078, 5783, 4888, 18489, 18234, 9660, 5085, 18270}\n",
      "dict_items([(\"Lemma('kill.v.01.kill')\", 4), (\"Lemma('killing.n.02.killing')\", 5), (\"Lemma('killing.n.01.killing')\", 5)])\n",
      "collecting tokens for  causing\n",
      "indices:    {34433, 3972, 3461, 4198, 2251, 3470, 27728, 24848, 29560, 27797, 1494, 16919, 4888, 1563, 15486}\n",
      "dict_items([(\"Lemma('cause.v.01.cause')\", 11), (\"Lemma('induce.v.02.cause')\", 4)])\n",
      "collecting tokens for  elected\n",
      "indices:    {25091, 20615, 25096, 19, 24598, 25375, 42, 5301, 16441, 37050, 21693, 26431, 20415, 74, 14155, 11339, 23247, 23888, 20448, 31716, 21741, 21744, 117}\n",
      "dict_items([(\"Lemma('elect.v.01.elect')\", 16), (\"Lemma('elective.a.01.elected')\", 3)])\n",
      "collecting tokens for  bridges\n",
      "indices:    {29955}\n",
      "dict_items([])\n",
      "collecting tokens for  technological\n",
      "indices:    {1312, 13536, 32130, 15520, 14150, 14187, 15510, 14839, 16342, 13534, 14174, 31231}\n",
      "dict_items([(\"Lemma('technological.s.01.technological')\", 6), (\"Lemma('technical.a.03.technological')\", 3)])\n",
      "collecting tokens for  provided\n",
      "indices:    {29267, 25740, 26975, 14855}\n",
      "dict_items([(\"Lemma('supply.v.01.provide')\", 2), (\"Lemma('put_up.v.02.provide')\", 1)])\n",
      "collecting tokens for  consultant\n",
      "indices:    {21760, 23553, 23557, 21767, 32456, 22283, 21521, 23543, 21527, 21753}\n",
      "dict_items([])\n",
      "collecting tokens for  seeking\n",
      "indices:    {31105, 23298, 26758, 23704, 22564, 28848, 20416, 23749, 30918, 5320, 12884, 10715, 5225, 4586, 31599, 32376, 21882, 23934, 31103}\n",
      "dict_items([(\"Lemma('search.v.01.seek')\", 6), (\"Lemma('seek.v.01.seek')\", 7), (\"Lemma('try.v.01.seek')\", 5)])\n",
      "collecting tokens for  businesses\n",
      "indices:    {2720, 2753, 21574, 11634, 14195, 5436}\n",
      "dict_items([(\"Lemma('business.n.01.business')\", 5)])\n",
      "collecting tokens for  apply\n",
      "indices:    {31873, 32390, 22024, 10633, 22026, 31114, 31116, 15757, 5003, 32399, 28688, 31118, 31123, 16279, 29981, 3372, 28853, 4542, 11712, 20932, 32456, 23166, 4431, 15569, 14293, 29783, 29784, 15959, 20315, 28893, 16095, 22627, 25961, 11373, 1649, 4729, 2301, 15230}\n",
      "dict_items([(\"Lemma('apply.v.02.apply')\", 11), (\"Lemma('apply.v.03.apply')\", 6), (\"Lemma('use.v.01.apply')\", 12), (\"Lemma('lend_oneself.v.01.apply')\", 1), (\"Lemma('enforce.v.01.apply')\", 1), (\"Lemma('put_on.v.07.apply')\", 4), (\"Lemma('apply.v.09.apply')\", 1), (\"Lemma('practice.v.04.apply')\", 1)])\n",
      "collecting tokens for  marks\n",
      "indices:    {16394, 21260, 28300, 34191, 16016, 24082, 31140, 21680, 15805, 1733, 24773, 32456, 4940, 31437, 19278, 18667, 10097, 32628, 30070, 32633}\n",
      "dict_items([(\"Lemma('distinguish.v.03.mark')\", 2), (\"Lemma('mark.v.02.mark')\", 4), (\"Lemma('marker.n.02.mark')\", 1), (\"Lemma('commemorate.v.01.mark')\", 2), (\"Lemma('tag.v.01.mark')\", 1)])\n",
      "collecting tokens for  availability\n",
      "indices:    {12321, 32456, 27883, 3949, 27922, 32755, 21236, 15519}\n",
      "dict_items([(\"Lemma('handiness.n.02.availability')\", 3)])\n",
      "collecting tokens for  trading\n",
      "indices:    {21797, 21800, 21933, 12473, 21916}\n",
      "dict_items([(\"Lemma('trade.v.03.trade')\", 1)])\n",
      "collecting tokens for  collected\n",
      "indices:    {3331, 3332, 26502, 25223, 25094, 13577, 22411, 8721, 5522, 5523, 22035, 5526, 22423, 21375, 5529, 2331, 29979, 33053, 27180, 3763, 15796, 3388, 30013, 4163, 5070, 32123, 32725, 3547, 12643, 32742, 21753, 21371, 26110, 13567}\n",
      "dict_items([(\"Lemma('collect.v.02.collect')\", 7), (\"Lemma('collect.v.04.collect')\", 6), (\"Lemma('roll_up.v.02.collect')\", 10), (\"Lemma('collect.v.05.collect')\", 1), (\"Lemma('gather.v.01.collect')\", 7)])\n",
      "collecting tokens for  passenger\n",
      "indices:    {23840, 14912, 25223, 25255, 23305, 25224, 32265, 32334, 32337, 20405, 24122, 29695}\n",
      "dict_items([(\"Lemma('passenger.n.01.passenger')\", 1)])\n",
      "collecting tokens for  station\n",
      "indices:    {20317}\n",
      "dict_items([])\n",
      "collecting tokens for  exceeds\n",
      "indices:    {15041, 25188, 16231, 2791, 2631, 3923, 14261, 14012}\n",
      "dict_items([(\"Lemma('exceed.v.01.exceed')\", 6), (\"Lemma('exceed.v.02.exceed')\", 2)])\n",
      "collecting tokens for  ringing\n",
      "indices:    {7376, 20883, 11403, 34501}\n",
      "dict_items([(\"Lemma('resound.v.01.ring')\", 2), (\"Lemma('ring.v.01.ring')\", 1)])\n",
      "collecting tokens for  falling\n",
      "indices:    {23935}\n",
      "dict_items([(\"Lemma('fall.v.04.fall')\", 1)])\n",
      "collecting tokens for  stability\n",
      "indices:    {4582, 3462, 32967, 8873, 2922, 23666, 14643, 32153}\n",
      "dict_items([(\"Lemma('stability.n.01.stability')\", 5)])\n",
      "collecting tokens for  organized\n",
      "indices:    {11265, 27009, 19332, 902, 21767, 22799, 32401, 29984, 4770, 5294, 25136, 13240, 13244, 36927, 22852, 4934, 20809, 4938, 30032, 31697, 32477, 23525, 14185, 10218, 26987, 4716, 28018, 33142, 16247, 23545}\n",
      "dict_items([(\"Lemma('organized.a.01.organized')\", 5), (\"Lemma('organize.v.02.organize')\", 2), (\"Lemma('organize.v.04.organize')\", 2), (\"Lemma('form.v.01.organize')\", 5), (\"Lemma('mastermind.v.01.organize')\", 2), (\"Lemma('organize.v.05.organize')\", 1), (\"Lemma('organized.a.02.organized')\", 2)])\n",
      "collecting tokens for  momentum\n",
      "indices:    {4576, 21890, 3377, 3351, 10745, 3354, 3355, 3356, 3358}\n",
      "dict_items([(\"Lemma('momentum.n.02.momentum')\", 2), (\"Lemma('momentum.n.01.momentum')\", 6)])\n",
      "collecting tokens for  sell\n",
      "indices:    {11266, 994, 21826, 11842, 23151, 19216, 10098, 12146, 5043, 12853, 12150, 34939, 988}\n",
      "dict_items([(\"Lemma('sell.v.01.sell')\", 7), (\"Lemma('sell.v.02.sell')\", 1), (\"Lemma('sell.v.03.sell')\", 2)])\n",
      "collecting tokens for  painter\n",
      "indices:    {31882, 19596, 19565, 11278, 2709, 33976, 25690}\n",
      "dict_items([(\"Lemma('painter.n.01.painter')\", 4)])\n",
      "collecting tokens for  studio\n",
      "indices:    {19555, 29539, 7562, 21586, 19541, 20919, 9785, 22142}\n",
      "dict_items([(\"Lemma('studio.n.01.studio')\", 4)])\n",
      "collecting tokens for  artists\n",
      "indices:    {19555, 2472, 26763, 1037, 19601, 21106}\n",
      "dict_items([(\"Lemma('artist.n.01.artist')\", 4)])\n",
      "collecting tokens for  talent\n",
      "indices:    {27653, 29191, 23179, 32653, 22290, 20884, 1046, 24728, 20890, 37036, 14637, 26414, 36145, 36146, 26689, 8259, 28355, 13258, 23120, 21586, 22997, 27613, 2654, 13797, 19944, 19945, 1147}\n",
      "dict_items([(\"Lemma('endowment.n.01.talent')\", 8), (\"Lemma('talent.n.02.talent')\", 1)])\n",
      "collecting tokens for  smile\n",
      "indices:    {8843, 20991, 37137, 1174, 10905, 16539, 31005, 35230, 18338, 18978, 5926, 16554, 8364, 18611, 31667, 10936, 17721, 17338, 36286, 35775, 17729, 37064, 19538, 17618, 24794, 16478, 26857, 13418, 10347, 16492, 31596, 28395, 8180, 16503, 33663}\n",
      "dict_items([(\"Lemma('smile.v.01.smile')\", 4), (\"Lemma('smile.n.01.smile')\", 19)])\n",
      "collecting tokens for  seek\n",
      "indices:    {28291, 5128, 24331, 31887, 33816, 22808, 23068, 23709, 23971, 12965, 33835, 23726, 28462, 20656, 20273, 25522, 21295, 25524, 19385, 4667, 829, 25023, 64, 24771, 14276, 32375, 24778, 1867, 17360, 20817, 24273, 14676, 469, 24148, 471, 11480, 27099, 28509, 27745, 4599, 229, 7910, 14696, 18029, 31088, 24821, 25335, 23289, 23674, 12923, 20477}\n",
      "dict_items([(\"Lemma('search.v.01.seek')\", 14), (\"Lemma('seek.v.01.seek')\", 20), (\"Lemma('try.v.01.seek')\", 10), (\"Lemma('seek_out.v.01.seek_out')\", 2)])\n",
      "collecting tokens for  specifically\n",
      "indices:    {29825, 34306, 2821, 27527, 1544, 14867, 23706, 32412, 16162, 30243, 15014, 28714, 27829, 24640, 4033, 71, 4175, 15056, 4184, 26076, 2654, 25323, 11511, 11897, 32383}\n",
      "dict_items([(\"Lemma('specifically.r.01.specifically')\", 13)])\n",
      "collecting tokens for  drunk\n",
      "indices:    {20102, 35244, 2610, 11128, 8087, 8088, 2681, 8188}\n",
      "dict_items([(\"Lemma('intoxicated.a.01.drunk')\", 3), (\"Lemma('drink.v.02.drink')\", 1), (\"Lemma('drunkard.n.01.drunk')\", 3)])\n",
      "collecting tokens for  presented\n",
      "indices:    {24961, 1026, 3842, 22149, 645, 31625, 20362, 2060, 11414, 15254, 1302, 21145, 25110, 2457, 1948, 26909, 21662, 32544, 928, 21666, 8872, 22824, 4907, 7597, 21039, 22072, 26810, 26427, 21052, 21180, 8513, 16323, 32708, 3528, 26318, 11134, 31831, 14681, 12251, 27612, 15709, 22492, 23777, 3042, 32740, 32741, 16742, 26345, 18538, 6377, 2673, 26354, 20723, 20722, 20854, 23672, 12666, 14331, 26366}\n",
      "dict_items([(\"Lemma('show.v.01.present')\", 21), (\"Lemma('stage.v.01.present')\", 6), (\"Lemma('deliver.v.01.present')\", 3), (\"Lemma('present.v.02.present')\", 9), (\"Lemma('present.v.04.present')\", 7), (\"Lemma('portray.v.04.present')\", 1), (\"Lemma('award.v.01.present')\", 3), (\"Lemma('introduce.v.01.present')\", 2), (\"Lemma('give.v.08.present')\", 1), (\"Lemma('present.v.05.present')\", 1)])\n",
      "collecting tokens for  administrator\n",
      "indices:    {14877, 23250, 21524, 17365}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('administrator.n.02.administrator')\", 2)])\n",
      "collecting tokens for  oliver\n",
      "indices:    {3732}\n",
      "dict_items([(\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  pratt\n",
      "indices:    {20700}\n",
      "dict_items([])\n",
      "collecting tokens for  notte\n",
      "indices:    {20328}\n",
      "dict_items([])\n",
      "collecting tokens for  cafeteria\n",
      "indices:    {5601, 5606, 11751, 11752, 11849, 22124, 21464, 11065}\n",
      "dict_items([(\"Lemma('cafeteria.n.01.cafeteria')\", 6)])\n",
      "collecting tokens for  lawyers\n",
      "indices:    {21760, 17377, 23174, 30952, 31209, 30953, 27850, 27312, 24144, 5236, 24692, 31190, 17335, 17332, 21278}\n",
      "dict_items([(\"Lemma('lawyer.n.01.lawyer')\", 4)])\n",
      "collecting tokens for  expanded\n",
      "indices:    {24738, 16295, 31209, 5388, 32173, 25485, 16304, 32370, 21844, 17750, 10615, 32310, 378, 29339, 20444}\n",
      "dict_items([(\"Lemma('inflate.v.01.expand')\", 2), (\"Lemma('expand.v.02.expand')\", 2), (\"Lemma('expanded.a.01.expanded')\", 3), (\"Lemma('expand.v.03.expand')\", 2), (\"Lemma('boom.v.05.expand')\", 1)])\n",
      "collecting tokens for  beethoven\n",
      "indices:    {26785}\n",
      "dict_items([])\n",
      "collecting tokens for  sensible\n",
      "indices:    {4899, 33571, 25255, 3721, 1033, 26801, 30002, 24658, 30033, 36090, 27133}\n",
      "dict_items([(\"Lemma('reasonable.a.01.sensible')\", 3)])\n",
      "collecting tokens for  serum\n",
      "indices:    {3511}\n",
      "dict_items([(\"Lemma('serum.n.01.serum')\", 1)])\n",
      "collecting tokens for  rpm\n",
      "indices:    {18800, 3524, 3525, 29766}\n",
      "dict_items([(\"Lemma('revolutions_per_minute.n.01.rpm')\", 3)])\n",
      "collecting tokens for  appeal\n",
      "indices:    {15360, 23177, 21641, 15370, 25868, 25869, 24617, 27311, 2355, 23092, 13880, 15292, 29117, 15294, 13901, 26837, 25814, 854, 15330, 15332, 5479, 7399, 15340, 15345, 15346, 2289, 15359}\n",
      "dict_items([(\"Lemma('appeal.n.02.appeal')\", 5), (\"Lemma('appeal.n.03.appeal')\", 4), (\"Lemma('entreaty.n.01.appeal')\", 2), (\"Lemma('appeal.v.01.appeal')\", 2), (\"Lemma('appeal.v.02.appeal')\", 1)])\n",
      "collecting tokens for  cardinal\n",
      "indices:    {595}\n",
      "dict_items([(\"Lemma('group.n.01.group')\", 1)])\n",
      "collecting tokens for  renewed\n",
      "indices:    {10657, 21446, 23975, 22279, 2215, 9575, 3147, 34576, 24112, 14996, 25463, 24572, 25471}\n",
      "dict_items([(\"Lemma('reincarnate.v.02.renew')\", 3), (\"Lemma('regenerate.v.01.renew')\", 5), (\"Lemma('renewed.s.01.renewed')\", 1)])\n",
      "collecting tokens for  eastern\n",
      "indices:    {20980}\n",
      "dict_items([])\n",
      "collecting tokens for  admit\n",
      "indices:    {13445, 19464, 35727, 10769, 36498, 6807, 25370, 11293, 27421, 35997, 9901, 9902, 26031, 25278, 24256, 33989, 7877, 13255, 14666, 17229, 31822, 31826, 25687, 7780, 18409, 1391, 23159, 27257, 27899}\n",
      "dict_items([(\"Lemma('admit.v.01.admit')\", 26), (\"Lemma('admit.v.02.admit')\", 3)])\n",
      "collecting tokens for  reporter\n",
      "indices:    {10625, 25921, 33987, 23044, 33989, 26371, 34000, 33938, 26675, 34041, 29946, 10620, 23039}\n",
      "dict_items([(\"Lemma('reporter.n.01.reporter')\", 2)])\n",
      "collecting tokens for  talked\n",
      "indices:    {20485, 20105, 12554, 20107, 34441, 5648, 9495, 8858, 30874, 412, 36128, 23332, 8236, 19503, 33333, 6070, 20150, 2617, 22585, 6841, 30012, 14526, 8256, 9283, 1608, 27135, 6093, 19542, 1114, 6618, 19548, 5598, 36845, 13039, 31601, 19321, 6139, 36732, 30847}\n",
      "dict_items([(\"Lemma('talk.v.02.talk')\", 4), (\"Lemma('talk.v.01.talk')\", 24), (\"Lemma('talk_into.v.01.talk_into')\", 4), (\"Lemma('spill.v.05.talk')\", 1)])\n",
      "collecting tokens for  absolutely\n",
      "indices:    {25211, 5260, 34590, 11295, 4907, 8879, 1336, 4923, 31310, 4946, 2644, 26197, 2652, 20193, 2658, 25446, 2407, 26098, 25464, 6139}\n",
      "dict_items([(\"Lemma('absolutely.r.01.absolutely')\", 12)])\n",
      "collecting tokens for  patterns\n",
      "indices:    {29440, 24577, 16014, 5008, 29587, 11286, 29594, 11291, 10141, 2846, 16035, 31909, 5030, 5031, 31913, 16042, 32945, 4274, 2614, 11325, 15806, 7878, 3912, 27978, 15963, 32988, 11744, 14690, 3561, 29549, 14701, 29679, 4979, 34675, 4985, 29436}\n",
      "dict_items([(\"Lemma('form.n.03.pattern')\", 13), (\"Lemma('design.n.04.pattern')\", 4), (\"Lemma('practice.n.01.pattern')\", 6)])\n",
      "collecting tokens for  authors\n",
      "indices:    {14592, 13854, 14368, 4907, 4908, 2864, 4914, 14390, 4920, 14392, 4923, 14399, 14400, 16322, 4930, 14415, 4954, 5211, 4958, 4960, 5220, 9584, 14708}\n",
      "dict_items([(\"Lemma('writer.n.01.author')\", 23)])\n",
      "collecting tokens for  progress\n",
      "indices:    {26211, 26859, 4973, 14320, 14161, 22611, 24406, 4604, 32223}\n",
      "dict_items([(\"Lemma('advancement.n.03.progress')\", 3), (\"Lemma('progress.n.03.progress')\", 1)])\n",
      "collecting tokens for  breakdown\n",
      "indices:    {31008, 22624, 12328, 12298, 171, 21228, 13613, 21231, 2255, 2256, 13329, 24820, 32988}\n",
      "dict_items([(\"Lemma('dislocation.n.02.breakdown')\", 5)])\n",
      "collecting tokens for  structure\n",
      "indices:    {3076, 3080, 3081, 35722, 3082, 14221, 29965, 3218, 6035, 4118, 14998, 4248, 33046, 14362, 22775, 15644, 11421, 15005, 15007, 31008, 3360, 29984, 11299, 4642, 25120, 15006, 20771, 31224, 29357, 8496, 3634, 29980, 27958, 32951, 26808, 27702, 24894, 32702, 31550, 27330, 3067, 27721, 14923, 23243, 27981, 27982, 26959, 30416, 14032, 15706, 11355, 1244, 15708, 1243, 22763, 15084, 3053, 29934, 3054, 2035, 14196, 31991, 28024, 3066, 2811, 2556, 4990}\n",
      "dict_items([(\"Lemma('structure.n.03.structure')\", 5), (\"Lemma('structure.n.02.structure')\", 13), (\"Lemma('structure.n.01.structure')\", 17), (\"Lemma('structure.n.04.structure')\", 2), (\"Lemma('structure.v.01.structure')\", 1)])\n",
      "collecting tokens for  supports\n",
      "indices:    {31008, 5473, 26819, 5764, 21990, 26822, 1865, 4684, 23988, 32858}\n",
      "dict_items([(\"Lemma('support.n.07.support')\", 1), (\"Lemma('subscribe.v.03.support')\", 2), (\"Lemma('hold.v.10.support')\", 2), (\"Lemma('support.v.01.support')\", 1), (\"Lemma('back.v.01.support')\", 1)])\n",
      "collecting tokens for  dot\n",
      "indices:    {18786, 26949, 30572, 21261, 3928, 3892, 34422, 3896, 3865}\n",
      "dict_items([(\"Lemma('point.n.09.dot')\", 5), (\"Lemma('dot.v.01.dot')\", 1)])\n",
      "collecting tokens for  supported\n",
      "indices:    {4738, 15368, 24970, 4754, 6041, 32026, 31772, 21405, 25762, 34468, 11184, 26164, 13116, 21437, 13244, 8639, 32704, 25026, 29378, 12361, 20298, 29390, 20435, 15701, 11990, 18269, 22879, 11495, 15466, 20461, 4718, 20721, 3828, 25982}\n",
      "dict_items([(\"Lemma('confirm.v.01.support')\", 3), (\"Lemma('support.v.01.support')\", 9), (\"Lemma('defend.v.01.support')\", 1), (\"Lemma('hold.v.10.support')\", 4), (\"Lemma('support.v.02.support')\", 6), (\"Lemma('back.v.01.support')\", 8)])\n",
      "collecting tokens for  differently\n",
      "indices:    {33221, 23527, 24524, 9997, 9175, 33235, 26164, 2198, 11254, 1335, 670}\n",
      "dict_items([(\"Lemma('differently.r.01.differently')\", 6)])\n",
      "collecting tokens for  municipalities\n",
      "indices:    {24897, 32582, 23590, 32618, 32396, 32559, 32368, 20464, 32597}\n",
      "dict_items([])\n",
      "collecting tokens for  difficulties\n",
      "indices:    {25474, 4866, 20233, 30241, 15395, 24996, 32679, 29992, 22570, 16045, 34735, 32433, 13365, 32570, 22210, 4931, 23621, 30795, 32844, 2893, 24526, 23763, 27734, 33111, 16088, 16095, 32618, 32625, 16114, 36596, 4607}\n",
      "dict_items([(\"Lemma('difficulty.n.03.difficulty')\", 6), (\"Lemma('difficulty.n.04.difficulty')\", 1), (\"Lemma('difficulty.n.02.difficulty')\", 2), (\"Lemma('trouble.n.04.difficulty')\", 1)])\n",
      "collecting tokens for  fiscal\n",
      "indices:    {32401, 32149, 32534, 14748, 32540, 32543, 32545, 32546, 32547, 32549, 32551, 32556, 32557, 15026, 32563, 32695, 32696, 32185, 32571, 15548, 15038, 15559, 32587, 23636, 32598, 32599, 32612, 32613, 15465, 24170, 32620, 31726, 24175}\n",
      "dict_items([])\n",
      "collecting tokens for  object\n",
      "indices:    {4865, 35974, 25354, 27530, 7562, 7569, 30355, 32918, 20504, 16028, 11295, 16043, 4913, 8114, 8115, 19253, 4925, 30789, 30791, 13512, 4936, 36941, 7119, 4945, 13651, 4947, 1235, 4950, 22873, 11101, 4960, 24547, 10728, 2156, 2413, 3188, 1396, 13815, 31866, 27903}\n",
      "dict_items([(\"Lemma('object.v.01.object')\", 8), (\"Lemma('object.n.01.object')\", 15), (\"Lemma('aim.n.02.object')\", 2), (\"Lemma('object.n.03.object')\", 2), (\"Lemma('object.n.04.object')\", 1)])\n",
      "collecting tokens for  india\n",
      "indices:    {32719}\n",
      "dict_items([])\n",
      "collecting tokens for  inhabitants\n",
      "indices:    {4993, 13763, 29315, 4997, 20615, 20560, 37040, 36340, 3643, 35996, 32382}\n",
      "dict_items([(\"Lemma('inhabitant.n.01.inhabitant')\", 4)])\n",
      "collecting tokens for  severely\n",
      "indices:    {24194, 15717, 12679, 12713, 15274, 27739, 12944, 15857, 16596, 20340, 3637, 16059}\n",
      "dict_items([(\"Lemma('badly.r.01.severely')\", 7), (\"Lemma('hard.r.04.severely')\", 1), (\"Lemma('sternly.r.01.severely')\", 1)])\n",
      "collecting tokens for  hardship\n",
      "indices:    {24257, 22689, 26053, 26021, 15274, 25902, 22227, 32312}\n",
      "dict_items([(\"Lemma('adversity.n.01.hardship')\", 1)])\n",
      "collecting tokens for  hundreds\n",
      "indices:    {9217, 31528, 22284, 21359, 24210, 2228, 12342, 2326, 2236, 30365, 28350}\n",
      "dict_items([(\"Lemma('hundred.n.01.hundred')\", 5)])\n",
      "collecting tokens for  innocent\n",
      "indices:    {30339, 10627, 21262, 26642, 15274, 36012, 8370, 21304, 25923, 14533, 12231, 19402, 19405, 19408, 19415, 7518, 19427, 19430, 6377, 19437, 19438, 25327, 36974, 36977}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('innocent.a.01.innocent')\", 11), (\"Lemma('innocent.s.02.innocent')\", 2), (\"Lemma('innocent.s.04.innocent')\", 1), (\"Lemma('impeccant.s.01.innocent')\", 1)])\n",
      "collecting tokens for  investors\n",
      "indices:    {21794, 23435, 21909, 23430}\n",
      "dict_items([])\n",
      "collecting tokens for  chemical\n",
      "indices:    {34922, 30291}\n",
      "dict_items([])\n",
      "collecting tokens for  stocks\n",
      "indices:    {96, 130, 15274, 23499, 14539, 22005, 21270, 21814, 21816, 21819}\n",
      "dict_items([(\"Lemma('stock.n.01.stock')\", 3), (\"Lemma('stock_certificate.n.01.stock')\", 1)])\n",
      "collecting tokens for  tremendous\n",
      "indices:    {4627, 20244, 28437, 27542, 37015, 24728, 1052, 4637, 22942, 13855, 21920, 24481, 1951, 21792, 26406, 15274, 13873, 28468, 12732, 23101, 1087, 13137, 3670, 25305, 3052, 15728, 32880, 20594, 1137, 4725, 633, 27645, 11263}\n",
      "dict_items([(\"Lemma('enormous.s.01.tremendous')\", 12), (\"Lemma('fantastic.s.02.tremendous')\", 5)])\n",
      "collecting tokens for  hanging\n",
      "indices:    {33762, 5892, 7492, 7303, 25353, 9456, 33431}\n",
      "dict_items([(\"Lemma('hang.v.01.hang')\", 2)])\n",
      "collecting tokens for  automobile\n",
      "indices:    {11936, 26284, 2607}\n",
      "dict_items([(\"Lemma('car.n.01.automobile')\", 2)])\n",
      "collecting tokens for  activity\n",
      "indices:    {32480, 18723, 11620, 12491, 3762, 23892, 32028, 3575, 4220}\n",
      "dict_items([(\"Lemma('action.n.02.activity')\", 3), (\"Lemma('activity.n.01.activity')\", 2)])\n",
      "collecting tokens for  gifted\n",
      "indices:    {32674, 7561, 14506, 26059, 13259, 30671, 36208, 11186, 22963, 31159, 26233}\n",
      "dict_items([(\"Lemma('endow.v.01.gift')\", 1)])\n",
      "collecting tokens for  conductor\n",
      "indices:    {31624, 22525}\n",
      "dict_items([])\n",
      "collecting tokens for  superior\n",
      "indices:    {31069}\n",
      "dict_items([])\n",
      "collecting tokens for  legislators\n",
      "indices:    {20218, 147}\n",
      "dict_items([(\"Lemma('legislator.n.01.legislator')\", 1)])\n",
      "collecting tokens for  drum\n",
      "indices:    {25665, 8706, 20931, 26917, 6186, 12564, 24631, 33788}\n",
      "dict_items([(\"Lemma('drum.n.01.drum')\", 2)])\n",
      "collecting tokens for  shades\n",
      "indices:    {6499, 29572, 22276, 9789, 22151, 26995, 9787, 9788, 25949}\n",
      "dict_items([(\"Lemma('shade.n.03.shade')\", 3)])\n",
      "collecting tokens for  acquire\n",
      "indices:    {26240, 131, 14729, 30091, 14734, 14223, 1569, 15272, 29225, 16298, 22957, 26555, 16448, 2501, 31046, 30672, 30053, 1772, 28145, 6004, 15229, 16254}\n",
      "dict_items([(\"Lemma('get.v.01.acquire')\", 18), (\"Lemma('assume.v.03.acquire')\", 3), (\"Lemma('grow.v.08.acquire')\", 1)])\n",
      "collecting tokens for  secret\n",
      "indices:    {30338, 31364, 18244, 21542, 19140, 34602, 26192, 25554, 19032, 5275}\n",
      "dict_items([(\"Lemma('secret.n.01.secret')\", 1), (\"Lemma('unavowed.s.03.secret')\", 1), (\"Lemma('secret.s.01.secret')\", 2)])\n",
      "collecting tokens for  applications\n",
      "indices:    {11406}\n",
      "dict_items([(\"Lemma('application.n.01.application')\", 1)])\n",
      "collecting tokens for  rights\n",
      "indices:    {29955, 14853, 32010, 14742, 15261, 31774, 2464, 15272, 26154, 14251, 28077, 30509, 2481, 9523, 2485, 23863, 20156, 14149, 23890, 22108, 37090, 5349, 37095, 34027, 31989, 27894, 24698, 32255}\n",
      "dict_items([(\"Lemma('right.n.01.right')\", 7)])\n",
      "collecting tokens for  plants\n",
      "indices:    {1667, 1668, 11782, 24071, 1674, 14734, 1678, 23439, 2065, 11799, 14750, 14751, 25121, 25122, 16163, 4132, 5431, 32183, 32445, 5438, 5439, 10046, 10049, 32450, 5443, 10051, 16196, 5447, 32458, 3658, 1612, 1613, 1870, 1611, 21710, 32461, 1620, 22749, 1633, 23138, 25059, 9186, 1642, 4202, 1649, 10098, 32630, 1657, 21626, 13565, 1662}\n",
      "dict_items([(\"Lemma('plant.n.01.plant')\", 10), (\"Lemma('plant.n.02.plant')\", 26)])\n",
      "collecting tokens for  grow\n",
      "indices:    {11138, 24968, 5001, 1675, 11659, 1679, 1683, 13206, 36769, 36516, 23207, 23466, 29228, 24245, 28341, 36408, 10046, 24895, 10047, 10049, 7745, 36546, 28224, 20040, 32968, 27343, 6866, 1619, 1620, 23509, 6869, 24916, 22226, 7261, 12126, 10083, 10468, 3686, 7015, 8685, 12527, 24559, 35186, 6003, 1653, 12149, 34808, 11900}\n",
      "dict_items([(\"Lemma('grow.v.02.grow')\", 9), (\"Lemma('grow.v.03.grow')\", 15), (\"Lemma('mature.v.01.grow')\", 2), (\"Lemma('grow.v.04.grow')\", 8), (\"Lemma('turn.v.07.grow')\", 6), (\"Lemma('grow.v.08.grow')\", 1)])\n",
      "collecting tokens for  wing\n",
      "indices:    {1217, 18690, 20965, 35333, 11270, 18697, 23371, 235, 5682, 24828, 23509, 35576, 18681, 31324, 7645, 31358}\n",
      "dict_items([(\"Lemma('wing.n.02.wing')\", 5), (\"Lemma('fly.v.01.wing')\", 1), (\"Lemma('wing.n.01.wing')\", 1)])\n",
      "collecting tokens for  whereby\n",
      "indices:    {23940, 36681, 3467, 33004, 14701, 20172, 23823, 16432, 34739, 23509, 31605, 22394, 2941, 3199}\n",
      "dict_items([])\n",
      "collecting tokens for  resources\n",
      "indices:    {32129, 12930, 26114, 13187, 20356, 32903, 33032, 4618, 32149, 15511, 3481, 36122, 32155, 32156, 4642, 32165, 1318, 32173, 2736, 1330, 26933, 32184, 15424, 32192, 24131, 30659, 26053, 15054, 23509, 23513, 28635, 23519, 14178, 23522, 23527, 32878, 4591, 32879, 11890, 34677, 32504, 11258, 12796}\n",
      "dict_items([(\"Lemma('resource.n.01.resource')\", 7), (\"Lemma('resource.n.02.resource')\", 4), (\"Lemma('resource.n.03.resource')\", 1)])\n",
      "collecting tokens for  basis\n",
      "indices:    {31236, 11783, 14348, 15885, 32276, 32277, 21527, 30234, 24605, 11811, 32291, 3118, 30770, 29237, 13368, 26184, 32331, 32335, 3665, 24151, 2148, 32876, 23157, 2687, 23168, 32903, 16533, 15002, 24220, 25760, 4261, 15013, 32427, 28843, 22700, 14001, 22705, 4286, 25800, 14024, 15562, 2761, 15052, 30412, 25805, 3800, 2776, 12001, 37090, 1768, 15599, 14066, 2802, 1779, 3830, 32502, 32504, 32503, 16138, 3347, 4382, 15647, 3366, 15666, 14130, 12086, 17210, 33082, 3391, 15691, 32079, 20310, 15703, 4955, 33115, 16225, 16232, 12138, 11630, 24431, 24432, 25463, 20346, 25979, 21884, 31100, 4987, 14726, 31112, 15241, 32137, 30201, 16279, 25497, 5533, 32159, 15266, 5541, 2990, 1454, 21424, 13242, 13245, 21438, 9151, 32192, 11713, 21441, 1481, 32724, 23509, 33237, 4578, 15842, 13285, 13287, 23015, 20464, 32754, 15346, 23545, 32764}\n",
      "dict_items([(\"Lemma('footing.n.02.basis')\", 26), (\"Lemma('basis.n.02.basis')\", 26)])\n",
      "collecting tokens for  happen\n",
      "indices:    {24455, 19848, 19463, 19467, 7948, 25101, 30608, 33171, 23571, 33172, 16665, 6426, 7322, 925, 7842, 27682, 6564, 5924, 27685, 34855, 34856, 24231, 23844, 3630, 34865, 33206, 33207, 6456, 20536, 11068, 35516, 1215, 31939, 24137, 19915, 7886, 36558, 13774, 33617, 22226, 8662, 34779, 31324, 4830, 33249, 34529, 30055, 36588, 16500, 30708, 26233, 31356}\n",
      "dict_items([(\"Lemma('happen.v.01.happen')\", 26), (\"Lemma('happen.v.02.happen')\", 11), (\"Lemma('happen.v.03.happen')\", 5), (\"Lemma('happen.v.04.happen')\", 3)])\n",
      "collecting tokens for  boulevard\n",
      "indices:    {13468}\n",
      "dict_items([])\n",
      "collecting tokens for  portion\n",
      "indices:    {26624, 32384, 32393, 13710, 15, 4112, 36752, 13714, 3859, 36761, 11418, 3867, 3872, 11425, 3873, 2848, 3876, 7973, 11940, 3879, 3877, 4649, 32426, 3882, 3874, 3875, 1710, 11057, 13749, 3770, 15163, 59, 14782, 3905, 2243, 35911, 11341, 28497, 5341, 27358, 14943, 12648, 16107, 31352, 29947}\n",
      "dict_items([(\"Lemma('part.n.01.portion')\", 25), (\"Lemma('share.n.01.portion')\", 2), (\"Lemma('parcel.n.02.portion')\", 4), (\"Lemma('part.n.02.portion')\", 3)])\n",
      "collecting tokens for  romantic\n",
      "indices:    {14078, 14687}\n",
      "dict_items([(\"Lemma('romantic.a.01.romantic')\", 1)])\n",
      "collecting tokens for  listeners\n",
      "indices:    {26722, 24646, 26969, 26410, 26734, 9939, 26004, 24659, 1718, 26745}\n",
      "dict_items([(\"Lemma('hearer.n.01.listener')\", 2)])\n",
      "collecting tokens for  understand\n",
      "indices:    {2054, 36872, 2056, 27157, 22568, 10280, 4659, 35901, 34373, 17991, 26704, 10832, 34387, 32856, 30821, 3686, 23658, 6763, 6764, 36464, 26231, 22647, 7297, 24706, 6803, 9364, 28311, 35993, 22685, 5278, 12966, 9898, 36011, 2732, 24760, 7865, 24764, 22219, 30924, 25812, 36573, 36596, 8970, 8973, 32014, 8975, 14098, 31507, 35096, 17694, 37156, 14631, 35121, 1330, 32054, 8000, 19780, 14661, 19782, 25944, 11097, 5989, 14695, 5993, 10609, 882, 31606, 10619, 6012, 32638, 8066, 24962, 10628, 1925, 33670, 10121, 24972, 27558, 35243, 35757, 20416, 28118, 11737, 14305, 6115, 7144, 25066, 6123, 2029, 25581, 4591, 19439, 7153, 26099}\n",
      "dict_items([(\"Lemma('understand.v.01.understand')\", 26), (\"Lemma('understand.v.02.understand')\", 24), (\"Lemma('understand.v.04.understand')\", 3), (\"Lemma('understand.v.03.understand')\", 4)])\n",
      "collecting tokens for  moves\n",
      "indices:    {3084, 32014, 4499, 21403, 27036, 11421, 20251, 23460, 26021, 31407, 13488, 29873, 28719, 31023, 28724, 28721, 31922, 4538, 23870, 3007, 24390, 711, 34253, 718, 13653, 16215, 26074, 15460, 24423, 22635, 22639}\n",
      "dict_items([(\"Lemma('motivate.v.01.move')\", 1), (\"Lemma('move.v.02.move')\", 4), (\"Lemma('affect.v.05.move')\", 1), (\"Lemma('travel.v.01.move')\", 7), (\"Lemma('move.n.01.move')\", 1), (\"Lemma('go.v.02.move')\", 3), (\"Lemma('move.v.03.move')\", 3), (\"Lemma('move.v.04.move')\", 1), (\"Lemma('move.v.07.move')\", 1)])\n",
      "collecting tokens for  sacrifice\n",
      "indices:    {1434}\n",
      "dict_items([])\n",
      "collecting tokens for  lives\n",
      "indices:    {13184, 13953, 30725, 13191, 32010, 20490, 20492, 32014, 1295, 23568, 32015, 28307, 25365, 21782, 14615, 32024, 23965, 36769, 32677, 22184, 31403, 16043, 12075, 22447, 36144, 31537, 5042, 25397, 28214, 15418, 26941, 12735, 22218, 5710, 8911, 20046, 7892, 20823, 25688, 14170, 28253, 1245, 1504, 12009, 21738, 12777, 20460, 8811, 24559, 14708, 14582, 13815, 10744, 21754, 27644, 27134}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('live.v.02.live')\", 6), (\"Lemma('life.n.06.life')\", 1), (\"Lemma('life.n.03.life')\", 5), (\"Lemma('survive.v.01.live')\", 1), (\"Lemma('populate.v.01.live')\", 11), (\"Lemma('exist.v.02.live')\", 1), (\"Lemma('life.n.02.life')\", 3), (\"Lemma('be.v.11.live')\", 1), (\"Lemma('animation.n.01.life')\", 2), (\"Lemma('life.n.01.life')\", 4), (\"Lemma('life.n.05.life')\", 1), (\"Lemma('life.n.08.life')\", 1)])\n",
      "collecting tokens for  error\n",
      "indices:    {25984, 24835, 32013, 32014, 11308, 11693, 26031, 11444, 15798, 3384, 3385, 9792, 33089, 31427, 202, 26827, 30808, 12390, 24824, 2170}\n",
      "dict_items([(\"Lemma('error.n.04.error')\", 1), (\"Lemma('error.n.03.error')\", 2), (\"Lemma('erroneousness.n.01.error')\", 2), (\"Lemma('mistake.n.01.error')\", 3)])\n",
      "collecting tokens for  truth\n",
      "indices:    {25603, 17036, 26137, 25370, 670, 21536, 8231, 28200, 29997, 16942, 11444, 18617, 13629, 27326, 31679, 16833, 24771, 27737, 31579, 35425, 20453, 34919, 17898, 28401, 25588, 13434}\n",
      "dict_items([(\"Lemma('truth.n.02.truth')\", 3), (\"Lemma('truth.n.01.truth')\", 7)])\n",
      "collecting tokens for  defend\n",
      "indices:    {14402, 25506, 10139, 25976, 27266, 24831, 36383, 25613, 32014, 19502, 21749, 35541, 17976, 19417, 21530, 14459, 25087}\n",
      "dict_items([(\"Lemma('defend.v.01.defend')\", 8), (\"Lemma('defend.v.02.defend')\", 7), (\"Lemma('champion.v.01.defend')\", 1), (\"Lemma('fight.v.02.defend')\", 1)])\n",
      "collecting tokens for  laos\n",
      "indices:    {23751}\n",
      "dict_items([])\n",
      "collecting tokens for  unpleasant\n",
      "indices:    {31491, 31493, 1693, 14600, 11037, 36240, 20662, 4599, 24120, 30811, 26717}\n",
      "dict_items([(\"Lemma('unpleasant.a.01.unpleasant')\", 4)])\n",
      "collecting tokens for  arose\n",
      "indices:    {22626, 12709, 28042, 11037, 2187, 20367, 28048, 23249, 16884, 19869, 25502}\n",
      "dict_items([(\"Lemma('arise.v.04.arise')\", 2), (\"Lemma('originate.v.01.arise')\", 5), (\"Lemma('arise.v.03.arise')\", 2), (\"Lemma('arise.v.02.arise')\", 2)])\n",
      "collecting tokens for  soloist\n",
      "indices:    {26273, 31649, 31651, 26408, 26800, 915, 921, 26491, 11037}\n",
      "dict_items([(\"Lemma('soloist.n.01.soloist')\", 3)])\n",
      "collecting tokens for  approach\n",
      "indices:    {31875, 1030, 3720, 36490, 34570, 16144, 8339, 25752, 36505, 3482, 12062, 26274, 31908, 32165, 2090, 13355, 3888, 12725, 23609, 14397, 23741, 24896, 22595, 1091, 18638, 22351, 12501, 14554, 12765, 32863, 36450, 30820, 36455, 20593, 32882, 11634, 5109, 30582, 36603, 20991}\n",
      "dict_items([(\"Lemma('approach.n.01.approach')\", 12), (\"Lemma('approach.n.02.approach')\", 5), (\"Lemma('approach.v.05.approach')\", 1), (\"Lemma('approach.v.01.approach')\", 1), (\"Lemma('border_on.v.01.approach')\", 1)])\n",
      "collecting tokens for  smelled\n",
      "indices:    {8705, 7683, 19622, 36039, 36712, 11037, 9515, 8557, 36654, 35153, 8501, 33270, 34331, 10525}\n",
      "dict_items([(\"Lemma('smell.v.02.smell')\", 8), (\"Lemma('smell.v.01.smell')\", 5), (\"Lemma('smell.v.03.smell')\", 1)])\n",
      "collecting tokens for  senators\n",
      "indices:    {106}\n",
      "dict_items([(\"Lemma('senator.n.01.senator')\", 1)])\n",
      "collecting tokens for  occasionally\n",
      "indices:    {30450, 7158}\n",
      "dict_items([(\"Lemma('occasionally.r.01.occasionally')\", 1)])\n",
      "collecting tokens for  michigan\n",
      "indices:    {3684}\n",
      "dict_items([(\"Lemma('location.n.01.location')\", 1)])\n",
      "collecting tokens for  maryland\n",
      "indices:    {21220}\n",
      "dict_items([])\n",
      "collecting tokens for  oysters\n",
      "indices:    {29185, 29188, 29162, 29163, 23373, 29166, 21071}\n",
      "dict_items([])\n",
      "collecting tokens for  washington\n",
      "indices:    {29306}\n",
      "dict_items([])\n",
      "collecting tokens for  zen\n",
      "indices:    {28167}\n",
      "dict_items([])\n",
      "collecting tokens for  reveals\n",
      "indices:    {30243, 28166, 15848, 30251, 15852, 27533, 27854, 30257, 2643, 27348, 28148, 2650, 32282}\n",
      "dict_items([(\"Lemma('unwrap.v.02.reveal')\", 5), (\"Lemma('uncover.v.01.reveal')\", 4)])\n",
      "collecting tokens for  fame\n",
      "indices:    {576, 11240, 27401, 28074, 12459, 6764, 6767, 26450, 28148, 1173, 19390, 19391}\n",
      "dict_items([(\"Lemma('fame.n.01.fame')\", 7)])\n",
      "collecting tokens for  search\n",
      "indices:    {4992, 35457, 9346, 18307, 35203, 13831, 32651, 33164, 13966, 34327, 36888, 16418, 31277, 23602, 32052, 14646, 27832, 11065, 11068, 30407, 1738, 14794, 5070, 7392, 17377, 21475, 20580, 7525, 32101, 14581, 23286, 32634, 12796, 28031}\n",
      "dict_items([(\"Lemma('search.n.02.search')\", 5), (\"Lemma('search.v.01.search')\", 1), (\"Lemma('search.n.01.search')\", 10), (\"Lemma('search.v.02.search')\", 3), (\"Lemma('research.v.02.search')\", 1)])\n",
      "collecting tokens for  anticipation\n",
      "indices:    {16995, 6564, 32581, 14630, 14629, 32680, 32553, 5837, 32558, 32559, 8917, 12122, 14717, 1695}\n",
      "dict_items([(\"Lemma('prediction.n.01.anticipation')\", 1), (\"Lemma('anticipation.n.01.anticipation')\", 4), (\"Lemma('anticipation.n.02.anticipation')\", 3)])\n",
      "collecting tokens for  claude\n",
      "indices:    {1560}\n",
      "dict_items([])\n",
      "collecting tokens for  specialist\n",
      "indices:    {24003, 12165, 31046, 1543, 14345, 1673, 14187, 1610, 9746, 14068, 14071, 5598, 26175}\n",
      "dict_items([(\"Lemma('specialist.n.01.specialist')\", 8), (\"Lemma('specialist.n.02.specialist')\", 1)])\n",
      "collecting tokens for  torso\n",
      "indices:    {34882, 1538, 1543, 1545, 9714, 26233, 7611, 1565}\n",
      "dict_items([(\"Lemma('torso.n.01.torso')\", 6)])\n",
      "collecting tokens for  favored\n",
      "indices:    {8416, 19425, 19426, 2467, 32422, 1543, 23239, 23238, 262, 4774, 23240, 4784, 4753, 2522}\n",
      "dict_items([(\"Lemma('prefer.v.03.favor')\", 9), (\"Lemma('privilege.v.01.favor')\", 1), (\"Lemma('favor.v.02.favor')\", 2), (\"Lemma('favored.s.01.favored')\", 2)])\n",
      "collecting tokens for  push-pull\n",
      "indices:    {1545}\n",
      "dict_items([])\n",
      "collecting tokens for  super-set\n",
      "indices:    {1544}\n",
      "dict_items([])\n",
      "collecting tokens for  sector\n",
      "indices:    {23681, 30309, 1543, 4590, 27476, 1245, 14329, 11421, 11422}\n",
      "dict_items([(\"Lemma('sector.n.02.sector')\", 1), (\"Lemma('sector.n.01.sector')\", 3), (\"Lemma('sector.n.03.sector')\", 2)])\n",
      "collecting tokens for  muscle\n",
      "indices:    {23617, 1570, 24611, 4037, 25669, 27243, 4108, 22990, 4016, 7794, 4115, 1565}\n",
      "dict_items([(\"Lemma('muscle.n.01.muscle')\", 6)])\n",
      "collecting tokens for  pulling\n",
      "indices:    {22299, 22305, 17442, 10592, 9540, 9508, 9477, 1543, 33960, 17253, 5098, 6956, 18358, 17560, 33978, 28731, 18908, 22975}\n",
      "dict_items([(\"Lemma('attract.v.01.pull_in')\", 3), (\"Lemma('pluck.v.01.pull_off')\", 1), (\"Lemma('pull.v.03.pull')\", 1), (\"Lemma('pull.v.01.pull')\", 6), (\"Lemma('perpetrate.v.01.pull')\", 1), (\"Lemma('gather.v.01.pull_together')\", 1), (\"Lemma('attract.v.01.pull')\", 1), (\"Lemma('pull_the_leg_of.v.01.pull_the_leg_of')\", 1), (\"Lemma('pull.n.01.pulling')\", 1)])\n",
      "collecting tokens for  opposing\n",
      "indices:    {6022, 1543, 14989, 29967, 32018, 27538, 18773, 29982}\n",
      "dict_items([(\"Lemma('fight.v.02.oppose')\", 1), (\"Lemma('opponent.s.01.opposing')\", 1), (\"Lemma('oppose.v.01.oppose')\", 1)])\n",
      "collecting tokens for  tickets\n",
      "indices:    {35680, 33377, 35681, 35683, 8806, 22408, 21002, 31530, 21004, 17581, 35695, 22031, 22383}\n",
      "dict_items([(\"Lemma('ticket.n.01.ticket')\", 2)])\n",
      "collecting tokens for  sweep\n",
      "indices:    {8704, 32225, 24354, 25411, 26981, 29350, 33618, 11093, 12058}\n",
      "dict_items([(\"Lemma('sweep.n.01.sweep')\", 2), (\"Lemma('sweep.v.03.sweep')\", 2), (\"Lemma('sweep.v.02.sweep')\", 1)])\n",
      "collecting tokens for  feels\n",
      "indices:    {13955, 272, 401, 24976, 28565, 12058, 31137, 31138, 30502, 31911, 20264, 15791, 31152, 13999, 34359, 22204, 829, 17869, 22352, 24787, 22367, 24801, 24802, 24803, 11491, 27112, 13675, 13164, 11639, 2298, 28543}\n",
      "dict_items([(\"Lemma('feel.v.01.feel')\", 10), (\"Lemma('find.v.05.feel')\", 16), (\"Lemma('feel.v.04.feel')\", 1), (\"Lemma('feel.v.03.feel')\", 2), (\"Lemma('feel.v.05.feel')\", 1), (\"Lemma('feel.v.06.feel')\", 1)])\n",
      "collecting tokens for  scale\n",
      "indices:    {36992, 3225, 15674, 12141}\n",
      "dict_items([(\"Lemma('scale.n.02.scale')\", 2), (\"Lemma('scale.n.01.scale')\", 1)])\n",
      "collecting tokens for  efficient\n",
      "indices:    {1891, 30148, 24131, 14916, 6183, 21705, 12778, 7306, 8329, 3438, 27856, 20113, 35635, 11771, 32569, 2395, 29821, 25246}\n",
      "dict_items([(\"Lemma('efficient.a.01.efficient')\", 7), (\"Lemma('effective.s.02.efficient')\", 3)])\n",
      "collecting tokens for  detail\n",
      "indices:    {16128, 16130, 33161, 12044, 2704, 32404, 16149, 9881, 1821, 29855, 32292, 29863, 26539, 31154, 21298, 26676, 21302, 2874, 4929, 11717, 1735, 32588, 2895, 2640, 15961, 2138, 25050, 26204, 14942, 8802, 13541, 2150, 3942, 32363, 13675, 11371, 17646, 32495, 17644, 11378, 25971, 23548, 27646}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('detail.n.02.detail')\", 2), (\"Lemma('detail.n.01.detail')\", 5), (\"Lemma('detail.n.04.detail')\", 2), (\"Lemma('detail.n.03.detail')\", 5)])\n",
      "collecting tokens for  1949\n",
      "indices:    {4000, 23680, 2851, 621, 32750, 623, 32752, 625, 4048, 22864, 2807, 14907, 477, 11134, 3999}\n",
      "dict_items([])\n",
      "collecting tokens for  strokes\n",
      "indices:    {9473, 22915, 7876, 8876, 22989, 22924, 22928, 22930, 538, 26298, 22909}\n",
      "dict_items([(\"Lemma('stroke.n.05.stroke')\", 1), (\"Lemma('stroke.n.01.stroke')\", 1), (\"Lemma('throw.n.03.stroke')\", 2)])\n",
      "collecting tokens for  deliberate\n",
      "indices:    {12964, 31368, 30798, 22928, 27827, 12308, 34806, 8887, 35997, 13695}\n",
      "dict_items([(\"Lemma('deliberate.s.01.deliberate')\", 2), (\"Lemma('careful.s.03.deliberate')\", 2)])\n",
      "collecting tokens for  successive\n",
      "indices:    {3564, 25357, 2159, 1426, 22995}\n",
      "dict_items([(\"Lemma('consecutive.s.02.successive')\", 3)])\n",
      "collecting tokens for  december\n",
      "indices:    {1436}\n",
      "dict_items([(\"Lemma('december.n.01.December')\", 1)])\n",
      "collecting tokens for  portable\n",
      "indices:    {22048, 29478, 20907, 29452, 29485, 7448, 15193, 8671}\n",
      "dict_items([(\"Lemma('portable.a.01.portable')\", 3)])\n",
      "collecting tokens for  vocal\n",
      "indices:    {5829, 843, 26315, 34702, 15824, 34741}\n",
      "dict_items([(\"Lemma('outspoken.s.01.vocal')\", 1), (\"Lemma('vocal.a.01.vocal')\", 1)])\n",
      "collecting tokens for  sing\n",
      "indices:    {27461, 26251, 24690, 34739, 9949}\n",
      "dict_items([(\"Lemma('sing.v.02.sing')\", 2), (\"Lemma('sing.v.01.sing')\", 2)])\n",
      "collecting tokens for  consumer\n",
      "indices:    {11648, 1706, 22062, 11633, 22770}\n",
      "dict_items([(\"Lemma('consumer.n.01.consumer')\", 3)])\n",
      "collecting tokens for  ration\n",
      "indices:    {11556, 27178, 23215, 23216, 11546, 7485, 11550}\n",
      "dict_items([(\"Lemma('ration.n.02.ration')\", 1), (\"Lemma('ration.n.01.ration')\", 3)])\n",
      "collecting tokens for  intervals\n",
      "indices:    {26114, 20323, 12740, 33092, 36069, 20389, 23216, 17298, 5523, 31892, 3348, 4533, 4532, 31350, 14778, 10526, 4543}\n",
      "dict_items([(\"Lemma('time_interval.n.01.interval')\", 5), (\"Lemma('interval.n.02.interval')\", 2)])\n",
      "collecting tokens for  theological\n",
      "indices:    {12288, 27905, 13346, 27720, 12296, 13642, 27848, 28021, 1302, 13494, 12280, 27771, 27291}\n",
      "dict_items([(\"Lemma('theological.a.01.theological')\", 7)])\n",
      "collecting tokens for  understandable\n",
      "indices:    {2306, 840, 24745, 6762, 1578, 6892, 10859, 22323, 10334, 22682, 26493, 10942}\n",
      "dict_items([(\"Lemma('apprehensible.s.01.understandable')\", 6)])\n",
      "collecting tokens for  observing\n",
      "indices:    {14800, 12497, 15402, 5646}\n",
      "dict_items([(\"Lemma('note.v.03.observe')\", 1), (\"Lemma('detect.v.01.observe')\", 2), (\"Lemma('observe.v.04.observe')\", 1)])\n",
      "collecting tokens for  conduct\n",
      "indices:    {28098, 23946, 27595, 27630, 13918}\n",
      "dict_items([(\"Lemma('conduct.v.01.conduct')\", 1)])\n",
      "collecting tokens for  resulting\n",
      "indices:    {4225, 3588, 14727, 31881, 21899, 32402, 14741, 14743, 3492, 25389, 11823, 15028, 3394, 1611, 15695, 32987, 15071, 3424, 14945, 32995, 28901, 29037, 5360, 5489, 32754, 11506, 11378}\n",
      "dict_items([(\"Lemma('result.v.01.result')\", 13), (\"Lemma('leave.v.07.result')\", 5)])\n",
      "collecting tokens for  allotment\n",
      "indices:    {21516, 21520, 15008, 15010, 15013, 15024, 15026, 15027, 15028, 15029, 15032, 15038, 15040, 15041, 15042, 15043, 15044, 15045, 15046, 15047, 15048, 15049, 15052, 15053, 15055}\n",
      "dict_items([(\"Lemma('allotment.n.01.allotment')\", 22), (\"Lemma('allotment.n.02.allotment')\", 1)])\n",
      "collecting tokens for  lowered\n",
      "indices:    {18464, 35749, 15719, 9769, 34987, 33611, 28461, 8811, 6291, 15028, 19379, 5619, 22071, 7161, 8602, 15071}\n",
      "dict_items([(\"Lemma('lower.v.01.lower')\", 8), (\"Lemma('lowered.a.01.lowered')\", 2), (\"Lemma('lower.v.02.lower')\", 3), (\"Lemma('turn_down.v.05.lower')\", 1)])\n",
      "collecting tokens for  neatly\n",
      "indices:    {5729, 20071, 36968, 9801, 22442, 9803, 17740, 26063, 27249, 29075, 25813, 27542, 8253}\n",
      "dict_items([(\"Lemma('neatly.r.01.neatly')\", 6)])\n",
      "collecting tokens for  foods\n",
      "indices:    {21801, 3500, 27246, 29462}\n",
      "dict_items([(\"Lemma('food.n.01.food')\", 1)])\n",
      "collecting tokens for  deficiency\n",
      "indices:    {23428, 5577, 3981, 3987, 27193, 27194, 27195, 4284, 4285, 11166}\n",
      "dict_items([(\"Lemma('lack.n.01.deficiency')\", 5), (\"Lemma('insufficiency.n.03.deficiency')\", 1)])\n",
      "collecting tokens for  namely\n",
      "indices:    {28024, 32837, 4836, 22855, 32841, 26122, 32809, 1487, 16176, 16178, 12308, 4533, 4502, 32824, 12955, 4284, 27805, 27134}\n",
      "dict_items([(\"Lemma('namely.r.01.namely')\", 9)])\n",
      "collecting tokens for  fully\n",
      "indices:    {33154, 11779, 23050, 15373, 4627, 9364, 16020, 28316, 5406, 23328, 27558, 8233, 26282, 26747, 15534, 4911, 23858, 4659, 15290, 27328, 64, 32578, 1347, 32068, 23749, 20678, 15305, 6603, 6221, 6606, 10577, 27346, 14417, 15572, 1235, 25049, 23515, 23259, 13917, 11742, 9696, 27234, 11235, 2663, 24168, 30574, 28657, 32628, 2682, 15867, 2172, 14079}\n",
      "dict_items([(\"Lemma('fully.r.01.fully')\", 26), (\"Lemma('amply.r.02.fully')\", 2), (\"Lemma('in_full.r.01.fully')\", 1)])\n",
      "collecting tokens for  deserved\n",
      "indices:    {11077, 16901, 37160, 26282, 5291, 13038, 6999, 26587, 23645}\n",
      "dict_items([(\"Lemma('deserve.v.01.deserve')\", 6)])\n",
      "collecting tokens for  eileen\n",
      "indices:    {8143}\n",
      "dict_items([(\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  lift\n",
      "indices:    {5378, 21890, 10951, 21961, 34922, 1518, 18226, 33683, 29557, 29561, 9116, 36286}\n",
      "dict_items([(\"Lemma('lift.v.02.lift')\", 1), (\"Lemma('raise.v.02.lift')\", 6), (\"Lemma('hoist.v.01.lift')\", 1)])\n",
      "collecting tokens for  pillow\n",
      "indices:    {22436, 17740, 8941, 26542, 9215, 8125, 8990, 24351}\n",
      "dict_items([(\"Lemma('pillow.n.01.pillow')\", 5)])\n",
      "collecting tokens for  pressed\n",
      "indices:    {3011, 27909, 18917, 13894, 6281, 3593, 34316, 29581, 16751, 16303, 8817, 31154, 13139, 17971, 16883, 29563, 33852, 9182}\n",
      "dict_items([(\"Lemma('press.v.01.press')\", 11), (\"Lemma('compress.v.02.press')\", 1), (\"Lemma('press.v.04.press')\", 1), (\"Lemma('weigh.v.05.press')\", 1), (\"Lemma('urge.v.01.press')\", 2)])\n",
      "collecting tokens for  purely\n",
      "indices:    {25475, 13958, 26630, 4361, 2063, 27542, 1319, 13995, 1580, 15661, 13617, 15409, 23741, 25667, 30788, 13139, 25813, 27863, 32867, 2162, 2169, 32892}\n",
      "dict_items([(\"Lemma('strictly.r.01.purely')\", 12)])\n",
      "collecting tokens for  encountered\n",
      "indices:    {5344, 2498, 19683, 17868, 24461, 11150, 14412, 13139, 27093, 35702, 6333, 26711, 2169, 32570, 25116, 3229}\n",
      "dict_items([(\"Lemma('meet.v.01.encounter')\", 8), (\"Lemma('find.v.01.encounter')\", 7), (\"Lemma('run_into.v.01.encounter')\", 1)])\n",
      "collecting tokens for  ethnic\n",
      "indices:    {27845, 2376, 23244, 13135, 33072, 13202, 13139, 24821, 2326, 32985, 2331, 23196}\n",
      "dict_items([(\"Lemma('cultural.s.02.ethnic')\", 3)])\n",
      "collecting tokens for  loyalty\n",
      "indices:    {32227, 32228, 32229, 20774, 24198, 7715, 2537, 27634, 13044, 31221, 13850, 35259, 2300, 27903}\n",
      "dict_items([(\"Lemma('loyalty.n.01.loyalty')\", 5)])\n",
      "collecting tokens for  sight\n",
      "indices:    {7936, 18817, 34693, 18693, 1927, 34700, 29329, 33810, 19347, 12694, 22934, 26138, 8733, 16417, 36898, 17572, 7844, 16933, 17065, 4911, 4913, 16305, 14003, 34100, 24376, 17338, 4923, 7161, 8511, 4928, 36292, 33739, 33100, 33102, 7120, 36052, 10584, 7003, 29277, 18527, 9313, 28641, 34273, 13282, 18785, 10470, 6888, 8169, 33768, 13550, 17134, 25202, 24947, 34422, 33143, 34425, 34558, 2431}\n",
      "dict_items([(\"Lemma('sight.n.03.sight')\", 6), (\"Lemma('sight.n.01.sight')\", 7), (\"Lemma('view.n.03.sight')\", 2), (\"Lemma('sight.n.05.sight')\", 1), (\"Lemma('batch.n.02.sight')\", 1), (\"Lemma('sight.n.02.sight')\", 4)])\n",
      "collecting tokens for  whisper\n",
      "indices:    {8610, 9765, 8742, 34887, 6452, 7352, 8633, 28319}\n",
      "dict_items([(\"Lemma('whisper.n.01.whisper')\", 4), (\"Lemma('whisper.v.01.whisper')\", 2)])\n",
      "collecting tokens for  die\n",
      "indices:    {25646}\n",
      "dict_items([])\n",
      "collecting tokens for  trees\n",
      "indices:    {26134, 25117, 25118, 29213, 11297, 29227, 25662, 7757, 8805, 8806, 7795, 10367, 11905, 17038, 35985, 29329, 8341, 35989, 35992, 35995, 36018, 10425, 36025, 5822, 36035, 5830, 36038, 8904, 1229, 36054, 36061, 5855, 10470, 25319, 13548, 6391, 26879, 6404, 35591, 13576, 17682, 13587, 13589, 9503, 13600, 10530, 13604, 31525, 6953, 6954, 30000, 10544, 1844, 1849, 1852, 16703, 6464, 1858, 5443, 1870, 18772, 4951, 13661, 7006, 1906, 36210, 1914, 35207, 35208, 20906, 12715, 18353, 22976, 35814, 30182, 8685, 24562, 30715}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('tree.n.01.tree')\", 26)])\n",
      "collecting tokens for  sidewalk\n",
      "indices:    {13600, 13603, 17542, 10538, 5195, 34028, 13996, 28333, 13423, 7472, 13998, 8140, 33587, 5940, 25145, 25148}\n",
      "dict_items([(\"Lemma('sidewalk.n.01.sidewalk')\", 11)])\n",
      "collecting tokens for  proposals\n",
      "indices:    {21888, 21889, 139, 24595, 14234, 24630, 16312, 20153, 20666, 23367, 25037, 25038, 25039, 25042, 25312, 15459, 20199, 20216, 23423}\n",
      "dict_items([(\"Lemma('proposal.n.01.proposal')\", 4)])\n",
      "collecting tokens for  lesser\n",
      "indices:    {15266, 5380, 12228, 27818, 32463, 24595, 27796, 14452, 1149, 31230}\n",
      "dict_items([(\"Lemma('lesser.a.01.lesser')\", 5)])\n",
      "collecting tokens for  38\n",
      "indices:    {353, 28995, 3811, 29029, 15556, 21223, 328, 29035, 21165, 3727, 24595, 15094, 3740}\n",
      "dict_items([])\n",
      "collecting tokens for  congressional\n",
      "indices:    {32706, 20627, 22874, 24822}\n",
      "dict_items([])\n",
      "collecting tokens for  rational\n",
      "indices:    {22785, 22786, 13670, 33257, 32816, 28115, 31894, 5209, 16442, 1467}\n",
      "dict_items([(\"Lemma('rational.a.01.rational')\", 3)])\n",
      "collecting tokens for  damn\n",
      "indices:    {17285, 18856, 6540, 8975, 34321, 9875, 6716, 7774}\n",
      "dict_items([(\"Lemma('curse.v.03.damn')\", 1), (\"Lemma('damn.s.01.damn')\", 5)])\n",
      "collecting tokens for  extensive\n",
      "indices:    {27527, 27530, 26637, 2459, 3234, 30755, 3878, 25391, 4017, 14392, 32699, 10690, 26954, 25037, 30800, 21461, 32343, 29920, 4706, 4707, 14954, 2796, 4088, 3450, 4091}\n",
      "dict_items([(\"Lemma('across-the-board.s.01.extensive')\", 3), (\"Lemma('extensive.s.01.extensive')\", 7)])\n",
      "collecting tokens for  publication\n",
      "indices:    {33056, 32705, 14466, 26018, 32706, 32750, 27022, 11727, 32753, 25969, 11509, 5271, 32764}\n",
      "dict_items([(\"Lemma('issue.n.11.publication')\", 3), (\"Lemma('publication.n.01.publication')\", 1)])\n",
      "collecting tokens for  reasonably\n",
      "indices:    {23816, 4617, 37002, 30223, 29840, 14488, 32280, 32158, 34342, 16167, 3123, 1206, 32193, 14916, 27080, 27091, 3668, 26836, 16469, 15450, 33514, 3180, 2413, 32878, 4975, 25841, 32755}\n",
      "dict_items([(\"Lemma('reasonably.r.01.reasonably')\", 11), (\"Lemma('sanely.r.01.reasonably')\", 1)])\n",
      "collecting tokens for  measurement\n",
      "indices:    {3136, 3749, 2985, 2987, 12717, 3120, 14835, 28948, 3128, 3129, 2910, 14847}\n",
      "dict_items([(\"Lemma('measurement.n.01.measurement')\", 2)])\n",
      "collecting tokens for  thermometer\n",
      "indices:    {14817, 14818, 14819, 29418, 29419, 16589, 14802, 14805, 14809}\n",
      "dict_items([(\"Lemma('thermometer.n.01.thermometer')\", 6)])\n",
      "collecting tokens for  thursday\n",
      "indices:    {325}\n",
      "dict_items([(\"Lemma('thursday.n.01.Thursday')\", 1)])\n",
      "collecting tokens for  plot\n",
      "indices:    {23650, 23332, 19406, 7059, 12117}\n",
      "dict_items([(\"Lemma('plot.n.02.plot')\", 1), (\"Lemma('plot.n.01.plot')\", 2)])\n",
      "collecting tokens for  tournament\n",
      "indices:    {5159, 649, 5161, 22969, 27089, 22902, 22905, 572, 22943}\n",
      "dict_items([(\"Lemma('tournament.n.01.tournament')\", 3)])\n",
      "collecting tokens for  lester\n",
      "indices:    {35236}\n",
      "dict_items([])\n",
      "collecting tokens for  wave\n",
      "indices:    {2829, 2831, 2833, 20498, 10517, 2840, 2842, 17703, 12714, 22957, 13357, 12718, 12720, 12721, 26550, 11449, 12731, 12735, 12738, 12739, 12740, 1865, 34381, 2385, 19419, 12765, 6624, 33890, 12773, 13547, 2796, 15853, 2798, 2413, 27761, 2802, 2804, 2806, 2811, 2812, 2815}\n",
      "dict_items([(\"Lemma('beckon.v.01.wave')\", 2), (\"Lemma('wave.n.01.wave')\", 14), (\"Lemma('wave.n.02.wave')\", 2), (\"Lemma('wave.n.06.wave')\", 1), (\"Lemma('wave.n.04.wave')\", 2), (\"Lemma('wave.n.05.wave')\", 1)])\n",
      "collecting tokens for  orientation\n",
      "indices:    {30240, 22688, 22687, 26758, 4686, 3118, 12976, 28115, 29845, 4922, 25629, 25631}\n",
      "dict_items([(\"Lemma('orientation.n.02.orientation')\", 1), (\"Lemma('orientation.n.01.orientation')\", 2)])\n",
      "collecting tokens for  hostile\n",
      "indices:    {30403, 12464, 19313, 12978, 25567}\n",
      "dict_items([(\"Lemma('hostile.a.01.hostile')\", 2)])\n",
      "collecting tokens for  david\n",
      "indices:    {21886}\n",
      "dict_items([])\n",
      "collecting tokens for  considers\n",
      "indices:    {32930, 16324, 24613, 30502, 31815, 25316, 937, 32970, 2479, 12278, 2554, 31643, 27708}\n",
      "dict_items([(\"Lemma('see.v.05.consider')\", 11), (\"Lemma('study.v.03.consider')\", 2)])\n",
      "collecting tokens for  evolution\n",
      "indices:    {5016, 26427}\n",
      "dict_items([(\"Lemma('development.n.02.evolution')\", 1)])\n",
      "collecting tokens for  fits\n",
      "indices:    {1495, 4646, 34090, 29591, 34641, 20438, 29590, 2554, 31742, 26239}\n",
      "dict_items([(\"Lemma('match.v.01.fit')\", 2), (\"Lemma('suit.v.01.fit')\", 2), (\"Lemma('meet.v.05.fit')\", 4), (\"Lemma('fit.v.02.fit')\", 1)])\n",
      "collecting tokens for  beautifully\n",
      "indices:    {21728, 11266, 27046, 26055, 18855, 26442, 26430, 1746, 31411, 18771, 26718, 2554, 30397, 8830}\n",
      "dict_items([(\"Lemma('beautifully.r.01.beautifully')\", 6)])\n",
      "collecting tokens for  protective\n",
      "indices:    {2624, 1698, 1156, 13190, 36330, 5836, 2554, 25143, 22778, 3803, 22684, 12766, 31775}\n",
      "dict_items([(\"Lemma('protective.a.01.protective')\", 7)])\n",
      "collecting tokens for  clerk\n",
      "indices:    {6155, 35724, 35727, 35730, 34208, 35756, 5165, 17585, 12849, 17587, 19506, 19511, 31683, 35652, 12870, 35663, 34387, 35669, 12391, 21608, 20329, 35689, 35697, 21491, 21493, 35703, 33019}\n",
      "dict_items([(\"Lemma('clerk.n.01.clerk')\", 6), (\"Lemma('salesclerk.n.01.clerk')\", 2)])\n",
      "collecting tokens for  processing\n",
      "indices:    {21943, 27170, 27169, 1702, 2728, 3502, 21870, 21521, 21522, 21523, 1812, 21526, 35703, 2779, 21847}\n",
      "dict_items([(\"Lemma('process.v.01.process')\", 2), (\"Lemma('procedure.n.01.process')\", 1), (\"Lemma('processing.n.01.processing')\", 2)])\n",
      "collecting tokens for  completed\n",
      "indices:    {13830, 36999, 1546, 24843, 9357, 26000, 29972, 32151, 21529, 15143, 29356, 21296, 32179, 15156, 32183, 4804, 34757, 12486, 25031, 5194, 15565, 29395, 22496, 29925}\n",
      "dict_items([(\"Lemma('complete.v.01.complete')\", 20), (\"Lemma('complete.v.05.complete')\", 1), (\"Lemma('accomplished.s.02.completed')\", 1)])\n",
      "collecting tokens for  oxidation\n",
      "indices:    {5504, 5506, 5508, 5509, 5529, 5542, 3240, 5561, 5584, 5586, 5590, 30438, 5488, 5489, 27250, 5491, 5492, 5490, 5497, 5501, 5502}\n",
      "dict_items([(\"Lemma('oxidation.n.01.oxidation')\", 19)])\n",
      "collecting tokens for  electron\n",
      "indices:    {3112, 3049, 3115, 3052, 26830, 3118, 26831, 3380}\n",
      "dict_items([(\"Lemma('electron.n.01.electron')\", 4)])\n",
      "collecting tokens for  paramagnetic\n",
      "indices:    {3043, 3140, 3046, 3112, 3049, 3050, 14796, 14798, 3056, 3057, 3058, 3070}\n",
      "dict_items([(\"Lemma('paramagnetic.a.01.paramagnetic')\", 12)])\n",
      "collecting tokens for  interpreted\n",
      "indices:    {32002, 31119, 2842, 1307, 27560, 24630, 24766, 26572, 4814, 15695, 4053, 2143, 9953, 19441, 3058, 31987, 14710, 15864, 761}\n",
      "dict_items([(\"Lemma('interpret.v.01.interpret')\", 9), (\"Lemma('translate.v.01.interpret')\", 1), (\"Lemma('rede.v.01.interpret')\", 7), (\"Lemma('interpret.v.03.interpret')\", 1), (\"Lemma('understand.v.03.interpret')\", 1)])\n",
      "collecting tokens for  models\n",
      "indices:    {21880, 32906, 25108, 5016, 29081, 4385, 9633, 7615, 29127, 29128, 29132, 2896, 26960, 29271, 21096, 28654, 28661, 29047, 14584}\n",
      "dict_items([(\"Lemma('exemplar.n.01.model')\", 1), (\"Lemma('model.n.02.model')\", 2), (\"Lemma('model.n.04.model')\", 1), (\"Lemma('model.n.01.model')\", 1), (\"Lemma('model.n.06.model')\", 1)])\n",
      "collecting tokens for  forest\n",
      "indices:    {20442, 35987, 6046}\n",
      "dict_items([(\"Lemma('forest.n.01.forest')\", 1)])\n",
      "collecting tokens for  cares\n",
      "indices:    {26376, 26380, 9045, 15449, 26618}\n",
      "dict_items([(\"Lemma('care.v.01.care')\", 3), (\"Lemma('wish.v.02.care')\", 1)])\n",
      "collecting tokens for  campers\n",
      "indices:    {11910, 11945, 11951, 11921, 11924, 11925, 11926, 11957}\n",
      "dict_items([(\"Lemma('camper.n.01.camper')\", 8)])\n",
      "collecting tokens for  preparation\n",
      "indices:    {27585}\n",
      "dict_items([])\n",
      "collecting tokens for  85\n",
      "indices:    {24737, 13185, 3233, 22533, 22504, 21932, 16253, 30574, 29134, 21621, 5496, 3290, 27581, 23358, 22527}\n",
      "dict_items([])\n",
      "collecting tokens for  90\n",
      "indices:    {29057, 4499, 11421, 11422, 21932, 4525, 2864, 21173, 27581, 22209, 29129, 25418, 21968, 31056, 28759, 20186, 14947, 14831, 12030}\n",
      "dict_items([(\"Lemma('ninety.s.01.90')\", 6)])\n",
      "collecting tokens for  loyal\n",
      "indices:    {10881, 7714, 1189, 26694, 25840, 25553, 23794, 19347, 20633, 7866, 7067, 26748, 27581}\n",
      "dict_items([(\"Lemma('loyal.a.01.loyal')\", 6)])\n",
      "collecting tokens for  et\n",
      "indices:    {9857, 30221, 2711, 33052, 34682, 4131, 426, 4783, 30261, 15671, 15417, 15674, 26327, 7257, 11481, 26338, 3944, 4201, 15725, 33011, 3578, 24830}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([])\n",
      "collecting tokens for  concerts\n",
      "indices:    {22525, 26909}\n",
      "dict_items([])\n",
      "collecting tokens for  grand\n",
      "indices:    {20163, 21542, 21589, 21599, 10911}\n",
      "dict_items([(\"Lemma('expansive.s.02.grand')\", 1)])\n",
      "collecting tokens for  occupy\n",
      "indices:    {12961, 11297, 31337, 31530, 2158, 13391, 3087, 8338, 32882, 26327, 27262}\n",
      "dict_items([(\"Lemma('occupy.v.03.occupy')\", 2), (\"Lemma('busy.v.01.occupy')\", 2), (\"Lemma('occupy.v.02.occupy')\", 1)])\n",
      "collecting tokens for  reveal\n",
      "indices:    {21280, 14369, 5670, 32073, 11371, 35213, 13390, 5103, 2649, 13330, 31859, 31220, 30835, 26327, 28152, 27865, 32346, 26332}\n",
      "dict_items([(\"Lemma('uncover.v.01.reveal')\", 12), (\"Lemma('unwrap.v.02.reveal')\", 3)])\n",
      "collecting tokens for  delicate\n",
      "indices:    {12556, 26254, 17560, 13565, 4767, 5682, 26042, 19515, 23997, 22603, 11093, 26327, 17880, 3803, 13795, 5992, 34667, 6773, 7544, 23037, 27262}\n",
      "dict_items([(\"Lemma('delicate.s.04.delicate')\", 1), (\"Lemma('delicate.s.03.delicate')\", 2), (\"Lemma('delicate.s.06.delicate')\", 1), (\"Lemma('delicate.a.01.delicate')\", 4), (\"Lemma('delicate.s.02.delicate')\", 2), (\"Lemma('finespun.s.01.delicate')\", 1)])\n",
      "collecting tokens for  flexible\n",
      "indices:    {32897, 1061, 24421, 2027, 16279, 26898, 11828, 4406, 26327, 32278, 22268, 4925}\n",
      "dict_items([(\"Lemma('flexible.a.02.flexible')\", 2), (\"Lemma('elastic.s.02.flexible')\", 1), (\"Lemma('flexible.a.01.flexible')\", 2), (\"Lemma('flexible.s.04.flexible')\", 1)])\n",
      "collecting tokens for  protein\n",
      "indices:    {11576, 27235, 3557, 3558, 27238, 3560, 4042, 3947, 1710, 3571, 4056, 27225, 27194, 11515, 2556, 3933, 3550}\n",
      "dict_items([(\"Lemma('protein.n.01.protein')\", 13)])\n",
      "collecting tokens for  molecules\n",
      "indices:    {27235, 3204, 3237, 27238, 14790, 14793, 14794, 12781, 2556}\n",
      "dict_items([(\"Lemma('molecule.n.01.molecule')\", 7)])\n",
      "collecting tokens for  insoluble\n",
      "indices:    {27235, 3588, 3589, 3590, 34726, 3566, 3218, 4125, 3542, 3997, 3582}\n",
      "dict_items([(\"Lemma('insoluble.a.01.insoluble')\", 9)])\n",
      "collecting tokens for  exceed\n",
      "indices:    {4576, 14854, 14855, 12776, 14859, 14893, 32892, 23506, 14771, 32180, 16087, 11708, 14751}\n",
      "dict_items([(\"Lemma('exceed.v.01.exceed')\", 9), (\"Lemma('exceed.v.02.exceed')\", 3), (\"Lemma('surpass.v.02.exceed')\", 1)])\n",
      "collecting tokens for  awards\n",
      "indices:    {513, 516, 485, 32710, 32357, 11338, 14891, 14893, 14894, 21583, 14868, 14871}\n",
      "dict_items([(\"Lemma('award.n.02.award')\", 2), (\"Lemma('award.n.01.award')\", 5), (\"Lemma('prize.n.01.award')\", 1)])\n",
      "collecting tokens for  boss\n",
      "indices:    {11972, 17926, 20940, 20942, 10128, 25272, 8797}\n",
      "dict_items([(\"Lemma('foreman.n.01.boss')\", 3), (\"Lemma('boss.n.03.boss')\", 1)])\n",
      "collecting tokens for  decisive\n",
      "indices:    {1350, 12198, 32011, 2603, 31819, 32141, 28121, 22585, 12282, 2587, 2652}\n",
      "dict_items([(\"Lemma('decisive.a.01.decisive')\", 6)])\n",
      "collecting tokens for  deadlock\n",
      "indices:    {1350, 22855, 22861, 23289, 182, 24697, 22621, 22622}\n",
      "dict_items([(\"Lemma('deadlock.n.01.deadlock')\", 2)])\n",
      "collecting tokens for  theology\n",
      "indices:    {28039, 21032, 1352, 1359, 1362, 14706, 28052, 1495, 1341, 1310, 7455}\n",
      "dict_items([(\"Lemma('theology.n.01.theology')\", 5), (\"Lemma('theology.n.02.theology')\", 1)])\n",
      "collecting tokens for  societies\n",
      "indices:    {4605, 31248, 16401, 2323, 20247, 32154, 28059, 4636, 4637, 2081, 20773, 4646, 4647, 2087, 4649, 2089, 12235, 32723, 13534, 4575, 4581, 14183, 4593, 5234, 4595, 4596, 4597, 4599, 4733, 2303}\n",
      "dict_items([(\"Lemma('society.n.01.society')\", 20), (\"Lemma('club.n.02.society')\", 4)])\n",
      "collecting tokens for  limits\n",
      "indices:    {31172, 32550, 28748, 3919, 15504, 7792, 2512, 16463, 11446, 27070}\n",
      "dict_items([(\"Lemma('restrict.v.03.limit')\", 1), (\"Lemma('limit.n.01.limit')\", 2), (\"Lemma('terminus_ad_quem.n.01.limit')\", 1)])\n",
      "collecting tokens for  goals\n",
      "indices:    {14146, 23429, 11209, 2924, 11788, 11728, 1302, 4702}\n",
      "dict_items([(\"Lemma('goal.n.01.goal')\", 6)])\n",
      "collecting tokens for  frequent\n",
      "indices:    {27009, 23554, 3461, 2184, 3851, 30486, 31000, 8857, 2588, 26269, 22053, 1707, 14636, 25652, 1722, 33212, 14285, 30816, 4715, 10736, 14705, 35697, 7027, 31987, 26742}\n",
      "dict_items([(\"Lemma('frequent.a.01.frequent')\", 9), (\"Lemma('frequent.s.02.frequent')\", 3), (\"Lemma('frequent.v.02.frequent')\", 1)])\n",
      "collecting tokens for  vases\n",
      "indices:    {5025, 29654, 4967}\n",
      "dict_items([(\"Lemma('vase.n.01.vase')\", 2)])\n",
      "collecting tokens for  greece\n",
      "indices:    {5016}\n",
      "dict_items([(\"Lemma('greece.n.01.Greece')\", 1)])\n",
      "collecting tokens for  non\n",
      "indices:    {13184, 16385, 4358, 1800, 11785, 3085, 1422, 7823, 10774, 10776, 10777, 10778, 1307, 16165, 4393, 11062, 13623, 11832, 4794, 11836, 12222, 10817, 10825, 4688, 11090, 11092, 16350, 1377, 10860, 3436, 37103, 2799, 2800, 4979, 10616, 13177}\n",
      "dict_items([])\n",
      "collecting tokens for  mostly\n",
      "indices:    {7822, 26631}\n",
      "dict_items([(\"Lemma('largely.r.01.mostly')\", 1)])\n",
      "collecting tokens for  vanished\n",
      "indices:    {34406, 2183, 18824, 34381, 18830, 4979, 19155, 27195, 26718}\n",
      "dict_items([(\"Lemma('disappear.v.01.vanish')\", 7), (\"Lemma('vanished.s.01.vanished')\", 1), (\"Lemma('vanish.v.02.vanish')\", 1)])\n",
      "collecting tokens for  ninth\n",
      "indices:    {27521, 194, 29339, 22995}\n",
      "dict_items([(\"Lemma('ninth.s.01.ninth')\", 1)])\n",
      "collecting tokens for  wine\n",
      "indices:    {13120, 9186, 29443, 29225, 26411, 691, 13107, 9336, 27322}\n",
      "dict_items([(\"Lemma('wine.n.01.wine')\", 4)])\n",
      "collecting tokens for  merchant\n",
      "indices:    {32648, 16463}\n",
      "dict_items([])\n",
      "collecting tokens for  beating\n",
      "indices:    {30049, 6563, 19300, 9656, 20392, 21169, 30036, 246, 24631, 8632, 22742}\n",
      "dict_items([(\"Lemma('beat.v.04.beat')\", 3), (\"Lemma('beat.v.03.beat')\", 2), (\"Lemma('beat.v.01.beat')\", 1), (\"Lemma('drum.v.01.beat')\", 1), (\"Lemma('beat.v.02.beat')\", 1)])\n",
      "collecting tokens for  reminded\n",
      "indices:    {27266, 10854, 9415, 8806, 17212, 17291, 7756, 19534, 14351, 27697, 31706, 17211, 15868, 25309, 7487}\n",
      "dict_items([(\"Lemma('prompt.v.03.remind')\", 7), (\"Lemma('remind.v.01.remind')\", 7)])\n",
      "collecting tokens for  map\n",
      "indices:    {13059, 11409, 22355, 1817, 31358}\n",
      "dict_items([(\"Lemma('map.n.01.map')\", 2)])\n",
      "collecting tokens for  divisions\n",
      "indices:    {33027, 29929, 24138, 15466, 33072, 27697, 15218, 15217, 27698, 4276}\n",
      "dict_items([(\"Lemma('division.n.01.division')\", 1), (\"Lemma('part.n.09.division')\", 3)])\n",
      "collecting tokens for  resultant\n",
      "indices:    {12517, 3306, 1099, 27697, 3250, 30743, 2840, 28891}\n",
      "dict_items([(\"Lemma('attendant.s.02.resultant')\", 5)])\n",
      "collecting tokens for  release\n",
      "indices:    {32036, 35818, 11980, 19980, 17036, 3950, 3087, 1812, 29557, 27927, 14616, 1080, 32059, 18236, 5853, 21534}\n",
      "dict_items([(\"Lemma('let_go_of.v.01.release')\", 3), (\"Lemma('exhaust.v.05.release')\", 1), (\"Lemma('turn.v.08.release')\", 1), (\"Lemma('handout.n.01.release')\", 1), (\"Lemma('liberation.n.01.release')\", 1), (\"Lemma('release.n.03.release')\", 1), (\"Lemma('dismissal.n.04.release')\", 1), (\"Lemma('release.n.01.release')\", 1), (\"Lemma('free.v.01.release')\", 1)])\n",
      "collecting tokens for  steinberg\n",
      "indices:    {31593}\n",
      "dict_items([])\n",
      "collecting tokens for  minimal\n",
      "indices:    {4352, 3462, 4362, 3466, 2061, 11428, 2097, 2614, 4281, 4287, 4292, 4294, 4297, 4299, 4313, 4320, 4323, 4325, 4327, 4338, 1785}\n",
      "dict_items([(\"Lemma('minimal.a.01.minimal')\", 21)])\n",
      "collecting tokens for  musical\n",
      "indices:    {11264, 1761, 26492, 31593, 14634, 31624, 1772, 25998, 26062, 25646, 26448, 1173, 26361, 32057, 1179, 11257, 27549}\n",
      "dict_items([(\"Lemma('musical.a.01.musical')\", 6)])\n",
      "collecting tokens for  motives\n",
      "indices:    {12322, 12323, 34339, 17321, 35757, 24624, 17009, 8242, 13040, 5309}\n",
      "dict_items([(\"Lemma('motivation.n.01.motive')\", 7)])\n",
      "collecting tokens for  conclusive\n",
      "indices:    {34401, 27266, 14855, 17321, 14897, 3954, 14865, 16215}\n",
      "dict_items([(\"Lemma('conclusive.a.01.conclusive')\", 3)])\n",
      "collecting tokens for  pointing\n",
      "indices:    {9852, 15843, 13123, 23045, 17321, 14377, 29386, 11673, 25130, 5840, 20465, 2005, 9944, 2809, 29980, 33150}\n",
      "dict_items([(\"Lemma('indicate.v.02.point')\", 5), (\"Lemma('charge.v.17.point')\", 1), (\"Lemma('orient.v.01.point')\", 1)])\n",
      "collecting tokens for  asking\n",
      "indices:    {31107, 14601, 33932, 27661, 23180, 21395, 8342, 11158, 24856, 11800, 21402, 12059, 36633, 8355, 9898, 31659, 6701, 15795, 8251, 11067, 69, 13895, 27336, 34382, 16591, 34384, 30417, 30559, 27361, 7530, 24943, 33648, 7407, 20722, 9203, 27762, 30453, 25846, 34935, 6131, 5874, 15740, 30334}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('ask.v.01.ask')\", 13), (\"Lemma('ask.v.02.ask')\", 26)])\n",
      "collecting tokens for  alive\n",
      "indices:    {3714, 19587, 1290, 19472, 1301, 30235, 8863, 9632, 16813, 26926, 23599, 19632, 10547, 32051, 19645, 36416, 32064, 34371, 32068, 10052, 6728, 33738, 36046, 21713, 2262, 34909, 23138, 14308, 5093, 36326, 7536, 22387, 32115, 34427, 25468}\n",
      "dict_items([(\"Lemma('alive.a.01.alive')\", 14), (\"Lemma('alive.s.02.alive')\", 3)])\n",
      "collecting tokens for  musicians\n",
      "indices:    {7784, 22539, 26415, 31631, 31567, 1042, 1749, 31896, 14488}\n",
      "dict_items([(\"Lemma('musician.n.01.musician')\", 3)])\n",
      "collecting tokens for  driver\n",
      "indices:    {24451, 25289, 23122, 24370, 20500, 33685, 29205, 18905}\n",
      "dict_items([(\"Lemma('driver.n.01.driver')\", 1)])\n",
      "collecting tokens for  slammed\n",
      "indices:    {17828, 21444, 17053, 453, 35434, 203, 18447, 18800, 34097, 8469, 37047, 18907, 16957}\n",
      "dict_items([(\"Lemma('slam.v.01.slam')\", 5), (\"Lemma('slam.v.02.slam')\", 7)])\n",
      "collecting tokens for  belief\n",
      "indices:    {12296, 12297, 3722, 12298, 28169, 33172, 25628, 5024, 7073, 36515, 15282, 14644, 36021, 31931, 4676, 27595, 4685, 2510, 28499, 20822, 20824, 31960, 20827, 22624, 12258, 27110, 7917, 27886, 11120, 14065, 1270, 12280}\n",
      "dict_items([(\"Lemma('belief.n.01.belief')\", 8), (\"Lemma('impression.n.01.belief')\", 2)])\n",
      "collecting tokens for  supernatural\n",
      "indices:    {22688, 28163, 4734, 28110, 28142, 4657, 28114, 4690, 28151, 28152, 13883, 4670}\n",
      "dict_items([(\"Lemma('supernatural.n.01.supernatural')\", 2), (\"Lemma('supernatural.a.01.supernatural')\", 3)])\n",
      "collecting tokens for  cosmic\n",
      "indices:    {28087, 3329, 25668, 1445, 28142, 32049, 28115, 10099, 2197, 1463, 26808, 26841, 27546, 32700, 4670, 10079}\n",
      "dict_items([(\"Lemma('cosmic.a.01.cosmic')\", 7)])\n",
      "collecting tokens for  therapeutic\n",
      "indices:    {4258, 32867, 4260, 2244, 2250, 2286, 4242, 4243, 2228, 30232, 32057, 4670}\n",
      "dict_items([(\"Lemma('therapeutic.a.02.therapeutic')\", 4), (\"Lemma('curative.s.01.therapeutic')\", 5)])\n",
      "collecting tokens for  worry\n",
      "indices:    {18688, 16518, 28680, 36110, 27279, 7697, 30999, 29851, 17052, 35869, 2204, 2590, 6562, 27427, 2210, 12069, 24614, 20135, 20014, 33327, 20539, 16572, 33598, 1599, 27200, 19657, 17741, 7641, 25827, 36072, 14570, 21100, 27506, 34168, 636, 8317}\n",
      "dict_items([(\"Lemma('worry.v.01.worry')\", 21), (\"Lemma('worry.v.03.worry')\", 2), (\"Lemma('worry.n.02.worry')\", 4), (\"Lemma('worry.v.02.worry')\", 4), (\"Lemma('concern.n.04.worry')\", 1)])\n",
      "collecting tokens for  whoever\n",
      "indices:    {16806}\n",
      "dict_items([])\n",
      "collecting tokens for  commit\n",
      "indices:    {25088, 28102, 5225, 527, 28209, 36917, 32184, 31261}\n",
      "dict_items([(\"Lemma('perpetrate.v.01.commit')\", 4), (\"Lemma('give.v.18.commit')\", 2), (\"Lemma('invest.v.01.commit')\", 1)])\n",
      "collecting tokens for  proves\n",
      "indices:    {2688, 11489, 32225, 3717, 14699, 13293, 6896, 2707, 17463, 25274, 25627, 27325}\n",
      "dict_items([(\"Lemma('prove.v.02.prove')\", 9), (\"Lemma('prove.v.01.prove')\", 3)])\n",
      "collecting tokens for  caring\n",
      "indices:    {34962, 32861, 36644, 12101}\n",
      "dict_items([(\"Lemma('care.v.01.care')\", 3), (\"Lemma('care.v.02.care')\", 1)])\n",
      "collecting tokens for  radiation\n",
      "indices:    {2824, 2813, 15183, 2832, 25400, 15159, 2872, 15133}\n",
      "dict_items([(\"Lemma('radiation.n.02.radiation')\", 2), (\"Lemma('radiation.n.01.radiation')\", 5)])\n",
      "collecting tokens for  thermal\n",
      "indices:    {2829, 30096, 3092, 3100, 3231, 3238, 3126, 3262, 2887, 3277, 3287, 3041, 2794, 2795, 14829, 2798, 14830, 2799, 2800, 2802, 2803, 2804, 2806, 2941, 2814}\n",
      "dict_items([(\"Lemma('thermal.a.01.thermal')\", 23)])\n",
      "collecting tokens for  origin\n",
      "indices:    {30218, 2828, 14098, 1044, 16406, 16407, 16408, 2467, 4520, 32305, 30394, 20417, 32322, 2814, 24154, 26075, 4062, 32992, 11109, 2534, 5482, 32755, 36980, 2803, 4982, 2812, 28030, 32511}\n",
      "dict_items([(\"Lemma('beginning.n.04.origin')\", 10), (\"Lemma('origin.n.04.origin')\", 1), (\"Lemma('origin.n.02.origin')\", 3), (\"Lemma('origin.n.03.origin')\", 1)])\n",
      "collecting tokens for  venus\n",
      "indices:    {8381}\n",
      "dict_items([(\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  cm\n",
      "indices:    {2851, 2853, 14790, 14793, 2798, 2833, 2802, 3540, 2806, 2807, 2843, 2844, 2814, 2815}\n",
      "dict_items([(\"Lemma('centimeter.n.01.cm')\", 14)])\n",
      "collecting tokens for  jupiter\n",
      "indices:    {2812}\n",
      "dict_items([(\"Lemma('jupiter.n.01.Jupiter')\", 1)])\n",
      "collecting tokens for  1956\n",
      "indices:    {25607, 265, 3978, 23058, 2834, 33045, 277, 2844, 21281, 4143, 4021, 27830, 32336, 22864, 15321, 23131, 3933, 15327, 15331, 16235, 23020, 25837, 3955, 25723, 2814}\n",
      "dict_items([])\n",
      "collecting tokens for  1957\n",
      "indices:    {23426, 4747, 4748, 4749, 15247, 15248, 4752, 4755, 4758, 279, 4759, 15257, 4129, 4001, 4771, 5414, 25770, 23469, 4022, 14905, 24123, 22205, 17345, 27076, 22864, 31830, 15326, 23902, 23020, 22894, 27892, 3957, 24052, 3962, 2814}\n",
      "dict_items([])\n",
      "collecting tokens for  axis\n",
      "indices:    {30280, 3087, 27541, 3030, 4574}\n",
      "dict_items([(\"Lemma('axis.n.01.axis')\", 2)])\n",
      "collecting tokens for  layer\n",
      "indices:    {3078, 2794, 31850, 29773, 31375, 31407, 21206}\n",
      "dict_items([(\"Lemma('layer.n.01.layer')\", 1), (\"Lemma('layer.n.02.layer')\", 1)])\n",
      "collecting tokens for  directly\n",
      "indices:    {17536, 16354, 34085, 28773, 27782, 3880, 4202, 15438, 35727, 3793, 18225, 25460, 29368, 31993, 30202, 35644, 27545}\n",
      "dict_items([(\"Lemma('directly.r.01.directly')\", 5), (\"Lemma('directly.r.02.directly')\", 2)])\n",
      "collecting tokens for  repeat\n",
      "indices:    {28811, 25266, 17015, 5656, 12671}\n",
      "dict_items([(\"Lemma('repeat.n.01.repeat')\", 1), (\"Lemma('repeat.v.01.repeat')\", 3), (\"Lemma('duplicate.v.01.repeat')\", 1)])\n",
      "collecting tokens for  properties\n",
      "indices:    {11520, 32772, 27532, 25100, 27534, 11535, 32399, 3472, 3991, 3229, 4385, 27554, 4003, 27556, 4007, 2988, 13999, 3510, 14775, 4420, 4421, 3403, 3033, 3420, 12125, 2783, 21609, 14826, 11114, 3052, 3186, 2553, 30077}\n",
      "dict_items([(\"Lemma('place.n.02.property')\", 1), (\"Lemma('property.n.02.property')\", 20), (\"Lemma('property.n.01.property')\", 1)])\n",
      "collecting tokens for  nearing\n",
      "indices:    {18624, 33883, 21972, 23429}\n",
      "dict_items([(\"Lemma('approach.v.01.near')\", 4)])\n",
      "collecting tokens for  analyzed\n",
      "indices:    {31143, 16455, 24811, 27181, 3277, 32911, 3343, 15733, 2526, 33054}\n",
      "dict_items([(\"Lemma('analyze.v.01.analyze')\", 9), (\"Lemma('analyze.v.02.analyze')\", 1)])\n",
      "collecting tokens for  variations\n",
      "indices:    {13988, 31909, 3335, 29127, 30988, 3919, 5553, 4980}\n",
      "dict_items([(\"Lemma('variation.n.01.variation')\", 3), (\"Lemma('variation.n.05.variation')\", 1)])\n",
      "collecting tokens for  narrow\n",
      "indices:    {5891, 27908, 17542, 13837, 36754, 18709, 29334, 7829, 37015, 12569, 24345, 533, 33822, 2848, 17580, 3137, 21699, 23494, 18887, 6090, 33611, 9170, 18520, 27864, 27866, 29275, 35935, 1891, 1893, 13541, 31471, 33904, 36340, 17535}\n",
      "dict_items([(\"Lemma('narrow.a.01.narrow')\", 16), (\"Lemma('narrow-minded.a.02.narrow')\", 1)])\n",
      "collecting tokens for  safely\n",
      "indices:    {22977, 16097, 19395, 18886, 15463, 21388, 8077, 29692, 29979, 30524, 8445}\n",
      "dict_items([(\"Lemma('safely.r.01.safely')\", 6)])\n",
      "collecting tokens for  wind\n",
      "indices:    {35203, 31395, 18855, 7048, 28318, 34573, 35248, 26773, 30587, 35198}\n",
      "dict_items([(\"Lemma('wind.n.01.wind')\", 2)])\n",
      "collecting tokens for  gentile\n",
      "indices:    {22995}\n",
      "dict_items([])\n",
      "collecting tokens for  homer\n",
      "indices:    {20880, 488, 392, 453}\n",
      "dict_items([(\"Lemma('homer.n.01.homer')\", 3)])\n",
      "collecting tokens for  100000\n",
      "indices:    {28707, 12696, 23525, 28649, 172, 23533, 30896, 11924, 28344, 23353, 3162, 12702}\n",
      "dict_items([(\"Lemma('hundred_thousand.n.01.100000')\", 1)])\n",
      "collecting tokens for  hypothalamic\n",
      "indices:    {4225, 4226, 4231, 4234, 4236, 4238, 4241, 4243, 4247, 4249, 4253, 4254, 4255, 4256, 4276, 4277, 4278, 4279, 4209, 4212, 4215, 4218, 4220, 4222}\n",
      "dict_items([(\"Lemma('hypothalamic.a.01.hypothalamic')\", 24)])\n",
      "collecting tokens for  experiment\n",
      "indices:    {4480, 31874, 33162, 12299, 27928, 14106, 1051, 31133, 4384, 11683, 4263, 12328, 4393, 24104, 27179, 14641, 4786, 4403, 4402, 4405, 4406, 4404, 2611, 31100, 1600, 4420, 26564, 33229, 27342, 14799, 11473, 4436, 26966, 4438, 23131, 4444, 4443, 4449, 4450, 28386, 4456, 4459, 747, 29550, 4848, 4209, 4466, 3056, 4467, 31090, 4476, 4474, 32892}\n",
      "dict_items([(\"Lemma('experiment.n.01.experiment')\", 26), (\"Lemma('experiment.n.03.experiment')\", 3), (\"Lemma('experiment.n.02.experiment')\", 4), (\"Lemma('experiment.v.01.experiment')\", 6)])\n",
      "collecting tokens for  affect\n",
      "indices:    {16706, 28931, 1865, 3021, 36397, 23184, 13713, 3090, 31026, 2515, 27989, 31056, 13719, 31000, 28601, 22648, 3966}\n",
      "dict_items([(\"Lemma('affect.v.01.affect')\", 10), (\"Lemma('affect.v.02.affect')\", 7)])\n",
      "collecting tokens for  parade\n",
      "indices:    {20608, 30523, 35396, 21093, 9503, 20590, 29205, 20598, 32630, 14042, 30042, 14043, 27420, 26621, 35294, 29247}\n",
      "dict_items([(\"Lemma('parade.n.01.parade')\", 1)])\n",
      "collecting tokens for  tanks\n",
      "indices:    {859, 31510}\n",
      "dict_items([(\"Lemma('tank.n.01.tank')\", 1)])\n",
      "collecting tokens for  artillery\n",
      "indices:    {13217, 12898, 13062, 12473, 22847}\n",
      "dict_items([(\"Lemma('artillery.n.01.artillery')\", 1), (\"Lemma('artillery.n.02.artillery')\", 1), (\"Lemma('weapon.n.02.artillery')\", 1)])\n",
      "collecting tokens for  48\n",
      "indices:    {20704, 20804, 11563, 22827, 3821, 28784, 3828, 374, 3831, 23353, 3098, 27164}\n",
      "dict_items([])\n",
      "collecting tokens for  cuba\n",
      "indices:    {28398}\n",
      "dict_items([])\n",
      "collecting tokens for  cuban\n",
      "indices:    {23332}\n",
      "dict_items([])\n",
      "collecting tokens for  regarded\n",
      "indices:    {36480, 20481, 36354, 22027, 18316, 6931, 12307, 15766, 1305, 32154, 22681, 16285, 36125, 8870, 14634, 4402, 29109, 1720, 27197, 30274, 27715, 16460, 4817, 23379, 23638, 14693, 13158, 5612, 32888}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('see.v.05.regard')\", 8), (\"Lemma('regard.v.02.regard')\", 4), (\"Lemma('think_of.v.03.regard_as')\", 1)])\n",
      "collecting tokens for  buying\n",
      "indices:    {11650, 37133, 24336, 12697, 11945, 2217, 11948, 22065, 22066, 32309, 18871, 27202, 1610, 21972, 11733, 23139, 20070, 32359, 2279, 12139, 21997, 33139}\n",
      "dict_items([(\"Lemma('buy.v.01.buy')\", 15), (\"Lemma('buying.n.01.buying')\", 3)])\n",
      "collecting tokens for  pilots\n",
      "indices:    {18816, 27106, 21736, 18698, 21717, 30523, 18719}\n",
      "dict_items([(\"Lemma('pilot.n.01.pilot')\", 3)])\n",
      "collecting tokens for  formed\n",
      "indices:    {16644, 11401, 4746, 13584, 7443, 5142, 4758, 19224, 19225, 5402, 3099, 28699, 4765, 7711, 32674, 2083, 33058, 25123, 25122, 5430, 4665, 5563, 9149, 33598, 25279, 30526, 27328, 31556, 26824, 12880, 32978, 9171, 2900, 23513, 1372, 3933, 3935, 3936, 31970, 21737, 31978, 26737, 15857, 2425, 20733}\n",
      "dict_items([(\"Lemma('form.v.03.form')\", 9), (\"Lemma('form.v.02.form')\", 8), (\"Lemma('form.v.01.form')\", 16), (\"Lemma('shape.v.02.form')\", 4), (\"Lemma('shape.v.03.form')\", 1), (\"Lemma('imprint.v.01.form')\", 2)])\n",
      "collecting tokens for  ranks\n",
      "indices:    {11202, 259, 33829, 12550, 6919, 5606, 21737, 6922, 33803, 24588, 35635, 14038, 27671, 20631, 13339, 12606}\n",
      "dict_items([(\"Lemma('social_station.n.01.rank')\", 1), (\"Lemma('rank.n.01.rank')\", 3), (\"Lemma('rank.v.01.rank')\", 1), (\"Lemma('rank.n.02.rank')\", 1), (\"Lemma('rank_and_file.n.01.rank')\", 3)])\n",
      "collecting tokens for  project\n",
      "indices:    {20736, 20737, 30215, 145, 14484, 35861, 15516, 15521, 8232, 15154, 27831, 20669, 25031, 24776, 14176, 11877, 22373, 22501, 14827, 20728, 20729, 29561, 32892, 20733, 20734}\n",
      "dict_items([(\"Lemma('stick_out.v.01.project')\", 1), (\"Lemma('undertaking.n.01.project')\", 5), (\"Lemma('project.v.01.project')\", 1)])\n",
      "collecting tokens for  halted\n",
      "indices:    {24417, 6594, 35814, 8583, 18536, 21737, 18953, 35306, 12428, 8593, 35445}\n",
      "dict_items([(\"Lemma('stop.v.01.halt')\", 3), (\"Lemma('stop.v.03.halt')\", 1), (\"Lemma('halt.v.01.halt')\", 3)])\n",
      "collecting tokens for  allied\n",
      "indices:    {26211, 20237}\n",
      "dict_items([])\n",
      "collecting tokens for  communists\n",
      "indices:    {20283}\n",
      "dict_items([])\n",
      "collecting tokens for  sincere\n",
      "indices:    {25125, 37064, 6569, 28330, 14219, 28265, 27667, 19509, 26582, 25175, 4729, 9145, 32254}\n",
      "dict_items([(\"Lemma('sincere.a.01.sincere')\", 5)])\n",
      "collecting tokens for  wanting\n",
      "indices:    {18180, 5894, 7558, 21803, 25741, 19630, 8144, 34897, 24278, 25175, 22009}\n",
      "dict_items([(\"Lemma('desire.v.01.want')\", 10)])\n",
      "collecting tokens for  mexican\n",
      "indices:    {5051}\n",
      "dict_items([(\"Lemma('mexican.n.01.Mexican')\", 1)])\n",
      "collecting tokens for  trick\n",
      "indices:    {34467, 34980, 24548, 12069, 34951, 432, 18003, 34963, 2643}\n",
      "dict_items([(\"Lemma('trick.n.01.trick')\", 1), (\"Lemma('trick.n.02.trick')\", 1), (\"Lemma('trick.n.03.trick')\", 1)])\n",
      "collecting tokens for  herd\n",
      "indices:    {34915, 31269, 13576, 30412, 34897, 18002, 18003, 35540, 35543, 18010}\n",
      "dict_items([(\"Lemma('herd.n.01.herd')\", 3)])\n",
      "collecting tokens for  rules\n",
      "indices:    {15704, 20517}\n",
      "dict_items([(\"Lemma('principle.n.01.rule')\", 1)])\n",
      "collecting tokens for  automatically\n",
      "indices:    {36644, 14314, 16075, 18683, 14259, 16120, 6715}\n",
      "dict_items([(\"Lemma('automatically.r.01.automatically')\", 6)])\n",
      "collecting tokens for  ahead\n",
      "indices:    {7804, 30727, 17580, 29389, 36716, 21585, 13138, 22930, 6101, 23605, 5047, 29369, 11900, 15390}\n",
      "dict_items([(\"Lemma('ahead.r.01.ahead')\", 1), (\"Lemma('ahead.r.03.ahead')\", 2), (\"Lemma('ahead.r.02.ahead')\", 2)])\n",
      "collecting tokens for  filed\n",
      "indices:    {15247, 14869, 34710, 21783, 26, 14880, 15268, 6057, 15276, 5816, 21688, 15550, 30911, 35778, 15298, 20680, 15562, 20683, 15571, 23895, 22124, 15597, 33015, 21627}\n",
      "dict_items([(\"Lemma('file.v.01.file')\", 16), (\"Lemma('charge.v.06.file')\", 2), (\"Lemma('file.v.05.file')\", 1), (\"Lemma('file.v.05.file_away')\", 1), (\"Lemma('file.v.03.file')\", 1)])\n",
      "collecting tokens for  offers\n",
      "indices:    {23425, 22146, 13318, 14859, 29323, 21017, 2722, 14120, 32050, 5043, 4664, 15163, 29245, 2109, 1743, 976, 1745, 26450, 23511, 14685, 29278, 2783, 32869, 27370, 23530, 29298, 883}\n",
      "dict_items([(\"Lemma('offer.v.01.offer')\", 23), (\"Lemma('offer.v.02.offer')\", 2), (\"Lemma('offer.v.04.offer')\", 1), (\"Lemma('offer.n.02.offer')\", 1)])\n",
      "collecting tokens for  administrative\n",
      "indices:    {15296, 32366, 4626, 14867, 24148}\n",
      "dict_items([(\"Lemma('administrative.a.01.administrative')\", 2)])\n",
      "collecting tokens for  management\n",
      "indices:    {32267, 32272, 4628, 2718, 36641, 2724, 11698, 11707, 444, 32317, 2749, 11709, 32322, 11718, 11721, 3402, 25057, 32364, 11640, 32891, 25212}\n",
      "dict_items([(\"Lemma('management.n.01.management')\", 7), (\"Lemma('management.n.02.management')\", 3)])\n",
      "collecting tokens for  courses\n",
      "indices:    {16260, 13319, 16266, 16274, 23186, 13204, 16282, 12826, 157, 158, 2723, 2083, 46, 2100, 32695, 32696, 13241, 26044, 2115, 13275, 13276, 13277, 13283, 13284, 34920, 13291, 13292, 2034, 33140, 2036, 2037, 16247, 2040, 2044, 2303}\n",
      "dict_items([(\"Lemma('course.n.01.course')\", 26), (\"Lemma('course.n.03.course')\", 1)])\n",
      "collecting tokens for  constructive\n",
      "indices:    {11108, 1349, 32870, 27847, 11722, 25963, 33708, 22350, 32879, 20273, 1816, 4764}\n",
      "dict_items([(\"Lemma('constructive.a.01.constructive')\", 5)])\n",
      "collecting tokens for  suggestions\n",
      "indices:    {20962, 16067, 17826, 16136, 29512, 32905, 25963, 23180, 22733, 31182, 1583, 15378, 15251, 15412, 16025, 24570, 15417}\n",
      "dict_items([(\"Lemma('suggestion.n.02.suggestion')\", 4), (\"Lemma('suggestion.n.01.suggestion')\", 5)])\n",
      "collecting tokens for  critical\n",
      "indices:    {32901, 3205, 3207, 3206, 8464, 3473, 5753, 2705, 13204, 27029, 27158, 23575, 4249, 15521, 20260, 20264, 14381, 2350, 22189, 21173, 27331, 16324, 27332, 1861, 26189, 3414, 2655, 20322, 16355, 28777, 25963, 32879, 3060, 14841}\n",
      "dict_items([(\"Lemma('critical.s.04.critical')\", 3), (\"Lemma('critical.a.01.critical')\", 5), (\"Lemma('critical.a.06.critical')\", 1), (\"Lemma('critical.a.03.critical')\", 3), (\"Lemma('critical.a.02.critical')\", 5), (\"Lemma('critical.s.05.critical')\", 2)])\n",
      "collecting tokens for  startled\n",
      "indices:    {8865, 33670, 8266, 20139, 33615, 34610, 9172, 9685, 9367, 35352, 6362, 17019, 8828}\n",
      "dict_items([(\"Lemma('startled.s.01.startled')\", 5), (\"Lemma('startle.v.01.startle')\", 5)])\n",
      "collecting tokens for  stall\n",
      "indices:    {18368, 18371, 33414, 36231, 18439, 6472, 18379, 7116, 18349, 18477, 18478, 6351, 34682, 18491}\n",
      "dict_items([(\"Lemma('stall.n.01.stall')\", 8), (\"Lemma('stall.n.03.stall')\", 1), (\"Lemma('booth.n.02.stall')\", 2)])\n",
      "collecting tokens for  original\n",
      "indices:    {24192, 20738, 11398, 3590, 28041, 26505, 30732, 31892, 5269, 4500, 25120, 11297, 31522, 29217, 25636, 31653, 21923, 25638, 34483, 25654, 25655, 3897, 15289, 31034, 26940, 9145, 10621, 15296, 15553, 26307, 4932, 3909, 30532, 11640, 15304, 3145, 26954, 18760, 27210, 13645, 30534, 1744, 1878, 2136, 26078, 11232, 2145, 2147, 14565, 1767, 25704, 35817, 9838, 20592, 1778, 11379, 37107, 29940, 15351, 12536, 28925, 20475, 29948, 26621}\n",
      "dict_items([(\"Lemma('original.a.03.original')\", 5), (\"Lemma('original.s.01.original')\", 15), (\"Lemma('original.s.02.original')\", 6), (\"Lemma('original.n.02.original')\", 1), (\"Lemma('master.n.06.original')\", 3)])\n",
      "collecting tokens for  welfare\n",
      "indices:    {13}\n",
      "dict_items([(\"Lemma('social_welfare.n.01.welfare')\", 1)])\n",
      "collecting tokens for  sir\n",
      "indices:    {17626}\n",
      "dict_items([(\"Lemma('sir.n.01.sir')\", 1)])\n",
      "collecting tokens for  editorial\n",
      "indices:    {25034, 25035, 25890, 10655}\n",
      "dict_items([(\"Lemma('column.n.05.editorial')\", 1)])\n",
      "collecting tokens for  slum\n",
      "indices:    {33666, 13321, 25098, 13322, 1835, 25099, 25101, 12636}\n",
      "dict_items([(\"Lemma('slum.n.01.slum')\", 1)])\n",
      "collecting tokens for  magnificent\n",
      "indices:    {22400, 10883, 6408, 29325, 5016, 27288, 26393, 26655, 26528, 6050, 5922, 303, 29251, 11221, 32225, 26083, 13940, 26999, 4728}\n",
      "dict_items([(\"Lemma('brilliant.s.03.magnificent')\", 9)])\n",
      "collecting tokens for  flesh\n",
      "indices:    {7557, 28295, 3719, 35471, 35616, 28203, 7222, 8120, 7352, 7611, 33852, 5827, 5828, 28232, 27465, 36048, 35154, 14290, 2644, 14293, 1494, 2654, 28254, 7649, 9316, 28263, 7144, 34922, 10604, 27504, 7792, 15734}\n",
      "dict_items([(\"Lemma('flesh.n.01.flesh')\", 9), (\"Lemma('human_body.n.01.flesh')\", 7)])\n",
      "collecting tokens for  chancellor\n",
      "indices:    {23902}\n",
      "dict_items([])\n",
      "collecting tokens for  chicken\n",
      "indices:    {22137, 30466, 10019}\n",
      "dict_items([(\"Lemma('chicken.n.01.chicken')\", 1)])\n",
      "collecting tokens for  limit\n",
      "indices:    {11744, 32160, 16418, 16354, 27844, 16356, 16358, 30917, 11816, 16298, 11754, 22830, 29425, 3988, 3386}\n",
      "dict_items([(\"Lemma('limit.n.01.limit')\", 5), (\"Lemma('restrict.v.03.limit')\", 4), (\"Lemma('limit.v.02.limit')\", 2)])\n",
      "collecting tokens for  wage\n",
      "indices:    {16320, 16354, 16356, 16358, 16364, 16366, 20654, 24656, 16337, 16372, 16374, 16375, 16383, 16351}\n",
      "dict_items([(\"Lemma('wage.n.01.wage')\", 12), (\"Lemma('engage.v.07.wage')\", 2)])\n",
      "collecting tokens for  heights\n",
      "indices:    {664, 7822}\n",
      "dict_items([(\"Lemma('acme.n.01.height')\", 1)])\n",
      "collecting tokens for  rustling\n",
      "indices:    {18211, 9572, 9188, 18309, 18248, 18313, 18319, 9556, 18298}\n",
      "dict_items([(\"Lemma('rustle.v.01.rustle')\", 3), (\"Lemma('rustling.n.01.rustling')\", 4), (\"Lemma('rustle.v.02.rustle')\", 2)])\n",
      "collecting tokens for  driven\n",
      "indices:    {9217, 5377, 21635, 13832, 27801, 29981, 12865, 18883, 22220, 33746, 32091, 13915, 21214, 22241, 6763, 21611, 19056, 10357, 22394}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('drive.v.01.drive')\", 5), (\"Lemma('drive.v.02.drive')\", 1), (\"Lemma('drive.v.05.drive')\", 2), (\"Lemma('drive.v.08.drive')\", 1), (\"Lemma('force.v.06.drive')\", 2), (\"Lemma('drive.v.07.drive')\", 3), (\"Lemma('drive.v.03.drive')\", 2)])\n",
      "collecting tokens for  wyoming\n",
      "indices:    {31261}\n",
      "dict_items([])\n",
      "collecting tokens for  presently\n",
      "indices:    {23252, 33102}\n",
      "dict_items([])\n",
      "collecting tokens for  furnace\n",
      "indices:    {30562, 36132, 36134, 30151, 36136, 30123, 30124, 30126}\n",
      "dict_items([])\n",
      "collecting tokens for  grandma\n",
      "indices:    {36140}\n",
      "dict_items([])\n",
      "collecting tokens for  dealer\n",
      "indices:    {29858, 22890, 11659, 23150, 6287, 1615, 28693, 22005, 11127, 22008, 11898}\n",
      "dict_items([(\"Lemma('trader.n.01.dealer')\", 3), (\"Lemma('dealer.n.02.dealer')\", 1)])\n",
      "collecting tokens for  pickup\n",
      "indices:    {21981, 24833, 17222, 33767, 33864, 33833, 21996, 21877, 33878, 24025, 1661}\n",
      "dict_items([(\"Lemma('pickup.n.03.pickup')\", 1), (\"Lemma('pickup.n.02.pickup')\", 1)])\n",
      "collecting tokens for  persistence\n",
      "indices:    {4644, 32969, 1930, 16184, 13657, 16188, 16189}\n",
      "dict_items([(\"Lemma('continuity.n.03.persistence')\", 4), (\"Lemma('doggedness.n.01.persistence')\", 2)])\n",
      "collecting tokens for  piled\n",
      "indices:    {33765, 20071, 18855, 12714, 13748, 30869, 9113, 9148, 23806}\n",
      "dict_items([(\"Lemma('stack.v.02.pile')\", 5), (\"Lemma('accumulate.v.02.pile_up')\", 1), (\"Lemma('throng.v.01.pile')\", 2)])\n",
      "collecting tokens for  roared\n",
      "indices:    {30370, 33828, 33765, 30379, 17036, 6959, 34897, 33842, 18900, 9182, 7094, 6902, 10526, 12735}\n",
      "dict_items([(\"Lemma('howl.v.01.roar')\", 4), (\"Lemma('bellow.v.02.roar')\", 1), (\"Lemma('roar.v.01.roar')\", 7), (\"Lemma('thunder.v.02.roar')\", 1)])\n",
      "collecting tokens for  sped\n",
      "indices:    {6466, 31812, 33765, 33767, 9835, 6384, 21331, 35262}\n",
      "dict_items([(\"Lemma('travel_rapidly.v.01.speed')\", 2), (\"Lemma('rush.v.01.speed')\", 4), (\"Lemma('speed.v.04.speed')\", 1), (\"Lemma('accelerate.v.01.speed')\", 1)])\n",
      "collecting tokens for  admired\n",
      "indices:    {37026, 643, 9156, 5351, 5322, 19595, 7279, 14417, 9425, 14452, 19548, 29215}\n",
      "dict_items([(\"Lemma('admire.v.01.admire')\", 8), (\"Lemma('admire.v.02.admire')\", 4)])\n",
      "collecting tokens for  escape\n",
      "indices:    {35809, 2182, 35911, 8232, 6505, 27430, 33836, 14576}\n",
      "dict_items([(\"Lemma('miss.v.09.escape')\", 2), (\"Lemma('escape.v.01.escape')\", 2), (\"Lemma('get_off.v.05.escape')\", 1)])\n",
      "collecting tokens for  beef\n",
      "indices:    {30466, 11536, 24229, 22310, 5036, 24237, 11564, 11573, 11586, 18245, 11592, 7113, 30412, 11608, 7134, 29536, 11511, 11515, 30463}\n",
      "dict_items([(\"Lemma('beef.n.01.beef')\", 6), (\"Lemma('cattleman.n.01.beef_man')\", 1), (\"Lemma('beef.n.02.beef')\", 3)])\n",
      "collecting tokens for  vegetables\n",
      "indices:    {30496, 29412, 24229, 5548, 30483, 12116, 30484, 24245, 12150, 30420, 30457}\n",
      "dict_items([(\"Lemma('vegetable.n.01.vegetable')\", 3)])\n",
      "collecting tokens for  museum\n",
      "indices:    {22496, 25700}\n",
      "dict_items([])\n",
      "collecting tokens for  chase\n",
      "indices:    {20970}\n",
      "dict_items([])\n",
      "collecting tokens for  avenue\n",
      "indices:    {21508}\n",
      "dict_items([])\n",
      "collecting tokens for  southwest\n",
      "indices:    {31448, 30523, 14413}\n",
      "dict_items([(\"Lemma('southwest.n.02.Southwest')\", 1)])\n",
      "collecting tokens for  achievements\n",
      "indices:    {26757, 2565, 12583, 421, 777, 13387, 5008, 28081, 27379, 5016, 2620, 2622, 32735}\n",
      "dict_items([(\"Lemma('accomplishment.n.01.achievement')\", 9)])\n",
      "collecting tokens for  skill\n",
      "indices:    {32876, 25535}\n",
      "dict_items([])\n",
      "collecting tokens for  employers\n",
      "indices:    {16257, 25346, 13281, 18244, 22799, 24211, 22808, 22748}\n",
      "dict_items([(\"Lemma('employer.n.01.employer')\", 3)])\n",
      "collecting tokens for  types\n",
      "indices:    {3843, 32900, 3846, 3975, 3848, 32521, 3849, 3851, 33164, 13203, 4249, 2970, 16283, 32411, 32413, 4510, 4257, 2721, 16291, 32289, 32421, 16292, 1319, 2346, 13994, 13995, 685, 32942, 23470, 32941, 2737, 32946, 32950, 14008, 16057, 14777, 5560, 3774, 16063, 3264, 2755, 3268, 3783, 15816, 12233, 29901, 24914, 12115, 28887, 11608, 34520, 23514, 3803, 29915, 33113, 32343, 32731, 32737, 11622, 14056, 14057, 1898, 3819, 3583, 1776, 10610, 20340, 5240, 25210, 3963, 22142, 3711}\n",
      "dict_items([(\"Lemma('type.n.01.type')\", 26), (\"Lemma('character.n.05.type')\", 1)])\n",
      "collecting tokens for  bathroom\n",
      "indices:    {7489, 710, 7431, 33385, 19664, 30199, 7420, 7422}\n",
      "dict_items([(\"Lemma('bathroom.n.01.bathroom')\", 6)])\n",
      "collecting tokens for  bedroom\n",
      "indices:    {36098, 22149, 22150, 7431, 19079, 35081, 22282, 7307, 35084, 16651, 35973, 17813, 30906, 16832, 8385, 8390, 5453, 16845, 36181, 16854, 9303, 7000, 21212, 7393, 8163, 11108, 36968, 8425, 8429, 23024, 23025, 12018, 33908, 30202, 9340, 17406}\n",
      "dict_items([(\"Lemma('bedroom.n.01.bedroom')\", 18)])\n",
      "collecting tokens for  judging\n",
      "indices:    {24131, 28598}\n",
      "dict_items([(\"Lemma('estimate.v.01.judge')\", 1)])\n",
      "collecting tokens for  photographs\n",
      "indices:    {36672, 1825, 8865, 7431, 2408, 26953, 7434, 26539, 31020, 3027, 26838, 2071, 1048, 11418, 26782, 34687}\n",
      "dict_items([(\"Lemma('photograph.n.01.photograph')\", 8), (\"Lemma('photograph.v.01.photograph')\", 1), (\"Lemma('photograph.v.02.photograph')\", 1)])\n",
      "collecting tokens for  belong\n",
      "indices:    {3204, 3461, 7431, 2700, 32923, 26781, 11293, 21919, 26662, 3753, 13619, 1341, 28228, 20047, 19923, 23524, 25317, 27365, 27367, 27368, 14309, 27370, 28137, 17391, 2676}\n",
      "dict_items([(\"Lemma('belong.v.02.belong')\", 3), (\"Lemma('belong_to.v.01.belong_to')\", 1), (\"Lemma('belong.v.01.belong')\", 3), (\"Lemma('belong.v.03.belong')\", 2)])\n",
      "collecting tokens for  motive\n",
      "indices:    {13824, 13328, 25328, 17202, 17171, 27545, 32027}\n",
      "dict_items([(\"Lemma('motivation.n.01.motive')\", 3), (\"Lemma('motive.s.01.motive')\", 1)])\n",
      "collecting tokens for  entries\n",
      "indices:    {15872, 15938, 26502, 15946, 28593, 21493, 28536, 33017, 15962}\n",
      "dict_items([(\"Lemma('entry.n.01.entry')\", 4)])\n",
      "collecting tokens for  wisconsin\n",
      "indices:    {27003}\n",
      "dict_items([])\n",
      "collecting tokens for  kentucky\n",
      "indices:    {36256}\n",
      "dict_items([])\n",
      "collecting tokens for  rear\n",
      "indices:    {18177, 35393, 21635, 18916, 6309, 18039, 35403, 35439, 8944, 28945, 18961, 23346, 29812, 33423, 29750, 5911, 35738}\n",
      "dict_items([(\"Lemma('rear.n.02.rear')\", 1), (\"Lemma('back.n.03.rear')\", 1)])\n",
      "collecting tokens for  stockade\n",
      "indices:    {35424, 35297, 35393, 35331, 35402, 35341, 35406, 12468, 35351, 35386}\n",
      "dict_items([(\"Lemma('stockade.n.01.stockade')\", 1)])\n",
      "collecting tokens for  gen.\n",
      "indices:    {20975}\n",
      "dict_items([])\n",
      "collecting tokens for  displacement\n",
      "indices:    {28899, 12963, 28901, 28900, 28902, 28905, 16458, 28909, 28910, 28917, 16182, 28919, 32856, 28927}\n",
      "dict_items([(\"Lemma('supplanting.n.01.displacement')\", 2), (\"Lemma('shift.n.01.displacement')\", 1)])\n",
      "collecting tokens for  solids\n",
      "indices:    {5547, 5549, 5550, 5551, 5554, 5555, 5556, 5557, 5559, 3003}\n",
      "dict_items([(\"Lemma('solid.n.02.solid')\", 1), (\"Lemma('solid.n.01.solid')\", 9)])\n",
      "collecting tokens for  kissed\n",
      "indices:    {5731, 10664, 10665, 35306, 35312, 35281, 7921, 10071, 35963, 36188}\n",
      "dict_items([(\"Lemma('snog.v.01.kiss')\", 10)])\n",
      "collecting tokens for  arbitrary\n",
      "indices:    {11778, 26115, 27555, 14666, 32842, 4363, 15789, 4430, 32784, 4753, 16178, 32785, 32820, 17173, 32504}\n",
      "dict_items([(\"Lemma('arbitrary.a.01.arbitrary')\", 8)])\n",
      "collecting tokens for  achieved\n",
      "indices:    {1792, 30977, 24193, 25601, 29060, 19720, 523, 4619, 24205, 13841, 32914, 1555, 2066, 28049, 28311, 4762, 26907, 542, 14241, 5026, 24741, 14247, 12457, 29487, 687, 1331, 2101, 14776, 11963, 29888, 27077, 3271, 14794, 3152, 27732, 1495, 31710, 31712, 16226, 32999, 23400, 30823, 31719, 12912, 28144, 14194, 31733, 12918, 13815, 37118}\n",
      "dict_items([(\"Lemma('achieve.v.01.achieve')\", 26)])\n",
      "collecting tokens for  rivers\n",
      "indices:    {6595, 27051}\n",
      "dict_items([(\"Lemma('river.n.01.river')\", 1)])\n",
      "collecting tokens for  dairy\n",
      "indices:    {11592, 11594, 3979, 30414, 11567, 24248, 11601, 11605, 11511, 11608, 11578, 11515, 24253}\n",
      "dict_items([(\"Lemma('dairy_cattle.n.01.dairy_cattle')\", 1), (\"Lemma('dairy.n.01.dairy')\", 1), (\"Lemma('dairyman.n.01.dairyman')\", 1)])\n",
      "collecting tokens for  farms\n",
      "indices:    {7841, 25731, 30440, 19593, 29246, 30414, 7823, 21999, 31854, 7822, 7827, 36824, 21016, 25, 28414}\n",
      "dict_items([(\"Lemma('farm.n.01.farm')\", 5)])\n",
      "collecting tokens for  compost\n",
      "indices:    {1641, 1642, 30412, 30414, 30415, 30416, 1616, 30425}\n",
      "dict_items([(\"Lemma('compost.n.01.compost')\", 3)])\n",
      "collecting tokens for  wise\n",
      "indices:    {142}\n",
      "dict_items([])\n",
      "collecting tokens for  realize\n",
      "indices:    {16384, 12802, 25347, 24196, 13306, 14088, 5898, 14, 26390, 32662, 14237, 30749, 18846, 30626, 12834, 15398, 2087, 11051, 23085, 11949, 32685, 30769, 7731, 22710, 2360, 22209, 11341, 25166, 31440, 26072, 27356, 13277, 14174, 15456, 10852, 26981, 24554, 25451, 28141, 27887, 28527, 4594, 14194, 14068, 31093, 31475, 25082, 25339, 6012, 24445}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('recognize.v.02.realize')\", 26), (\"Lemma('understand.v.02.realize')\", 19), (\"Lemma('realize.v.03.realize')\", 2)])\n",
      "collecting tokens for  troubles\n",
      "indices:    {27401, 20233, 23446, 23191, 23192, 27420, 23965, 23966, 27425, 31013, 37170, 22984, 33101, 5075, 29030, 1127, 19185, 35954, 23929}\n",
      "dict_items([(\"Lemma('trouble.n.03.trouble')\", 2)])\n",
      "collecting tokens for  richard\n",
      "indices:    {865}\n",
      "dict_items([])\n",
      "collecting tokens for  detroit\n",
      "indices:    {25238}\n",
      "dict_items([])\n",
      "collecting tokens for  tougher\n",
      "indices:    {17184, 29442, 12814, 29104, 23282, 11636, 20277, 14969, 11706}\n",
      "dict_items([(\"Lemma('tough.a.01.tough')\", 1), (\"Lemma('rugged.s.04.tough')\", 3), (\"Lemma('sturdy.s.03.tough')\", 1)])\n",
      "collecting tokens for  norms\n",
      "indices:    {32995, 32931, 32935, 30217, 32941, 32943, 16464, 16433, 15666, 16434, 3863, 32920, 16442, 4731, 30238, 3871}\n",
      "dict_items([(\"Lemma('norm.n.01.norm')\", 6), (\"Lemma('average.n.01.norm')\", 2)])\n",
      "collecting tokens for  governing\n",
      "indices:    {23809, 28678, 27560, 32297, 14379, 32364, 3980, 32943, 32272, 12307, 32949, 32278, 23831, 5243, 16413, 21439}\n",
      "dict_items([(\"Lemma('regulate.v.02.govern')\", 6), (\"Lemma('governing.s.01.governing')\", 2), (\"Lemma('govern.v.02.govern')\", 5)])\n",
      "collecting tokens for  usual\n",
      "indices:    {26112, 26368, 20486, 9990, 30731, 28172, 6030, 21519, 30224, 24848, 3218, 21650, 35732, 30225, 12566, 36632, 20122, 20634, 26141, 34206, 27551, 31652, 11944, 7849, 23594, 3241, 6316, 6701, 36654, 18734, 29488, 2097, 19506, 11315, 12717, 11321, 20537, 16570, 4921, 5437, 4929, 23874, 32203, 15824, 15827, 5081, 6876, 3039, 1249, 15208, 6249, 36969, 34665, 6252, 24301, 2164, 2037, 2041, 2042, 10877}\n",
      "dict_items([(\"Lemma('usual.a.01.usual')\", 26), (\"Lemma('common.s.04.usual')\", 2)])\n",
      "collecting tokens for  suggested\n",
      "indices:    {3841, 132, 20357, 13434, 31880, 23818, 37130, 5386, 4625, 36242, 16661, 3097, 36252, 13852, 12700, 2719, 34208, 34721, 6817, 25256, 5929, 25133, 14641, 24883, 5043, 28597, 36278, 16311, 4279, 4278, 28602, 3387, 30780, 30523, 12478, 10937, 1601, 28610, 9539, 25411, 16710, 14719, 5320, 8779, 22222, 31823, 16080, 33235, 13395, 16089, 22618, 15963, 19417, 15325, 3962, 14046, 17889, 16099, 13157, 22629, 25191, 20840, 14060, 20333, 20349, 10097, 34550, 2042, 16125, 5630, 36479}\n",
      "dict_items([(\"Lemma('propose.v.01.suggest')\", 26), (\"Lemma('suggest.v.03.suggest')\", 8), (\"Lemma('hint.v.01.suggest')\", 10), (\"Lemma('suggest.v.05.suggest')\", 4), (\"Lemma('indicate.v.05.suggest')\", 4)])\n",
      "collecting tokens for  selkirk\n",
      "indices:    {12464}\n",
      "dict_items([(\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  atlantic\n",
      "indices:    {30268}\n",
      "dict_items([])\n",
      "collecting tokens for  wonder\n",
      "indices:    {24969, 25740, 22673, 28179, 37140, 10389, 35991, 19482, 3229, 19486, 19487, 19488, 25763, 22951, 36648, 9649, 35124, 27959, 2619, 26942, 26945, 28233, 19787, 27088, 34902, 16600, 26203, 2140, 3804, 26715, 33758, 988, 17763, 34532, 1379, 2277, 13028, 24934, 14315, 8684, 18284, 28143, 29302, 28664}\n",
      "dict_items([(\"Lemma('wonder.v.02.wonder')\", 14), (\"Lemma('wonder.n.02.wonder')\", 3), (\"Lemma('wonder.v.01.wonder')\", 11), (\"Lemma('wonder.n.01.wonder')\", 3), (\"Lemma('wonder.v.03.wonder')\", 1), (\"Lemma('curiosity.n.01.wonder')\", 1)])\n",
      "collecting tokens for  pleased\n",
      "indices:    {13569, 17922, 29189, 9606, 23178, 5652, 26647, 36249, 36397, 10032, 21811, 28600, 33337, 34750, 6846, 31940, 14933, 6486, 30807, 14936, 9435, 21340, 5732, 14439, 19052, 19699, 2169, 10106}\n",
      "dict_items([(\"Lemma('please.v.02.please')\", 3), (\"Lemma('please.v.01.please')\", 5), (\"Lemma('pleased.a.01.pleased')\", 9), (\"Lemma('pleased.s.02.pleased')\", 3)])\n",
      "collecting tokens for  hunter\n",
      "indices:    {20493}\n",
      "dict_items([])\n",
      "collecting tokens for  cruel\n",
      "indices:    {8866, 33701, 14331, 6761, 7145, 24781, 14419, 6933, 8185, 14299, 27294, 36191}\n",
      "dict_items([(\"Lemma('barbarous.s.01.cruel')\", 2)])\n",
      "collecting tokens for  tolley\n",
      "indices:    {36226}\n",
      "dict_items([])\n",
      "collecting tokens for  unfair\n",
      "indices:    {27584, 28609, 5989, 27751, 25036, 22765, 4799, 5298, 20154, 36191}\n",
      "dict_items([(\"Lemma('unfair.a.01.unfair')\", 1)])\n",
      "collecting tokens for  atomic\n",
      "indices:    {21250, 25384, 15159, 34734, 24979, 20788, 27959, 14845}\n",
      "dict_items([(\"Lemma('nuclear.a.01.atomic')\", 1), (\"Lemma('atomic.a.01.atomic')\", 1)])\n",
      "collecting tokens for  sponsored\n",
      "indices:    {16263, 32651, 143, 28563, 14741, 33051, 2726, 4783, 23987, 14135, 22333, 32703, 20809, 20174, 32723, 32478, 32481, 26339, 22376, 13162, 22507, 11887, 11888, 14836, 32250, 19071}\n",
      "dict_items([(\"Lemma('sponsor.v.01.sponsor')\", 20), (\"Lemma('sponsor.v.02.sponsor')\", 6)])\n",
      "collecting tokens for  long-range\n",
      "indices:    {14240, 23586, 23362, 14983, 14216, 28489, 23561, 28458, 28492, 14957, 23367, 32507, 28498, 28440, 30299, 26748, 31133, 32189}\n",
      "dict_items([(\"Lemma('long-range.s.01.long-range')\", 2), (\"Lemma('long-range.s.02.long-range')\", 2)])\n",
      "collecting tokens for  institute\n",
      "indices:    {164}\n",
      "dict_items([])\n",
      "collecting tokens for  suspension\n",
      "indices:    {25184, 3520, 6403, 3523, 23847, 3437, 3407, 3439, 29950, 32703}\n",
      "dict_items([(\"Lemma('suspension.n.01.suspension')\", 5)])\n",
      "collecting tokens for  cultures\n",
      "indices:    {31580, 4093, 11244}\n",
      "dict_items([(\"Lemma('culture.n.01.culture')\", 1), (\"Lemma('culture.n.04.culture')\", 1)])\n",
      "collecting tokens for  acute\n",
      "indices:    {13957, 25192, 13196, 25422, 20658, 27316, 30203, 32703}\n",
      "dict_items([(\"Lemma('acute.s.02.acute')\", 1), (\"Lemma('acute.a.01.acute')\", 1)])\n",
      "collecting tokens for  comment\n",
      "indices:    {25042, 17701, 9359}\n",
      "dict_items([(\"Lemma('remark.n.01.comment')\", 1)])\n",
      "collecting tokens for  cleveland\n",
      "indices:    {23323}\n",
      "dict_items([])\n",
      "collecting tokens for  hengesbach\n",
      "indices:    {21345}\n",
      "dict_items([])\n",
      "collecting tokens for  measurements\n",
      "indices:    {14816, 3714, 29829, 2823, 3720, 2951, 20137, 3760, 3345, 2832, 14803, 3029, 11387}\n",
      "dict_items([(\"Lemma('measurement.n.01.measurement')\", 4)])\n",
      "collecting tokens for  mounted\n",
      "indices:    {11392, 2822, 903, 18184, 28429, 28049, 28055, 18205, 4133, 23845, 4141, 35247, 4144, 29873, 35759, 29878, 28726, 4154, 27835, 12866, 452, 5575, 2387, 2899, 6234, 32738, 28007, 32744, 36969, 29816}\n",
      "dict_items([(\"Lemma('mount.v.01.mount')\", 8), (\"Lemma('mount.v.04.mount')\", 4), (\"Lemma('wax.v.02.mount')\", 4), (\"Lemma('mounted.s.01.mounted')\", 2), (\"Lemma('hop_on.v.01.mount')\", 3), (\"Lemma('mount.v.03.mount')\", 6), (\"Lemma('climb.v.01.mount')\", 1)])\n",
      "collecting tokens for  systematic\n",
      "indices:    {2822, 32138, 30219, 3279, 31287, 33080, 32122, 30237, 32119}\n",
      "dict_items([(\"Lemma('systematic.a.01.systematic')\", 2)])\n",
      "collecting tokens for  substantial\n",
      "indices:    {15232, 15236, 21893, 2822, 21894, 32136, 21896, 16405, 21911, 26650, 27162, 31770, 15515, 3362, 32163, 14247, 32168, 30121, 13354, 3883, 9648, 32435, 13749, 5436, 2243, 16334, 15573, 14550, 15231, 23516, 4587, 12268, 241, 24819, 15478, 15485, 15230, 32127}\n",
      "dict_items([(\"Lemma('substantial.s.02.substantial')\", 1), (\"Lemma('significant.s.02.substantial')\", 22)])\n",
      "collecting tokens for  votes\n",
      "indices:    {24098, 4450, 4453, 22854, 135, 24840, 23913, 12671, 20167, 76, 22861, 20236, 15803, 27771, 22878, 4447}\n",
      "dict_items([(\"Lemma('vote.v.01.vote')\", 2), (\"Lemma('vote.n.01.vote')\", 4), (\"Lemma('vote.n.02.vote')\", 1)])\n",
      "collecting tokens for  recommend\n",
      "indices:    {29956, 14726, 21386, 15249, 1688, 1707, 34351, 20275, 30006, 24130, 11076, 24905, 718, 31061, 31062, 93, 30053, 5609, 10733, 15473, 20210}\n",
      "dict_items([(\"Lemma('recommend.v.01.recommend')\", 17), (\"Lemma('commend.v.04.recommend')\", 4)])\n",
      "collecting tokens for  construction\n",
      "indices:    {29955, 24714, 21644, 15501, 15118, 15117, 15124, 16020, 31775, 5545, 32179, 32310, 30013, 2753, 32450, 3909, 5199, 2657, 25061, 32487, 21608, 21230, 24052, 29947, 21244}\n",
      "dict_items([(\"Lemma('construction.n.03.construction')\", 1), (\"Lemma('construction.n.01.construction')\", 8), (\"Lemma('construction.n.02.construction')\", 1)])\n",
      "collecting tokens for  demonstration\n",
      "indices:    {12673, 14726, 26649, 10777, 14750, 14751, 33203, 33207, 25791, 16326, 1100, 5324, 5331, 23774, 21603, 14697, 23660, 11501, 3828, 24570, 24571}\n",
      "dict_items([(\"Lemma('presentation.n.02.demonstration')\", 7), (\"Lemma('demonstration.n.03.demonstration')\", 3), (\"Lemma('demonstration.n.04.demonstration')\", 2)])\n",
      "collecting tokens for  purposes\n",
      "indices:    {14723, 14724, 29444, 32390, 14726, 32388, 25094, 14727, 14733, 15759, 14736, 4751, 14226, 14739, 21019, 14747, 32411, 14751, 15265, 15653, 15655, 1580, 12973, 33199, 20656, 14001, 32436, 34744, 16442, 4667, 15549, 15165, 14144, 15554, 14024, 16328, 2762, 15051, 16336, 30805, 2774, 26199, 32727, 16341, 32739, 27750, 21608, 10218, 5355, 27115, 17646, 4465, 14065, 14069, 32374, 16376, 7550}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('function.n.02.purpose')\", 11), (\"Lemma('purpose.n.01.purpose')\", 26)])\n",
      "collecting tokens for  recommendation\n",
      "indices:    {15362, 14726, 15368, 16912, 15377, 29858, 8227, 168, 11577, 30781, 15294, 24001, 15327, 15330, 15332, 15334, 15340, 15342, 15343, 15353, 15357, 15359}\n",
      "dict_items([(\"Lemma('recommendation.n.01.recommendation')\", 18), (\"Lemma('recommendation.n.02.recommendation')\", 1)])\n",
      "collecting tokens for  accompanied\n",
      "indices:    {6400, 14726, 23305, 23439, 2192, 21910, 15639, 36761, 31281, 22836, 25142, 20026, 26176, 14018, 28742, 12745, 31826, 26346, 28013, 12784, 32374, 24701}\n",
      "dict_items([(\"Lemma('attach_to.v.01.accompany')\", 13), (\"Lemma('accompany.v.02.accompany')\", 5), (\"Lemma('play_along.v.02.accompany')\", 2), (\"Lemma('accompanied.a.01.accompanied')\", 1)])\n",
      "collecting tokens for  thereto\n",
      "indices:    {14721, 15331, 14726, 14859, 14735, 14742, 14877, 14878}\n",
      "dict_items([(\"Lemma('thereto.r.01.thereto')\", 6)])\n",
      "collecting tokens for  half-man\n",
      "indices:    {34849, 34853, 34829, 34861, 34868, 34869, 34871, 34842, 34844}\n",
      "dict_items([])\n",
      "collecting tokens for  46\n",
      "indices:    {3747, 28579, 21829, 21254, 4042, 29036, 398, 26845, 21208, 28571, 22332, 24797}\n",
      "dict_items([])\n",
      "collecting tokens for  52\n",
      "indices:    {24739, 21829, 23207, 3821, 29037, 23312, 21808, 3832, 665, 25661}\n",
      "dict_items([])\n",
      "collecting tokens for  erected\n",
      "indices:    {29356, 5077, 29943}\n",
      "dict_items([(\"Lemma('raise.v.09.erect')\", 3)])\n",
      "collecting tokens for  perspective\n",
      "indices:    {32192, 4641, 1251, 25924, 1766, 11718, 27919, 5360, 31153, 25462, 32825, 14394, 34715, 1789}\n",
      "dict_items([(\"Lemma('position.n.03.perspective')\", 6), (\"Lemma('perspective.n.02.perspective')\", 1)])\n",
      "collecting tokens for  sketch\n",
      "indices:    {19521, 1825, 11297, 11301, 11305, 11308, 11292, 17102, 2705, 14581, 13788, 14619, 26204}\n",
      "dict_items([(\"Lemma('sketch.n.01.sketch')\", 6), (\"Lemma('sketch.n.03.sketch')\", 2), (\"Lemma('sketch.n.02.sketch')\", 2)])\n",
      "collecting tokens for  skeletal\n",
      "indices:    {3868}\n",
      "dict_items([(\"Lemma('skeletal.a.01.skeletal')\", 1)])\n",
      "collecting tokens for  rating\n",
      "indices:    {15649, 28675, 31141, 3879, 3884, 30158, 15665, 30166, 3865}\n",
      "dict_items([(\"Lemma('evaluation.n.01.rating')\", 1), (\"Lemma('rate.v.01.rate')\", 1), (\"Lemma('evaluation.n.02.rating')\", 3)])\n",
      "collecting tokens for  shoulder\n",
      "indices:    {16515, 19080, 1545, 16524, 1561, 34843, 3872, 35241, 1967, 35253, 18487, 24376, 5845, 9686, 7256, 21611, 34033, 29684, 18553, 18426, 9471}\n",
      "dict_items([(\"Lemma('shoulder.n.01.shoulder')\", 13), (\"Lemma('shoulder.v.02.shoulder')\", 1)])\n",
      "collecting tokens for  wishes\n",
      "indices:    {13984, 11328, 25024, 15846, 2343, 3884, 27085, 26636, 25006, 27856, 4594, 24949, 36118, 2360, 14014, 26975}\n",
      "dict_items([(\"Lemma('wish.v.02.wish')\", 6), (\"Lemma('wish.v.01.wish')\", 2), (\"Lemma('wish.n.01.wish')\", 1)])\n",
      "collecting tokens for  aspects\n",
      "indices:    {31233, 14593, 36359, 12938, 31244, 22157, 32016, 13585, 32401, 15507, 23569, 3731, 5021, 16413, 1568, 16419, 23461, 22951, 33194, 3884, 30775, 25404, 32191, 13632, 13759, 5571, 4803, 27852, 28750, 27994, 15453, 4958, 14689, 1506, 1505, 4710, 31849, 32509, 4973, 28014, 13561, 1405, 4990}\n",
      "dict_items([(\"Lemma('aspect.n.02.aspect')\", 12), (\"Lemma('aspect.n.01.aspect')\", 11), (\"Lemma('view.n.02.aspect')\", 1)])\n",
      "collecting tokens for  childhood\n",
      "indices:    {30753, 8866, 6210, 2661, 3878, 25705, 8874, 13515, 3884, 13516, 36302, 6794, 2578, 3859, 25397, 27194}\n",
      "dict_items([(\"Lemma('childhood.n.01.childhood')\", 8), (\"Lemma('childhood.n.02.childhood')\", 2)])\n",
      "collecting tokens for  includes\n",
      "indices:    {14722, 32130, 3729, 32149, 32150, 32151, 26746, 15015, 14763, 32940, 31226, 31799, 23619, 4675, 29254, 29129, 15057, 14674, 28882, 2642, 23506, 16341, 14177, 21861, 21094, 20843, 29293, 2551, 762, 15867, 27388}\n",
      "dict_items([(\"Lemma('include.v.01.include')\", 26), (\"Lemma('include.v.02.include')\", 2), (\"Lemma('admit.v.03.include')\", 1)])\n",
      "collecting tokens for  bones\n",
      "indices:    {30496, 3874, 35202, 3875, 14309, 3911, 11412}\n",
      "dict_items([(\"Lemma('bone.n.01.bone')\", 2)])\n",
      "collecting tokens for  oxen\n",
      "indices:    {29958, 29959, 19275, 19277, 19153, 19250, 19156, 19227}\n",
      "dict_items([(\"Lemma('cattle.n.01.oxen')\", 6)])\n",
      "collecting tokens for  absorb\n",
      "indices:    {32134, 4198, 11369, 11370, 32170, 19565, 20783, 37171, 23677}\n",
      "dict_items([(\"Lemma('absorb.v.02.absorb')\", 2), (\"Lemma('absorb.v.01.absorb')\", 3), (\"Lemma('absorb.v.03.absorb')\", 2), (\"Lemma('absorb.v.04.absorb')\", 2)])\n",
      "collecting tokens for  termed\n",
      "indices:    {36133, 12200, 23819, 2988, 14382, 20783, 7070, 25367, 20380, 94, 36927}\n",
      "dict_items([(\"Lemma('term.v.01.term')\", 11)])\n",
      "collecting tokens for  hardly\n",
      "indices:    {24365}\n",
      "dict_items([])\n",
      "collecting tokens for  occasions\n",
      "indices:    {37120, 15844, 5220, 2404, 15849, 23050, 36491, 4715, 33004, 24462, 36430, 9840, 7121, 11284, 33173, 13940, 984, 13119}\n",
      "dict_items([(\"Lemma('juncture.n.01.occasion')\", 7), (\"Lemma('occasions.n.01.occasions')\", 1), (\"Lemma('affair.n.03.occasion')\", 3)])\n",
      "collecting tokens for  unexpected\n",
      "indices:    {33762, 26948, 30022, 30474, 2797, 8909, 12080, 33171, 9684, 23189, 23284, 30838, 984, 6299}\n",
      "dict_items([(\"Lemma('unexpected.a.01.unexpected')\", 5)])\n",
      "collecting tokens for  lunch\n",
      "indices:    {5601, 31815, 35723, 29387, 543, 13523, 17331, 33395, 21375, 17336, 13695}\n",
      "dict_items([(\"Lemma('lunch.n.01.lunch')\", 5), (\"Lemma('lunch.v.01.lunch')\", 1)])\n",
      "collecting tokens for  maude\n",
      "indices:    {16749}\n",
      "dict_items([])\n",
      "collecting tokens for  shook\n",
      "indices:    {7424, 13568, 10117, 17416, 19985, 19093, 18073, 18460, 17057, 10913, 35107, 18081, 36007, 17194, 35500, 17325, 6190, 18480, 7091, 19510, 35128, 7098, 17094, 5704, 8781, 8022, 7259, 18269, 34654, 6114, 18787, 9956, 8932, 36070, 9062, 9704, 9830, 19938, 19304, 30326, 36345}\n",
      "dict_items([(\"Lemma('shake.v.01.shake')\", 26), (\"Lemma('rock.v.01.shake')\", 2), (\"Lemma('shake.v.02.shake')\", 8), (\"Lemma('judder.v.01.shake')\", 5)])\n",
      "collecting tokens for  absorption\n",
      "indices:    {25664, 2273, 4043, 3119, 3125, 26840, 26906, 2811, 3293}\n",
      "dict_items([(\"Lemma('absorption.n.01.absorption')\", 2), (\"Lemma('absorption.n.02.absorption')\", 3)])\n",
      "collecting tokens for  length\n",
      "indices:    {13697, 16129, 9345, 20737, 29066, 3732, 2070, 3738, 3739, 21152, 3756, 12723, 29237, 3906, 29890, 31045, 31947, 1355, 3919, 2512, 3923, 3683, 3684, 28902, 29932, 3692, 28913, 13554, 29051, 3065, 32890, 3707, 2812}\n",
      "dict_items([(\"Lemma('duration.n.03.length')\", 3), (\"Lemma('length.n.01.length')\", 15), (\"Lemma('length.n.03.length')\", 1)])\n",
      "collecting tokens for  variation\n",
      "indices:    {22146, 3336, 1548, 1549, 1550, 1552, 26011, 4384, 2851, 2852, 3364, 26664, 3765, 1744, 1746, 1621, 16085, 3801, 15961, 3163, 3297, 3813, 2406, 2794, 2808, 2810, 2811}\n",
      "dict_items([(\"Lemma('variation.n.01.variation')\", 15), (\"Lemma('variation.n.02.variation')\", 6), (\"Lemma('variation.n.03.variation')\", 2)])\n",
      "collecting tokens for  depths\n",
      "indices:    {2149, 36134, 12042, 25387, 2125, 12791, 1337, 12794, 2811, 12765, 8446, 11167}\n",
      "dict_items([(\"Lemma('depth.n.02.depth')\", 2), (\"Lemma('depth.n.01.depth')\", 8)])\n",
      "collecting tokens for  beneath\n",
      "indices:    {13569, 12675, 18952, 18444, 24588, 13581, 8605, 31394, 18987, 35263, 31558, 35404, 35928, 10590, 35423, 13540, 11109, 8423, 33271, 6397}\n",
      "dict_items([(\"Lemma('below.r.01.beneath')\", 1)])\n",
      "collecting tokens for  detect\n",
      "indices:    {14119, 28459, 9326, 11409, 14164, 29719, 2811, 15900}\n",
      "dict_items([(\"Lemma('detect.v.01.detect')\", 7)])\n",
      "collecting tokens for  composition\n",
      "indices:    {2169, 11298, 11299, 4003, 4965, 8683, 15503, 2706, 13331, 31891, 11286, 20153, 2811, 11295, 31871}\n",
      "dict_items([(\"Lemma('constitution.n.04.composition')\", 4), (\"Lemma('composition.n.01.composition')\", 4), (\"Lemma('composition.n.03.composition')\", 1), (\"Lemma('writing.n.01.composition')\", 1), (\"Lemma('musical_composition.n.01.composition')\", 1), (\"Lemma('composing.n.02.composition')\", 1)])\n",
      "collecting tokens for  lunar\n",
      "indices:    {2848, 2835, 2836, 2837, 2807, 2811}\n",
      "dict_items([(\"Lemma('lunar.a.01.lunar')\", 6)])\n",
      "collecting tokens for  treasurer\n",
      "indices:    {97, 22178, 5123, 21091, 20962, 5197, 21742, 20307, 5148}\n",
      "dict_items([(\"Lemma('treasurer.n.01.treasurer')\", 3)])\n",
      "collecting tokens for  assume\n",
      "indices:    {16389, 31112, 13193, 2449, 4883, 15898, 3486, 30754, 23716, 4517, 25381, 14122, 1329, 819, 14392, 2234, 31164, 24893, 14016, 3012, 32069, 3018, 23248, 9681, 16120, 36306, 28756, 16342, 35672, 31706, 27231, 15850, 16369, 10100, 14196, 16376, 4602, 16380, 13178, 3071}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('assume.v.03.assume')\", 4), (\"Lemma('assume.v.05.assume')\", 1), (\"Lemma('assume.v.01.assume')\", 26), (\"Lemma('assume.v.02.assume')\", 3), (\"Lemma('bear.v.06.assume')\", 2)])\n",
      "collecting tokens for  dressed\n",
      "indices:    {36992, 19977, 6285, 29713, 36630, 16663, 9629, 24991, 36272, 35633, 1725, 6852, 6853, 19526, 6221, 7374, 6868, 36180, 7386, 2654, 7777, 36731, 36328, 2665, 6384, 10100, 9718, 9339}\n",
      "dict_items([(\"Lemma('dress.v.01.dress')\", 6), (\"Lemma('dress.v.04.dress')\", 1), (\"Lemma('dress.v.02.dress')\", 6), (\"Lemma('appareled.s.01.dressed')\", 7)])\n",
      "collecting tokens for  aloud\n",
      "indices:    {6593, 8551, 6539, 6545, 10100, 6585, 17756, 23037, 33886, 16959}\n",
      "dict_items([(\"Lemma('aloud.r.01.aloud')\", 8)])\n",
      "collecting tokens for  assistant\n",
      "indices:    {20771, 5138, 14467, 15300}\n",
      "dict_items([(\"Lemma('assistant.n.01.assistant')\", 2)])\n",
      "collecting tokens for  stolen\n",
      "indices:    {21252, 36423, 35851, 20143, 5072, 10100, 36888, 23353, 29372, 16670, 21247}\n",
      "dict_items([(\"Lemma('steal.v.01.steal')\", 7), (\"Lemma('steal.v.02.steal')\", 1)])\n",
      "collecting tokens for  dirt\n",
      "indices:    {35970, 31496, 3593, 31498, 33806, 9486, 3222, 35228, 13604, 185, 199, 9169, 12883, 15207, 18665, 3186, 3190, 33784, 30075, 18943}\n",
      "dict_items([(\"Lemma('dirt.n.02.dirt')\", 4), (\"Lemma('soil.n.02.dirt')\", 8)])\n",
      "collecting tokens for  leaves\n",
      "indices:    {8705, 28164, 26643, 14615, 11819, 36018, 13251, 36040, 15946, 26698, 17237, 30807, 29152, 9575, 1257, 1258, 13547, 25975, 30715}\n",
      "dict_items([(\"Lemma('leaf.n.01.leaf')\", 3), (\"Lemma('leave.v.03.leave')\", 5), (\"Lemma('leave.v.01.leave')\", 1), (\"Lemma('leave.v.06.leave')\", 1), (\"Lemma('leave.v.08.leave')\", 1), (\"Lemma('leave.v.12.leave')\", 1), (\"Lemma('leave.n.01.leave')\", 1)])\n",
      "collecting tokens for  connections\n",
      "indices:    {23427, 35760, 8180, 5016, 23421, 14014}\n",
      "dict_items([(\"Lemma('connection.n.04.connection')\", 1), (\"Lemma('association.n.04.connection')\", 1), (\"Lemma('connection.n.01.connection')\", 1)])\n",
      "collecting tokens for  lost\n",
      "indices:    {11265, 23047, 27143, 24074, 8205, 27672, 26140, 29213, 34334, 19486, 16417, 23589, 24104, 27689, 7733, 4663, 14907, 33854, 15423, 34886, 24135, 25171, 34403, 30820, 7269, 25704, 28265, 7786, 28269, 35956, 24185, 24186, 2681, 6281, 141, 6801, 34466, 7844, 12454, 6312, 8875, 6316, 9391, 4785, 4786, 30902, 5816, 14522, 24764, 31424, 36544, 34497, 33481, 2252, 1236, 16606, 24804, 30950, 30438, 26860, 19189, 35580, 16638, 2305, 18701, 278, 32023, 31001, 35099, 22813, 4897, 34084, 13607, 24360, 23849, 32044, 7472, 34100, 12094, 22851, 19781, 12102, 4936, 33100, 10574, 24916, 8041, 34680, 22904, 33658, 36224, 31623, 21896, 22921, 34700, 21389, 31631, 34192, 33170, 25490, 12708, 26535, 17832, 19369, 26545, 7089, 20407, 16827, 1469, 24006, 22995, 34778, 11231, 12776, 28145, 10227, 11253, 21494, 17919}\n",
      "dict_items([(\"Lemma('lose.v.01.lose')\", 26), (\"Lemma('lose.v.02.lose')\", 7), (\"Lemma('confused.s.03.lost')\", 5), (\"Lemma('lose.v.05.lose')\", 4), (\"Lemma('lose.v.03.lose')\", 4), (\"Lemma('misplace.v.01.lose')\", 4), (\"Lemma('lost.a.01.lost')\", 5), (\"Lemma('lost.s.05.lost')\", 2), (\"Lemma('lose.v.06.lose')\", 2), (\"Lemma('lose.v.08.lose')\", 1), (\"Lemma('lost.a.04.lost')\", 1), (\"Lemma('lost.a.03.lost')\", 2), (\"Lemma('lose.v.07.lose')\", 1), (\"Lemma('fall_back.v.04.lose')\", 1)])\n",
      "collecting tokens for  straightened\n",
      "indices:    {35875, 16547, 36358, 29030, 17576, 17866, 18860, 35342, 19665, 17972, 16478, 7386, 19486}\n",
      "dict_items([(\"Lemma('tidy.v.01.straighten')\", 1), (\"Lemma('straighten.v.03.straighten')\", 3), (\"Lemma('straighten.v.02.straighten')\", 2), (\"Lemma('straighten.v.01.straighten')\", 2)])\n",
      "collecting tokens for  success\n",
      "indices:    {14800, 4474}\n",
      "dict_items([(\"Lemma('success.n.02.success')\", 1), (\"Lemma('success.n.01.success')\", 1)])\n",
      "collecting tokens for  steak\n",
      "indices:    {29416, 22322, 5151}\n",
      "dict_items([(\"Lemma('steak.n.01.steak')\", 1)])\n",
      "collecting tokens for  permits\n",
      "indices:    {96, 16353, 3874, 20707, 3843, 3875, 23207, 29482, 31020, 13069, 29485, 27790, 30196, 20734}\n",
      "dict_items([(\"Lemma('permit.v.01.permit')\", 4), (\"Lemma('let.v.01.permit')\", 8), (\"Lemma('license.n.01.permit')\", 1)])\n",
      "collecting tokens for  buns\n",
      "indices:    {29476, 29509, 29483, 29485, 29521, 29492, 29494, 29464}\n",
      "dict_items([])\n",
      "collecting tokens for  facts\n",
      "indices:    {30208, 24961, 13570, 15367, 34440, 23688, 16141, 11790, 2317, 4880, 24212, 2327, 2714, 17180, 31135, 16159, 2296, 5282, 25506, 31141, 27177, 26671, 16946, 11698, 30262, 26936, 24120, 15423, 4930, 27719, 24904, 14923, 30796, 24016, 12250, 11872, 26212, 11112, 12265, 25448, 23917, 27885, 14192, 26353, 34675, 22772, 12792, 6012, 2301, 30206}\n",
      "dict_items([(\"Lemma('fact.n.02.fact')\", 9), (\"Lemma('fact.n.01.fact')\", 15), (\"Lemma('fact.n.04.fact')\", 1)])\n",
      "collecting tokens for  conversation\n",
      "indices:    {23169, 24707, 36612, 37001, 37002, 26124, 24973, 13075, 30231, 30206, 6843, 21181, 2123, 4942, 27854, 27857, 26837, 24662, 8277, 13405, 13407, 1249, 27746, 7400, 19435, 18031, 13424, 31091, 31092, 33524, 13430, 13427, 632, 23290, 24828, 7422}\n",
      "dict_items([(\"Lemma('conversation.n.01.conversation')\", 16)])\n",
      "collecting tokens for  1948\n",
      "indices:    {3746, 14888, 20302, 14895, 3375, 14896, 15218, 23794, 26001, 1394, 14870, 22864, 27896, 476, 26076}\n",
      "dict_items([])\n",
      "collecting tokens for  wrote\n",
      "indices:    {31751, 28173, 31762, 31766, 10777, 7709, 7710, 14369, 25639, 551, 7719, 29231, 13879, 14419, 14426, 5221, 14441, 10861, 8816, 14453, 14459, 14466, 5256, 14472, 6800, 16016, 24726, 8348, 8351, 27295, 3746, 27300, 5299, 35507, 11443, 27318, 30392, 5309, 11454, 12481, 11460, 5325, 9425, 26323, 4824, 12504, 27362, 5355, 16625, 37107, 21748, 12533, 22775, 12535, 12538, 8444, 12543, 12546, 12547, 24323, 24325, 26371, 12552, 12554, 12557, 22797, 12561, 12566, 12567, 37145, 21786, 12578, 37156, 12583, 12591, 12596, 12597, 12599, 14650, 12606, 12608, 12611, 12613, 12617, 12618, 25943, 20336, 25970, 10618, 15748, 26514, 1426, 9621, 15799, 2489, 21947, 22479, 24532, 5076, 8150, 15316, 25045, 31711, 31718, 31736, 10746}\n",
      "dict_items([(\"Lemma('write.v.04.write')\", 5), (\"Lemma('write.v.02.write')\", 26), (\"Lemma('publish.v.03.write')\", 11), (\"Lemma('write.v.05.write')\", 5), (\"Lemma('write.v.01.write')\", 26), (\"Lemma('write.v.07.write')\", 2)])\n",
      "collecting tokens for  giant\n",
      "indices:    {27019, 29329, 19605, 28437, 22810, 9632, 3746, 36134, 26805, 12729, 12735, 19400, 35919, 32215, 13911, 28631, 6363, 26843, 25820, 19550, 11240}\n",
      "dict_items([(\"Lemma('elephantine.s.01.giant')\", 8), (\"Lemma('colossus.n.02.giant')\", 2)])\n",
      "collecting tokens for  rooms\n",
      "indices:    {22144, 2048, 34053, 7443, 5652, 7062, 30109, 31261, 37028, 37029, 31531, 7487, 30915, 31556, 30153, 29261, 35917, 31693, 17109, 7003, 9437, 31585, 20706, 5090, 35941, 17127, 23024, 7921, 18552, 24573}\n",
      "dict_items([(\"Lemma('room.n.01.room')\", 12)])\n",
      "collecting tokens for  paint\n",
      "indices:    {6371, 11277, 11281, 11091, 11284, 5363, 25303, 29784, 17082, 13655, 37055}\n",
      "dict_items([(\"Lemma('paint.v.01.paint')\", 2), (\"Lemma('paint.v.02.paint')\", 2), (\"Lemma('paint.v.03.paint')\", 2), (\"Lemma('paint.n.01.paint')\", 3)])\n",
      "collecting tokens for  succeed\n",
      "indices:    {26505, 161, 21220}\n",
      "dict_items([(\"Lemma('succeed.v.02.succeed')\", 2)])\n",
      "collecting tokens for  farther\n",
      "indices:    {1984, 17580, 26990, 12411, 28700, 27007}\n",
      "dict_items([(\"Lemma('far.r.02.far')\", 1), (\"Lemma('far.r.03.far')\", 2)])\n",
      "collecting tokens for  smu\n",
      "indices:    {22109}\n",
      "dict_items([])\n",
      "collecting tokens for  plates\n",
      "indices:    {9411, 5031, 31021, 33493, 29465}\n",
      "dict_items([(\"Lemma('plate.n.03.plate')\", 1), (\"Lemma('plate.n.04.plate')\", 1)])\n",
      "collecting tokens for  youngsters\n",
      "indices:    {21882, 29692, 31005}\n",
      "dict_items([])\n",
      "collecting tokens for  freely\n",
      "indices:    {32065, 776, 7786, 33230, 14350, 11311, 12625, 27507, 35987, 27413, 25974, 31927, 27067, 11293}\n",
      "dict_items([(\"Lemma('freely.r.01.freely')\", 6)])\n",
      "collecting tokens for  recordings\n",
      "indices:    {27624, 1097, 11053, 759, 30233, 11258, 26971, 1727}\n",
      "dict_items([(\"Lemma('recording.n.01.recording')\", 4)])\n",
      "collecting tokens for  language\n",
      "indices:    {30216, 36751, 26643, 32037, 24619, 1330, 22451, 16179, 32057, 24764, 10045, 10828, 14552, 10203, 24933, 12267, 4718, 24049, 23542, 31993}\n",
      "dict_items([(\"Lemma('language.n.01.language')\", 5), (\"Lemma('lyric.n.01.language')\", 1), (\"Lemma('speech.n.02.language')\", 1)])\n",
      "collecting tokens for  commerce\n",
      "indices:    {22063}\n",
      "dict_items([])\n",
      "collecting tokens for  establish\n",
      "indices:    {15872, 5379, 14218, 14219, 14733, 20366, 14224, 20885, 31766, 32664, 4377, 30234, 21403, 25245, 14366, 22304, 13858, 14766, 20784, 31925, 12214, 4919, 32185, 2752, 32192, 2887, 32589, 37069, 26705, 32594, 2898, 13777, 27091, 32600, 23515, 14945, 32865, 23012, 31212, 109, 31215, 12917, 2295, 31995, 31996, 27135}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('establish.v.01.establish')\", 18), (\"Lemma('lay_down.v.01.establish')\", 5), (\"Lemma('prove.v.02.establish')\", 7), (\"Lemma('establish.v.02.establish')\", 11), (\"Lemma('establish.v.05.establish')\", 2), (\"Lemma('establish.v.08.establish')\", 1), (\"Lemma('build.v.03.establish')\", 1), (\"Lemma('install.v.03.establish')\", 1)])\n",
      "collecting tokens for  closer\n",
      "indices:    {5764, 28166, 34954, 22029, 3088, 10000, 26138, 22698, 31154, 12469, 8896, 17229, 2008, 26975, 9315, 25445, 10088, 9576, 10603, 33788}\n",
      "dict_items([(\"Lemma('close.a.02.close')\", 2), (\"Lemma('close.a.01.close')\", 7), (\"Lemma('nearer.r.01.closer')\", 1), (\"Lemma('near.a.01.close')\", 1)])\n",
      "collecting tokens for  acts\n",
      "indices:    {32673, 32993, 3202, 32931, 14473, 16233, 21324, 22797, 5422, 25871, 15504, 22806, 23256, 121}\n",
      "dict_items([(\"Lemma('act.n.03.act')\", 1), (\"Lemma('act.n.01.act')\", 2), (\"Lemma('act.v.04.act')\", 1), (\"Lemma('act.v.01.act')\", 1), (\"Lemma('act_as.v.01.act_as')\", 1), (\"Lemma('act.n.02.act')\", 1)])\n",
      "collecting tokens for  clad\n",
      "indices:    {12865, 6450, 35397, 30853}\n",
      "dict_items([(\"Lemma('clothed.a.01.clad')\", 2), (\"Lemma('invest.v.03.clothe')\", 1)])\n",
      "collecting tokens for  toe\n",
      "indices:    {704, 34538, 17962, 1998, 6672, 689, 9108, 31868}\n",
      "dict_items([(\"Lemma('toe.n.02.toe')\", 1), (\"Lemma('toe.n.01.toe')\", 2)])\n",
      "collecting tokens for  hits\n",
      "indices:    {30186, 31139}\n",
      "dict_items([(\"Lemma('hit.v.02.hit')\", 1)])\n",
      "collecting tokens for  dave\n",
      "indices:    {33586}\n",
      "dict_items([])\n",
      "collecting tokens for  aim\n",
      "indices:    {32899, 25467, 1670, 7688, 2057, 17941, 11798, 18455, 8600, 2328, 35606, 14623, 31929, 13626, 2879, 11874, 14967, 5370, 2427, 18943}\n",
      "dict_items([(\"Lemma('aim.n.03.aim')\", 3), (\"Lemma('draw_a_bead_on.v.02.aim')\", 2), (\"Lemma('purpose.n.01.aim')\", 6), (\"Lemma('aim.v.02.aim')\", 2), (\"Lemma('aim.n.02.aim')\", 1), (\"Lemma('aim.v.01.aim')\", 1), (\"Lemma('drive.v.11.aim')\", 1)])\n",
      "collecting tokens for  neutralist\n",
      "indices:    {20291, 12968, 12970, 12973, 12975, 22838, 25629, 25630}\n",
      "dict_items([(\"Lemma('neutralist.n.01.neutralist')\", 4)])\n",
      "collecting tokens for  doc\n",
      "indices:    {36531}\n",
      "dict_items([])\n",
      "collecting tokens for  naval\n",
      "indices:    {14959, 29247}\n",
      "dict_items([])\n",
      "collecting tokens for  suited\n",
      "indices:    {28448, 20289, 12164, 12167, 3239, 26633, 3054, 36528, 25780, 6260, 13881, 13883}\n",
      "dict_items([(\"Lemma('suitable.s.01.suited')\", 4), (\"Lemma('suit.v.01.suit')\", 4)])\n",
      "collecting tokens for  nut\n",
      "indices:    {36896, 29888, 10985, 36916, 28790, 23319, 1692, 28797}\n",
      "dict_items([(\"Lemma('nut.n.01.nut')\", 2)])\n",
      "collecting tokens for  repel\n",
      "indices:    {30791, 4970, 13867, 27825, 3221, 34519, 27836, 13663}\n",
      "dict_items([(\"Lemma('repel.v.01.repel')\", 5), (\"Lemma('repel.v.03.repel')\", 2), (\"Lemma('repel.v.02.repel')\", 1)])\n",
      "collecting tokens for  injury\n",
      "indices:    {647, 1932, 4108, 35473, 276, 21661, 4905, 31025, 4917, 24503, 27836, 7869, 4928, 328, 330, 339, 476, 631, 382}\n",
      "dict_items([(\"Lemma('injury.n.02.injury')\", 5), (\"Lemma('injury.n.01.injury')\", 9)])\n",
      "collecting tokens for  accept\n",
      "indices:    {27409, 24850, 27341}\n",
      "dict_items([(\"Lemma('accept.v.02.accept')\", 1), (\"Lemma('accept.v.01.accept')\", 1)])\n",
      "collecting tokens for  steep\n",
      "indices:    {22243, 10468, 10473, 29964, 27825, 10449, 22067, 12729, 36730, 27835}\n",
      "dict_items([(\"Lemma('steep.a.01.steep')\", 4)])\n",
      "collecting tokens for  slope\n",
      "indices:    {31168, 36001, 5762, 5763, 12166, 22919, 4520, 3049, 30186, 27825, 35988, 8568, 9786, 27835, 4572}\n",
      "dict_items([(\"Lemma('gradient.n.02.slope')\", 4), (\"Lemma('slope.n.01.slope')\", 4)])\n",
      "collecting tokens for  vertical\n",
      "indices:    {29728, 14057, 29550, 718, 3440, 29873, 18734, 29687, 3446, 28503, 3865, 29594, 9148, 3454}\n",
      "dict_items([(\"Lemma('vertical.a.01.vertical')\", 8)])\n",
      "collecting tokens for  cloud\n",
      "indices:    {6277, 34442, 6923, 31381, 3496, 23868, 30274, 3401, 5834, 4437, 3417, 21338, 10593, 30568, 3438, 3446, 30583, 6908, 6910}\n",
      "dict_items([(\"Lemma('cloud.n.01.cloud')\", 7), (\"Lemma('cloud.n.02.cloud')\", 2)])\n",
      "collecting tokens for  prime\n",
      "indices:    {1118, 13076, 5420}\n",
      "dict_items([(\"Lemma('choice.s.01.prime')\", 1), (\"Lemma('premier.s.01.prime')\", 1)])\n",
      "collecting tokens for  strode\n",
      "indices:    {34950, 34023, 6475, 34029, 18190, 13108, 33595, 7420}\n",
      "dict_items([])\n",
      "collecting tokens for  drank\n",
      "indices:    {19174, 34987, 8427, 9229, 18927, 36499, 36214, 9306, 543}\n",
      "dict_items([(\"Lemma('toast.v.02.drink')\", 1), (\"Lemma('drink.v.02.drink')\", 1), (\"Lemma('drink.v.01.drink')\", 7)])\n",
      "collecting tokens for  brace\n",
      "indices:    {739, 19335, 36173, 29742, 5264, 35411}\n",
      "dict_items([(\"Lemma('brace.v.02.brace')\", 1)])\n",
      "collecting tokens for  happier\n",
      "indices:    {19656, 28301, 36111, 9748, 24404, 1181, 668, 14333}\n",
      "dict_items([(\"Lemma('happy.a.01.happy')\", 3), (\"Lemma('felicitous.s.02.happy')\", 1)])\n",
      "collecting tokens for  lies\n",
      "indices:    {2307, 24070, 21014, 4247, 31518, 11040, 3748, 28453, 12584, 27049, 27816, 15924, 27701, 567, 26942, 19656, 27983, 30800, 26707, 3160, 857, 31963, 31588, 31589, 24935, 6763, 2671, 31992, 28668}\n",
      "dict_items([(\"Lemma('dwell.v.02.lie')\", 3), (\"Lemma('lie.n.01.lie')\", 3), (\"Lemma('lie.v.01.lie')\", 8), (\"Lemma('lie.v.04.lie')\", 2), (\"Lemma('lie.v.02.lie')\", 4)])\n",
      "collecting tokens for  poorly\n",
      "indices:    {3776, 15841, 3851, 6060, 11469, 2353, 36498, 11412, 21206, 14203, 15711}\n",
      "dict_items([(\"Lemma('ill.r.01.poorly')\", 9)])\n",
      "collecting tokens for  equipped\n",
      "indices:    {24964, 5518, 32399, 32401, 28836, 28717, 3247, 4145, 3252, 3255, 25785, 30141, 29128, 11469, 26839, 12763, 29023, 2400, 21731, 28657, 32628, 3324, 13055}\n",
      "dict_items([(\"Lemma('equipped.a.01.equipped')\", 1), (\"Lemma('equip.v.01.equip')\", 11)])\n",
      "collecting tokens for  sciences\n",
      "indices:    {32696, 14364}\n",
      "dict_items([])\n",
      "collecting tokens for  decency\n",
      "indices:    {9953, 27272, 20396, 32240, 36466, 2643, 19423, 8095}\n",
      "dict_items([(\"Lemma('decency.n.02.decency')\", 2), (\"Lemma('decency.n.01.decency')\", 2)])\n",
      "collecting tokens for  piano\n",
      "indices:    {26787, 19495, 26413, 26423, 26425, 9658, 11199}\n",
      "dict_items([(\"Lemma('piano.n.01.piano')\", 1)])\n",
      "collecting tokens for  races\n",
      "indices:    {24610, 34349, 27054, 34350, 29371, 243, 27065, 34363, 28957}\n",
      "dict_items([(\"Lemma('race.n.02.race')\", 1)])\n",
      "collecting tokens for  whereas\n",
      "indices:    {31993, 1895, 27078, 16439}\n",
      "dict_items([])\n",
      "collecting tokens for  smell\n",
      "indices:    {31491, 31493, 31495, 9995, 31500, 31502, 6935, 35630, 31152, 18361, 8127, 8903, 5963, 24783, 80, 30419, 17747, 7773, 7263, 5986, 23141, 24805, 10483, 7802, 17023}\n",
      "dict_items([(\"Lemma('smell.v.02.smell')\", 2), (\"Lemma('olfactory_property.n.01.smell')\", 5), (\"Lemma('smell.n.01.smell')\", 6), (\"Lemma('spirit.n.02.smell')\", 1), (\"Lemma('smell.v.01.smell')\", 4)])\n",
      "collecting tokens for  arc\n",
      "indices:    {14848, 2817, 2944, 534, 11421, 2856, 2857, 2858, 2860, 2861, 4525, 34095, 2864, 4526, 2870, 2872, 4537, 2875, 5441, 2883, 3268, 2887, 2888, 2902, 2914, 2921, 2923, 2926, 2929, 2930, 2932, 14845, 14847}\n",
      "dict_items([(\"Lemma('discharge.n.05.arc')\", 25), (\"Lemma('arc.n.02.arc')\", 6)])\n",
      "collecting tokens for  voltage\n",
      "indices:    {2945, 14786, 2887, 2921, 2860, 20115, 2932, 14781}\n",
      "dict_items([(\"Lemma('voltage.n.01.voltage')\", 6), (\"Lemma('electric_potential.n.01.voltage')\", 2)])\n",
      "collecting tokens for  connected\n",
      "indices:    {5122, 4488, 11785, 2697, 7824, 2196, 35350, 5014, 16919, 13846, 16169, 30762, 28720, 26290, 32052, 28729, 2113, 34757, 31316, 29917, 2921, 27114, 16108, 14449, 23539, 15220, 36982, 9335, 13304, 25343}\n",
      "dict_items([(\"Lemma('connect.v.03.connect')\", 2), (\"Lemma('connect.v.01.connect')\", 5), (\"Lemma('affiliated.s.01.connected')\", 5), (\"Lemma('connected.a.02.connected')\", 3), (\"Lemma('associate.v.01.connect')\", 3), (\"Lemma('connect.v.04.connect')\", 1), (\"Lemma('connect.v.05.connect')\", 1)])\n",
      "collecting tokens for  anode\n",
      "indices:    {2945, 2950, 2951, 2952, 2953, 2957, 2856, 2857, 2858, 2859, 2863, 2864, 2865, 2866, 2868, 2869, 2870, 2873, 2875, 2876, 2877, 2878, 2879, 2881, 2883, 2885, 2887, 2888, 2891, 2896, 2899, 2900, 2903, 2904, 2905, 2910, 2911, 2912, 2913, 2914, 2916, 2921, 2924, 2927, 2929, 2930, 2931, 2933, 2941}\n",
      "dict_items([(\"Lemma('anode.n.01.anode')\", 26)])\n",
      "collecting tokens for  cathode\n",
      "indices:    {2921, 2897, 2866, 2900, 2902, 2873, 2875, 2877}\n",
      "dict_items([(\"Lemma('cathode.n.01.cathode')\", 8)])\n",
      "collecting tokens for  reverend\n",
      "indices:    {6397}\n",
      "dict_items([(\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  sunlight\n",
      "indices:    {17028, 29289, 29290, 13131, 19247, 29265, 35249, 3415, 16956, 31517}\n",
      "dict_items([(\"Lemma('sunlight.n.01.sunlight')\", 5)])\n",
      "collecting tokens for  associate\n",
      "indices:    {11339, 21220, 20055}\n",
      "dict_items([(\"Lemma('associate.n.01.associate')\", 2)])\n",
      "collecting tokens for  responses\n",
      "indices:    {31679, 34669, 25461, 33191}\n",
      "dict_items([])\n",
      "collecting tokens for  settings\n",
      "indices:    {32896, 1122, 32900, 26251, 27884, 31532, 1776, 29271, 29915}\n",
      "dict_items([(\"Lemma('mise_en_scene.n.01.setting')\", 1), (\"Lemma('setting.n.02.setting')\", 1)])\n",
      "collecting tokens for  long-term\n",
      "indices:    {23377, 4620, 16182}\n",
      "dict_items([(\"Lemma('long-run.s.01.long-term')\", 2)])\n",
      "collecting tokens for  pituitary\n",
      "indices:    {3972, 4007, 4009, 27211, 34674, 3989, 34679, 3994, 3996}\n",
      "dict_items([(\"Lemma('pituitary.n.01.pituitary')\", 4)])\n",
      "collecting tokens for  undoubtedly\n",
      "indices:    {31793, 1242, 1233}\n",
      "dict_items([(\"Lemma('undoubtedly.r.01.undoubtedly')\", 2)])\n",
      "collecting tokens for  subsystems\n",
      "indices:    {32996, 32938, 16075, 16076, 32939, 32977, 32953, 32954, 16092}\n",
      "dict_items([(\"Lemma('subsystem.n.01.subsystem')\", 3)])\n",
      "collecting tokens for  singled\n",
      "indices:    {201, 366, 207, 32977, 369, 371, 5112, 186}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('single.v.01.single')\", 6)])\n",
      "collecting tokens for  lonely\n",
      "indices:    {24321, 20106, 19616, 6062, 33334, 34488, 34491, 8775, 8779, 10067, 10069, 10070, 34776, 13792, 24801, 33378, 24804, 25706, 33269}\n",
      "dict_items([(\"Lemma('lonely.s.02.lonely')\", 4), (\"Lemma('alone.s.02.lonely')\", 4)])\n",
      "collecting tokens for  bell\n",
      "indices:    {10481, 21919}\n",
      "dict_items([(\"Lemma('bell.n.01.bell')\", 1)])\n",
      "collecting tokens for  computing\n",
      "indices:    {11936, 28905, 15062, 15905}\n",
      "dict_items([(\"Lemma('calculate.v.01.compute')\", 4)])\n",
      "collecting tokens for  adjusted\n",
      "indices:    {22063, 32036, 15621, 15055}\n",
      "dict_items([(\"Lemma('adjusted.a.01.adjusted')\", 1), (\"Lemma('adjust.v.04.adjust')\", 1)])\n",
      "collecting tokens for  deductions\n",
      "indices:    {15625, 15627, 22029, 15599, 15601, 15602, 22037, 15543, 15545, 15607}\n",
      "dict_items([(\"Lemma('tax_write-off.n.01.deduction')\", 8)])\n",
      "collecting tokens for  loudly\n",
      "indices:    {36064, 7459, 9380, 8550, 7046, 5613, 9358, 24785, 23473, 18643, 34033, 5683, 18937}\n",
      "dict_items([(\"Lemma('loudly.r.01.loudly')\", 7), (\"Lemma('obstreperously.r.01.loudly')\", 1)])\n",
      "collecting tokens for  floating\n",
      "indices:    {24680, 27051, 24366, 30001, 12402, 3668, 6935, 7807}\n",
      "dict_items([(\"Lemma('float.v.01.float')\", 4), (\"Lemma('float.v.02.float')\", 1)])\n",
      "collecting tokens for  stairs\n",
      "indices:    {36098, 35978, 17674, 9357, 9358, 9360, 9362, 34067, 19734, 35735, 20121, 9755, 6430, 9380, 6184, 9385, 6187, 9777, 9779, 7735, 7738, 6204, 34108, 17482, 34127, 6228, 9688, 9698, 8163, 9701, 5734, 17517, 21243}\n",
      "dict_items([(\"Lemma('stairs.n.01.stairs')\", 15)])\n",
      "collecting tokens for  vital\n",
      "indices:    {32000, 22687, 28484, 8776, 31294, 29483, 25388, 21298, 21247, 27668, 33046, 25369, 23771, 33084, 32030, 27647}\n",
      "dict_items([(\"Lemma('critical.s.04.vital')\", 1)])\n",
      "collecting tokens for  writes\n",
      "indices:    {24220, 740, 4887, 826, 16151, 824, 20503, 853, 33493, 27127, 728, 26137, 26682, 32763, 26940, 26943}\n",
      "dict_items([(\"Lemma('write.v.02.write')\", 3), (\"Lemma('publish.v.03.write')\", 3), (\"Lemma('write.v.01.write')\", 5), (\"Lemma('write.v.04.write')\", 1), (\"Lemma('write.v.05.write')\", 1)])\n",
      "collecting tokens for  compulsive\n",
      "indices:    {24624, 15698, 15699, 15668, 27221, 15702, 15700, 15707, 15678}\n",
      "dict_items([(\"Lemma('compulsive.s.01.compulsive')\", 7)])\n",
      "collecting tokens for  structured\n",
      "indices:    {15713, 15719, 22760, 15659, 15660, 15724, 15727, 15728, 15698, 15699, 22738, 15702, 15645, 15711}\n",
      "dict_items([(\"Lemma('structured.a.01.structured')\", 12)])\n",
      "collecting tokens for  significantly\n",
      "indices:    {15657, 27882}\n",
      "dict_items([(\"Lemma('significantly.r.01.significantly')\", 1)])\n",
      "collecting tokens for  relation\n",
      "indices:    {4609, 5381, 5382, 25608, 11273, 30987, 33167, 11670, 3351, 12315, 31134, 32543, 11300, 11819, 4272, 4277, 31925, 28855, 3000, 11702, 14400, 1729, 15427, 14407, 15433, 11726, 27088, 24914, 25814, 16346, 15709, 2659, 15460, 16356, 3048, 5226, 32621, 15470, 27887, 5360, 16118, 14072, 2940, 2941}\n",
      "dict_items([(\"Lemma('relation.n.01.relation')\", 19)])\n",
      "collecting tokens for  heat\n",
      "indices:    {26945, 30146, 19180, 2925, 2872, 21021}\n",
      "dict_items([(\"Lemma('heat.n.04.heat')\", 1), (\"Lemma('heat.n.01.heat')\", 2)])\n",
      "collecting tokens for  evaluation\n",
      "indices:    {32921, 32931, 3170, 32930, 15814, 32999, 15816, 15756, 5517, 32397, 15729, 15763, 15734, 32124, 14841, 11386, 32700}\n",
      "dict_items([(\"Lemma('evaluation.n.01.evaluation')\", 8), (\"Lemma('evaluation.n.02.evaluation')\", 2)])\n",
      "collecting tokens for  fields\n",
      "indices:    {7520, 21989, 3004, 7822, 4604}\n",
      "dict_items([(\"Lemma('field.n.05.field')\", 1), (\"Lemma('sphere.n.01.field')\", 1), (\"Lemma('field.n.01.field')\", 2)])\n",
      "collecting tokens for  probabilities\n",
      "indices:    {14849, 14845, 27801, 4420, 4389, 4391, 27785, 4431, 4463, 27794, 4468, 4438, 14841, 14842, 4475, 31132, 27837, 14846}\n",
      "dict_items([(\"Lemma('probability.n.01.probability')\", 13)])\n",
      "collecting tokens for  cross\n",
      "indices:    {15456, 13508, 32716, 27311, 27343, 24658, 33587}\n",
      "dict_items([(\"Lemma('traverse.v.01.cross')\", 2)])\n",
      "collecting tokens for  t.\n",
      "indices:    {21474}\n",
      "dict_items([])\n",
      "collecting tokens for  review\n",
      "indices:    {14126}\n",
      "dict_items([])\n",
      "collecting tokens for  poetry\n",
      "indices:    {31528, 24675, 31579}\n",
      "dict_items([])\n",
      "collecting tokens for  monk\n",
      "indices:    {28164, 28167, 2709, 21755, 28156, 28157, 5886}\n",
      "dict_items([(\"Lemma('monk.n.01.monk')\", 2)])\n",
      "collecting tokens for  cockpit\n",
      "indices:    {30564, 29702, 29704, 23305, 30506, 23308, 21711, 29693, 18706, 18682, 29691, 27101, 30558}\n",
      "dict_items([(\"Lemma('cockpit.n.01.cockpit')\", 2)])\n",
      "collecting tokens for  selling\n",
      "indices:    {21312, 14244, 21925, 11685, 2279, 12173, 9871, 11632, 11664, 21808, 1396, 30965, 23190, 11669, 11640, 21817, 2750, 23391}\n",
      "dict_items([(\"Lemma('selling.n.01.selling')\", 6), (\"Lemma('sell.v.01.sell')\", 8), (\"Lemma('sell.v.02.sell')\", 3)])\n",
      "collecting tokens for  developing\n",
      "indices:    {11649, 16258, 32900, 4996, 4741, 2309, 4617, 15117, 30734, 18717, 4768, 23848, 20785, 11701, 9144, 11709, 2750, 23879, 32457, 334, 28502, 16088, 3804, 20734}\n",
      "dict_items([(\"Lemma('developing.s.01.developing')\", 2), (\"Lemma('develop.v.01.develop')\", 4), (\"Lemma('evolve.v.01.develop')\", 5), (\"Lemma('develop.v.03.develop')\", 3), (\"Lemma('grow.v.08.develop')\", 2), (\"Lemma('modernize.v.02.develop')\", 2), (\"Lemma('originate.v.01.develop')\", 1), (\"Lemma('train.v.01.develop')\", 2), (\"Lemma('build_up.v.05.develop')\", 2)])\n",
      "collecting tokens for  customers\n",
      "indices:    {11680, 22305, 21793, 21795, 29475, 21794, 99, 16359, 29473, 14219, 25247, 19511, 16346, 5469, 190, 25663}\n",
      "dict_items([(\"Lemma('customer.n.01.customer')\", 8)])\n",
      "collecting tokens for  surfaces\n",
      "indices:    {30049, 21731, 5412, 2952, 4072, 14824, 28843, 28782, 2862, 2959, 3216, 3184, 3158, 3191, 3353, 3163, 4095}\n",
      "dict_items([(\"Lemma('surface.n.01.surface')\", 10), (\"Lemma('surface.n.02.surface')\", 3)])\n",
      "collecting tokens for  arcs\n",
      "indices:    {2894, 2862, 2864, 2895, 2866, 2873, 2876, 2877}\n",
      "dict_items([(\"Lemma('discharge.n.05.arc')\", 8)])\n",
      "collecting tokens for  indian\n",
      "indices:    {36013}\n",
      "dict_items([])\n",
      "collecting tokens for  colony\n",
      "indices:    {31488, 31714, 23207, 7560, 12488, 12490, 23209, 12491, 12461, 12475, 3633, 3635, 12502, 22103, 23193, 23227}\n",
      "dict_items([(\"Lemma('colony.n.02.colony')\", 2), (\"Lemma('colony.n.01.colony')\", 6)])\n",
      "collecting tokens for  choosing\n",
      "indices:    {29824, 27810, 8802, 6244, 24873, 8367, 30002, 21237, 34333, 4415}\n",
      "dict_items([(\"Lemma('choose.v.01.choose')\", 8)])\n",
      "collecting tokens for  scientists\n",
      "indices:    {14587}\n",
      "dict_items([(\"Lemma('scientist.n.01.scientist')\", 1)])\n",
      "collecting tokens for  mathematics\n",
      "indices:    {25796, 11434, 13290, 23117, 28847, 20528, 14064, 28860, 28852, 28949, 26809, 12827, 26812}\n",
      "dict_items([(\"Lemma('mathematics.n.01.mathematics')\", 4)])\n",
      "collecting tokens for  lot\n",
      "indices:    {8321, 2178, 25730, 35073, 29701, 3722, 11530, 21004, 25359, 17682, 1043, 30711, 24467, 33942, 24471, 4886, 9881, 36379, 30077, 21537, 29986, 422, 8486, 22951, 19624, 13098, 5421, 16947, 30391, 4408, 10936, 19641, 5437, 30654, 22208, 4417, 322, 11072, 20034, 25413, 323, 37067, 33483, 22349, 6481, 30673, 2258, 16597, 11608, 9817, 19675, 12507, 5598, 5471, 11616, 34272, 33376, 26724, 11111, 16489, 30185, 12906, 18285, 17391, 6896, 5747, 13555, 6900, 19319, 9849, 30714, 34555, 14333, 36607}\n",
      "dict_items([(\"Lemma('batch.n.02.lot')\", 4), (\"Lemma('lot.n.02.lot')\", 3), (\"Lemma('set.n.05.lot')\", 2), (\"Lemma('fortune.n.04.lot')\", 2), (\"Lemma('draw.n.04.lot')\", 2), (\"Lemma('bunch.n.03.lot')\", 1), (\"Lemma('a_lot.r.01.a_lot')\", 1)])\n",
      "collecting tokens for  leonard\n",
      "indices:    {28584}\n",
      "dict_items([])\n",
      "collecting tokens for  veteran\n",
      "indices:    {15744, 24960, 260, 12807, 23312, 23324, 6943, 672, 23077, 4903, 11062, 5180, 5181, 1600, 68, 12362, 75, 26199, 21465, 222, 24944, 22649, 24956, 381}\n",
      "dict_items([(\"Lemma('seasoned.s.02.veteran')\", 8), (\"Lemma('veteran.n.02.veteran')\", 4), (\"Lemma('veteran.n.03.veteran')\", 3)])\n",
      "collecting tokens for  border\n",
      "indices:    {23348}\n",
      "dict_items([])\n",
      "collecting tokens for  patrol\n",
      "indices:    {5816, 18672, 21509}\n",
      "dict_items([(\"Lemma('patrol.v.01.patrol')\", 1), (\"Lemma('patrol.n.01.patrol')\", 1)])\n",
      "collecting tokens for  friend\n",
      "indices:    {11072, 18273, 24290, 26690, 31719, 33320, 26766, 34897, 14453, 6999, 10744, 30874, 14456, 29151}\n",
      "dict_items([(\"Lemma('friend.n.01.friend')\", 5)])\n",
      "collecting tokens for  recall\n",
      "indices:    {10624, 27265, 28042, 29311, 37138, 14108, 26525, 10669, 34748, 26946, 24783, 27093, 2137, 12249, 28642, 9582, 25839, 23794, 30839, 10621, 2431}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('remember.v.01.recall')\", 19)])\n",
      "collecting tokens for  laughter\n",
      "indices:    {8866, 4899, 10915, 36005, 17989, 6760, 9257, 18952, 24783, 15856, 15857, 7408, 10996, 26870, 4887, 9721, 28378}\n",
      "dict_items([(\"Lemma('laugh.n.01.laughter')\", 13)])\n",
      "collecting tokens for  autumn\n",
      "indices:    {21890, 3594, 8474, 11172, 27049, 14510, 11439, 22194, 26810, 27070, 24777, 24783, 29151, 26981, 26984, 26985, 24811, 26987, 7289, 8702}\n",
      "dict_items([(\"Lemma('fall.n.01.autumn')\", 6)])\n",
      "collecting tokens for  pond\n",
      "indices:    {5489, 12162}\n",
      "dict_items([(\"Lemma('pond.n.01.pond')\", 2)])\n",
      "collecting tokens for  save\n",
      "indices:    {31771}\n",
      "dict_items([])\n",
      "collecting tokens for  fruits\n",
      "indices:    {30469, 30470, 30025, 1705, 27344, 12116, 2550, 1693}\n",
      "dict_items([(\"Lemma('fruit.n.01.fruit')\", 3)])\n",
      "collecting tokens for  saving\n",
      "indices:    {21672, 25256, 25131, 20461, 35469, 111, 27344, 32562, 25874, 32564, 307, 13241, 9626, 27774}\n",
      "dict_items([(\"Lemma('save.v.05.save')\", 2), (\"Lemma('salvage.v.01.save')\", 2), (\"Lemma('rescue.n.01.saving')\", 1), (\"Lemma('save.v.02.save')\", 1), (\"Lemma('save.v.06.save')\", 1), (\"Lemma('save.v.03.save')\", 2), (\"Lemma('redemptive.s.02.saving')\", 1)])\n",
      "collecting tokens for  expressing\n",
      "indices:    {32262, 12300, 19343, 12305, 30226, 1305, 5024, 4653, 21683, 27586, 13635, 27344, 26706, 26199, 4835, 15848, 4846, 34798, 22773}\n",
      "dict_items([(\"Lemma('express.v.01.express')\", 12), (\"Lemma('carry.v.04.express')\", 2), (\"Lemma('express.v.02.express')\", 4)])\n",
      "collecting tokens for  bud\n",
      "indices:    {13568, 459}\n",
      "dict_items([(\"Lemma('bud.n.01.bud')\", 1)])\n",
      "collecting tokens for  thereafter\n",
      "indices:    {22773, 15493, 22943}\n",
      "dict_items([(\"Lemma('thereafter.r.01.thereafter')\", 1)])\n",
      "collecting tokens for  applause\n",
      "indices:    {6823, 6249, 26476, 26398, 9938, 20402, 4895, 13754, 1053, 1054, 1055}\n",
      "dict_items([(\"Lemma('applause.n.01.applause')\", 8)])\n",
      "collecting tokens for  reserved\n",
      "indices:    {22722, 12036, 12519, 27657, 13642, 21803, 26348, 32045, 25999, 36274, 15891, 22162, 915, 32024, 1274, 1055}\n",
      "dict_items([(\"Lemma('allow.v.04.reserve')\", 5), (\"Lemma('reserve.v.01.reserve')\", 3), (\"Lemma('reserve.v.03.reserve')\", 1)])\n",
      "collecting tokens for  strain\n",
      "indices:    {33032, 22670, 28052, 1055, 37155, 23335, 11180, 11310, 4143, 559, 29234, 3006, 27201, 36424, 26699, 15704, 10970, 11753, 14570, 35563}\n",
      "dict_items([(\"Lemma('strain.n.01.strain')\", 4), (\"Lemma('sift.v.02.strain')\", 1), (\"Lemma('breed.n.01.strain')\", 1), (\"Lemma('tune.n.01.strain')\", 1), (\"Lemma('strain.n.04.strain')\", 1), (\"Lemma('stress.n.04.strain')\", 2)])\n",
      "collecting tokens for  acting\n",
      "indices:    {26560, 1216, 14055, 14230, 14455, 31993, 20154, 10811, 31996, 5310}\n",
      "dict_items([(\"Lemma('act.v.03.act')\", 1), (\"Lemma('act.v.02.act')\", 2), (\"Lemma('acting.n.01.acting')\", 2), (\"Lemma('act.v.01.act')\", 1)])\n",
      "collecting tokens for  uncomfortable\n",
      "indices:    {27205, 7302, 30174, 9259, 14091, 34575, 34386, 32158, 1055}\n",
      "dict_items([(\"Lemma('uncomfortable.a.02.uncomfortable')\", 2), (\"Lemma('uncomfortable.a.01.uncomfortable')\", 2)])\n",
      "collecting tokens for  gravel\n",
      "indices:    {15105, 30509, 35919, 35920, 19122, 12821, 15101, 15103}\n",
      "dict_items([(\"Lemma('gravel.n.01.gravel')\", 3)])\n",
      "collecting tokens for  teen-agers\n",
      "indices:    {13184, 13154, 13219, 13159, 30059, 23563, 13166, 13135, 13182, 13171, 30037, 33790, 13151}\n",
      "dict_items([(\"Lemma('adolescent.n.01.teenager')\", 9)])\n",
      "collecting tokens for  confirmed\n",
      "indices:    {1032, 13928, 5129, 25865, 24170, 28265, 34510, 13135, 1392, 24018, 16127, 1049, 33919, 20223}\n",
      "dict_items([(\"Lemma('confirm.v.02.confirm')\", 3), (\"Lemma('confirm.v.01.confirm')\", 5), (\"Lemma('confirmed.s.01.confirmed')\", 2), (\"Lemma('confirm.v.04.confirm')\", 1), (\"Lemma('confirmed.a.02.confirmed')\", 1), (\"Lemma('confirm.v.03.confirm')\", 1)])\n",
      "collecting tokens for  portrait\n",
      "indices:    {14401, 31881, 1428, 7353, 29405}\n",
      "dict_items([(\"Lemma('portrait.n.02.portrait')\", 1), (\"Lemma('portrayal.n.01.portrait')\", 1)])\n",
      "collecting tokens for  bonds\n",
      "indices:    {130, 23429, 3079, 23432, 23435, 147, 21270, 150, 56, 58, 59, 60, 61, 14539, 13135, 23376, 23379, 23380, 8150, 23383, 23384, 23385, 23386, 23387, 23388, 23389, 23391, 23392, 23393, 23394, 25059, 25061, 23406, 32623, 7665, 3065}\n",
      "dict_items([(\"Lemma('bond.n.02.bond')\", 9), (\"Lemma('alliance.n.02.bond')\", 2), (\"Lemma('chemical_bond.n.01.bond')\", 1), (\"Lemma('attachment.n.04.bond')\", 1)])\n",
      "collecting tokens for  indonesia\n",
      "indices:    {25860}\n",
      "dict_items([])\n",
      "collecting tokens for  dancers\n",
      "indices:    {26473, 25674, 26250, 25677, 1917, 31919, 31856, 25680, 21586, 31920, 26452, 26909, 7773, 22334, 1919}\n",
      "dict_items([(\"Lemma('dancer.n.01.dancer')\", 3)])\n",
      "collecting tokens for  bigger\n",
      "indices:    {20481, 10503, 11912, 35607, 3609, 12698, 23835, 17184, 5026, 8996, 25257, 3626, 25265, 818, 34484, 574, 23747, 10310, 25677, 11623, 34420, 26484, 23032, 12670}\n",
      "dict_items([(\"Lemma('large.a.01.big')\", 3), (\"Lemma('bigger.s.01.bigger')\", 9), (\"Lemma('big.s.02.big')\", 1)])\n",
      "collecting tokens for  attendant\n",
      "indices:    {14112, 33440, 33415, 5128, 31886, 10766, 33429, 33430}\n",
      "dict_items([(\"Lemma('attendant.n.01.attendant')\", 1)])\n",
      "collecting tokens for  flux\n",
      "indices:    {2951, 2955, 3340, 31886, 3344, 3345, 3347, 3348, 3364, 3365, 3369, 3370, 3373, 26415, 2878, 25586, 3318, 3319, 3321}\n",
      "dict_items([(\"Lemma('flux.n.02.flux')\", 3), (\"Lemma('flux.n.01.flux')\", 13)])\n",
      "collecting tokens for  impressions\n",
      "indices:    {31162, 31155, 9575, 2167}\n",
      "dict_items([(\"Lemma('impression.n.02.impression')\", 1), (\"Lemma('impression.n.01.impression')\", 1)])\n",
      "collecting tokens for  discovered\n",
      "indices:    {5896, 12426, 37003, 13323, 11155, 10644, 21784, 21020, 18846, 31902, 10272, 5036, 31277, 30256, 31921, 15666, 34487, 34360, 34745, 20537, 31932, 14528, 30019, 35911, 5323, 6092, 15695, 2256, 11474, 2396, 13149, 27749, 16873, 4842, 30827, 14828, 28525, 14829, 36972, 32115, 24820, 10099, 30844, 26749}\n",
      "dict_items([(\"Lemma('detect.v.01.discover')\", 8), (\"Lemma('learn.v.02.discover')\", 8), (\"Lemma('discover.v.03.discover')\", 12), (\"Lemma('fall_upon.v.01.discover')\", 3), (\"Lemma('discover.v.04.discover')\", 5), (\"Lemma('unwrap.v.02.discover')\", 3), (\"Lemma('ascertained.s.01.discovered')\", 2), (\"Lemma('discover.v.07.discover')\", 1)])\n",
      "collecting tokens for  brand\n",
      "indices:    {17889, 22787, 10725, 11660, 37037, 11662, 11663, 36464, 18001, 7665, 22702, 11668, 10644, 26419, 18300, 26749}\n",
      "dict_items([(\"Lemma('brand.n.03.brand')\", 2), (\"Lemma('trade_name.n.01.brand')\", 5), (\"Lemma('brand.n.02.brand')\", 3)])\n",
      "collecting tokens for  closet\n",
      "indices:    {9472, 16999, 9481, 33931, 17580, 30125, 9394, 19510, 6458}\n",
      "dict_items([(\"Lemma('cupboard.n.01.closet')\", 4), (\"Lemma('wardrobe.n.01.closet')\", 1), (\"Lemma('water_closet.n.01.closet')\", 1)])\n",
      "collecting tokens for  dared\n",
      "indices:    {37088, 36423, 6472, 9616, 35985, 26388, 5973, 6325, 6458, 5023}\n",
      "dict_items([(\"Lemma('defy.v.03.dare')\", 1), (\"Lemma('make_bold.v.01.dare')\", 3), (\"Lemma('dare.v.02.dare')\", 1)])\n",
      "collecting tokens for  lightning\n",
      "indices:    {26400, 26145, 18092, 6463}\n",
      "dict_items([(\"Lemma('lightning.n.01.lightning')\", 2)])\n",
      "collecting tokens for  notion\n",
      "indices:    {2564, 23813, 16008, 14603, 14607, 14608, 14610, 14100, 14102, 1304, 8859, 4897, 20651, 2605, 2610, 13490, 14260, 30774, 26560, 34383, 1487, 10964, 14703, 22779, 14332, 14719}\n",
      "dict_items([(\"Lemma('impression.n.01.notion')\", 8), (\"Lemma('notion.n.02.notion')\", 11), (\"Lemma('notion.n.03.notion')\", 1)])\n",
      "collecting tokens for  napoleon\n",
      "indices:    {16436}\n",
      "dict_items([])\n",
      "collecting tokens for  struggle\n",
      "indices:    {18561, 2308, 20489, 34957, 4632, 35996, 12957, 23582, 24616, 14122, 14125, 23982, 14129, 25778, 11443, 12980, 4789, 13366, 32054, 22585, 28089, 13370, 27839, 13375, 13889, 23750, 24138, 24658, 26197, 32214, 855, 15704, 31706, 24668, 2534, 25585, 31221, 26101, 17919}\n",
      "dict_items([(\"Lemma('conflict.n.01.struggle')\", 3), (\"Lemma('struggle.n.01.struggle')\", 11), (\"Lemma('fight.v.03.struggle')\", 2), (\"Lemma('clamber.v.01.struggle')\", 1), (\"Lemma('struggle.v.02.struggle')\", 1), (\"Lemma('struggle.n.03.struggle')\", 1), (\"Lemma('contend.v.06.struggle')\", 1)])\n",
      "collecting tokens for  amounts\n",
      "indices:    {25090, 12163, 3973, 21770, 15501, 3985, 14874, 16411, 30497, 15011, 2598, 14886, 14889, 3242, 14894, 1712, 14129, 20147, 4404, 16694, 27705, 3258, 4156, 3522, 23629, 13902, 3412, 27225, 23516, 4189, 36069, 3561, 27245, 4082}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('sum.n.01.amount')\", 6), (\"Lemma('amount.n.02.amount')\", 6), (\"Lemma('measure.n.02.amount')\", 6), (\"Lemma('amount.v.01.amount')\", 7), (\"Lemma('total.v.01.amount')\", 1), (\"Lemma('come.v.15.amount')\", 1)])\n",
      "collecting tokens for  predict\n",
      "indices:    {20618, 23018, 20620, 20621, 10157, 14129, 1367, 16888}\n",
      "dict_items([(\"Lemma('predict.v.01.predict')\", 8)])\n",
      "collecting tokens for  bought\n",
      "indices:    {8836, 24710, 9481, 13961, 29714, 35859, 11156, 29845, 13083, 37024, 9633, 7589, 7471, 21937, 22453, 7485, 11201, 22084, 9162, 10321, 23383, 11992, 20059, 20060, 2268, 37089, 23144, 36073, 26604, 23546, 5755, 21628, 7551}\n",
      "dict_items([(\"Lemma('buy.v.01.buy')\", 26), (\"Lemma('bribe.v.01.buy')\", 1)])\n",
      "collecting tokens for  drainage\n",
      "indices:    {12166, 5545, 1898, 33806, 5522, 29845, 25302, 5558, 33848, 33823, 30079}\n",
      "dict_items([(\"Lemma('drain.n.01.drainage')\", 3)])\n",
      "collecting tokens for  noticed\n",
      "indices:    {10498, 9732, 35716, 22536, 2186, 33162, 17292, 9357, 9486, 34834, 34838, 19225, 35738, 13851, 18339, 941, 22962, 10421, 12726, 31545, 5701, 17096, 5577, 17354, 18125, 35663, 18257, 29010, 19283, 33491, 27353, 34783, 13681, 33522}\n",
      "dict_items([(\"Lemma('notice.v.02.notice')\", 9), (\"Lemma('detect.v.01.notice')\", 25)])\n",
      "collecting tokens for  ride\n",
      "indices:    {10558, 35362, 35300, 35909, 18395, 230, 25224, 18504, 18092, 28661, 35831, 601, 29691, 2685, 23742}\n",
      "dict_items([(\"Lemma('ride.v.02.ride')\", 4), (\"Lemma('ride.v.03.ride')\", 1), (\"Lemma('drive.n.08.ride')\", 3), (\"Lemma('ride.v.01.ride')\", 4)])\n",
      "collecting tokens for  lantern\n",
      "indices:    {32707, 18378, 32715, 32717, 15149, 32719, 35409, 2071, 29144, 35418, 18460, 35421}\n",
      "dict_items([(\"Lemma('lantern.n.01.lantern')\", 3)])\n",
      "collecting tokens for  pathology\n",
      "indices:    {32706}\n",
      "dict_items([])\n",
      "collecting tokens for  library\n",
      "indices:    {22496, 22338}\n",
      "dict_items([])\n",
      "collecting tokens for  illustration\n",
      "indices:    {23425, 32714, 19518}\n",
      "dict_items([(\"Lemma('illustration.n.01.illustration')\", 1)])\n",
      "collecting tokens for  missing\n",
      "indices:    {22912, 7332, 25444, 7304, 24011, 16652, 18348, 25260, 7727, 26415, 5809, 19344, 30515, 19343, 5877, 36889, 2172, 36765}\n",
      "dict_items([(\"Lemma('missing.s.01.missing')\", 4), (\"Lemma('miss.v.03.miss')\", 2), (\"Lemma('neglect.v.01.miss')\", 1), (\"Lemma('miss.v.01.miss')\", 1)])\n",
      "collecting tokens for  flat\n",
      "indices:    {8075, 13580, 5404, 8605, 21158, 28969, 32301, 11314, 35250, 11319, 12729, 11325, 30526, 3142, 30545, 18002, 30554, 20715, 21365}\n",
      "dict_items([(\"Lemma('flat.s.01.flat')\", 6), (\"Lemma('flat.s.02.flat')\", 2), (\"Lemma('flat.a.05.flat')\", 1), (\"Lemma('flat.n.01.flat')\", 1)])\n",
      "collecting tokens for  walter\n",
      "indices:    {12915}\n",
      "dict_items([])\n",
      "collecting tokens for  matters\n",
      "indices:    {26754, 1428, 22, 23190, 15392, 24099, 7080, 12329, 15405, 26035, 15668, 2100, 14389, 30775, 31800, 26041, 26682, 35643, 26043, 10876, 32325, 14025, 11343, 31186, 31956, 7509, 34400, 14433, 4964, 32364, 23278, 3054, 13044, 4598, 9591, 7932}\n",
      "dict_items([(\"Lemma('count.v.02.matter')\", 3), (\"Lemma('topic.n.02.matter')\", 9), (\"Lemma('matter.n.01.matter')\", 7)])\n",
      "collecting tokens for  plans\n",
      "indices:    {23461, 20328, 34922, 17549, 31088, 20785, 15098, 22525}\n",
      "dict_items([(\"Lemma('plan.v.01.plan')\", 1), (\"Lemma('plan.n.01.plan')\", 1), (\"Lemma('plan.n.03.plan')\", 1)])\n",
      "collecting tokens for  1962\n",
      "indices:    {23431, 24841, 24586, 14748, 22174, 24606, 24099, 24611, 15015, 40, 15017, 15022, 15026, 14771, 28595, 15550, 15552, 15553, 15554, 15558, 15559, 15560, 15563, 15053, 15057, 15059, 15065, 15069, 22248, 21246}\n",
      "dict_items([])\n",
      "collecting tokens for  ladies\n",
      "indices:    {7921, 9949}\n",
      "dict_items([(\"Lemma('lady.n.01.lady')\", 1), (\"Lemma('dame.n.02.lady')\", 1)])\n",
      "collecting tokens for  marriages\n",
      "indices:    {36882, 32919, 32923, 32932, 32935, 34220, 13231, 32949, 11972, 11973, 11974, 33101, 32082, 32099, 12003, 22249, 22250, 12010, 22251, 22253, 12014, 8811, 27383}\n",
      "dict_items([(\"Lemma('marriage.n.02.marriage')\", 6), (\"Lemma('marriage.n.01.marriage')\", 1), (\"Lemma('marriage.n.03.marriage')\", 1)])\n",
      "collecting tokens for  kingdom\n",
      "indices:    {27523}\n",
      "dict_items([])\n",
      "collecting tokens for  r.\n",
      "indices:    {21886}\n",
      "dict_items([])\n",
      "collecting tokens for  met\n",
      "indices:    {28164, 33289, 18971, 23583, 8736, 32814, 25141, 35381, 22595, 32329, 26189, 23131, 19550, 36448, 3177, 24682, 8832, 2179, 15495, 30856, 30857, 2186, 14985, 20622, 37012, 37016, 37019, 19614, 18591, 14497, 22699, 28332, 30895, 8893, 11453, 12479, 32959, 37057, 5823, 30405, 30919, 14541, 13027, 19173, 5861, 1263, 17140, 23800, 14586, 17150, 20231, 13063, 23831, 22807, 19765, 24886, 26424, 28152, 30546, 3414, 17240, 3419, 24423, 24425, 19314, 31097, 27515, 20867, 29067, 32147, 19348, 8095, 20897, 20898, 36279, 10692, 12244, 8150, 6107, 19429, 15845, 16888}\n",
      "dict_items([(\"Lemma('meet.v.01.meet')\", 26), (\"Lemma('meet.v.02.meet')\", 11), (\"Lemma('meet.v.11.meet')\", 6), (\"Lemma('meet.v.04.meet')\", 6), (\"Lemma('meet.v.06.meet')\", 3), (\"Lemma('meet.v.07.meet')\", 4), (\"Lemma('meet.v.08.meet')\", 3), (\"Lemma('converge.v.01.meet')\", 4), (\"Lemma('meet.v.05.meet')\", 5), (\"Lemma('meet.v.09.meet')\", 3), (\"Lemma('suffer.v.10.meet')\", 2), (\"Lemma('meet.v.10.meet')\", 1)])\n",
      "collecting tokens for  takes\n",
      "indices:    {26754, 2435, 24958, 7687, 26632, 24329, 11403, 1806, 11279, 27536, 33940, 20, 11286, 23190, 1561, 10650, 4891, 1694, 4641, 26531, 34340, 13991, 31527, 2733, 1582, 34865, 22065, 23604, 11959, 14399, 13119, 4929, 30786, 15939, 15428, 22466, 11075, 26439, 28365, 26190, 20942, 31064, 25691, 21087, 992, 30049, 28385, 13671, 2025, 2666, 32622, 29295, 25203, 4468, 26357, 20468, 11385, 13690, 26235, 29052, 1533, 15998}\n",
      "dict_items([(\"Lemma('take.v.02.take')\", 6), (\"Lemma('necessitate.v.01.take')\", 5), (\"Lemma('take.v.04.take')\", 1), (\"Lemma('assume.v.03.take')\", 5), (\"Lemma('take.v.01.take')\", 3), (\"Lemma('lead.v.01.take')\", 3), (\"Lemma('consider.v.03.take')\", 1), (\"Lemma('remove.v.01.take_away')\", 1), (\"Lemma('accept.v.02.take')\", 2), (\"Lemma('claim.v.05.take')\", 1), (\"Lemma('choose.v.01.take')\", 2), (\"Lemma('take.v.19.take')\", 1), (\"Lemma('take.v.24.take')\", 1)])\n",
      "collecting tokens for  c-plane\n",
      "indices:    {4506}\n",
      "dict_items([])\n",
      "collecting tokens for  occurs\n",
      "indices:    {4384, 3232, 13624, 2628, 11301, 3911, 2601, 2648, 27243, 3922, 25331, 16084, 4245, 1495, 4536, 16063}\n",
      "dict_items([(\"Lemma('happen.v.01.occur')\", 12), (\"Lemma('occur.v.02.occur')\", 1)])\n",
      "collecting tokens for  financed\n",
      "indices:    {28672, 6106, 28676, 23656, 32331, 20176, 11892, 31288, 23514, 32446}\n",
      "dict_items([(\"Lemma('finance.v.01.finance')\", 8)])\n",
      "collecting tokens for  security\n",
      "indices:    {20980}\n",
      "dict_items([])\n",
      "collecting tokens for  payroll\n",
      "indices:    {21153, 21154, 21160, 21161, 24970, 21771, 20176, 20177, 20178, 20179, 20180, 11829, 20184, 21757, 21758}\n",
      "dict_items([(\"Lemma('payroll.n.01.payroll')\", 1)])\n",
      "collecting tokens for  37\n",
      "indices:    {21256, 15628, 3725, 23445, 288, 3748, 3751, 4136, 4142, 21694, 3529, 3535, 20176, 29012, 29015, 29033, 29930, 28542, 27390}\n",
      "dict_items([])\n",
      "collecting tokens for  paying\n",
      "indices:    {21313, 13026, 37093, 25189, 33576, 21610, 16043, 30540, 20176, 22512, 16242, 147, 32628, 26709, 20540, 190, 32287}\n",
      "dict_items([(\"Lemma('pay.v.01.pay')\", 7), (\"Lemma('pay_up.v.01.pay')\", 3), (\"Lemma('give.v.05.pay')\", 3)])\n",
      "collecting tokens for  somehow\n",
      "indices:    {17729, 30597, 27272, 14603, 34324, 17020, 37117}\n",
      "dict_items([(\"Lemma('somehow.r.02.somehow')\", 1), (\"Lemma('somehow.r.01.somehow')\", 2)])\n",
      "collecting tokens for  solely\n",
      "indices:    {24896, 3489, 16300, 32365, 4012, 15230, 2707, 15221, 16280, 4955, 35708, 15229, 32094}\n",
      "dict_items([(\"Lemma('entirely.r.02.solely')\", 9)])\n",
      "collecting tokens for  demands\n",
      "indices:    {25350, 3719, 25353, 31758, 2447, 2062, 9359, 23829, 16280, 924, 12060, 16290, 7078, 12071, 7082, 16431, 15663, 23731, 7092, 20153, 7097, 22843, 30012, 27515, 16325, 21446, 21447, 1738, 23627, 7628, 31954, 26966, 13657, 26074, 23519, 32370, 31987, 2036, 16375, 16635, 24444}\n",
      "dict_items([(\"Lemma('necessitate.v.01.demand')\", 7), (\"Lemma('demand.n.01.demand')\", 9), (\"Lemma('demand.v.01.demand')\", 2), (\"Lemma('requirement.n.01.demand')\", 5), (\"Lemma('demand.n.02.demand')\", 1)])\n",
      "collecting tokens for  ideological\n",
      "indices:    {25312, 25541, 23660, 22350, 31217, 25554, 31219, 22585, 26202}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([])\n",
      "collecting tokens for  passion\n",
      "indices:    {2688, 13795, 36810, 10511, 36303, 32082, 26297, 26550, 29305, 7451, 27100, 28030}\n",
      "dict_items([(\"Lemma('love.n.02.passion')\", 1), (\"Lemma('passion.n.01.passion')\", 1), (\"Lemma('mania.n.01.passion')\", 1), (\"Lemma('passion.n.05.passion')\", 1)])\n",
      "collecting tokens for  ryan\n",
      "indices:    {34499}\n",
      "dict_items([])\n",
      "collecting tokens for  moving\n",
      "indices:    {11908, 30888, 23752, 28458, 1137, 9171, 18356, 12856, 7674, 26747}\n",
      "dict_items([(\"Lemma('travel.v.01.move')\", 4), (\"Lemma('moving.a.02.moving')\", 1), (\"Lemma('move.v.07.move')\", 1), (\"Lemma('move.v.03.move')\", 1)])\n",
      "collecting tokens for  term\n",
      "indices:    {1, 14722, 2, 30730, 26775, 5275, 161, 24097, 25855, 38, 15015, 33065, 14763, 45, 23725, 22703, 14646, 11709, 31173, 25670, 22855, 21324, 14669, 2766, 20815, 15057, 20818, 11347, 11096, 32472, 20829, 5598, 5599, 14176, 13283, 31719, 21226, 20476, 26095, 20722, 13298, 14196, 31990, 27258, 4348, 20477, 890, 14335}\n",
      "dict_items([(\"Lemma('term.n.02.term')\", 8), (\"Lemma('term.n.01.term')\", 13), (\"Lemma('term.v.01.term')\", 2), (\"Lemma('term.n.04.term')\", 1)])\n",
      "collecting tokens for  republic\n",
      "indices:    {27259, 5233, 5250, 31699}\n",
      "dict_items([(\"Lemma('democracy.n.02.republic')\", 1)])\n",
      "collecting tokens for  phrase\n",
      "indices:    {34401, 26117, 30253, 25999, 31120, 11153, 26295, 28380}\n",
      "dict_items([(\"Lemma('phrase.n.01.phrase')\", 1)])\n",
      "collecting tokens for  name\n",
      "indices:    {20480, 9729, 27655, 24080, 24081, 24083, 2077, 9759, 19488, 6689, 34860, 21559, 30267, 12349, 30269, 19009, 23116, 7248, 2648, 19034, 23134, 24675, 28263, 6760, 19070, 2687, 28289, 14465, 30851, 28300, 24212, 9881, 25754, 10398, 30906, 2237, 29373, 33491, 26325, 8927, 8928, 31967, 28388, 8420, 27369, 27370, 5869, 37102, 1266, 23799, 11516, 11517, 26364, 24843, 5909, 17687, 21279, 11046, 831, 33600, 18243, 22851, 26446, 14161, 8539, 12635, 36707, 8037, 18277, 34663, 20328, 13695, 6020, 31108, 22414, 10639, 28052, 3989, 25499, 18332, 12190, 31137, 36259, 15281, 9142, 20417, 34245, 26054, 10701, 21457, 19411, 979, 8666, 17377, 14307, 32238, 28654}\n",
      "dict_items([(\"Lemma('name.n.01.name')\", 26), (\"Lemma('name.n.02.name')\", 3), (\"Lemma('name.v.03.name')\", 1), (\"Lemma('name.v.01.name')\", 1), (\"Lemma('identify.v.05.name')\", 1), (\"Lemma('name.n.05.name')\", 1), (\"Lemma('name.v.02.name')\", 2), (\"Lemma('name.v.05.name')\", 1), (\"Lemma('appoint.v.01.name')\", 1)])\n",
      "collecting tokens for  envelope\n",
      "indices:    {36096, 36199, 8735, 36205, 9581, 16670, 16664, 16570, 14520, 25855}\n",
      "dict_items([(\"Lemma('envelope.n.01.envelope')\", 6)])\n",
      "collecting tokens for  faded\n",
      "indices:    {8802, 35974, 4870, 28012, 1743, 1809, 10391, 8828, 17085, 25855}\n",
      "dict_items([(\"Lemma('evanesce.v.01.fade')\", 1), (\"Lemma('fade.v.01.fade')\", 1), (\"Lemma('attenuate.s.01.faded')\", 2), (\"Lemma('bleached.s.01.faded')\", 1), (\"Lemma('fade.v.02.fade')\", 2)])\n",
      "collecting tokens for  commuter\n",
      "indices:    {14912, 14914, 14915, 14925, 14929, 14899, 14900, 14901, 14904, 14908}\n",
      "dict_items([(\"Lemma('commuter.n.02.commuter')\", 2), (\"Lemma('commuter.n.01.commuter')\", 6)])\n",
      "collecting tokens for  ownership\n",
      "indices:    {32416, 24673, 25058, 22307, 25057, 1894, 2567, 32361, 22733, 14901, 14745, 5243}\n",
      "dict_items([(\"Lemma('possession.n.01.ownership')\", 2), (\"Lemma('ownership.n.01.ownership')\", 3)])\n",
      "collecting tokens for  streams\n",
      "indices:    {3337, 5130, 35921, 35249, 29206, 23382, 2330, 2333}\n",
      "dict_items([(\"Lemma('stream.n.02.stream')\", 2), (\"Lemma('stream.n.01.stream')\", 1), (\"Lemma('flow.n.03.stream')\", 1)])\n",
      "collecting tokens for  wet\n",
      "indices:    {6925, 9503, 13606, 33706, 26410, 19503, 19248, 9393, 7219, 9140, 19895, 33723, 7619, 19270, 10569, 6476, 12883, 9173, 3159, 1626, 19163, 7518, 27103, 5088, 19297, 24805, 19174, 36327, 6513, 6897, 31477, 18678, 30074, 15102, 7551}\n",
      "dict_items([(\"Lemma('wet.a.01.wet')\", 21), (\"Lemma('wet.v.01.wet')\", 4), (\"Lemma('moisture.n.01.wet')\", 1)])\n",
      "collecting tokens for  pastor\n",
      "indices:    {27617, 27586, 24260, 27590, 6054, 11433, 6058, 7019, 6063, 6127, 6065, 24921, 27578, 6042}\n",
      "dict_items([(\"Lemma('curate.n.01.pastor')\", 8)])\n",
      "collecting tokens for  convenient\n",
      "indices:    {16389, 16392, 21651, 5143, 3864, 13213, 5437, 27586, 3012, 3912, 4428, 11852, 726, 5468, 29921, 17122, 5475, 17131, 11375, 22648, 11647}\n",
      "dict_items([(\"Lemma('convenient.a.01.convenient')\", 15)])\n",
      "collecting tokens for  crash\n",
      "indices:    {11265, 19330, 34309, 24710, 18951, 13061, 21509, 5899, 23851, 18957, 23858, 10228, 23860, 822, 894, 24831}\n",
      "dict_items([(\"Lemma('clang.n.01.crash')\", 1), (\"Lemma('crash.n.03.crash')\", 1), (\"Lemma('crash.n.04.crash')\", 1), (\"Lemma('crash.n.02.crash')\", 3), (\"Lemma('crash.v.05.crash')\", 1)])\n",
      "collecting tokens for  sprang\n",
      "indices:    {18528, 19330, 27527, 18889, 8425, 34315, 33738, 28048, 19890, 35702, 18557}\n",
      "dict_items([(\"Lemma('jump.v.01.spring')\", 6), (\"Lemma('form.v.03.spring')\", 1), (\"Lemma('bounce.v.01.spring')\", 1)])\n",
      "collecting tokens for  unions\n",
      "indices:    {22787, 22788, 21767, 21768, 22793, 22798, 24211, 11797, 22805, 22809, 22811, 23969, 23971, 21158, 32936, 23727, 22742, 22743, 22754, 25343}\n",
      "dict_items([(\"Lemma('union.n.01.union')\", 1)])\n",
      "collecting tokens for  courts\n",
      "indices:    {22817, 28418, 28708, 651, 10799, 10800, 22801, 20850, 16463, 26581, 24918, 57}\n",
      "dict_items([(\"Lemma('court.n.01.court')\", 2), (\"Lemma('court.n.04.court')\", 1), (\"Lemma('woo.v.02.court')\", 1), (\"Lemma('court.n.02.court')\", 2)])\n",
      "collecting tokens for  veto\n",
      "indices:    {23811, 22627, 2567, 24168, 24169, 885, 24156, 24701, 22622}\n",
      "dict_items([(\"Lemma('veto.n.01.veto')\", 2), (\"Lemma('forbid.v.01.veto')\", 1)])\n",
      "collecting tokens for  w.\n",
      "indices:    {5140}\n",
      "dict_items([])\n",
      "collecting tokens for  mills\n",
      "indices:    {20059}\n",
      "dict_items([])\n",
      "collecting tokens for  warned\n",
      "indices:    {24896, 5602, 5346, 25383, 21919, 43, 5324, 5099, 5073, 16658, 24979, 24980, 5823, 19231}\n",
      "dict_items([(\"Lemma('warn.v.01.warn')\", 10), (\"Lemma('warn.v.02.warn')\", 4)])\n",
      "collecting tokens for  vigorously\n",
      "indices:    {24640, 23913, 1545, 5073, 23575, 16375, 14459, 16381}\n",
      "dict_items([(\"Lemma('vigorously.r.01.vigorously')\", 5)])\n",
      "collecting tokens for  crimes\n",
      "indices:    {12228, 25740, 12239, 24625, 12250}\n",
      "dict_items([(\"Lemma('crime.n.01.crime')\", 2)])\n",
      "collecting tokens for  arriving\n",
      "indices:    {5040, 31567}\n",
      "dict_items([(\"Lemma('arrive.v.01.arrive')\", 2)])\n",
      "collecting tokens for  baltimore\n",
      "indices:    {22995}\n",
      "dict_items([])\n",
      "collecting tokens for  adams\n",
      "indices:    {21886}\n",
      "dict_items([])\n",
      "collecting tokens for  covering\n",
      "indices:    {32513, 4620, 30993, 11681, 14754, 2725, 7590, 27946, 29867, 17579, 14637, 7341, 25400, 12481, 20674, 18635, 35799, 10590, 33140, 31349}\n",
      "dict_items([(\"Lemma('traverse.v.01.cover')\", 1), (\"Lemma('report.v.05.cover')\", 1), (\"Lemma('cover.v.03.cover')\", 3), (\"Lemma('cover.v.04.cover')\", 1), (\"Lemma('embrace.v.01.cover')\", 3), (\"Lemma('cover.v.13.cover')\", 1), (\"Lemma('cover.v.01.cover')\", 1), (\"Lemma('cover.v.09.cover')\", 1), (\"Lemma('cover.v.05.cover')\", 5), (\"Lemma('cover.v.02.cover')\", 2), (\"Lemma('cover.v.14.cover')\", 1)])\n",
      "collecting tokens for  missouri\n",
      "indices:    {5490}\n",
      "dict_items([(\"Lemma('missouri.n.01.Missouri')\", 1)])\n",
      "collecting tokens for  illinois\n",
      "indices:    {24057}\n",
      "dict_items([])\n",
      "collecting tokens for  torn\n",
      "indices:    {34976, 865, 5093, 6824, 10570, 6411, 35437, 21486, 35471, 34960, 20752, 30771, 6934, 12503, 2649, 18652, 29950, 8671}\n",
      "dict_items([(\"Lemma('torn.s.02.torn')\", 2), (\"Lemma('tear.v.01.tear')\", 4), (\"Lemma('tear.v.02.tear')\", 4), (\"Lemma('lacerate.s.02.torn')\", 1)])\n",
      "collecting tokens for  guard\n",
      "indices:    {20612}\n",
      "dict_items([])\n",
      "collecting tokens for  cycle\n",
      "indices:    {30147, 11140, 13379, 2919, 28667, 26474, 3661, 3663, 13811, 4243, 26488, 3419, 4221, 2591}\n",
      "dict_items([(\"Lemma('cycle.n.05.cycle')\", 1), (\"Lemma('hertz.n.01.cycle')\", 1), (\"Lemma('cycle.n.01.cycle')\", 3), (\"Lemma('cycle.n.03.cycle')\", 2), (\"Lemma('cycle.n.02.cycle')\", 1)])\n",
      "collecting tokens for  symphony\n",
      "indices:    {6907, 26797}\n",
      "dict_items([(\"Lemma('symphony.n.01.symphony')\", 1)])\n",
      "collecting tokens for  vertex\n",
      "indices:    {4503, 32802, 4517, 4496, 4497, 4498, 4499, 4500, 32820, 4502, 32822, 4569, 32828, 32829}\n",
      "dict_items([(\"Lemma('vertex.n.01.vertex')\", 9)])\n",
      "collecting tokens for  intersection\n",
      "indices:    {4512, 33954, 21507, 32802, 32837, 4517, 4510, 4524, 4527, 7472, 32815, 32828, 4509, 18845, 4511}\n",
      "dict_items([(\"Lemma('intersection.n.02.intersection')\", 2), (\"Lemma('intersection.n.01.intersection')\", 4)])\n",
      "collecting tokens for  revelation\n",
      "indices:    {14118, 28292, 25108, 2654}\n",
      "dict_items([(\"Lemma('disclosure.n.01.revelation')\", 1), (\"Lemma('revelation.n.02.revelation')\", 1)])\n",
      "collecting tokens for  superiority\n",
      "indices:    {14432, 11011, 30309, 25445, 26598, 12939, 15787, 25453, 30738, 14459}\n",
      "dict_items([(\"Lemma('superiority.n.03.superiority')\", 1), (\"Lemma('superiority.n.01.superiority')\", 3), (\"Lemma('superiority.n.02.superiority')\", 1)])\n",
      "collecting tokens for  testament\n",
      "indices:    {14709}\n",
      "dict_items([])\n",
      "collecting tokens for  scotland\n",
      "indices:    {12468}\n",
      "dict_items([(\"Lemma('scotland.n.01.Scotland')\", 1)])\n",
      "collecting tokens for  presbyterian\n",
      "indices:    {22373}\n",
      "dict_items([])\n",
      "collecting tokens for  ireland\n",
      "indices:    {884}\n",
      "dict_items([(\"Lemma('ireland.n.01.Ireland')\", 1)])\n",
      "collecting tokens for  british\n",
      "indices:    {23752}\n",
      "dict_items([])\n",
      "collecting tokens for  outcomes\n",
      "indices:    {4416, 4417, 4391, 4428, 4431, 4432, 4438, 4443, 4383}\n",
      "dict_items([(\"Lemma('result.n.03.outcome')\", 8), (\"Lemma('consequence.n.01.outcome')\", 1)])\n",
      "collecting tokens for  montero\n",
      "indices:    {35498}\n",
      "dict_items([])\n",
      "collecting tokens for  blow\n",
      "indices:    {25728, 35203, 19463, 35345, 18465, 6822, 10417, 17974, 6200, 6333, 14916, 204, 850, 9173, 35418, 22624, 34928, 23795, 37108}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('blow.n.01.blow')\", 7), (\"Lemma('reverse.n.03.blow')\", 1), (\"Lemma('blow.v.03.blow')\", 1), (\"Lemma('explode.v.01.blow_up')\", 1), (\"Lemma('blow.v.02.blow')\", 1), (\"Lemma('blow.n.02.blow')\", 1)])\n",
      "collecting tokens for  gently\n",
      "indices:    {36371, 8854, 29606, 29607, 29234, 9410, 30789, 37065, 12747, 31440, 29649, 8913, 34897, 5847, 30040, 3682, 7267, 13413, 7270, 10986, 35182, 29552, 34928, 9586, 29557, 19194}\n",
      "dict_items([(\"Lemma('lightly.r.03.gently')\", 3), (\"Lemma('gently.r.02.gently')\", 2), (\"Lemma('gently.r.01.gently')\", 7)])\n",
      "collecting tokens for  parasympathetic\n",
      "indices:    {4226, 4231, 4234, 4244, 4276, 4246, 4248}\n",
      "dict_items([(\"Lemma('parasympathetic.a.01.parasympathetic')\", 7)])\n",
      "collecting tokens for  hypothalamus\n",
      "indices:    {4224, 4227, 4228, 27207, 4231, 4203, 4204, 4205, 4271, 4240, 4210, 4211, 4248, 4217, 4218, 4219, 4216}\n",
      "dict_items([(\"Lemma('hypothalamus.n.01.hypothalamus')\", 16)])\n",
      "collecting tokens for  induced\n",
      "indices:    {32995, 4229, 13928, 3466, 4299, 32185, 4206, 4017, 4248, 4217, 25372, 4319}\n",
      "dict_items([(\"Lemma('induce.v.02.induce')\", 3), (\"Lemma('induce.v.03.induce')\", 4), (\"Lemma('induce.v.01.induce')\", 3), (\"Lemma('induced.a.01.induced')\", 1)])\n",
      "collecting tokens for  causes\n",
      "indices:    {31009, 27426, 25379, 25921, 29899, 11403, 2669, 1293, 12241, 178, 25105, 21461, 4218, 12798, 1151}\n",
      "dict_items([(\"Lemma('induce.v.02.cause')\", 4), (\"Lemma('cause.v.01.cause')\", 5), (\"Lemma('cause.n.01.cause')\", 1)])\n",
      "collecting tokens for  reactivity\n",
      "indices:    {4226, 33218, 4228, 33194, 33227, 33196, 33198, 4239, 4208, 33201, 33234, 4240, 4247, 4248, 4249, 3163, 33214}\n",
      "dict_items([(\"Lemma('responsiveness.n.01.reactivity')\", 8), (\"Lemma('reactivity.n.02.reactivity')\", 1)])\n",
      "collecting tokens for  leads\n",
      "indices:    {4244, 4248, 15906, 15907, 29347, 17580, 4781, 11056, 14642, 27191, 4668, 27069, 26177, 32455, 1487, 27348, 4693, 15445, 26594, 355, 12007, 3695, 26235}\n",
      "dict_items([(\"Lemma('run.v.03.lead')\", 2), (\"Lemma('leave.v.07.lead')\", 6), (\"Lemma('lead.v.01.lead')\", 3), (\"Lemma('conduct.v.02.lead')\", 1), (\"Lemma('lead.v.04.lead')\", 3), (\"Lemma('run.v.23.lead')\", 1), (\"Lemma('go.v.25.lead')\", 3), (\"Lemma('lead.v.05.lead')\", 1)])\n",
      "collecting tokens for  autonomic\n",
      "indices:    {4226, 4228, 4271, 4274, 4242, 4243, 4277, 4279, 4248, 4249, 4253}\n",
      "dict_items([(\"Lemma('autonomic.s.01.autonomic')\", 11)])\n",
      "collecting tokens for  stimulus\n",
      "indices:    {24065, 32036, 14438, 4264, 22729, 14443, 13645, 16018, 4248, 24634, 16219, 4253, 25503}\n",
      "dict_items([(\"Lemma('stimulation.n.02.stimulus')\", 6)])\n",
      "collecting tokens for  shift\n",
      "indices:    {2432, 5249, 32002, 4231, 4234, 4238, 4239, 4243, 12696, 31002, 4253, 1197, 33205, 33080, 3133, 13636, 11845, 32586, 22606, 7119, 31184, 3045, 11750, 31077, 30186, 32875, 27883, 7542, 8573}\n",
      "dict_items([(\"Lemma('transfer.v.04.shift')\", 2), (\"Lemma('shift.n.03.shift')\", 2), (\"Lemma('shift.n.01.shift')\", 5), (\"Lemma('switch.v.04.shift')\", 2), (\"Lemma('shift.v.02.shift')\", 5), (\"Lemma('transformation.n.01.shift')\", 3), (\"Lemma('switch.n.07.shift')\", 2), (\"Lemma('shift.v.05.shift')\", 1)])\n",
      "collecting tokens for  calendars\n",
      "indices:    {32544, 32582, 32615, 32586, 32620, 32622, 32592, 34865, 32603, 32574}\n",
      "dict_items([])\n",
      "collecting tokens for  subjected\n",
      "indices:    {2497, 27331, 11046, 3559, 7336, 16425, 26858, 16427, 24844, 3022, 15279, 25940, 11605, 85, 37108, 20635, 3581}\n",
      "dict_items([(\"Lemma('subject.v.02.subject')\", 4), (\"Lemma('subject.v.01.subject')\", 10)])\n",
      "collecting tokens for  afford\n",
      "indices:    {34946, 14220, 11788, 19482, 11935, 30112, 1323, 2350, 33838, 1328, 25652, 24887, 29248, 30917, 35025, 5977, 19166, 35682, 21990, 20201, 15209, 23532, 9455, 32241, 22648, 4601}\n",
      "dict_items([(\"Lemma('afford.v.01.afford')\", 24), (\"Lemma('yield.v.01.afford')\", 2)])\n",
      "collecting tokens for  push\n",
      "indices:    {672, 1985, 31261, 5411, 6309, 12294, 2686, 30430, 29053, 17969, 25621, 2581, 19129, 4635, 17660, 1981, 34174}\n",
      "dict_items([(\"Lemma('push.n.01.push')\", 1), (\"Lemma('push.v.01.push')\", 10), (\"Lemma('tug.v.02.push')\", 1), (\"Lemma('advertise.v.02.push')\", 1), (\"Lemma('push.v.02.push')\", 2), (\"Lemma('push.n.02.push')\", 1)])\n",
      "collecting tokens for  buttons\n",
      "indices:    {17540, 31334, 31306, 714, 30676, 30681, 31261, 19550}\n",
      "dict_items([(\"Lemma('push_button.n.01.button')\", 1), (\"Lemma('button.n.01.button')\", 2)])\n",
      "collecting tokens for  happening\n",
      "indices:    {23488, 7968, 33219, 23397, 4840, 30824, 8014, 2575, 8911, 16975, 18068, 26900, 18006, 12886, 27482, 18075, 26206}\n",
      "dict_items([(\"Lemma('happen.v.01.happen')\", 16), (\"Lemma('happening.n.01.happening')\", 1)])\n",
      "collecting tokens for  dose\n",
      "indices:    {25379, 11591, 26858, 3468, 16655, 11604, 3413, 4022, 34552}\n",
      "dict_items([(\"Lemma('dose.n.01.dose')\", 3), (\"Lemma('dose.n.02.dose')\", 2)])\n",
      "collecting tokens for  knock\n",
      "indices:    {28292, 9382, 23834, 662, 18454, 34552, 9366, 5914, 12572, 28286}\n",
      "dict_items([(\"Lemma('knock.n.01.knock')\", 2), (\"Lemma('knock.v.02.knock')\", 2), (\"Lemma('knock.v.01.knock')\", 1), (\"Lemma('knock_out.v.01.knock_out')\", 1), (\"Lemma('knock.n.02.knock')\", 1)])\n",
      "collecting tokens for  slowed\n",
      "indices:    {30370, 18823, 332, 23341, 17042, 6356, 34591, 27067, 36828, 20575}\n",
      "dict_items([(\"Lemma('slow.v.02.slow')\", 2), (\"Lemma('slow.v.03.slow')\", 1), (\"Lemma('decelerate.v.01.slow')\", 5)])\n",
      "collecting tokens for  vegetable\n",
      "indices:    {992, 1156, 34665, 5547, 36432, 27250, 27251, 30418}\n",
      "dict_items([(\"Lemma('vegetable.n.01.vegetable')\", 2)])\n",
      "collecting tokens for  grocery\n",
      "indices:    {28711, 27176, 5452, 20341, 11163}\n",
      "dict_items([(\"Lemma('grocery_store.n.01.grocery')\", 1)])\n",
      "collecting tokens for  shopping\n",
      "indices:    {7331, 21547, 14444, 25009, 21205, 5527, 7548, 5468, 20346, 16571, 20732, 5469, 25247}\n",
      "dict_items([(\"Lemma('shopping.n.01.shopping')\", 4), (\"Lemma('shop.v.01.shop')\", 1)])\n",
      "collecting tokens for  created\n",
      "indices:    {27651, 24838, 23559, 2312, 26892, 2318, 2320, 26772, 2454, 1053, 20765, 5407, 21920, 30750, 4765, 30751, 14884, 28196, 36125, 15906, 14889, 5547, 31660, 25137, 22068, 23094, 1463, 1464, 1465, 23997, 35262, 11327, 1469, 18242, 1475, 26822, 1480, 26826, 1483, 28240, 9680, 28636, 25564, 28638, 26078, 37090, 1507, 31973, 870, 31975, 1768, 22632, 31974, 14187, 1515, 5358, 2415, 27761, 5489, 31989, 5371, 3455}\n",
      "dict_items([(\"Lemma('make.v.03.create')\", 26), (\"Lemma('create.v.02.create')\", 26), (\"Lemma('create.v.03.create')\", 2)])\n",
      "collecting tokens for  suspended\n",
      "indices:    {23173, 3590, 10259, 10266, 5547, 5550, 5555, 5556, 5557, 5559, 35644, 3010, 3525, 3022, 11090, 3027, 3542, 3415, 12252, 2280, 243, 32764}\n",
      "dict_items([(\"Lemma('suspend.v.02.suspend')\", 4), (\"Lemma('suspended.s.01.suspended')\", 6), (\"Lemma('suspend.v.01.suspend')\", 5), (\"Lemma('suspend.v.03.suspend')\", 2), (\"Lemma('freeze.v.05.suspend')\", 2)])\n",
      "collecting tokens for  stream\n",
      "indices:    {34944, 11270, 20619, 6028, 3340, 23699, 2198, 31528, 2345, 557, 5046, 5047, 5818, 5821, 14397, 1856, 10435, 1861, 1864, 3550, 11234, 2149, 1893, 9585, 13555, 3960, 22911}\n",
      "dict_items([(\"Lemma('stream.n.01.stream')\", 13), (\"Lemma('stream.n.02.stream')\", 2), (\"Lemma('flow.n.03.stream')\", 2), (\"Lemma('current.n.02.stream')\", 2), (\"Lemma('pour.v.02.stream')\", 1)])\n",
      "collecting tokens for  fishing\n",
      "indices:    {1872, 11908, 11862}\n",
      "dict_items([(\"Lemma('fishing.n.01.fishing')\", 2)])\n",
      "collecting tokens for  arkansas\n",
      "indices:    {22742}\n",
      "dict_items([])\n",
      "collecting tokens for  promptly\n",
      "indices:    {9184, 23622, 10729, 23274, 29177, 34456, 17337, 2716}\n",
      "dict_items([(\"Lemma('promptly.r.01.promptly')\", 2), (\"Lemma('promptly.r.03.promptly')\", 1), (\"Lemma('promptly.r.02.promptly')\", 1)])\n",
      "collecting tokens for  hills\n",
      "indices:    {7713, 21927}\n",
      "dict_items([])\n",
      "collecting tokens for  climate\n",
      "indices:    {20231, 19340, 22932, 36122, 20509, 23199, 1824, 34865, 11189, 11325, 11710, 30403, 22852, 22618, 36571, 22620, 32487, 11624, 26986, 18685}\n",
      "dict_items([(\"Lemma('climate.n.02.climate')\", 3), (\"Lemma('climate.n.01.climate')\", 4)])\n",
      "collecting tokens for  compensation\n",
      "indices:    {31745, 4675, 22724, 22725, 14859, 17, 16312, 15609, 24029, 11710}\n",
      "dict_items([(\"Lemma('compensation.n.01.compensation')\", 5)])\n",
      "collecting tokens for  fortune\n",
      "indices:    {19425, 37115, 31756, 35311}\n",
      "dict_items([(\"Lemma('luck.n.02.fortune')\", 1)])\n",
      "collecting tokens for  amended\n",
      "indices:    {14720, 15553, 15009, 32515, 16236, 34706, 2741, 15543, 15546, 123, 14749, 2779}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('better.v.02.amend')\", 2), (\"Lemma('amend.v.01.amend')\", 5), (\"Lemma('amended.a.01.amended')\", 2)])\n",
      "collecting tokens for  corners\n",
      "indices:    {10785, 28801, 4569, 35695, 4495, 1117, 4564, 11421, 25846, 4953, 13561, 29624, 16796, 19517}\n",
      "dict_items([(\"Lemma('corner.n.02.corner')\", 3), (\"Lemma('corner.n.05.corner')\", 2), (\"Lemma('corner.n.01.corner')\", 3), (\"Lemma('corner.n.03.corner')\", 1)])\n",
      "collecting tokens for  doorway\n",
      "indices:    {17667, 19527, 7497, 8430, 8847, 34896, 17680, 7738, 17690, 19517}\n",
      "dict_items([(\"Lemma('doorway.n.01.doorway')\", 9)])\n",
      "collecting tokens for  daring\n",
      "indices:    {27299, 27303, 2605, 23375, 27282, 23091, 2389, 27350, 36917, 19517}\n",
      "dict_items([(\"Lemma('make_bold.v.01.dare')\", 1), (\"Lemma('boldness.n.01.daring')\", 1), (\"Lemma('dare.v.02.dare')\", 1), (\"Lemma('defy.v.03.dare')\", 2)])\n",
      "collecting tokens for  shirt\n",
      "indices:    {19683, 35107, 9719, 19527, 35274, 35819, 35660, 36685, 13422, 17866, 18476, 19538, 7475, 34260, 35927, 35928, 19517, 19550}\n",
      "dict_items([(\"Lemma('shirt.n.01.shirt')\", 8)])\n",
      "collecting tokens for  revolver\n",
      "indices:    {34948, 29060, 29066, 29071, 29072, 29073, 19517, 17754, 2427, 18205}\n",
      "dict_items([(\"Lemma('revolver.n.01.revolver')\", 4)])\n",
      "collecting tokens for  towards\n",
      "indices:    {10881, 12675, 9222, 9351, 6282, 3212, 9357, 10257, 10900, 9365, 8216, 9386, 31917, 19885, 16815, 19886, 20785, 2614, 16183, 26550, 2873, 1471, 16835, 34515, 2900, 25813, 26333, 27127, 2937, 25339}\n",
      "dict_items([])\n",
      "collecting tokens for  aqueous\n",
      "indices:    {3208, 3272, 3209, 3273, 3212, 3437, 3214, 3274, 3216, 3219, 3092, 3222, 3159, 3098}\n",
      "dict_items([(\"Lemma('aqueous.a.01.aqueous')\", 14)])\n",
      "collecting tokens for  continuous\n",
      "indices:    {14593, 4515, 11588, 24774, 11590, 14632, 15511, 4537}\n",
      "dict_items([(\"Lemma('continuous.a.01.continuous')\", 5), (\"Lemma('continuous.a.02.continuous')\", 2)])\n",
      "collecting tokens for  rector\n",
      "indices:    {8295}\n",
      "dict_items([(\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  irony\n",
      "indices:    {14112, 31235, 14410, 1263, 2672, 10832, 8444, 6782}\n",
      "dict_items([(\"Lemma('sarcasm.n.01.irony')\", 5), (\"Lemma('irony.n.02.irony')\", 2)])\n",
      "collecting tokens for  publicly\n",
      "indices:    {21824, 18241, 12675, 37094, 1895, 23951, 2546, 25971, 37138, 25752, 5275}\n",
      "dict_items([(\"Lemma('publicly.r.01.publicly')\", 5)])\n",
      "collecting tokens for  letters\n",
      "indices:    {12546, 17859, 32489, 12586, 9580, 9583, 8816, 12595, 12564, 7030, 14455, 25944, 21946, 12574}\n",
      "dict_items([(\"Lemma('letter.n.01.letter')\", 10), (\"Lemma('letter.n.02.letter')\", 1)])\n",
      "collecting tokens for  ministers\n",
      "indices:    {23680, 28025, 28067}\n",
      "dict_items([])\n",
      "collecting tokens for  bushes\n",
      "indices:    {36064, 11297, 36004, 7807, 36019, 20029, 36415}\n",
      "dict_items([(\"Lemma('shrub.n.01.bush')\", 2), (\"Lemma('scrub.n.01.bush')\", 1)])\n",
      "collecting tokens for  roast\n",
      "indices:    {29447, 29163, 37039, 29170, 9301, 29528, 36990}\n",
      "dict_items([(\"Lemma('roast.v.01.roast')\", 2)])\n",
      "collecting tokens for  mound\n",
      "indices:    {19864, 21362, 19884}\n",
      "dict_items([(\"Lemma('mound.n.01.mound')\", 2)])\n",
      "collecting tokens for  mays\n",
      "indices:    {437}\n",
      "dict_items([(\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  grass\n",
      "indices:    {13568, 34945, 35587, 23696, 35859, 8341, 28318, 30648, 35513, 34626, 197, 7369, 10449, 18002, 5843, 6240, 10468, 36327, 14063, 35577, 35198}\n",
      "dict_items([(\"Lemma('grass.n.01.grass')\", 10)])\n",
      "collecting tokens for  rookie\n",
      "indices:    {233, 34511, 24468, 187, 223}\n",
      "dict_items([(\"Lemma('cub.n.01.rookie')\", 3)])\n",
      "collecting tokens for  rushed\n",
      "indices:    {27269, 36884, 23840, 19363, 19364, 19366, 19240, 683, 19887, 30384, 27058, 30387, 31415, 10946, 5060, 35277, 22873, 5096, 32628, 24315}\n",
      "dict_items([(\"Lemma('rush.v.03.rush')\", 1), (\"Lemma('rush.v.02.rush')\", 4), (\"Lemma('rush.v.01.rush')\", 10), (\"Lemma('rush.v.04.rush')\", 1)])\n",
      "collecting tokens for  pennant\n",
      "indices:    {683, 23019, 460, 627, 181, 24506, 24475, 24510}\n",
      "dict_items([(\"Lemma('pennant.n.01.pennant')\", 4)])\n",
      "collecting tokens for  tyranny\n",
      "indices:    {26115, 11208, 13710, 28398, 25720, 36411, 14654}\n",
      "dict_items([(\"Lemma('dictatorship.n.01.tyranny')\", 3)])\n",
      "collecting tokens for  tires\n",
      "indices:    {22468, 32327, 33900, 23341, 19278, 23340, 21204, 19284, 19190, 18842}\n",
      "dict_items([(\"Lemma('tire.n.01.tire')\", 4)])\n",
      "collecting tokens for  decisions\n",
      "indices:    {27145, 32137, 21899, 23956, 15392, 1568, 27810, 20262, 15530, 22826, 8235, 15789, 16432, 26035, 20153, 28601, 32187, 26190, 22736, 32978, 31190, 24156, 14052, 27876, 12281}\n",
      "dict_items([(\"Lemma('decision.n.01.decision')\", 4), (\"Lemma('decision.n.02.decision')\", 2), (\"Lemma('decision.n.04.decision')\", 1)])\n",
      "collecting tokens for  batting\n",
      "indices:    {608, 226, 10147, 605, 198, 15751, 19949, 398, 19951, 24689, 23090, 439, 24508, 24509}\n",
      "dict_items([(\"Lemma('batting.n.01.batting')\", 2), (\"Lemma('bat.v.01.bat')\", 4), (\"Lemma('bat.v.02.bat')\", 2)])\n",
      "collecting tokens for  competitive\n",
      "indices:    {16396, 15504, 15510, 11672, 23459, 2730, 15531, 23480, 11511, 21822, 5445, 14919, 14925, 14928, 28900, 11620, 11623, 11624, 22764, 28533, 15221, 11639}\n",
      "dict_items([(\"Lemma('competitive.a.01.competitive')\", 11), (\"Lemma('competitive.s.02.competitive')\", 4)])\n",
      "collecting tokens for  muscles\n",
      "indices:    {17924, 1544, 4107, 11411, 4123, 33435, 1568, 1582, 1585, 34746, 30784, 30786, 30790, 30792, 2001, 30811, 731, 22764, 19181, 1518, 1524, 1528}\n",
      "dict_items([(\"Lemma('muscle.n.01.muscle')\", 13), (\"Lemma('muscle.n.02.muscle')\", 1)])\n",
      "collecting tokens for  survivors\n",
      "indices:    {21474, 2279, 35639}\n",
      "dict_items([(\"Lemma('survivor.n.02.survivor')\", 1)])\n",
      "collecting tokens for  wearing\n",
      "indices:    {9349, 22153, 17929, 9596, 24985, 11162, 37032, 37033, 18987, 13996, 36142, 7475, 31027, 30909, 37053, 25666, 16964, 9158, 7882, 36683, 7370, 9680, 35927, 19550, 19681, 9700, 29040, 31478, 7672, 23804, 35710}\n",
      "dict_items([(\"Lemma('wear.v.01.wear')\", 23), (\"Lemma('wear.v.02.wear')\", 6), (\"Lemma('wear.v.05.wear')\", 1)])\n",
      "collecting tokens for  player\n",
      "indices:    {10592, 22930, 640}\n",
      "dict_items([(\"Lemma('player.n.01.player')\", 1), (\"Lemma('musician.n.01.player')\", 1)])\n",
      "collecting tokens for  gap\n",
      "indices:    {35225}\n",
      "dict_items([])\n",
      "collecting tokens for  clearer\n",
      "indices:    {24768, 27780, 24166, 1771, 33101, 24622, 15888, 34544, 24752, 28853, 23993, 9660, 7836, 23999}\n",
      "dict_items([(\"Lemma('clear.a.01.clear')\", 4)])\n",
      "collecting tokens for  sphere\n",
      "indices:    {837, 35653, 10585, 4625, 26833, 3570, 26835, 1365, 26834, 3545, 3546, 12029, 10846, 3359}\n",
      "dict_items([(\"Lemma('sphere.n.03.sphere')\", 2), (\"Lemma('sector.n.03.sphere')\", 1), (\"Lemma('sphere.n.01.sphere')\", 4), (\"Lemma('sphere.n.02.sphere')\", 3)])\n",
      "collecting tokens for  fewer\n",
      "indices:    {16260, 11655, 20242, 30099, 1941, 30104, 31129, 30233, 25247, 11680, 799, 27051, 16695, 23993, 1726, 27075, 23236, 25156, 26183, 16077, 28755, 23001, 26080, 1397, 12029}\n",
      "dict_items([(\"Lemma('fewer.a.01.fewer')\", 10)])\n",
      "collecting tokens for  sexual\n",
      "indices:    {31495, 12041, 12046, 12307, 3732, 12051, 32027, 33179, 12064, 32036, 12069, 32037, 32039, 32041, 32047, 3762, 32055, 32056, 32057, 11967, 11968, 11979, 11980, 11991, 11992, 32088, 30823, 32105, 28010, 32110, 30833, 10098, 4211, 12022}\n",
      "dict_items([(\"Lemma('sexual.a.02.sexual')\", 1), (\"Lemma('sexual.a.01.sexual')\", 9)])\n",
      "collecting tokens for  historical\n",
      "indices:    {32742, 14663, 14153, 16426, 26187, 26190, 12206, 11248, 29266, 1043, 14708, 1878, 16408, 26969, 23195, 2303}\n",
      "dict_items([(\"Lemma('historical.a.01.historical')\", 5), (\"Lemma('historical.s.02.historical')\", 2), (\"Lemma('historic.s.01.historical')\", 1)])\n",
      "collecting tokens for  enjoy\n",
      "indices:    {30723, 24196, 25735, 2568, 20621, 21017, 24732, 27037, 10657, 20774, 32685, 11953, 29240, 36541, 1853, 14661, 25157, 31820, 19277, 31571, 24539, 28638, 24544, 1251, 22508, 9199, 23156, 11900}\n",
      "dict_items([(\"Lemma('delight.v.02.enjoy')\", 3), (\"Lemma('enjoy.v.01.enjoy')\", 18), (\"Lemma('enjoy.v.02.enjoy')\", 4), (\"Lemma('love.v.02.enjoy')\", 2), (\"Lemma('enjoy.v.04.enjoy')\", 1)])\n",
      "collecting tokens for  possibility\n",
      "indices:    {34561, 16898, 2566, 34569, 22670, 25870, 35984, 33169, 4754, 25747, 23961, 16411, 27807, 20256, 672, 30078, 2595, 22692, 3493, 27814, 27815, 22568, 25763, 22564, 12331, 17319, 32429, 15279, 25395, 16819, 16311, 4919, 35641, 32826, 14651, 15164, 1084, 15678, 4666, 25399, 23614, 4539, 14144, 32965, 32839, 32967, 35017, 5319, 1357, 1359, 31954, 14040, 22745, 22618, 22624, 11745, 22883, 25445, 3818, 5484, 16380, 14957, 25839, 2799, 21750, 12921, 3834, 3068, 31102}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('possibility.n.02.possibility')\", 13), (\"Lemma('hypothesis.n.02.possibility')\", 8), (\"Lemma('possibility.n.01.possibility')\", 8), (\"Lemma('possibility.n.04.possibility')\", 4)])\n",
      "collecting tokens for  bound\n",
      "indices:    {35330, 25479, 2441, 10252, 15376, 35473, 12954, 6428, 32413, 3360, 37025, 11683, 22951, 21544, 35760, 14651, 31932, 27972, 21319, 4042, 14414, 1494, 3932, 16224, 29671, 12010, 33259, 10094, 13294, 23536, 14449, 13559}\n",
      "dict_items([(\"Lemma('bind.v.03.bind')\", 2), (\"Lemma('bound.a.01.bound')\", 4), (\"Lemma('bound.a.02.bound')\", 3), (\"Lemma('tie_down.v.01.bind')\", 1), (\"Lemma('bind.v.02.bind')\", 1), (\"Lemma('boundary.n.02.bound')\", 1), (\"Lemma('bound.s.06.bound')\", 1), (\"Lemma('bound.a.03.bound')\", 2), (\"Lemma('restrict.v.03.bound')\", 2), (\"Lemma('bound.s.04.bound')\", 2), (\"Lemma('oblige.v.02.bind')\", 1), (\"Lemma('adhere.v.06.bind')\", 1)])\n",
      "collecting tokens for  promised\n",
      "indices:    {25728, 24196, 19078, 36999, 32009, 34451, 21757, 36507, 7595, 8636, 18243, 4675, 6781, 24005, 12365, 1488, 86, 24666, 27358, 20448, 5092, 27365, 34281, 28413, 24683, 20469, 9206, 8441, 893}\n",
      "dict_items([(\"Lemma('promise.v.01.promise')\", 17), (\"Lemma('promise.v.02.promise')\", 8), (\"Lemma('predict.v.01.promise')\", 2), (\"Lemma('promise.v.04.promise')\", 1)])\n",
      "collecting tokens for  sampling\n",
      "indices:    {32889, 33089, 33090, 33092, 33093, 3430, 33062, 33033, 15661, 3405, 33071, 33074, 37139, 3444, 33080, 3449, 33083, 3454}\n",
      "dict_items([(\"Lemma('sampling.n.01.sampling')\", 4), (\"Lemma('sample.v.01.sample')\", 1)])\n",
      "collecting tokens for  ratios\n",
      "indices:    {33028, 33030, 16167, 16168, 29894, 16172, 33074, 21819}\n",
      "dict_items([(\"Lemma('ratio.n.01.ratio')\", 3)])\n",
      "collecting tokens for  afraid\n",
      "indices:    {19467, 1808, 5776, 2578, 27411, 27287, 6935, 12572, 23070, 16031, 7073, 17700, 34213, 6822, 33703, 24881, 35894, 27456, 6467, 27460, 6469, 6473, 23501, 19665, 5970, 27355, 27488, 2024, 9193, 6124, 25327, 33263, 8821, 20470, 25338}\n",
      "dict_items([(\"Lemma('afraid.a.01.afraid')\", 15), (\"Lemma('afraid.s.03.afraid')\", 1), (\"Lemma('afraid.s.02.afraid')\", 3)])\n",
      "collecting tokens for  feared\n",
      "indices:    {12196, 6443, 31692, 17500, 2579, 86, 27862, 14332, 26399}\n",
      "dict_items([(\"Lemma('fear.v.02.fear')\", 4), (\"Lemma('fear.v.01.fear')\", 5)])\n",
      "collecting tokens for  sloan\n",
      "indices:    {26761}\n",
      "dict_items([])\n",
      "collecting tokens for  thereby\n",
      "indices:    {24451, 2955, 14736, 21266, 12306, 26772, 32664, 21273, 11810, 31907, 29989, 4778, 13999, 14002, 564, 2752, 15044, 32968, 24778, 24907, 5461, 12256, 22887, 3691, 11500, 17646, 26230, 24829}\n",
      "dict_items([(\"Lemma('thereby.r.01.thereby')\", 15)])\n",
      "collecting tokens for  paintings\n",
      "indices:    {27014, 26762, 22540, 26765, 22543, 7442, 26771, 26776, 5405, 37031, 31912, 31664, 961, 962, 26946, 19530, 19537, 23136, 23139, 25711, 21105, 25714, 25718, 19582}\n",
      "dict_items([(\"Lemma('painting.n.01.painting')\", 6)])\n",
      "collecting tokens for  saloon\n",
      "indices:    {7683, 12807, 35881, 35244, 18516, 37175}\n",
      "dict_items([(\"Lemma('barroom.n.01.saloon')\", 1), (\"Lemma('public_house.n.01.saloon')\", 1)])\n",
      "collecting tokens for  jesus\n",
      "indices:    {28039}\n",
      "dict_items([])\n",
      "collecting tokens for  thee\n",
      "indices:    {28231, 7207, 28233, 28202, 28179, 28028}\n",
      "dict_items([])\n",
      "collecting tokens for  poet\n",
      "indices:    {13824, 31874, 27023, 8467, 5012, 22548, 27031, 28063, 14624, 32050, 14137, 26556, 26303, 2370, 26182, 13786, 32092, 31588, 8432, 13809, 10097, 754, 32119}\n",
      "dict_items([(\"Lemma('poet.n.01.poet')\", 10)])\n",
      "collecting tokens for  sentimental\n",
      "indices:    {30208, 26081, 36320, 10788, 26628, 25997, 12952, 35322, 26556}\n",
      "dict_items([(\"Lemma('bathetic.s.01.sentimental')\", 1), (\"Lemma('sentimental.s.01.sentimental')\", 1)])\n",
      "collecting tokens for  unusual\n",
      "indices:    {31648, 3758, 35727, 28079, 9392, 12599, 36155, 29116, 22782}\n",
      "dict_items([(\"Lemma('unusual.a.01.unusual')\", 3)])\n",
      "collecting tokens for  vivid\n",
      "indices:    {5241, 5378, 5369, 26213, 37032, 14601, 13643, 14283, 13807, 26991, 6523, 33236, 13653, 22103, 2137, 13851, 26556}\n",
      "dict_items([(\"Lemma('graphic.s.05.vivid')\", 8), (\"Lemma('vivid.s.02.vivid')\", 2)])\n",
      "collecting tokens for  stretching\n",
      "indices:    {18913, 17602, 3715, 32167, 26951, 32174, 22512, 7217, 8885, 27001, 31035, 17244, 7133}\n",
      "dict_items([(\"Lemma('elongate.v.01.stretch')\", 1), (\"Lemma('stretch.v.02.stretch')\", 3), (\"Lemma('stretch.v.04.stretch')\", 1), (\"Lemma('stretch.v.01.stretch')\", 4), (\"Lemma('stretching.n.01.stretching')\", 1), (\"Lemma('unfold.v.03.stretch')\", 1)])\n",
      "collecting tokens for  seriously\n",
      "indices:    {12933, 28552, 10890, 10892, 25488, 21524, 25750, 29978, 17179, 4638, 2089, 21170, 13621, 31673, 11195, 11197, 12871, 30280, 22347, 6096, 14168, 30808, 16090, 5211, 26840, 5598, 18913, 30306, 25446, 12016, 22769, 14064}\n",
      "dict_items([(\"Lemma('seriously.r.01.seriously')\", 16), (\"Lemma('badly.r.01.seriously')\", 2)])\n",
      "collecting tokens for  correspondent\n",
      "indices:    {7333, 14184, 5131, 20267, 9584, 26104, 24217, 24220}\n",
      "dict_items([(\"Lemma('correspondent.n.01.correspondent')\", 2), (\"Lemma('correspondent.n.02.correspondent')\", 2)])\n",
      "collecting tokens for  dash\n",
      "indices:    {29536, 28661}\n",
      "dict_items([])\n",
      "collecting tokens for  wit\n",
      "indices:    {26624, 26503, 14280, 34920, 9584, 10736, 26354, 26224, 26323, 10741, 15761, 14553, 24794, 10651, 924, 26333}\n",
      "dict_items([(\"Lemma('wit.n.01.wit')\", 8)])\n",
      "collecting tokens for  books\n",
      "indices:    {14593, 1125, 15207, 36744, 28137, 27528, 33160, 28362, 21009, 23577, 30718, 26015}\n",
      "dict_items([(\"Lemma('book.n.02.book')\", 1), (\"Lemma('book.n.01.book')\", 1)])\n",
      "collecting tokens for  recommended\n",
      "indices:    {15490, 5, 26118, 23557, 10, 21643, 15501, 28177, 32401, 20, 22, 28699, 4129, 29861, 4774, 11559, 11561, 29868, 1967, 24241, 5945, 30779, 11590, 29895, 20557, 21204, 11734, 15326, 15211, 20206, 9584, 17393, 15089, 2039}\n",
      "dict_items([(\"Lemma('recommend.v.01.recommend')\", 26), (\"Lemma('commend.v.04.recommend')\", 2)])\n",
      "collecting tokens for  enrolled\n",
      "indices:    {33122, 33155, 28070, 9584, 16247, 15771, 13277, 12639}\n",
      "dict_items([(\"Lemma('enroll.v.01.enroll')\", 2), (\"Lemma('enroll.v.01.enrol')\", 3)])\n",
      "collecting tokens for  worship\n",
      "indices:    {27650, 27651, 28164, 25354, 9997, 14105, 23198, 6046, 24740, 19622, 13359, 26551, 6971, 14275, 4678, 13384, 4685, 6098, 27476, 13142, 22371, 4708, 11495}\n",
      "dict_items([(\"Lemma('worship.n.01.worship')\", 12), (\"Lemma('worship.v.03.worship')\", 1), (\"Lemma('idolize.v.01.worship')\", 2), (\"Lemma('worship.v.02.worship')\", 1)])\n",
      "collecting tokens for  boundary\n",
      "indices:    {32996, 32998, 33001, 33004, 28686, 5423, 13584, 5422, 858}\n",
      "dict_items([(\"Lemma('boundary.n.01.boundary')\", 3), (\"Lemma('boundary.n.02.boundary')\", 1)])\n",
      "collecting tokens for  jerked\n",
      "indices:    {18624, 35619, 19335, 35242, 18988, 34031, 5103, 35577, 34967, 36472, 12665}\n",
      "dict_items([(\"Lemma('yank.v.01.jerk')\", 7), (\"Lemma('jerk.v.02.jerk')\", 3), (\"Lemma('twitch.v.01.jerk')\", 1)])\n",
      "collecting tokens for  identical\n",
      "indices:    {2697, 2188, 1295, 17306, 15898, 15900, 20774, 16174, 5295, 4400, 16177, 16189, 15937, 4420, 33095, 15945, 3660, 3279, 2132, 29913, 4707, 32621, 16369, 10105, 22143}\n",
      "dict_items([(\"Lemma('identical.s.02.identical')\", 9), (\"Lemma('identical.s.01.identical')\", 11)])\n",
      "collecting tokens for  weather\n",
      "indices:    {36196, 11268, 19335, 26393, 24028, 30110}\n",
      "dict_items([(\"Lemma('upwind.s.01.weather')\", 1), (\"Lemma('weather.n.01.weather')\", 1)])\n",
      "collecting tokens for  dependent\n",
      "indices:    {32395, 2956, 15632, 16402, 21526, 2341, 24230, 169, 3882, 12978, 32579, 28484, 4683, 16461, 25806, 15960, 13922, 14820, 25327, 33521, 24178, 3834, 12027}\n",
      "dict_items([(\"Lemma('dependent.a.01.dependent')\", 8), (\"Lemma('dependent.s.02.dependent')\", 2), (\"Lemma('dependant.n.01.dependent')\", 1)])\n",
      "collecting tokens for  multiplying\n",
      "indices:    {28930, 28906, 28907, 23563, 2989, 27537, 28882, 4438}\n",
      "dict_items([(\"Lemma('multiply.v.01.multiply')\", 7), (\"Lemma('multiply.v.02.multiply')\", 1)])\n",
      "collecting tokens for  engine\n",
      "indices:    {18692, 18699, 18828, 6411, 18830, 28701, 18855, 30506, 15539, 33730, 9163, 30540, 28505, 27102, 28900, 28902, 28905, 18800, 4725, 28663, 28667}\n",
      "dict_items([(\"Lemma('engine.n.01.engine')\", 7), (\"Lemma('engine.n.02.engine')\", 1), (\"Lemma('locomotive.n.01.engine')\", 1)])\n",
      "collecting tokens for  fats\n",
      "indices:    {27233, 27239, 27244, 27250, 3187, 27251, 27252, 27254, 27255, 27256}\n",
      "dict_items([(\"Lemma('fat.n.01.fat')\", 1)])\n",
      "collecting tokens for  leading\n",
      "indices:    {17504, 24776, 26473, 22736, 18672, 81, 37117, 32447}\n",
      "dict_items([(\"Lemma('lead_up.v.01.lead_up')\", 1), (\"Lemma('lead.v.01.lead')\", 2), (\"Lemma('lead.v.04.lead')\", 1)])\n",
      "collecting tokens for  weapons\n",
      "indices:    {903, 12938, 15509, 15511, 28440, 5788, 28447, 28448, 26528, 28449, 3494, 28456, 25384, 28458, 2604, 33838, 24111, 25264, 31278, 27443, 28468, 28469, 25782, 27831, 5309, 30274, 3394, 31301, 25159, 25160, 30281, 30283, 13003, 30285, 22624, 22625, 25442, 25446, 14957, 28526, 28529, 18674, 28531, 21749, 21750, 21751, 21752, 15484}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('weapon.n.01.weapon')\", 9)])\n",
      "collecting tokens for  constantly\n",
      "indices:    {35712, 26502, 31499, 5649, 13337, 6427, 30876, 1307, 18729, 20267, 32687, 10804, 20031, 27328, 4936, 23242, 26699, 26080, 9575, 32233, 32108, 1137, 12403, 21749, 13686, 25207, 4597, 33142}\n",
      "dict_items([(\"Lemma('constantly.r.01.constantly')\", 2), (\"Lemma('constantly.r.02.constantly')\", 1)])\n",
      "collecting tokens for  probable\n",
      "indices:    {12160, 2849, 223, 11235, 23811, 3751, 11630, 24143, 15438, 26195, 12180, 12181, 17398, 31800, 15450, 24796, 12765, 27807}\n",
      "dict_items([(\"Lemma('probable.a.01.probable')\", 10), (\"Lemma('probable.s.02.probable')\", 2)])\n",
      "collecting tokens for  eat\n",
      "indices:    {23217, 29463}\n",
      "dict_items([(\"Lemma('eat.v.02.eat')\", 1), (\"Lemma('eat.v.01.eat')\", 1)])\n",
      "collecting tokens for  nerves\n",
      "indices:    {17924, 34826, 2155, 17100, 36237, 559, 9359, 22902, 18522, 30110}\n",
      "dict_items([(\"Lemma('nervousness.n.02.nerves')\", 2), (\"Lemma('nerve.n.01.nerve')\", 4)])\n",
      "collecting tokens for  snapping\n",
      "indices:    {34531, 15461, 7110, 34343, 19154, 8921, 2235, 6685, 6559}\n",
      "dict_items([(\"Lemma('snap.v.05.snap')\", 1), (\"Lemma('snap.v.01.snap')\", 1), (\"Lemma('snap.v.04.snap')\", 1), (\"Lemma('snap.v.03.snap')\", 2), (\"Lemma('snatch.v.01.snap')\", 1), (\"Lemma('snap_up.v.01.snap_up')\", 1)])\n",
      "collecting tokens for  dust\n",
      "indices:    {6914, 26777, 18849, 13090, 35624, 13608, 1458, 17986, 18883, 17866, 17108, 19160, 9186, 31588, 6885, 19300, 34156, 2679, 3321, 3327}\n",
      "dict_items([(\"Lemma('dust.n.01.dust')\", 13), (\"Lemma('debris.n.01.dust')\", 2), (\"Lemma('dust.v.01.dust')\", 1)])\n",
      "collecting tokens for  lungs\n",
      "indices:    {3842, 3843, 3812, 4071, 4072, 6889, 3819, 9181, 19154, 36051, 3410, 3796, 34744, 17305, 9466, 3837, 17310}\n",
      "dict_items([(\"Lemma('lung.n.01.lung')\", 15)])\n",
      "collecting tokens for  aids\n",
      "indices:    {11579, 20150}\n",
      "dict_items([(\"Lemma('help.v.01.aid')\", 1)])\n",
      "collecting tokens for  flies\n",
      "indices:    {23301, 7910, 31499, 3599, 372, 8052, 22327}\n",
      "dict_items([(\"Lemma('fly.n.01.fly')\", 2), (\"Lemma('fly.v.02.fly')\", 1), (\"Lemma('fly.v.01.fly')\", 1), (\"Lemma('fly.v.05.fly')\", 1), (\"Lemma('fly.n.04.fly')\", 1)])\n",
      "collecting tokens for  preventing\n",
      "indices:    {31076, 32872, 27154, 11542, 11544, 27898, 11579, 33212, 14941, 11583}\n",
      "dict_items([(\"Lemma('prevent.v.01.prevent')\", 8), (\"Lemma('prevent.v.02.prevent')\", 2)])\n",
      "collecting tokens for  imperative\n",
      "indices:    {27457, 25506, 32070, 32904, 25386, 2029, 4919, 31966}\n",
      "dict_items([(\"Lemma('imperative.a.01.imperative')\", 2)])\n",
      "collecting tokens for  measuring\n",
      "indices:    {4096, 28934, 28941, 28945, 28946, 29588, 14777, 22974, 12757, 28887, 2913, 3174, 29670, 4072, 4073, 2930, 4083, 29942, 11382, 11386, 4095}\n",
      "dict_items([(\"Lemma('measure.v.03.measure')\", 6), (\"Lemma('measure.v.01.measure')\", 10), (\"Lemma('measurement.n.01.measuring')\", 1), (\"Lemma('quantify.v.02.measure')\", 2)])\n",
      "collecting tokens for  depth\n",
      "indices:    {5379, 5381, 28934, 29319, 5382, 5385, 5386, 5387, 1805, 5391, 5392, 5396, 29588, 5403, 12580, 24742, 2091, 12721, 14645, 26553, 28475, 1085, 11327, 13506, 1865, 13646, 12754, 29912, 29913, 27100, 5360, 5361, 32117, 5369, 2810, 5371, 5373, 5502}\n",
      "dict_items([(\"Lemma('depth.n.01.depth')\", 22), (\"Lemma('depth.n.02.depth')\", 6)])\n",
      "collecting tokens for  multiply\n",
      "indices:    {28915, 15023}\n",
      "dict_items([(\"Lemma('multiply.v.01.multiply')\", 2)])\n",
      "collecting tokens for  dropped\n",
      "indices:    {26496, 31489, 35973, 23047, 18440, 15752, 1167, 27920, 8600, 18841, 36121, 18715, 18586, 24219, 19870, 15769, 21660, 33695, 30365, 33700, 25765, 34983, 26492, 36779, 5931, 557, 34990, 814, 19884, 18348, 16690, 23346, 179, 11179, 8758, 25269, 22063, 14905, 25276, 18237, 10435, 19270, 36553, 9162, 26575, 9426, 2387, 217, 34522, 24030, 26976, 29155, 29668, 22247, 555, 30318, 31343, 15472, 369, 34291, 34036, 627, 35574, 18679, 36472, 18420, 35443, 18684, 33149}\n",
      "dict_items([(\"Lemma('drop.v.01.drop')\", 24), (\"Lemma('fell.v.01.drop')\", 1), (\"Lemma('drop.v.08.drop')\", 2), (\"Lemma('drop.v.05.drop')\", 3), (\"Lemma('drop.v.03.drop')\", 8), (\"Lemma('drop.v.07.drop')\", 3), (\"Lemma('drop.v.06.drop')\", 3), (\"Lemma('sink.v.01.drop')\", 3), (\"Lemma('drop.v.02.drop')\", 12), (\"Lemma('flatten.v.03.drop')\", 1), (\"Lemma('spend.v.02.drop')\", 1), (\"Lemma('drop.v.10.drop')\", 2)])\n",
      "collecting tokens for  hints\n",
      "indices:    {7337, 30796, 27533, 29046, 29049, 32026, 32092, 18237}\n",
      "dict_items([(\"Lemma('hint.n.01.hint')\", 1), (\"Lemma('hint.n.02.hint')\", 1), (\"Lemma('hint.v.01.hint')\", 1)])\n",
      "collecting tokens for  coordinated\n",
      "indices:    {32544, 14049, 32589, 4623, 32594, 13843, 14739, 32595, 28696, 32570, 1948, 32605, 33151}\n",
      "dict_items([(\"Lemma('organize.v.04.coordinate')\", 3), (\"Lemma('coordinated.s.01.coordinated')\", 1), (\"Lemma('coordinated.s.02.coordinated')\", 1), (\"Lemma('coordinate.v.02.coordinate')\", 1), (\"Lemma('align.v.04.coordinate')\", 1)])\n",
      "collecting tokens for  harvard\n",
      "indices:    {13223}\n",
      "dict_items([(\"Lemma('harvard_university.n.01.Harvard')\", 1)])\n",
      "collecting tokens for  publishing\n",
      "indices:    {21696, 20581, 28326, 24734, 16286}\n",
      "dict_items([(\"Lemma('print.v.01.publish')\", 1)])\n",
      "collecting tokens for  recognize\n",
      "indices:    {16396, 30585, 30746, 2590, 23969, 16422, 1447, 24106, 7343, 3642, 21437, 4926, 27456, 17601, 26948, 4935, 25288, 4938, 4940, 32591, 27728, 4946, 4948, 2133, 24794, 28123, 4956, 24795, 2144, 14689, 27875, 4582, 5351, 12268, 25081, 2033, 32883, 31989, 25974, 2296, 14713, 14714, 25339}\n",
      "dict_items([(\"Lemma('acknowledge.v.06.recognize')\", 12), (\"Lemma('spot.v.02.recognize')\", 14), (\"Lemma('recognize.v.02.recognize')\", 16), (\"Lemma('recognize.v.04.recognize')\", 1)])\n",
      "collecting tokens for  acknowledge\n",
      "indices:    {15842, 1285, 5478, 24968, 20650, 36240, 27824, 31519, 25974, 25087}\n",
      "dict_items([(\"Lemma('admit.v.01.acknowledge')\", 4), (\"Lemma('acknowledge.v.04.acknowledge')\", 1)])\n",
      "collecting tokens for  invited\n",
      "indices:    {27265, 27611, 24618, 27850, 9614, 9582, 16880, 23288, 28596, 13076, 25974, 24727, 22520, 15252, 28538, 15739, 21980}\n",
      "dict_items([(\"Lemma('invite.v.06.invite')\", 2), (\"Lemma('invite.v.01.invite')\", 2), (\"Lemma('invite.v.05.invite')\", 2), (\"Lemma('invite.v.02.invite')\", 5), (\"Lemma('invite.v.04.invite')\", 3), (\"Lemma('invite.v.07.invite')\", 1), (\"Lemma('tempt.v.03.invite')\", 2)])\n",
      "collecting tokens for  print\n",
      "indices:    {17859, 8293}\n",
      "dict_items([(\"Lemma('print.v.02.print')\", 1)])\n",
      "collecting tokens for  exception\n",
      "indices:    {26368, 28165, 22027, 13, 12561, 3606, 2838, 18201, 32538, 18202, 4640, 22433, 36, 25767, 14331, 16169, 31658, 16171, 5297, 14643, 29751, 14138, 14140, 3004, 8259, 9669, 28108, 27343, 3685, 11880, 32619, 13293, 29806, 27638, 12279, 14459}\n",
      "dict_items([(\"Lemma('exception.n.01.exception')\", 14), (\"Lemma('exception.n.02.exception')\", 8)])\n",
      "collecting tokens for  hino\n",
      "indices:    {8262}\n",
      "dict_items([(\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  repaired\n",
      "indices:    {8259, 6088, 22410, 9324, 6060, 22413, 20689, 23859, 17907, 6067}\n",
      "dict_items([(\"Lemma('repair.v.01.repair')\", 8)])\n",
      "collecting tokens for  proved\n",
      "indices:    {25601, 29957, 9349, 15239, 1033, 13068, 32013, 2192, 32017, 25492, 1173, 3094, 25495, 5143, 22941, 31774, 27304, 298, 26794, 2223, 1072, 14514, 21811, 24502, 26806, 36152, 14650, 4922, 186, 30528, 36674, 8259, 24643, 12232, 22345, 11211, 717, 12245, 8150, 26070, 14174, 16743, 28008, 32487, 33263, 11506, 1267, 2550, 22902, 29947, 894}\n",
      "dict_items([(\"Lemma('prove.v.01.prove')\", 26), (\"Lemma('prove.v.02.prove')\", 16), (\"Lemma('testify.v.02.prove')\", 1)])\n",
      "collecting tokens for  spreading\n",
      "indices:    {2306, 898, 8870, 5449, 24434, 36051, 10003, 29784, 35449, 16731, 6046, 23839}\n",
      "dict_items([(\"Lemma('go_around.v.02.spread')\", 1), (\"Lemma('spread.v.01.spread')\", 5), (\"Lemma('diffuse.v.01.spread')\", 1), (\"Lemma('spread.v.02.spread')\", 1)])\n",
      "collecting tokens for  steel\n",
      "indices:    {16323, 28841, 12809, 21899, 18937, 13040, 2899, 9145, 24700, 20671}\n",
      "dict_items([(\"Lemma('steel.n.01.steel')\", 5)])\n",
      "collecting tokens for  bands\n",
      "indices:    {26752, 19493, 5030, 3557, 5031, 3114, 31021, 36051, 1081}\n",
      "dict_items([(\"Lemma('dance_band.n.01.band')\", 1), (\"Lemma('band.n.04.band')\", 2), (\"Lemma('band.n.02.band')\", 1), (\"Lemma('band.n.03.band')\", 2)])\n",
      "collecting tokens for  tightly\n",
      "indices:    {1799, 3593, 6346, 36717, 15191, 36754, 36051, 29527, 22714, 9788, 36830, 17535}\n",
      "dict_items([(\"Lemma('tightly.r.01.tightly')\", 3), (\"Lemma('tightly.r.02.tightly')\", 1)])\n",
      "collecting tokens for  stuck\n",
      "indices:    {19718, 22472, 35113, 35114, 9900, 20080, 15825, 36051, 23188, 17589, 5887}\n",
      "dict_items([(\"Lemma('lodge.v.02.stick')\", 3), (\"Lemma('adhere.v.06.stick')\", 1), (\"Lemma('insert.v.02.stick_in')\", 1)])\n",
      "collecting tokens for  roof\n",
      "indices:    {17538, 15077, 35462, 15078, 6376, 30186, 29389, 26773, 18937, 9787}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('roof.n.02.roof')\", 1), (\"Lemma('roof.n.01.roof')\", 4)])\n",
      "collecting tokens for  rigid\n",
      "indices:    {36769, 14279, 31371, 36051, 2587, 12793, 11162, 4635, 5853, 28093}\n",
      "dict_items([(\"Lemma('rigid.s.02.rigid')\", 2), (\"Lemma('rigid.s.01.rigid')\", 2), (\"Lemma('inflexible.s.04.rigid')\", 2)])\n",
      "collecting tokens for  jaws\n",
      "indices:    {30976, 12549, 30984, 31020, 19181, 36051, 30997, 8854, 18361, 17663}\n",
      "dict_items([(\"Lemma('jaw.n.01.jaw')\", 5)])\n",
      "collecting tokens for  wild\n",
      "indices:    {6051, 199, 29288, 969, 1194, 5931, 35244, 36415, 26417, 35251, 23251, 981, 23927, 17502, 11292, 3646, 36927}\n",
      "dict_items([(\"Lemma('wild.a.01.wild')\", 5), (\"Lemma('wild.a.02.wild')\", 2)])\n",
      "collecting tokens for  tropical\n",
      "indices:    {3717, 3686, 7273, 29270, 1687, 27193, 27194, 23935}\n",
      "dict_items([(\"Lemma('tropical.s.01.tropical')\", 4)])\n",
      "collecting tokens for  perfectly\n",
      "indices:    {36491, 30999, 1576, 16051, 14260, 11443, 33208, 32312, 10942, 5950, 7488, 840, 2646, 1753, 25449, 8682, 2668, 13936, 12918, 13950}\n",
      "dict_items([(\"Lemma('absolutely.r.01.perfectly')\", 13), (\"Lemma('perfectly.r.02.perfectly')\", 2)])\n",
      "collecting tokens for  arlene\n",
      "indices:    {26364}\n",
      "dict_items([])\n",
      "collecting tokens for  friendly\n",
      "indices:    {15745, 32648, 1422, 36369, 1436, 24093, 4638, 23077, 11431, 13353, 13354, 13355, 13356, 23085, 13358, 36272, 13360, 13362, 24376, 57, 12218, 10942, 36292, 4678, 13389, 10320, 5072, 24662, 13527, 25567, 15975, 12264, 10094, 6256, 31218, 14450}\n",
      "dict_items([(\"Lemma('friendly.a.01.friendly')\", 21), (\"Lemma('friendly.s.02.friendly')\", 4)])\n",
      "collecting tokens for  0\n",
      "indices:    {4352, 391, 273, 4387, 4390, 4392, 16180, 16182, 4413, 23358, 4550, 590, 4559, 4561, 21976, 4319, 613, 4456, 4460, 4334, 4471, 4474, 4475, 4348, 4349, 4478, 4479}\n",
      "dict_items([(\"Lemma('zero.s.01.0')\", 3), (\"Lemma('zero.n.02.0')\", 18)])\n",
      "collecting tokens for  published\n",
      "indices:    {20494, 26018, 24740, 4011, 2496, 14418, 3026, 32728, 11872, 32486, 29927, 22248, 27882, 13805, 17778, 17779, 29940, 1269, 25972, 32762, 2171, 32765, 2046, 8447}\n",
      "dict_items([(\"Lemma('publish.v.02.publish')\", 5), (\"Lemma('print.v.01.publish')\", 16), (\"Lemma('published.a.01.published')\", 1)])\n",
      "collecting tokens for  1946\n",
      "indices:    {5124, 5125, 14867, 23188, 14369, 24739, 24236, 5179, 12743, 461, 12756, 14936, 12768, 31201, 22114, 12774, 20583, 16234, 2806}\n",
      "dict_items([])\n",
      "collecting tokens for  nearby\n",
      "indices:    {22914, 16263, 16265, 30486, 35359, 25123, 11431, 24367, 1844, 25782, 30013, 29247, 31938, 23492, 36422, 1873, 30419, 1629, 18014, 5088, 11110, 1896, 3052, 14444, 21614, 29295, 29935, 33775, 5105, 12149, 23673, 253}\n",
      "dict_items([(\"Lemma('nearby.s.01.nearby')\", 8), (\"Lemma('nearby.r.01.nearby')\", 7)])\n",
      "collecting tokens for  mile\n",
      "indices:    {21375}\n",
      "dict_items([])\n",
      "collecting tokens for  27\n",
      "indices:    {29697, 29322, 15123, 27412, 3737, 929, 27942, 33202, 1715, 22334, 27459, 198, 21576, 4057, 28252, 2268, 21342, 25832, 25192, 363, 29295, 1392, 253, 27005}\n",
      "dict_items([(\"Lemma('twenty-seven.s.01.27')\", 7), (\"Lemma('twenty-seven.n.01.27')\", 1)])\n",
      "collecting tokens for  douglass\n",
      "indices:    {3095}\n",
      "dict_items([(\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  crystal\n",
      "indices:    {3139, 22309, 653, 3054, 10031, 11384}\n",
      "dict_items([(\"Lemma('crystal.n.02.crystal')\", 1), (\"Lemma('crystal.n.01.crystal')\", 3)])\n",
      "collecting tokens for  penalty\n",
      "indices:    {25184, 21409, 128, 25858, 1098, 5291, 36750, 27343, 8849, 34353, 21267, 21692}\n",
      "dict_items([(\"Lemma('penalty.n.03.penalty')\", 1), (\"Lemma('punishment.n.01.penalty')\", 3)])\n",
      "collecting tokens for  waved\n",
      "indices:    {18849, 17061, 424, 34665, 5995, 18477, 26388, 33430, 24375, 9946, 33563, 34911}\n",
      "dict_items([(\"Lemma('brandish.v.01.wave')\", 2), (\"Lemma('beckon.v.01.wave')\", 9)])\n",
      "collecting tokens for  individuals\n",
      "indices:    {22788, 24949, 27180, 28079}\n",
      "dict_items([])\n",
      "collecting tokens for  sad\n",
      "indices:    {23712, 22535, 27436, 27438, 9488, 35381, 9461}\n",
      "dict_items([(\"Lemma('sad.a.01.sad')\", 2)])\n",
      "collecting tokens for  competent\n",
      "indices:    {22736, 26810, 26675}\n",
      "dict_items([])\n",
      "collecting tokens for  hail\n",
      "indices:    {25362}\n",
      "dict_items([])\n",
      "collecting tokens for  canyon\n",
      "indices:    {19241, 5051}\n",
      "dict_items([(\"Lemma('canyon.n.01.canyon')\", 1)])\n",
      "collecting tokens for  poised\n",
      "indices:    {26956, 7935}\n",
      "dict_items([(\"Lemma('brace.v.01.poise')\", 1), (\"Lemma('poised.s.01.poised')\", 1)])\n",
      "collecting tokens for  please\n",
      "indices:    {13013}\n",
      "dict_items([])\n",
      "collecting tokens for  lecture\n",
      "indices:    {5313, 5315, 36999, 2123, 22354, 11509, 27262, 5631}\n",
      "dict_items([(\"Lemma('lecture.n.01.lecture')\", 5)])\n",
      "collecting tokens for  crime\n",
      "indices:    {25376, 20301, 6030, 13968, 19347, 21754, 13980, 10141}\n",
      "dict_items([(\"Lemma('crime.n.01.crime')\", 5)])\n",
      "collecting tokens for  punishment\n",
      "indices:    {1504, 37158, 36998, 5318, 6441, 2666, 1510, 1513, 28265, 27214, 11117, 5297, 5919}\n",
      "dict_items([(\"Lemma('punishment.n.01.punishment')\", 8)])\n",
      "collecting tokens for  reaches\n",
      "indices:    {1954, 3685, 36998, 15718, 13868, 13261, 3725, 3694, 27950, 430, 10317, 2355, 1780, 2808, 27643, 3389, 15422}\n",
      "dict_items([(\"Lemma('range.n.02.reach')\", 1), (\"Lemma('reach.v.02.reach')\", 8), (\"Lemma('reach.v.01.reach')\", 3), (\"Lemma('reach.v.04.reach')\", 3)])\n",
      "collecting tokens for  gavin\n",
      "indices:    {35178}\n",
      "dict_items([])\n",
      "collecting tokens for  blanket\n",
      "indices:    {7168, 33668, 34579, 3363, 27950, 3374, 2114, 30026, 17740, 6732, 35151, 35413, 19035, 35421, 30954, 5102, 5103, 3312, 26995, 23926, 7167}\n",
      "dict_items([(\"Lemma('blanket.n.01.blanket')\", 6), (\"Lemma('blanket.n.02.blanket')\", 4)])\n",
      "collecting tokens for  excuse\n",
      "indices:    {24164, 25652, 10645, 19343}\n",
      "dict_items([(\"Lemma('excuse.n.01.excuse')\", 1), (\"Lemma('excuse.v.01.excuse')\", 1)])\n",
      "collecting tokens for  mistaken\n",
      "indices:    {14338, 10274, 34588, 11079, 19338, 26190, 9296, 12241, 30352, 28118, 26135, 4857, 23803, 14332, 6137}\n",
      "dict_items([(\"Lemma('misguided.s.02.mistaken')\", 5), (\"Lemma('mistake.v.01.mistake')\", 4), (\"Lemma('false.s.02.mistaken')\", 2)])\n",
      "collecting tokens for  belgian\n",
      "indices:    {23253}\n",
      "dict_items([])\n",
      "collecting tokens for  mercenaries\n",
      "indices:    {23276, 25851, 12463, 12465, 25847, 37112, 25849, 25850, 23803}\n",
      "dict_items([(\"Lemma('mercenary.n.01.mercenary')\", 2)])\n",
      "collecting tokens for  advised\n",
      "indices:    {14457, 28546, 15331, 15492, 10882, 10988, 17358, 20337, 10931, 212, 2740, 21686, 10647, 5075, 20345, 12766}\n",
      "dict_items([(\"Lemma('advise.v.02.advise')\", 6), (\"Lemma('rede.v.02.advise')\", 6), (\"Lemma('propose.v.01.advise')\", 4)])\n",
      "collecting tokens for  factory\n",
      "indices:    {5140}\n",
      "dict_items([])\n",
      "collecting tokens for  u\n",
      "indices:    {890}\n",
      "dict_items([])\n",
      "collecting tokens for  comparison\n",
      "indices:    {3587, 32265, 25354, 12938, 16010, 12174, 32282, 2971, 16159, 25504, 3874, 3875, 24744, 16041, 4009, 32555, 32556, 4014, 12723, 8373, 14777, 4921, 7358, 7362, 26948, 16207, 3796, 14421, 1884, 11484, 3806, 11613, 26213, 24040, 30568, 35692, 21875}\n",
      "dict_items([(\"Lemma('comparison.n.01.comparison')\", 15), (\"Lemma('comparison.n.02.comparison')\", 6)])\n",
      "collecting tokens for  perry\n",
      "indices:    {22195}\n",
      "dict_items([])\n",
      "collecting tokens for  defined\n",
      "indices:    {32771, 5386, 33035, 31246, 14230, 4504, 36762, 13349, 27304, 4014, 4015, 33070, 33199, 4535, 3131, 4540, 33214, 3775, 2759, 4552, 4553, 31818, 14671, 4561, 33004, 32495, 3186, 4980}\n",
      "dict_items([(\"Lemma('define.v.02.define')\", 7), (\"Lemma('define.v.03.define')\", 6), (\"Lemma('specify.v.03.define')\", 8), (\"Lemma('defined.a.01.defined')\", 2), (\"Lemma('define.v.04.define')\", 1)])\n",
      "collecting tokens for  mg\n",
      "indices:    {3982, 5532, 5533, 4126, 5535, 4014, 4015, 5552, 5550, 5554, 5557, 4149, 5558, 4164, 4168, 4171, 4172, 5580, 5581, 5587, 5589, 5592, 5593, 5596, 5490}\n",
      "dict_items([(\"Lemma('milligram.n.01.mg')\", 25)])\n",
      "collecting tokens for  observe\n",
      "indices:    {8064, 24960, 32779, 1435, 29984, 34722, 15663, 12208, 30271, 32836, 32840, 14691, 34281, 11114, 26859, 35692, 2805, 2295, 9854}\n",
      "dict_items([(\"Lemma('note.v.03.observe')\", 5), (\"Lemma('note.v.01.observe')\", 4), (\"Lemma('detect.v.01.observe')\", 5), (\"Lemma('respect.v.02.observe')\", 1), (\"Lemma('observe.v.04.observe')\", 3), (\"Lemma('observe.v.06.observe')\", 1)])\n",
      "collecting tokens for  singular\n",
      "indices:    {7907, 32836, 32772, 32038, 32838, 32810, 32782, 32817, 32786, 17111}\n",
      "dict_items([(\"Lemma('remarkable.s.01.singular')\", 1), (\"Lemma('singular.s.03.singular')\", 1)])\n",
      "collecting tokens for  exaggerated\n",
      "indices:    {22720, 15329, 27554, 21408, 26212, 33553, 15667, 31829, 9659, 1085}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('exaggerated.s.01.exaggerated')\", 2), (\"Lemma('overstate.v.01.exaggerate')\", 4), (\"Lemma('overdo.v.01.exaggerate')\", 1)])\n",
      "collecting tokens for  guerrillas\n",
      "indices:    {35424, 35441, 5937, 35415, 35450, 35389}\n",
      "dict_items([(\"Lemma('guerrilla.n.01.guerrilla')\", 1)])\n",
      "collecting tokens for  hen\n",
      "indices:    {7808, 9344, 9347, 9350, 9361, 9363, 9367, 9368, 27164, 3619, 9382, 9390, 9395, 9398, 12090, 9323, 9329, 12531, 9334, 9337}\n",
      "dict_items([(\"Lemma('hen.n.01.hen')\", 17), (\"Lemma('hen.n.02.hen')\", 1)])\n",
      "collecting tokens for  vision\n",
      "indices:    {18951, 20108, 5773, 27916, 27918, 27919, 18449, 34066, 30742, 26136, 34714, 34719, 32053, 9144, 19770, 30013, 5441, 4929, 4934, 19533, 4945, 16594, 26707, 34138, 20840, 7147, 4976, 9587, 26102, 26103, 7931}\n",
      "dict_items([(\"Lemma('vision.n.01.vision')\", 5), (\"Lemma('sight.n.03.vision')\", 5), (\"Lemma('vision.n.03.vision')\", 1), (\"Lemma('vision.n.05.vision')\", 1), (\"Lemma('imagination.n.01.vision')\", 2)])\n",
      "collecting tokens for  baked\n",
      "indices:    {29218, 30436, 36103, 22185, 30443, 36080, 19155, 35542}\n",
      "dict_items([(\"Lemma('bake.v.02.bake')\", 1), (\"Lemma('bake.v.01.bake')\", 3), (\"Lemma('adust.s.01.baked')\", 1)])\n",
      "collecting tokens for  contributed\n",
      "indices:    {32646, 16391, 31624, 14097, 21652, 15637, 22679, 12183, 23836, 16413, 14752, 5536, 28073, 307, 32314, 26301, 2115, 21577, 23243, 26191, 12239, 2133, 11742, 2788, 27751, 11882, 28015, 14837, 32758}\n",
      "dict_items([(\"Lemma('lend.v.01.contribute')\", 10), (\"Lemma('contribute.v.02.contribute')\", 10), (\"Lemma('contribute.v.03.contribute')\", 7), (\"Lemma('put_up.v.08.contribute')\", 2)])\n",
      "collecting tokens for  vigorous\n",
      "indices:    {25992, 12309, 15384, 26777, 6040, 12059, 29985, 30501, 26417, 26301, 16324, 32452, 18886, 1612, 26979, 5222, 11881, 26862, 22649, 16379, 7293, 1534}\n",
      "dict_items([(\"Lemma('vigorous.s.01.vigorous')\", 11), (\"Lemma('vigorous.s.02.vigorous')\", 1)])\n",
      "collecting tokens for  policeman\n",
      "indices:    {33568, 33314, 17540, 12676, 74, 78, 21327, 25326, 10866, 10869, 10870, 10873, 10877, 33566}\n",
      "dict_items([(\"Lemma('policeman.n.01.policeman')\", 8)])\n",
      "collecting tokens for  dealers\n",
      "indices:    {11910, 21991, 23143, 21993, 22000}\n",
      "dict_items([(\"Lemma('trader.n.01.dealer')\", 1)])\n",
      "collecting tokens for  tv\n",
      "indices:    {22428}\n",
      "dict_items([])\n",
      "collecting tokens for  newspapers\n",
      "indices:    {1425, 37020, 20510, 5282, 5157, 5295, 21810, 948, 27446, 5307, 24901, 9804, 14414, 24911, 5332, 14935, 30940, 14940, 5344, 9186, 12260, 33273, 26878}\n",
      "dict_items([(\"Lemma('newspaper.n.02.newspaper')\", 6), (\"Lemma('newspaper.n.01.newspaper')\", 7)])\n",
      "collecting tokens for  sporting\n",
      "indices:    {11872, 21004, 11901}\n",
      "dict_items([(\"Lemma('sporting.a.02.sporting')\", 1)])\n",
      "collecting tokens for  correct\n",
      "indices:    {1541, 28435, 23956, 23575, 32157, 21534, 34590, 31137, 31146, 28855, 28856, 28861, 34751, 31041, 26955, 31067, 24543, 5478, 15850, 24179, 17397, 3702}\n",
      "dict_items([(\"Lemma('right.v.01.correct')\", 3), (\"Lemma('correct.v.01.correct')\", 4), (\"Lemma('correct.a.01.correct')\", 3), (\"Lemma('correct.s.02.correct')\", 1)])\n",
      "collecting tokens for  exposed\n",
      "indices:    {3456, 11906, 2950, 27279, 17684, 14357, 17575, 23722, 34734, 31667, 20285, 3137, 11457, 22849, 3279, 3409, 26202, 2907, 28000, 15206, 12779, 9325, 15863, 3455}\n",
      "dict_items([(\"Lemma('expose.v.01.expose')\", 11), (\"Lemma('unwrap.v.02.expose')\", 2), (\"Lemma('disclose.v.02.expose')\", 1), (\"Lemma('queer.v.02.expose')\", 1), (\"Lemma('exposed.s.02.exposed')\", 1), (\"Lemma('exposed.s.01.exposed')\", 5), (\"Lemma('expose.v.03.expose')\", 1), (\"Lemma('uncover.v.02.expose')\", 1)])\n",
      "collecting tokens for  fantastic\n",
      "indices:    {2177, 13830, 32905, 33360, 29331, 19443, 30741, 26650, 22779, 32028}\n",
      "dict_items([(\"Lemma('fantastic.s.04.fantastic')\", 1), (\"Lemma('fantastic.s.03.fantastic')\", 1), (\"Lemma('antic.s.01.fantastic')\", 1)])\n",
      "collecting tokens for  taylor\n",
      "indices:    {21643}\n",
      "dict_items([])\n",
      "collecting tokens for  likely\n",
      "indices:    {4608, 4610, 3090, 4633, 2092, 27182, 55, 30271, 24131, 24137, 24142, 29268, 5215, 613, 15980, 3698, 15987, 1652, 15989, 16500, 16002, 16007, 20623, 20627, 17556, 29334, 12953, 27802, 27809, 26785, 22704, 2737, 4799, 11982, 34521, 32987, 4834, 12004, 16101, 17127, 745, 2800, 2809, 29946, 30983, 1800, 14601, 12039, 1291, 1808, 6943, 12064, 25381, 29997, 30002, 30520, 15673, 14653, 9028, 26436, 1864, 14683, 18268, 31072, 4450, 3938, 5476, 31078, 5483, 4462, 15219, 13180, 3453, 23934, 9086, 15231, 15237, 3462, 15238, 26501, 24457, 17804, 5010, 21909, 12195, 31143, 17320, 13224, 13234, 16307, 30138, 13244, 32193, 14792, 24018, 26078, 23519, 16352, 25569, 26083, 4590, 24562, 27129, 14333}\n",
      "dict_items([(\"Lemma('likely.a.01.likely')\", 26), (\"Lemma('probably.r.01.likely')\", 7), (\"Lemma('probable.a.01.likely')\", 4)])\n",
      "collecting tokens for  propaganda\n",
      "indices:    {25921, 25955, 24195, 12965, 24966, 25962, 14188, 23662, 27740, 27479, 14972}\n",
      "dict_items([(\"Lemma('propaganda.n.01.propaganda')\", 3)])\n",
      "collecting tokens for  d.\n",
      "indices:    {23311}\n",
      "dict_items([])\n",
      "collecting tokens for  cafe\n",
      "indices:    {22307}\n",
      "dict_items([])\n",
      "collecting tokens for  rested\n",
      "indices:    {15072, 27554, 10378, 36972, 34030, 5682, 21363, 33011, 1173, 4987, 15229}\n",
      "dict_items([(\"Lemma('rest.v.01.rest')\", 5), (\"Lemma('rest.v.02.rest')\", 1), (\"Lemma('lie.v.06.rest')\", 1), (\"Lemma('repose_on.v.01.rest_on')\", 2)])\n",
      "collecting tokens for  motel\n",
      "indices:    {33493, 21685, 21021, 29463}\n",
      "dict_items([])\n",
      "collecting tokens for  norman\n",
      "indices:    {11084}\n",
      "dict_items([])\n",
      "collecting tokens for  knocked\n",
      "indices:    {1542, 20746, 12688, 18448, 16785, 21028, 17447, 30383, 304, 306, 28992, 12609, 19272, 21321, 35801, 12637, 7134, 28515, 7396, 12775, 18540, 368, 8567, 30328, 34046, 7423}\n",
      "dict_items([(\"Lemma('knock.v.01.knock')\", 4), (\"Lemma('knock.v.02.knock')\", 2), (\"Lemma('buffet.v.01.knock_about')\", 1), (\"Lemma('knock_cold.v.01.knock_out')\", 1), (\"Lemma('down.v.05.knock_down')\", 1), (\"Lemma('bump.v.01.knock')\", 2), (\"Lemma('shave.v.03.knock_off')\", 1)])\n",
      "collecting tokens for  charm\n",
      "indices:    {8197, 11135, 29015}\n",
      "dict_items([(\"Lemma('spell.n.04.charm')\", 1), (\"Lemma('appeal.n.02.charm')\", 1)])\n",
      "collecting tokens for  revolutionary\n",
      "indices:    {5409, 21411, 12327, 21421, 14702, 28048, 11091, 5363, 27990, 14106}\n",
      "dict_items([(\"Lemma('revolutionary.s.01.revolutionary')\", 6)])\n",
      "collecting tokens for  onion\n",
      "indices:    {29536, 29187, 29219, 29517, 22132, 29498, 29181, 29503}\n",
      "dict_items([])\n",
      "collecting tokens for  nai\n",
      "indices:    {33218, 30022, 33224, 33105, 33202, 33242, 33211, 33214}\n",
      "dict_items([])\n",
      "collecting tokens for  ve\n",
      "indices:    {33249, 33218, 30022, 33224, 33105, 33202, 33242, 33211, 33214}\n",
      "dict_items([])\n",
      "collecting tokens for  condition\n",
      "indices:    {33214}\n",
      "dict_items([])\n",
      "collecting tokens for  subjective\n",
      "indices:    {33249, 16450, 4964, 2404, 31914, 2988, 33071, 31888, 13617, 33234, 14162, 13620, 15861, 31896, 15866, 12283}\n",
      "dict_items([(\"Lemma('subjective.a.01.subjective')\", 10)])\n",
      "collecting tokens for  follows\n",
      "indices:    {14720, 2050, 14084, 29188, 3853, 3855, 23440, 32786, 4243, 29716, 3730, 25374, 32798, 928, 32801, 4643, 2852, 14634, 33067, 15408, 16051, 32819, 32821, 4533, 2046, 3768, 15801, 32825, 4921, 1470, 1856, 15813, 33093, 25669, 1354, 25803, 32843, 4175, 26454, 4569, 15966, 13150, 19422, 4837, 4841, 10734, 13807, 29039, 21876, 2038, 12922, 15739, 4350}\n",
      "dict_items([(\"Lemma('follow.v.03.follow')\", 19), (\"Lemma('follow.v.07.follow')\", 2), (\"Lemma('postdate.v.01.follow')\", 3), (\"Lemma('follow.v.08.follow')\", 3), (\"Lemma('follow.v.04.follow')\", 3), (\"Lemma('comply.v.01.follow')\", 1), (\"Lemma('take_after.v.02.follow')\", 1), (\"Lemma('follow.v.01.follow')\", 1)])\n",
      "collecting tokens for  progressed\n",
      "indices:    {1185, 27173, 34283, 14031, 11088, 9365, 23896, 36955, 9343}\n",
      "dict_items([(\"Lemma('progress.v.01.progress')\", 8)])\n",
      "collecting tokens for  equitable\n",
      "indices:    {17351, 15242, 15243, 32395, 32399, 23896, 24, 32378}\n",
      "dict_items([(\"Lemma('equitable.a.01.equitable')\", 4)])\n",
      "collecting tokens for  levels\n",
      "indices:    {21893, 3718, 4617, 3983, 11675, 3874, 3875, 11560, 14123, 25389, 25392, 4656, 25137, 13631, 13632, 11585, 13634, 13636, 26692, 13640, 22728, 4045, 30798, 23888, 11600, 15699, 22611, 14037, 23896, 20060, 14054, 11628, 26734, 16367, 16366, 27250, 21108, 32503, 22010, 25596, 3454, 29695}\n",
      "dict_items([(\"Lemma('degree.n.01.level')\", 13), (\"Lemma('degree.n.02.level')\", 6), (\"Lemma('grade.n.02.level')\", 5), (\"Lemma('level.n.05.level')\", 1)])\n",
      "collecting tokens for  arise\n",
      "indices:    {12929, 771, 447, 2058, 2732, 2636, 13485, 16461, 26637, 2893, 2585, 29407, 25439, 23896, 10201, 22651, 12093, 15487}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('originate.v.01.arise')\", 11), (\"Lemma('arise.v.04.arise')\", 4), (\"Lemma('arise.v.02.arise')\", 3)])\n",
      "collecting tokens for  spectrum\n",
      "indices:    {11361, 32901, 32137, 3114, 11369, 3533, 3469, 2798, 2799, 2800, 32882, 23896}\n",
      "dict_items([(\"Lemma('spectrum.n.02.spectrum')\", 2), (\"Lemma('spectrum.n.01.spectrum')\", 3)])\n",
      "collecting tokens for  gov.\n",
      "indices:    {23629}\n",
      "dict_items([])\n",
      "collecting tokens for  marvin\n",
      "indices:    {12845}\n",
      "dict_items([])\n",
      "collecting tokens for  lt.\n",
      "indices:    {48}\n",
      "dict_items([])\n",
      "collecting tokens for  byrd\n",
      "indices:    {48}\n",
      "dict_items([])\n",
      "collecting tokens for  invitations\n",
      "indices:    {22163}\n",
      "dict_items([])\n",
      "collecting tokens for  tour\n",
      "indices:    {22528, 22534, 29193, 29326, 24849, 17685, 22934, 22425, 24730, 27035, 22940, 27036, 22937, 29347, 31655, 24872, 34687, 13112, 11195, 29247, 20929, 29255, 26580, 29274, 27615, 26976, 27748, 34149, 34283, 24826, 1023}\n",
      "dict_items([(\"Lemma('tour.n.01.tour')\", 2), (\"Lemma('go.n.01.tour')\", 1)])\n",
      "collecting tokens for  shea\n",
      "indices:    {508}\n",
      "dict_items([(\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  feature\n",
      "indices:    {32898, 20739, 12938, 16145, 3091, 14628, 14633, 22192, 29241, 698, 16063, 1218, 30150, 36681, 3664, 2392, 31192, 29273, 22497, 28130, 11108, 31213, 30583, 20732}\n",
      "dict_items([(\"Lemma('have.v.02.feature')\", 6), (\"Lemma('feature.n.03.feature')\", 2), (\"Lemma('feature.n.01.feature')\", 8)])\n",
      "collecting tokens for  facets\n",
      "indices:    {13510, 14575, 31184, 31192, 22138, 25179, 27036, 31199}\n",
      "dict_items([(\"Lemma('aspect.n.01.facet')\", 2)])\n",
      "collecting tokens for  conventional\n",
      "indices:    {31877, 2696, 25488, 30226, 11415, 20248, 20249, 1311, 23848, 21291, 29484, 24111, 1721, 5438, 23617, 1732, 25159, 33480, 14410, 13643, 14796, 24656, 13650, 13651, 13653, 31192, 24669, 15463, 5360, 5491}\n",
      "dict_items([(\"Lemma('conventional.s.05.conventional')\", 1), (\"Lemma('conventional.a.01.conventional')\", 10), (\"Lemma('conventional.s.02.conventional')\", 2), (\"Lemma('conventional.s.06.conventional')\", 1), (\"Lemma('conventional.a.03.conventional')\", 1)])\n",
      "collecting tokens for  clinical\n",
      "indices:    {3458, 32899, 4237, 4240, 4241, 4242, 4254, 4261, 4016, 4278, 15672, 32706, 15687, 4046, 9679, 32727, 32734, 13158, 32873, 32877, 32757, 15867}\n",
      "dict_items([(\"Lemma('clinical.a.01.clinical')\", 14), (\"Lemma('clinical.s.02.clinical')\", 1)])\n",
      "collecting tokens for  exposure\n",
      "indices:    {1824, 3459, 3332, 3333, 30438, 14632, 29289, 11209, 1258, 3404, 3407, 14649, 25405}\n",
      "dict_items([(\"Lemma('exposure.n.03.exposure')\", 2), (\"Lemma('exposure.n.01.exposure')\", 4), (\"Lemma('exposure.n.04.exposure')\", 1), (\"Lemma('exposure.n.02.exposure')\", 3)])\n",
      "collecting tokens for  peak\n",
      "indices:    {21890, 2919, 29296, 26994, 3634, 3571, 32853, 23385, 2846}\n",
      "dict_items([(\"Lemma('acme.n.01.peak')\", 1), (\"Lemma('extremum.n.02.peak')\", 1), (\"Lemma('flower.n.03.peak')\", 1)])\n",
      "collecting tokens for  arch\n",
      "indices:    {13942, 2006}\n",
      "dict_items([(\"Lemma('arch.v.01.arch')\", 1)])\n",
      "collecting tokens for  toes\n",
      "indices:    {2016, 9345, 36966, 11113, 10571, 2350, 2001, 689, 22071, 7416, 2015, 2013, 36735}\n",
      "dict_items([(\"Lemma('toe.n.01.toe')\", 7), (\"Lemma('toe.n.02.toe')\", 1)])\n",
      "collecting tokens for  vehicle\n",
      "indices:    {22784, 32388, 32389, 32264, 24586, 32267, 21389, 32275, 14488, 3357, 13343, 13634, 13385, 26958, 32337, 13393, 32343, 32346, 20317, 32354, 15848, 21626}\n",
      "dict_items([(\"Lemma('vehicle.n.02.vehicle')\", 6), (\"Lemma('vehicle.n.01.vehicle')\", 1)])\n",
      "collecting tokens for  add\n",
      "indices:    {29504, 14791, 24168, 14153, 33102, 13558, 29239, 32254}\n",
      "dict_items([(\"Lemma('add.v.02.add')\", 2), (\"Lemma('total.v.02.add')\", 1), (\"Lemma('add.v.01.add')\", 4)])\n",
      "collecting tokens for  crude\n",
      "indices:    {3225, 27751, 8810, 18251, 14414, 5806, 2705, 8499, 36505, 23930, 5276}\n",
      "dict_items([(\"Lemma('crude.s.02.crude')\", 2), (\"Lemma('crude.s.01.crude')\", 5)])\n",
      "collecting tokens for  religions\n",
      "indices:    {27776, 27328, 10851, 27751, 27753, 23198, 27760, 4721, 4658, 26099, 4666, 4661, 4657, 27736, 4730, 4700, 29342}\n",
      "dict_items([(\"Lemma('religion.n.01.religion')\", 8)])\n",
      "collecting tokens for  dates\n",
      "indices:    {32263, 29321, 2446, 4756, 32533, 31131, 26617, 29352, 31145, 939, 32572, 32573, 581, 26310, 11856, 15571, 13911, 32607, 32616, 22250, 13558, 22009, 9594, 33147}\n",
      "dict_items([(\"Lemma('date.n.01.date')\", 5), (\"Lemma('go_back.v.01.date_back')\", 1), (\"Lemma('date.n.02.date')\", 1)])\n",
      "collecting tokens for  synthesis\n",
      "indices:    {15874, 3971, 3940, 3946, 3947, 11324, 3965}\n",
      "dict_items([(\"Lemma('synthesis.n.02.synthesis')\", 2), (\"Lemma('synthesis.n.01.synthesis')\", 5)])\n",
      "collecting tokens for  demonstrated\n",
      "indices:    {14725, 3211, 3223, 30233, 23968, 4263, 14506, 15674, 9659, 3902, 3786, 4043, 4686, 3408, 3168, 2400, 15714, 26601, 3946, 32233, 4204, 3951, 3824, 3826, 23541, 22649, 4605}\n",
      "dict_items([(\"Lemma('prove.v.02.demonstrate')\", 11), (\"Lemma('show.v.01.demonstrate')\", 10), (\"Lemma('demonstrated.s.01.demonstrated')\", 1)])\n",
      "collecting tokens for  systems\n",
      "indices:    {15489, 11395, 33031, 15496, 23561, 32267, 15509, 15510, 15511, 25503, 15525, 5415, 3499, 15531, 27566, 15534, 4272, 32178, 13618, 16052, 4276, 3510, 4277, 32952, 30137, 16057, 14776, 16060, 16056, 16441, 16058, 30144, 30145, 3394, 9787, 31294, 32969, 16077, 16079, 15485, 11350, 23510, 23512, 20185, 23514, 23515, 23516, 16093, 16094, 32734, 10847, 3934, 3932, 4195, 3942, 16103, 16125, 3946, 16105, 33004, 15727, 4208, 16113, 16114, 26099, 16116, 26100, 30582, 4730, 21245}\n",
      "dict_items([(\"Lemma('system.n.03.system')\", 5), (\"Lemma('system.n.01.system')\", 9), (\"Lemma('system.n.02.system')\", 7), (\"Lemma('arrangement.n.03.system')\", 1), (\"Lemma('system.n.06.system')\", 4), (\"Lemma('system.n.04.system')\", 1)])\n",
      "collecting tokens for  thyroid\n",
      "indices:    {4041, 3948, 3937, 3935}\n",
      "dict_items([(\"Lemma('thyroid_gland.n.01.thyroid')\", 4)])\n",
      "collecting tokens for  provinces\n",
      "indices:    {24198, 23244, 33068, 27566, 23247, 26990, 16216}\n",
      "dict_items([(\"Lemma('state.n.01.province')\", 1)])\n",
      "collecting tokens for  awful\n",
      "indices:    {30049, 31426, 7363, 36518, 1254, 33705, 7276, 25133, 7308, 9071, 9009, 18612, 8222}\n",
      "dict_items([(\"Lemma('terribly.r.01.awful')\", 4), (\"Lemma('atrocious.s.02.awful')\", 3), (\"Lemma('awful.s.02.awful')\", 1)])\n",
      "collecting tokens for  port\n",
      "indices:    {20405}\n",
      "dict_items([])\n",
      "collecting tokens for  experimental\n",
      "indices:    {3456, 1665, 32904, 4235, 3981, 23186, 4253, 3357, 31140, 4261, 4267, 4278, 32699, 2877, 3404, 2894, 3406, 33110, 3070, 33253, 3048, 33129, 2797, 20209, 34678, 3320, 32892, 23550, 3839}\n",
      "dict_items([(\"Lemma('experimental.a.01.experimental')\", 13), (\"Lemma('experimental.s.03.experimental')\", 2), (\"Lemma('experimental.s.02.experimental')\", 3)])\n",
      "collecting tokens for  iodine\n",
      "indices:    {3969, 3970, 3973, 4042, 3980, 3981, 3982, 3983, 3949, 3985, 3959, 3986, 3991, 3931, 3932}\n",
      "dict_items([(\"Lemma('iodine.n.01.iodine')\", 15)])\n",
      "collecting tokens for  1954\n",
      "indices:    {3969, 32515, 3981, 276, 14870, 15000, 667, 15005, 15010, 21291, 21434, 22843, 22844, 15043, 31811, 15045, 31814, 23751, 15048, 24138, 20555, 2508, 24141, 11874, 11875, 25833, 4201, 25838, 3952, 13684, 11897}\n",
      "dict_items([])\n",
      "collecting tokens for  deserve\n",
      "indices:    {26501, 5318, 16136, 25293, 23635, 23668, 16150, 24215, 4989}\n",
      "dict_items([(\"Lemma('deserve.v.01.deserve')\", 9)])\n",
      "collecting tokens for  bars\n",
      "indices:    {23943, 1928, 28811, 28814, 1553, 28819, 28822, 23706, 37151, 27175, 28719, 28720, 28722, 28725, 28729, 28730, 28743, 18513, 28754, 28765, 12643, 28780, 24695, 28792, 28795}\n",
      "dict_items([(\"Lemma('bar.v.01.bar')\", 1), (\"Lemma('barroom.n.01.bar')\", 1), (\"Lemma('barricade.v.01.bar')\", 1), (\"Lemma('bar.n.05.bar')\", 1)])\n",
      "collecting tokens for  commonly\n",
      "indices:    {26852, 16104, 1578, 27243, 1260, 1324, 16108, 16111, 32592, 16051, 1205, 11350, 16058, 5018}\n",
      "dict_items([(\"Lemma('normally.r.01.commonly')\", 11)])\n",
      "collecting tokens for  electronic\n",
      "indices:    {32464, 33481, 11352, 33540}\n",
      "dict_items([(\"Lemma('electronic.a.01.electronic')\", 1)])\n",
      "collecting tokens for  devices\n",
      "indices:    {31873, 16135, 15499, 32910, 33426, 31890, 12320, 3493, 3494, 25383, 36652, 31278, 2228, 2229, 2244, 2246, 31944, 30280, 31304, 28745, 2254, 11350, 26839, 3171, 16229, 30183, 31855, 5361}\n",
      "dict_items([(\"Lemma('device.n.01.device')\", 13)])\n",
      "collecting tokens for  courage\n",
      "indices:    {27142, 1930, 35211, 23820, 27284, 32679, 19500, 25134, 32689, 28339, 25270, 27324, 26049, 30529, 5317, 7121, 32081, 24018, 9590, 1018}\n",
      "dict_items([(\"Lemma('courage.n.01.courage')\", 6)])\n",
      "collecting tokens for  happily\n",
      "indices:    {27268, 24612, 23942, 36360, 26889, 23184, 34004, 26232, 1051, 8511}\n",
      "dict_items([(\"Lemma('happily.r.01.happily')\", 2)])\n",
      "collecting tokens for  episode\n",
      "indices:    {36899, 22602, 8395, 2646, 3480, 1019, 27324, 20511}\n",
      "dict_items([(\"Lemma('episode.n.02.episode')\", 1), (\"Lemma('episode.n.01.episode')\", 3)])\n",
      "collecting tokens for  comparative\n",
      "indices:    {3812, 14663, 33197, 15729, 4465, 4793, 14708, 3830, 4601, 27804, 3837, 16191}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('comparative.a.01.comparative')\", 4)])\n",
      "collecting tokens for  ratings\n",
      "indices:    {15648, 30023, 3881, 3882, 3883, 15729, 15666, 15677}\n",
      "dict_items([(\"Lemma('evaluation.n.02.rating')\", 4), (\"Lemma('evaluation.n.01.rating')\", 2), (\"Lemma('rating.n.03.rating')\", 1)])\n",
      "collecting tokens for  isolated\n",
      "indices:    {4610, 3976, 5393, 15892, 2326, 5403, 3357, 2226, 4532, 17991, 3786, 33358, 32982, 4184, 32733, 13661, 13674, 4589, 28147, 3702}\n",
      "dict_items([(\"Lemma('disjunct.s.03.isolated')\", 3), (\"Lemma('isolated.s.01.isolated')\", 5), (\"Lemma('detached.s.02.isolated')\", 2), (\"Lemma('sequester.v.05.isolate')\", 1), (\"Lemma('isolate.v.01.isolate')\", 4), (\"Lemma('isolate.v.02.isolate')\", 1)])\n",
      "collecting tokens for  appetite\n",
      "indices:    {27207, 5642, 27210, 5738, 5617, 27222, 18395, 26975}\n",
      "dict_items([(\"Lemma('appetite.n.01.appetite')\", 4)])\n",
      "collecting tokens for  caused\n",
      "indices:    {32641, 24831, 21637, 32649, 33162, 20242, 32658, 13716, 13717, 12566, 28439, 2326, 12697, 32665, 3354, 20380, 27552, 14496, 5538, 3105, 20640, 32675, 5539, 10275, 11048, 1062, 6442, 7850, 30764, 2989, 26799, 2993, 5553, 305, 5300, 32690, 2999, 12093, 2495, 24257, 25798, 5575, 10951, 21703, 23119, 12752, 13776, 30931, 22997, 22619, 12508, 22622, 20192, 23265, 12259, 11497, 20074, 32497, 9590, 32631, 16383}\n",
      "dict_items([(\"Lemma('cause.v.01.cause')\", 26), (\"Lemma('induce.v.02.cause')\", 17)])\n",
      "collecting tokens for  stimulation\n",
      "indices:    {4228, 21897, 4205, 30799, 12752, 16018, 19602, 30814, 27838}\n",
      "dict_items([(\"Lemma('stimulation.n.01.stimulation')\", 4), (\"Lemma('stimulation.n.02.stimulation')\", 1)])\n",
      "collecting tokens for  announcement\n",
      "indices:    {21252, 16906, 15757, 21285, 24617, 22835, 11451, 22589, 25024, 24130, 20422, 20679, 36681, 24022, 32473, 485, 25832, 4595, 22646, 22650}\n",
      "dict_items([(\"Lemma('announcement.n.01.announcement')\", 3), (\"Lemma('announcement.n.02.announcement')\", 2)])\n",
      "collecting tokens for  award\n",
      "indices:    {21570, 517, 14855, 21579, 14892, 14861}\n",
      "dict_items([(\"Lemma('award.n.01.award')\", 3)])\n",
      "collecting tokens for  chapter\n",
      "indices:    {15610}\n",
      "dict_items([(\"Lemma('chapter.n.01.chapter')\", 1)])\n",
      "collecting tokens for  legs\n",
      "indices:    {7552, 7810, 22274, 13573, 35592, 28556, 28955, 31390, 17183, 17184, 8865, 10913, 36257, 7974, 23336, 5676, 10927, 6320, 8882, 1587, 9013, 3639, 1594, 1983, 34880, 9409, 1986, 34882, 29001, 18505, 2001, 3667, 24790, 17239, 2013, 7648, 22243, 31471, 36719, 6900, 20084, 1535}\n",
      "dict_items([(\"Lemma('leg.n.01.leg')\", 19), (\"Lemma('leg.n.02.leg')\", 5), (\"Lemma('leg.n.03.leg')\", 1)])\n",
      "collecting tokens for  overhead\n",
      "indices:    {21860, 22760, 29289, 4617, 4587, 11148, 32714, 30573, 35695, 2001, 5462, 25303, 19512, 17561, 18654}\n",
      "dict_items([(\"Lemma('operating_expense.n.01.overhead')\", 3), (\"Lemma('overhead.r.01.overhead')\", 1), (\"Lemma('overhead.a.01.overhead')\", 2), (\"Lemma('overhead.r.02.overhead')\", 2)])\n",
      "collecting tokens for  conceive\n",
      "indices:    {27846, 33132, 17420, 7598, 2159, 3086, 29237, 31582}\n",
      "dict_items([(\"Lemma('conceive.v.03.conceive')\", 1), (\"Lemma('gestate.v.01.conceive')\", 4)])\n",
      "collecting tokens for  seeks\n",
      "indices:    {23559, 11048, 14700, 4655, 31919, 20815, 12241, 28185}\n",
      "dict_items([(\"Lemma('try.v.01.seek')\", 4), (\"Lemma('search.v.01.seek')\", 2), (\"Lemma('seek.v.01.seek')\", 2)])\n",
      "collecting tokens for  orders\n",
      "indices:    {11777, 23330, 35490, 36933, 7845, 8006, 22408, 24009, 32810, 15591, 8071, 22766, 35773, 32179, 35542, 31261, 31358}\n",
      "dict_items([(\"Lemma('order.n.01.order')\", 3), (\"Lemma('order.n.07.order')\", 1)])\n",
      "collecting tokens for  zero\n",
      "indices:    {18755, 3367, 4490, 4877, 4302, 4303, 2996, 14040}\n",
      "dict_items([(\"Lemma('nothing.n.01.zero')\", 2), (\"Lemma('zero.s.01.zero')\", 2), (\"Lemma('zero.n.02.zero')\", 2)])\n",
      "collecting tokens for  greenwich\n",
      "indices:    {21129}\n",
      "dict_items([])\n",
      "collecting tokens for  currently\n",
      "indices:    {2749, 28711}\n",
      "dict_items([(\"Lemma('presently.r.02.currently')\", 1)])\n",
      "collecting tokens for  facing\n",
      "indices:    {25858}\n",
      "dict_items([(\"Lemma('confront.v.02.face')\", 1)])\n",
      "collecting tokens for  combined\n",
      "indices:    {21377, 7, 21899, 31757, 4622, 31633, 13851, 32668, 14242, 16044, 21302, 14909, 14910, 32063, 1089, 16194, 21825, 1090, 11208, 2009, 32858, 347, 353, 25826, 13420, 20205, 21114, 31869}\n",
      "dict_items([(\"Lemma('compound.v.02.combine')\", 7), (\"Lemma('combine.v.04.combine')\", 2), (\"Lemma('unite.v.03.combine')\", 4), (\"Lemma('combined.a.01.combined')\", 1), (\"Lemma('compound.v.05.combine')\", 2), (\"Lemma('aggregate.v.02.combine')\", 1)])\n",
      "collecting tokens for  millions\n",
      "indices:    {24192, 25096, 21006, 23696, 27936, 36129, 418, 25121, 34341, 27431, 21420, 12207, 14515, 31283, 2228, 2236, 5437, 5310, 2241, 21827, 26825, 17364, 17365, 27992, 17370, 31706, 11867, 22493, 27996, 20192, 101, 20205, 26095, 20214, 11897, 11900}\n",
      "dict_items([(\"Lemma('million.n.01.million')\", 4)])\n",
      "collecting tokens for  physician\n",
      "indices:    {19841, 257, 30787, 30778, 21317, 2219, 21614, 2222, 12255, 24955, 27420, 24958, 24959}\n",
      "dict_items([(\"Lemma('doctor.n.01.physician')\", 5)])\n",
      "collecting tokens for  injured\n",
      "indices:    {256, 19841, 27808, 291, 20740, 12453, 21442, 4903, 3395, 27243, 5069, 10669, 21170, 27475, 30551, 7645}\n",
      "dict_items([(\"Lemma('injured.a.01.injured')\", 4), (\"Lemma('injure.v.01.injure')\", 11)])\n",
      "collecting tokens for  singer\n",
      "indices:    {27048}\n",
      "dict_items([])\n",
      "collecting tokens for  anonymous\n",
      "indices:    {31587, 18212, 30894, 14097, 82, 21683, 18292, 18228, 18198, 85, 84, 23930}\n",
      "dict_items([(\"Lemma('anonymous.a.01.anonymous')\", 7), (\"Lemma('anonymous.s.02.anonymous')\", 1)])\n",
      "collecting tokens for  plains\n",
      "indices:    {21589}\n",
      "dict_items([])\n",
      "collecting tokens for  aged\n",
      "indices:    {31587, 20199, 10585, 24969, 20041, 20173, 20174, 29040, 36368, 27475, 30101, 11160, 20185, 36412, 20191}\n",
      "dict_items([(\"Lemma('aged.s.01.aged')\", 1), (\"Lemma('aged.n.01.aged')\", 1), (\"Lemma('age.v.01.age')\", 1)])\n",
      "collecting tokens for  garland\n",
      "indices:    {48}\n",
      "dict_items([])\n",
      "collecting tokens for  par\n",
      "indices:    {25888, 22916, 14246, 22983, 28104, 524, 22988, 530, 26390, 22971, 22909, 22973}\n",
      "dict_items([(\"Lemma('par.n.01.par')\", 2), (\"Lemma('equality.n.02.par')\", 1)])\n",
      "collecting tokens for  newport\n",
      "indices:    {1138}\n",
      "dict_items([])\n",
      "collecting tokens for  ignore\n",
      "indices:    {36000, 14657, 27844, 15402, 17009, 24915, 25812, 36309, 28282, 28283, 14652}\n",
      "dict_items([(\"Lemma('ignore.v.01.ignore')\", 4), (\"Lemma('dismiss.v.01.ignore')\", 6), (\"Lemma('neglect.v.04.ignore')\", 1)])\n",
      "collecting tokens for  rush\n",
      "indices:    {20880, 20793, 16733, 33447}\n",
      "dict_items([(\"Lemma('rush.n.02.rush')\", 1), (\"Lemma('rush.v.01.rush')\", 1)])\n",
      "collecting tokens for  motor\n",
      "indices:    {32387, 32388, 32267, 32286, 33961, 24879, 14641, 33461, 10811, 20412, 29885, 29890, 712, 4040, 32330, 714, 30166, 10713, 32356, 30441, 24567, 22009}\n",
      "dict_items([(\"Lemma('motor.n.01.motor')\", 3)])\n",
      "collecting tokens for  underlying\n",
      "indices:    {30241, 1018, 4964, 28105, 22825, 16333, 4911, 4212, 26647, 13658, 5019}\n",
      "dict_items([(\"Lemma('underlie.v.01.underlie')\", 3), (\"Lemma('implicit_in.s.01.underlying')\", 5)])\n",
      "collecting tokens for  shortage\n",
      "indices:    {20640, 25025, 14721, 25796, 32903, 21516, 21518, 12272, 20657, 13776, 11699, 21784}\n",
      "dict_items([(\"Lemma('dearth.n.01.shortage')\", 1), (\"Lemma('deficit.n.01.shortage')\", 3)])\n",
      "collecting tokens for  carries\n",
      "indices:    {289, 23618, 27095, 32452, 22436, 31366, 1128, 21256, 26506, 10737, 5458, 25395, 32244, 2230, 10711, 20185, 32507, 21692}\n",
      "dict_items([(\"Lemma('carry.v.02.carry')\", 2), (\"Lemma('carry.v.17.carry')\", 1), (\"Lemma('stock.v.01.carry')\", 1), (\"Lemma('carry.v.04.carry')\", 3), (\"Lemma('carry.v.05.carry')\", 1), (\"Lemma('carry.v.10.carry')\", 1), (\"Lemma('carry.v.12.carry')\", 1), (\"Lemma('carry.n.01.carry')\", 1), (\"Lemma('hold.v.11.carry')\", 1), (\"Lemma('behave.v.02.carry')\", 1), (\"Lemma('transport.v.02.carry')\", 1)])\n",
      "collecting tokens for  aimed\n",
      "indices:    {26722, 32452, 30537, 12522, 12235, 16300, 28142, 18224, 28144, 32149, 22806, 22810}\n",
      "dict_items([(\"Lemma('aim.v.02.aim')\", 3), (\"Lemma('target.v.01.aim')\", 1), (\"Lemma('drive.v.11.aim')\", 2), (\"Lemma('calculate.v.05.aim')\", 3), (\"Lemma('aim.v.01.aim')\", 3)])\n",
      "collecting tokens for  antique\n",
      "indices:    {29665, 29666, 11110, 2600, 29613, 9327, 29556, 2590}\n",
      "dict_items([(\"Lemma('antique.s.02.antique')\", 2), (\"Lemma('antique.s.01.antique')\", 2)])\n",
      "collecting tokens for  pretending\n",
      "indices:    {35329, 37001, 6413, 34584, 34578, 34964, 2645, 30200, 10426, 35325, 6842}\n",
      "dict_items([(\"Lemma('dissemble.v.03.pretend')\", 5), (\"Lemma('feign.v.01.pretend')\", 6)])\n",
      "collecting tokens for  antibody\n",
      "indices:    {3584, 3585, 3589, 3558, 3590, 3534, 3542, 3513, 3514, 3549, 3518}\n",
      "dict_items([(\"Lemma('antibody.n.01.antibody')\", 9)])\n",
      "collecting tokens for  hurry\n",
      "indices:    {35490, 36182}\n",
      "dict_items([(\"Lemma('travel_rapidly.v.01.hurry')\", 1)])\n",
      "collecting tokens for  rounded\n",
      "indices:    {17754, 22147, 2026, 8846}\n",
      "dict_items([(\"Lemma('rounded.a.01.rounded')\", 2)])\n",
      "collecting tokens for  slim\n",
      "indices:    {26036}\n",
      "dict_items([])\n",
      "collecting tokens for  glory\n",
      "indices:    {13793, 7221, 12902}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('glory.n.01.glory')\", 1), (\"Lemma('glory.n.02.glory')\", 1)])\n",
      "collecting tokens for  dominated\n",
      "indices:    {28165, 26379, 2347, 33259, 2353, 2423}\n",
      "dict_items([(\"Lemma('predominate.v.01.dominate')\", 3)])\n",
      "collecting tokens for  realism\n",
      "indices:    {2146, 16803, 14426, 13638, 26855, 28329, 23819, 23820, 2413, 36122, 1102, 2706, 13650, 13622, 2137, 1082, 13851, 1116}\n",
      "dict_items([(\"Lemma('realism.n.03.realism')\", 1), (\"Lemma('realism.n.01.realism')\", 3), (\"Lemma('reality.n.02.realism')\", 1)])\n",
      "collecting tokens for  confederate\n",
      "indices:    {31996}\n",
      "dict_items([])\n",
      "collecting tokens for  flag\n",
      "indices:    {30244, 6281, 7721, 13039, 31826, 2332, 8508, 8505, 25018, 35739, 25020, 19359}\n",
      "dict_items([(\"Lemma('flag.v.02.flag')\", 1), (\"Lemma('masthead.n.01.flag')\", 1)])\n",
      "collecting tokens for  sigh\n",
      "indices:    {34460, 5826, 27266, 10956, 35631, 31826, 10133, 26904, 7772}\n",
      "dict_items([(\"Lemma('sigh.n.01.sigh')\", 4), (\"Lemma('sigh.v.02.sigh')\", 1)])\n",
      "collecting tokens for  traditions\n",
      "indices:    {14690, 26308, 31717, 13834, 14379, 14380, 14381, 31790, 31826, 27738, 2331}\n",
      "dict_items([(\"Lemma('tradition.n.01.tradition')\", 2), (\"Lemma('custom.n.02.tradition')\", 4)])\n",
      "collecting tokens for  verdict\n",
      "indices:    {21350, 21351, 21352, 21673, 21356, 21357, 21678, 12207, 21679, 20849, 21334, 21336, 21339}\n",
      "dict_items([(\"Lemma('verdict.n.01.verdict')\", 1)])\n",
      "collecting tokens for  neighbor\n",
      "indices:    {21370, 14059, 24259}\n",
      "dict_items([(\"Lemma('neighbor.n.01.neighbor')\", 1)])\n",
      "collecting tokens for  mickey\n",
      "indices:    {34079}\n",
      "dict_items([])\n",
      "collecting tokens for  attend\n",
      "indices:    {13185, 25985, 13187, 29956, 27398, 22406, 22407, 29190, 16266, 1423, 13182, 9622, 8360, 22327, 28605, 20803, 21448, 21452, 21328, 21459, 20571, 24928, 33121, 36962, 24553, 28265, 25707, 109, 13166, 111, 14445, 25844, 13172, 13174, 9204, 23293, 25470}\n",
      "dict_items([(\"Lemma('attend.v.01.attend')\", 26), (\"Lemma('attend.v.02.attend')\", 1), (\"Lemma('serve.v.10.attend')\", 1)])\n",
      "collecting tokens for  academy\n",
      "indices:    {11282}\n",
      "dict_items([(\"Lemma('academy.n.02.academy')\", 1)])\n",
      "collecting tokens for  vienna\n",
      "indices:    {22593}\n",
      "dict_items([])\n",
      "collecting tokens for  thinks\n",
      "indices:    {1028, 19464, 27103, 27243, 19468, 19565, 23438, 5903, 11914, 10833, 20460, 113, 24022, 27415, 13494, 33628, 19487}\n",
      "dict_items([(\"Lemma('think.v.02.think')\", 2), (\"Lemma('think.v.01.think')\", 10), (\"Lemma('intend.v.01.think')\", 1), (\"Lemma('think.v.03.think')\", 2)])\n",
      "collecting tokens for  enormous\n",
      "indices:    {24194, 10905, 6173, 4385, 30755, 15525, 22950, 3501, 7729, 27057, 7354, 5438, 2623, 9411, 8773, 31176, 9162, 31564, 11345, 28628, 31191, 25561, 28510, 26086, 10224, 2164, 34425, 31483, 7165}\n",
      "dict_items([(\"Lemma('enormous.s.01.enormous')\", 16)])\n",
      "collecting tokens for  accuracy\n",
      "indices:    {15296, 2947, 28931, 2951, 29099, 26317, 18735, 11281, 11378, 28531, 28529, 29078, 16183, 29880, 28889}\n",
      "dict_items([(\"Lemma('accuracy.n.02.accuracy')\", 2), (\"Lemma('accuracy.n.01.accuracy')\", 4)])\n",
      "collecting tokens for  continuously\n",
      "indices:    {30816, 11585, 34150, 13767, 15147, 4364, 4365, 14223, 5520, 23952, 32752, 2160, 2931, 26677, 11674, 30175}\n",
      "dict_items([(\"Lemma('continuously.r.01.continuously')\", 6), (\"Lemma('endlessly.r.02.continuously')\", 4)])\n",
      "collecting tokens for  differential\n",
      "indices:    {32904, 33218, 3100}\n",
      "dict_items([(\"Lemma('differential.a.01.differential')\", 1)])\n",
      "collecting tokens for  equation\n",
      "indices:    {22656, 28938, 4364, 4365, 2957, 4372, 4373, 28951, 2995, 3380, 28857, 28858, 16188, 7361, 15691, 28880, 28881, 28883, 22743, 28891, 4572, 28892}\n",
      "dict_items([(\"Lemma('equation.n.01.equation')\", 7)])\n",
      "collecting tokens for  guards\n",
      "indices:    {11747, 35812, 8581, 8582, 35948, 22540, 7959, 8592, 8561, 20756, 8597, 9943, 8602}\n",
      "dict_items([(\"Lemma('guard.n.01.guard')\", 9)])\n",
      "collecting tokens for  menace\n",
      "indices:    {10754, 12238, 8597, 24630, 27194, 5852, 29949, 21502}\n",
      "dict_items([(\"Lemma('menace.n.01.menace')\", 4)])\n",
      "collecting tokens for  kiss\n",
      "indices:    {9601, 8424, 35309, 17838, 9615, 5712, 35768, 10491, 10078, 9599}\n",
      "dict_items([(\"Lemma('snog.v.01.kiss')\", 6), (\"Lemma('kiss.n.01.kiss')\", 3)])\n",
      "collecting tokens for  actors\n",
      "indices:    {22432, 26593, 33252, 6311, 30906, 37036, 1009, 32978, 2388, 2458, 30747, 32925, 1022}\n",
      "dict_items([(\"Lemma('actor.n.01.actor')\", 5)])\n",
      "collecting tokens for  contemporary\n",
      "indices:    {30115, 22153, 1226, 31882, 31660, 28078, 22138, 24734, 25372, 14654, 24767}\n",
      "dict_items([(\"Lemma('contemporary.s.01.contemporary')\", 2)])\n",
      "collecting tokens for  venture\n",
      "indices:    {5026, 21891, 12142, 33166, 1493, 4982, 37143, 1430, 1209, 12123, 31134}\n",
      "dict_items([(\"Lemma('guess.v.02.venture')\", 3), (\"Lemma('venture.v.01.venture')\", 1), (\"Lemma('venture.n.01.venture')\", 2), (\"Lemma('venture.n.03.venture')\", 1), (\"Lemma('speculation.n.03.venture')\", 1)])\n",
      "collecting tokens for  woke\n",
      "indices:    {6691, 10757, 36967, 34844, 35036, 19701, 9270, 34937, 3612}\n",
      "dict_items([(\"Lemma('wake.v.01.wake')\", 2)])\n",
      "collecting tokens for  bells\n",
      "indices:    {7003, 13867}\n",
      "dict_items([(\"Lemma('bell.n.01.bell')\", 1)])\n",
      "collecting tokens for  dialysis\n",
      "indices:    {3552, 3555, 3588, 3582, 3559, 3562, 3566, 3540, 3573, 3542, 3550}\n",
      "dict_items([(\"Lemma('dialysis.n.01.dialysis')\", 11)])\n",
      "collecting tokens for  j.\n",
      "indices:    {5140}\n",
      "dict_items([])\n",
      "collecting tokens for  landing\n",
      "indices:    {12515, 21732, 21733, 9351, 9352, 23337, 17483, 18891, 1997, 17486, 2002, 34099, 34548, 30546, 28503, 7736, 17561, 30557}\n",
      "dict_items([(\"Lemma('landing.n.02.landing')\", 1), (\"Lemma('landing.n.01.landing')\", 6), (\"Lemma('land.v.01.land')\", 4)])\n",
      "collecting tokens for  greg\n",
      "indices:    {18785}\n",
      "dict_items([(\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  bitterness\n",
      "indices:    {17217, 17220, 35588, 19206, 26764, 8850, 7767, 26201, 24791, 34940, 12702}\n",
      "dict_items([(\"Lemma('bitterness.n.02.bitterness')\", 1), (\"Lemma('resentment.n.01.bitterness')\", 5)])\n",
      "collecting tokens for  stick\n",
      "indices:    {36752, 24081, 29524, 18836, 22293, 18840}\n",
      "dict_items([(\"Lemma('adhere.v.06.stick')\", 1), (\"Lemma('stick.n.03.stick')\", 2), (\"Lemma('lodge.v.02.stick')\", 1)])\n",
      "collecting tokens for  wheels\n",
      "indices:    {28708, 13060, 27044, 12228, 28745, 27052, 34669, 18286, 19279, 19283, 19284, 7796, 21526, 29174, 19190, 19257, 30557}\n",
      "dict_items([(\"Lemma('wheel.n.01.wheel')\", 7)])\n",
      "collecting tokens for  trailers\n",
      "indices:    {28640, 11907, 28645, 28646, 32421, 27052, 28691, 32409, 28639}\n",
      "dict_items([])\n",
      "collecting tokens for  craft\n",
      "indices:    {23840, 23971, 28685, 32630}\n",
      "dict_items([])\n",
      "collecting tokens for  instrumental\n",
      "indices:    {26338, 1090, 24718, 1806, 26321, 27860, 34740, 34741}\n",
      "dict_items([(\"Lemma('instrumental.a.01.instrumental')\", 2)])\n",
      "collecting tokens for  texture\n",
      "indices:    {22144, 706, 22536, 26313, 19178, 14664, 5358, 1617, 1778, 5363, 14681, 7611, 14428, 29565, 19551}\n",
      "dict_items([(\"Lemma('texture.n.01.texture')\", 7), (\"Lemma('texture.n.02.texture')\", 3), (\"Lemma('texture.n.03.texture')\", 1)])\n",
      "collecting tokens for  heels\n",
      "indices:    {28976, 698}\n",
      "dict_items([])\n",
      "collecting tokens for  rider\n",
      "indices:    {21673, 35628, 6894, 15504, 6902, 6903, 12535}\n",
      "dict_items([(\"Lemma('rider.n.01.rider')\", 4), (\"Lemma('rider.n.02.rider')\", 1)])\n",
      "collecting tokens for  empty\n",
      "indices:    {10760, 4873, 18570, 8847, 17555, 34068, 10262, 14615, 8857, 31002, 7195, 14617, 18297, 13599, 17314, 9380, 17061, 26534, 25638, 7974, 9385, 13610, 33579, 25132, 13615, 34481, 27964, 18109, 27965, 16959, 35008, 17739, 16849, 36177, 34897, 17753, 18267, 7773, 9437, 9183, 36963, 30054, 27370, 1389, 15857, 18038, 7671, 6265, 7163}\n",
      "dict_items([(\"Lemma('empty.a.01.empty')\", 26), (\"Lemma('empty.s.02.empty')\", 5)])\n",
      "collecting tokens for  calf\n",
      "indices:    {24227, 12101, 20084, 31572, 30268, 36638}\n",
      "dict_items([(\"Lemma('calf.n.01.calf')\", 2)])\n",
      "collecting tokens for  shipments\n",
      "indices:    {11777, 35943, 32458, 14991, 14992, 22006}\n",
      "dict_items([(\"Lemma('cargo.n.01.shipment')\", 2), (\"Lemma('dispatch.n.02.shipment')\", 1)])\n",
      "collecting tokens for  hong\n",
      "indices:    {36453}\n",
      "dict_items([])\n",
      "collecting tokens for  kong\n",
      "indices:    {36453}\n",
      "dict_items([])\n",
      "collecting tokens for  expanding\n",
      "indices:    {26816, 27681, 13376, 24610, 5178, 20553, 2377, 26825, 23472, 27888, 14899, 2714, 13368, 34746, 11868, 11901, 2335}\n",
      "dict_items([(\"Lemma('inflate.v.01.expand')\", 1), (\"Lemma('expand.v.01.expand')\", 2), (\"Lemma('expand.v.02.expand')\", 2), (\"Lemma('expand.v.03.expand')\", 1), (\"Lemma('boom.v.05.expand')\", 1)])\n",
      "collecting tokens for  pony\n",
      "indices:    {35545, 28555, 35628}\n",
      "dict_items([])\n",
      "collecting tokens for  animals\n",
      "indices:    {2144, 3456, 3395, 26180, 21710, 32696, 35388}\n",
      "dict_items([(\"Lemma('animal.n.01.animal')\", 2)])\n",
      "collecting tokens for  hesperus\n",
      "indices:    {34456}\n",
      "dict_items([])\n",
      "collecting tokens for  jack\n",
      "indices:    {34428}\n",
      "dict_items([])\n",
      "collecting tokens for  convey\n",
      "indices:    {11328, 9601, 27105, 33724, 20651, 13164, 1778, 22394, 31388}\n",
      "dict_items([(\"Lemma('carry.v.04.convey')\", 4), (\"Lemma('convey.v.01.convey')\", 5)])\n",
      "collecting tokens for  highways\n",
      "indices:    {24174}\n",
      "dict_items([])\n",
      "collecting tokens for  investigations\n",
      "indices:    {33027, 3205, 33049, 33065, 3244, 3053, 33070, 4271, 15726, 33046, 30231, 33048, 31289, 12346, 33051, 20508}\n",
      "dict_items([(\"Lemma('investigation.n.02.investigation')\", 3), (\"Lemma('probe.n.01.investigation')\", 3)])\n",
      "collecting tokens for  stripped\n",
      "indices:    {5826, 5828, 8805, 36004, 5095, 35273, 6956, 20634, 1951}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('denude.v.01.strip')\", 1), (\"Lemma('deprive.v.01.strip')\", 5), (\"Lemma('undress.v.01.strip')\", 1), (\"Lemma('leach.v.03.strip')\", 1), (\"Lemma('strip.v.03.strip')\", 1)])\n",
      "collecting tokens for  tales\n",
      "indices:    {865}\n",
      "dict_items([])\n",
      "collecting tokens for  requiring\n",
      "indices:    {4928, 20227, 15259, 29864, 1327, 3957, 23893, 23705, 15355, 1951}\n",
      "dict_items([(\"Lemma('necessitate.v.01.require')\", 9), (\"Lemma('command.v.02.require')\", 1)])\n",
      "collecting tokens for  searching\n",
      "indices:    {8704, 36929, 24323, 15524, 28356, 1291, 18219, 3613}\n",
      "dict_items([(\"Lemma('search.v.02.search')\", 3), (\"Lemma('inquisitory.s.01.searching')\", 1), (\"Lemma('search.v.01.search')\", 1)])\n",
      "collecting tokens for  circulation\n",
      "indices:    {12640, 736, 30563, 28355, 1765, 24676, 101, 27240, 7696, 14832, 20727, 37015, 28346}\n",
      "dict_items([(\"Lemma('circulation.n.01.circulation')\", 4), (\"Lemma('circulation.n.02.circulation')\", 1)])\n",
      "collecting tokens for  evidenced\n",
      "indices:    {3137, 28129, 33253, 1317, 33254, 4715, 31791, 30226, 4211, 3574, 31194, 15327}\n",
      "dict_items([(\"Lemma('attest.v.01.evidence')\", 8), (\"Lemma('testify.v.02.evidence')\", 3), (\"Lemma('tell.v.07.evidence')\", 1)])\n",
      "collecting tokens for  yearly\n",
      "indices:    {28051}\n",
      "dict_items([])\n",
      "collecting tokens for  flow\n",
      "indices:    {2947, 7556, 1020, 3983, 5520, 26515, 20632, 5531, 29724, 1563, 22820, 12197, 5543, 5544, 2860, 2861, 29228, 27439, 7159, 25014, 14263, 16443, 2876, 2878, 3135, 22850, 2883, 1861, 27979, 11388, 2902, 3799, 2904, 18905, 3547, 11391, 21729, 14818, 14819, 2917, 26601, 27242, 12523, 27243, 11499, 2927, 11376, 2929, 3824, 11379, 2932, 35959, 12793, 28924, 2942, 22527}\n",
      "dict_items([(\"Lemma('flow.n.03.flow')\", 3), (\"Lemma('flow.n.01.flow')\", 15), (\"Lemma('flow.v.01.flow')\", 7), (\"Lemma('run.v.06.flow')\", 3), (\"Lemma('flow.n.04.flow')\", 3), (\"Lemma('flow.n.02.flow')\", 7), (\"Lemma('stream.n.02.flow')\", 1), (\"Lemma('stream.n.04.flow')\", 1)])\n",
      "collecting tokens for  hr\n",
      "indices:    {5520, 5526, 5527, 5528, 5530, 5531, 5533, 5535, 5552, 5554, 3523, 3525, 3529, 5581, 5582, 3537, 3538, 5589, 3554, 3556, 3559, 5493}\n",
      "dict_items([(\"Lemma('hour.n.01.hr')\", 22)])\n",
      "collecting tokens for  transportation\n",
      "indices:    {23670}\n",
      "dict_items([])\n",
      "collecting tokens for  500\n",
      "indices:    {24066, 29322, 29706, 20755, 15125, 24598, 3098, 14877, 21667, 20391, 21805, 6065, 12722, 27061, 4159, 26051, 31043, 29136, 850, 20690, 23506, 3559, 12135, 21618, 20724, 21884}\n",
      "dict_items([(\"Lemma('five_hundred.s.01.500')\", 9)])\n",
      "collecting tokens for  morton\n",
      "indices:    {21801}\n",
      "dict_items([])\n",
      "collecting tokens for  staggered\n",
      "indices:    {20192, 6913, 17986, 7108, 20389, 33894, 11753, 35052, 34291, 21369, 34910}\n",
      "dict_items([(\"Lemma('stagger.v.01.stagger')\", 3), (\"Lemma('stagger.v.02.stagger')\", 4), (\"Lemma('stagger.v.03.stagger')\", 1)])\n",
      "collecting tokens for  fighting\n",
      "indices:    {12807}\n",
      "dict_items([])\n",
      "collecting tokens for  issued\n",
      "indices:    {32643, 32004, 34695, 28039, 22410, 4751, 12306, 29203, 21139, 4754, 21783, 36632, 24735, 28065, 29474, 5039, 59, 20160, 12225, 33093, 30279, 33095, 20298, 23890, 854, 11481, 26729, 33005, 33006, 32496, 21105, 33009, 756, 22645, 33020, 33021, 5118}\n",
      "dict_items([(\"Lemma('issue.v.03.issue')\", 10), (\"Lemma('publish.v.02.issue')\", 15), (\"Lemma('issue.v.02.issue')\", 8), (\"Lemma('issue.v.04.issue')\", 4)])\n",
      "collecting tokens for  1910\n",
      "indices:    {21856, 5153, 22019, 20356, 20360, 33005, 5366, 20350}\n",
      "dict_items([])\n",
      "collecting tokens for  prescribed\n",
      "indices:    {25184, 30209, 14871, 33005, 14894, 15543, 1560, 15290, 5275}\n",
      "dict_items([(\"Lemma('order.v.03.prescribe')\", 4), (\"Lemma('prescribed.s.01.prescribed')\", 2), (\"Lemma('appointed.s.03.prescribed')\", 1)])\n",
      "collecting tokens for  adult\n",
      "indices:    {13250, 24548, 21576, 23561, 11880, 28619, 23504, 22353, 27603, 15187, 33014, 27385, 15674, 33020, 33021, 33022}\n",
      "dict_items([(\"Lemma('adult.s.01.adult')\", 1), (\"Lemma('adult.n.01.adult')\", 2)])\n",
      "collecting tokens for  printed\n",
      "indices:    {1378, 8709, 13799, 6760, 138, 32492, 21261, 9582, 9424, 29841, 28401, 947, 1429, 24759, 21275, 10621}\n",
      "dict_items([(\"Lemma('print.v.01.print')\", 9)])\n",
      "collecting tokens for  contact\n",
      "indices:    {24544, 14690, 3045, 11880, 19600, 14707, 8247, 22648, 29725, 4958}\n",
      "dict_items([(\"Lemma('contact.n.01.contact')\", 4), (\"Lemma('contact.n.07.contact')\", 1), (\"Lemma('contact.n.03.contact')\", 1)])\n",
      "collecting tokens for  vacuum\n",
      "indices:    {8473, 3240, 11980, 2061, 34576, 3280, 3250, 10746, 23666, 17109, 3254, 30104, 3257, 3258, 3256}\n",
      "dict_items([(\"Lemma('vacuum.n.01.vacuum')\", 11)])\n",
      "collecting tokens for  hastily\n",
      "indices:    {30885, 7333, 33928, 9929, 33932, 9839, 12656, 5107, 18645, 20223}\n",
      "dict_items([(\"Lemma('hurriedly.r.01.hastily')\", 6)])\n",
      "collecting tokens for  mates\n",
      "indices:    {20480, 13090, 33125, 20489, 20497, 34609, 595, 23028, 33174, 20477}\n",
      "dict_items([(\"Lemma('teammate.n.01.mate')\", 2)])\n",
      "collecting tokens for  dried\n",
      "indices:    {7553, 3203, 3556, 27941, 30470, 4135, 4136, 27175, 19397, 3615, 6477, 7668, 16694, 19162, 31482, 3099, 7133, 3199}\n",
      "dict_items([(\"Lemma('dry.v.02.dry')\", 5), (\"Lemma('dried.s.01.dried')\", 3), (\"Lemma('dried.s.02.dried')\", 1), (\"Lemma('dry.v.01.dry')\", 4), (\"Lemma('dry.a.01.dry')\", 1)])\n",
      "collecting tokens for  purchased\n",
      "indices:    {192, 5153, 20067, 24677, 30470, 4583, 12456, 12520, 27750, 5051, 21836, 5200, 5044, 7380, 17686, 21369, 21627}\n",
      "dict_items([(\"Lemma('buy.v.01.purchase')\", 17)])\n",
      "collecting tokens for  flashed\n",
      "indices:    {8832, 35911, 5833, 18665, 19313, 32851, 34067, 18613, 17019, 31293, 33310}\n",
      "dict_items([(\"Lemma('flash.v.01.flash')\", 3), (\"Lemma('flaunt.v.01.flash')\", 2), (\"Lemma('flash.v.02.flash')\", 1), (\"Lemma('flash.v.04.flash')\", 2), (\"Lemma('dart.v.02.flash')\", 2), (\"Lemma('flash.v.06.flash')\", 1)])\n",
      "collecting tokens for  expand\n",
      "indices:    {23558, 11240, 20173, 5009, 499, 23574, 21497, 24218}\n",
      "dict_items([(\"Lemma('boom.v.05.expand')\", 2), (\"Lemma('expand.v.02.expand')\", 2), (\"Lemma('expand.v.01.expand')\", 3), (\"Lemma('expand.v.03.expand')\", 1)])\n",
      "collecting tokens for  boundaries\n",
      "indices:    {23558, 11209, 31180, 33004, 26199, 32504, 24602, 23196}\n",
      "dict_items([(\"Lemma('boundary.n.02.boundary')\", 1)])\n",
      "collecting tokens for  bari\n",
      "indices:    {30268}\n",
      "dict_items([])\n",
      "collecting tokens for  youth\n",
      "indices:    {26786, 21443, 13830, 33800, 31848, 22346, 32655, 9181, 24497, 22525, 23311, 26364, 21661}\n",
      "dict_items([(\"Lemma('young_person.n.01.youth')\", 1), (\"Lemma('youth.n.03.youth')\", 1)])\n",
      "collecting tokens for  comparable\n",
      "indices:    {4192, 3911, 29709, 627, 27765, 11485, 14719}\n",
      "dict_items([(\"Lemma('comparable.a.01.comparable')\", 3)])\n",
      "collecting tokens for  discussion\n",
      "indices:    {22626, 2502, 3911, 15821, 27886, 14643, 15252, 4215, 4792, 26815}\n",
      "dict_items([(\"Lemma('discussion.n.01.discussion')\", 7)])\n",
      "collecting tokens for  landscape\n",
      "indices:    {31424, 35200, 11266, 26947, 11332, 11269, 4998, 11270, 8685, 34478, 22960, 31411, 7795, 13557, 30583, 31451, 11326}\n",
      "dict_items([(\"Lemma('landscape.n.01.landscape')\", 6), (\"Lemma('landscape.n.03.landscape')\", 2)])\n",
      "collecting tokens for  ridge\n",
      "indices:    {3249}\n",
      "dict_items([])\n",
      "collecting tokens for  spy\n",
      "indices:    {6405, 34570, 13965, 21297, 26292, 8181, 21273, 21247}\n",
      "dict_items([(\"Lemma('spy.n.01.spy')\", 2), (\"Lemma('descry.v.01.spy')\", 1)])\n",
      "collecting tokens for  breakfast\n",
      "indices:    {36641, 37028, 36389, 36390, 24360, 10984, 5641, 16680, 19734, 24248, 15417, 29148}\n",
      "dict_items([(\"Lemma('breakfast.n.01.breakfast')\", 4)])\n",
      "collecting tokens for  attempting\n",
      "indices:    {23685, 9354, 26122, 9357, 24087, 13464, 22807, 4125, 5282, 25638, 30384, 24888, 24896, 27332, 27852, 2134, 18018, 15230, 21759}\n",
      "dict_items([(\"Lemma('try.v.01.attempt')\", 14), (\"Lemma('undertake.v.01.attempt')\", 5)])\n",
      "collecting tokens for  linguists\n",
      "indices:    {16068, 16120, 30266, 16126, 16063}\n",
      "dict_items([(\"Lemma('linguist.n.01.linguist')\", 4)])\n",
      "collecting tokens for  deserves\n",
      "indices:    {29248, 1, 21537, 1504, 22698, 4972, 29934, 1201, 26611, 31828, 16119, 4825, 14620}\n",
      "dict_items([(\"Lemma('deserve.v.01.deserve')\", 13)])\n",
      "collecting tokens for  women\n",
      "indices:    {15465, 20980, 28039}\n",
      "dict_items([(\"Lemma('woman.n.01.woman')\", 1)])\n",
      "collecting tokens for  foundation\n",
      "indices:    {31100}\n",
      "dict_items([])\n",
      "collecting tokens for  aggressive\n",
      "indices:    {16387, 35525, 26220, 11661, 4270, 24974, 22638, 4273, 12049, 24565, 12056, 5471}\n",
      "dict_items([(\"Lemma('aggressive.a.01.aggressive')\", 6)])\n",
      "collecting tokens for  champion\n",
      "indices:    {27290, 211, 21589, 399}\n",
      "dict_items([(\"Lemma('champion.n.01.champion')\", 2)])\n",
      "collecting tokens for  businessman\n",
      "indices:    {21568, 28323, 28324, 21412, 14312, 13899, 14480, 14515}\n",
      "dict_items([(\"Lemma('businessman.n.01.businessman')\", 4)])\n",
      "collecting tokens for  raymond\n",
      "indices:    {21886}\n",
      "dict_items([])\n",
      "collecting tokens for  thornburg\n",
      "indices:    {9979}\n",
      "dict_items([(\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  spend\n",
      "indices:    {9602, 21122, 4866, 9604, 13578, 11788, 29710, 21392, 23185, 34192, 13972, 6933, 22557, 3613, 10144, 13222, 27431, 27432, 27174, 16298, 27433, 31537, 24881, 8243, 8247, 36665, 30398, 29890, 17475, 20422, 31046, 22232, 28506, 5598, 8287, 26722, 30057, 22506, 28652, 21998, 20847, 16245, 36985, 14460}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('spend.v.01.spend')\", 26), (\"Lemma('spend.v.02.spend')\", 12)])\n",
      "collecting tokens for  blind\n",
      "indices:    {18820, 8715, 9491, 17178, 14372, 8616, 4905, 31532, 5296, 4913, 4916, 319, 28354, 31567, 26207, 8035, 8036, 31852, 7664, 12532}\n",
      "dict_items([(\"Lemma('blind.a.01.blind')\", 7), (\"Lemma('blind.s.02.blind')\", 1), (\"Lemma('blind.s.03.blind')\", 2), (\"Lemma('blind.n.01.blind')\", 1), (\"Lemma('blind.n.02.blind')\", 1)])\n",
      "collecting tokens for  concert\n",
      "indices:    {22504, 26403, 22381, 22807}\n",
      "dict_items([])\n",
      "collecting tokens for  consistent\n",
      "indices:    {32390, 25627, 32137, 2794, 14748, 11245, 26509, 32154, 3117, 31920, 2803, 32982, 4855, 5366, 24889, 4666, 16154, 24668}\n",
      "dict_items([(\"Lemma('consistent.a.01.consistent')\", 7)])\n",
      "collecting tokens for  interpretation\n",
      "indices:    {36744, 24333, 30240, 22817, 26795, 4779, 14258, 24764, 31293, 33212, 32454, 13382, 1736, 1481, 26062, 1362, 3923, 27867, 27871, 25191, 11881, 1516, 1517, 31726}\n",
      "dict_items([(\"Lemma('interpretation.n.01.interpretation')\", 8), (\"Lemma('rendition.n.04.interpretation')\", 1), (\"Lemma('interpretation.n.04.interpretation')\", 1)])\n",
      "collecting tokens for  stars\n",
      "indices:    {34920, 28318, 7020, 26614}\n",
      "dict_items([(\"Lemma('star.n.01.star')\", 1)])\n",
      "collecting tokens for  false\n",
      "indices:    {23712, 25349, 1267, 14329, 2238}\n",
      "dict_items([(\"Lemma('false.a.01.false')\", 2)])\n",
      "collecting tokens for  cited\n",
      "indices:    {13697, 17985, 24899, 21924, 20776, 23659, 12014, 11992, 21206, 28151, 31672, 27099, 20380, 639}\n",
      "dict_items([(\"Lemma('mention.v.01.cite')\", 7), (\"Lemma('quote.v.01.cite')\", 1), (\"Lemma('reference.v.01.cite')\", 3), (\"Lemma('mention.v.03.cite')\", 3)])\n",
      "collecting tokens for  chest\n",
      "indices:    {21633, 22148, 10374, 1544, 1545, 12809, 4107, 9104, 31507, 35604, 35608, 1561, 5659, 1564, 7197, 1962, 19884, 19501, 18225, 5682, 9012, 5941, 1973, 35131, 34880, 26432, 1989, 10572, 35660, 6222, 18257, 2012, 23778, 6244, 2021, 17000, 35560, 26218, 35564, 7277, 11380, 35574, 2686}\n",
      "dict_items([(\"Lemma('thorax.n.02.chest')\", 26), (\"Lemma('chest.n.02.chest')\", 1)])\n",
      "collecting tokens for  advice\n",
      "indices:    {18045, 2728, 26091, 15436, 2734, 37170, 18066, 24157, 2270, 12574}\n",
      "dict_items([(\"Lemma('advice.n.01.advice')\", 7)])\n",
      "collecting tokens for  childish\n",
      "indices:    {16708, 16709, 1518, 8334, 26195, 35124, 16629, 13561, 9146, 9695}\n",
      "dict_items([(\"Lemma('childish.s.01.childish')\", 8)])\n",
      "collecting tokens for  frighten\n",
      "indices:    {25280, 16707, 16708, 18309, 16746, 24298, 16750, 16656, 16660}\n",
      "dict_items([(\"Lemma('frighten.v.01.frighten')\", 8), (\"Lemma('frighten.v.02.frighten')\", 1)])\n",
      "collecting tokens for  emotional\n",
      "indices:    {31872, 2308, 4235, 14609, 1939, 4245, 12055, 2328, 17432, 14619, 4251, 4256, 4257, 14625, 4259, 14628, 12195, 2469, 30249, 30251, 30253, 4656, 4275, 26676, 31927, 30775, 14647, 4279, 2494, 4673, 30796, 14669, 27216, 16087, 30814, 12265, 32874, 25706, 15851, 4203, 4206, 4207, 4208, 4724, 4213, 4212, 31226}\n",
      "dict_items([(\"Lemma('emotional.a.01.emotional')\", 18), (\"Lemma('emotional.a.03.emotional')\", 2), (\"Lemma('emotional.a.02.emotional')\", 7)])\n",
      "collecting tokens for  excitement\n",
      "indices:    {28546, 34308, 6411, 6931, 6935, 9628, 4257, 6825, 5300, 7736, 6840, 35257, 26557, 30535, 1737, 21067, 30799, 36066, 30818, 18532, 28391, 4207}\n",
      "dict_items([(\"Lemma('excitation.n.03.excitement')\", 3), (\"Lemma('exhilaration.n.01.excitement')\", 6), (\"Lemma('agitation.n.04.excitement')\", 1), (\"Lemma('excitement.n.02.excitement')\", 1)])\n",
      "collecting tokens for  neurotic\n",
      "indices:    {4257, 4267, 26640, 15859, 4279, 27416, 27098, 11163}\n",
      "dict_items([(\"Lemma('neurotic.a.02.neurotic')\", 1), (\"Lemma('neurotic.a.01.neurotic')\", 3), (\"Lemma('neurotic.n.01.neurotic')\", 1)])\n",
      "collecting tokens for  symptoms\n",
      "indices:    {4257, 4226, 4267, 11531, 9679, 15857, 4274, 11603, 11124, 26902, 33433, 25757}\n",
      "dict_items([(\"Lemma('symptom.n.01.symptom')\", 6), (\"Lemma('symptom.n.02.symptom')\", 3)])\n",
      "collecting tokens for  emotion\n",
      "indices:    {9603, 16006, 14605, 14607, 14608, 14611, 14613, 30235, 4255, 4256, 4257, 14626, 14623, 31918, 5042, 13497, 5969, 26706, 15826, 21334, 8541, 4835, 14577, 7669, 15864}\n",
      "dict_items([(\"Lemma('emotion.n.01.emotion')\", 21)])\n",
      "collecting tokens for  pit\n",
      "indices:    {34184, 31530, 34155, 35916, 34156, 36689, 34162, 8539, 28438, 6392, 14235, 26302, 34175}\n",
      "dict_items([(\"Lemma('pit.n.01.pit')\", 2), (\"Lemma('pit.v.01.pit')\", 1)])\n",
      "collecting tokens for  pride\n",
      "indices:    {27840, 32196, 22095, 34193, 27126, 1047}\n",
      "dict_items([(\"Lemma('pride.n.02.pride')\", 1)])\n",
      "collecting tokens for  teachers\n",
      "indices:    {5604, 5606, 25799, 25801, 158}\n",
      "dict_items([(\"Lemma('teacher.n.01.teacher')\", 3)])\n",
      "collecting tokens for  horizon\n",
      "indices:    {34949, 30600, 2056, 23694, 31376, 31506, 19224, 15390, 4643, 18852, 30630, 11689, 34479, 8885, 11190, 10046, 6367, 27498, 22512, 6391}\n",
      "dict_items([(\"Lemma('horizon.n.01.horizon')\", 6), (\"Lemma('horizon.n.02.horizon')\", 5)])\n",
      "collecting tokens for  grab\n",
      "indices:    {23193, 33922, 9661, 5530}\n",
      "dict_items([(\"Lemma('catch.v.04.grab')\", 1), (\"Lemma('snap_up.v.01.grab')\", 2)])\n",
      "collecting tokens for  thou\n",
      "indices:    {28161, 28258, 28163, 28155, 28159}\n",
      "dict_items([])\n",
      "collecting tokens for  huff\n",
      "indices:    {21787}\n",
      "dict_items([])\n",
      "collecting tokens for  25000\n",
      "indices:    {22179, 25351, 25353, 463, 23249, 31795, 23219, 21782, 25374}\n",
      "dict_items([])\n",
      "collecting tokens for  mortgage\n",
      "indices:    {21889, 36132, 30089, 6104, 6105, 32446}\n",
      "dict_items([(\"Lemma('mortgage.n.01.mortgage')\", 2)])\n",
      "collecting tokens for  extraordinary\n",
      "indices:    {20296, 937, 4905, 31532, 2540, 5328, 28081}\n",
      "dict_items([(\"Lemma('extraordinary.a.01.extraordinary')\", 3), (\"Lemma('extraordinary.s.03.extraordinary')\", 1)])\n",
      "collecting tokens for  competition\n",
      "indices:    {15232, 11648, 21923, 11685, 22791, 8232, 11691, 8236, 11663, 16335, 28574, 28533, 5464, 15230}\n",
      "dict_items([(\"Lemma('competition.n.01.competition')\", 7), (\"Lemma('competition.n.03.competition')\", 2)])\n",
      "collecting tokens for  policies\n",
      "indices:    {21899, 32272, 4625, 32274, 32273, 32149, 4635, 32287, 25888, 4642, 23717, 15402, 20269, 20271, 20279, 32185, 16320, 22339, 22608, 16344, 31717, 32364, 32366, 4721, 25338}\n",
      "dict_items([(\"Lemma('policy.n.01.policy')\", 4), (\"Lemma('policy.n.02.policy')\", 3)])\n",
      "collecting tokens for  scrutiny\n",
      "indices:    {21761, 25089, 16324, 14279, 7304, 22698, 24844, 22029, 34191, 23955, 14201}\n",
      "dict_items([(\"Lemma('scrutiny.n.02.scrutiny')\", 1), (\"Lemma('examination.n.01.scrutiny')\", 3)])\n",
      "collecting tokens for  precious\n",
      "indices:    {32640, 9994, 8110}\n",
      "dict_items([(\"Lemma('cherished.s.01.precious')\", 1), (\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  reluctant\n",
      "indices:    {23264, 24838, 13594, 20045, 5487, 5079, 27129, 9370}\n",
      "dict_items([(\"Lemma('reluctant.s.03.reluctant')\", 1), (\"Lemma('reluctant.s.02.reluctant')\", 2), (\"Lemma('loath.s.01.reluctant')\", 2)])\n",
      "collecting tokens for  succeeded\n",
      "indices:    {31621, 27526, 21266, 9370, 31904, 10272, 39, 5164, 50, 2237, 11069, 35646, 26054, 33228, 5202, 37098, 11499, 9847, 23675}\n",
      "dict_items([(\"Lemma('succeed.v.02.succeed')\", 6), (\"Lemma('succeed.v.01.succeed')\", 13)])\n",
      "collecting tokens for  considered\n",
      "indices:    {5120, 28679, 13328, 31763, 12318, 14388, 4156, 20557, 23637, 9825, 30306, 14439, 15475, 14966, 3707, 19071, 2693, 24200, 2703, 666, 24735, 4769, 32933, 37031, 22706, 32947, 22711, 32953, 701, 36542, 1729, 25284, 11466, 29924, 33000, 14069, 3829, 29949, 12038, 22799, 16152, 22814, 25375, 17701, 15655, 21819, 22844, 25405, 16192, 3396, 1353, 32588, 32602, 17755, 17253, 4970, 17258, 19325, 11653, 31115, 15761, 27540, 17812, 15765, 15766, 2968, 2983, 20394, 27564, 16819, 14778, 21441, 2507, 10188, 21459, 28627, 469, 11749, 27110, 28137, 13291, 25068, 11755, 28139, 11760, 15345, 15346, 12273, 15349, 32246, 12282}\n",
      "dict_items([(\"Lemma('see.v.05.consider')\", 26), (\"Lemma('study.v.03.consider')\", 15), (\"Lemma('consider.v.03.consider')\", 5), (\"Lemma('consider.v.05.consider')\", 4), (\"Lemma('consider.v.04.consider')\", 6)])\n",
      "collecting tokens for  missions\n",
      "indices:    {28039}\n",
      "dict_items([])\n",
      "collecting tokens for  objectives\n",
      "indices:    {32129, 12929, 4620, 14740, 3476, 1815, 14748, 2466, 13992, 2102, 33080, 14026, 11723, 11727, 26197, 14691, 15467, 12268, 32880, 32497, 32498, 15475, 12276, 12414, 32127}\n",
      "dict_items([(\"Lemma('aim.n.02.objective')\", 18)])\n",
      "collecting tokens for  colleges\n",
      "indices:    {25088, 25090, 24207, 22672, 23579, 22683, 13726, 22690, 22695, 22699, 20524, 21430, 21431, 24777, 13770, 13775, 27865, 11881, 13182}\n",
      "dict_items([(\"Lemma('college.n.01.college')\", 4)])\n",
      "collecting tokens for  appreciation\n",
      "indices:    {27329, 25282, 26103, 8452, 27879, 24072, 22569, 25289, 8427, 34734, 2352, 4593, 20242, 32657, 27602, 2551, 12121, 4637}\n",
      "dict_items([(\"Lemma('appreciation.n.01.appreciation')\", 4), (\"Lemma('appreciation.n.05.appreciation')\", 1), (\"Lemma('admiration.n.03.appreciation')\", 1), (\"Lemma('taste.n.03.appreciation')\", 1)])\n",
      "collecting tokens for  hired\n",
      "indices:    {17786, 8228, 6574, 15738}\n",
      "dict_items([(\"Lemma('hire.v.01.hire')\", 3), (\"Lemma('hired.s.01.hired')\", 1)])\n",
      "collecting tokens for  presence\n",
      "indices:    {33222, 36969, 9386, 12491, 3980, 17710, 11122, 18196, 21461, 2487, 6429, 1791}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('presence.n.01.presence')\", 5), (\"Lemma('presence.n.03.presence')\", 1), (\"Lemma('presence.n.04.presence')\", 1), (\"Lemma('presence.n.02.presence')\", 2)])\n",
      "collecting tokens for  opportunities\n",
      "indices:    {23429, 24211, 16285, 8350, 16290, 16294, 16300, 16301, 16306, 13243, 30395, 15292, 12990, 26687, 1856, 16316, 13250, 4678, 13254, 1868, 11260, 29272, 27611, 13278, 12518, 27887, 1903, 12145, 18672, 12147, 32630, 36984, 27900, 27901}\n",
      "dict_items([(\"Lemma('opportunity.n.01.opportunity')\", 23)])\n",
      "collecting tokens for  swim\n",
      "indices:    {10024, 33486}\n",
      "dict_items([(\"Lemma('swim.v.01.swim')\", 1)])\n",
      "collecting tokens for  sins\n",
      "indices:    {6976, 28291, 27399, 6763, 25741, 27502, 24336, 10707, 24278, 22423, 27895, 28191}\n",
      "dict_items([(\"Lemma('sin.n.02.sin')\", 3)])\n",
      "collecting tokens for  brings\n",
      "indices:    {2688, 12931, 15246, 22297, 30235, 30114, 24868, 25764, 32551, 30504, 12329, 30762, 27053, 9396, 26940, 7740, 2112, 15043, 26951, 29131, 2640, 1746, 26976, 2658, 36706, 14579}\n",
      "dict_items([(\"Lemma('bring.v.03.bring')\", 4), (\"Lemma('bring.v.01.bring')\", 10), (\"Lemma('bring.v.02.bring')\", 4), (\"Lemma('bring.v.05.bring')\", 2), (\"Lemma('fetch.v.02.bring')\", 1), (\"Lemma('bring.v.04.bring')\", 1)])\n",
      "collecting tokens for  standards\n",
      "indices:    {12928, 21441, 32931, 2087, 11975, 24332, 12717, 14836, 24887, 24666, 28699, 28093}\n",
      "dict_items([(\"Lemma('criterion.n.02.standard')\", 1), (\"Lemma('standard.n.01.standard')\", 1)])\n",
      "collecting tokens for  institution\n",
      "indices:    {32098, 14182, 12743, 31529, 22729, 23629, 24145, 4022, 32760, 6751}\n",
      "dict_items([(\"Lemma('institution.n.01.institution')\", 2), (\"Lemma('initiation.n.02.institution')\", 1)])\n",
      "collecting tokens for  obligations\n",
      "indices:    {99, 16452, 16453, 25189, 25191, 16456, 2059, 25451, 24115, 32180, 21427, 212, 20250, 28092, 32255}\n",
      "dict_items([(\"Lemma('duty.n.01.obligation')\", 6)])\n",
      "collecting tokens for  cruz\n",
      "indices:    {29176}\n",
      "dict_items([])\n",
      "collecting tokens for  adapted\n",
      "indices:    {32129, 16162, 12100, 9349, 14088, 33034, 751, 30805, 15672, 30397, 12798}\n",
      "dict_items([(\"Lemma('adapt.v.01.adapt')\", 6), (\"Lemma('adjust.v.03.adapt')\", 1), (\"Lemma('adapted.s.01.adapted')\", 1)])\n",
      "collecting tokens for  minnesota\n",
      "indices:    {27006}\n",
      "dict_items([])\n",
      "collecting tokens for  selection\n",
      "indices:    {26112, 23555, 15752, 3469, 1814, 32922, 32925, 15653, 15655, 3881, 21674, 15672, 11705, 16060, 32956, 27841, 15939, 29508, 21572, 5453, 15441, 468, 32986, 32987, 11611, 26088, 1902}\n",
      "dict_items([(\"Lemma('choice.n.02.selection')\", 12), (\"Lemma('selection.n.02.selection')\", 2), (\"Lemma('choice.n.01.selection')\", 1)])\n",
      "collecting tokens for  anxiety\n",
      "indices:    {15674, 32891, 32861}\n",
      "dict_items([])\n",
      "collecting tokens for  behaved\n",
      "indices:    {8033, 12675, 9610, 27276, 37169, 26550, 8408, 10141}\n",
      "dict_items([(\"Lemma('act.v.02.behave')\", 6), (\"Lemma('behave.v.02.behave')\", 1)])\n",
      "collecting tokens for  masterpiece\n",
      "indices:    {419, 23141, 13841, 24466, 11093, 13814, 11222, 14426}\n",
      "dict_items([(\"Lemma('masterpiece.n.02.masterpiece')\", 2), (\"Lemma('masterpiece.n.01.masterpiece')\", 4)])\n",
      "collecting tokens for  continent\n",
      "indices:    {12708, 23214, 23695, 12431, 34487, 11449, 9147, 25500}\n",
      "dict_items([(\"Lemma('continent.n.01.continent')\", 3), (\"Lemma('continent.n.02.Continent')\", 1)])\n",
      "collecting tokens for  alfred\n",
      "indices:    {21957}\n",
      "dict_items([])\n",
      "collecting tokens for  mentioned\n",
      "indices:    {32385, 14850, 2690, 26753, 18310, 32524, 11918, 3856, 1041, 8344, 5657, 32409, 5662, 25631, 16159, 11425, 3362, 4256, 3498, 4142, 22706, 6066, 15924, 19124, 30262, 32958, 3010, 21315, 36163, 25794, 4930, 31684, 2888, 25416, 17352, 18251, 14149, 31689, 31177, 26959, 20942, 21972, 28374, 14423, 24538, 3420, 1759, 16096, 17377, 23141, 29287, 19560, 32361, 18025, 29933, 23278, 12271, 15992, 15994, 14719}\n",
      "dict_items([(\"Lemma('note.v.01.mention')\", 12), (\"Lemma('mention.v.01.mention')\", 26), (\"Lemma('mention.v.03.mention')\", 2)])\n",
      "collecting tokens for  insane\n",
      "indices:    {8035, 8036, 7816, 18952, 35982, 25617, 2449, 18515, 6931, 2610, 34677, 33879, 6907}\n",
      "dict_items([(\"Lemma('insane.a.01.insane')\", 8), (\"Lemma('harebrained.s.01.insane')\", 1)])\n",
      "collecting tokens for  correctly\n",
      "indices:    {13289, 2027, 1586, 4211, 21944, 28121, 4955, 28892, 669}\n",
      "dict_items([(\"Lemma('correctly.r.01.correctly')\", 6)])\n",
      "collecting tokens for  attractive\n",
      "indices:    {34822, 26631, 25993, 28554, 26639, 8088, 1702, 20405, 22073, 1852, 31037, 13507, 1861, 1096, 24392, 26317, 26335, 28134, 32492, 23672, 4731, 27007}\n",
      "dict_items([(\"Lemma('attractive.a.01.attractive')\", 4), (\"Lemma('attractive.s.02.attractive')\", 3)])\n",
      "collecting tokens for  operates\n",
      "indices:    {22112, 32706, 21156, 20615, 22343, 22731, 31215, 32724, 2232, 13246}\n",
      "dict_items([(\"Lemma('operate.v.01.operate')\", 5), (\"Lemma('operate.v.03.operate')\", 2), (\"Lemma('function.v.01.operate')\", 3)])\n",
      "collecting tokens for  athlete\n",
      "indices:    {23000, 8417, 522, 1932}\n",
      "dict_items([(\"Lemma('athlete.n.01.athlete')\", 2)])\n",
      "collecting tokens for  tables\n",
      "indices:    {4741, 12940, 18540, 15696, 30480, 14844}\n",
      "dict_items([(\"Lemma('table.n.01.table')\", 3)])\n",
      "collecting tokens for  joan\n",
      "indices:    {17371}\n",
      "dict_items([(\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  baker\n",
      "indices:    {21370}\n",
      "dict_items([])\n",
      "collecting tokens for  technology\n",
      "indices:    {164}\n",
      "dict_items([])\n",
      "collecting tokens for  ribbon\n",
      "indices:    {3713, 21602, 5987, 3684, 169, 19251, 19252, 22520, 6937, 7802, 21598}\n",
      "dict_items([(\"Lemma('ribbon.n.01.ribbon')\", 5)])\n",
      "collecting tokens for  muddy\n",
      "indices:    {33827, 19466, 19279, 6930, 19251, 6931, 18678, 8568, 20029}\n",
      "dict_items([(\"Lemma('mucky.s.02.muddy')\", 1), (\"Lemma('boggy.s.01.muddy')\", 7)])\n",
      "collecting tokens for  hay\n",
      "indices:    {1632, 18254, 5072, 1649, 30004, 30100, 2231, 13592, 13591, 29982}\n",
      "dict_items([(\"Lemma('hay.n.01.hay')\", 6)])\n",
      "collecting tokens for  intelligent\n",
      "indices:    {27079, 139, 2476, 33294, 26033, 9364, 12278, 25278}\n",
      "dict_items([(\"Lemma('healthy.s.04.intelligent')\", 1), (\"Lemma('intelligent.s.02.intelligent')\", 2), (\"Lemma('intelligent.a.01.intelligent')\", 1)])\n",
      "collecting tokens for  unconscious\n",
      "indices:    {32027}\n",
      "dict_items([])\n",
      "collecting tokens for  cap\n",
      "indices:    {17664, 35881, 29684, 31567}\n",
      "dict_items([(\"Lemma('detonator.n.01.cap')\", 1)])\n",
      "collecting tokens for  lookup\n",
      "indices:    {15945, 15916, 15888, 15889, 15958, 15929, 15933}\n",
      "dict_items([(\"Lemma('search.n.03.lookup')\", 7)])\n",
      "collecting tokens for  missed\n",
      "indices:    {16640, 7680, 8452, 22923, 35472, 34323, 34324, 277, 7702, 1175, 932, 933, 24103, 23854, 6453, 26687, 8897, 35010, 36549, 37063, 12235, 7631, 21331, 33107, 26082, 29284, 35569, 8946, 10483, 26739, 631, 9721}\n",
      "dict_items([(\"Lemma('miss.v.03.miss')\", 4), (\"Lemma('miss.v.07.miss')\", 3), (\"Lemma('miss.v.02.miss')\", 7), (\"Lemma('miss.v.01.miss')\", 7), (\"Lemma('miss.v.05.miss')\", 3), (\"Lemma('neglect.v.01.miss')\", 4), (\"Lemma('miss.v.06.miss')\", 3)])\n",
      "collecting tokens for  summary\n",
      "indices:    {32544, 8452, 3366, 33096, 3913, 16332, 25937, 33079, 3708}\n",
      "dict_items([(\"Lemma('summary.n.01.summary')\", 5)])\n",
      "collecting tokens for  stored\n",
      "indices:    {16008, 15883, 15895, 36122, 15900, 7197, 15901, 12703, 35107, 4005, 15910, 4135, 15915, 3247, 3252, 15925, 14277, 15943, 24135, 3534, 15186, 11106, 34555}\n",
      "dict_items([(\"Lemma('store.v.01.store')\", 9), (\"Lemma('store.v.02.store')\", 9)])\n",
      "collecting tokens for  `\n",
      "indices:    {29580, 3597, 2830, 2831, 4499, 3092, 13081, 3098, 3099, 3100, 3102, 3231, 3104, 3105, 3106, 1699, 4132, 3232, 3233, 2849, 4136, 4137, 4525, 4142, 3247, 3246, 3252, 29624, 3134, 5567, 5568, 3137, 3138, 3007, 3264, 3015, 3529, 22986, 5580, 3534, 3535, 3278, 3283, 3543, 3290, 3294, 3551, 3550, 3556, 3560, 2798}\n",
      "dict_items([])\n",
      "collecting tokens for  firing\n",
      "indices:    {17664, 21409, 29570, 29538, 35617, 903, 29607, 29578, 28459, 12876, 29581, 30319, 5105, 28408, 11866, 2427, 29565}\n",
      "dict_items([(\"Lemma('open_fire.v.01.fire')\", 4), (\"Lemma('fire.v.05.fire')\", 2), (\"Lemma('fire.v.02.fire')\", 2), (\"Lemma('fire.v.03.fire')\", 1)])\n",
      "collecting tokens for  fired\n",
      "indices:    {29573, 29575, 6921, 6922, 29583, 916, 35097, 21660, 29229, 5934, 29617, 30386, 6196, 20677, 5064, 17228, 29667, 5093, 35442, 29560}\n",
      "dict_items([(\"Lemma('displace.v.03.fire')\", 3), (\"Lemma('fire.v.03.fire')\", 7), (\"Lemma('fire.v.02.fire')\", 2), (\"Lemma('arouse.v.01.fire')\", 1), (\"Lemma('burn.v.01.fire')\", 1), (\"Lemma('open_fire.v.01.fire')\", 5), (\"Lemma('fire.v.05.fire')\", 1)])\n",
      "collecting tokens for  file\n",
      "indices:    {28800, 32706, 23844, 28838, 15598, 23536, 7315, 34324}\n",
      "dict_items([(\"Lemma('file.v.01.file')\", 2), (\"Lemma('file.v.02.file')\", 1)])\n",
      "collecting tokens for  sodium\n",
      "indices:    {5505, 5506, 3272, 3273, 3150, 5585}\n",
      "dict_items([(\"Lemma('sodium.n.01.sodium')\", 1)])\n",
      "collecting tokens for  iodide\n",
      "indices:    {3968, 3938, 3973, 3272, 3273, 3948, 3988, 3959, 3965}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('iodide.n.01.iodide')\", 7)])\n",
      "collecting tokens for  walks\n",
      "indices:    {31940, 22246, 23048, 27144, 1936, 2679, 31037, 20029}\n",
      "dict_items([(\"Lemma('walk.v.02.walk')\", 1), (\"Lemma('walk.v.01.walk')\", 6)])\n",
      "collecting tokens for  techniques\n",
      "indices:    {26560, 16068, 32745, 26729, 32876, 3405, 27091, 11669, 11352, 32122}\n",
      "dict_items([(\"Lemma('technique.n.01.technique')\", 4)])\n",
      "collecting tokens for  superbly\n",
      "indices:    {2400, 25667, 1061, 26693, 30220, 26444, 30255, 31760}\n",
      "dict_items([(\"Lemma('wonderfully.r.01.superbly')\", 2)])\n",
      "collecting tokens for  interview\n",
      "indices:    {23168, 23169, 17415, 30220, 35731, 30233, 30235, 30238, 8351, 30242, 8355, 30248, 30894, 30254, 30256, 15665, 30257, 15662, 20532, 33987, 20549, 21959, 32856, 13407, 32865, 32867, 21756, 10749}\n",
      "dict_items([(\"Lemma('interview.n.01.interview')\", 4), (\"Lemma('consultation.n.01.interview')\", 3), (\"Lemma('interview.v.01.interview')\", 1)])\n",
      "collecting tokens for  successfully\n",
      "indices:    {16384, 30220, 661, 8474, 15519, 21924, 25900, 4914, 28599, 2886, 2761, 1622, 5471, 11872, 1505, 28515, 22757, 15464, 2282, 2553}\n",
      "dict_items([(\"Lemma('successfully.r.01.successfully')\", 14)])\n",
      "collecting tokens for  therapy\n",
      "indices:    {12256, 32899, 15848, 15850, 4239, 4016, 15830, 30233, 4027, 4223}\n",
      "dict_items([(\"Lemma('therapy.n.01.therapy')\", 7)])\n",
      "collecting tokens for  hotels\n",
      "indices:    {20704, 29346, 20706, 29348, 20709, 20711, 23943, 6506, 24430, 24432, 21233, 8787, 7413, 12667, 23133, 2047}\n",
      "dict_items([(\"Lemma('hotel.n.01.hotel')\", 5)])\n",
      "collecting tokens for  effectiveness\n",
      "indices:    {15001, 23968, 20643, 3492, 14756, 14759, 11688, 13993, 4009, 26676, 3386, 23994, 3393, 11734, 30167, 15447, 32352, 4597, 11514, 11263}\n",
      "dict_items([(\"Lemma('effectiveness.n.01.effectiveness')\", 11), (\"Lemma('potency.n.02.effectiveness')\", 3)])\n",
      "collecting tokens for  hypothesis\n",
      "indices:    {1026, 33252, 33220, 33246, 15688, 4842, 33227, 31216, 16114, 15701, 3223, 31134}\n",
      "dict_items([(\"Lemma('hypothesis.n.02.hypothesis')\", 2), (\"Lemma('hypothesis.n.01.hypothesis')\", 4)])\n",
      "collecting tokens for  proposition\n",
      "indices:    {14336, 16326, 14318, 25807, 31216, 27829, 14586, 14588, 6109, 18271}\n",
      "dict_items([(\"Lemma('suggestion.n.02.proposition')\", 2), (\"Lemma('proposition.n.01.proposition')\", 5)])\n",
      "collecting tokens for  theoretical\n",
      "indices:    {2566, 13642, 2986, 3376, 13937, 3059, 15734, 2586, 26812}\n",
      "dict_items([(\"Lemma('theoretical.a.01.theoretical')\", 7)])\n",
      "collecting tokens for  sheets\n",
      "indices:    {20432}\n",
      "dict_items([])\n",
      "collecting tokens for  lincoln\n",
      "indices:    {29306}\n",
      "dict_items([])\n",
      "collecting tokens for  finish\n",
      "indices:    {20097, 22916, 22152, 33298, 37143, 29083, 19615, 17698, 29859, 28838, 28841, 11306, 1585, 30904, 5049, 697, 22850, 707, 29909, 18138, 14560, 29666, 9958, 18414, 14963, 8823, 33274, 5374}\n",
      "dict_items([(\"Lemma('complete.v.01.finish')\", 11), (\"Lemma('finish_up.v.02.finish')\", 2), (\"Lemma('coating.n.02.finish')\", 2), (\"Lemma('finish.v.04.finish')\", 1), (\"Lemma('end.v.01.finish')\", 1)])\n",
      "collecting tokens for  wrapped\n",
      "indices:    {10496, 17665, 7170, 7523, 11111, 11720, 36944, 10483, 11160}\n",
      "dict_items([(\"Lemma('cloaked.s.02.wrapped')\", 2), (\"Lemma('wrap.v.01.wrap')\", 2), (\"Lemma('wind.v.03.wrap')\", 3)])\n",
      "collecting tokens for  prepare\n",
      "indices:    {32513, 25092, 4614, 29447, 30217, 24982, 15000, 1955, 5284, 11940, 1958, 3240, 3243, 28459, 3249, 23229, 29506, 8289, 7523, 28286, 2027, 9581, 16882, 9339, 35710}\n",
      "dict_items([(\"Lemma('cook.v.02.prepare')\", 3), (\"Lemma('prepare.v.05.prepare')\", 4), (\"Lemma('fix.v.12.prepare')\", 9), (\"Lemma('organize.v.05.prepare')\", 2), (\"Lemma('prepare.v.03.prepare')\", 2), (\"Lemma('train.v.01.prepare')\", 1)])\n",
      "collecting tokens for  critic\n",
      "indices:    {13637, 27910, 31739, 6062, 25648, 20753, 14580, 27029, 10744, 27161, 26394, 21179, 14653}\n",
      "dict_items([(\"Lemma('critic.n.01.critic')\", 3), (\"Lemma('critic.n.02.critic')\", 1)])\n",
      "collecting tokens for  cleaning\n",
      "indices:    {34321, 3179, 8293, 3158}\n",
      "dict_items([(\"Lemma('cleaning.n.01.cleaning')\", 2), (\"Lemma('clean.v.01.clean')\", 1)])\n",
      "collecting tokens for  involves\n",
      "indices:    {28942, 32016, 11032, 14624, 32187, 32962, 13638, 1353, 14797, 28880, 4693, 3159, 1112, 32472, 14679, 16222, 27886, 3184, 14577, 31218, 12278, 13307, 10620}\n",
      "dict_items([(\"Lemma('imply.v.05.involve')\", 8), (\"Lemma('necessitate.v.01.involve')\", 3), (\"Lemma('involve.v.05.involve')\", 4), (\"Lemma('involve.v.01.involve')\", 6), (\"Lemma('involve.v.02.involve')\", 2)])\n",
      "collecting tokens for  soil\n",
      "indices:    {3214, 3225, 3226, 16692, 30404, 30406, 36040, 1616, 1618, 35923, 30418, 1625, 30427, 3679, 3173, 3175, 31848, 1643, 8811, 31853, 1647}\n",
      "dict_items([(\"Lemma('dirt.n.02.soil')\", 5), (\"Lemma('soil.n.02.soil')\", 8)])\n",
      "collecting tokens for  inserted\n",
      "indices:    {26112, 11392, 7461, 4940, 30800, 7473, 30801, 1269, 2905, 14780, 33725, 11390}\n",
      "dict_items([(\"Lemma('insert.v.02.insert')\", 3), (\"Lemma('insert.v.01.insert')\", 6), (\"Lemma('tuck.v.01.insert')\", 3)])\n",
      "collecting tokens for  dreams\n",
      "indices:    {33368, 30965}\n",
      "dict_items([])\n",
      "collecting tokens for  feelings\n",
      "indices:    {6787, 24971, 30226, 33184, 32677, 1191, 12210, 4921, 27840, 33227, 13644, 13649, 32850, 32852, 4948, 27478, 32856, 14426, 13661, 7518, 13663, 4578, 13666, 13671, 1384, 15848, 4846, 15857, 15859, 4724, 1143, 4863}\n",
      "dict_items([(\"Lemma('feeling.n.01.feeling')\", 13), (\"Lemma('feeling.n.04.feeling')\", 2), (\"Lemma('impression.n.01.feeling')\", 2), (\"Lemma('feelings.n.01.feelings')\", 4), (\"Lemma('spirit.n.02.feeling')\", 1)])\n",
      "collecting tokens for  fan\n",
      "indices:    {22531, 26918, 4135, 27019, 35693, 13678, 2318, 26288, 4142, 26258, 435, 35696, 30199, 1049, 2327, 1695}\n",
      "dict_items([(\"Lemma('fan.n.01.fan')\", 2), (\"Lemma('fan.v.02.fan')\", 2), (\"Lemma('fan.n.03.fan')\", 2), (\"Lemma('sports_fan.n.01.fan')\", 1)])\n",
      "collecting tokens for  ultimately\n",
      "indices:    {32164, 16172, 9172, 20084, 11065, 23962, 2652}\n",
      "dict_items([(\"Lemma('ultimately.r.01.ultimately')\", 3)])\n",
      "collecting tokens for  unlike\n",
      "indices:    {14456}\n",
      "dict_items([])\n",
      "collecting tokens for  destroy\n",
      "indices:    {23566, 3475, 6009, 28442, 27806, 28447, 30751, 29982, 28449, 28452, 28463, 25263, 21295, 28465, 28470, 25271, 28473, 14523, 28480, 28483, 32069, 21702, 21701, 25160, 25809, 1500, 28509, 4577, 28514, 100, 27370, 5483, 28525, 28532, 14969, 31999}\n",
      "dict_items([(\"Lemma('destroy.v.01.destroy')\", 23), (\"Lemma('destroy.v.02.destroy')\", 12), (\"Lemma('demolish.v.03.destroy')\", 1)])\n",
      "collecting tokens for  thayer\n",
      "indices:    {17413}\n",
      "dict_items([(\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  prayer\n",
      "indices:    {1409}\n",
      "dict_items([])\n",
      "collecting tokens for  supper\n",
      "indices:    {34712, 8794, 36531, 30495}\n",
      "dict_items([(\"Lemma('supper.n.01.supper')\", 1)])\n",
      "collecting tokens for  authorities\n",
      "indices:    {59, 13251, 32525, 2247}\n",
      "dict_items([(\"Lemma('government.n.01.authorities')\", 2), (\"Lemma('authority.n.02.authority')\", 1)])\n",
      "collecting tokens for  remarked\n",
      "indices:    {12416, 34701, 2575, 13199, 10915, 34723, 423, 429, 9399, 27967, 34752, 17346, 20546, 10947, 24394, 26577, 13137, 13145, 25580, 22511, 10609, 22514, 12537, 14459, 31101, 31742}\n",
      "dict_items([(\"Lemma('note.v.01.remark')\", 26)])\n",
      "collecting tokens for  combination\n",
      "indices:    {26242, 27532, 19468, 29070, 28943, 5267, 3605, 28951, 23448, 26010, 30748, 36640, 2338, 3236, 15527, 29098, 24497, 29106, 21813, 11707, 21820, 25915, 22086, 21838, 26070, 28123, 32617, 26986, 30957, 2799, 2800, 32625, 2682, 15227, 2556, 35839}\n",
      "dict_items([(\"Lemma('combination.n.01.combination')\", 9), (\"Lemma('combination_in_restraint_of_trade.n.01.combination_in_restraint_of_trade')\", 1)])\n",
      "collecting tokens for  ferguson\n",
      "indices:    {26427}\n",
      "dict_items([])\n",
      "collecting tokens for  dragging\n",
      "indices:    {611, 34949, 36153, 25804, 35438, 31601, 23089, 23641, 6906, 36126}\n",
      "dict_items([(\"Lemma('drag.v.05.drag')\", 1), (\"Lemma('puff.v.02.drag')\", 1), (\"Lemma('drag.v.01.drag')\", 3), (\"Lemma('haul.v.01.drag')\", 2)])\n",
      "collecting tokens for  august\n",
      "indices:    {18215}\n",
      "dict_items([(\"Lemma('august.n.01.August')\", 1)])\n",
      "collecting tokens for  satisfactory\n",
      "indices:    {21632, 12168, 22668, 15762, 16154, 15525, 4134, 2985, 14767, 3248, 32433, 16434, 16051, 4919, 24891, 25282, 5190, 31694, 30545, 4434, 13784, 11610, 22237, 31072, 17763, 12136, 3438, 3318, 5497, 3454}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('satisfactory.s.02.satisfactory')\", 7), (\"Lemma('satisfactory.a.01.satisfactory')\", 14)])\n",
      "collecting tokens for  pipe\n",
      "indices:    {10466, 10563, 22021, 10567, 33615, 31601, 19510, 10582, 30076}\n",
      "dict_items([(\"Lemma('pipe.n.01.pipe')\", 4), (\"Lemma('pipe.n.02.pipe')\", 1)])\n",
      "collecting tokens for  smoke\n",
      "indices:    {12620, 34277}\n",
      "dict_items([(\"Lemma('smoke.v.01.smoke')\", 1)])\n",
      "collecting tokens for  pattern\n",
      "indices:    {24576, 25669, 13358, 4243, 7188, 29589, 7192, 1436, 4988}\n",
      "dict_items([(\"Lemma('form.n.03.pattern')\", 4), (\"Lemma('pattern.n.05.pattern')\", 1), (\"Lemma('convention.n.02.pattern')\", 1)])\n",
      "collecting tokens for  desperate\n",
      "indices:    {13376, 36128, 12450, 26114, 24806, 13863, 19368, 36137, 18569, 2251, 2654, 20423, 24943, 35634, 21722, 13374}\n",
      "dict_items([(\"Lemma('despairing.s.01.desperate')\", 7), (\"Lemma('desperate.n.01.desperate')\", 1)])\n",
      "collecting tokens for  prosecution\n",
      "indices:    {25858, 22755, 15333, 15302, 12209, 5112, 20154, 22780}\n",
      "dict_items([(\"Lemma('prosecution.n.01.prosecution')\", 3), (\"Lemma('prosecution.n.02.prosecution')\", 1)])\n",
      "collecting tokens for  refusal\n",
      "indices:    {32038, 15782, 15302, 25456, 9617, 27827, 27828, 18043, 12701}\n",
      "dict_items([(\"Lemma('refusal.n.01.refusal')\", 4), (\"Lemma('refusal.n.02.refusal')\", 1)])\n",
      "collecting tokens for  contents\n",
      "indices:    {14594, 23843, 5383, 20039, 37001, 9325, 15950, 13390, 5521, 31351, 15931, 3259, 35420, 15869, 7198}\n",
      "dict_items([(\"Lemma('content.n.01.content')\", 10), (\"Lemma('content.n.05.content')\", 1)])\n",
      "collecting tokens for  sugar\n",
      "indices:    {37001, 21004, 30490, 27037, 29487, 29233, 29236, 29498, 21702, 14024, 29643, 29515, 7115, 33614, 29517, 33613, 15313, 29650, 33618, 29652, 29525, 33624, 7393, 7400, 26993}\n",
      "dict_items([(\"Lemma('sugar.n.01.sugar')\", 4)])\n",
      "collecting tokens for  partial\n",
      "indices:    {5447, 31111, 3468, 13710, 13488, 11761, 26258, 4055}\n",
      "dict_items([(\"Lemma('partial.s.01.partial')\", 5), (\"Lemma('partial.a.02.partial')\", 1)])\n",
      "collecting tokens for  encouraged\n",
      "indices:    {30090, 28564, 25240, 8737, 16294, 4777, 1972, 14008, 34753, 24130, 25283, 21705, 14538, 5071, 26959, 11732, 11738, 33119, 32864, 12269, 12270, 21236, 27260}\n",
      "dict_items([(\"Lemma('promote.v.01.encourage')\", 16), (\"Lemma('encourage.v.02.encourage')\", 4), (\"Lemma('encourage.v.03.encourage')\", 1)])\n",
      "collecting tokens for  ideal\n",
      "indices:    {27523, 30828, 31693, 1040, 13628}\n",
      "dict_items([(\"Lemma('ideal.s.02.ideal')\", 1), (\"Lemma('ideal.s.01.ideal')\", 1)])\n",
      "collecting tokens for  intention\n",
      "indices:    {25731, 34948, 1797, 27525, 19335, 530, 1304, 12699, 26652, 27809, 23330, 20392, 31920, 35764, 14398, 30785, 27077, 30282, 27091, 18262, 24670, 22496, 1508}\n",
      "dict_items([(\"Lemma('purpose.n.01.intention')\", 8)])\n",
      "collecting tokens for  cover\n",
      "indices:    {7552, 28964, 14887, 142, 29520, 15191, 29240}\n",
      "dict_items([(\"Lemma('top.n.09.cover')\", 1), (\"Lemma('cover.v.02.cover')\", 1), (\"Lemma('cover.v.01.cover')\", 2), (\"Lemma('cover.v.04.cover')\", 1), (\"Lemma('traverse.v.01.cover')\", 1)])\n",
      "collecting tokens for  relationships\n",
      "indices:    {35202, 14219, 32908, 28942, 31887, 11666, 15384, 16414, 31907, 27823, 32569, 11967, 22339, 5571, 11982, 24301, 33135, 32113, 2295, 22648}\n",
      "dict_items([(\"Lemma('relationship.n.03.relationship')\", 2), (\"Lemma('relationship.n.01.relationship')\", 4)])\n",
      "collecting tokens for  hawksley\n",
      "indices:    {20307}\n",
      "dict_items([])\n",
      "collecting tokens for  watch\n",
      "indices:    {33955, 7972, 17604, 36076, 5869, 27439, 20914, 36660, 19098, 33915}\n",
      "dict_items([(\"Lemma('watch.v.01.watch')\", 3), (\"Lemma('watch.v.02.watch')\", 3), (\"Lemma('watch.n.01.watch')\", 2)])\n",
      "collecting tokens for  proceeded\n",
      "indices:    {11106, 12670, 15235, 1381, 11463, 1544, 13833, 20111, 33167, 22962, 36888, 33786, 22972, 4797, 37118, 31231}\n",
      "dict_items([(\"Lemma('continue.v.02.proceed')\", 13), (\"Lemma('go.v.02.proceed')\", 2), (\"Lemma('proceed.v.02.proceed')\", 1)])\n",
      "collecting tokens for  knight\n",
      "indices:    {20936}\n",
      "dict_items([])\n",
      "collecting tokens for  dedicated\n",
      "indices:    {24897, 23910, 13897, 25226, 24107, 13772, 18317, 31627, 23599, 34225, 22707, 19381, 32216, 31741, 20639}\n",
      "dict_items([(\"Lemma('dedicated.a.01.dedicated')\", 3), (\"Lemma('give.v.18.dedicate')\", 3)])\n",
      "collecting tokens for  beloved\n",
      "indices:    {31716, 30788, 10249, 26715, 32202, 32204, 18317, 12846, 36206, 10227, 10707, 7003}\n",
      "dict_items([(\"Lemma('beloved.s.01.beloved')\", 6)])\n",
      "collecting tokens for  delightful\n",
      "indices:    {26337, 12545, 1124, 6775, 1751, 8364, 26253, 1167, 26417, 11026, 26431, 27286, 1687, 26360, 29274, 26365, 1694, 22399}\n",
      "dict_items([(\"Lemma('delightful.s.01.delightful')\", 9)])\n",
      "collecting tokens for  wonderfully\n",
      "indices:    {36672, 14559, 26699, 31390, 32115, 1686, 22399, 990, 26079}\n",
      "dict_items([(\"Lemma('wonderfully.r.01.wonderfully')\", 3)])\n",
      "collecting tokens for  poetic\n",
      "indices:    {24735, 23650, 14623, 25637, 26664, 14676, 26486, 26906, 24764, 22399}\n",
      "dict_items([(\"Lemma('poetic.a.01.poetic')\", 1), (\"Lemma('poetic.s.02.poetic')\", 1)])\n",
      "collecting tokens for  okay\n",
      "indices:    {34476}\n",
      "dict_items([])\n",
      "collecting tokens for  manifestations\n",
      "indices:    {33219, 28137, 28106, 11115, 4972, 5004, 20238, 4053}\n",
      "dict_items([(\"Lemma('manifestation.n.01.manifestation')\", 2), (\"Lemma('manifestation.n.02.manifestation')\", 2)])\n",
      "collecting tokens for  voltaire\n",
      "indices:    {6756}\n",
      "dict_items([(\"Lemma('voltaire.n.01.Voltaire')\", 1)])\n",
      "collecting tokens for  convinced\n",
      "indices:    {12608, 22592, 28226, 15779, 26841, 16901, 25802, 22605, 28269, 25361, 5074, 16063, 1271, 24505, 4635, 34396, 11294, 31679}\n",
      "dict_items([(\"Lemma('convert.v.09.convince')\", 3), (\"Lemma('convinced.a.02.convinced')\", 3)])\n",
      "collecting tokens for  burn\n",
      "indices:    {10304, 19463, 33368, 26545, 30289, 10292, 19221, 6744, 31835, 18653, 5759}\n",
      "dict_items([(\"Lemma('burn.v.01.burn')\", 3), (\"Lemma('burn.v.09.burn')\", 1), (\"Lemma('burn.v.03.burn')\", 2), (\"Lemma('burn.n.01.burn')\", 1), (\"Lemma('tan.n.01.burn')\", 1)])\n",
      "collecting tokens for  agents\n",
      "indices:    {3456, 3394, 3461, 3493, 32458, 3404, 3468, 2222, 3182, 26192, 4278, 3967, 3416, 3484, 21307, 27740, 21247}\n",
      "dict_items([(\"Lemma('agent.n.03.agent')\", 4), (\"Lemma('agent.n.01.agent')\", 7), (\"Lemma('agent.n.02.agent')\", 1)])\n",
      "collecting tokens for  settlers\n",
      "indices:    {12483, 36645, 18245, 12519, 12489, 12464, 23700, 12470, 12503, 18297}\n",
      "dict_items([(\"Lemma('settler.n.01.settler')\", 8)])\n",
      "collecting tokens for  october\n",
      "indices:    {32486}\n",
      "dict_items([])\n",
      "collecting tokens for  posts\n",
      "indices:    {31296, 23714, 22147, 13541, 13542, 30217, 15225, 20557, 36272, 20375, 24915, 20565, 20566, 12503, 31321}\n",
      "dict_items([(\"Lemma('position.n.06.post')\", 1), (\"Lemma('post.n.04.post')\", 1), (\"Lemma('post.n.01.post')\", 1)])\n",
      "collecting tokens for  timber\n",
      "indices:    {7840, 5764, 2736, 34161, 11153, 29941, 29111, 12503, 29053}\n",
      "dict_items([(\"Lemma('lumber.n.01.timber')\", 3), (\"Lemma('timber.n.02.timber')\", 1)])\n",
      "collecting tokens for  lively\n",
      "indices:    {30340, 6407, 26633, 26635, 1170, 23187, 25637, 26034, 36414, 22086, 26064, 26321, 22996, 19553, 13798, 13808, 1137, 26227, 14460}\n",
      "dict_items([(\"Lemma('lively.a.01.lively')\", 7)])\n",
      "collecting tokens for  55\n",
      "indices:    {289, 32476, 21254, 31015, 28972, 12749, 14770, 23418, 27004}\n",
      "dict_items([])\n",
      "collecting tokens for  findings\n",
      "indices:    {15241, 32531, 33047, 17314, 31142, 14764, 27182, 4919, 16184, 4025, 15674, 16195, 12358, 2134, 3806, 27876, 27882, 3948, 24052, 3836, 3837}\n",
      "dict_items([(\"Lemma('determination.n.01.finding')\", 12), (\"Lemma('finding.n.02.finding')\", 1), (\"Lemma('finding.n.03.finding')\", 1)])\n",
      "collecting tokens for  circuit\n",
      "indices:    {20802, 11395, 11403, 24843, 1484, 1491, 31316, 27091, 31322}\n",
      "dict_items([(\"Lemma('tour.n.01.circuit')\", 2), (\"Lemma('circuit.n.01.circuit')\", 1)])\n",
      "collecting tokens for  juvenile\n",
      "indices:    {24104, 20296, 20301, 33838, 27385, 21210}\n",
      "dict_items([])\n",
      "collecting tokens for  dare\n",
      "indices:    {1505, 26564, 1445, 30535, 6058, 36014, 5296, 6898, 11219, 18035, 1267, 33846, 36282, 17502}\n",
      "dict_items([(\"Lemma('make_bold.v.01.dare')\", 6), (\"Lemma('dare.v.02.dare')\", 2)])\n",
      "collecting tokens for  bored\n",
      "indices:    {9156, 30725, 28553, 20041, 20079, 30901, 29912, 29913, 22427, 29724, 31678}\n",
      "dict_items([(\"Lemma('bore.v.02.bore')\", 4), (\"Lemma('blase.s.02.bored')\", 1), (\"Lemma('bore.v.01.bore')\", 2), (\"Lemma('bored.s.01.bored')\", 1)])\n",
      "collecting tokens for  dominican\n",
      "indices:    {23668}\n",
      "dict_items([])\n",
      "collecting tokens for  seized\n",
      "indices:    {30852, 35397, 21415, 24104, 16554, 18891, 33613, 14992, 13649, 8917, 25782, 35413, 24093, 28414}\n",
      "dict_items([(\"Lemma('impound.v.01.seize')\", 3), (\"Lemma('seize.v.01.seize')\", 5), (\"Lemma('appropriate.v.02.seize')\", 4), (\"Lemma('seize.v.02.seize')\", 2)])\n",
      "collecting tokens for  van\n",
      "indices:    {33061, 470}\n",
      "dict_items([])\n",
      "collecting tokens for  possess\n",
      "indices:    {4704, 32899, 3462, 26218, 23087, 4497, 16210, 1299, 11127, 28152, 11098, 28157}\n",
      "dict_items([(\"Lemma('own.v.01.possess')\", 4), (\"Lemma('possess.v.01.possess')\", 8)])\n",
      "collecting tokens for  realistic\n",
      "indices:    {2176, 22146, 3462, 15754, 32398, 32150, 1064, 24883, 20794, 32192, 1101, 14413, 14420, 16088, 32984, 25825, 2147, 22245, 25574, 26218, 25834, 2413, 2169}\n",
      "dict_items([(\"Lemma('realistic.a.01.realistic')\", 10), (\"Lemma('naturalistic.s.01.realistic')\", 1)])\n",
      "collecting tokens for  someone\n",
      "indices:    {16469}\n",
      "dict_items([(\"Lemma('person.n.01.someone')\", 1)])\n",
      "collecting tokens for  stein\n",
      "indices:    {21769}\n",
      "dict_items([])\n",
      "collecting tokens for  hoping\n",
      "indices:    {16513, 35721, 17297, 34076, 25892, 11308, 26798, 9905, 37170, 22978, 36423, 19660, 30927, 36698, 11099, 19293, 5987, 5991, 35693, 11248}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('hope.v.03.hope')\", 3), (\"Lemma('hope.v.02.hope')\", 11), (\"Lemma('hope.v.01.hope')\", 6)])\n",
      "collecting tokens for  vain\n",
      "indices:    {35202, 2307, 5765, 35693, 12952, 12596, 2710, 26200, 9246}\n",
      "dict_items([(\"Lemma('bootless.s.01.vain')\", 2), (\"Lemma('conceited.s.01.vain')\", 3)])\n",
      "collecting tokens for  dim\n",
      "indices:    {7008, 34049, 36001, 6274, 34052, 35693, 17102, 35696, 7889, 28341, 17019, 7386, 35995}\n",
      "dict_items([(\"Lemma('dim.s.02.dim')\", 2), (\"Lemma('dim.s.01.dim')\", 4)])\n",
      "collecting tokens for  titled\n",
      "indices:    {26968, 752, 22449, 30828}\n",
      "dict_items([(\"Lemma('entitle.v.02.title')\", 1)])\n",
      "collecting tokens for  perception\n",
      "indices:    {14153, 14643}\n",
      "dict_items([(\"Lemma('percept.n.01.perception')\", 1), (\"Lemma('perception.n.02.perception')\", 1)])\n",
      "collecting tokens for  feb.\n",
      "indices:    {21937}\n",
      "dict_items([])\n",
      "collecting tokens for  resort\n",
      "indices:    {29344, 27810, 29314, 19078, 31750, 30285, 11310, 23281, 32052, 27287}\n",
      "dict_items([(\"Lemma('fall_back.v.05.resort')\", 5)])\n",
      "collecting tokens for  stravinsky\n",
      "indices:    {11240}\n",
      "dict_items([(\"Lemma('stravinsky.n.01.Stravinsky')\", 1)])\n",
      "collecting tokens for  melody\n",
      "indices:    {1098, 1804, 27981, 14543, 11217, 14546, 36434, 25332, 18842}\n",
      "dict_items([(\"Lemma('tune.n.01.melody')\", 3), (\"Lemma('melody.n.02.melody')\", 2)])\n",
      "collecting tokens for  athletic\n",
      "indices:    {444}\n",
      "dict_items([])\n",
      "collecting tokens for  mental\n",
      "indices:    {2142, 18754, 14436, 2148, 32903, 17403, 17769, 32859, 23628, 4656, 14384, 11990, 4279, 25209, 27, 31166}\n",
      "dict_items([(\"Lemma('mental.a.02.mental')\", 1), (\"Lemma('mental.a.01.mental')\", 7)])\n",
      "collecting tokens for  curt\n",
      "indices:    {18487}\n",
      "dict_items([(\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  jess\n",
      "indices:    {18476}\n",
      "dict_items([(\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  stride\n",
      "indices:    {30816, 35428, 35429, 28964, 24009, 36720, 11058, 19156, 28982, 1657, 27835, 31389, 9598, 35263}\n",
      "dict_items([(\"Lemma('pace.n.04.stride')\", 1)])\n",
      "collecting tokens for  pepper\n",
      "indices:    {29536, 29187, 29635, 30479, 22128, 29653, 30709, 29465, 29181, 29471}\n",
      "dict_items([(\"Lemma('pepper.v.01.pepper')\", 1)])\n",
      "collecting tokens for  finest\n",
      "indices:    {26945, 23108, 26981, 937, 26186, 1163, 22385, 36273, 13812, 14261, 13847}\n",
      "dict_items([])\n",
      "collecting tokens for  tools\n",
      "indices:    {29827, 34691, 20112, 20115, 20120, 29823, 2733, 29872, 2865, 11315, 14261, 2624, 9801, 29898, 29901, 5072, 15441, 11352, 20059, 20060, 20067, 12132, 20072, 23535, 20090, 7935}\n",
      "dict_items([(\"Lemma('instrument.n.02.tool')\", 3), (\"Lemma('tool.n.01.tool')\", 12)])\n",
      "collecting tokens for  sentence\n",
      "indices:    {25864, 25865, 14121, 2280, 30250, 10633, 5295, 6992, 2672, 2225, 10000, 21393, 30393, 32223}\n",
      "dict_items([(\"Lemma('sentence.n.01.sentence')\", 4), (\"Lemma('conviction.n.02.sentence')\", 1), (\"Lemma('prison_term.n.01.sentence')\", 3)])\n",
      "collecting tokens for  characteristics\n",
      "indices:    {2816, 13332, 5531, 33052, 5025, 13992, 15786, 32811, 13997, 33079, 15677, 3404, 26320, 31056, 3799, 26729, 2795, 2796, 32237, 14191, 5489}\n",
      "dict_items([(\"Lemma('feature.n.01.characteristic')\", 11), (\"Lemma('characteristic.n.02.characteristic')\", 3)])\n",
      "collecting tokens for  hollywood\n",
      "indices:    {22338}\n",
      "dict_items([])\n",
      "collecting tokens for  surely\n",
      "indices:    {16593, 26091}\n",
      "dict_items([(\"Lemma('surely.r.01.surely')\", 1)])\n",
      "collecting tokens for  boating\n",
      "indices:    {27072, 28705, 28708, 32439, 28684, 28685, 28663, 28630, 28631, 32440, 28633, 1850, 28635, 28636, 28638, 36543}\n",
      "dict_items([(\"Lemma('boating.n.01.boating')\", 1)])\n",
      "collecting tokens for  ocean\n",
      "indices:    {22298}\n",
      "dict_items([])\n",
      "collecting tokens for  palmer\n",
      "indices:    {549}\n",
      "dict_items([(\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  rounds\n",
      "indices:    {4387, 18215, 22924, 22926, 22927, 4402, 13075, 30387, 11867, 25791}\n",
      "dict_items([(\"Lemma('beat.n.01.round')\", 1), (\"Lemma('round.n.01.round')\", 3), (\"Lemma('round.n.04.round')\", 1)])\n",
      "collecting tokens for  composite\n",
      "indices:    {22153}\n",
      "dict_items([])\n",
      "collecting tokens for  indicating\n",
      "indices:    {14690, 30244, 3236, 20360, 15372, 5583, 10288, 3919, 7956, 32406}\n",
      "dict_items([(\"Lemma('bespeak.v.01.indicate')\", 6), (\"Lemma('argue.v.03.indicate')\", 1), (\"Lemma('indicate.v.02.indicate')\", 2), (\"Lemma('indicate.v.03.indicate')\", 1)])\n",
      "collecting tokens for  savage\n",
      "indices:    {23252, 8468, 23863, 29113, 35198}\n",
      "dict_items([(\"Lemma('barbarous.s.01.savage')\", 1)])\n",
      "collecting tokens for  amateur\n",
      "indices:    {2352, 30266}\n",
      "dict_items([(\"Lemma('amateur.n.01.amateur')\", 1)])\n",
      "collecting tokens for  conservative\n",
      "indices:    {14080, 3719, 27279, 25887, 20521, 14121, 14126, 4784, 16441, 17338, 2493, 25415, 2248, 22857, 844, 23770, 5466, 22874, 94, 5218, 23922}\n",
      "dict_items([(\"Lemma('conservative.a.01.conservative')\", 10), (\"Lemma('conservative.n.01.conservative')\", 1), (\"Lemma('cautious.s.02.conservative')\", 1), (\"Lemma('conservative.s.02.conservative')\", 1)])\n",
      "collecting tokens for  pack\n",
      "indices:    {35427, 22855, 361, 37097, 1529, 7888, 17681, 9460, 31382, 16569, 12476}\n",
      "dict_items([(\"Lemma('pack.v.01.pack')\", 3), (\"Lemma('pack.v.05.pack')\", 1), (\"Lemma('pack.n.03.pack')\", 1), (\"Lemma('pack.n.02.pack')\", 1), (\"Lemma('pack.v.04.pack')\", 1), (\"Lemma('pack.v.02.pack')\", 1)])\n",
      "collecting tokens for  mississippi\n",
      "indices:    {14387}\n",
      "dict_items([(\"Lemma('mississippi.n.02.Mississippi')\", 1)])\n",
      "collecting tokens for  pronounced\n",
      "indices:    {4033, 15718, 22855, 17703, 17228, 1779, 17620, 20725, 29910, 21171, 10142}\n",
      "dict_items([(\"Lemma('pronounce.v.01.pronounce')\", 3), (\"Lemma('pronounce.v.02.pronounce')\", 3), (\"Lemma('marked.s.01.pronounced')\", 4)])\n",
      "collecting tokens for  mae\n",
      "indices:    {17041}\n",
      "dict_items([(\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  bag\n",
      "indices:    {13572, 29462, 13080, 16664, 16670, 17827, 18860, 30899, 7475, 16569, 13754, 7484, 7485, 21318, 18889, 21321, 36682, 7498, 31945, 18891, 35413, 19801, 19803, 19166, 2018, 33385, 34156, 9325, 30974}\n",
      "dict_items([(\"Lemma('bag.n.01.bag')\", 6), (\"Lemma('bag.n.06.bag')\", 1), (\"Lemma('base.n.03.bag')\", 2), (\"Lemma('bag.n.05.bag')\", 1), (\"Lemma('bag.n.04.bag')\", 2)])\n",
      "collecting tokens for  barton\n",
      "indices:    {35911}\n",
      "dict_items([])\n",
      "collecting tokens for  milk\n",
      "indices:    {3425, 9215, 36391}\n",
      "dict_items([(\"Lemma('milk.n.01.milk')\", 2)])\n",
      "collecting tokens for  martyr\n",
      "indices:    {5217, 5317, 5319, 5226, 14358, 5215, 5279}\n",
      "dict_items([(\"Lemma('martyr.n.01.martyr')\", 7)])\n",
      "collecting tokens for  waterfront\n",
      "indices:    {20512, 7683, 23941, 28710, 35718, 28712, 26254, 23964, 28702}\n",
      "dict_items([(\"Lemma('waterfront.n.01.waterfront')\", 1)])\n",
      "collecting tokens for  winning\n",
      "indices:    {384, 515, 651, 32020, 12955, 28957, 32157, 28068, 26664, 298, 12459, 5306, 186, 28484, 21578, 27223, 21594, 21595, 31708, 22878, 22881, 483, 26084, 360, 12399, 245, 1526, 37116}\n",
      "dict_items([(\"Lemma('win.v.01.win')\", 10), (\"Lemma('winning.n.01.winning')\", 1), (\"Lemma('victorious.s.01.winning')\", 2), (\"Lemma('acquire.v.05.win')\", 8)])\n",
      "collecting tokens for  suggests\n",
      "indices:    {26144, 24577, 26115, 25667, 26760, 33260, 30253, 2799, 3953, 25138, 31219, 2676, 14614, 25369, 982, 3449, 12954}\n",
      "dict_items([(\"Lemma('indicate.v.05.suggest')\", 5), (\"Lemma('suggest.v.05.suggest')\", 3), (\"Lemma('hint.v.01.suggest')\", 5), (\"Lemma('suggest.v.03.suggest')\", 3), (\"Lemma('propose.v.01.suggest')\", 1)])\n",
      "collecting tokens for  associations\n",
      "indices:    {14634, 32478, 22102}\n",
      "dict_items([(\"Lemma('association.n.04.association')\", 1)])\n",
      "collecting tokens for  somewhere\n",
      "indices:    {29890, 5768, 34441, 19731, 6392, 17178, 4668, 23935}\n",
      "dict_items([(\"Lemma('somewhere.r.01.somewhere')\", 5)])\n",
      "collecting tokens for  faculty\n",
      "indices:    {27904, 21378, 25988, 27909, 23184, 13203, 36508, 22703, 22706, 22708, 22711, 22715, 2108, 4923, 4929, 27849, 22730, 22731, 22729, 27853, 22734, 27852, 22737, 22739, 22741, 33122, 33130, 27882, 30444, 21628}\n",
      "dict_items([(\"Lemma('faculty.n.01.faculty')\", 2), (\"Lemma('staff.n.03.faculty')\", 2)])\n",
      "collecting tokens for  readiness\n",
      "indices:    {31264, 4580}\n",
      "dict_items([(\"Lemma('set.n.12.readiness')\", 1)])\n",
      "collecting tokens for  jeep\n",
      "indices:    {13090}\n",
      "dict_items([(\"Lemma('jeep.n.01.jeep')\", 1)])\n",
      "collecting tokens for  arrived\n",
      "indices:    {28928, 16893, 26372, 22533, 32902, 30089, 34830, 37016, 37017, 21669, 7591, 28970, 21421, 24752, 9398, 25786, 16187, 19131, 30269, 23874, 23623, 34889, 12492, 19151, 6610, 13394, 18010, 7643, 8288, 36963, 28004, 5990, 30953, 21481, 234, 9836, 5108, 12663, 36987, 7293}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('arrive.v.01.arrive')\", 26)])\n",
      "collecting tokens for  clearing\n",
      "indices:    {20643, 2729, 21195, 10317, 36111, 15413, 11095, 25786, 6207}\n",
      "dict_items([(\"Lemma('clearing.n.01.clearing')\", 1), (\"Lemma('unclutter.v.01.clear')\", 2)])\n",
      "collecting tokens for  squeezed\n",
      "indices:    {22210, 13572, 35944, 6314, 18988, 6925, 35573, 20665, 34843, 21724}\n",
      "dict_items([(\"Lemma('squeeze.v.02.squeeze')\", 4), (\"Lemma('squash.v.01.squeeze')\", 3)])\n",
      "collecting tokens for  urged\n",
      "indices:    {4866, 21891, 21892, 14213, 9, 11, 28175, 15251, 24995, 2212, 23857, 27843, 30033, 21206, 18648, 25179, 1116, 14941, 20833, 36962, 20456, 20846, 23283, 10101, 6774}\n",
      "dict_items([(\"Lemma('urge.v.01.urge')\", 20), (\"Lemma('recommend.v.01.urge')\", 5)])\n",
      "collecting tokens for  convert\n",
      "indices:    {32579, 28069, 4902, 22799, 5234, 29077, 8252, 28926}\n",
      "dict_items([(\"Lemma('convert.n.01.convert')\", 1), (\"Lemma('convert.v.03.convert')\", 1), (\"Lemma('convert.v.01.convert')\", 5)])\n",
      "collecting tokens for  goodness\n",
      "indices:    {4899, 10084, 28389, 4902, 20935, 11268, 17097, 9995, 4815, 10037, 28317, 4863}\n",
      "dict_items([(\"Lemma('good.n.03.goodness')\", 7)])\n",
      "collecting tokens for  curled\n",
      "indices:    {8992, 6244, 10952, 10473, 26539, 36717, 36237, 36754, 33716, 34074}\n",
      "dict_items([(\"Lemma('curl.v.04.curl')\", 1), (\"Lemma('coil.v.03.curl')\", 1)])\n",
      "collecting tokens for  radish\n",
      "indices:    {10951, 10952, 10985, 10955, 10965, 10969, 10970}\n",
      "dict_items([(\"Lemma('radish.n.01.radish')\", 7)])\n",
      "collecting tokens for  song\n",
      "indices:    {29039}\n",
      "dict_items([])\n",
      "collecting tokens for  ambitious\n",
      "indices:    {768, 5955, 5956, 20199, 14568, 26667, 14475, 4749, 27179, 30701, 5424, 14449}\n",
      "dict_items([(\"Lemma('ambitious.a.01.ambitious')\", 4), (\"Lemma('ambitious.s.02.ambitious')\", 4)])\n",
      "collecting tokens for  nice\n",
      "indices:    {26945}\n",
      "dict_items([])\n",
      "collecting tokens for  dear\n",
      "indices:    {14456, 36189, 11095}\n",
      "dict_items([(\"Lemma('beloved.s.01.dear')\", 1)])\n",
      "collecting tokens for  confined\n",
      "indices:    {25408, 16417, 31433, 4013, 32365, 32271, 13360, 14800, 24055, 14398, 13342, 32030}\n",
      "dict_items([(\"Lemma('restrict.v.03.confine')\", 5), (\"Lemma('confine.v.03.confine')\", 3), (\"Lemma('limit.v.02.confine')\", 3)])\n",
      "collecting tokens for  introduction\n",
      "indices:    {37065, 4011, 16144, 25492, 32374, 28439, 26678, 9946, 13882}\n",
      "dict_items([(\"Lemma('introduction.n.02.introduction')\", 2), (\"Lemma('introduction.n.04.introduction')\", 1), (\"Lemma('presentation.n.06.introduction')\", 1)])\n",
      "collecting tokens for  reference\n",
      "indices:    {3080, 9362, 4632, 31898, 28699, 32037, 4011, 4015, 2993, 2994, 2995, 13620, 25022, 20415, 4690, 26323, 22739, 27861, 10711, 3544, 25062, 22249, 23531, 23532, 10732, 26092, 23535, 10736, 10737, 31220, 16117, 15862}\n",
      "dict_items([(\"Lemma('reference.n.06.reference')\", 3), (\"Lemma('reference_book.n.01.reference')\", 2), (\"Lemma('reference_point.n.01.reference')\", 4), (\"Lemma('mention.n.01.reference')\", 4), (\"Lemma('citation.n.03.reference')\", 2), (\"Lemma('character.n.07.reference')\", 1)])\n",
      "collecting tokens for  nowhere\n",
      "indices:    {1376}\n",
      "dict_items([(\"Lemma('nowhere.r.01.nowhere')\", 1)])\n",
      "collecting tokens for  modest\n",
      "indices:    {20193, 26979, 424, 24876, 19352, 13182}\n",
      "dict_items([(\"Lemma('modest.a.01.modest')\", 1), (\"Lemma('modest.s.02.modest')\", 2)])\n",
      "collecting tokens for  imply\n",
      "indices:    {33248, 27776, 30242, 4450, 22787, 27780, 1267, 21750, 8695, 4255}\n",
      "dict_items([(\"Lemma('imply.v.02.imply')\", 5), (\"Lemma('imply.v.01.imply')\", 5)])\n",
      "collecting tokens for  panels\n",
      "indices:    {22147, 22148, 24581, 27014, 24583, 27016, 29833, 22150, 29830, 21147, 29855, 29856, 29859, 29861, 29862, 31269, 29864, 29865, 29866, 37165, 29869, 29871, 34761, 31329, 29174, 34680}\n",
      "dict_items([])\n",
      "collecting tokens for  framework\n",
      "indices:    {29856, 14108, 4600, 9936, 33138, 33141, 32504, 1244}\n",
      "dict_items([(\"Lemma('model.n.01.framework')\", 3), (\"Lemma('framework.n.02.framework')\", 1)])\n",
      "collecting tokens for  structural\n",
      "indices:    {8226, 29830, 32939, 3054, 15118, 16144, 32945}\n",
      "dict_items([(\"Lemma('structural.a.02.structural')\", 1), (\"Lemma('structural.s.04.structural')\", 1), (\"Lemma('structural.a.01.structural')\", 1)])\n",
      "collecting tokens for  stopping\n",
      "indices:    {9152, 36932, 21671, 23815, 30761, 18859, 17676, 5839, 6610, 25426}\n",
      "dict_items([(\"Lemma('stop.v.01.stop')\", 5), (\"Lemma('discontinue.v.01.stop')\", 2), (\"Lemma('stop.v.03.stop')\", 1), (\"Lemma('stop.v.04.stop')\", 1)])\n",
      "collecting tokens for  allen\n",
      "indices:    {22502}\n",
      "dict_items([])\n",
      "collecting tokens for  shear\n",
      "indices:    {1666, 1668, 2964, 2967, 2971, 2984, 2989, 2992, 2993, 2999, 3004, 3006, 3007, 3008, 3010, 3015, 3016, 3022, 3029}\n",
      "dict_items([(\"Lemma('shear.n.01.shear')\", 16), (\"Lemma('shear.v.01.shear')\", 3)])\n",
      "collecting tokens for  h\n",
      "indices:    {29009, 15539, 28990}\n",
      "dict_items([])\n",
      "collecting tokens for  opposed\n",
      "indices:    {23296, 22788, 24970, 31775, 28065, 32418, 22703, 2992, 4783, 830, 16450, 68, 23371, 25164, 14669, 20815, 20816, 15317, 27349, 11742, 5218, 5347, 29924, 11495, 20713, 27890, 27892, 24693, 28150, 1273, 20218, 4988}\n",
      "dict_items([(\"Lemma('oppose.v.01.oppose')\", 15), (\"Lemma('oppose.v.03.oppose')\", 4), (\"Lemma('pit.v.01.oppose')\", 2), (\"Lemma('fight.v.02.oppose')\", 2), (\"Lemma('opposed.a.01.opposed')\", 1)])\n",
      "collecting tokens for  milligrams\n",
      "indices:    {11521, 11525, 11526, 11527, 11528, 11536, 11538, 11540, 11541, 11547, 11555, 11558, 11560, 11561, 11562, 11565, 27184, 11580, 11593, 11606}\n",
      "dict_items([(\"Lemma('milligram.n.01.milligram')\", 19)])\n",
      "collecting tokens for  weekend\n",
      "indices:    {21509, 29832, 24586, 6798, 22162, 25492, 22164, 23, 419, 22954, 23859, 30529, 23367, 30039, 221, 15200, 225, 609, 21491, 9718, 23288}\n",
      "dict_items([(\"Lemma('weekend.n.01.weekend')\", 8)])\n",
      "collecting tokens for  pitching\n",
      "indices:    {419, 421, 614, 358, 680, 233, 24487, 486, 297, 24496, 593, 12532, 22997, 19864, 18460, 607}\n",
      "dict_items([(\"Lemma('flip.v.06.pitch')\", 5), (\"Lemma('pitching.n.01.pitching')\", 7), (\"Lemma('lurch.v.02.pitch')\", 2)])\n",
      "collecting tokens for  projects\n",
      "indices:    {23872, 26753, 32450, 1027, 13094, 14567, 26735, 32177, 14738, 20530, 20532, 32179, 178, 32151, 22874}\n",
      "dict_items([(\"Lemma('undertaking.n.01.project')\", 5)])\n",
      "collecting tokens for  blindness\n",
      "indices:    {14688, 4929, 4933, 4906, 4944, 1264, 9172, 11415}\n",
      "dict_items([(\"Lemma('blindness.n.01.blindness')\", 7)])\n",
      "collecting tokens for  well-known\n",
      "indices:    {14790, 1095, 25161, 4906, 1687, 14136, 30906, 11035, 3037}\n",
      "dict_items([(\"Lemma('well-known.s.01.well-known')\", 6), (\"Lemma('long-familiar.s.01.well-known')\", 1)])\n",
      "collecting tokens for  manage\n",
      "indices:    {30784, 1953, 5380, 11304, 15433, 16520, 9832, 34892, 1101, 10832, 11473, 8312, 3612, 14621}\n",
      "dict_items([(\"Lemma('pull_off.v.03.manage')\", 11), (\"Lemma('cope.v.01.manage')\", 1), (\"Lemma('manage.v.02.manage')\", 2)])\n",
      "collecting tokens for  jump\n",
      "indices:    {18855, 20941, 34639, 10929, 29750}\n",
      "dict_items([(\"Lemma('jump.v.01.jump')\", 1)])\n",
      "collecting tokens for  k\n",
      "indices:    {2849}\n",
      "dict_items([(\"Lemma('kelvin.n.01.K')\", 1)])\n",
      "collecting tokens for  pencil\n",
      "indices:    {36096, 12810, 29581, 17298, 32788, 32802, 29607, 32813, 32814, 32815, 32816, 32817, 32820, 34233, 32828, 32829, 9153, 32834, 32837, 32838, 3654, 17102, 9425, 2268}\n",
      "dict_items([(\"Lemma('pencil.n.01.pencil')\", 6)])\n",
      "collecting tokens for  ribs\n",
      "indices:    {21633, 31457, 19301, 4102, 18932, 34101, 18518, 17589, 34106, 19295}\n",
      "dict_items([(\"Lemma('rib.n.01.rib')\", 4), (\"Lemma('rib.n.02.rib')\", 2)])\n",
      "collecting tokens for  delay\n",
      "indices:    {18496, 15394, 15395, 30340, 5285, 20227, 136, 24872, 1704, 2251, 3886, 23119, 35727, 26385, 26261, 23327}\n",
      "dict_items([(\"Lemma('delay.v.02.delay')\", 3), (\"Lemma('delay.n.01.delay')\", 2), (\"Lemma('delay.n.02.delay')\", 2), (\"Lemma('delay.v.01.delay')\", 1), (\"Lemma('stay.v.06.delay')\", 2)])\n",
      "collecting tokens for  misery\n",
      "indices:    {4899, 12997, 1257, 30250, 2251, 13869, 27440, 13112, 24827, 13823}\n",
      "dict_items([(\"Lemma('misery.n.01.misery')\", 7)])\n",
      "collecting tokens for  jean\n",
      "indices:    {1179}\n",
      "dict_items([])\n",
      "collecting tokens for  brannon\n",
      "indices:    {18167}\n",
      "dict_items([(\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  twisted\n",
      "indices:    {19265, 32772, 35589, 18442, 32810, 34060, 34094, 30991, 6323, 28788, 18451, 34871, 18425, 9626}\n",
      "dict_items([(\"Lemma('writhe.v.01.twist')\", 6), (\"Lemma('twist.v.03.twist')\", 1), (\"Lemma('flex.v.05.twist')\", 1)])\n",
      "collecting tokens for  accomplish\n",
      "indices:    {15873, 8545, 14723, 5351, 15880, 20841, 21161, 25227, 32590, 35986, 1971, 7574, 32311, 7545, 3483}\n",
      "dict_items([(\"Lemma('achieve.v.01.accomplish')\", 5), (\"Lemma('carry_through.v.01.accomplish')\", 10)])\n",
      "collecting tokens for  kayabashi\n",
      "indices:    {8245}\n",
      "dict_items([(\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  restraint\n",
      "indices:    {14596, 32038, 13902, 16368, 14352, 23571, 23897, 15227, 31740}\n",
      "dict_items([(\"Lemma('restraint.n.02.restraint')\", 2), (\"Lemma('restraint.n.01.restraint')\", 2)])\n",
      "collecting tokens for  illustrated\n",
      "indices:    {27680, 705, 15520, 14596, 12902, 522, 3436, 30831, 29812, 11416, 2393, 4286}\n",
      "dict_items([(\"Lemma('exemplify.v.02.illustrate')\", 6), (\"Lemma('illustrate.v.03.illustrate')\", 1), (\"Lemma('illustrate.v.02.illustrate')\", 3)])\n",
      "collecting tokens for  intellectual\n",
      "indices:    {27264, 5250, 14350, 13204, 1308, 16804, 26033, 19768, 11449, 23225, 13630, 21441, 13513, 13264, 10832, 5205, 26845, 26847, 8417, 28001, 26085, 14443, 26093, 4974, 26095, 28015, 31732, 23036}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('intellectual.s.01.intellectual')\", 3), (\"Lemma('intellectual.n.01.intellectual')\", 2), (\"Lemma('intellectual.a.02.intellectual')\", 1)])\n",
      "collecting tokens for  so-called\n",
      "indices:    {27527, 14088, 12299, 30614, 26775, 24217, 153, 14075, 10661, 14251, 8368, 11062, 13513, 2260, 3545, 20329, 12271, 23922, 24820, 32887, 16633, 25338, 32123, 25343}\n",
      "dict_items([(\"Lemma('alleged.s.02.so-called')\", 13)])\n",
      "collecting tokens for  rugged\n",
      "indices:    {30500, 13894, 14183, 969, 28969, 1740, 14189, 13901, 1623, 30904, 29245}\n",
      "dict_items([(\"Lemma('rugged.a.01.rugged')\", 6)])\n",
      "collecting tokens for  colt\n",
      "indices:    {29129, 28973}\n",
      "dict_items([])\n",
      "collecting tokens for  wonderful\n",
      "indices:    {24714, 3598, 10255, 10899, 23831, 8087, 23833, 20890, 10905, 27934, 29470, 20129, 26404, 28964, 28969, 682, 36522, 13865, 26927, 11696, 37170, 33716, 28982, 30391, 30649, 19515, 29248, 26434, 11075, 9156, 25028, 11221, 24919, 27101, 34789, 24933, 8167, 27373, 22518}\n",
      "dict_items([(\"Lemma('fantastic.s.02.wonderful')\", 14)])\n",
      "collecting tokens for  ease\n",
      "indices:    {28960, 28483, 26275, 1251, 32299, 29068, 28973, 15723, 29685, 22614, 28668}\n",
      "dict_items([(\"Lemma('ease.v.01.ease')\", 1), (\"Lemma('still.v.03.ease')\", 1)])\n",
      "collecting tokens for  codes\n",
      "indices:    {28098, 31299, 31300, 4710, 4712, 28009, 29835, 31280, 21300, 31349, 34682, 31355, 31356, 4734, 23711}\n",
      "dict_items([(\"Lemma('code.n.01.code')\", 2)])\n",
      "collecting tokens for  hidden\n",
      "indices:    {5760, 13540, 18855, 16429, 14040, 15865}\n",
      "dict_items([(\"Lemma('hide.v.01.hide')\", 1), (\"Lemma('concealed.s.01.hidden')\", 3)])\n",
      "collecting tokens for  fastened\n",
      "indices:    {29795, 9417, 29802, 29738, 29771, 29774, 31378, 21300, 29748, 29750, 29720, 7167}\n",
      "dict_items([(\"Lemma('fasten.v.01.fasten')\", 10), (\"Lemma('fasten.v.02.fasten')\", 2)])\n",
      "collecting tokens for  lid\n",
      "indices:    {29601, 29602, 29606, 29607, 29608, 29609, 29611, 29612, 29616, 29650, 29587, 29652, 21300, 29590, 29591, 29651}\n",
      "dict_items([])\n",
      "collecting tokens for  insistence\n",
      "indices:    {28131, 22628, 23942, 16202, 17228, 23374, 11056, 31634, 24212, 22645, 15771}\n",
      "dict_items([(\"Lemma('insistence.n.01.insistence')\", 4)])\n",
      "collecting tokens for  realities\n",
      "indices:    {2169, 27842, 2149, 12329, 25419, 1230, 11694, 13304, 22585, 27866, 35837}\n",
      "dict_items([(\"Lemma('reality.n.03.reality')\", 2), (\"Lemma('reality.n.02.reality')\", 1), (\"Lemma('world.n.03.reality')\", 3)])\n",
      "collecting tokens for  realm\n",
      "indices:    {2660, 16713, 12329, 31852, 27541, 4664, 32090, 26458, 13215}\n",
      "dict_items([(\"Lemma('kingdom.n.01.realm')\", 5)])\n",
      "collecting tokens for  panel\n",
      "indices:    {34691, 29831, 18951, 22158, 29858, 29860, 20519, 29869, 21681, 21682, 21683, 18745, 21689, 21690, 24776, 31439, 31440, 20561, 32736, 2033, 20980, 29816}\n",
      "dict_items([(\"Lemma('panel.n.01.panel')\", 1)])\n",
      "collecting tokens for  exhibits\n",
      "indices:    {32708, 32709, 32742, 31433, 32628, 32767}\n",
      "dict_items([])\n",
      "collecting tokens for  displayed\n",
      "indices:    {26914, 22782, 22269, 2709}\n",
      "dict_items([(\"Lemma('expose.v.03.display')\", 3)])\n",
      "collecting tokens for  listening\n",
      "indices:    {19494, 36625, 26448, 33334}\n",
      "dict_items([(\"Lemma('listen.v.01.listen')\", 2), (\"Lemma('listen.v.02.listen')\", 1)])\n",
      "collecting tokens for  jan.\n",
      "indices:    {21275}\n",
      "dict_items([])\n",
      "collecting tokens for  consistency\n",
      "indices:    {32128, 31496, 26893, 29520, 30419, 24627, 30485, 4696, 1690, 3288, 7551}\n",
      "dict_items([(\"Lemma('consistency.n.02.consistency')\", 2), (\"Lemma('consistency.n.01.consistency')\", 2)])\n",
      "collecting tokens for  territory\n",
      "indices:    {33061, 31719}\n",
      "dict_items([])\n",
      "collecting tokens for  wholly\n",
      "indices:    {29985, 35713, 14179, 34340, 16156, 5220, 26722, 25419, 16180, 7861, 29917, 2678, 23544, 1241, 16181, 14652, 5405, 1374}\n",
      "dict_items([(\"Lemma('wholly.r.01.wholly')\", 11)])\n",
      "collecting tokens for  separated\n",
      "indices:    {15872, 35713, 1411, 3090, 15891, 18709, 20888, 8216, 16156, 3878, 26793, 22954, 31147, 8237, 33197, 16446, 31552, 12740, 3273, 28874, 28879, 28760, 10202, 19808, 1505, 1506, 29929, 3049, 9579, 3567, 3570, 31099, 31102}\n",
      "dict_items([(\"Lemma('separate.v.05.separate')\", 2), (\"Lemma('detached.s.02.separated')\", 1), (\"Lemma('separated.s.02.separated')\", 2), (\"Lemma('separate.v.01.separate')\", 10), (\"Lemma('distinguish.v.01.separate')\", 3), (\"Lemma('separate.v.07.separate')\", 1), (\"Lemma('divide.v.01.separate')\", 4), (\"Lemma('separate.v.02.separate')\", 6), (\"Lemma('separate.v.08.separate')\", 1), (\"Lemma('classify.v.01.separate')\", 1)])\n",
      "collecting tokens for  fists\n",
      "indices:    {7108, 6346, 27478, 6461, 17662}\n",
      "dict_items([(\"Lemma('fist.n.01.fist')\", 4)])\n",
      "collecting tokens for  nest\n",
      "indices:    {18341, 8393, 9390, 3632, 3633, 9361, 30737}\n",
      "dict_items([(\"Lemma('nest.n.01.nest')\", 5), (\"Lemma('location.n.01.location')\", 1)])\n",
      "collecting tokens for  opens\n",
      "indices:    {1247, 22307, 6756, 14118, 11914, 11086, 5231, 11028, 20955, 27036, 926, 24191}\n",
      "dict_items([(\"Lemma('open.v.02.open')\", 7), (\"Lemma('open.v.04.open')\", 3), (\"Lemma('open.v.01.open')\", 2)])\n",
      "collecting tokens for  script\n",
      "indices:    {28416, 9893, 20614, 1198, 1042, 9876, 14487, 14557, 24191}\n",
      "dict_items([(\"Lemma('script.n.01.script')\", 6)])\n",
      "collecting tokens for  puts\n",
      "indices:    {24000, 31940, 1574, 10855, 20559, 24016, 32113, 13744, 31668, 32341, 19958, 24148, 17882, 988, 27196}\n",
      "dict_items([(\"Lemma('frame.v.04.put')\", 7), (\"Lemma('put.v.02.put')\", 4), (\"Lemma('put.v.04.put')\", 1), (\"Lemma('set_down.v.04.put_down')\", 1)])\n",
      "collecting tokens for  grows\n",
      "indices:    {1280, 26177, 24547, 1254, 4999, 24742, 1257, 746, 17837, 1294, 31024, 6865, 27954, 23574, 24248, 25374, 24895}\n",
      "dict_items([(\"Lemma('turn.v.07.grow')\", 3), (\"Lemma('grow.v.02.grow')\", 10), (\"Lemma('grow.v.03.grow')\", 3), (\"Lemma('grow.v.04.grow')\", 1)])\n",
      "collecting tokens for  residential\n",
      "indices:    {13381, 5586, 13370, 13371, 13372}\n",
      "dict_items([(\"Lemma('residential.a.01.residential')\", 5)])\n",
      "collecting tokens for  lap\n",
      "indices:    {5655, 7529, 10378, 7593, 19754, 11146, 29743, 9328, 11155, 7604, 5622, 7543, 36888, 32857, 22903}\n",
      "dict_items([(\"Lemma('lap.n.01.lap')\", 11), (\"Lemma('lap.v.01.lap')\", 1)])\n",
      "collecting tokens for  sixty\n",
      "indices:    {5186, 29930, 7955, 25528, 8728, 9561, 7422}\n",
      "dict_items([(\"Lemma('sixty.s.01.sixty')\", 5)])\n",
      "collecting tokens for  prison\n",
      "indices:    {128, 13216, 12642, 35812, 35818, 24695, 25, 11994}\n",
      "dict_items([(\"Lemma('prison.n.01.prison')\", 2)])\n",
      "collecting tokens for  boards\n",
      "indices:    {21188, 27844, 15078, 15077, 23946, 18891, 33870, 24690, 20085, 24695}\n",
      "dict_items([(\"Lemma('board.n.02.board')\", 3)])\n",
      "collecting tokens for  parochial\n",
      "indices:    {24073, 13385, 34382, 27695, 20528, 1392, 22674, 22677, 22678, 22679, 31190, 31706}\n",
      "dict_items([(\"Lemma('parochial.a.01.parochial')\", 2)])\n",
      "collecting tokens for  spreads\n",
      "indices:    {11617, 998, 1256, 18315, 5452, 3857, 22714, 5374}\n",
      "dict_items([(\"Lemma('ranch.n.01.spread')\", 1), (\"Lemma('unfold.v.04.spread')\", 1), (\"Lemma('go_around.v.02.spread')\", 1), (\"Lemma('spread.v.01.spread')\", 3), (\"Lemma('spread.v.03.spread')\", 1), (\"Lemma('spread.v.02.spread')\", 1)])\n",
      "collecting tokens for  deepest\n",
      "indices:    {31331, 15206, 37129, 13802, 4653, 27406, 13655, 27322, 26906, 26013, 27327}\n",
      "dict_items([(\"Lemma('deep.a.03.deep')\", 1), (\"Lemma('deep.s.02.deep')\", 3)])\n",
      "collecting tokens for  fairly\n",
      "indices:    {30209, 15235, 23941, 25736, 6926, 33806, 16144, 11411, 21922, 32420, 21933, 16178, 24626, 12345, 4795, 23101, 17346, 26568, 27217, 2647, 8286, 11107, 26984, 26862, 4590, 24563, 15225, 15996, 29055}\n",
      "dict_items([(\"Lemma('reasonably.r.01.fairly')\", 11), (\"Lemma('fairly.r.02.fairly')\", 3)])\n",
      "collecting tokens for  pink\n",
      "indices:    {24576, 13569, 29572, 22151, 37129, 34698, 9493, 21026, 27175, 29616, 17589, 34871, 7736, 9549, 17102, 9422, 35536, 34637, 34897, 9561, 10585, 19550, 21093, 36326, 30954, 9582, 9719, 35962}\n",
      "dict_items([(\"Lemma('pink.n.01.pink')\", 2), (\"Lemma('pink.s.01.pink')\", 10)])\n",
      "collecting tokens for  heaven\n",
      "indices:    {35139}\n",
      "dict_items([])\n",
      "collecting tokens for  require\n",
      "indices:    {21004, 1702, 5420, 32178, 27702, 25018, 32188, 27711, 11845, 27595, 27599, 28498, 15188, 32598, 30819, 28900, 32613, 2020, 3701, 11774}\n",
      "dict_items([(\"Lemma('necessitate.v.01.require')\", 16), (\"Lemma('command.v.02.require')\", 2), (\"Lemma('ask.v.04.require')\", 2)])\n",
      "collecting tokens for  stern\n",
      "indices:    {10712, 28025, 6450, 19398}\n",
      "dict_items([(\"Lemma('stern.n.01.stern')\", 1), (\"Lemma('austere.s.02.stern')\", 2)])\n",
      "collecting tokens for  discipline\n",
      "indices:    {30816, 2338, 26789, 28007, 28295, 27145, 2665, 37159, 1930, 19369, 11219, 10099, 26037, 25716, 30012, 36511}\n",
      "dict_items([(\"Lemma('discipline.n.01.discipline')\", 2), (\"Lemma('discipline.n.04.discipline')\", 1), (\"Lemma('discipline.n.02.discipline')\", 1), (\"Lemma('discipline.n.03.discipline')\", 2), (\"Lemma('discipline.v.01.discipline')\", 2)])\n",
      "collecting tokens for  neighbors\n",
      "indices:    {21382, 8710, 8722, 21396, 12191, 27425, 13601, 9635, 18212, 29989, 18214, 7335, 27305, 20912, 25139, 34488, 23609, 30012, 14016, 20289, 14019, 14020, 24262, 18247, 14023, 12238, 26194, 11111, 7655, 1642, 25071, 21359, 17013, 20343, 30847}\n",
      "dict_items([(\"Lemma('neighbor.n.01.neighbor')\", 18)])\n",
      "collecting tokens for  failed\n",
      "indices:    {15365, 8590, 21784, 20762, 4123, 23201, 34466, 27683, 13860, 36898, 21673, 4266, 18099, 22580, 19382, 19383, 5303, 14904, 14524, 26045, 15294, 193, 12354, 834, 196, 21701, 21446, 31687, 23420, 20425, 21450, 4939, 19276, 13774, 21456, 24915, 12244, 21588, 15319, 4056, 21336, 15321, 12375, 4833, 26470, 12904, 15337, 6634, 17646, 6769, 24818, 27122, 498, 4087, 3836, 26365}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('fail.v.02.fail')\", 18), (\"Lemma('fail.v.01.fail')\", 26), (\"Lemma('fail.v.03.fail')\", 3)])\n",
      "collecting tokens for  indiana\n",
      "indices:    {29965}\n",
      "dict_items([])\n",
      "collecting tokens for  answering\n",
      "indices:    {4960, 12961, 18434, 18219, 24749, 28368, 9688, 8412}\n",
      "dict_items([(\"Lemma('answer.v.01.answer')\", 6), (\"Lemma('answering.s.01.answering')\", 1), (\"Lemma('answer.v.03.answer')\", 1)])\n",
      "collecting tokens for  demanded\n",
      "indices:    {7040, 25858, 12683, 17932, 12439, 6297, 35354, 7194, 7196, 13211, 21278, 20764, 22560, 25506, 27426, 14500, 17958, 5040, 35004, 24640, 34631, 11080, 5067, 34764, 5069, 10830, 20047, 16343, 11992, 7257, 23771, 8412, 23913, 17771, 17395, 8438, 8056}\n",
      "dict_items([(\"Lemma('demand.v.01.demand')\", 26), (\"Lemma('necessitate.v.01.demand')\", 7), (\"Lemma('demand.v.03.demand')\", 3)])\n",
      "collecting tokens for  spark\n",
      "indices:    {13819}\n",
      "dict_items([])\n",
      "collecting tokens for  tar\n",
      "indices:    {28976}\n",
      "dict_items([])\n",
      "collecting tokens for  sand\n",
      "indices:    {18945, 23810, 22919, 7829, 36893, 31407, 1844, 6334, 7618, 36931, 36932, 6340, 5058, 1866, 27984, 1625, 1642, 5358, 23935}\n",
      "dict_items([(\"Lemma('sand.n.01.sand')\", 9)])\n",
      "collecting tokens for  bounced\n",
      "indices:    {198, 22919, 230, 202, 35434, 19756, 18447, 31440, 6518, 5815, 21788, 9661, 6462}\n",
      "dict_items([(\"Lemma('bounce.v.02.bounce')\", 4), (\"Lemma('bounce.v.04.bounce')\", 1), (\"Lemma('bounce.v.05.bounce')\", 1), (\"Lemma('bounce.v.01.bounce')\", 6)])\n",
      "collecting tokens for  tower\n",
      "indices:    {25889, 7047, 6379, 23339, 10481, 23327}\n",
      "dict_items([(\"Lemma('tower.n.01.tower')\", 2)])\n",
      "collecting tokens for  imitation\n",
      "indices:    {13633, 13636, 13610, 13612, 5363, 5364, 1781, 4982, 8694, 13620, 13625, 13626, 13627, 13622, 13623, 13628}\n",
      "dict_items([(\"Lemma('imitation.n.02.imitation')\", 2), (\"Lemma('fake.s.02.imitation')\", 2), (\"Lemma('imitation.n.01.imitation')\", 9), (\"Lemma('imitation.n.03.imitation')\", 3)])\n",
      "collecting tokens for  southeast\n",
      "indices:    {22667}\n",
      "dict_items([])\n",
      "collecting tokens for  federation\n",
      "indices:    {23973}\n",
      "dict_items([])\n",
      "collecting tokens for  actor\n",
      "indices:    {1153, 1147, 26642, 2459, 32931, 37159, 37165, 26298, 30907, 14524, 14531, 14535, 10826, 10833, 33366, 26591, 26594, 33387, 1007, 33392, 33403, 26236}\n",
      "dict_items([(\"Lemma('actor.n.01.actor')\", 9)])\n",
      "collecting tokens for  mystery\n",
      "indices:    {8384, 5861, 7498, 20120, 13615, 31671, 2136, 441, 13471}\n",
      "dict_items([(\"Lemma('mystery.n.01.mystery')\", 8)])\n",
      "collecting tokens for  mad\n",
      "indices:    {13953, 10755, 10756, 7816, 406, 23063, 35866, 9002, 25270, 9797, 6223, 6224, 20945, 6226, 9169, 8924, 22884, 10857, 25846, 1142}\n",
      "dict_items([(\"Lemma('brainsick.s.01.mad')\", 8), (\"Lemma('huffy.s.02.mad')\", 5)])\n",
      "collecting tokens for  passages\n",
      "indices:    {26213, 24744, 2123, 30796, 37165, 26066, 26484, 1466, 23037}\n",
      "dict_items([(\"Lemma('passage.n.02.passage')\", 2)])\n",
      "collecting tokens for  eccentric\n",
      "indices:    {13957, 2027, 37165, 3311, 13935, 29944, 13947, 13949, 14431}\n",
      "dict_items([(\"Lemma('eccentric.n.01.eccentric')\", 2), (\"Lemma('bizarre.s.01.eccentric')\", 4), (\"Lemma('eccentric.a.02.eccentric')\", 1)])\n",
      "collecting tokens for  transducer\n",
      "indices:    {11424, 11392, 14820, 14822, 11401, 11417, 11420, 11421}\n",
      "dict_items([(\"Lemma('transducer.n.01.transducer')\", 8)])\n",
      "collecting tokens for  rejected\n",
      "indices:    {31872, 23168, 3721, 9997, 22038, 15776, 16422, 23726, 21438, 67, 23751, 1224, 7113, 11466, 1359, 22869, 23267, 7654, 13159, 4976, 113, 25716, 26872, 23163}\n",
      "dict_items([(\"Lemma('refuse.v.02.reject')\", 11), (\"Lemma('reject.v.01.reject')\", 9), (\"Lemma('disapprove.v.02.reject')\", 1), (\"Lemma('reject.v.04.reject')\", 1)])\n",
      "collecting tokens for  amendment\n",
      "indices:    {25200, 16235}\n",
      "dict_items([])\n",
      "collecting tokens for  raises\n",
      "indices:    {13474, 67, 4258, 20359, 27208, 73, 2025, 8621, 30463, 14773, 13367, 29887}\n",
      "dict_items([(\"Lemma('raise.v.02.raise')\", 2), (\"Lemma('raise.v.03.raise')\", 3), (\"Lemma('raise.v.01.raise')\", 2), (\"Lemma('enhance.v.01.raise')\", 1), (\"Lemma('raise.n.01.raise')\", 2), (\"Lemma('grow.v.07.raise')\", 1)])\n",
      "collecting tokens for  legislature\n",
      "indices:    {20620}\n",
      "dict_items([])\n",
      "collecting tokens for  statements\n",
      "indices:    {147}\n",
      "dict_items([(\"Lemma('statement.n.01.statement')\", 1)])\n",
      "collecting tokens for  installation\n",
      "indices:    {2050, 5188, 30152, 30092, 5203, 30196, 30201, 11611}\n",
      "dict_items([(\"Lemma('installation.n.01.installation')\", 4)])\n",
      "collecting tokens for  cards\n",
      "indices:    {34848, 27653, 8811, 17581, 623, 4464, 18552, 33018, 33021}\n",
      "dict_items([(\"Lemma('group.n.01.group')\", 1), (\"Lemma('card.n.01.card')\", 1), (\"Lemma('card.n.02.card')\", 1), (\"Lemma('card_game.n.01.cards')\", 1)])\n",
      "collecting tokens for  desired\n",
      "indices:    {22274, 24579, 29956, 14213, 15252, 10262, 2328, 29859, 12456, 2739, 4919, 3258, 19390, 29888, 32583, 29520, 29651, 29526, 14041, 12124, 32604, 11999, 24674, 26218, 29562}\n",
      "dict_items([(\"Lemma('desire.v.03.desire')\", 2), (\"Lemma('coveted.s.01.desired')\", 5), (\"Lemma('desire.v.01.desire')\", 10), (\"Lemma('hope.v.01.desire')\", 1), (\"Lemma('craved.s.01.desired')\", 1)])\n",
      "collecting tokens for  bold\n",
      "indices:    {11200, 35329, 26274, 37091, 24192, 7333, 35206, 31816, 26218, 1098, 31726, 13808, 18416, 6325, 36023, 6874, 8383}\n",
      "dict_items([(\"Lemma('bold.a.01.bold')\", 5), (\"Lemma('bold.s.02.bold')\", 2)])\n",
      "collecting tokens for  fever\n",
      "indices:    {3459, 3461, 11545, 14470, 9190, 11529, 26218, 11531, 11537, 19186, 19185, 4052, 30100, 2231, 34521, 3486, 11519}\n",
      "dict_items([(\"Lemma('fever.n.01.fever')\", 4)])\n",
      "collecting tokens for  devotion\n",
      "indices:    {22688, 36226, 32228, 30215, 26218, 8237, 31757, 30927, 32017, 32018, 27667, 27602, 11862, 8472, 23036, 37118, 31960}\n",
      "dict_items([(\"Lemma('devotion.n.02.devotion')\", 1), (\"Lemma('devotion.n.01.devotion')\", 2)])\n",
      "collecting tokens for  resume\n",
      "indices:    {24640, 15296, 11076, 25383, 24424, 25448, 15370, 15372, 25456, 31762, 28563, 11126, 26876}\n",
      "dict_items([(\"Lemma('sketch.n.03.resume')\", 4), (\"Lemma('resume.v.03.resume')\", 2), (\"Lemma('resume.v.01.resume')\", 4), (\"Lemma('resume.v.02.resume')\", 2)])\n",
      "collecting tokens for  battens\n",
      "indices:    {29761, 29768, 29801, 29867, 29805, 29807, 29808, 29714, 29746, 29748, 29750, 29751, 29721, 29755, 29724}\n",
      "dict_items([])\n",
      "collecting tokens for  jackson\n",
      "indices:    {34305}\n",
      "dict_items([])\n",
      "collecting tokens for  engaged\n",
      "indices:    {24000, 27328, 7303, 23979, 12524, 13749, 14455, 24668}\n",
      "dict_items([(\"Lemma('engage.v.04.engage')\", 1), (\"Lemma('hire.v.01.engage')\", 1), (\"Lemma('absorb.v.09.engage')\", 3), (\"Lemma('prosecute.v.03.engage')\", 3)])\n",
      "collecting tokens for  1500\n",
      "indices:    {21766, 20202, 20204, 15119, 22551, 11385, 30138, 11871}\n",
      "dict_items([])\n",
      "collecting tokens for  mount\n",
      "indices:    {29306}\n",
      "dict_items([])\n",
      "collecting tokens for  drastically\n",
      "indices:    {27136, 11941, 1577, 28521, 28461, 24949, 37113, 19036}\n",
      "dict_items([(\"Lemma('drastically.r.01.drastically')\", 3)])\n",
      "collecting tokens for  influences\n",
      "indices:    {15873, 26849, 14628, 1577, 14395, 26191, 20, 27861, 27544, 15963}\n",
      "dict_items([(\"Lemma('influence.n.01.influence')\", 2), (\"Lemma('influence.n.03.influence')\", 2), (\"Lemma('determine.v.02.influence')\", 2)])\n",
      "collecting tokens for  apart\n",
      "indices:    {20199}\n",
      "dict_items([])\n",
      "collecting tokens for  audiences\n",
      "indices:    {1577, 4715, 2381, 26861, 26863, 1136, 2389, 26648, 11258, 1948, 1949, 27774, 23775}\n",
      "dict_items([(\"Lemma('audience.n.01.audience')\", 7), (\"Lemma('audience.n.02.audience')\", 1)])\n",
      "collecting tokens for  muscular\n",
      "indices:    {1537, 9154, 1570, 27205, 4046, 22991, 4018, 3828, 11221, 1527, 4921}\n",
      "dict_items([(\"Lemma('muscular.a.01.muscular')\", 4), (\"Lemma('mesomorphic.a.01.muscular')\", 3), (\"Lemma('muscular.s.03.muscular')\", 1)])\n",
      "collecting tokens for  sex\n",
      "indices:    {12045, 22414, 33166, 3859, 12055, 32025, 32028, 33181, 12062, 32029, 32034, 32035, 32036, 32933, 32037, 30763, 30765, 10799, 32057, 30781, 32062, 11983, 32082, 32091, 30811, 14431, 12005, 32102, 32104, 12008}\n",
      "dict_items([(\"Lemma('sexual_activity.n.01.sex')\", 5), (\"Lemma('sex.n.02.sex')\", 2)])\n",
      "collecting tokens for  marijuana\n",
      "indices:    {32036, 32071, 32111, 32112, 32113, 32050, 32115, 32091, 32063}\n",
      "dict_items([])\n",
      "collecting tokens for  virtue\n",
      "indices:    {28119, 13688, 13704, 23530, 14699, 13964, 13902, 26094, 5360, 13968, 28116, 26197, 28118, 13687, 22392, 28117, 36316, 35932}\n",
      "dict_items([(\"Lemma('virtue.n.01.virtue')\", 5)])\n",
      "collecting tokens for  abrupt\n",
      "indices:    {31809, 31813, 21894, 30407, 31816, 14959, 5360, 31824, 15055, 25459, 9653, 14554, 26524}\n",
      "dict_items([(\"Lemma('abrupt.s.01.abrupt')\", 2), (\"Lemma('abrupt.s.02.abrupt')\", 2)])\n",
      "collecting tokens for  literal\n",
      "indices:    {5411, 5413, 5357, 5389, 27321, 5373, 11294}\n",
      "dict_items([(\"Lemma('actual.s.03.literal')\", 5), (\"Lemma('literal.s.02.literal')\", 1)])\n",
      "collecting tokens for  drove\n",
      "indices:    {384, 35461, 9222, 7560, 7819, 18444, 17037, 9485, 33937, 33938, 667, 13084, 29981, 34204, 29979, 6563, 8868, 33955, 17063, 22464, 9280, 7878, 36810, 31436, 33486, 18255, 16591, 1493, 33621, 29143, 213, 36185, 34149, 34153, 31467, 5360, 33525, 28661, 35965, 5631}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('drive.v.02.drive')\", 13), (\"Lemma('drive.v.01.drive')\", 12), (\"Lemma('chase_away.v.01.drive_out')\", 1), (\"Lemma('drive.v.03.drive')\", 1), (\"Lemma('chase_away.v.01.drive_off')\", 2), (\"Lemma('force.v.06.drive')\", 2), (\"Lemma('drive.v.05.drive')\", 1), (\"Lemma('chase_away.v.01.drive_away')\", 1), (\"Lemma('tug.v.02.drive')\", 1)])\n",
      "collecting tokens for  printing\n",
      "indices:    {32760, 32706, 2988, 2717}\n",
      "dict_items([])\n",
      "collecting tokens for  depicted\n",
      "indices:    {3916, 5389}\n",
      "dict_items([(\"Lemma('describe.v.01.depict')\", 1), (\"Lemma('picture.v.02.depict')\", 1)])\n",
      "collecting tokens for  illusion\n",
      "indices:    {5379, 2185, 5388, 5391, 5392, 5395, 5396, 5398, 31510, 8857, 5407, 11327, 2124, 22607, 22736, 5211, 2403, 19559, 2666, 7276, 5360, 33264, 5362, 5371, 5373, 5375}\n",
      "dict_items([(\"Lemma('illusion.n.01.illusion')\", 16), (\"Lemma('illusion.n.02.illusion')\", 5), (\"Lemma('delusion.n.03.illusion')\", 1)])\n",
      "collecting tokens for  confirm\n",
      "indices:    {19927, 22602, 20492, 15726, 2991, 17873, 3026, 5365, 22935, 3704, 28026}\n",
      "dict_items([(\"Lemma('confirm.v.01.confirm')\", 8), (\"Lemma('confirm.v.03.confirm')\", 1), (\"Lemma('confirm.v.02.confirm')\", 2)])\n",
      "collecting tokens for  observations\n",
      "indices:    {2849, 16131, 14800, 2833, 21206, 2842, 32831}\n",
      "dict_items([(\"Lemma('observation.n.01.observation')\", 3), (\"Lemma('observation.n.04.observation')\", 1)])\n",
      "collecting tokens for  contributing\n",
      "indices:    {2752, 20641, 36073, 5130, 32331, 4781, 14580, 32664, 36120, 25979, 1789, 32766}\n",
      "dict_items([(\"Lemma('contribute.v.02.contribute')\", 4), (\"Lemma('conducive.s.01.contributing')\", 1), (\"Lemma('lend.v.01.contribute')\", 5), (\"Lemma('contribute.v.03.contribute')\", 2)])\n",
      "collecting tokens for  monthly\n",
      "indices:    {23376, 2716, 22445}\n",
      "dict_items([])\n",
      "collecting tokens for  collapsed\n",
      "indices:    {34161, 15218, 21555, 6932, 18261, 14517, 37045, 6905, 6334}\n",
      "dict_items([(\"Lemma('break_down.v.08.collapse')\", 4), (\"Lemma('collapse.v.01.collapse')\", 5)])\n",
      "collecting tokens for  carbon\n",
      "indices:    {14808}\n",
      "dict_items([(\"Lemma('carbon.n.01.carbon')\", 1)])\n",
      "collecting tokens for  uniformity\n",
      "indices:    {32545, 27695, 14383, 32530, 32600, 2904, 32571, 32543}\n",
      "dict_items([(\"Lemma('uniformity.n.01.uniformity')\", 2)])\n",
      "collecting tokens for  rockets\n",
      "indices:    {3330, 835, 28483, 903, 28488, 34922, 34286, 27377, 28441, 24667, 3324, 25278, 28447}\n",
      "dict_items([(\"Lemma('rocket.n.02.rocket')\", 2), (\"Lemma('rocket.n.01.rocket')\", 2)])\n",
      "collecting tokens for  proceed\n",
      "indices:    {30817, 20230, 23878, 3947, 14668, 31021, 13486, 16063, 25813, 13658, 24061, 31358, 14751}\n",
      "dict_items([(\"Lemma('proceed.v.02.proceed')\", 5), (\"Lemma('go.v.02.proceed')\", 3), (\"Lemma('continue.v.02.proceed')\", 5)])\n",
      "collecting tokens for  advantage\n",
      "indices:    {16384, 18435, 15237, 22665, 12938, 651, 12945, 25367, 28568, 29336, 28441, 12826, 14364, 12958, 20385, 6946, 2083, 32548, 30757, 34598, 21922, 28449, 28458, 32299, 4270, 23086, 180, 20669, 4799, 30144, 32581, 455, 14419, 21972, 11738, 20315, 25437, 15581, 16351, 12896, 30817, 18416, 32630, 28668}\n",
      "dict_items([(\"Lemma('advantage.n.01.advantage')\", 15)])\n",
      "collecting tokens for  electrical\n",
      "indices:    {4228, 29855, 2230, 13243, 14782, 11461, 14789, 26829, 33487, 26834, 11484, 11485, 11486, 11491, 22755, 22761, 11503, 28784, 12156, 22782}\n",
      "dict_items([(\"Lemma('electrical.a.01.electrical')\", 11)])\n",
      "collecting tokens for  entering\n",
      "indices:    {27361, 23705, 20837, 30791, 20587, 43, 15952, 33361, 3410, 25907, 35696, 20852, 31510, 25815, 14777, 5052, 23166, 19036}\n",
      "dict_items([(\"Lemma('enter.v.02.enter')\", 1), (\"Lemma('enter.v.01.enter')\", 9), (\"Lemma('enroll.v.01.enter')\", 4), (\"Lemma('figure.v.02.enter')\", 1), (\"Lemma('record.v.01.enter')\", 1)])\n",
      "collecting tokens for  uncertainty\n",
      "indices:    {4577, 4674, 25733, 7399, 14825, 31818, 2636, 14799, 26257, 27794, 30261, 14777, 32380, 27326}\n",
      "dict_items([(\"Lemma('uncertainty.n.01.uncertainty')\", 4), (\"Lemma('doubt.n.01.uncertainty')\", 3)])\n",
      "collecting tokens for  percent\n",
      "indices:    {33027, 2182, 10257, 3095, 1965, 31795, 33076, 14773, 15159, 15160, 14777, 14907, 14914, 14788, 2766, 21975, 21976, 25304, 21978, 20704, 2790, 20711, 2791, 32893, 14847}\n",
      "dict_items([(\"Lemma('percentage.n.01.percent')\", 13)])\n",
      "collecting tokens for  resumption\n",
      "indices:    {25441, 25449, 25450, 20273, 25428, 25439, 22623, 831}\n",
      "dict_items([(\"Lemma('resumption.n.01.resumption')\", 1)])\n",
      "collecting tokens for  geneva\n",
      "indices:    {23751}\n",
      "dict_items([])\n",
      "collecting tokens for  talks\n",
      "indices:    {20578, 32259, 20998, 14951, 20490, 22605, 23856, 24657, 22354, 23475, 25428, 26810, 23293, 20575}\n",
      "dict_items([(\"Lemma('negotiation.n.01.talks')\", 1), (\"Lemma('talk.v.01.talk')\", 2)])\n",
      "collecting tokens for  clayton\n",
      "indices:    {35226}\n",
      "dict_items([])\n",
      "collecting tokens for  consequences\n",
      "indices:    {12291, 27787, 27797, 27798, 27287, 27800, 15262, 22947, 805, 37030, 12200, 4650, 13999, 11443, 25395, 27829, 14916, 31943, 2515, 25812, 31191, 3426, 4579}\n",
      "dict_items([(\"Lemma('consequence.n.01.consequence')\", 11)])\n",
      "collecting tokens for  consciousness\n",
      "indices:    {28137, 11626, 2167, 13655, 13534}\n",
      "dict_items([(\"Lemma('consciousness.n.01.consciousness')\", 4)])\n",
      "collecting tokens for  deceased\n",
      "indices:    {31107, 15561, 11819, 31085, 18000, 31088, 15832, 14876}\n",
      "dict_items([(\"Lemma('dead_person.n.01.deceased')\", 1), (\"Lemma('asleep.s.03.deceased')\", 4)])\n",
      "collecting tokens for  motivated\n",
      "indices:    {16296, 4651, 14700, 14220, 24331, 528, 24690, 14231, 31930}\n",
      "dict_items([(\"Lemma('motivated.a.01.motivated')\", 3), (\"Lemma('motivate.v.01.motivate')\", 4)])\n",
      "collecting tokens for  arnold\n",
      "indices:    {21886}\n",
      "dict_items([])\n",
      "collecting tokens for  grateful\n",
      "indices:    {35064, 8386, 15843, 7013, 24939, 26891, 9805, 22511, 9204, 1238, 30807, 17334, 26969, 34684, 7487}\n",
      "dict_items([(\"Lemma('grateful.a.01.grateful')\", 8)])\n",
      "collecting tokens for  featured\n",
      "indices:    {36676, 32485, 11337, 42, 16491, 31628, 1870, 239, 243}\n",
      "dict_items([(\"Lemma('have.v.02.feature')\", 5), (\"Lemma('featured.s.01.featured')\", 2), (\"Lemma('featured.s.02.featured')\", 1), (\"Lemma('sport.v.01.feature')\", 1)])\n",
      "collecting tokens for  concerto\n",
      "indices:    {11252, 26278, 11199}\n",
      "dict_items([(\"Lemma('concerto.n.01.concerto')\", 1)])\n",
      "collecting tokens for  heavier\n",
      "indices:    {34146, 27842, 8196, 22150, 12136, 14792, 29066, 11282, 5555, 8630, 8890, 5564}\n",
      "dict_items([(\"Lemma('heavy.a.01.heavy')\", 3), (\"Lemma('fleshy.s.01.heavy')\", 1), (\"Lemma('heavy.a.02.heavy')\", 3)])\n",
      "collecting tokens for  application\n",
      "indices:    {31236, 30406, 2214, 15595, 15821, 16463, 4243, 32696, 31228}\n",
      "dict_items([(\"Lemma('application.n.01.application')\", 3), (\"Lemma('application.n.03.application')\", 1), (\"Lemma('application.n.02.application')\", 1)])\n",
      "collecting tokens for  minerals\n",
      "indices:    {30496, 11588, 2214, 14070, 11515, 2783}\n",
      "dict_items([(\"Lemma('mineral.n.01.mineral')\", 5)])\n",
      "collecting tokens for  exploration\n",
      "indices:    {16193, 19137, 31907, 14633, 12334, 14643, 2783}\n",
      "dict_items([(\"Lemma('exploration.n.01.exploration')\", 3), (\"Lemma('exploration.n.02.exploration')\", 2), (\"Lemma('exploration.n.03.exploration')\", 1)])\n",
      "collecting tokens for  u.s.\n",
      "indices:    {3358}\n",
      "dict_items([(\"Lemma('united_states_government.n.01.U.S.')\", 1)])\n",
      "collecting tokens for  d.c.\n",
      "indices:    {2749}\n",
      "dict_items([(\"Lemma('district_of_columbia.n.01.District_of_Columbia')\", 1)])\n",
      "collecting tokens for  lousy\n",
      "indices:    {3491, 3487, 6572, 24975, 24976, 17657, 6527}\n",
      "dict_items([(\"Lemma('lousy.s.02.lousy')\", 2), (\"Lemma('icky.s.01.lousy')\", 3)])\n",
      "collecting tokens for  suppose\n",
      "indices:    {8693, 879}\n",
      "dict_items([(\"Lemma('suppose.v.01.suppose')\", 2)])\n",
      "collecting tokens for  settle\n",
      "indices:    {11680, 8355, 12677, 12455, 24263, 20618, 13835, 32906, 14318, 9167, 976, 12497, 27278, 9363, 34171, 8214, 16379, 13405}\n",
      "dict_items([(\"Lemma('settle.v.13.settle')\", 1), (\"Lemma('settle.v.08.settle')\", 1), (\"Lemma('settle.v.03.settle')\", 4), (\"Lemma('settle.v.04.settle')\", 3), (\"Lemma('settle.v.07.settle')\", 1), (\"Lemma('decide.v.02.settle')\", 2), (\"Lemma('settle.v.01.settle')\", 1), (\"Lemma('reconcile.v.03.settle')\", 1), (\"Lemma('settle.v.12.settle')\", 1)])\n",
      "collecting tokens for  slice\n",
      "indices:    {7181}\n",
      "dict_items([(\"Lemma('piece.n.08.slice')\", 1)])\n",
      "collecting tokens for  fluids\n",
      "indices:    {3010, 2979, 2978, 2980, 2987, 3022, 2970, 2971, 3004, 3006}\n",
      "dict_items([(\"Lemma('fluid.n.01.fluid')\", 9), (\"Lemma('fluid.n.02.fluid')\", 1)])\n",
      "collecting tokens for  drops\n",
      "indices:    {3010, 13252, 26410, 29328, 9490, 3027, 26644, 3028, 32086, 2007, 3032, 3026, 22847}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('drop.n.01.drop')\", 6), (\"Lemma('sink.v.01.drop')\", 1), (\"Lemma('drop.v.02.drop')\", 1), (\"Lemma('drop.v.05.drop')\", 1), (\"Lemma('drop.v.07.drop')\", 1)])\n",
      "collecting tokens for  viscosity\n",
      "indices:    {3010, 3019, 14830, 3022, 3026, 3027, 3028, 3032}\n",
      "dict_items([(\"Lemma('viscosity.n.01.viscosity')\", 8)])\n",
      "collecting tokens for  profit\n",
      "indices:    {31747, 774, 20359, 14220, 11792, 27043, 29991, 16552, 11697, 20667, 16325, 21574, 11848, 14926, 16347, 16352, 16353, 16378, 27388}\n",
      "dict_items([(\"Lemma('net_income.n.01.profit')\", 6), (\"Lemma('profit.v.02.profit')\", 2), (\"Lemma('profit.n.02.profit')\", 1), (\"Lemma('profit.v.01.profit')\", 2)])\n",
      "collecting tokens for  gnp\n",
      "indices:    {16341}\n",
      "dict_items([(\"Lemma('gross_national_product.n.01.GNP')\", 1)])\n",
      "collecting tokens for  naive\n",
      "indices:    {30873, 27706, 2477, 909, 1809, 16121, 19418, 5276}\n",
      "dict_items([(\"Lemma('naive.a.01.naive')\", 6)])\n",
      "collecting tokens for  grandfather\n",
      "indices:    {25665, 2082, 18883, 2088, 36746, 7434, 28399, 25370, 21342}\n",
      "dict_items([(\"Lemma('grandfather.n.01.grandfather')\", 2)])\n",
      "collecting tokens for  varying\n",
      "indices:    {4108, 13585, 32533, 32921, 32542, 2339, 29993, 27563, 2987, 1712, 22706, 11064, 15673, 32698, 9786, 25670, 3271, 25671, 33095, 31691, 15054, 29910, 3300, 2404, 25062, 3949, 26099, 4595, 3707}\n",
      "dict_items([(\"Lemma('vary.v.03.vary')\", 2), (\"Lemma('deviate.v.02.vary')\", 3), (\"Lemma('change.v.03.vary')\", 5), (\"Lemma('vary.v.04.vary')\", 1), (\"Lemma('varying.s.01.varying')\", 5)])\n",
      "collecting tokens for  speeds\n",
      "indices:    {26816, 29891, 25670, 29895, 5578, 5580, 5519, 5553, 5554, 1588}\n",
      "dict_items([(\"Lemma('speed.n.01.speed')\", 5), (\"Lemma('accelerate.v.01.speed')\", 1)])\n",
      "collecting tokens for  strings\n",
      "indices:    {26913}\n",
      "dict_items([])\n",
      "collecting tokens for  literary\n",
      "indices:    {14592, 14690, 24675, 32120, 5219, 2360, 10744, 24629, 11478, 14709, 14392, 31800}\n",
      "dict_items([(\"Lemma('literary.a.01.literary')\", 7)])\n",
      "collecting tokens for  hub\n",
      "indices:    {9830}\n",
      "dict_items([(\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  quietly\n",
      "indices:    {19849, 24586, 7307, 37003, 10380, 21135, 9340, 5648, 18966, 22564, 677, 34871, 19897, 19772, 37052, 7743, 25666, 36803, 34503, 36040, 6990, 5842, 33618, 19669, 36826, 22875, 35811, 34150, 24427, 8302, 24431, 9846, 26108}\n",
      "dict_items([(\"Lemma('quietly.r.03.quietly')\", 2), (\"Lemma('softly.r.01.quietly')\", 8), (\"Lemma('quietly.r.02.quietly')\", 5)])\n",
      "collecting tokens for  attributed\n",
      "indices:    {26208, 3297, 22498, 14818, 15304, 5131, 33234, 13342, 7672, 15289, 13341, 14302, 11615}\n",
      "dict_items([(\"Lemma('impute.v.01.attribute')\", 13)])\n",
      "collecting tokens for  samuel\n",
      "indices:    {13524}\n",
      "dict_items([])\n",
      "collecting tokens for  salem\n",
      "indices:    {1255}\n",
      "dict_items([(\"Lemma('location.n.01.location')\", 1)])\n",
      "collecting tokens for  architect\n",
      "indices:    {22498, 7587, 37027, 2062, 29935, 2032, 29361, 22192, 13813, 13816, 14362, 29822}\n",
      "dict_items([(\"Lemma('architect.n.01.architect')\", 6)])\n",
      "collecting tokens for  capitol\n",
      "indices:    {20174}\n",
      "dict_items([])\n",
      "collecting tokens for  picnic\n",
      "indices:    {1857, 1891, 29508, 29445, 29478, 11620, 29480, 22376, 36941, 29487, 26961, 29462, 29464, 14495}\n",
      "dict_items([(\"Lemma('field_day.n.04.picnic')\", 2), (\"Lemma('cinch.n.01.picnic')\", 1)])\n",
      "collecting tokens for  gasoline\n",
      "indices:    {28711, 32327}\n",
      "dict_items([])\n",
      "collecting tokens for  parks\n",
      "indices:    {1857, 26890, 1867, 29325, 5426, 11892, 36123}\n",
      "dict_items([(\"Lemma('park.n.01.park')\", 3)])\n",
      "collecting tokens for  barbecue\n",
      "indices:    {29408, 29536, 29412, 21572, 29449, 29484, 29492, 29461, 29464, 29437, 29470, 29407}\n",
      "dict_items([(\"Lemma('barbeque.v.01.barbecue')\", 1)])\n",
      "collecting tokens for  drinks\n",
      "indices:    {25676, 8748, 3502, 33230, 29458, 17749, 29462, 29464, 9595, 8764, 25053}\n",
      "dict_items([(\"Lemma('drink.n.01.drink')\", 3)])\n",
      "collecting tokens for  75\n",
      "indices:    {11521, 11526, 11527, 2833, 29464, 22173, 21932, 5550, 14769, 15025, 15027, 22197, 14788, 29126, 11593, 21324, 20689, 32468, 15317, 21607, 22504, 11891, 21620, 5496, 2303}\n",
      "dict_items([])\n",
      "collecting tokens for  cheaper\n",
      "indices:    {23492, 24127, 5435, 11731, 29464, 11770, 30139, 28413, 29439}\n",
      "dict_items([(\"Lemma('cheap.a.01.cheap')\", 3)])\n",
      "collecting tokens for  restaurant\n",
      "indices:    {13026, 29189, 33673, 33578, 22320, 21555, 29463}\n",
      "dict_items([(\"Lemma('restaurant.n.01.restaurant')\", 1)])\n",
      "collecting tokens for  unlikely\n",
      "indices:    {3745, 11042, 17252, 34427, 21898, 26636, 11054, 20656, 3089, 33362, 885, 26325, 18583, 3480, 18523, 8287, 31135}\n",
      "dict_items([(\"Lemma('improbable.a.01.unlikely')\", 5), (\"Lemma('unlikely.a.02.unlikely')\", 5)])\n",
      "collecting tokens for  businessmen\n",
      "indices:    {2716, 23460, 2724, 32454, 8267, 27181, 4784, 15606, 21980}\n",
      "dict_items([(\"Lemma('businessmen.n.01.businessmen')\", 1), (\"Lemma('businessman.n.01.businessman')\", 4)])\n",
      "collecting tokens for  curiosity\n",
      "indices:    {9369, 34371, 13407, 7364, 11014, 12735, 8268, 26545, 10898, 31089, 36340, 13397, 15863, 16825, 7675, 6811, 17918, 8287}\n",
      "dict_items([(\"Lemma('curiosity.n.01.curiosity')\", 14)])\n",
      "collecting tokens for  whispered\n",
      "indices:    {19872, 19777, 9763, 35175, 35112, 9643, 6188, 35503, 5840, 19441, 2131, 35156, 35187, 13591, 35992, 36025, 36986}\n",
      "dict_items([(\"Lemma('whisper.v.01.whisper')\", 16)])\n",
      "collecting tokens for  crombie\n",
      "indices:    {20119}\n",
      "dict_items([])\n",
      "collecting tokens for  midst\n",
      "indices:    {6880, 26410, 910, 24846, 22641, 6034, 27797, 27990, 20122, 24349, 27519}\n",
      "dict_items([(\"Lemma('midst.n.01.midst')\", 1)])\n",
      "collecting tokens for  cooking\n",
      "indices:    {5891, 29449, 17550, 11920, 30483, 17559, 20122, 30490, 12577, 29482, 11953, 14529, 27073, 8147, 29400, 986, 37083, 9694, 30687, 9695, 15198, 11999, 29413, 29423, 23026, 7158}\n",
      "dict_items([(\"Lemma('cooking.n.01.cooking')\", 4), (\"Lemma('cook.v.02.cook')\", 1), (\"Lemma('cook.v.01.cook')\", 2), (\"Lemma('cook.v.03.cook')\", 1)])\n",
      "collecting tokens for  disapproval\n",
      "indices:    {13158, 22664, 783, 22650, 5340, 4863}\n",
      "dict_items([(\"Lemma('disapproval.n.01.disapproval')\", 3), (\"Lemma('disapproval.n.02.disapproval')\", 1)])\n",
      "collecting tokens for  resentment\n",
      "indices:    {24259, 20477}\n",
      "dict_items([])\n",
      "collecting tokens for  sentences\n",
      "indices:    {25408, 16039, 26123, 15980, 10605, 9582, 16045, 15795, 13427, 24760, 15963, 22782, 30239}\n",
      "dict_items([(\"Lemma('sentence.n.01.sentence')\", 8)])\n",
      "collecting tokens for  satisfaction\n",
      "indices:    {14883, 13256, 36475, 27691, 18894, 10734, 18200, 21779, 22515, 17365, 33917, 6807, 16696, 12051, 32218, 32059, 17596, 6589}\n",
      "dict_items([(\"Lemma('satisfaction.n.01.satisfaction')\", 7), (\"Lemma('atonement.n.01.satisfaction')\", 1), (\"Lemma('gratification.n.01.satisfaction')\", 3)])\n",
      "collecting tokens for  hat\n",
      "indices:    {35330, 9475, 9476, 9482, 33931, 18570, 29197, 11148, 18577, 29204, 9494, 13079, 9639, 8103, 24364, 26412, 10419, 24373, 22071, 36286, 24005, 9670, 17735, 35272, 9158, 9680, 22609, 35665, 19158, 36566, 9695, 5602, 9700, 9702, 16999, 36968, 34029, 9468}\n",
      "dict_items([(\"Lemma('hat.n.01.hat')\", 18)])\n",
      "collecting tokens for  fur\n",
      "indices:    {20932, 12517, 12516, 12494, 12464, 12470, 12472, 12541}\n",
      "dict_items([(\"Lemma('fur.n.01.fur')\", 5), (\"Lemma('fur.n.02.fur')\", 1)])\n",
      "collecting tokens for  trim\n",
      "indices:    {29824, 29601, 7299, 29608, 30539, 29870, 22903, 703}\n",
      "dict_items([(\"Lemma('pare.v.04.trim')\", 2), (\"Lemma('trimming.n.02.trim')\", 1), (\"Lemma('spare.s.01.trim')\", 1)])\n",
      "collecting tokens for  onto\n",
      "indices:    {34049, 31489, 36997, 3216, 26384, 10517, 36634, 19229, 3256, 1980, 26306, 18117, 12486, 31559, 31560, 31437, 19793, 18002, 19284, 16085, 18263, 33624, 9178, 24672, 30050, 34147, 9954, 34152, 18154, 21612, 34157, 10862, 27250, 19059, 26868, 35572, 6775, 34169, 3195, 3196, 35839}\n",
      "dict_items([])\n",
      "collecting tokens for  witness\n",
      "indices:    {30850, 30852, 21893, 12192, 10147, 5156, 28323, 21667, 13611, 10671, 1330, 37045, 21314, 29254, 11464, 30938, 8672, 8811, 28143}\n",
      "dict_items([(\"Lemma('witness.v.01.witness')\", 7), (\"Lemma('witness.v.02.witness')\", 2), (\"Lemma('witness.n.01.witness')\", 2), (\"Lemma('witness.n.03.witness')\", 2)])\n",
      "collecting tokens for  lo\n",
      "indices:    {27559}\n",
      "dict_items([])\n",
      "collecting tokens for  shu\n",
      "indices:    {27559}\n",
      "dict_items([])\n",
      "collecting tokens for  nucleus\n",
      "indices:    {33153, 23525, 30828, 13357, 13335, 13336, 27961, 27962, 27963}\n",
      "dict_items([(\"Lemma('core.n.01.nucleus')\", 3)])\n",
      "collecting tokens for  contains\n",
      "indices:    {11401, 2705, 11411, 26654, 3871, 15910, 15911, 1710, 32817, 27188, 27963, 31552, 33094, 15943, 3067, 2638, 4559, 4307, 31577, 27225, 32092, 3040, 26338, 10726, 31355, 26621}\n",
      "dict_items([(\"Lemma('incorporate.v.02.contain')\", 21), (\"Lemma('hold.v.11.contain')\", 5)])\n",
      "collecting tokens for  electricity\n",
      "indices:    {11488, 5185, 11492, 28711, 12170, 11084, 29839, 5199, 11505, 21365, 27958, 11482, 11451, 11485}\n",
      "dict_items([(\"Lemma('electricity.n.03.electricity')\", 1), (\"Lemma('electricity.n.01.electricity')\", 6), (\"Lemma('electricity.n.02.electricity')\", 3)])\n",
      "collecting tokens for  electrons\n",
      "indices:    {27970, 27975, 3113, 26828, 26829, 3054, 2869, 27958, 27959, 27963}\n",
      "dict_items([(\"Lemma('electron.n.01.electron')\", 3)])\n",
      "collecting tokens for  orbits\n",
      "indices:    {3363, 3307, 3309, 3310, 3311, 27963, 28318}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('orbit.n.01.orbit')\", 5)])\n",
      "collecting tokens for  director\n",
      "indices:    {20307, 32366}\n",
      "dict_items([])\n",
      "collecting tokens for  regime\n",
      "indices:    {14208, 25601, 31623, 25611, 20619, 28435, 20764, 24094, 27806, 23717, 21413, 12206, 20273, 19780, 25576, 28401, 22387, 27763, 27766, 24183, 28411, 25724}\n",
      "dict_items([(\"Lemma('government.n.01.regime')\", 2), (\"Lemma('regimen.n.01.regime')\", 1)])\n",
      "collecting tokens for  eligible\n",
      "indices:    {28576, 2786, 20315, 11845, 21324, 4814, 21554, 20341, 2744, 2779, 28575}\n",
      "dict_items([(\"Lemma('eligible.a.01.eligible')\", 5)])\n",
      "collecting tokens for  voted\n",
      "indices:    {5124, 20363, 140, 24993, 24994, 32423, 7721, 45, 21553, 21554, 64, 23876, 23366, 2508, 23258, 32480, 23784, 37101, 31738, 24702}\n",
      "dict_items([(\"Lemma('vote.v.01.vote')\", 15), (\"Lemma('vote.v.02.vote')\", 3), (\"Lemma('vote.v.03.vote')\", 1)])\n",
      "collecting tokens for  visiting\n",
      "indices:    {6048, 23811, 2500, 21125, 34374, 36995, 7683, 5865, 21608, 16043, 24780, 36405, 21559, 31831, 21176, 26871, 4446}\n",
      "dict_items([(\"Lemma('inflict.v.01.visit')\", 1), (\"Lemma('travel_to.v.01.visit')\", 3), (\"Lemma('visit.v.01.visit')\", 6), (\"Lemma('visit.v.04.visit')\", 1), (\"Lemma('visit.v.03.visit')\", 2)])\n",
      "collecting tokens for  nurse\n",
      "indices:    {21376, 16235, 36495}\n",
      "dict_items([])\n",
      "collecting tokens for  illness\n",
      "indices:    {34656, 24197, 3398, 518, 24968, 26699, 13388, 27022, 23795, 15574, 5753, 20186, 20190}\n",
      "dict_items([(\"Lemma('illness.n.01.illness')\", 5)])\n",
      "collecting tokens for  tobacco\n",
      "indices:    {24834, 5891, 4196, 13573, 31782, 12499, 27037}\n",
      "dict_items([(\"Lemma('tobacco.n.01.tobacco')\", 3)])\n",
      "collecting tokens for  occur\n",
      "indices:    {10240, 16385, 4227, 3977, 33162, 5774, 21776, 32147, 4254, 7327, 5924, 13224, 14633, 2091, 30763, 7869, 11838, 26431, 31942, 11465, 3786, 16088, 3800, 4571, 14440, 29289, 745, 3819, 3824, 12791, 12794}\n",
      "dict_items([(\"Lemma('happen.v.01.occur')\", 21), (\"Lemma('occur.v.02.occur')\", 4)])\n",
      "collecting tokens for  output\n",
      "indices:    {25824, 2881, 21987, 3972, 14440, 15884, 11726, 12465, 34551, 22013, 11231}\n",
      "dict_items([(\"Lemma('output.n.02.output')\", 2), (\"Lemma('end_product.n.01.output')\", 5)])\n",
      "collecting tokens for  residents\n",
      "indices:    {20321, 12802, 20323, 20322, 23689, 24618, 846, 12498, 21650, 13332, 25140, 33078, 20311, 21655, 30908, 5470, 23935}\n",
      "dict_items([(\"Lemma('resident.n.01.resident')\", 5)])\n",
      "collecting tokens for  mothers\n",
      "indices:    {36097, 25220, 13226, 3595, 21100, 8717, 25226, 24530, 14334, 7929, 6683, 20798}\n",
      "dict_items([(\"Lemma('mother.n.01.mother')\", 6)])\n",
      "collecting tokens for  instantly\n",
      "indices:    {6344}\n",
      "dict_items([(\"Lemma('instantaneously.r.01.instantly')\", 1)])\n",
      "collecting tokens for  premier\n",
      "indices:    {23751}\n",
      "dict_items([])\n",
      "collecting tokens for  comfortable\n",
      "indices:    {29697, 34569, 23436, 22924, 24334, 10895, 11920, 13581, 24599, 685, 10030, 11949, 8388, 19398, 15195, 14558, 9310, 9313, 34273, 9314, 6244, 36069, 10864, 1777, 35962}\n",
      "dict_items([(\"Lemma('comfortable.a.01.comfortable')\", 14), (\"Lemma('comfortable.a.02.comfortable')\", 2)])\n",
      "collecting tokens for  consequence\n",
      "indices:    {12768, 1463, 1506, 15715, 27807, 14426, 26568, 13192, 13642, 12559, 13279, 18516, 27733, 24599, 18616, 25626, 4638, 27839}\n",
      "dict_items([(\"Lemma('consequence.n.02.consequence')\", 3), (\"Lemma('consequence.n.03.consequence')\", 2), (\"Lemma('consequence.n.01.consequence')\", 7)])\n",
      "collecting tokens for  belongs\n",
      "indices:    {23937, 23938, 2691, 12066, 1763, 22663, 26631, 30698, 2674, 1491, 2677, 15286, 24599, 14683}\n",
      "dict_items([(\"Lemma('belong.v.04.belong')\", 1), (\"Lemma('belong.v.01.belong')\", 3), (\"Lemma('belong.v.03.belong')\", 1)])\n",
      "collecting tokens for  disk\n",
      "indices:    {2817, 2818, 2949, 2823, 2826, 2827, 2830, 2831, 29596, 2848, 28835, 28836, 29605, 2855, 29640, 29641, 29650, 2899, 28757, 26330, 29786, 2911, 2808}\n",
      "dict_items([(\"Lemma('disk.n.02.disk')\", 3), (\"Lemma('disk.n.01.disk')\", 10)])\n",
      "collecting tokens for  practices\n",
      "indices:    {27906, 32130, 6, 267, 32530, 25367, 32282, 28699, 32156, 22812, 12321, 14243, 2224, 23475, 11448, 22723, 11868, 11869, 37093, 4713, 4721, 1783}\n",
      "dict_items([(\"Lemma('practice.n.01.practice')\", 9), (\"Lemma('drill.v.03.practice')\", 1)])\n",
      "collecting tokens for  domination\n",
      "indices:    {12064, 12065, 25859, 2534, 20270, 11983, 25425, 27731, 12980, 12055, 16124, 27805, 27806}\n",
      "dict_items([(\"Lemma('domination.n.01.domination')\", 6), (\"Lemma('domination.n.02.domination')\", 1)])\n",
      "collecting tokens for  mistake\n",
      "indices:    {35968, 19201, 24711, 3593, 17808, 26389, 26520, 27803, 2587, 11934, 11945, 11180, 11949, 948, 21952, 10308, 841, 27725, 33494, 25565, 13675, 10351, 4858}\n",
      "dict_items([(\"Lemma('mistake.n.02.mistake')\", 4), (\"Lemma('mistake.n.01.mistake')\", 7), (\"Lemma('mistake.v.01.mistake')\", 1)])\n",
      "collecting tokens for  operational\n",
      "indices:    {5537, 16225, 32353, 32900, 4616, 3401, 15531, 15532, 15533, 16207, 11760, 15409, 5489, 24147, 15516}\n",
      "dict_items([(\"Lemma('operational.s.04.operational')\", 1), (\"Lemma('operational.a.01.operational')\", 6), (\"Lemma('operational.a.03.operational')\", 2), (\"Lemma('functional.s.04.operational')\", 3)])\n",
      "collecting tokens for  matched\n",
      "indices:    {37056, 15049, 24970, 15052, 16207, 15920, 15921, 22194, 16243, 15919, 22995, 15930, 23003, 22494}\n",
      "dict_items([(\"Lemma('match.v.03.match')\", 3), (\"Lemma('match.v.02.match')\", 4), (\"Lemma('equal.v.02.match')\", 2), (\"Lemma('match.v.01.match')\", 4)])\n",
      "collecting tokens for  troubled\n",
      "indices:    {22624, 24418, 17511, 31721, 6410, 14477, 12655, 6803, 12501, 27355, 23934}\n",
      "dict_items([(\"Lemma('disturb.v.01.trouble')\", 3), (\"Lemma('troubled.a.01.troubled')\", 1), (\"Lemma('perturb.v.01.trouble')\", 1), (\"Lemma('disruptive.s.01.troubled')\", 1)])\n",
      "collecting tokens for  soldiers\n",
      "indices:    {31554, 12579, 32714, 7530, 26033, 12563, 12595, 2679, 6397, 29983}\n",
      "dict_items([(\"Lemma('soldier.n.01.soldier')\", 6)])\n",
      "collecting tokens for  panic\n",
      "indices:    {5923, 6307, 35459, 13383, 33671, 22665, 10827, 24971, 32847, 7664, 33680, 16884, 18837, 7641, 33851, 16733}\n",
      "dict_items([(\"Lemma('panic.n.01.panic')\", 5), (\"Lemma('panic.n.02.panic')\", 2), (\"Lemma('panic.v.01.panic')\", 1), (\"Lemma('panic.v.02.panic')\", 1)])\n",
      "collecting tokens for  suburb\n",
      "indices:    {12801, 13219, 13157, 23529, 5484, 21361, 5427, 12696, 13371, 7965, 24446}\n",
      "dict_items([(\"Lemma('suburb.n.01.suburb')\", 8)])\n",
      "collecting tokens for  bus\n",
      "indices:    {25224, 25231, 20882, 9493, 33692, 13219, 29349, 29350, 29353, 21673, 21676, 21677, 5437, 31809, 21316, 13508, 21319, 22216, 21321, 21320, 33358, 33364, 22242, 22243, 33267, 24436, 33269, 11768, 23673}\n",
      "dict_items([(\"Lemma('bus.n.01.bus')\", 2)])\n",
      "collecting tokens for  camps\n",
      "indices:    {13219, 11907, 31433, 21420, 18316, 7959, 7954, 12562, 20629, 4886, 12247, 7966}\n",
      "dict_items([(\"Lemma('camp.n.02.camp')\", 1), (\"Lemma('camp.n.03.camp')\", 1), (\"Lemma('camp.n.01.camp')\", 1), (\"Lemma('concentration_camp.n.01.concentration_camp')\", 2), (\"Lemma('camp.n.05.camp')\", 2)])\n",
      "collecting tokens for  primitive\n",
      "indices:    {32134, 12944, 19226, 17205, 26807, 17208, 17207, 26430, 26432, 1480, 36425, 2379, 3665, 7890, 13655, 4700, 13663, 13671, 32104, 14063, 4210, 28665, 2556, 4733}\n",
      "dict_items([(\"Lemma('crude.s.04.primitive')\", 8), (\"Lemma('archaic.s.02.primitive')\", 2), (\"Lemma('primitive.s.03.primitive')\", 1)])\n",
      "collecting tokens for  markets\n",
      "indices:    {23491, 25832, 32457, 32458, 11914, 11693, 25013, 12149, 11706, 36125, 25823}\n",
      "dict_items([(\"Lemma('grocery_store.n.01.market')\", 1), (\"Lemma('market.n.01.market')\", 2), (\"Lemma('market.n.02.market')\", 1)])\n",
      "collecting tokens for  vicious\n",
      "indices:    {20417, 32237, 16750, 34093, 2353, 13267, 18932, 18525, 2230, 13271, 12219, 4221, 12639}\n",
      "dict_items([(\"Lemma('barbarous.s.01.vicious')\", 3), (\"Lemma('evil.s.02.vicious')\", 2)])\n",
      "collecting tokens for  aboard\n",
      "indices:    {29696, 29697, 391, 23304, 30344, 34448, 19352, 31260, 22048, 30380, 19385, 19388, 8508, 19407, 30291, 10197, 28644, 30317, 30318}\n",
      "dict_items([(\"Lemma('aboard.r.01.aboard')\", 4), (\"Lemma('aboard.r.02.aboard')\", 1)])\n",
      "collecting tokens for  comedie\n",
      "indices:    {26569}\n",
      "dict_items([])\n",
      "collecting tokens for  hers\n",
      "indices:    {9316, 9189, 8423, 30920, 35976, 14459, 9581, 8398, 33940, 8725, 33943, 8378, 23611}\n",
      "dict_items([])\n",
      "collecting tokens for  cherished\n",
      "indices:    {31778, 421, 28041, 10058, 9994, 10255, 32208, 27349, 26781, 1654, 13565}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('care_for.v.02.cherish')\", 8), (\"Lemma('cherished.s.01.cherished')\", 2)])\n",
      "collecting tokens for  subsequent\n",
      "indices:    {30208, 32992, 32322, 22342, 11371, 22988, 12397, 15248, 32850, 33079}\n",
      "dict_items([(\"Lemma('subsequent.a.01.subsequent')\", 3)])\n",
      "collecting tokens for  depends\n",
      "indices:    {32640, 32130, 16005, 32518, 28298, 3595, 11916, 23565, 2585, 21532, 4642, 26915, 21285, 12069, 20519, 1832, 13351, 2602, 30254, 1330, 28724, 4788, 2870, 30152, 19020, 2764, 32593, 12113, 3034, 11611, 16356, 25585, 27253, 14205}\n",
      "dict_items([(\"Lemma('depend_on.v.01.depend_on')\", 2), (\"Lemma('depend.v.01.depend')\", 4), (\"Lemma('depend_on.v.01.depend_upon')\", 1)])\n",
      "collecting tokens for  queen\n",
      "indices:    {24121}\n",
      "dict_items([])\n",
      "collecting tokens for  exhibit\n",
      "indices:    {3204, 23559, 777, 25106, 13332, 25110, 13720, 31665, 28607, 21831, 3414, 26586, 3169, 25698, 15716, 32741, 32740, 25700, 2665, 21105, 3186, 26110}\n",
      "dict_items([(\"Lemma('show.v.01.exhibit')\", 1), (\"Lemma('exhibit.v.01.exhibit')\", 6), (\"Lemma('expose.v.03.exhibit')\", 3), (\"Lemma('exhibit.n.01.exhibit')\", 1)])\n",
      "collecting tokens for  blue\n",
      "indices:    {11322, 21772}\n",
      "dict_items([])\n",
      "collecting tokens for  angel\n",
      "indices:    {1808}\n",
      "dict_items([(\"Lemma('group.n.01.group')\", 1)])\n",
      "collecting tokens for  import\n",
      "indices:    {22720, 32458, 29130, 14602, 26636, 25679, 11035, 23485, 23486}\n",
      "dict_items([(\"Lemma('meaning.n.01.import')\", 1), (\"Lemma('import.v.01.import')\", 1), (\"Lemma('import.n.02.import')\", 1)])\n",
      "collecting tokens for  twist\n",
      "indices:    {29902, 12783, 29903, 14483, 14100, 14101, 29206, 23668, 29533, 7743}\n",
      "dict_items([(\"Lemma('writhe.v.01.twist')\", 2), (\"Lemma('construction.n.06.twist')\", 2), (\"Lemma('flex.v.05.twist')\", 1), (\"Lemma('twist.v.05.twist')\", 1), (\"Lemma('device.n.03.twist')\", 1)])\n",
      "collecting tokens for  leap\n",
      "indices:    {31904, 30050, 25444, 19045, 12459, 2445, 33806, 19535, 9777, 6323, 14644, 31957}\n",
      "dict_items([(\"Lemma('jump.v.01.leap')\", 7), (\"Lemma('leap.n.02.leap')\", 2), (\"Lemma('leap.n.01.leap')\", 1)])\n",
      "collecting tokens for  gang\n",
      "indices:    {21763, 12676, 12639, 27401, 1289, 21755, 19900, 10141, 12702, 19455}\n",
      "dict_items([(\"Lemma('crowd.n.02.gang')\", 1), (\"Lemma('gang.n.03.gang')\", 1), (\"Lemma('gang.n.01.gang')\", 3)])\n",
      "collecting tokens for  candy\n",
      "indices:    {30364, 30491, 21004, 30492}\n",
      "dict_items([])\n",
      "collecting tokens for  hungry\n",
      "indices:    {10017, 10018, 18245, 16697, 27401, 27210, 33484, 33520, 35057, 23217, 33524, 36629, 7830, 12535, 12537, 27163, 36413}\n",
      "dict_items([(\"Lemma('hungry.a.01.hungry')\", 6), (\"Lemma('athirst.s.01.hungry')\", 1)])\n",
      "collecting tokens for  hunger\n",
      "indices:    {4832, 16870, 12198, 27400, 27401, 11209, 16017, 33521, 16018}\n",
      "dict_items([(\"Lemma('hunger.n.01.hunger')\", 5), (\"Lemma('hunger.n.02.hunger')\", 1)])\n",
      "collecting tokens for  temporarily\n",
      "indices:    {29729, 30950, 27401, 29738, 33227, 14986, 20525, 3215, 22864, 33233, 2322, 4251}\n",
      "dict_items([(\"Lemma('temporarily.r.01.temporarily')\", 4)])\n",
      "collecting tokens for  ambiguous\n",
      "indices:    {15715, 4, 10661, 16035, 33189, 33190, 5382, 31435, 5388, 10605, 10734, 4919, 33134, 25394, 10706, 11509, 10615, 13465}\n",
      "dict_items([(\"Lemma('equivocal.a.01.ambiguous')\", 8), (\"Lemma('ambiguous.a.02.ambiguous')\", 4), (\"Lemma('ambiguous.s.03.ambiguous')\", 1)])\n",
      "collecting tokens for  rancher\n",
      "indices:    {18276, 31463, 35850, 31435, 31438, 5072, 31441, 5050, 18234}\n",
      "dict_items([(\"Lemma('rancher.n.01.rancher')\", 4)])\n",
      "collecting tokens for  expert\n",
      "indices:    {29953, 26249, 21646, 37015, 1176, 36512, 34605, 23601, 8244, 15424, 15425, 5826, 31435, 12628, 11357, 23907, 15459, 9702, 22121, 30969, 20347, 639}\n",
      "dict_items([(\"Lemma('adept.s.01.expert')\", 2), (\"Lemma('expert.n.01.expert')\", 6)])\n",
      "collecting tokens for  jane\n",
      "indices:    {5926}\n",
      "dict_items([(\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  savings\n",
      "indices:    {15489, 21890}\n",
      "dict_items([(\"Lemma('savings.n.01.savings')\", 1)])\n",
      "collecting tokens for  desperately\n",
      "indices:    {18561, 35202, 36449, 33380, 2282, 17963, 2571, 1325, 8238, 23854, 32663, 25714, 7702, 18935, 11993, 14237}\n",
      "dict_items([(\"Lemma('urgently.r.01.desperately')\", 9), (\"Lemma('desperately.r.02.desperately')\", 1)])\n",
      "collecting tokens for  producers\n",
      "indices:    {26563, 14531, 16325, 22023, 14792, 14766, 14767, 14769, 14770, 25652, 11896, 2333}\n",
      "dict_items([(\"Lemma('producer.n.03.producer')\", 1), (\"Lemma('producer.n.02.producer')\", 2), (\"Lemma('manufacturer.n.02.producer')\", 6)])\n",
      "collecting tokens for  zinc\n",
      "indices:    {3429, 14766}\n",
      "dict_items([(\"Lemma('zinc.n.01.zinc')\", 1)])\n",
      "collecting tokens for  saint\n",
      "indices:    {19776, 6389, 1255}\n",
      "dict_items([(\"Lemma('saint.n.02.saint')\", 2)])\n",
      "collecting tokens for  cents\n",
      "indices:    {28416, 12001, 23528, 23080, 11816, 17581, 5136, 14769, 14770, 11735, 11739, 6653, 2750, 12607}\n",
      "dict_items([(\"Lemma('cent.n.01.cent')\", 10)])\n",
      "collecting tokens for  crossing\n",
      "indices:    {29962, 9611, 34956, 4493, 21390, 24368, 13113, 24123, 36414}\n",
      "dict_items([(\"Lemma('traverse.v.01.cross')\", 6), (\"Lemma('intersect.v.01.cross')\", 1)])\n",
      "collecting tokens for  brick\n",
      "indices:    {22144, 5440, 6376, 13033, 22025, 31561, 29229, 15118, 21647, 17405, 8051, 21212, 31549}\n",
      "dict_items([(\"Lemma('brick.n.01.brick')\", 5), (\"Lemma('brick.n.02.brick')\", 1)])\n",
      "collecting tokens for  monday\n",
      "indices:    {21934}\n",
      "dict_items([])\n",
      "collecting tokens for  advisory\n",
      "indices:    {23898, 20563, 23892, 22734}\n",
      "dict_items([])\n",
      "collecting tokens for  elementary\n",
      "indices:    {20584, 23578, 25260}\n",
      "dict_items([])\n",
      "collecting tokens for  attempts\n",
      "indices:    {672, 5312, 3234, 288, 11044, 15717, 1316, 32904, 21965, 24653, 3184, 30835, 2804, 2455, 33720, 13273, 27805}\n",
      "dict_items([(\"Lemma('attempt.n.01.attempt')\", 10), (\"Lemma('try.v.01.attempt')\", 2)])\n",
      "collecting tokens for  balanced\n",
      "indices:    {23610, 36326, 14086, 14919, 27083, 27564, 11515, 14928, 34737, 29905, 474, 27541, 11383, 14074, 26267, 4605, 4606}\n",
      "dict_items([(\"Lemma('poise.v.04.balance')\", 1), (\"Lemma('balanced.a.01.balanced')\", 9), (\"Lemma('balance.v.01.balance')\", 1)])\n",
      "collecting tokens for  duly\n",
      "indices:    {14880, 3721, 14761, 14863, 17334, 12505, 37020, 14879}\n",
      "dict_items([(\"Lemma('punctually.r.01.duly')\", 7)])\n",
      "collecting tokens for  evaluated\n",
      "indices:    {3906, 32357, 3175, 11688, 3721, 15755, 14830, 15733}\n",
      "dict_items([(\"Lemma('measure.v.04.evaluate')\", 8)])\n",
      "collecting tokens for  prestige\n",
      "indices:    {15757, 26735, 27767, 755, 12948, 31734, 12950, 22934, 4799}\n",
      "dict_items([(\"Lemma('prestige.n.01.prestige')\", 5)])\n",
      "collecting tokens for  newman\n",
      "indices:    {13688}\n",
      "dict_items([])\n",
      "collecting tokens for  matson\n",
      "indices:    {17633}\n",
      "dict_items([(\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  recovery\n",
      "indices:    {22789}\n",
      "dict_items([])\n",
      "collecting tokens for  excessive\n",
      "indices:    {25475, 27524, 25351, 3464, 21897, 11541, 30998, 32149, 25374, 22053, 26957, 4047, 32340, 11605, 30810, 32346, 25058, 14824, 32872, 5489, 8050, 25461}\n",
      "dict_items([(\"Lemma('excessive.s.01.excessive')\", 7)])\n",
      "collecting tokens for  moderate\n",
      "indices:    {13152, 27205, 4038, 24199, 21897, 22857, 27210, 3870, 2522, 3443, 2164, 5141, 1623, 3864, 3865, 3866, 1438}\n",
      "dict_items([(\"Lemma('moderate.a.01.moderate')\", 10), (\"Lemma('moderate.s.02.moderate')\", 2)])\n",
      "collecting tokens for  consonantal\n",
      "indices:    {16112, 16105, 16114, 16044}\n",
      "dict_items([(\"Lemma('consonantal.a.01.consonantal')\", 2)])\n",
      "collecting tokens for  linguistic\n",
      "indices:    {30250, 16044, 16081, 16083, 16085, 16086, 4985, 30238}\n",
      "dict_items([(\"Lemma('linguistic.a.01.linguistic')\", 3), (\"Lemma('linguistic.a.02.linguistic')\", 2)])\n",
      "collecting tokens for  component\n",
      "indices:    {3327, 2852, 32837, 4550, 32871, 4552, 4554, 4559, 13648, 4562, 16084, 24598, 16215, 14616, 32377, 3326, 4031}\n",
      "dict_items([(\"Lemma('component.n.03.component')\", 3), (\"Lemma('part.n.01.component')\", 4), (\"Lemma('component.n.01.component')\", 6)])\n",
      "collecting tokens for  attacked\n",
      "indices:    {24205, 19345, 1939, 28063, 15778, 31657, 10668, 36921, 26170, 12863, 22981, 35536, 6745, 21482, 21485, 28531, 27126, 22777, 8447}\n",
      "dict_items([(\"Lemma('attack.v.01.attack')\", 12), (\"Lemma('attack.v.03.attack')\", 3), (\"Lemma('attack.v.02.attack')\", 4)])\n",
      "collecting tokens for  clock\n",
      "indices:    {23840, 13601, 6377, 6380, 35730, 13395, 6393, 19706}\n",
      "dict_items([(\"Lemma('clock.n.01.clock')\", 4)])\n",
      "collecting tokens for  outstanding\n",
      "indices:    {22400, 29287, 488, 21831, 32654, 14673, 32630, 28572, 27006}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('outstanding.s.02.outstanding')\", 1), (\"Lemma('outstanding.s.01.outstanding')\", 1)])\n",
      "collecting tokens for  contribution\n",
      "indices:    {24064, 16000, 16001, 648, 27149, 22030, 16142, 15392, 14757, 25650, 26674, 11963, 16191, 16321, 25025, 16326, 22729, 1739, 29136, 6096, 6097, 14932, 1749, 21083, 2790, 1130, 32239, 11760, 31860, 25726}\n",
      "dict_items([(\"Lemma('contribution.n.04.contribution')\", 2), (\"Lemma('contribution.n.01.contribution')\", 12), (\"Lemma('contribution.n.03.contribution')\", 2), (\"Lemma('contribution.n.02.contribution')\", 2)])\n",
      "collecting tokens for  suitable\n",
      "indices:    {23552, 23841, 14721, 29890, 29956, 16292, 15110, 12104, 3497, 21642, 30477, 15118, 32623, 24567, 11863, 15163, 3613}\n",
      "dict_items([(\"Lemma('suitable.s.01.suitable')\", 2)])\n",
      "collecting tokens for  strongest\n",
      "indices:    {195, 23981, 22287, 1680, 16047, 26774, 22902, 27546, 32958, 24605, 14110, 1375}\n",
      "dict_items([(\"Lemma('strong.a.01.strong')\", 4), (\"Lemma('potent.s.02.strong')\", 1)])\n",
      "collecting tokens for  balls\n",
      "indices:    {8608, 12568, 368, 36304, 22992, 21139, 27957, 27958, 374, 6680, 5113, 6587}\n",
      "dict_items([(\"Lemma('ball.n.01.ball')\", 1), (\"Lemma('ball.n.03.ball')\", 1), (\"Lemma('musket_ball.n.01.ball')\", 2), (\"Lemma('testis.n.01.ball')\", 1)])\n",
      "collecting tokens for  pilot\n",
      "indices:    {32256, 25857, 18691, 14725, 5510, 5511, 25865, 5513, 5515, 5517, 5518, 18705, 25874, 23315, 5532, 23327, 23329, 30506, 5558, 33228, 30546, 29909, 30551, 29911, 30552, 7388, 21726, 30574, 11889, 18681, 30587}\n",
      "dict_items([(\"Lemma('pilot.n.01.pilot')\", 3), (\"Lemma('navigate.v.02.pilot')\", 1)])\n",
      "collecting tokens for  bomber\n",
      "indices:    {31262, 31368, 15530, 21711, 30320, 21712, 15539, 21724, 21726}\n",
      "dict_items([(\"Lemma('bomber.n.01.bomber')\", 2)])\n",
      "collecting tokens for  incredible\n",
      "indices:    {36928, 16007, 13928, 26215, 8877, 27439, 25776, 1329, 1950, 33270, 23000, 6332, 21726, 1310}\n",
      "dict_items([(\"Lemma('incredible.a.01.incredible')\", 7)])\n",
      "collecting tokens for  sail\n",
      "indices:    {12411, 12420, 12366, 29015}\n",
      "dict_items([(\"Lemma('cruise.n.01.sail')\", 1), (\"Lemma('sail.v.01.sail')\", 2)])\n",
      "collecting tokens for  crushed\n",
      "indices:    {23074, 708, 27022, 27295, 688, 13588, 29526, 29498, 12383}\n",
      "dict_items([(\"Lemma('oppress.v.01.crush')\", 3), (\"Lemma('crushed.s.01.crushed')\", 2), (\"Lemma('crush.v.04.crush')\", 1)])\n",
      "collecting tokens for  sighed\n",
      "indices:    {36106, 19984, 26130, 9884, 10784, 7075, 423, 36650, 36398, 8240, 19895, 35001, 14521, 9290, 22477, 37070, 8283, 36831, 7656, 35199}\n",
      "dict_items([(\"Lemma('sigh.v.01.sigh')\", 19), (\"Lemma('sigh.v.02.sigh')\", 1)])\n",
      "collecting tokens for  permit\n",
      "indices:    {25088, 11104, 24451, 14782, 7753, 34027, 27788, 21964, 4622, 12274, 21906, 27800, 15934, 3071}\n",
      "dict_items([(\"Lemma('let.v.01.permit')\", 5), (\"Lemma('permit.v.01.permit')\", 8)])\n",
      "collecting tokens for  senator\n",
      "indices:    {10628}\n",
      "dict_items([(\"Lemma('senator.n.01.senator')\", 1)])\n",
      "collecting tokens for  combat\n",
      "indices:    {25348, 18694, 12812, 5772, 12814, 12817, 11174, 19372, 12590, 26040, 5945, 12856, 20668, 16066, 14418, 28503, 15466, 18667, 30187, 15468, 18678}\n",
      "dict_items([(\"Lemma('combat.n.01.combat')\", 12), (\"Lemma('battle.v.01.combat')\", 4)])\n",
      "collecting tokens for  grandmother\n",
      "indices:    {36995, 11975, 21364, 15828, 8694, 13563, 13566}\n",
      "dict_items([(\"Lemma('grandma.n.01.grandmother')\", 4)])\n",
      "collecting tokens for  chairs\n",
      "indices:    {21026, 34275, 24580, 7461, 30691, 33579, 22155, 8495, 7441, 26385, 8857, 22516, 8694, 19512, 30040, 9240, 22490, 9311}\n",
      "dict_items([(\"Lemma('chair.n.01.chair')\", 7)])\n",
      "collecting tokens for  merge\n",
      "indices:    {7906, 21957, 21959, 9992, 9994, 27979, 14925, 31858, 30040}\n",
      "dict_items([(\"Lemma('unify.v.01.merge')\", 7), (\"Lemma('blend.v.03.merge')\", 2)])\n",
      "collecting tokens for  forgiveness\n",
      "indices:    {24270, 35981, 24278}\n",
      "dict_items([])\n",
      "collecting tokens for  yeah\n",
      "indices:    {7236}\n",
      "dict_items([])\n",
      "collecting tokens for  propose\n",
      "indices:    {16226, 16227, 16899, 15879, 13782, 20215, 27705, 11100, 27709, 24158}\n",
      "dict_items([(\"Lemma('propose.v.01.propose')\", 4), (\"Lemma('aim.v.02.propose')\", 1), (\"Lemma('propose.v.05.propose')\", 1), (\"Lemma('project.v.08.propose')\", 4)])\n",
      "collecting tokens for  inadequate\n",
      "indices:    {35458, 4, 25482, 21899, 12050, 15251, 14999, 23576, 14375, 32300, 4911, 16311, 26042, 4671, 33219, 33220, 25288, 32121, 23505, 1241, 23643, 16226, 9578, 14062, 4596, 32377}\n",
      "dict_items([(\"Lemma('inadequate.a.01.inadequate')\", 13)])\n",
      "collecting tokens for  track\n",
      "indices:    {20320, 28745, 20237, 20669, 24703}\n",
      "dict_items([])\n",
      "collecting tokens for  trace\n",
      "indices:    {3297, 34497, 2181, 4936, 3242, 27147, 34381, 14703, 1712, 30769, 24721, 14098, 6937, 14491, 18207}\n",
      "dict_items([(\"Lemma('hound.v.01.trace')\", 1), (\"Lemma('trace.n.01.trace')\", 3), (\"Lemma('trace.v.01.trace')\", 4), (\"Lemma('trace.v.02.trace')\", 2), (\"Lemma('trace.n.02.trace')\", 2)])\n",
      "collecting tokens for  brood\n",
      "indices:    {3755, 3738, 33790, 3735, 3736, 3674, 28957, 14462}\n",
      "dict_items([(\"Lemma('brood.n.01.brood')\", 6)])\n",
      "collecting tokens for  nigger\n",
      "indices:    {6512, 6522, 6235, 6165}\n",
      "dict_items([(\"Lemma('nigger.n.01.nigger')\", 4)])\n",
      "collecting tokens for  spiral\n",
      "indices:    {3303, 4488, 1450, 1483, 1451, 1453, 1491}\n",
      "dict_items([(\"Lemma('spiral.n.01.spiral')\", 6), (\"Lemma('gyrate.v.01.spiral')\", 1)])\n",
      "collecting tokens for  descending\n",
      "indices:    {9352, 1483, 24751, 3535, 24758, 14103, 4216, 7354, 26652}\n",
      "dict_items([(\"Lemma('descend.v.01.descend')\", 5), (\"Lemma('condescend.v.02.descend')\", 1), (\"Lemma('descending.a.01.descending')\", 1), (\"Lemma('derive.v.05.descend')\", 1)])\n",
      "collecting tokens for  immortality\n",
      "indices:    {1474, 1475, 4676, 1476, 1477, 31719, 1483, 1488, 1490, 13815, 31800, 1500, 1469}\n",
      "dict_items([(\"Lemma('immortality.n.01.immortality')\", 11)])\n",
      "collecting tokens for  ethics\n",
      "indices:    {20912, 4880, 25504, 25495}\n",
      "dict_items([(\"Lemma('ethical_motive.n.01.ethics')\", 1)])\n",
      "collecting tokens for  media\n",
      "indices:    {32460, 25357, 1424, 3216, 31794, 3219, 32468, 25917, 2302}\n",
      "dict_items([(\"Lemma('medium.n.02.medium')\", 2)])\n",
      "collecting tokens for  financing\n",
      "indices:    {32577, 2753, 23619, 2754, 28675, 32615, 32616, 23881, 32460, 32622, 20432, 32447, 14998, 15005, 2751}\n",
      "dict_items([(\"Lemma('financing.n.01.financing')\", 5), (\"Lemma('finance.v.01.finance')\", 3)])\n",
      "collecting tokens for  advantages\n",
      "indices:    {32544, 30787, 23524, 32582, 18758, 4585, 6763, 32460, 11405, 32558, 14925, 14225, 16274, 30582, 32476, 14942, 1087}\n",
      "dict_items([(\"Lemma('advantage.n.01.advantage')\", 8)])\n",
      "collecting tokens for  faces\n",
      "indices:    {36480, 18849, 6915, 35557, 10790, 12998, 30504, 9641, 35210, 36748, 24882, 15414, 18234}\n",
      "dict_items([(\"Lemma('confront.v.02.face')\", 1), (\"Lemma('face.n.01.face')\", 3), (\"Lemma('face.n.03.face')\", 1), (\"Lemma('confront.v.03.face')\", 1), (\"Lemma('confront.v.01.face')\", 1)])\n",
      "collecting tokens for  widespread\n",
      "indices:    {3, 22020, 25349, 24198, 8853, 32155, 25500, 3229, 25891, 1321, 23223, 23493, 2632, 1226, 1237, 25824, 3424, 31208, 3818, 32239, 11120, 14704, 11633}\n",
      "dict_items([(\"Lemma('far-flung.s.01.widespread')\", 3), (\"Lemma('widespread.s.01.widespread')\", 9)])\n",
      "collecting tokens for  hate\n",
      "indices:    {28418, 26252, 19472, 12692, 14621, 8098, 8099, 6569, 30258, 27699, 35127, 21182, 17216, 32073, 27722, 15830, 19286, 8043, 7147, 35183, 7928, 7929, 26106}\n",
      "dict_items([(\"Lemma('hate.v.01.hate')\", 20), (\"Lemma('hate.n.01.hate')\", 2)])\n",
      "collecting tokens for  shifting\n",
      "indices:    {23242, 4234, 11244, 22605, 15824, 15515, 32572, 10141}\n",
      "dict_items([(\"Lemma('shifting.s.01.shifting')\", 1), (\"Lemma('transfer.v.04.shift')\", 1), (\"Lemma('switch.v.04.shift')\", 3), (\"Lemma('shift.v.05.shift')\", 1), (\"Lemma('shift.v.07.shift')\", 1), (\"Lemma('shift.v.06.shift')\", 1)])\n",
      "collecting tokens for  fitting\n",
      "indices:    {4896, 26659, 28814, 1780, 15191, 4894}\n",
      "dict_items([(\"Lemma('fitting.s.02.fitting')\", 1), (\"Lemma('fit.v.05.fit')\", 1), (\"Lemma('fitting.s.01.fitting')\", 1), (\"Lemma('fit.v.04.fit')\", 1)])\n",
      "collecting tokens for  fox\n",
      "indices:    {9946, 996}\n",
      "dict_items([(\"Lemma('fox.n.01.fox')\", 1), (\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  sticks\n",
      "indices:    {13120, 8865, 8609, 30383, 33458, 30387, 23730, 15220, 9688, 31482, 29563, 7133}\n",
      "dict_items([(\"Lemma('stick.n.01.stick')\", 2), (\"Lemma('lodge.v.02.stick')\", 1), (\"Lemma('stick.n.02.stick')\", 1)])\n",
      "collecting tokens for  laying\n",
      "indices:    {3758}\n",
      "dict_items([(\"Lemma('laying.n.01.laying')\", 1)])\n",
      "collecting tokens for  frames\n",
      "indices:    {11907, 2439, 7434, 29717, 29722, 29723, 29725, 29726, 29729, 29730, 29734, 36135, 29864, 29742, 29748, 181, 193, 29768, 1622, 29797, 2408, 2409, 29807}\n",
      "dict_items([(\"Lemma('frame.n.02.frame')\", 3), (\"Lemma('inning.n.01.frame')\", 2), (\"Lemma('frame.n.01.frame')\", 2)])\n",
      "collecting tokens for  transom\n",
      "indices:    {29761, 29729, 29797, 29734, 29768, 29801, 29802, 29717, 29720, 29721, 29787, 29726}\n",
      "dict_items([])\n",
      "collecting tokens for  admirable\n",
      "indices:    {26273, 12545, 11009, 2693, 5445, 12583, 26890, 26219, 26074}\n",
      "dict_items([(\"Lemma('admirable.s.01.admirable')\", 3), (\"Lemma('admirable.s.02.admirable')\", 1)])\n",
      "collecting tokens for  continuity\n",
      "indices:    {31872, 2145, 2178, 14210, 2147, 2176, 14690, 31914, 26970, 1744, 4977, 26074, 2167, 2169, 31930, 31899, 31933}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('continuity.n.01.continuity')\", 10)])\n",
      "collecting tokens for  yang\n",
      "indices:    {28157}\n",
      "dict_items([])\n",
      "collecting tokens for  reflecting\n",
      "indices:    {4705, 33189, 29414, 36971, 22157, 11246, 19504, 7537, 24658, 15477, 31190, 19607}\n",
      "dict_items([(\"Lemma('reflect.v.01.reflect')\", 6), (\"Lemma('reflect.v.03.reflect')\", 4), (\"Lemma('reflect.v.04.reflect')\", 1)])\n",
      "collecting tokens for  elderly\n",
      "indices:    {8258, 33412, 421, 24996, 7434, 724, 5652, 28661, 8221}\n",
      "dict_items([(\"Lemma('aged.s.01.elderly')\", 6)])\n",
      "collecting tokens for  stiffly\n",
      "indices:    {33412, 8815, 8818, 5622, 5655, 34070, 8506, 10430}\n",
      "dict_items([(\"Lemma('stiffly.r.01.stiffly')\", 5), (\"Lemma('rigidly.r.01.stiffly')\", 1)])\n",
      "collecting tokens for  forming\n",
      "indices:    {29635, 3204, 6598, 3654, 29801, 35471, 36019, 22516, 29301, 4118, 20568, 7352}\n",
      "dict_items([(\"Lemma('form.v.01.form')\", 1), (\"Lemma('form.v.02.form')\", 3), (\"Lemma('form.v.03.form')\", 4), (\"Lemma('shape.v.03.form')\", 3), (\"Lemma('shape.v.02.form')\", 1)])\n",
      "collecting tokens for  kick\n",
      "indices:    {1992, 34092, 34093, 1973, 7158, 18555}\n",
      "dict_items([(\"Lemma('kick.n.01.kick')\", 1)])\n",
      "collecting tokens for  lip\n",
      "indices:    {29601, 16963, 6435, 10950, 10951, 7878, 28393, 11180, 36237, 20431, 23952, 31543}\n",
      "dict_items([(\"Lemma('lip.n.01.lip')\", 6)])\n",
      "collecting tokens for  moments\n",
      "indices:    {2692, 26505, 24971, 19988, 26521, 6687, 6563, 26790, 26791, 11051, 22960, 3132, 26430, 13642, 10444, 26575, 32207, 5974, 2652, 33762, 21733, 19309, 36079, 6255, 14707, 26484, 14708, 9717}\n",
      "dict_items([(\"Lemma('moment.n.01.moment')\", 10), (\"Lemma('moment.n.02.moment')\", 4)])\n",
      "collecting tokens for  tea\n",
      "indices:    {22550, 20894, 111}\n",
      "dict_items([(\"Lemma('group.n.01.group')\", 1)])\n",
      "collecting tokens for  visitors\n",
      "indices:    {27587, 22534, 34697, 25226, 25515, 34956, 22544, 27985, 1877, 32630}\n",
      "dict_items([(\"Lemma('visitor.n.01.visitor')\", 1)])\n",
      "collecting tokens for  charcoal\n",
      "indices:    {29478, 11302, 19177, 19178, 19179, 19180, 5368, 29497, 11322, 29501}\n",
      "dict_items([(\"Lemma('charcoal.n.01.charcoal')\", 4), (\"Lemma('charcoal.n.02.charcoal')\", 2)])\n",
      "collecting tokens for  welcomed\n",
      "indices:    {33123, 30833, 24852, 21081, 24634, 20571, 28540, 28541, 13051}\n",
      "dict_items([(\"Lemma('welcome.v.01.welcome')\", 6), (\"Lemma('welcome.v.02.welcome')\", 2), (\"Lemma('welcome.v.03.welcome')\", 1)])\n",
      "collecting tokens for  finals\n",
      "indices:    {28537, 22181}\n",
      "dict_items([])\n",
      "collecting tokens for  elaborate\n",
      "indices:    {5024, 16289, 2630}\n",
      "dict_items([(\"Lemma('detailed.s.01.elaborate')\", 1), (\"Lemma('elaborate.s.01.elaborate')\", 2)])\n",
      "collecting tokens for  periodic\n",
      "indices:    {4808, 12322, 33007}\n",
      "dict_items([(\"Lemma('periodic.a.01.periodic')\", 1)])\n",
      "collecting tokens for  jones\n",
      "indices:    {35076}\n",
      "dict_items([])\n",
      "collecting tokens for  seventh\n",
      "indices:    {28039}\n",
      "dict_items([])\n",
      "collecting tokens for  targets\n",
      "indices:    {28480, 32192, 28514, 28515, 28517, 29100, 28525, 29101, 814, 30382, 18672, 28468, 28470, 31358}\n",
      "dict_items([(\"Lemma('target.n.03.target')\", 1)])\n",
      "collecting tokens for  recognition\n",
      "indices:    {2184, 25500, 25293, 16431, 27760, 1425, 31922, 11282, 11860, 11446, 14679, 24700}\n",
      "dict_items([(\"Lemma('recognition.n.02.recognition')\", 2), (\"Lemma('recognition.n.01.recognition')\", 4), (\"Lemma('recognition.n.03.recognition')\", 1)])\n",
      "collecting tokens for  growing\n",
      "indices:    {17923, 2570, 24076, 7701, 27670, 25117, 25121, 27684, 16420, 27179, 16437, 13368, 34880, 4678, 27732, 30296, 26725, 26731, 10860, 11893, 15484, 27772, 2686, 3711, 29825, 25732, 15495, 11929, 13979, 8864, 3745, 24232, 21676, 18620, 11967, 30404, 18632, 8920, 1256, 2303, 28417, 12547, 9995, 9997, 5405, 7967, 30499, 12074, 27953, 27954, 12087, 16698, 21820, 10052, 22344, 23381, 27997, 16222, 2399, 8542, 10082, 24425, 18297, 25468, 18304, 14223, 13204, 5015, 11674, 23969, 35759, 11706, 16316, 11715, 31186, 23513, 1507, 36327, 34792, 24043, 26091, 27635, 6141, 28670}\n",
      "dict_items([(\"Lemma('grow.v.02.grow')\", 18), (\"Lemma('turn.v.07.grow')\", 9), (\"Lemma('grow.v.03.grow')\", 6), (\"Lemma('originate.v.01.grow')\", 2), (\"Lemma('grow.v.04.grow')\", 2), (\"Lemma('grow.v.08.grow')\", 1), (\"Lemma('mature.v.01.grow')\", 2), (\"Lemma('growth.n.01.growing')\", 2)])\n",
      "collecting tokens for  pale\n",
      "indices:    {13572, 11322, 26631, 35660, 14416, 4113, 27290}\n",
      "dict_items([(\"Lemma('pale.s.03.pale')\", 1), (\"Lemma('pale.s.01.pale')\", 2), (\"Lemma('pale.s.02.pale')\", 1)])\n",
      "collecting tokens for  lyric\n",
      "indices:    {14561, 26404, 14565, 14536, 1802, 10574, 14543, 25999, 14676, 1718, 14553}\n",
      "dict_items([(\"Lemma('lyric.n.01.lyric')\", 5), (\"Lemma('lyric.s.01.lyric')\", 2)])\n",
      "collecting tokens for  negotiations\n",
      "indices:    {23747, 22628, 21446, 21449, 23882, 14922, 22636, 25161, 22604, 24655, 22605, 16337, 24656, 20279, 20568, 22652, 22621, 22591}\n",
      "dict_items([(\"Lemma('negotiation.n.01.negotiation')\", 2)])\n",
      "collecting tokens for  joining\n",
      "indices:    {23520, 16106, 27403, 13355, 2221, 13328, 23922, 13151, 26391, 32828, 27645, 24510, 13535}\n",
      "dict_items([(\"Lemma('join.v.02.join')\", 2), (\"Lemma('join.v.01.join')\", 10)])\n",
      "collecting tokens for  relieve\n",
      "indices:    {130, 28035, 27400, 11753, 27403, 26965, 32956, 6879}\n",
      "dict_items([(\"Lemma('relieve.v.01.relieve')\", 5), (\"Lemma('remedy.v.02.relieve')\", 1), (\"Lemma('salvage.v.01.relieve')\", 1)])\n",
      "collecting tokens for  inner\n",
      "indices:    {7552, 26114, 27397, 28042, 13329, 30740, 17559, 29591, 5401, 793, 32895, 27554, 29859, 29608, 14633, 4650, 4652, 29742, 29744, 4656, 17721, 24258, 19533, 5853, 2915, 13924, 27238, 2155, 1007, 27380, 12790, 8063, 17016, 22655}\n",
      "dict_items([(\"Lemma('inner.a.02.inner')\", 5), (\"Lemma('inner.s.01.inner')\", 10), (\"Lemma('inner.s.03.inner')\", 3)])\n",
      "collecting tokens for  blonde\n",
      "indices:    {36707, 18853, 18854, 37033, 30954, 34985, 30892, 36653, 36649, 22517, 18870, 30901, 36697}\n",
      "dict_items([(\"Lemma('blond.n.01.blonde')\", 2), (\"Lemma('blond.a.01.blonde')\", 1)])\n",
      "collecting tokens for  rev\n",
      "indices:    {16724}\n",
      "dict_items([(\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  lolotte\n",
      "indices:    {16728}\n",
      "dict_items([(\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  appointment\n",
      "indices:    {31106, 20581, 27591, 36616, 20428, 465, 17334, 24090, 891}\n",
      "dict_items([(\"Lemma('appointment.n.01.appointment')\", 2), (\"Lemma('date.n.03.appointment')\", 1)])\n",
      "collecting tokens for  burma\n",
      "indices:    {26036}\n",
      "dict_items([])\n",
      "collecting tokens for  proof\n",
      "indices:    {3719, 36296, 4363, 14027, 11821, 34542, 33363, 20852, 27381, 4308, 4317, 21311}\n",
      "dict_items([(\"Lemma('proof.n.02.proof')\", 4), (\"Lemma('proof.n.01.proof')\", 2)])\n",
      "collecting tokens for  influential\n",
      "indices:    {30277, 31880, 31721, 31241, 28398, 31733}\n",
      "dict_items([])\n",
      "collecting tokens for  semester\n",
      "indices:    {33187, 33156, 33098, 33110, 33144, 153, 154, 155}\n",
      "dict_items([])\n",
      "collecting tokens for  interviewed\n",
      "indices:    {25124, 23174, 13159, 33098, 15738, 13171, 9492, 27576, 23130, 13151}\n",
      "dict_items([(\"Lemma('interview.v.01.interview')\", 6), (\"Lemma('interview.v.02.interview')\", 3), (\"Lemma('interview.v.03.interview')\", 1)])\n",
      "collecting tokens for  christianity\n",
      "indices:    {28003}\n",
      "dict_items([])\n",
      "collecting tokens for  tended\n",
      "indices:    {13632, 27555, 4963, 2469, 12072, 22602, 15402, 5548, 33037, 22670, 31856, 31827, 13268, 25493, 27734, 7705, 18298, 26717}\n",
      "dict_items([(\"Lemma('tend.v.01.tend')\", 12), (\"Lemma('tend.v.02.tend')\", 2), (\"Lemma('tend.v.03.tend')\", 1)])\n",
      "collecting tokens for  organ\n",
      "indices:    {30466}\n",
      "dict_items([])\n",
      "collecting tokens for  salesmen\n",
      "indices:    {15744, 36608, 15748, 15749, 26725, 15609, 15753, 15737, 11699, 15736, 11705, 15740, 36606, 11679}\n",
      "dict_items([(\"Lemma('salesman.n.01.salesman')\", 11)])\n",
      "collecting tokens for  satisfied\n",
      "indices:    {33166, 2329, 20765, 12063, 30497, 14499, 30892, 8237, 5296, 9393, 16439, 25799, 12619, 32857, 36575, 11488, 357, 16101, 8680, 13803, 749, 35063, 892, 31231}\n",
      "dict_items([(\"Lemma('meet.v.04.satisfy')\", 2), (\"Lemma('satisfy.v.01.satisfy')\", 3), (\"Lemma('satisfied.s.01.satisfied')\", 10), (\"Lemma('satisfy.v.02.satisfy')\", 6)])\n",
      "collecting tokens for  sites\n",
      "indices:    {131, 21608, 1815, 1837, 14733, 1816, 5431, 1880, 22745, 1882, 1884, 24887, 1914, 14015}\n",
      "dict_items([(\"Lemma('site.n.01.site')\", 10)])\n",
      "collecting tokens for  etcetera\n",
      "indices:    {1824, 1865, 8202, 1899, 1866, 1906, 1881, 1882, 1915}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('etcetera.n.01.etcetera')\", 8), (\"Lemma('and_so_forth.r.01.etcetera')\", 1)])\n",
      "collecting tokens for  cooperation\n",
      "indices:    {32256, 21536, 28610, 32356, 22343, 24903, 32137, 2155, 2156, 20334, 32503, 20248, 28699, 14748, 4607}\n",
      "dict_items([(\"Lemma('cooperation.n.01.cooperation')\", 3)])\n",
      "collecting tokens for  grants\n",
      "indices:    {14731, 15002, 14748, 15007, 15008, 24122, 20299, 20173, 20183, 23516, 20191, 20199, 20204, 20206, 20207, 20208, 20209, 20212, 20214}\n",
      "dict_items([(\"Lemma('grant.n.01.grant')\", 3), (\"Lemma('grant.n.02.grant')\", 1)])\n",
      "collecting tokens for  receive\n",
      "indices:    {27650, 12546, 516, 518, 138, 35979, 14602, 15370, 15, 27408, 25622, 24343, 36631, 24217, 24220, 11551, 27680, 28707, 24996, 3620, 15144, 16297, 3627, 17579, 6066, 22070, 22071, 8251, 15166, 30527, 2113, 28610, 20549, 5063, 1735, 25033, 13898, 21578, 21579, 30541, 28368, 31314, 20563, 24148, 20188, 14430, 4447, 20192, 21349, 27365, 487, 488, 25579, 877, 28269, 36978, 15219, 31096}\n",
      "dict_items([(\"Lemma('receive.v.01.receive')\", 26), (\"Lemma('experience.v.03.receive')\", 3), (\"Lemma('receive.v.05.receive')\", 6), (\"Lemma('pick_up.v.09.receive')\", 3), (\"Lemma('receive.v.02.receive')\", 6), (\"Lemma('welcome.v.02.receive')\", 1), (\"Lemma('receive.v.06.receive')\", 3), (\"Lemma('receive.v.08.receive')\", 1)])\n",
      "collecting tokens for  creator\n",
      "indices:    {1513}\n",
      "dict_items([(\"Lemma('godhead.n.01.Creator')\", 1)])\n",
      "collecting tokens for  corporation\n",
      "indices:    {14182, 22036, 32446}\n",
      "dict_items([(\"Lemma('corporation.n.01.corporation')\", 1)])\n",
      "collecting tokens for  designer\n",
      "indices:    {23105, 22083, 2054, 2055, 22285, 2096, 2032, 2045, 2036, 2070, 22071, 9145, 2044, 22077}\n",
      "dict_items([(\"Lemma('architect.n.01.designer')\", 1), (\"Lemma('interior_designer.n.01.designer')\", 1)])\n",
      "collecting tokens for  hats\n",
      "indices:    {21603, 35459, 9668, 21066, 11152, 9681, 1171, 22071, 9151}\n",
      "dict_items([(\"Lemma('hat.n.01.hat')\", 4)])\n",
      "collecting tokens for  sophisticated\n",
      "indices:    {22140, 12004, 13702, 19494, 13673, 11633, 1745, 22068, 9621, 26933, 22071, 11389, 2235, 32668, 9245, 11224}\n",
      "dict_items([(\"Lemma('sophisticated.a.01.sophisticated')\", 9), (\"Lemma('advanced.s.05.sophisticated')\", 1)])\n",
      "collecting tokens for  roger\n",
      "indices:    {21643}\n",
      "dict_items([])\n",
      "collecting tokens for  laid\n",
      "indices:    {29832, 29962, 11146, 27275, 7822, 12311, 20250, 17185, 13604, 17966, 30257, 22398, 9012, 13877, 28986, 30395, 29371, 20285, 11582, 23103, 31551, 1472, 30526, 9533, 25790, 30013, 30023, 7113, 27087, 29777, 29013, 35802, 34012, 7133, 18270, 23648, 29794, 36072, 19688, 7530, 35179, 17646, 22894, 881, 26098, 11508, 18169, 33404, 20094, 25727}\n",
      "dict_items([(\"Lemma('put.v.01.lay')\", 17), (\"Lemma('lay.v.02.lay')\", 6), (\"Lemma('lay.v.04.lay')\", 1), (\"Lemma('lay.v.03.lay')\", 2), (\"Lemma('lay.v.05.lay')\", 1)])\n",
      "collecting tokens for  assembled\n",
      "indices:    {14720, 16393, 28175, 28177, 26261, 29592, 14754, 14118, 29606, 14766, 26671, 26932, 17604, 12870, 32715, 31708, 26465, 15734, 22142}\n",
      "dict_items([(\"Lemma('meet.v.07.assemble')\", 8), (\"Lemma('assemble.v.01.assemble')\", 8), (\"Lemma('assemble.v.03.assemble')\", 1)])\n",
      "collecting tokens for  prayers\n",
      "indices:    {1408, 28387, 1413, 28265, 4715, 22365, 29967, 32688, 28177, 32221, 29983}\n",
      "dict_items([(\"Lemma('prayer.n.01.prayer')\", 2), (\"Lemma('entreaty.n.01.prayer')\", 1)])\n",
      "collecting tokens for  saved\n",
      "indices:    {36993, 29959, 29967, 5393, 23699, 15896, 37145, 8860, 23965, 12830, 15902, 36895, 29982, 15913, 13483, 15918, 15919, 23093, 20409, 7742, 32065, 12997, 3530, 28239, 4818, 12245, 30038, 31190, 12777, 28266, 28269, 27502, 10094, 17526, 30073, 23548}\n",
      "dict_items([(\"Lemma('salvage.v.01.save')\", 20), (\"Lemma('save.v.02.save')\", 8), (\"Lemma('deliver.v.08.save')\", 1), (\"Lemma('saved.a.01.saved')\", 1), (\"Lemma('keep_open.v.01.save')\", 1), (\"Lemma('spare.v.01.save')\", 1), (\"Lemma('save.v.06.save')\", 1), (\"Lemma('save.v.05.save')\", 2), (\"Lemma('save.v.04.save')\", 1)])\n",
      "collecting tokens for  representation\n",
      "indices:    {20741, 16167, 15913, 25097, 1421, 5391, 2707, 5396, 5395, 5398, 5397, 2708, 1302}\n",
      "dict_items([(\"Lemma('representation.n.01.representation')\", 5), (\"Lemma('representation.n.02.representation')\", 5), (\"Lemma('representation.n.03.representation')\", 1)])\n",
      "collecting tokens for  terribly\n",
      "indices:    {22849, 2658, 26371, 17796, 36870, 9606, 1257, 36845, 26128, 8754, 36498, 10840, 10617, 30938, 1150}\n",
      "dict_items([(\"Lemma('terribly.r.01.terribly')\", 8)])\n",
      "collecting tokens for  linda\n",
      "indices:    {9314}\n",
      "dict_items([])\n",
      "collecting tokens for  kay\n",
      "indices:    {22288}\n",
      "dict_items([])\n",
      "collecting tokens for  centered\n",
      "indices:    {15368, 17322, 11148, 33165, 31280, 33168, 3088, 23542, 33144, 3102}\n",
      "dict_items([(\"Lemma('focus_on.v.01.center')\", 4), (\"Lemma('focus_on.v.01.center_on')\", 2), (\"Lemma('centered.s.01.centered')\", 2)])\n",
      "collecting tokens for  one-half\n",
      "indices:    {15041, 2786, 26847, 15752, 22133, 11320, 15803, 13727}\n",
      "dict_items([(\"Lemma('one-half.n.01.one-half')\", 5), (\"Lemma('half.s.01.half')\", 1)])\n",
      "collecting tokens for  examination\n",
      "indices:    {5536, 5506, 17865, 3115, 3118, 28624, 15763, 1817, 5594, 14588}\n",
      "dict_items([(\"Lemma('examination.n.01.examination')\", 9)])\n",
      "collecting tokens for  vagina\n",
      "indices:    {30784, 30789, 30765, 30799, 30800, 30801, 30804, 30780, 30782, 30783}\n",
      "dict_items([])\n",
      "collecting tokens for  pause\n",
      "indices:    {34370, 10723, 34342, 2119, 1560, 35883, 1197, 23135, 30224, 5744, 22655, 26904, 6270, 35999}\n",
      "dict_items([(\"Lemma('pause.v.02.pause')\", 1), (\"Lemma('pause.n.01.pause')\", 5), (\"Lemma('hesitate.v.02.pause')\", 1)])\n",
      "collecting tokens for  devised\n",
      "indices:    {27080, 11497, 30091, 1197, 24915, 12756, 23925, 31605, 4793, 12475, 32668, 11389, 22783}\n",
      "dict_items([(\"Lemma('invent.v.01.devise')\", 11), (\"Lemma('organize.v.05.devise')\", 1)])\n",
      "collecting tokens for  minimum\n",
      "indices:    {29830, 31368, 30089, 28684, 6674, 1989, 30235, 30236, 15010, 15044, 1197, 1710, 23619, 32563, 2996, 37045, 11830, 2998, 14008, 30138, 15041, 15042, 15043, 11841, 15045, 3014, 15046, 15048, 12102, 30789, 23879, 15052, 24138, 27598, 15184, 15314, 5593, 5594, 30046, 1889, 30823, 3305, 4587, 15471, 28531, 30200, 2041}\n",
      "dict_items([(\"Lemma('minimal.a.01.minimum')\", 20), (\"Lemma('minimum.n.01.minimum')\", 9)])\n",
      "collecting tokens for  defendants\n",
      "indices:    {21315, 20138, 21678, 20143, 20144, 20145, 20148, 24693, 21303, 21311}\n",
      "dict_items([])\n",
      "collecting tokens for  indictment\n",
      "indices:    {21315, 22755, 12645, 21546, 2642, 12211, 27573, 21302, 18232, 18233, 21310}\n",
      "dict_items([(\"Lemma('indictment.n.01.indictment')\", 4), (\"Lemma('indictment.n.02.indictment')\", 1)])\n",
      "collecting tokens for  hell\n",
      "indices:    {18374, 6536, 28265, 18064, 19959, 10744, 35003, 27774}\n",
      "dict_items([])\n",
      "collecting tokens for  jay\n",
      "indices:    {31700}\n",
      "dict_items([])\n",
      "collecting tokens for  chemistry\n",
      "indices:    {27940, 14315, 11470, 23184, 3184, 25394, 11063, 157, 2622, 2623}\n",
      "dict_items([(\"Lemma('chemistry.n.01.chemistry')\", 5)])\n",
      "collecting tokens for  instructor\n",
      "indices:    {32713, 2075, 30532}\n",
      "dict_items([(\"Lemma('teacher.n.01.instructor')\", 1)])\n",
      "collecting tokens for  tasks\n",
      "indices:    {23872, 32193, 20994, 4805, 4581, 4583, 31271, 15175, 15177, 27115, 33068, 31177, 4619, 37074, 4627, 23259}\n",
      "dict_items([(\"Lemma('undertaking.n.01.task')\", 4), (\"Lemma('job.n.02.task')\", 3)])\n",
      "collecting tokens for  applying\n",
      "indices:    {29824, 31137, 2885, 35752, 2856, 28938, 35754, 15820, 35757, 31893, 14070, 7640}\n",
      "dict_items([(\"Lemma('give.v.20.apply')\", 1), (\"Lemma('put_on.v.07.apply')\", 1), (\"Lemma('apply.v.03.apply')\", 3), (\"Lemma('use.v.01.apply')\", 4), (\"Lemma('apply.v.02.apply')\", 1)])\n",
      "collecting tokens for  reviewed\n",
      "indices:    {4000, 11718, 21608, 15819, 11723, 10097, 25969, 33010, 340, 20279, 3993, 11514}\n",
      "dict_items([(\"Lemma('review.v.02.review')\", 5), (\"Lemma('review.v.01.review')\", 7)])\n",
      "collecting tokens for  efficacy\n",
      "indices:    {13667, 25475, 3174, 13672, 13673, 13677, 27545}\n",
      "dict_items([(\"Lemma('efficacy.n.01.efficacy')\", 5)])\n",
      "collecting tokens for  formulations\n",
      "indices:    {1349, 3174, 3173, 3149, 3151, 3153, 32889, 2559}\n",
      "dict_items([(\"Lemma('formulation.n.01.formulation')\", 5), (\"Lemma('conceptualization.n.01.formulation')\", 1), (\"Lemma('formulation.n.03.formulation')\", 1)])\n",
      "collecting tokens for  forget\n",
      "indices:    {25472, 27393, 32259, 27396, 29443, 36614, 23047, 2312, 17291, 29459, 14356, 17171, 7704, 34717, 30111, 27042, 17188, 27430, 24257, 14529, 22981, 8139, 24268, 10701, 18401, 29409, 34280, 24939, 26228, 34932, 11894, 10618, 29435, 10108, 30078}\n",
      "dict_items([(\"Lemma('forget.v.01.forget')\", 24), (\"Lemma('forget.v.03.forget')\", 2), (\"Lemma('forget.v.02.forget')\", 8)])\n",
      "collecting tokens for  preliminary\n",
      "indices:    {33094, 5031, 11291, 25322, 2187, 11308, 32652, 20685, 15249, 14807, 23960, 14810, 35643}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('preliminary.s.01.preliminary')\", 7)])\n",
      "collecting tokens for  oxygen\n",
      "indices:    {5506, 3083, 3084, 3085, 3086, 3088, 5539, 5552, 5553, 5554, 27958, 34744, 32700, 34498, 5571, 5572, 5574, 5576, 5577, 5578, 5580, 5581, 5582, 5583, 3279, 3285, 3295, 3816, 14829, 10094, 5492, 5493, 14845}\n",
      "dict_items([(\"Lemma('oxygen.n.01.oxygen')\", 26)])\n",
      "collecting tokens for  beckett\n",
      "indices:    {13434}\n",
      "dict_items([(\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  rack\n",
      "indices:    {7492, 18504, 18889, 18891, 18254, 17584, 11376, 29045, 36669}\n",
      "dict_items([(\"Lemma('rack.n.01.rack')\", 5), (\"Lemma('single-foot.v.01.rack')\", 2)])\n",
      "collecting tokens for  stepped\n",
      "indices:    {36737, 35972, 8837, 10005, 17045, 18457, 12442, 18592, 35764, 24373, 22971, 16956, 18111, 35144, 18889, 33992, 13131, 24141, 34511, 16994, 9186, 34029, 34033, 19825, 29175, 15486}\n",
      "dict_items([(\"Lemma('step.v.02.step')\", 2), (\"Lemma('step.v.01.step')\", 13)])\n",
      "collecting tokens for  evidently\n",
      "indices:    {10619}\n",
      "dict_items([(\"Lemma('obviously.r.01.evidently')\", 1)])\n",
      "collecting tokens for  stomach\n",
      "indices:    {18562, 11138, 12679, 23306, 36240, 28438, 17310, 36641, 17314, 10793, 19501, 16174, 10671, 17971, 9012, 17974, 11582, 6980, 25669, 17865, 17610, 23374, 9807, 9197, 33520, 4084, 4088}\n",
      "dict_items([(\"Lemma('stomach.n.01.stomach')\", 16), (\"Lemma('abdomen.n.01.stomach')\", 4)])\n",
      "collecting tokens for  chairman\n",
      "indices:    {22501, 24776, 234, 20428, 21069, 21743, 24661, 22102, 23767, 20985, 22874, 22875}\n",
      "dict_items([(\"Lemma('president.n.04.chairman')\", 1)])\n",
      "collecting tokens for  produce\n",
      "indices:    {25732, 14213, 4231, 4234, 26122, 28556, 30733, 30732, 28554, 12178, 12179, 660, 30740, 27157, 14485, 26008, 14360, 23835, 27167, 25504, 4267, 14383, 3632, 23983, 24244, 20023, 1090, 196, 15429, 21574, 1605, 1612, 22861, 11982, 7629, 30420, 14422, 13910, 2139, 32094, 94, 11488, 29150, 14816, 12132, 36072, 4459, 31083, 4471, 30200, 28671, 4476, 22141, 21758, 1279}\n",
      "dict_items([(\"Lemma('produce.v.04.produce')\", 2), (\"Lemma('produce.v.01.produce')\", 25), (\"Lemma('grow.v.07.produce')\", 5), (\"Lemma('produce.n.01.produce')\", 2), (\"Lemma('produce.v.03.produce')\", 9), (\"Lemma('produce.v.02.produce')\", 8)])\n",
      "collecting tokens for  blocked\n",
      "indices:    {6211, 22861, 30574, 17487, 15153, 8532, 9812, 20664, 14557}\n",
      "dict_items([(\"Lemma('obstruct.v.01.block')\", 2), (\"Lemma('barricade.v.01.block')\", 4), (\"Lemma('jam.v.04.block')\", 1)])\n",
      "collecting tokens for  avoid\n",
      "indices:    {8504, 30202, 30804}\n",
      "dict_items([(\"Lemma('debar.v.02.avoid')\", 2), (\"Lemma('avoid.v.03.avoid')\", 1)])\n",
      "collecting tokens for  embarrassing\n",
      "indices:    {7520, 23843, 22861, 13741, 8688, 17495, 2366, 27167}\n",
      "dict_items([(\"Lemma('embarrassing.s.02.embarrassing')\", 2), (\"Lemma('awkward.s.05.embarrassing')\", 3)])\n",
      "collecting tokens for  cage\n",
      "indices:    {1544, 13389, 24509, 13392, 13391, 1554, 13202, 7644, 7645}\n",
      "dict_items([(\"Lemma('cage.n.01.cage')\", 2), (\"Lemma('cage.n.02.cage')\", 2)])\n",
      "collecting tokens for  invented\n",
      "indices:    {24644, 29926, 1163, 1554, 9843, 30485, 2453, 5909, 25627, 11455}\n",
      "dict_items([(\"Lemma('invent.v.01.invent')\", 7), (\"Lemma('fabricate.v.02.invent')\", 3)])\n",
      "collecting tokens for  marginal\n",
      "indices:    {16352, 1314, 8258, 11813, 5478, 22760, 4585, 33003, 32844, 32141, 16464, 4688, 16369, 22770, 16372, 32953, 32926, 16063}\n",
      "dict_items([(\"Lemma('borderline.s.01.marginal')\", 3), (\"Lemma('fringy.s.01.marginal')\", 4)])\n",
      "collecting tokens for  denial\n",
      "indices:    {15366, 32872, 32873, 32844, 15340, 14862, 14864, 25747, 6835, 10621, 35997, 32862}\n",
      "dict_items([(\"Lemma('denial.n.02.denial')\", 2), (\"Lemma('denial.n.03.denial')\", 1), (\"Lemma('denial.n.01.denial')\", 3)])\n",
      "collecting tokens for  maker\n",
      "indices:    {4928, 21856, 4929, 21860, 2438, 15590, 23439, 2641, 2453, 23450}\n",
      "dict_items([(\"Lemma('maker.n.01.maker')\", 5)])\n",
      "collecting tokens for  michelangelo\n",
      "indices:    {7595}\n",
      "dict_items([(\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  douglas\n",
      "indices:    {12487}\n",
      "dict_items([])\n",
      "collecting tokens for  substantially\n",
      "indices:    {2752, 25088, 24067, 15207, 14761, 32137, 15229, 13167, 31983, 25393, 5457, 14227, 12273, 26261, 1808, 24635, 22301, 5438}\n",
      "dict_items([(\"Lemma('well.r.07.substantially')\", 9), (\"Lemma('substantially.r.02.substantially')\", 1)])\n",
      "collecting tokens for  carmer\n",
      "indices:    {18575}\n",
      "dict_items([(\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  outline\n",
      "indices:    {18855, 27656, 29718, 23672, 13788}\n",
      "dict_items([(\"Lemma('outline.n.01.outline')\", 1), (\"Lemma('outline.n.02.outline')\", 1), (\"Lemma('sketch.v.02.outline')\", 1)])\n",
      "collecting tokens for  card\n",
      "indices:    {34435, 9860, 27655, 36622, 36624, 21787, 26782, 18590, 19488, 12588, 17968, 33490, 12000, 33513, 18540, 17523, 33014, 33016, 33022, 33023}\n",
      "dict_items([(\"Lemma('card.n.03.card')\", 1), (\"Lemma('card.n.01.card')\", 2)])\n",
      "collecting tokens for  rapid\n",
      "indices:    {2560, 10884, 32133, 3207, 3986, 15508, 5524, 15510, 2839, 28696, 35617, 11298, 31010, 4270, 2875, 5438, 3656, 20296, 23627, 12510, 3171, 20837, 3173, 9336, 18810}\n",
      "dict_items([(\"Lemma('rapid.s.01.rapid')\", 17)])\n",
      "collecting tokens for  commercially\n",
      "indices:    {3171, 14727, 28711, 3437, 28717, 11600, 2865, 11061, 37142}\n",
      "dict_items([(\"Lemma('commercially.r.01.commercially')\", 6)])\n",
      "collecting tokens for  loneliness\n",
      "indices:    {7225, 8771, 7028, 26547}\n",
      "dict_items([(\"Lemma('loneliness.n.01.loneliness')\", 3)])\n",
      "collecting tokens for  incentive\n",
      "indices:    {33121, 32194, 19075, 4581, 23528, 32191, 22015, 11259, 11837, 32159}\n",
      "dict_items([(\"Lemma('incentive.n.01.incentive')\", 4)])\n",
      "collecting tokens for  mathematical\n",
      "indices:    {16333}\n",
      "dict_items([(\"Lemma('mathematical.a.01.mathematical')\", 1)])\n",
      "collecting tokens for  philosophers\n",
      "indices:    {27556, 5253, 16422, 9743, 11480, 14713, 14714, 11452}\n",
      "dict_items([(\"Lemma('philosopher.n.01.philosopher')\", 7)])\n",
      "collecting tokens for  picking\n",
      "indices:    {7269, 5928, 24585, 42, 16776, 13357, 16687, 13685, 7704, 19610, 5821}\n",
      "dict_items([(\"Lemma('clean.v.02.pick')\", 1), (\"Lemma('pick.v.01.pick')\", 1), (\"Lemma('blame.v.02.pick')\", 1), (\"Lemma('pick_up.v.01.pick_up')\", 1), (\"Lemma('pick.v.05.pick')\", 1), (\"Lemma('pick.v.02.pick')\", 1)])\n",
      "collecting tokens for  anniston\n",
      "indices:    {19793}\n",
      "dict_items([(\"Lemma('location.n.01.location')\", 1)])\n",
      "collecting tokens for  hardest\n",
      "indices:    {23872, 12617, 28528, 10608, 7701, 7702, 33431, 37117, 25052, 27741}\n",
      "dict_items([(\"Lemma('difficult.a.01.hard')\", 3), (\"Lemma('hard.a.02.hard')\", 1)])\n",
      "collecting tokens for  advanced\n",
      "indices:    {22656, 9351, 32137, 2068, 12948, 3864, 15513, 21913, 21914, 3866, 16408, 3870, 24736, 31777, 21284, 34085, 23844, 4649, 1588, 32182, 32310, 16057, 3903, 5824, 12491, 32122, 14673, 23510, 24934, 2280, 10097, 6386, 11509, 24949, 14842}\n",
      "dict_items([(\"Lemma('advanced.s.01.advanced')\", 5), (\"Lemma('advanced.s.06.advanced')\", 1), (\"Lemma('promote.v.01.advance')\", 1), (\"Lemma('advance.v.01.advance')\", 3), (\"Lemma('advanced.s.07.advanced')\", 1), (\"Lemma('progress.v.01.advance')\", 2), (\"Lemma('advanced.s.02.advanced')\", 2), (\"Lemma('gain.v.05.advance')\", 1), (\"Lemma('advanced.s.04.advanced')\", 1), (\"Lemma('advanced.s.03.advanced')\", 2), (\"Lemma('boost.v.04.advance')\", 2), (\"Lemma('advance.v.05.advance')\", 2), (\"Lemma('advance.v.02.advance')\", 3), (\"Lemma('advanced.s.05.advanced')\", 1)])\n",
      "collecting tokens for  iron\n",
      "indices:    {13096, 18202, 8226}\n",
      "dict_items([])\n",
      "collecting tokens for  barbed\n",
      "indices:    {5762, 5764, 33860, 5799, 27470, 33852, 26869, 18908}\n",
      "dict_items([])\n",
      "collecting tokens for  reducing\n",
      "indices:    {27136, 3393, 15396, 27967, 11592, 23849, 14794, 15950, 2835, 11542, 32150, 11546, 11291, 30172, 11741, 30175}\n",
      "dict_items([(\"Lemma('reduce.v.02.reduce')\", 1), (\"Lemma('reduce.v.01.reduce')\", 13), (\"Lemma('reduce.v.04.reduce')\", 1)])\n",
      "collecting tokens for  souls\n",
      "indices:    {7042, 27394, 9668, 13125, 13126, 13127, 9157, 26921, 13130, 13128, 27470, 6991, 28111, 13041, 1146, 28124, 27774, 36895}\n",
      "dict_items([(\"Lemma('soul.n.03.soul')\", 1), (\"Lemma('person.n.01.soul')\", 5), (\"Lemma('soul.n.01.soul')\", 5)])\n",
      "collecting tokens for  deviation\n",
      "indices:    {3906, 15655, 15656, 3914, 24525, 30543, 4240, 3861, 3352, 31963, 3869}\n",
      "dict_items([(\"Lemma('deviation.n.01.deviation')\", 2)])\n",
      "collecting tokens for  cleared\n",
      "indices:    {7045, 34066, 21279, 34080, 17322, 23339, 35120, 35122, 10677, 25789, 28736, 28739, 6474, 17613, 1237, 19163, 7776, 34535, 1908, 1915}\n",
      "dict_items([(\"Lemma('unclutter.v.01.clear')\", 6), (\"Lemma('clear.v.08.clear')\", 1), (\"Lemma('clear.v.07.clear')\", 1), (\"Lemma('clear.s.03.clear')\", 1), (\"Lemma('clear_up.v.04.clear')\", 2), (\"Lemma('authorize.v.01.clear')\", 1), (\"Lemma('clear.v.05.clear')\", 1), (\"Lemma('clear.v.02.clear')\", 2), (\"Lemma('clear.v.09.clear')\", 1)])\n",
      "collecting tokens for  yankees\n",
      "indices:    {22995}\n",
      "dict_items([])\n",
      "collecting tokens for  threat\n",
      "indices:    {21906, 20760, 11163, 15515, 14112, 25381, 2601, 24240, 24630, 32440, 24122, 14908, 21957, 22344, 3147, 30804, 36436, 16346, 22874, 32997, 15718, 13158, 15722, 30836, 18169}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('menace.n.01.threat')\", 10), (\"Lemma('threat.n.03.threat')\", 1)])\n",
      "collecting tokens for  explanation\n",
      "indices:    {10624, 24459, 20235, 9359, 26640, 22674, 28312, 2851, 14499, 22693, 1319, 14120, 25653, 16053, 7482, 14522, 1083, 16320, 16322, 33219, 33220, 16323, 33223, 15051, 16080, 16089, 33246, 2143, 13023, 16095, 16099, 17256, 3817, 13940, 12661}\n",
      "dict_items([(\"Lemma('explanation.n.01.explanation')\", 18), (\"Lemma('explanation.n.02.explanation')\", 6)])\n",
      "collecting tokens for  ourselves\n",
      "indices:    {32640, 1923, 27271, 28039, 27274, 3598, 22674, 23570, 13079, 27928, 15388, 14237, 12957, 14110, 27808, 15390, 2594, 32167, 26152, 27305, 25129, 19374, 1330, 27319, 1338, 1340, 15807, 15428, 14660, 1349, 27468, 32206, 24912, 14929, 31996, 26199, 1243, 13404, 1246, 25823, 5225, 4842, 30829, 25455, 14193, 32882, 26101, 31995, 26108}\n",
      "dict_items([])\n",
      "collecting tokens for  eichmann\n",
      "indices:    {12201}\n",
      "dict_items([(\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  explain\n",
      "indices:    {33218, 808, 16884, 36633, 32028, 33246}\n",
      "dict_items([(\"Lemma('explain.v.01.explain')\", 6)])\n",
      "collecting tokens for  magical\n",
      "indices:    {28166, 28104, 14634, 28107, 28108, 19598, 28142, 28113, 32116, 12219, 28124, 28125}\n",
      "dict_items([(\"Lemma('charming.s.02.magical')\", 2)])\n",
      "collecting tokens for  respond\n",
      "indices:    {26563, 25476, 1959, 9191, 27306, 13610, 13355, 16301, 32049, 20402, 13649, 30420, 14646, 13463, 4634, 12219}\n",
      "dict_items([(\"Lemma('answer.v.01.respond')\", 3), (\"Lemma('react.v.01.respond')\", 13)])\n",
      "collecting tokens for  appearing\n",
      "indices:    {2402, 24578, 25122, 10986, 1130, 26859, 1425, 16179, 14676, 1620, 3674, 93}\n",
      "dict_items([(\"Lemma('appear.v.03.appear')\", 1), (\"Lemma('appear.v.02.appear')\", 10), (\"Lemma('appear.v.05.appear')\", 1)])\n",
      "collecting tokens for  crept\n",
      "indices:    {8581, 9385, 10986, 16651, 17037, 36048, 8568, 31805}\n",
      "dict_items([(\"Lemma('crawl.v.01.creep')\", 6), (\"Lemma('creep.v.03.creep')\", 1), (\"Lemma('sneak.v.01.creep')\", 1)])\n",
      "collecting tokens for  neglected\n",
      "indices:    {36673, 19779, 15463, 14125, 25485, 27119, 6030, 26353, 6068, 32885, 27671, 32376, 4603}\n",
      "dict_items([(\"Lemma('neglect.v.01.neglect')\", 4), (\"Lemma('neglect.v.03.neglect')\", 1), (\"Lemma('neglect.v.04.neglect')\", 3), (\"Lemma('ignored.s.01.neglected')\", 1), (\"Lemma('neglected.s.02.neglected')\", 1), (\"Lemma('fail.v.01.neglect')\", 1)])\n",
      "collecting tokens for  pansies\n",
      "indices:    {1603, 1604, 1654}\n",
      "dict_items([(\"Lemma('pansy.n.01.pansy')\", 3)])\n",
      "collecting tokens for  irenaeus\n",
      "indices:    {1501}\n",
      "dict_items([(\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  identify\n",
      "indices:    {14464, 16289, 26691, 14980, 16643, 1449, 1260, 31863, 27700, 1462, 9687, 34008, 1374}\n",
      "dict_items([(\"Lemma('identify.v.03.identify')\", 4), (\"Lemma('identify.v.01.identify')\", 6), (\"Lemma('identify.v.06.identify')\", 1), (\"Lemma('name.v.02.identify')\", 1), (\"Lemma('identify.v.05.identify')\", 1)])\n",
      "collecting tokens for  300\n",
      "indices:    {23174, 12683, 26388, 3092, 23190, 3999, 27041, 2978, 12706, 2212, 30896, 18228, 12471, 20930, 22345, 11338, 12491, 12494, 22353, 12371, 21848, 14809, 20188, 5090, 29926, 12135, 14825, 4086, 21241}\n",
      "dict_items([])\n",
      "collecting tokens for  nursing\n",
      "indices:    {33290, 339, 17364, 32858, 20187}\n",
      "dict_items([(\"Lemma('nurse.v.01.nurse')\", 1)])\n",
      "collecting tokens for  keeps\n",
      "indices:    {992, 24960, 3619, 28963, 5382, 20616, 2698, 8909, 559, 1650, 16533, 1628, 20958, 1631}\n",
      "dict_items([(\"Lemma('prevent.v.02.keep')\", 1), (\"Lemma('continue.v.01.keep')\", 3), (\"Lemma('keep.v.01.keep')\", 4), (\"Lemma('keep_in.v.01.keep_in')\", 1), (\"Lemma('keep.v.03.keep')\", 2)])\n",
      "collecting tokens for  honey\n",
      "indices:    {3617, 7297, 13572, 3620, 19111, 5644, 26510, 697, 7294}\n",
      "dict_items([(\"Lemma('honey.s.01.honey')\", 2), (\"Lemma('beloved.n.01.honey')\", 3), (\"Lemma('honey.n.01.honey')\", 3)])\n",
      "collecting tokens for  intend\n",
      "indices:    {13283, 36867, 12164, 21448, 25512, 29422, 6195, 21429, 1276, 11455}\n",
      "dict_items([(\"Lemma('intend.v.01.intend')\", 7), (\"Lemma('intend.v.02.intend')\", 2), (\"Lemma('mean.v.01.intend')\", 1)])\n",
      "collecting tokens for  theaters\n",
      "indices:    {933, 934, 21447, 21448, 30096, 21460, 21461, 21462, 2047}\n",
      "dict_items([(\"Lemma('theater.n.01.theater')\", 3)])\n",
      "collecting tokens for  wear\n",
      "indices:    {26250, 22166, 31261, 36265, 16569, 22457, 22458, 31036, 29886, 27201, 16578, 23105, 9665, 9159, 24267, 26699, 19021, 20942, 9561, 17885, 1374, 13153, 19686, 34796, 25582}\n",
      "dict_items([(\"Lemma('wear.v.01.wear')\", 19), (\"Lemma('wear.v.02.wear')\", 2), (\"Lemma('wear.v.05.wear')\", 1), (\"Lemma('tire.v.02.wear_down')\", 1)])\n",
      "collecting tokens for  costumes\n",
      "indices:    {26465, 22402, 26567, 20905, 25674, 26765, 1104, 31858, 1106, 26290, 1171, 22166, 1179}\n",
      "dict_items([(\"Lemma('costume.n.01.costume')\", 4)])\n",
      "collecting tokens for  gown\n",
      "indices:    {36508, 8422, 21149, 6187, 9549, 7791, 21041, 7420, 26710, 7416, 21147, 20892, 21053, 21150}\n",
      "dict_items([(\"Lemma('gown.n.01.gown')\", 3)])\n",
      "collecting tokens for  recognizing\n",
      "indices:    {28611, 26198}\n",
      "dict_items([(\"Lemma('recognize.v.02.recognize')\", 1), (\"Lemma('accredit.v.01.recognize')\", 1)])\n",
      "collecting tokens for  locating\n",
      "indices:    {28761, 4931, 32458, 2733, 5426, 32883, 32377, 28826, 15163, 12797, 1755}\n",
      "dict_items([(\"Lemma('locate.v.01.locate')\", 6), (\"Lemma('situate.v.01.locate')\", 1), (\"Lemma('settle.v.04.locate')\", 1), (\"Lemma('locate.v.03.locate')\", 2)])\n",
      "collecting tokens for  protect\n",
      "indices:    {11649, 11920, 25618, 16403, 19, 14250, 11818, 11310, 12464, 32689, 15284, 25014, 29881, 29908, 5079, 10840, 11743, 1888, 31969, 25072, 30321, 22770, 1657, 6015}\n",
      "dict_items([(\"Lemma('protect.v.01.protect')\", 24)])\n",
      "collecting tokens for  regulations\n",
      "indices:    {9632, 32292, 12260, 14056, 32297, 32458, 29835, 25099, 14863, 33009, 2783, 33014, 14747, 32287}\n",
      "dict_items([(\"Lemma('rule.n.01.regulation')\", 1), (\"Lemma('regulation.n.01.regulation')\", 5)])\n",
      "collecting tokens for  shadow\n",
      "indices:    {26713}\n",
      "dict_items([])\n",
      "collecting tokens for  italian\n",
      "indices:    {27180}\n",
      "dict_items([])\n",
      "collecting tokens for  cocktail\n",
      "indices:    {22148, 20881, 30877, 26399, 33954, 20390, 27175, 27439, 14002, 14007, 14008, 29498, 14011, 22080, 33985, 27210, 21068, 14045, 36445, 36961, 20976}\n",
      "dict_items([(\"Lemma('cocktail_party.n.01.cocktail_party')\", 1)])\n",
      "collecting tokens for  adjustments\n",
      "indices:    {7553, 16452, 32613, 15044, 32583, 32616, 21610, 32587, 30794, 15473, 32594, 32625, 53, 16376, 30776, 9790}\n",
      "dict_items([(\"Lemma('adjustment.n.01.adjustment')\", 3), (\"Lemma('alteration.n.02.adjustment')\", 3), (\"Lemma('adjustment.n.03.adjustment')\", 1)])\n",
      "collecting tokens for  laboratory\n",
      "indices:    {14800, 21882, 34732, 3541}\n",
      "dict_items([(\"Lemma('lab.n.01.laboratory')\", 2)])\n",
      "collecting tokens for  ultrasonic\n",
      "indices:    {11393, 11411, 11412, 11349, 11414, 11384, 11388, 11390}\n",
      "dict_items([(\"Lemma('supersonic.s.02.ultrasonic')\", 8)])\n",
      "collecting tokens for  effected\n",
      "indices:    {28129, 9347, 9384, 11, 4624, 32822, 14870, 28090, 32702, 14623}\n",
      "dict_items([(\"Lemma('effect.v.01.effect')\", 7), (\"Lemma('effect.v.02.effect')\", 3)])\n",
      "collecting tokens for  earthy\n",
      "indices:    {26848, 26916, 32040, 12553, 37170, 11222, 14426, 10591}\n",
      "dict_items([(\"Lemma('earthy.s.02.earthy')\", 1), (\"Lemma('crude.s.02.earthy')\", 2), (\"Lemma('earthy.s.03.earthy')\", 1)])\n",
      "collecting tokens for  orderly\n",
      "indices:    {21441, 25601, 24197, 35294, 33383, 9800, 4585, 27145, 11, 17864, 19661, 35406, 35408, 86, 35415, 24894}\n",
      "dict_items([(\"Lemma('orderly.a.01.orderly')\", 4)])\n",
      "collecting tokens for  intervention\n",
      "indices:    {32896, 26209, 25058, 26211, 26212, 32900, 32903, 22635, 32877, 14990, 13074, 20274, 4754, 33237, 23257, 23963}\n",
      "dict_items([(\"Lemma('intervention.n.01.intervention')\", 3)])\n",
      "collecting tokens for  kennan\n",
      "indices:    {27814}\n",
      "dict_items([])\n",
      "collecting tokens for  excellent\n",
      "indices:    {25856, 22400, 22403, 26244, 13320, 15124, 1176, 21017, 26907, 1819, 29086, 32544, 22951, 28969, 1835, 8247, 13880, 1085, 26431, 29121, 22466, 30799, 27988, 30939, 25948, 32603, 30049, 8428, 3056, 11900, 638}\n",
      "dict_items([(\"Lemma('excellent.s.01.excellent')\", 12)])\n",
      "collecting tokens for  arranged\n",
      "indices:    {1035, 3602, 1046, 24870, 12071, 24871, 9386, 36651, 6061, 12986, 3775, 32447, 9800, 23881, 26202, 26336, 6119, 13671, 36968, 23151, 28538, 34687}\n",
      "dict_items([(\"Lemma('arrange.v.01.arrange')\", 6), (\"Lemma('arrange.v.02.arrange')\", 3), (\"Lemma('format.v.01.arrange')\", 2), (\"Lemma('stage.v.02.arrange')\", 1), (\"Lemma('arranged.a.01.arranged')\", 2), (\"Lemma('dress.v.16.arrange')\", 1)])\n",
      "collecting tokens for  anglican\n",
      "indices:    {1430}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('anglican.a.01.Anglican')\", 1)])\n",
      "collecting tokens for  michael\n",
      "indices:    {12660}\n",
      "dict_items([])\n",
      "collecting tokens for  swing\n",
      "indices:    {32065, 26403, 1094, 13586, 26614, 19806}\n",
      "dict_items([(\"Lemma('swing.v.09.swing')\", 1), (\"Lemma('swing.v.02.swing')\", 2), (\"Lemma('swing.v.07.swing')\", 1)])\n",
      "collecting tokens for  crisis\n",
      "indices:    {25604, 2309, 2694, 25607, 25608, 32904, 32908, 21394, 27155, 4755, 33173, 6038, 11034, 25627, 25628, 20765, 23582, 30751, 5282, 23587, 24111, 24112, 28338, 20149, 24632, 20153, 14908, 13506, 24133, 24648, 2640, 32849, 24145, 31699, 32853, 24664, 24665, 32219, 27485, 12382, 32875, 30061, 25588, 25590, 27768, 25594}\n",
      "dict_items([(\"Lemma('crisis.n.01.crisis')\", 5), (\"Lemma('crisis.n.02.crisis')\", 5)])\n",
      "collecting tokens for  slid\n",
      "indices:    {10593, 8929, 34019, 21444, 21442, 34020, 33993, 34185, 11179, 34607, 36048, 34032, 12373, 33718, 35806, 10712, 19801, 17886}\n",
      "dict_items([(\"Lemma('skid.v.04.slide')\", 11), (\"Lemma('slither.v.01.slide')\", 5), (\"Lemma('slide.v.03.slide')\", 2)])\n",
      "collecting tokens for  diseases\n",
      "indices:    {32706, 3402, 2228, 33046, 32696, 27195}\n",
      "dict_items([(\"Lemma('disease.n.01.disease')\", 2)])\n",
      "collecting tokens for  waste\n",
      "indices:    {30980, 35595, 36114, 11795, 32156, 30117, 8486, 2728, 11823, 19511, 35775, 29759, 31427, 15441, 24916, 2265, 19294, 871, 13565}\n",
      "dict_items([(\"Lemma('waste.v.02.waste')\", 2), (\"Lemma('waste.n.02.waste')\", 4), (\"Lemma('thriftlessness.n.01.waste')\", 1), (\"Lemma('waste.v.01.waste')\", 4), (\"Lemma('waste.n.01.waste')\", 1)])\n",
      "collecting tokens for  fraud\n",
      "indices:    {22792, 17322, 17324, 17326, 20848, 2260, 17398}\n",
      "dict_items([(\"Lemma('fraud.n.01.fraud')\", 4)])\n",
      "collecting tokens for  messages\n",
      "indices:    {12578, 31299, 31109, 13992, 2377, 31085, 7953, 27186, 24724, 5141, 31352, 31354, 31355, 14012}\n",
      "dict_items([(\"Lemma('message.n.02.message')\", 4), (\"Lemma('message.n.01.message')\", 2)])\n",
      "collecting tokens for  dice\n",
      "indices:    {4952, 31570, 4439}\n",
      "dict_items([(\"Lemma('die.n.01.dice')\", 2)])\n",
      "collecting tokens for  tossed\n",
      "indices:    {18439, 34184, 11016, 17162, 17168, 9246, 13601, 4392, 19885, 4403, 4404, 4405, 72, 7887, 4441, 35421, 19806, 5095, 18154, 34156, 34039, 18936, 25593, 23802, 20095}\n",
      "dict_items([(\"Lemma('chuck.v.01.toss')\", 4), (\"Lemma('flip.v.06.toss')\", 9), (\"Lemma('flip.v.01.toss')\", 6), (\"Lemma('discard.v.01.toss')\", 1), (\"Lemma('toss.v.06.toss')\", 1), (\"Lemma('discard.v.01.toss_away')\", 2)])\n",
      "collecting tokens for  toss\n",
      "indices:    {4425, 31945}\n",
      "dict_items([(\"Lemma('flip.v.01.toss')\", 2)])\n",
      "collecting tokens for  declaring\n",
      "indices:    {32643, 31973, 21895, 5101, 25395, 24824, 5370, 7711}\n",
      "dict_items([(\"Lemma('declare.v.03.declare')\", 2), (\"Lemma('announce.v.02.declare')\", 2), (\"Lemma('declare.v.04.declare')\", 1), (\"Lemma('declare.v.01.declare')\", 1)])\n",
      "collecting tokens for  commander\n",
      "indices:    {30306, 12834, 21413, 36486, 26023, 26024, 31337, 12492, 17646, 12911, 17619, 12756, 31315, 21564, 26045}\n",
      "dict_items([(\"Lemma('commanding_officer.n.01.commander')\", 3), (\"Lemma('commander.n.02.commander')\", 2)])\n",
      "collecting tokens for  involve\n",
      "indices:    {26118, 8472, 8345, 4889, 31903, 31904, 31148, 20784, 32181, 13242, 30011, 28860, 32571, 15684, 20687, 26197, 26219, 30835, 22647, 4223}\n",
      "dict_items([(\"Lemma('involve.v.01.involve')\", 11), (\"Lemma('involve.v.02.involve')\", 3), (\"Lemma('imply.v.05.involve')\", 4), (\"Lemma('necessitate.v.01.involve')\", 2)])\n",
      "collecting tokens for  quarter\n",
      "indices:    {27521, 17192, 28171, 24685, 9390, 29018, 33522, 21875, 21877, 29275, 11291}\n",
      "dict_items([(\"Lemma('one-fourth.n.01.quarter')\", 2), (\"Lemma('quarter-century.n.01.quarter-century')\", 1)])\n",
      "collecting tokens for  vitally\n",
      "indices:    {26759, 4743, 4682, 32140, 27533, 26223, 14707, 1845, 23579}\n",
      "dict_items([(\"Lemma('vitally.r.01.vitally')\", 4)])\n",
      "collecting tokens for  e\n",
      "indices:    {17228, 15077}\n",
      "dict_items([])\n",
      "collecting tokens for  remaining\n",
      "indices:    {22533, 23951, 2322, 32542, 15011, 6824, 14895, 14400, 29504, 30659, 14020, 18120, 3144, 4561, 36306, 35799, 2519, 7773, 12516, 32612, 23784, 36201, 30316, 13549, 12399, 2801, 2804, 14966, 31999}\n",
      "dict_items([(\"Lemma('stay.v.01.remain')\", 5), (\"Lemma('leftover.s.01.remaining')\", 3), (\"Lemma('remain.v.03.remain')\", 2), (\"Lemma('persist.v.03.remain')\", 1), (\"Lemma('stay.v.04.remain')\", 3)])\n",
      "collecting tokens for  intermediate\n",
      "indices:    {4160, 1985, 32932, 3877, 32934, 15527, 28602, 32957, 4126, 15519}\n",
      "dict_items([(\"Lemma('intermediate.a.01.intermediate')\", 6)])\n",
      "collecting tokens for  rhythms\n",
      "indices:    {14565, 26629, 26405, 32073, 7277, 31891, 1718, 1976}\n",
      "dict_items([(\"Lemma('rhythm.n.01.rhythm')\", 2), (\"Lemma('cycle.n.01.rhythm')\", 1), (\"Lemma('rhythm.n.02.rhythm')\", 1)])\n",
      "collecting tokens for  livestock\n",
      "indices:    {12161, 12163, 12071, 12072, 12074, 12493, 12084, 12117, 28634, 29981, 21502}\n",
      "dict_items([(\"Lemma('livestock.n.01.livestock')\", 8)])\n",
      "collecting tokens for  superintendent\n",
      "indices:    {12473, 20823}\n",
      "dict_items([(\"Lemma('overseer.n.01.superintendent')\", 1)])\n",
      "collecting tokens for  jenkins\n",
      "indices:    {21180}\n",
      "dict_items([])\n",
      "collecting tokens for  maintained\n",
      "indices:    {3855, 16407, 32025, 6939, 4132, 6949, 11559, 5415, 11561, 3122, 32057, 32955, 3136, 34753, 30402, 31171, 4036, 3780, 14913, 11471, 4048, 14935, 3551, 31970, 32996, 3556, 23656, 12520, 2415, 3824, 12667, 1789}\n",
      "dict_items([(\"Lemma('conserve.v.02.maintain')\", 8), (\"Lemma('keep.v.01.maintain')\", 15), (\"Lemma('assert.v.01.maintain')\", 5), (\"Lemma('sustain.v.04.maintain')\", 3), (\"Lemma('kept_up.s.01.maintained')\", 1)])\n",
      "collecting tokens for  praise\n",
      "indices:    {1, 8450, 23656, 26505, 26743, 24018, 629, 25111, 32218, 29211, 11198, 27359}\n",
      "dict_items([(\"Lemma('praise.n.01.praise')\", 4), (\"Lemma('praise.v.01.praise')\", 2)])\n",
      "collecting tokens for  outcome\n",
      "indices:    {34444, 2586, 12957, 27805, 4395, 20270, 20399, 9393, 4401, 33219, 16198, 27342, 28239, 4438, 24796, 32877, 4467, 24952, 32890}\n",
      "dict_items([(\"Lemma('result.n.03.outcome')\", 7), (\"Lemma('consequence.n.01.outcome')\", 1)])\n",
      "collecting tokens for  virgin\n",
      "indices:    {1458, 15022}\n",
      "dict_items([(\"Lemma('virgin.s.01.virgin')\", 1)])\n",
      "collecting tokens for  saviour\n",
      "indices:    {27343}\n",
      "dict_items([])\n",
      "collecting tokens for  slashed\n",
      "indices:    {35360, 10532, 6213, 19269, 459, 6317, 34096, 34098, 23451, 19295}\n",
      "dict_items([(\"Lemma('slash.v.01.slash')\", 3), (\"Lemma('slashed.s.02.slashed')\", 1), (\"Lemma('flog.v.01.slash')\", 2), (\"Lemma('slashed.s.01.slashed')\", 1), (\"Lemma('slash.v.04.slash')\", 1), (\"Lemma('slash.v.03.slash')\", 2)])\n",
      "collecting tokens for  canvas\n",
      "indices:    {7136, 11906, 34692, 24805, 31912, 25704, 11914, 30571, 19166, 28658, 26775, 5364, 23540, 11094, 19295, 5368, 8670, 11231}\n",
      "dict_items([(\"Lemma('canvas.n.01.canvas')\", 7), (\"Lemma('canvas.n.02.canvas')\", 1), (\"Lemma('canvas_tent.n.01.canvas')\", 1)])\n",
      "collecting tokens for  glass\n",
      "indices:    {11016, 33928, 18956, 16524, 8724, 18849, 27175, 10538, 17579, 29870, 29373, 11455, 14531, 3143, 18887, 17100, 33613, 5461, 2268, 18786, 11109, 30188, 20986}\n",
      "dict_items([(\"Lemma('glass.n.01.glass')\", 9), (\"Lemma('glass.n.03.glass')\", 2), (\"Lemma('glass.n.02.glass')\", 2), (\"Lemma('field_glass.n.01.glass')\", 1)])\n",
      "collecting tokens for  correspondence\n",
      "indices:    {15872, 11456, 12545, 37090, 12579, 12300, 815, 32816, 24720, 31762, 32467, 32815, 32790, 14454, 12826, 26780, 22527}\n",
      "dict_items([(\"Lemma('correspondence.n.01.correspondence')\", 5), (\"Lemma('agreement.n.02.correspondence')\", 2)])\n",
      "collecting tokens for  settlement\n",
      "indices:    {19211, 31762, 14870, 29339, 30, 14884, 14889, 12459, 12460, 12466, 12469, 12474, 22599, 12498, 12501, 25178, 12515, 12525, 22896}\n",
      "dict_items([(\"Lemma('settlement.n.05.settlement')\", 1), (\"Lemma('colonization.n.01.settlement')\", 2), (\"Lemma('colony.n.01.settlement')\", 7), (\"Lemma('settlement.n.03.settlement')\", 2), (\"Lemma('village.n.01.settlement')\", 1)])\n",
      "collecting tokens for  twenty-five\n",
      "indices:    {34240, 17409, 20100, 17866, 26475, 25358, 5136, 12368, 31126, 17370}\n",
      "dict_items([(\"Lemma('twenty-five.s.01.twenty-five')\", 5)])\n",
      "collecting tokens for  predicted\n",
      "indices:    {21920, 23457, 15682, 21890, 5476, 33189, 15690, 32877, 33198, 816, 2802, 13683, 21239, 34424, 22201, 12444, 15711}\n",
      "dict_items([(\"Lemma('bode.v.01.predict')\", 1), (\"Lemma('predict.v.01.predict')\", 14)])\n",
      "collecting tokens for  interaction\n",
      "indices:    {16096, 15712, 15682, 15714, 32996, 3045, 1032, 4712, 3056, 32978, 32980, 15701, 3192, 2556, 15679}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('interaction.n.01.interaction')\", 12)])\n",
      "collecting tokens for  extend\n",
      "indices:    {23009, 1591, 27885, 23700, 22807, 13212, 33117, 14943}\n",
      "dict_items([(\"Lemma('extend.v.04.extend')\", 1), (\"Lemma('cover.v.03.extend')\", 2), (\"Lemma('run.v.03.extend')\", 2), (\"Lemma('offer.v.05.extend')\", 1), (\"Lemma('stretch.v.02.extend')\", 1), (\"Lemma('widen.v.04.extend')\", 1)])\n",
      "collecting tokens for  trusted\n",
      "indices:    {23299, 31684, 8009, 23146, 9522, 26549, 7799, 36152, 35930}\n",
      "dict_items([(\"Lemma('trust.v.02.trust')\", 3), (\"Lemma('believe.v.03.trust')\", 1), (\"Lemma('trust.v.01.trust')\", 3), (\"Lemma('sure.s.06.trusted')\", 1)])\n",
      "collecting tokens for  entertainment\n",
      "indices:    {21562, 10981, 27433, 8398, 27439, 22418, 26227, 2452, 2389, 20979, 21557, 2456, 30009, 20883, 29267, 22172, 23100}\n",
      "dict_items([(\"Lemma('entertainment.n.01.entertainment')\", 5)])\n",
      "collecting tokens for  emerging\n",
      "indices:    {27731, 31790}\n",
      "dict_items([(\"Lemma('issue.v.04.emerge')\", 1), (\"Lemma('emerge.v.01.emerge')\", 1)])\n",
      "collecting tokens for  glanced\n",
      "indices:    {34307, 23305, 30345, 34060, 30348, 33570, 7459, 36776, 7977, 8494, 19504, 17714, 17590, 33740, 8524, 10317, 18521, 5721, 18533, 23153}\n",
      "dict_items([(\"Lemma('glance.v.01.glance')\", 19), (\"Lemma('glance.v.02.glance')\", 1)])\n",
      "collecting tokens for  lean\n",
      "indices:    {11079, 8936, 12585, 31371, 22925, 35950, 7373, 19504, 24127, 24333, 7604, 9311, 25983}\n",
      "dict_items([(\"Lemma('thin.a.02.lean')\", 4), (\"Lemma('lean.v.04.lean')\", 1), (\"Lemma('lean.v.01.lean')\", 1), (\"Lemma('tend.v.01.lean')\", 1)])\n",
      "collecting tokens for  gratt\n",
      "indices:    {19461}\n",
      "dict_items([])\n",
      "collecting tokens for  k.\n",
      "indices:    {24677}\n",
      "dict_items([])\n",
      "collecting tokens for  shortly\n",
      "indices:    {5585, 21657, 52, 18868}\n",
      "dict_items([(\"Lemma('shortly.r.01.shortly')\", 2), (\"Lemma('soon.r.01.shortly')\", 1)])\n",
      "collecting tokens for  orthodontic\n",
      "indices:    {30979, 31015, 31017, 31053, 31069}\n",
      "dict_items([])\n",
      "collecting tokens for  decay\n",
      "indices:    {27649, 31010, 13379, 31076, 31077, 13574, 31078, 13618, 31028, 13620, 3129, 25758}\n",
      "dict_items([(\"Lemma('decay.v.02.decay')\", 2), (\"Lemma('decay.n.03.decay')\", 1), (\"Lemma('decay.n.02.decay')\", 2), (\"Lemma('decay.n.01.decay')\", 2)])\n",
      "collecting tokens for  token\n",
      "indices:    {36226, 23592, 20649, 24206, 27796, 24212, 11446, 20668}\n",
      "dict_items([(\"Lemma('token.n.01.token')\", 1)])\n",
      "collecting tokens for  fee\n",
      "indices:    {2272, 22337, 20706, 130, 21765, 20710, 23591, 11783, 20709, 13898, 14856, 31052, 20721}\n",
      "dict_items([(\"Lemma('fee.n.01.fee')\", 4)])\n",
      "collecting tokens for  enjoys\n",
      "indices:    {2345, 13898, 23021, 25839, 1424, 1201, 13234, 27769}\n",
      "dict_items([(\"Lemma('enjoy.v.01.enjoy')\", 3), (\"Lemma('enjoy.v.02.enjoy')\", 1), (\"Lemma('enjoy.v.04.enjoy')\", 2), (\"Lemma('love.v.02.enjoy')\", 2)])\n",
      "collecting tokens for  firmly\n",
      "indices:    {23296, 4993, 5253, 14214, 4752, 20241, 30484, 36251, 2592, 22947, 29606, 31785, 31017, 27178, 29996, 17966, 23087, 1331, 951, 13898, 35530, 25802, 25167, 29648, 31186, 31828, 20822, 25443, 31717, 4584, 16746, 10347, 16618, 29552, 4721, 29555, 30069}\n",
      "dict_items([(\"Lemma('firm.r.01.firmly')\", 9), (\"Lemma('securely.r.01.firmly')\", 4), (\"Lemma('hard.r.02.firmly')\", 1)])\n",
      "collecting tokens for  pianist\n",
      "indices:    {1761, 31618, 31619, 26340, 25988, 26279, 22311, 26281, 26346, 1740, 22320, 11185, 1746, 26482, 26001, 26907, 26012, 22334}\n",
      "dict_items([(\"Lemma('pianist.n.01.pianist')\", 4)])\n",
      "collecting tokens for  fifth\n",
      "indices:    {19793, 21196}\n",
      "dict_items([(\"Lemma('fifth.s.01.fifth')\", 1)])\n",
      "collecting tokens for  marvelous\n",
      "indices:    {11075, 27336, 5003, 14551, 921, 28124}\n",
      "dict_items([(\"Lemma('fantastic.s.02.marvelous')\", 2), (\"Lemma('improbable.s.03.marvelous')\", 1)])\n",
      "collecting tokens for  blessed\n",
      "indices:    {36480, 24761, 26379}\n",
      "dict_items([])\n",
      "collecting tokens for  departing\n",
      "indices:    {35396, 30343, 30888, 25202, 9654, 29175, 7263, 26399}\n",
      "dict_items([(\"Lemma('go.v.03.depart')\", 3), (\"Lemma('depart.v.03.depart')\", 2)])\n",
      "collecting tokens for  amy\n",
      "indices:    {1174}\n",
      "dict_items([(\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  destiny\n",
      "indices:    {14080, 14119, 25192, 13486, 25199, 11216, 33137, 8720, 25198, 24918, 31706, 16447}\n",
      "dict_items([(\"Lemma('destiny.n.01.destiny')\", 5), (\"Lemma('destiny.n.02.destiny')\", 1)])\n",
      "collecting tokens for  masses\n",
      "indices:    {27297, 418, 21026, 11267, 3367, 3369, 31882, 26667, 11212, 3341, 25330, 21076, 11093, 2329, 12410}\n",
      "dict_items([(\"Lemma('mass.n.01.mass')\", 3), (\"Lemma('multitude.n.03.masses')\", 3), (\"Lemma('batch.n.02.mass')\", 1), (\"Lemma('mass.n.03.mass')\", 1), (\"Lemma('mass.n.05.mass')\", 1)])\n",
      "collecting tokens for  authentic\n",
      "indices:    {19522, 19523, 19524, 17704, 31722, 26349, 36654, 1103, 11248, 27024, 1101, 11093, 7573, 14423, 9144, 1110}\n",
      "dict_items([(\"Lemma('authentic.s.02.authentic')\", 6), (\"Lemma('authentic.s.01.authentic')\", 6)])\n",
      "collecting tokens for  britain\n",
      "indices:    {12463}\n",
      "dict_items([])\n",
      "collecting tokens for  involving\n",
      "indices:    {15491, 33027, 20752, 27027, 25503, 10669, 10799, 20144, 21680, 4033, 14915, 20166, 24143, 14803, 12256, 23650, 32880, 32888, 16253, 37119}\n",
      "dict_items([(\"Lemma('involve.v.01.involve')\", 12), (\"Lemma('involve.v.02.involve')\", 2), (\"Lemma('imply.v.05.involve')\", 2), (\"Lemma('necessitate.v.01.involve')\", 3), (\"Lemma('involve.v.05.involve')\", 1)])\n",
      "collecting tokens for  stature\n",
      "indices:    {20417, 25638, 11240, 875, 11216, 1425, 27573, 22935, 10744, 10745, 14367}\n",
      "dict_items([(\"Lemma('stature.n.01.stature')\", 7)])\n",
      "collecting tokens for  killed\n",
      "indices:    {34563, 18189, 6159, 12817, 25105, 11030, 24993, 18471, 23338, 35243, 12716, 35629, 35118, 13871, 16943, 5937, 5936, 35896, 17594, 25277, 21442, 26051, 24780, 12625, 27474, 25171, 27091, 5075, 30551, 21337, 34780, 12775, 17260, 30957, 21359, 20722, 34546, 10228, 26228, 26226, 18301, 18302}\n",
      "dict_items([(\"Lemma('kill.v.01.kill')\", 26)])\n",
      "collecting tokens for  indifference\n",
      "indices:    {5600, 1321, 33294, 7896, 36240, 37137, 13615, 21459, 12632, 27321, 17917}\n",
      "dict_items([(\"Lemma('indifference.n.01.indifference')\", 4), (\"Lemma('apathy.n.02.indifference')\", 1), (\"Lemma('emotionlessness.n.01.indifference')\", 1)])\n",
      "collecting tokens for  lack\n",
      "indices:    {1924, 5510, 3087, 19602, 27156, 1812, 28694, 20247, 3480, 25128, 25129, 17198, 30255, 32433, 25400, 28117, 15704, 21210, 32861, 32352, 25446, 30826, 3692, 26094, 4463, 24560, 28529, 13301, 1913, 3706, 25212}\n",
      "dict_items([(\"Lemma('lack.n.01.lack')\", 12), (\"Lemma('miss.v.06.lack')\", 2)])\n",
      "collecting tokens for  fences\n",
      "indices:    {13537, 13603, 13539, 13540, 33861, 35207, 13543, 29223, 30181, 33860, 13581, 10543, 7828, 13559}\n",
      "dict_items([(\"Lemma('fence.n.01.fence')\", 8)])\n",
      "collecting tokens for  cement\n",
      "indices:    {13096, 15094}\n",
      "dict_items([(\"Lemma('cement.n.02.cement')\", 1)])\n",
      "collecting tokens for  rows\n",
      "indices:    {5762, 13603, 31334, 5031, 5032, 15083, 29390, 29679, 10478, 27536, 23989, 31260}\n",
      "dict_items([(\"Lemma('row.n.01.row')\", 4), (\"Lemma('course.n.08.row')\", 1), (\"Lemma('row.n.03.row')\", 1)])\n",
      "collecting tokens for  stones\n",
      "indices:    {13824, 13603, 13571, 13606, 36392, 13577, 30377, 1881, 31482}\n",
      "dict_items([(\"Lemma('rock.n.01.stone')\", 4)])\n",
      "collecting tokens for  pauling\n",
      "indices:    {17329}\n",
      "dict_items([(\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  crowds\n",
      "indices:    {225, 9229, 31565, 21495}\n",
      "dict_items([(\"Lemma('crowd.n.01.crowd')\", 2)])\n",
      "collecting tokens for  lined\n",
      "indices:    {5440, 35267, 10531, 1093, 35591, 28394, 18255, 13106, 31859, 33779, 19122, 29334, 5752, 859, 23964, 3709}\n",
      "dict_items([(\"Lemma('line.v.02.line')\", 2), (\"Lemma('line.v.01.line')\", 6), (\"Lemma('lined.s.01.lined')\", 3), (\"Lemma('lined.s.02.lined')\", 1)])\n",
      "collecting tokens for  throwing\n",
      "indices:    {24514, 5058, 14950, 27018, 27083, 29101, 24784, 23091, 342, 5113, 18906, 37115}\n",
      "dict_items([(\"Lemma('throw.v.01.throw')\", 6), (\"Lemma('shed.v.01.throw')\", 1), (\"Lemma('throw.v.04.throw')\", 1), (\"Lemma('throw.v.02.throw')\", 2), (\"Lemma('give.v.07.throw')\", 1)])\n",
      "collecting tokens for  withdraw\n",
      "indices:    {23264, 27137, 32898, 32043, 5070, 18099, 4052, 18069}\n",
      "dict_items([(\"Lemma('swallow.v.05.withdraw')\", 1), (\"Lemma('withdraw.v.01.withdraw')\", 4), (\"Lemma('retire.v.02.withdraw')\", 1), (\"Lemma('disengage.v.01.withdraw')\", 1), (\"Lemma('recall.v.07.withdraw')\", 1)])\n",
      "collecting tokens for  determining\n",
      "indices:    {25090, 15621, 15623, 4743, 15625, 4241, 3992, 20643, 15525, 32934, 28851, 2615, 3385, 4925, 32325, 13388, 15054, 27858, 1886, 15599, 12272, 12282, 11389}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('determine.v.01.determine')\", 13), (\"Lemma('determine.v.03.determine')\", 2), (\"Lemma('deciding.s.01.determining')\", 1), (\"Lemma('decide.v.01.determine')\", 2), (\"Lemma('determine.v.06.determine')\", 1), (\"Lemma('specify.v.02.determine')\", 1), (\"Lemma('determine.v.02.determine')\", 2)])\n",
      "collecting tokens for  ethical\n",
      "indices:    {25444, 25445, 4710, 25446, 25064, 28009, 16458, 27848, 25453, 4665, 20509, 2228, 25497, 12282, 27837, 12318, 28093}\n",
      "dict_items([(\"Lemma('ethical.a.02.ethical')\", 2), (\"Lemma('ethical.a.01.ethical')\", 3), (\"Lemma('ethical.s.03.ethical')\", 1)])\n",
      "collecting tokens for  exclaimed\n",
      "indices:    {28163, 5870, 24689, 18577, 9298, 337, 36533, 18844, 31935}\n",
      "dict_items([(\"Lemma('proclaim.v.02.exclaim')\", 5), (\"Lemma('exclaim.v.01.exclaim')\", 4)])\n",
      "collecting tokens for  glasses\n",
      "indices:    {30052, 36613, 18309, 27976, 7370, 37067, 36685, 17646, 8398, 24689, 19537, 9244, 36573}\n",
      "dict_items([(\"Lemma('spectacles.n.01.glasses')\", 3), (\"Lemma('glass.n.02.glass')\", 2)])\n",
      "collecting tokens for  commented\n",
      "indices:    {25344, 7554, 21700, 6, 22696, 21182, 32398, 17, 5139, 31702, 22518, 33245, 20823}\n",
      "dict_items([(\"Lemma('comment.v.01.comment')\", 13)])\n",
      "collecting tokens for  fulton\n",
      "indices:    {13}\n",
      "dict_items([])\n",
      "collecting tokens for  fees\n",
      "indices:    {20708, 14854, 14855, 31048, 20712, 20714, 20715, 20719, 24144, 6002, 21753}\n",
      "dict_items([(\"Lemma('fee.n.01.fee')\", 3)])\n",
      "collecting tokens for  quack\n",
      "indices:    {2246, 2249, 2254, 2223, 2260, 2229, 2264, 2266, 2239}\n",
      "dict_items([(\"Lemma('quack.n.01.quack')\", 5), (\"Lemma('quack.s.01.quack')\", 4)])\n",
      "collecting tokens for  accelerated\n",
      "indices:    {12035, 227, 4997, 24421, 26668, 32511, 5491, 13373, 31231}\n",
      "dict_items([(\"Lemma('accelerate.v.01.accelerate')\", 4), (\"Lemma('accelerated.s.01.accelerated')\", 1), (\"Lemma('accelerate.v.02.accelerate')\", 1)])\n",
      "collecting tokens for  vernon\n",
      "indices:    {29172}\n",
      "dict_items([])\n",
      "collecting tokens for  suburbs\n",
      "indices:    {17122, 11651, 13379, 24203, 26475, 10667, 31854, 26478, 5426, 26259, 21079, 5465}\n",
      "dict_items([(\"Lemma('suburb.n.01.suburb')\", 6)])\n",
      "collecting tokens for  parking\n",
      "indices:    {35970, 33423, 9849, 33428, 33429, 33942, 9881, 33439, 33443, 33444, 21547, 5421, 5424, 33460, 5437, 33475, 17736, 33483, 21204, 30042, 5470, 5471, 5474, 1899, 11766, 11767, 23673}\n",
      "dict_items([(\"Lemma('parking.n.02.parking')\", 2), (\"Lemma('parking.n.01.parking')\", 1)])\n",
      "collecting tokens for  branches\n",
      "indices:    {1664, 22412, 22799, 1680, 25231, 5670, 3771, 36038, 3785, 3787, 3788, 18254, 5462, 5463, 5464, 5465, 5470, 36064, 5477, 5478, 29289, 31983, 36343, 20607}\n",
      "dict_items([(\"Lemma('branch.n.03.branch')\", 4), (\"Lemma('branch.n.02.branch')\", 4), (\"Lemma('branch.n.01.branch')\", 7)])\n",
      "collecting tokens for  diplomacy\n",
      "indices:    {32161, 29987, 22595, 23621, 12648, 26219, 26189, 26222, 26201, 23284, 15445, 22649}\n",
      "dict_items([(\"Lemma('delicacy.n.06.diplomacy')\", 1), (\"Lemma('diplomacy.n.01.diplomacy')\", 1)])\n",
      "collecting tokens for  appointed\n",
      "indices:    {25091, 31109, 20873, 26384, 19, 24725, 1432, 20766, 14879, 7072, 14880, 19363, 15785, 4798, 5950, 11472, 17365, 5334, 14936, 20442, 21219, 22503, 1515, 26222, 1008}\n",
      "dict_items([(\"Lemma('appoint.v.02.appoint')\", 6), (\"Lemma('appoint.v.01.appoint')\", 10), (\"Lemma('appointed.s.03.appointed')\", 1), (\"Lemma('appointed.s.04.appointed')\", 1), (\"Lemma('appointed.s.02.appointed')\", 2), (\"Lemma('appointive.a.02.appointed')\", 2)])\n",
      "collecting tokens for  congolese\n",
      "indices:    {23212}\n",
      "dict_items([])\n",
      "collecting tokens for  sang\n",
      "indices:    {26370, 26379, 26508, 26894, 26267, 26917, 14504, 8362, 12843, 1070, 26417, 1073, 26294, 14140, 23230, 26055, 9933, 26066, 26713, 12641, 36326, 1768, 14446, 2679}\n",
      "dict_items([(\"Lemma('sing.v.01.sing')\", 12), (\"Lemma('sing.v.02.sing')\", 10), (\"Lemma('spill_the_beans.v.01.sing')\", 1)])\n",
      "collecting tokens for  cannery\n",
      "indices:    {24224, 24234, 24235, 24240, 24241, 24242, 24243, 24244, 24248, 24250, 24254, 24255}\n",
      "dict_items([])\n",
      "collecting tokens for  helps\n",
      "indices:    {11597, 30484, 23609, 24250, 24255}\n",
      "dict_items([(\"Lemma('help.v.01.help')\", 3), (\"Lemma('help.v.02.help')\", 1)])\n",
      "collecting tokens for  unto\n",
      "indices:    {832, 27362, 11140, 17991, 24747, 24749, 24751, 27354, 24284, 28189}\n",
      "dict_items([])\n",
      "collecting tokens for  suffer\n",
      "indices:    {17984, 15678, 18946, 4834, 25890, 5349, 5291, 25452, 24749, 15725, 32081, 4852, 3637, 11294, 24440, 27837, 8382, 23711}\n",
      "dict_items([(\"Lemma('suffer.v.01.suffer')\", 4), (\"Lemma('suffer.v.05.suffer')\", 4), (\"Lemma('suffer.v.03.suffer')\", 4), (\"Lemma('digest.v.03.suffer')\", 2), (\"Lemma('suffer.v.02.suffer')\", 1), (\"Lemma('suffer.v.06.suffer')\", 3)])\n",
      "collecting tokens for  staged\n",
      "indices:    {26761}\n",
      "dict_items([(\"Lemma('stage.v.01.stage')\", 1)])\n",
      "collecting tokens for  resonance\n",
      "indices:    {34208, 3137, 3138, 3042, 1794, 3045, 3046, 3052, 3053, 14798, 14796, 3119, 3131}\n",
      "dict_items([(\"Lemma('resonance.n.01.resonance')\", 5), (\"Lemma('resonance.n.02.resonance')\", 3)])\n",
      "collecting tokens for  shifts\n",
      "indices:    {12448, 25666, 11651, 11652, 11653, 3046, 32873, 3131, 30221, 14797, 12784, 1397, 26587}\n",
      "dict_items([(\"Lemma('shift.n.05.shift')\", 1), (\"Lemma('switch.n.07.shift')\", 1), (\"Lemma('population_shift.n.01.population_shift')\", 2), (\"Lemma('shift.v.02.shift')\", 1), (\"Lemma('transformation.n.01.shift')\", 2)])\n",
      "collecting tokens for  derive\n",
      "indices:    {5249, 3046, 22727, 32070, 13705, 4585, 14602, 26258}\n",
      "dict_items([(\"Lemma('derive.v.02.derive')\", 5), (\"Lemma('deduce.v.01.derive')\", 3)])\n",
      "collecting tokens for  specialized\n",
      "indices:    {5220, 3046, 16264, 16316, 23532, 22701, 12140, 13906, 15001, 16315, 12092}\n",
      "dict_items([(\"Lemma('specialized.a.01.specialized')\", 6), (\"Lemma('specify.v.04.specialize')\", 1)])\n",
      "collecting tokens for  adjustment\n",
      "indices:    {25638, 24845, 31027, 32598, 27227}\n",
      "dict_items([])\n",
      "collecting tokens for  accomplished\n",
      "indices:    {36992, 27524, 1671, 23687, 23688, 22673, 4374, 21535, 3489, 2083, 21157, 17192, 4529, 15794, 23609, 26299, 26060, 461, 3406, 30417, 28881, 25300, 11094, 2134, 25305, 5083, 3932, 32605, 3826}\n",
      "dict_items([(\"Lemma('carry_through.v.01.accomplish')\", 17), (\"Lemma('achieve.v.01.accomplish')\", 7), (\"Lemma('accomplished.s.02.accomplished')\", 1), (\"Lemma('accomplished.s.01.accomplished')\", 1)])\n",
      "collecting tokens for  formation\n",
      "indices:    {9345, 3970, 4747, 3212, 2445, 10895, 18714, 18720, 18726, 16048, 31923, 14773, 14774, 1466, 31056, 1880, 3932, 27231, 27240, 3945, 498, 3955, 22779, 32509}\n",
      "dict_items([(\"Lemma('formation.n.05.formation')\", 3), (\"Lemma('formation.n.01.formation')\", 4), (\"Lemma('formation.n.02.formation')\", 4), (\"Lemma('constitution.n.02.formation')\", 4), (\"Lemma('geological_formation.n.01.formation')\", 1)])\n",
      "collecting tokens for  borrowing\n",
      "indices:    {31750, 21967, 32623, 32559, 32561, 32563, 10813}\n",
      "dict_items([(\"Lemma('borrow.v.01.borrow')\", 2), (\"Lemma('adopt.v.02.borrow')\", 1)])\n",
      "collecting tokens for  guerrilla\n",
      "indices:    {23745, 24130, 12965, 22886, 25775, 14063, 25780, 35444, 35293}\n",
      "dict_items([])\n",
      "collecting tokens for  reputation\n",
      "indices:    {37024, 24004, 21061, 18310, 24199, 12676, 23658, 1195, 26715, 28398, 37115, 18302, 13817, 36954, 19547, 23134}\n",
      "dict_items([(\"Lemma('reputation.n.02.reputation')\", 3), (\"Lemma('repute.n.01.reputation')\", 3)])\n",
      "collecting tokens for  trends\n",
      "indices:    {27765, 25495, 13371, 22493, 16286}\n",
      "dict_items([(\"Lemma('tendency.n.04.trend')\", 2)])\n",
      "collecting tokens for  vulnerable\n",
      "indices:    {12956, 27204, 20070, 28488, 12779, 36307, 11799, 7738, 28507, 828, 893}\n",
      "dict_items([(\"Lemma('vulnerable.a.01.vulnerable')\", 7)])\n",
      "collecting tokens for  obligation\n",
      "indices:    {25184, 30752, 11748, 2789, 2790, 2056, 4586, 25069, 12271, 25841, 21437, 4638}\n",
      "dict_items([(\"Lemma('duty.n.01.obligation')\", 6), (\"Lemma('obligation.n.02.obligation')\", 1)])\n",
      "collecting tokens for  duration\n",
      "indices:    {4640, 15969, 17314, 14048, 16389, 31948, 12271, 28475, 16092}\n",
      "dict_items([(\"Lemma('duration.n.01.duration')\", 5), (\"Lemma('duration.n.02.duration')\", 1), (\"Lemma('duration.n.03.duration')\", 1)])\n",
      "collecting tokens for  indications\n",
      "indices:    {31088, 180, 13679}\n",
      "dict_items([(\"Lemma('indication.n.01.indication')\", 2)])\n",
      "collecting tokens for  weighed\n",
      "indices:    {2274, 4071, 4076, 12333, 4080, 4061, 27794, 4094, 1529, 3741, 16190}\n",
      "dict_items([(\"Lemma('consider.v.04.weigh')\", 2), (\"Lemma('weigh.v.01.weigh')\", 8)])\n",
      "collecting tokens for  permitted\n",
      "indices:    {28288, 24832, 24073, 11277, 17423, 22036, 5527, 34458, 157, 15279, 6962, 14008, 15289, 27837, 5954, 31301, 25286, 15304, 14284, 11724, 14035, 471, 36441, 22618, 3802, 350, 3550, 3552, 2274, 36453, 33127, 36327, 17646, 28271, 5486, 28275, 24700, 28285}\n",
      "dict_items([(\"Lemma('permit.v.01.permit')\", 26), (\"Lemma('let.v.01.permit')\", 8)])\n",
      "collecting tokens for  hang\n",
      "indices:    {19616, 24100, 33543, 35370, 20090, 17659, 2269}\n",
      "dict_items([(\"Lemma('hang.v.05.hang')\", 1), (\"Lemma('hang.v.02.hang')\", 2)])\n",
      "collecting tokens for  allows\n",
      "indices:    {27814, 27782, 969, 22026, 1546, 3084, 16368, 4915, 15956, 32341, 29877, 30395, 28318, 27807}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('permit.v.01.allow')\", 5), (\"Lemma('let.v.01.allow')\", 7)])\n",
      "collecting tokens for  islands\n",
      "indices:    {15022, 23935}\n",
      "dict_items([])\n",
      "collecting tokens for  japan\n",
      "indices:    {12751}\n",
      "dict_items([(\"Lemma('japan.n.01.Japan')\", 1)])\n",
      "collecting tokens for  revenue\n",
      "indices:    {15591}\n",
      "dict_items([])\n",
      "collecting tokens for  incurred\n",
      "indices:    {15589, 23655, 12306, 22037, 14873, 15612, 22750, 15614}\n",
      "dict_items([(\"Lemma('incur.v.01.incur')\", 8)])\n",
      "collecting tokens for  section\n",
      "indices:    {22789}\n",
      "dict_items([])\n",
      "collecting tokens for  taxpayer\n",
      "indices:    {24899, 24966, 15561, 9677, 11341, 24244, 23991, 22747, 22748, 22045, 22046}\n",
      "dict_items([(\"Lemma('taxpayer.n.01.taxpayer')\", 3)])\n",
      "collecting tokens for  ekstrohm\n",
      "indices:    {34577}\n",
      "dict_items([])\n",
      "collecting tokens for  centralized\n",
      "indices:    {32743, 32329, 32266, 4587, 32342, 4631, 20313, 31773}\n",
      "dict_items([(\"Lemma('centralized.a.01.centralized')\", 2)])\n",
      "collecting tokens for  arteries\n",
      "indices:    {3808, 11426, 4068, 4069, 4070, 3818, 3787, 4075, 3789, 34842, 4124, 3807}\n",
      "dict_items([(\"Lemma('artery.n.01.artery')\", 4)])\n",
      "collecting tokens for  1.5\n",
      "indices:    {22017, 11586, 11560, 25481, 25486, 14802, 2834, 20181, 24025, 4062}\n",
      "dict_items([(\"Lemma('fifteen.s.01.15')\", 1)])\n",
      "collecting tokens for  cm.\n",
      "indices:    {4096, 3265, 3300, 3301, 11398, 4072, 4083, 4084, 4095, 3262, 4062, 4063}\n",
      "dict_items([(\"Lemma('centimeter.n.01.cm')\", 12)])\n",
      "collecting tokens for  distal\n",
      "indices:    {3776, 3911, 3849, 3851, 3916, 3852, 3792, 3770, 4062}\n",
      "dict_items([(\"Lemma('distal.a.01.distal')\", 9)])\n",
      "collecting tokens for  terminal\n",
      "indices:    {3776, 14912, 17541, 3783, 9577, 3851, 3794, 2963, 4019, 3795, 4057}\n",
      "dict_items([(\"Lemma('terminal.n.01.terminal')\", 2)])\n",
      "collecting tokens for  whenever\n",
      "indices:    {36112, 27266, 11084}\n",
      "dict_items([])\n",
      "collecting tokens for  anatomy\n",
      "indices:    {3811, 10661, 19578, 7602, 25336, 3802, 2269, 7550}\n",
      "dict_items([(\"Lemma('anatomy.n.01.anatomy')\", 4), (\"Lemma('human_body.n.01.anatomy')\", 2), (\"Lemma('anatomy.n.03.anatomy')\", 1)])\n",
      "collecting tokens for  preaching\n",
      "indices:    {15328, 7041, 1317, 15334, 22377, 28075, 13359, 15314, 15319, 15317, 1303, 6974, 15327}\n",
      "dict_items([(\"Lemma('sermon.n.01.preaching')\", 10), (\"Lemma('preach.v.01.preach')\", 2)])\n",
      "collecting tokens for  powder\n",
      "indices:    {3139, 4164, 35588, 4198, 35423}\n",
      "dict_items([(\"Lemma('powder.n.01.powder')\", 3)])\n",
      "collecting tokens for  distinction\n",
      "indices:    {23681, 1795, 522, 33035, 29965, 22418, 27541, 1071, 34355, 179, 16058, 1468, 1474, 16194, 1219, 1733, 6088, 14666, 32203, 9170, 11099, 13920, 32232, 6893, 2673, 12279}\n",
      "dict_items([(\"Lemma('differentiation.n.01.distinction')\", 8), (\"Lemma('eminence.n.01.distinction')\", 5), (\"Lemma('distinction.n.04.distinction')\", 1), (\"Lemma('distinction.n.03.distinction')\", 4)])\n",
      "collecting tokens for  ml\n",
      "indices:    {4163, 3098, 3558, 3562, 3564, 3439, 3538, 3542, 3546, 3547}\n",
      "dict_items([(\"Lemma('milliliter.n.01.ml')\", 10)])\n",
      "collecting tokens for  cone\n",
      "indices:    {29664, 27104, 29667, 29573, 29575, 29612, 29583, 29617, 3570, 32821, 32824, 3545, 3546}\n",
      "dict_items([(\"Lemma('cone.n.01.cone')\", 3)])\n",
      "collecting tokens for  flashes\n",
      "indices:    {26400, 26401, 18125, 5837, 26224, 26712, 30845}\n",
      "dict_items([(\"Lemma('flash.n.01.flash')\", 2)])\n",
      "collecting tokens for  concept\n",
      "indices:    {31235, 27523, 2825, 31241, 1274, 2828, 9997, 31244, 9999, 1807, 2319, 13714, 25747, 32018, 12949, 31253, 31888, 14998, 27542, 25498, 5524, 2592, 14627, 32165, 31785, 23980, 15280, 34355, 34357, 2998, 13623, 7864, 31930, 14717, 3006, 33214, 30401, 32962, 34372, 31993, 23750, 3402, 31185, 31963, 16377, 31199, 2148, 31207, 7527, 1769, 31212, 31215, 2162, 31989, 31224, 7545, 12026, 31229, 31998}\n",
      "dict_items([(\"Lemma('concept.n.01.concept')\", 26)])\n",
      "collecting tokens for  drexel\n",
      "indices:    {21129}\n",
      "dict_items([])\n",
      "collecting tokens for  granted\n",
      "indices:    {12288, 14853, 14859, 28172, 12, 28171, 24082, 25618, 22808, 22816, 33315, 25509, 26280, 21426, 1331, 31542, 25017, 2106, 11841, 1221, 15309, 23246, 15568, 36436, 28249, 23642, 15583, 29924, 12916, 5879}\n",
      "dict_items([(\"Lemma('award.v.02.grant')\", 6), (\"Lemma('allow.v.03.grant')\", 7), (\"Lemma('given.s.01.granted')\", 3), (\"Lemma('accord.v.02.grant')\", 3)])\n",
      "collecting tokens for  macklin\n",
      "indices:    {18176}\n",
      "dict_items([(\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  performers\n",
      "indices:    {1029, 11260, 1038, 22384, 26961, 26416, 31956, 27160, 22332, 1053}\n",
      "dict_items([(\"Lemma('performer.n.01.performer')\", 4)])\n",
      "collecting tokens for  mahayana\n",
      "indices:    {28125}\n",
      "dict_items([])\n",
      "collecting tokens for  package\n",
      "indices:    {11808, 11809, 11789, 28110, 17871, 36944, 6191, 11798}\n",
      "dict_items([(\"Lemma('package.n.02.package')\", 3), (\"Lemma('package.n.01.package')\", 3)])\n",
      "collecting tokens for  resemblance\n",
      "indices:    {1185, 3937, 2564, 27302, 28110, 30255, 29010, 26807, 11484, 14461}\n",
      "dict_items([(\"Lemma('resemblance.n.01.resemblance')\", 5)])\n",
      "collecting tokens for  philosophical\n",
      "indices:    {14690, 27555, 27557, 16422, 13674, 13612, 28110, 13618, 11478, 25503, 13439}\n",
      "dict_items([(\"Lemma('philosophic.a.01.philosophical')\", 7)])\n",
      "collecting tokens for  killer\n",
      "indices:    {9664, 21249, 18276, 36006, 16841, 35019, 13963, 13970, 13973, 9783, 9658, 35836, 27229, 33375}\n",
      "dict_items([(\"Lemma('killer.n.01.killer')\", 8)])\n",
      "collecting tokens for  consecutive\n",
      "indices:    {22019, 196, 14051, 22062, 22926, 22995, 36695, 4153, 20829}\n",
      "dict_items([])\n",
      "collecting tokens for  preferred\n",
      "indices:    {22542, 32923, 32423, 32425, 32427, 29229, 26542, 3118, 11060, 33215, 1216, 33222, 28623, 9311, 24033, 15846, 12392, 36073, 12022}\n",
      "dict_items([(\"Lemma('choose.v.02.prefer')\", 8), (\"Lemma('prefer.v.01.prefer')\", 5), (\"Lemma('preferable.s.01.preferred')\", 1), (\"Lemma('prefer.v.03.prefer')\", 1)])\n",
      "collecting tokens for  insurance\n",
      "indices:    {11808, 11809, 27202, 28676, 20848, 32273, 27164}\n",
      "dict_items([(\"Lemma('insurance.n.01.insurance')\", 2)])\n",
      "collecting tokens for  guilt\n",
      "indices:    {27800, 25377, 35106, 5284, 5286, 11048, 20138, 20155, 21311, 8896, 12243, 32852, 32855, 19417, 5339, 32866, 19427, 32872, 2666}\n",
      "dict_items([(\"Lemma('guilt.n.01.guilt')\", 6), (\"Lemma('guilt.n.02.guilt')\", 2)])\n",
      "collecting tokens for  criminal\n",
      "indices:    {35971, 27043, 20165, 22777, 5339, 25168, 12241, 12243, 13972, 13940, 25622, 13977, 13947}\n",
      "dict_items([(\"Lemma('criminal.n.01.criminal')\", 5)])\n",
      "collecting tokens for  mercy\n",
      "indices:    {20969, 2571, 24277, 12014}\n",
      "dict_items([(\"Lemma('mercifulness.n.02.mercy')\", 1), (\"Lemma('clemency.n.02.mercy')\", 1)])\n",
      "collecting tokens for  guidance\n",
      "indices:    {2728}\n",
      "dict_items([(\"Lemma('guidance.n.01.guidance')\", 1)])\n",
      "collecting tokens for  spare\n",
      "indices:    {25666, 12131, 6441, 29705, 19531, 5676, 35084, 12109, 21739, 28413, 15148, 14453, 7671, 28443, 29980, 36541, 29822}\n",
      "dict_items([(\"Lemma('spare.v.01.spare')\", 3), (\"Lemma('spare.v.03.spare')\", 1), (\"Lemma('spare.v.02.spare')\", 1), (\"Lemma('excess.s.01.spare')\", 1), (\"Lemma('spare.s.01.spare')\", 1)])\n",
      "collecting tokens for  eternal\n",
      "indices:    {1509, 28265, 28138, 1515, 6444, 8239, 28081, 36210, 7070, 4692, 4661, 24919, 28089, 36122, 27645, 28286}\n",
      "dict_items([(\"Lemma('ageless.s.01.eternal')\", 4)])\n",
      "collecting tokens for  pupils\n",
      "indices:    {24931, 1731, 24934, 14474, 19595, 13323, 13325, 36303, 24913, 27412, 23578, 13279}\n",
      "dict_items([(\"Lemma('student.n.01.pupil')\", 6)])\n",
      "collecting tokens for  attorneys\n",
      "indices:    {21769, 21311}\n",
      "dict_items([])\n",
      "collecting tokens for  presentation\n",
      "indices:    {15748, 26760, 28169, 32657, 26519, 11031, 14767, 22192, 14272, 16194, 13644, 21709, 13649, 13654, 15708, 26076, 22387, 22388, 15733, 20474, 32638}\n",
      "dict_items([(\"Lemma('presentation.n.01.presentation')\", 3), (\"Lemma('presentation.n.03.presentation')\", 4), (\"Lemma('presentation.n.04.presentation')\", 1), (\"Lemma('presentation.n.02.presentation')\", 2)])\n",
      "collecting tokens for  witnesses\n",
      "indices:    {21760, 21761, 12197, 2282, 7531, 6421, 21753, 15327, 5083, 18234, 21759}\n",
      "dict_items([(\"Lemma('witness.n.01.witness')\", 3), (\"Lemma('spectator.n.01.witness')\", 2), (\"Lemma('witness.n.04.witness')\", 1)])\n",
      "collecting tokens for  mainly\n",
      "indices:    {16800, 4675, 30043, 3932, 25662}\n",
      "dict_items([(\"Lemma('chiefly.r.01.mainly')\", 3)])\n",
      "collecting tokens for  charles\n",
      "indices:    {13846}\n",
      "dict_items([])\n",
      "collecting tokens for  clung\n",
      "indices:    {5412, 13574, 8102, 35307, 4716, 18194, 5012, 36021, 18518, 19703, 36062}\n",
      "dict_items([(\"Lemma('cling.v.01.cling')\", 5), (\"Lemma('cling.v.02.cling')\", 2)])\n",
      "collecting tokens for  buried\n",
      "indices:    {12737, 867, 31780, 13574, 27143, 873, 7658, 21260, 12784, 21363, 12796, 7007}\n",
      "dict_items([(\"Lemma('bury.v.01.bury')\", 2), (\"Lemma('bury.v.02.bury')\", 5), (\"Lemma('bury.v.03.bury')\", 2), (\"Lemma('immerse.v.03.bury')\", 1)])\n",
      "collecting tokens for  farmer\n",
      "indices:    {23308, 19217, 12071, 12074, 21675, 12078, 19503, 23982, 23985, 12081, 9146, 12090, 8258, 12109, 30555, 31330, 30563, 12137, 31853, 22002, 26616}\n",
      "dict_items([(\"Lemma('farmer.n.01.farmer')\", 10)])\n",
      "collecting tokens for  ass\n",
      "indices:    {28584}\n",
      "dict_items([])\n",
      "collecting tokens for  mechanical\n",
      "indices:    {2432, 32131, 3214, 28688, 3225, 31270, 36652, 28718, 2998, 27201, 5571, 2243, 28745, 11608, 11614, 11616, 21857, 4201, 34669, 12279, 3199}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('mechanical.a.02.mechanical')\", 2), (\"Lemma('mechanical.a.01.mechanical')\", 9), (\"Lemma('mechanical.a.03.mechanical')\", 1)])\n",
      "collecting tokens for  sooner\n",
      "indices:    {36448, 21905, 18925}\n",
      "dict_items([(\"Lemma('sooner.r.01.sooner')\", 1)])\n",
      "collecting tokens for  deeper\n",
      "indices:    {33158, 19209, 5769, 13833, 10769, 22673, 34453, 20248, 22688, 30241, 13371, 26942, 13507, 27602, 27864, 36956, 6878, 13935, 12794}\n",
      "dict_items([(\"Lemma('deep.s.02.deep')\", 5), (\"Lemma('profoundly.r.01.deeply')\", 1), (\"Lemma('deeply.r.02.deeply')\", 1), (\"Lemma('deep.s.04.deep')\", 1), (\"Lemma('deep.a.01.deep')\", 1)])\n",
      "collecting tokens for  dodge\n",
      "indices:    {21501}\n",
      "dict_items([])\n",
      "collecting tokens for  crossed\n",
      "indices:    {6403, 28422, 17542, 12961, 13606, 29355, 5676, 7212, 18477, 33712, 16827, 8509, 29374, 5951, 35263, 199, 29385, 23113, 18379, 33998, 8666, 34267, 8540, 6500, 35691, 6385, 12018, 2164, 28154}\n",
      "dict_items([(\"Lemma('traverse.v.01.cross')\", 25), (\"Lemma('cross.v.04.cross')\", 1), (\"Lemma('intersect.v.01.cross')\", 1), (\"Lemma('thwart.v.01.cross')\", 1)])\n",
      "collecting tokens for  tap\n",
      "indices:    {28802, 31102, 10947, 28809, 26539, 28811, 28784, 29395, 19322, 2366}\n",
      "dict_items([(\"Lemma('tap.v.01.tap')\", 3), (\"Lemma('tap.v.02.tap')\", 2), (\"Lemma('pat.n.01.tap')\", 2)])\n",
      "collecting tokens for  badness\n",
      "indices:    {4864, 4899, 4901, 4840, 4845, 4849, 4854, 4863}\n",
      "dict_items([(\"Lemma('bad.n.01.badness')\", 8)])\n",
      "collecting tokens for  belonging\n",
      "indices:    {4864, 27840, 11140, 21158, 18376, 4233, 425, 5072, 32382}\n",
      "dict_items([(\"Lemma('belong.v.01.belong')\", 3), (\"Lemma('property.n.01.belongings')\", 1)])\n",
      "collecting tokens for  pine\n",
      "indices:    {2306, 19459, 16164, 10468, 31151, 36017, 35988, 36023, 2301, 22975}\n",
      "dict_items([(\"Lemma('pine.n.01.pine')\", 1), (\"Lemma('pine.n.02.pine')\", 1)])\n",
      "collecting tokens for  path\n",
      "indices:    {31876, 21511, 27144, 13581, 3855, 5409, 6063, 31151, 15281, 19122, 7348, 27131, 3768, 829, 36036, 27337, 24147, 33876, 25813, 15445, 29405, 7904, 13548, 13550, 2683, 2685}\n",
      "dict_items([(\"Lemma('path.n.02.path')\", 6), (\"Lemma('way.n.05.path')\", 6), (\"Lemma('path.n.03.path')\", 2)])\n",
      "collecting tokens for  bumblebees\n",
      "indices:    {3609, 3637}\n",
      "dict_items([(\"Lemma('bumblebee.n.01.bumblebee')\", 2)])\n",
      "collecting tokens for  observer\n",
      "indices:    {11360, 1425}\n",
      "dict_items([(\"Lemma('perceiver.n.01.observer')\", 1)])\n",
      "collecting tokens for  unfortunately\n",
      "indices:    {22122}\n",
      "dict_items([])\n",
      "collecting tokens for  choose\n",
      "indices:    {25888, 28289, 20196, 16744, 36879, 12145, 28660, 25429, 1080, 25754, 25980, 25501, 19359}\n",
      "dict_items([(\"Lemma('choose.v.01.choose')\", 10), (\"Lemma('choose.v.02.choose')\", 1), (\"Lemma('choose.v.03.choose')\", 2)])\n",
      "collecting tokens for  vein\n",
      "indices:    {3853, 3855, 35861, 2203, 26407, 24114, 27319, 3768, 3772, 702, 3779, 3781, 3783, 12619, 7645, 7646, 1759, 3824, 14322, 3826}\n",
      "dict_items([(\"Lemma('vein.n.02.vein')\", 5), (\"Lemma('vein.n.01.vein')\", 2), (\"Lemma('pulmonary_vein.n.01.pulmonary_vein')\", 3)])\n",
      "collecting tokens for  eugene\n",
      "indices:    {20800}\n",
      "dict_items([])\n",
      "collecting tokens for  harold\n",
      "indices:    {1156}\n",
      "dict_items([])\n",
      "collecting tokens for  cared\n",
      "indices:    {30434, 1678, 10513, 29140, 7414, 10232, 10554, 10524}\n",
      "dict_items([(\"Lemma('care.v.01.care')\", 2), (\"Lemma('wish.v.02.care')\", 2), (\"Lemma('care.v.02.care')\", 1), (\"Lemma('manage.v.02.care')\", 1)])\n",
      "collecting tokens for  improved\n",
      "indices:    {15752, 30091, 24463, 1565, 26910, 21534, 32418, 11682, 26411, 5420, 15539, 4148, 29113, 24509, 16190, 33088, 24001, 33091, 4164, 30149, 11724, 36429, 11726, 32591, 29136, 5203, 219, 31067, 2401, 23652, 15207, 5738, 27754, 15722, 29051, 2805, 32760, 1915, 21629}\n",
      "dict_items([(\"Lemma('better.v.02.improve')\", 16), (\"Lemma('improved.s.02.improved')\", 2), (\"Lemma('better.v.03.improve')\", 4), (\"Lemma('improved.a.01.improved')\", 3)])\n",
      "collecting tokens for  movable\n",
      "indices:    {32416, 31329, 32413, 32427, 32407, 32378, 32411, 29885}\n",
      "dict_items([])\n",
      "collecting tokens for  priority\n",
      "indices:    {24836, 13189, 32134, 73, 4618, 24075, 24073, 12767, 32499, 16211, 23285, 24950, 55, 21205, 32505, 32159}\n",
      "dict_items([(\"Lemma('precedence.n.01.priority')\", 6)])\n",
      "collecting tokens for  differs\n",
      "indices:    {31042, 13891, 1732, 3782, 29128, 4009, 13296, 5266}\n",
      "dict_items([(\"Lemma('differ.v.01.differ')\", 8)])\n",
      "collecting tokens for  deliver\n",
      "indices:    {5349, 3494, 23816, 635, 12650, 6191, 14511, 20149, 24218, 24219, 5310}\n",
      "dict_items([(\"Lemma('deliver.v.02.deliver')\", 5), (\"Lemma('deliver.v.01.deliver')\", 2), (\"Lemma('hand_over.v.01.deliver')\", 2), (\"Lemma('rescue.v.01.deliver')\", 2)])\n",
      "collecting tokens for  katanga\n",
      "indices:    {23808}\n",
      "dict_items([])\n",
      "collecting tokens for  chaos\n",
      "indices:    {23811, 13477, 31910, 23816, 17864, 22826, 13451, 13457, 13458, 23256, 9149, 5022}\n",
      "dict_items([(\"Lemma('chaos.n.01.chaos')\", 7)])\n",
      "collecting tokens for  lessons\n",
      "indices:    {20961, 15716, 9582, 34703, 11280, 10159, 36303, 10163, 31608, 34682, 15707, 24988, 1949, 7678}\n",
      "dict_items([(\"Lemma('lesson.n.01.lesson')\", 4), (\"Lemma('moral.n.01.lesson')\", 1), (\"Lemma('lesson.n.04.lesson')\", 2)])\n",
      "collecting tokens for  instruments\n",
      "indices:    {3330, 1794, 22289, 3357, 19492, 14503, 30773, 15163, 1086, 25665, 32707, 1092, 1093, 30789, 1743, 28887, 26084, 32742, 34415, 17143, 1791}\n",
      "dict_items([(\"Lemma('instrument.n.01.instrument')\", 10)])\n",
      "collecting tokens for  jacket\n",
      "indices:    {33931, 17680, 26386, 13079, 8103, 6956, 35245, 34101, 33589, 21053, 19518, 19519, 33610, 719, 31567, 27093, 33877, 19550, 19683, 36453, 19688, 36458, 21618, 25846, 9719}\n",
      "dict_items([(\"Lemma('jacket.n.01.jacket')\", 6), (\"Lemma('jacket.n.02.jacket')\", 2), (\"Lemma('crown.n.11.jacket')\", 1)])\n",
      "collecting tokens for  acquisition\n",
      "indices:    {15237, 15238, 15239, 32286, 31719, 15242, 28139, 22494, 15229, 2110, 15231}\n",
      "dict_items([(\"Lemma('acquisition.n.01.acquisition')\", 7)])\n",
      "collecting tokens for  condemned\n",
      "indices:    {36385, 5346, 21412, 15237, 15238, 12324, 21644, 12302, 10511, 5298, 1364, 28054, 5279}\n",
      "dict_items([(\"Lemma('condemn.v.01.condemn')\", 8), (\"Lemma('condemn.v.02.condemn')\", 2), (\"Lemma('sentence.v.01.condemn')\", 1), (\"Lemma('condemn.v.04.condemn')\", 1)])\n",
      "collecting tokens for  drying\n",
      "indices:    {21857, 29538, 26855, 29607, 10569, 7914, 36394, 21865, 29581, 4142, 3281, 7894}\n",
      "dict_items([(\"Lemma('dry.v.01.dry')\", 3)])\n",
      "collecting tokens for  linear\n",
      "indices:    {4355, 4357, 4361, 4363, 4367, 3088, 4374, 4375, 3352, 11302, 11303, 4280, 4296, 4326, 3047, 4335, 4337, 4338, 3059}\n",
      "dict_items([(\"Lemma('linear.a.01.linear')\", 4), (\"Lemma('linear.a.02.linear')\", 3)])\n",
      "collecting tokens for  dependence\n",
      "indices:    {2947, 3364, 3047, 2860, 32562, 28022, 32150, 20822, 3292, 4445}\n",
      "dict_items([(\"Lemma('dependence.n.01.dependence')\", 6)])\n",
      "collecting tokens for  berlin\n",
      "indices:    {23678}\n",
      "dict_items([])\n",
      "collecting tokens for  hatred\n",
      "indices:    {10528, 2497, 19399, 25320, 12551, 12615, 19180, 35853, 32078, 7919, 10544, 5778, 28405, 2491, 12220}\n",
      "dict_items([(\"Lemma('hate.n.01.hatred')\", 11)])\n",
      "collecting tokens for  promising\n",
      "indices:    {24642, 12004, 20932, 28999, 14922, 1067, 11914, 239, 14736, 28975, 11475, 22201, 15512, 15513, 23834, 7324, 14488, 28958}\n",
      "dict_items([(\"Lemma('bright.s.10.promising')\", 2), (\"Lemma('promising.s.01.promising')\", 9), (\"Lemma('promise.v.01.promise')\", 2)])\n",
      "collecting tokens for  reply\n",
      "indices:    {7042, 25743, 12438, 32407, 12701, 8356, 32424, 25001, 2476, 7085, 20268, 22962, 24627, 37174, 22848, 21953, 24642, 6978, 23502, 5736, 19818, 20717, 5745, 18546, 26104, 26105}\n",
      "dict_items([(\"Lemma('answer.n.01.reply')\", 8), (\"Lemma('answer.v.01.reply')\", 8)])\n",
      "collecting tokens for  thieves\n",
      "indices:    {21616, 6993, 5079, 6745, 18271}\n",
      "dict_items([(\"Lemma('thief.n.01.thief')\", 3)])\n",
      "collecting tokens for  chances\n",
      "indices:    {24130, 12195, 33189, 456, 18857, 8078, 401, 36244, 28853, 18292, 35095, 9784, 24372, 25652, 10716, 4765, 21278, 26687}\n",
      "dict_items([(\"Lemma('opportunity.n.01.chance')\", 5), (\"Lemma('chance.n.03.chance')\", 2), (\"Lemma('luck.n.02.chance')\", 1)])\n",
      "collecting tokens for  garage\n",
      "indices:    {16009, 33673, 34187, 34190, 2580, 32280, 10534, 17063, 5421, 30127, 17072, 17080, 33607, 7381, 34136, 33628, 5471, 32352, 17019}\n",
      "dict_items([(\"Lemma('garage.n.01.garage')\", 10), (\"Lemma('garage.v.01.garage')\", 1)])\n",
      "collecting tokens for  briefly\n",
      "indices:    {35841, 34831, 33938, 26777, 2843, 5666, 26410, 3244, 6061, 9390, 13115, 14400, 23113, 24393, 8524, 32222, 2655, 11104, 23779, 18533, 3184, 11381, 11512}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('concisely.r.01.briefly')\", 7), (\"Lemma('briefly.r.01.briefly')\", 7)])\n",
      "collecting tokens for  bang\n",
      "indices:    {17796, 10948, 17604, 11180, 31570, 344, 23835}\n",
      "dict_items([(\"Lemma('bang.n.02.bang')\", 2), (\"Lemma('bang.n.03.bang')\", 1), (\"Lemma('slam.v.01.bang')\", 1), (\"Lemma('slam.v.02.bang')\", 1)])\n",
      "collecting tokens for  consistently\n",
      "indices:    {10876, 24993, 14434, 68, 4996, 5574, 24454, 31054, 23887, 2673, 25847, 1468}\n",
      "dict_items([(\"Lemma('systematically.r.01.consistently')\", 7)])\n",
      "collecting tokens for  spectacle\n",
      "indices:    {2693, 26985, 31563, 1005, 1198, 23921, 2644, 9365, 2391, 27001, 35325, 12734}\n",
      "dict_items([(\"Lemma('spectacle.n.01.spectacle')\", 5), (\"Lemma('spectacle.n.02.spectacle')\", 2)])\n",
      "collecting tokens for  improving\n",
      "indices:    {23424, 21924, 5, 2730, 22620, 23631, 23763, 13269, 16311, 28665, 2714, 30427, 11548, 28990}\n",
      "dict_items([(\"Lemma('better.v.02.improve')\", 11), (\"Lemma('better.v.03.improve')\", 3)])\n",
      "collecting tokens for  africa\n",
      "indices:    {14507}\n",
      "dict_items([(\"Lemma('africa.n.01.Africa')\", 1)])\n",
      "collecting tokens for  radar\n",
      "indices:    {34434, 14981, 14982, 11418, 30365, 11421, 3365, 3366, 30373, 3378, 3387, 31292, 14044, 30314, 28530, 34420, 11386, 3325, 25982}\n",
      "dict_items([(\"Lemma('radar.n.01.radar')\", 11)])\n",
      "collecting tokens for  pa.\n",
      "indices:    {21697}\n",
      "dict_items([])\n",
      "collecting tokens for  affixed\n",
      "indices:    {5376, 32641, 32675, 5413, 32649, 5385, 5402, 32690, 32658, 32631, 5369, 32665, 5371, 20381}\n",
      "dict_items([(\"Lemma('affix.v.01.affix')\", 7), (\"Lemma('affixed.a.01.affixed')\", 6), (\"Lemma('append.v.01.affix')\", 1)])\n",
      "collecting tokens for  seeming\n",
      "indices:    {19413, 19079}\n",
      "dict_items([(\"Lemma('look.v.02.seem')\", 2)])\n",
      "collecting tokens for  alabama\n",
      "indices:    {6046}\n",
      "dict_items([(\"Lemma('location.n.01.location')\", 1)])\n",
      "collecting tokens for  soldier\n",
      "indices:    {909, 12559, 12561, 5908, 26517, 22548, 12578, 5922, 24874, 12596, 8505, 12606, 12617, 25546, 8527, 8028, 8553, 25834, 8047, 8560}\n",
      "dict_items([(\"Lemma('soldier.n.01.soldier')\", 15)])\n",
      "collecting tokens for  diet\n",
      "indices:    {37160}\n",
      "dict_items([])\n",
      "collecting tokens for  allotments\n",
      "indices:    {15009, 15044, 15062}\n",
      "dict_items([(\"Lemma('allotment.n.01.allotment')\", 3)])\n",
      "collecting tokens for  publicity\n",
      "indices:    {6145, 22755, 2472, 13359, 13361, 36951, 20985, 21534}\n",
      "dict_items([(\"Lemma('promotion.n.01.publicity')\", 3)])\n",
      "collecting tokens for  producer\n",
      "indices:    {25635, 1124, 1033, 23439, 21555, 33369, 11165}\n",
      "dict_items([(\"Lemma('producer.n.02.producer')\", 2)])\n",
      "collecting tokens for  scattered\n",
      "indices:    {13569, 17570, 11107, 20225, 17639, 26410, 33162, 31821, 10317, 7730, 35442, 19124, 181, 35446, 4021, 26136, 35420, 4669}\n",
      "dict_items([(\"Lemma('scattered.s.01.scattered')\", 6), (\"Lemma('scatter.v.03.scatter')\", 2), (\"Lemma('disperse.v.04.scatter')\", 1), (\"Lemma('break_up.v.17.scatter')\", 1), (\"Lemma('scatter.v.04.scatter')\", 1), (\"Lemma('disperse.v.02.scatter')\", 1)])\n",
      "collecting tokens for  sounded\n",
      "indices:    {26113, 36611, 9224, 7048, 7817, 33803, 18204, 14504, 35627, 13754, 1728, 16578, 9927, 18256, 34776, 35545, 15840, 99, 9444, 36709, 26472, 7912, 36336, 33788}\n",
      "dict_items([(\"Lemma('sound.v.01.sound')\", 10), (\"Lemma('sound.v.02.sound')\", 9), (\"Lemma('opine.v.01.sound_off')\", 1), (\"Lemma('sound.v.03.sound')\", 4)])\n",
      "collecting tokens for  bomb\n",
      "indices:    {8698, 3098, 14772}\n",
      "dict_items([(\"Lemma('bomb_calorimeter.n.01.bomb')\", 1), (\"Lemma('bombard.v.02.bomb')\", 1)])\n",
      "collecting tokens for  fogg\n",
      "indices:    {30540}\n",
      "dict_items([])\n",
      "collecting tokens for  planets\n",
      "indices:    {2824, 2825, 2829, 2831, 27949, 27950, 27955, 34484, 34483, 27959, 27977, 36304, 10847, 10848, 2793, 2797, 2801, 2804, 2805, 2806}\n",
      "dict_items([(\"Lemma('planet.n.01.planet')\", 12)])\n",
      "collecting tokens for  kill\n",
      "indices:    {136, 19466, 19468, 16658, 34328, 34329, 27808, 6177, 34981, 24229, 18730, 35499, 5038, 28462, 5041, 9271, 35578, 17979, 35260, 35773, 17982, 33344, 26051, 3397, 16711, 35016, 6602, 35531, 5075, 12629, 15320, 17498, 28511, 12641, 12898, 1381, 18409, 6901, 8186, 33279}\n",
      "dict_items([(\"Lemma('kill.v.01.kill')\", 26), (\"Lemma('kill.v.02.kill')\", 1), (\"Lemma('killing.n.02.kill')\", 3), (\"Lemma('kill.n.02.kill')\", 1)])\n",
      "collecting tokens for  blockade\n",
      "indices:    {14986, 14959}\n",
      "dict_items([(\"Lemma('blockade.n.01.blockade')\", 1)])\n",
      "collecting tokens for  bringing\n",
      "indices:    {16641, 14978, 20873, 8336, 14993, 13203, 26901, 12696, 7708, 15407, 8112, 14002, 564, 8891, 30523, 33227, 32730, 36570, 28638, 2654, 8288, 9189, 15846, 32873, 28016, 9587, 28405, 30972, 893}\n",
      "dict_items([(\"Lemma('bring.v.02.bring')\", 5), (\"Lemma('bring.v.06.bring')\", 2), (\"Lemma('bring_to_bear.v.01.bring_to_bear')\", 1), (\"Lemma('bring.v.01.bring')\", 13), (\"Lemma('bring.v.04.bring')\", 1)])\n",
      "collecting tokens for  promotion\n",
      "indices:    {1363}\n",
      "dict_items([])\n",
      "collecting tokens for  conclude\n",
      "indices:    {4930, 4965, 30246, 3337, 33162, 26637, 7950, 27982, 25393, 15928, 2175}\n",
      "dict_items([(\"Lemma('reason.v.01.conclude')\", 10), (\"Lemma('conclude.v.03.conclude')\", 1)])\n",
      "collecting tokens for  thumb\n",
      "indices:    {18950, 33575, 714, 19566, 30159, 30998, 24502, 36472}\n",
      "dict_items([(\"Lemma('thumb.n.01.thumb')\", 3)])\n",
      "collecting tokens for  vector\n",
      "indices:    {4354, 34467, 4357, 4358, 4296, 4362, 4363, 4335, 4369, 4337, 4313}\n",
      "dict_items([(\"Lemma('vector.n.01.vector')\", 10)])\n",
      "collecting tokens for  considerably\n",
      "indices:    {16897, 4999, 30215, 29066, 7435, 24461, 1422, 32270, 2708, 3734, 10265, 924, 30240, 32295, 13223, 26797, 23088, 32182, 29753, 4922, 25668, 17350, 14791, 14153, 22732, 32335, 29139, 212, 6104, 91, 16110, 23282, 1012, 26230, 2808}\n",
      "dict_items([(\"Lemma('well.r.07.considerably')\", 19)])\n",
      "collecting tokens for  rates\n",
      "indices:    {28674, 3332, 28677, 21894, 33028, 2948, 2955, 12175, 32150, 33046, 21528, 22809, 15769, 22808, 36125, 3234, 11813, 32293, 32295, 23847, 23848, 11815, 23849, 32294, 2866, 32562, 5554, 32955, 3004, 3007, 5572, 23493, 3015, 32967, 15049, 3022, 15055, 3279, 23378, 3283, 21972, 3285, 2780, 20704, 3297, 16354, 23395, 2929, 27250, 29300, 32373, 15480, 15482, 30203}\n",
      "dict_items([(\"Lemma('rate.n.01.rate')\", 16), (\"Lemma('rate.n.02.rate')\", 6), (\"Lemma('rate.v.02.rate')\", 2)])\n",
      "collecting tokens for  nationally\n",
      "indices:    {30979, 32295, 11886, 3151, 29971, 36980, 21976, 20347, 639}\n",
      "dict_items([(\"Lemma('nationally.r.01.nationally')\", 2), (\"Lemma('nationally.r.02.nationally')\", 1)])\n",
      "collecting tokens for  approximate\n",
      "indices:    {14849, 14850, 3747, 32295, 31948, 31949, 33038, 3380, 2968}\n",
      "dict_items([(\"Lemma('approximate.v.01.approximate')\", 2), (\"Lemma('approximate.s.01.approximate')\", 3), (\"Lemma('estimate.v.01.approximate')\", 1)])\n",
      "collecting tokens for  montgomery\n",
      "indices:    {30268}\n",
      "dict_items([])\n",
      "collecting tokens for  uneasy\n",
      "indices:    {1024, 27265, 9995, 2587, 2599, 9652, 31799, 7739, 14156, 7762, 5981, 10462, 12254, 1250, 35944, 8050, 12407, 12537, 30332}\n",
      "dict_items([(\"Lemma('uneasy.a.01.uneasy')\", 15)])\n",
      "collecting tokens for  insists\n",
      "indices:    {291, 23015, 20936, 28169, 24014, 23982, 28661, 31799, 13982}\n",
      "dict_items([(\"Lemma('insist.v.01.insist')\", 9)])\n",
      "collecting tokens for  classified\n",
      "indices:    {10648, 3880}\n",
      "dict_items([(\"Lemma('classified.a.01.classified')\", 1), (\"Lemma('classify.v.01.classify')\", 1)])\n",
      "collecting tokens for  dilemma\n",
      "indices:    {2656, 25825, 13922, 2660, 25420, 25421, 25422, 25423, 30000, 7762, 5395, 20659, 24882, 5398, 10616, 13979, 31806}\n",
      "dict_items([(\"Lemma('dilemma.n.01.dilemma')\", 8)])\n",
      "collecting tokens for  bouncing\n",
      "indices:    {6537, 5803, 13079, 207, 13086, 35575, 13084, 9662, 13087}\n",
      "dict_items([(\"Lemma('bounce.n.03.bouncing')\", 2), (\"Lemma('bounce.v.01.bounce')\", 4), (\"Lemma('bounce.v.03.bounce')\", 2)])\n",
      "collecting tokens for  irrelevant\n",
      "indices:    {24160, 2693, 12965, 31943, 28139, 27150, 34287, 1329, 2328, 25465, 13403, 1310}\n",
      "dict_items([(\"Lemma('irrelevant.a.01.irrelevant')\", 6)])\n",
      "collecting tokens for  ignorance\n",
      "indices:    {35997, 28694}\n",
      "dict_items([])\n",
      "collecting tokens for  preserved\n",
      "indices:    {12545, 23521, 3714, 36199, 27823, 32017, 5398, 2359, 19292, 31518}\n",
      "dict_items([(\"Lemma('save.v.02.preserve')\", 3), (\"Lemma('continue.v.03.preserve')\", 3), (\"Lemma('conserve.v.02.preserve')\", 1), (\"Lemma('preserved.a.02.preserved')\", 1), (\"Lemma('preserved.a.01.preserved')\", 1)])\n",
      "collecting tokens for  folklore\n",
      "indices:    {2342, 2354, 2327, 2360, 11257, 2300, 2303}\n",
      "dict_items([(\"Lemma('folklore.n.01.folklore')\", 6)])\n",
      "collecting tokens for  realtors\n",
      "indices:    {32489}\n",
      "dict_items([])\n",
      "collecting tokens for  civic\n",
      "indices:    {36967, 909, 12659, 25110, 32630, 24408}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('civic.a.01.civic')\", 2)])\n",
      "collecting tokens for  writings\n",
      "indices:    {31706, 24770, 30754, 5220, 30408, 1466, 27440, 14416, 4724, 14713, 27546, 29307, 31708}\n",
      "dict_items([(\"Lemma('writing.n.03.writing')\", 2), (\"Lemma('writing.n.02.writing')\", 1), (\"Lemma('hagiographa.n.01.Writings')\", 1)])\n",
      "collecting tokens for  warrant\n",
      "indices:    {27266, 13187, 25284, 27878, 27783, 31708, 25389, 21777, 5297, 21783, 14683, 27772, 5085, 16159}\n",
      "dict_items([(\"Lemma('justify.v.01.warrant')\", 10), (\"Lemma('warrant.n.01.warrant')\", 1)])\n",
      "collecting tokens for  heroic\n",
      "indices:    {31704, 26173, 5606}\n",
      "dict_items([(\"Lemma('epic.s.01.heroic')\", 1)])\n",
      "collecting tokens for  founding\n",
      "indices:    {23536, 31699}\n",
      "dict_items([])\n",
      "collecting tokens for  striking\n",
      "indices:    {9344, 1801, 4115, 14362, 31095, 1314, 22820, 26030, 13233, 24627, 8504, 34109, 6337, 13385, 29258, 4044, 3664, 3796, 8415, 15714, 4962, 21736, 15871, 20849, 32117, 31735, 14461, 21631}\n",
      "dict_items([(\"Lemma('strike.v.01.strike')\", 2), (\"Lemma('hit.v.02.strike')\", 2), (\"Lemma('dramatic.s.02.striking')\", 14), (\"Lemma('strike.v.07.strike')\", 1)])\n",
      "collecting tokens for  nuclei\n",
      "indices:    {4067, 3051, 4044, 3052, 4111, 3056, 4115, 4117, 4118, 4119, 4120, 4121, 4187}\n",
      "dict_items([(\"Lemma('nucleus.n.01.nucleus')\", 10), (\"Lemma('nucleus.n.02.nucleus')\", 3)])\n",
      "collecting tokens for  fibers\n",
      "indices:    {4067, 4044, 4108, 4110, 29903, 4112, 4111, 4113, 4115, 36052, 4117, 4118, 4121, 4122}\n",
      "dict_items([(\"Lemma('fiber.n.01.fiber')\", 10)])\n",
      "collecting tokens for  terrace\n",
      "indices:    {31793, 21242, 29443}\n",
      "dict_items([])\n",
      "collecting tokens for  observers\n",
      "indices:    {12743, 23752, 20139, 15727, 2835}\n",
      "dict_items([(\"Lemma('perceiver.n.01.observer')\", 1), (\"Lemma('observer.n.02.observer')\", 2)])\n",
      "collecting tokens for  andrus\n",
      "indices:    {7306}\n",
      "dict_items([])\n",
      "collecting tokens for  muttered\n",
      "indices:    {7333, 8517, 7879, 36776, 33610, 19211, 9965, 15830, 20950, 36474, 19709, 7294, 7327}\n",
      "dict_items([(\"Lemma('mumble.v.01.mutter')\", 10), (\"Lemma('murmur.v.02.mutter')\", 3)])\n",
      "collecting tokens for  sac\n",
      "indices:    {31341}\n",
      "dict_items([])\n",
      "collecting tokens for  bombers\n",
      "indices:    {224, 15521, 23362, 15527, 30376, 31282, 28498, 18714, 30365}\n",
      "dict_items([(\"Lemma('bomber.n.01.bomber')\", 3)])\n",
      "collecting tokens for  unquestionably\n",
      "indices:    {16905, 23724, 1237}\n",
      "dict_items([(\"Lemma('unquestionably.r.01.unquestionably')\", 2)])\n",
      "collecting tokens for  assure\n",
      "indices:    {21441, 25442, 11779, 14242, 32005, 2762, 28363, 20365, 2479, 4625, 30097, 29908, 11893, 14748, 28508, 12767}\n",
      "dict_items([(\"Lemma('guarantee.v.02.assure')\", 10), (\"Lemma('see.v.10.assure')\", 5), (\"Lemma('assure.v.02.assure')\", 1)])\n",
      "collecting tokens for  dominance\n",
      "indices:    {24129, 4226, 4227, 31172, 14247, 4231, 5425, 4246, 4632, 28508}\n",
      "dict_items([(\"Lemma('laterality.n.03.dominance')\", 4), (\"Lemma('dominance.n.02.dominance')\", 3)])\n",
      "collecting tokens for  lasted\n",
      "indices:    {23169, 34824, 30760, 24010, 3442, 12053, 8152, 26649}\n",
      "dict_items([(\"Lemma('last.v.01.last')\", 8)])\n",
      "collecting tokens for  anticipated\n",
      "indices:    {225, 24195, 17924, 24899, 19621, 30826, 32846, 16367, 15503, 31730, 20660, 22580, 12470, 21815, 1051, 1052, 94}\n",
      "dict_items([(\"Lemma('anticipate.v.03.anticipate')\", 2), (\"Lemma('expect.v.01.anticipate')\", 5), (\"Lemma('anticipated.s.01.anticipated')\", 3), (\"Lemma('anticipate.v.06.anticipate')\", 1), (\"Lemma('anticipate.v.05.anticipate')\", 1)])\n",
      "collecting tokens for  relatives\n",
      "indices:    {27425, 36509}\n",
      "dict_items([])\n",
      "collecting tokens for  ministry\n",
      "indices:    {4797}\n",
      "dict_items([])\n",
      "collecting tokens for  carla\n",
      "indices:    {22252}\n",
      "dict_items([])\n",
      "collecting tokens for  apprentice\n",
      "indices:    {31712, 7617, 13287, 243, 13304, 13241, 13242, 13307}\n",
      "dict_items([(\"Lemma('apprentice.n.01.apprentice')\", 7)])\n",
      "collecting tokens for  solidarity\n",
      "indices:    {25760, 32962, 32964, 32965, 16420, 4712, 15283, 12244, 4789, 25623, 20632, 25754, 32956}\n",
      "dict_items([(\"Lemma('solidarity.n.01.solidarity')\", 5)])\n",
      "collecting tokens for  bloc\n",
      "indices:    {22851, 27127, 20553, 23914, 20273, 14994, 25623, 20569, 23863}\n",
      "dict_items([(\"Lemma('bloc.n.01.bloc')\", 1)])\n",
      "collecting tokens for  theme\n",
      "indices:    {27015, 26378, 24208, 24209, 2706, 22164, 13973, 32662, 13850, 20635, 8348, 23581, 20895, 36129, 13988, 14630, 19502, 31922, 31923, 13637, 16454, 14671, 14681, 20833, 26853, 2668, 32626, 887, 14079}\n",
      "dict_items([(\"Lemma('theme.n.02.theme')\", 5), (\"Lemma('subject.n.01.theme')\", 9)])\n",
      "collecting tokens for  psychologists\n",
      "indices:    {11974, 31272, 2184, 12010, 12011, 27850, 11983, 14327, 12059}\n",
      "dict_items([(\"Lemma('psychologist.n.01.psychologist')\", 7)])\n",
      "collecting tokens for  wives\n",
      "indices:    {26572}\n",
      "dict_items([])\n",
      "collecting tokens for  browning\n",
      "indices:    {29128}\n",
      "dict_items([])\n",
      "collecting tokens for  automatic\n",
      "indices:    {33538, 903, 23309, 10260, 10262, 5789, 5162, 21168, 25782, 29120, 16452, 21700, 13003, 28750, 21209, 15579, 15580, 21724, 15581, 34025, 23797, 11767}\n",
      "dict_items([(\"Lemma('automatic.a.01.automatic')\", 6), (\"Lemma('automatic.s.02.automatic')\", 4)])\n",
      "collecting tokens for  susan\n",
      "indices:    {31027}\n",
      "dict_items([])\n",
      "collecting tokens for  judged\n",
      "indices:    {28608, 21568, 30568, 2988, 15727, 34193, 31545, 28570, 28572, 28573}\n",
      "dict_items([(\"Lemma('evaluate.v.02.judge')\", 3), (\"Lemma('judge.v.01.judge')\", 5), (\"Lemma('estimate.v.01.judge')\", 1), (\"Lemma('pronounce.v.02.judge')\", 1)])\n",
      "collecting tokens for  individually\n",
      "indices:    {12228, 28581, 2409, 27898, 31690, 34349, 31982, 16399, 2320, 15675, 7443, 28570, 16091, 27996, 24445}\n",
      "dict_items([(\"Lemma('individually.r.01.individually')\", 7)])\n",
      "collecting tokens for  translate\n",
      "indices:    {11136, 1508, 24622, 11697, 1330, 29302, 24663, 23574, 31163, 19774}\n",
      "dict_items([(\"Lemma('translate.v.01.translate')\", 3), (\"Lemma('translate.v.02.translate')\", 3), (\"Lemma('understand.v.03.translate')\", 3), (\"Lemma('translate.v.04.translate')\", 1)])\n",
      "collecting tokens for  transport\n",
      "indices:    {26048, 27233, 30530, 32130, 32183, 32135, 14826, 9943, 14827, 29711, 5431, 26042}\n",
      "dict_items([(\"Lemma('conveyance.n.03.transport')\", 2), (\"Lemma('transport.n.02.transport')\", 1), (\"Lemma('transport.v.01.transport')\", 1), (\"Lemma('transportation.n.05.transport')\", 1)])\n",
      "collecting tokens for  adults\n",
      "indices:    {23552, 31009, 3684, 3656, 33018, 30033, 3674, 30430}\n",
      "dict_items([(\"Lemma('adult.n.02.adult')\", 3)])\n",
      "collecting tokens for  expansion\n",
      "indices:    {5507, 21893, 21899, 8849, 2730, 11700, 23476, 28347, 32448, 2753, 26819, 20687, 26836, 22997, 20833, 23531, 497, 32371, 11893, 11382}\n",
      "dict_items([(\"Lemma('expansion.n.01.expansion')\", 8)])\n",
      "collecting tokens for  inevitably\n",
      "indices:    {23904, 2247, 5422, 27545, 26747}\n",
      "dict_items([(\"Lemma('inescapably.r.01.inevitably')\", 1), (\"Lemma('inevitably.r.01.inevitably')\", 1)])\n",
      "collecting tokens for  weaker\n",
      "indices:    {8512, 16000, 26216, 17749, 23094, 12953, 12954, 2399}\n",
      "dict_items([(\"Lemma('weak.a.01.weak')\", 2), (\"Lemma('unaccented.s.02.weak')\", 1), (\"Lemma('watery.s.04.weak')\", 1)])\n",
      "collecting tokens for  teams\n",
      "indices:    {29920, 18503, 651, 33068, 30257, 13169, 23095}\n",
      "dict_items([(\"Lemma('team.n.01.team')\", 2), (\"Lemma('team.n.02.team')\", 1)])\n",
      "collecting tokens for  feeding\n",
      "indices:    {11618, 25315, 11753, 11529, 4267, 25323, 11755, 11754, 32848, 4272, 32858, 11515}\n",
      "dict_items([(\"Lemma('feeding.n.02.feeding')\", 4), (\"Lemma('feed.v.02.feed')\", 1), (\"Lemma('eating.n.01.feeding')\", 3), (\"Lemma('feed.v.01.feed')\", 1)])\n",
      "collecting tokens for  expensive\n",
      "indices:    {29460, 36246, 2459, 37031, 32296, 11692, 32301, 30137, 22459, 11844, 28486, 3147, 974, 19675, 12125, 31072, 3170, 17124, 19559, 12140, 32880, 11764, 29430, 15737, 30847}\n",
      "dict_items([(\"Lemma('expensive.a.01.expensive')\", 13)])\n",
      "collecting tokens for  collar\n",
      "indices:    {35744, 1374, 9473, 707, 6501, 36274, 30614, 18134, 13371, 18525, 25694}\n",
      "dict_items([(\"Lemma('collar.n.01.collar')\", 4), (\"Lemma('collar.v.01.collar')\", 1)])\n",
      "collecting tokens for  grace\n",
      "indices:    {28224, 35986, 22900}\n",
      "dict_items([])\n",
      "collecting tokens for  zone\n",
      "indices:    {24218, 20612}\n",
      "dict_items([])\n",
      "collecting tokens for  tentative\n",
      "indices:    {24449, 3752, 4621, 34399, 20243, 4980, 17211, 15422, 9791}\n",
      "dict_items([(\"Lemma('probationary.s.01.tentative')\", 6)])\n",
      "collecting tokens for  commitments\n",
      "indices:    {32194, 7331, 15428, 31594, 22666, 20619, 4621, 22608, 32180, 27577, 32190}\n",
      "dict_items([(\"Lemma('commitment.n.03.commitment')\", 1), (\"Lemma('commitment.n.02.commitment')\", 2)])\n",
      "collecting tokens for  stubborn\n",
      "indices:    {19232, 1316, 12389, 27276, 26862, 9170, 25369, 16569, 34939}\n",
      "dict_items([(\"Lemma('stubborn.a.01.stubborn')\", 5)])\n",
      "collecting tokens for  whisky\n",
      "indices:    {7688, 7689, 9110, 12702, 12703, 23712, 36899, 5929, 9019, 9022, 9029, 9035, 9038, 17747, 9045, 8920, 8923, 9054, 7145, 12525, 7154}\n",
      "dict_items([(\"Lemma('whiskey.n.01.whisky')\", 19)])\n",
      "collecting tokens for  indicator\n",
      "indices:    {32890, 3911, 3885, 3886, 4786, 18772, 11418, 30556}\n",
      "dict_items([(\"Lemma('indicator.n.03.indicator')\", 2), (\"Lemma('indicator.n.02.indicator')\", 1), (\"Lemma('index.n.02.indicator')\", 3)])\n",
      "collecting tokens for  350\n",
      "indices:    {20773, 29128, 18772, 11541, 11540, 12505, 5532, 24734}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([])\n",
      "collecting tokens for  sees\n",
      "indices:    {4357, 20999, 37145, 19481, 31004, 14372, 1450, 4289, 13637, 1487, 32082, 13529, 27104, 2146, 26724, 5356, 4333, 13425, 13810, 30836, 25464, 14584, 28027, 24189}\n",
      "dict_items([(\"Lemma('see.v.01.see')\", 5), (\"Lemma('understand.v.02.see')\", 9), (\"Lemma('visualize.v.01.see')\", 4), (\"Lemma('see.v.05.see')\", 3), (\"Lemma('witness.v.02.see')\", 2), (\"Lemma('see.v.10.see')\", 1)])\n",
      "collecting tokens for  tears\n",
      "indices:    {12641, 19397, 35142, 27270, 33707, 17006, 13934, 7983, 32852, 27320, 6047}\n",
      "dict_items([(\"Lemma('crying.n.01.tears')\", 3), (\"Lemma('tear.n.01.tear')\", 3)])\n",
      "collecting tokens for  opposition\n",
      "indices:    {23297, 900, 24205, 24207, 25744, 14608, 23960, 20378, 20379, 13980, 23965, 10523, 5281, 12321, 32034, 20516, 2468, 20515, 20521, 25771, 5332, 6107, 5340, 5344, 3810, 99, 32100, 28132, 23653, 32233, 24172, 31724, 12655, 20220, 23933}\n",
      "dict_items([(\"Lemma('confrontation.n.04.opposition')\", 3), (\"Lemma('resistance.n.01.opposition')\", 4), (\"Lemma('opposition.n.02.opposition')\", 4), (\"Lemma('opposition.n.05.opposition')\", 1), (\"Lemma('opposition.n.04.opposition')\", 1)])\n",
      "collecting tokens for  angelo\n",
      "indices:    {16515}\n",
      "dict_items([(\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  fred\n",
      "indices:    {23323}\n",
      "dict_items([])\n",
      "collecting tokens for  weary\n",
      "indices:    {17858, 31782, 8584, 35208, 20649, 10003, 9397, 24790, 33435, 26621}\n",
      "dict_items([(\"Lemma('aweary.s.01.weary')\", 4)])\n",
      "collecting tokens for  summers\n",
      "indices:    {26945, 8878, 14509, 18334}\n",
      "dict_items([(\"Lemma('summer.n.01.summer')\", 2), (\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  thoughtfully\n",
      "indices:    {19296, 18340, 16484, 19368, 11305, 35978, 35950, 33428, 35636, 7575}\n",
      "dict_items([(\"Lemma('thoughtfully.r.01.thoughtfully')\", 3), (\"Lemma('thoughtfully.r.02.thoughtfully')\", 3)])\n",
      "collecting tokens for  affects\n",
      "indices:    {7042, 27170, 25891, 32258, 1862, 4645, 1544, 14633, 1482, 5419, 16367, 22005, 32216, 4604, 14589}\n",
      "dict_items([(\"Lemma('affect.v.01.affect')\", 9), (\"Lemma('affect.v.02.affect')\", 1), (\"Lemma('involve.v.01.affect')\", 2), (\"Lemma('feign.v.01.affect')\", 2)])\n",
      "collecting tokens for  hopeless\n",
      "indices:    {25891, 2125, 20081, 23794, 27830, 9590, 31452}\n",
      "dict_items([(\"Lemma('hopeless.a.01.hopeless')\", 3)])\n",
      "collecting tokens for  halfback\n",
      "indices:    {23164, 332, 301, 348}\n",
      "dict_items([(\"Lemma('halfback.n.01.halfback')\", 3)])\n",
      "collecting tokens for  stages\n",
      "indices:    {29827, 32132, 11529, 15884, 33167, 28048, 4625, 4253, 33184, 5025, 12964, 307, 24885, 32864, 31585, 2528, 32869, 33130, 33131, 32879, 240, 241, 34678, 11519}\n",
      "dict_items([(\"Lemma('degree.n.02.stage')\", 3), (\"Lemma('phase.n.01.stage')\", 8)])\n",
      "collecting tokens for  translation\n",
      "indices:    {27105, 36744, 24745, 11371, 15884, 4537, 4529, 11294, 11481, 15933, 24734, 5407}\n",
      "dict_items([(\"Lemma('translation.n.02.translation')\", 2), (\"Lemma('transformation.n.05.translation')\", 2), (\"Lemma('translation.n.01.translation')\", 4)])\n",
      "collecting tokens for  determination\n",
      "indices:    {2821, 28040, 15242, 32395, 15884, 32271, 19112, 25392, 25523, 20282, 3391, 28103, 840, 12764, 14815, 27109, 22631, 32365, 15346, 32635, 22655}\n",
      "dict_items([(\"Lemma('determination.n.01.determination')\", 6), (\"Lemma('decision.n.02.determination')\", 1), (\"Lemma('determination.n.02.determination')\", 2)])\n",
      "collecting tokens for  equivalents\n",
      "indices:    {15953, 26315, 2133, 15959}\n",
      "dict_items([(\"Lemma('equivalent.n.01.equivalent')\", 3)])\n",
      "collecting tokens for  holden\n",
      "indices:    {17045}\n",
      "dict_items([(\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  enthusiastic\n",
      "indices:    {23524, 11271, 1032, 41, 14713, 4748, 31665, 36632, 11891, 11193, 9653, 30839, 26424, 28697, 23130, 25979, 25663}\n",
      "dict_items([(\"Lemma('enthusiastic.a.01.enthusiastic')\", 7)])\n",
      "collecting tokens for  pulmonary\n",
      "indices:    {3848, 3849, 3853, 3855, 3767, 3768, 4024, 3770, 3772, 3773, 3779, 3781, 3783, 3790, 3792, 3795, 3801, 3816, 3820, 3824, 3826, 3829, 3830, 3836, 3838, 3839}\n",
      "dict_items([(\"Lemma('pneumonic.a.02.pulmonary')\", 5)])\n",
      "collecting tokens for  trust\n",
      "indices:    {21890, 26550}\n",
      "dict_items([])\n",
      "collecting tokens for  1947\n",
      "indices:    {21223, 28336, 27761, 15218, 32633, 28696, 14905, 22013}\n",
      "dict_items([])\n",
      "collecting tokens for  purchases\n",
      "indices:    {32357}\n",
      "dict_items([])\n",
      "collecting tokens for  favorably\n",
      "indices:    {5313, 32293, 28522, 32171, 32302, 15218, 15702, 32892}\n",
      "dict_items([(\"Lemma('favorably.r.01.favorably')\", 3)])\n",
      "collecting tokens for  thru\n",
      "indices:    {961, 25058, 20929, 21289, 939, 20907, 940, 951, 20152, 23836}\n",
      "dict_items([])\n",
      "collecting tokens for  complexity\n",
      "indices:    {16102, 23975, 4966, 21289, 10860, 1804, 16113, 1778, 26963, 11706, 15484}\n",
      "dict_items([(\"Lemma('complexity.n.01.complexity')\", 8)])\n",
      "collecting tokens for  mouths\n",
      "indices:    {23490, 34695, 10511, 35601, 29491, 16695, 7704, 36025}\n",
      "dict_items([(\"Lemma('mouth.n.05.mouth')\", 1), (\"Lemma('mouth.n.01.mouth')\", 2)])\n",
      "collecting tokens for  luxury\n",
      "indices:    {21025, 5954, 1323, 2060, 12563, 725, 24118, 30901, 32149, 27194, 30844, 19166}\n",
      "dict_items([(\"Lemma('luxury.n.01.luxury')\", 4), (\"Lemma('lavishness.n.01.luxury')\", 1)])\n",
      "collecting tokens for  appealing\n",
      "indices:    {11648, 23267, 27043, 22278, 36486, 1167, 30002, 26773, 1749, 1176, 29114, 33791}\n",
      "dict_items([(\"Lemma('appealing.a.01.appealing')\", 3), (\"Lemma('sympathetic.a.04.appealing')\", 1)])\n",
      "collecting tokens for  appealed\n",
      "indices:    {23265, 23267, 31875, 31815, 37097, 21323, 31758, 23257, 14271}\n",
      "dict_items([(\"Lemma('appeal.v.01.appeal')\", 2), (\"Lemma('appeal.v.02.appeal')\", 1), (\"Lemma('attract.v.02.appeal')\", 1)])\n",
      "collecting tokens for  binding\n",
      "indices:    {3575, 9514, 14827, 3577, 23694, 22894, 3568, 29905, 3572, 3191, 3961, 3962, 4733, 3583}\n",
      "dict_items([(\"Lemma('binding.n.01.binding')\", 4), (\"Lemma('bind.v.03.bind')\", 1), (\"Lemma('binding.s.01.binding')\", 1), (\"Lemma('binding.n.02.binding')\", 1), (\"Lemma('adhere.v.06.bind')\", 5)])\n",
      "collecting tokens for  kitti\n",
      "indices:    {16862}\n",
      "dict_items([(\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  abel\n",
      "indices:    {8820}\n",
      "dict_items([(\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  enjoyment\n",
      "indices:    {11200, 11330, 23747, 27012, 23940, 24037, 25991, 14662, 1100, 1808, 12921, 11863, 26233, 30395, 11257, 18270}\n",
      "dict_items([(\"Lemma('enjoyment.n.02.enjoyment')\", 2), (\"Lemma('enjoyment.n.01.enjoyment')\", 6), (\"Lemma('use.n.07.enjoyment')\", 1)])\n",
      "collecting tokens for  badly\n",
      "indices:    {16865, 6948, 12453, 31014, 22632, 21961, 23628, 1389, 9933, 16206, 10451, 35636, 31478, 35862, 5917, 12254}\n",
      "dict_items([(\"Lemma('ill.r.01.badly')\", 3), (\"Lemma('badly.r.01.badly')\", 6)])\n",
      "collecting tokens for  polaris\n",
      "indices:    {21287}\n",
      "dict_items([])\n",
      "collecting tokens for  fighters\n",
      "indices:    {25857, 22410, 12940, 5116}\n",
      "dict_items([(\"Lemma('champion.n.02.fighter')\", 1), (\"Lemma('fighter.n.02.fighter')\", 1)])\n",
      "collecting tokens for  bases\n",
      "indices:    {27554, 29380, 32393, 15372, 31931, 31341, 12940, 368, 19953, 22995, 32565, 374, 437, 21817, 31323, 667, 22267}\n",
      "dict_items([(\"Lemma('establish.v.08.base')\", 3), (\"Lemma('base.n.03.base')\", 3), (\"Lemma('base.n.01.base')\", 1)])\n",
      "collecting tokens for  atlas\n",
      "indices:    {32706}\n",
      "dict_items([])\n",
      "collecting tokens for  conjunction\n",
      "indices:    {33088, 14689, 33089, 5384, 1580, 32478, 26798, 16432, 3923, 14812, 1534, 23583}\n",
      "dict_items([(\"Lemma('concurrence.n.04.conjunction')\", 3), (\"Lemma('junction.n.02.conjunction')\", 1)])\n",
      "collecting tokens for  civilized\n",
      "indices:    {31495, 25354, 30283, 6060, 25361, 16405, 16406, 30743, 27836}\n",
      "dict_items([(\"Lemma('civilized.a.01.civilized')\", 3)])\n",
      "collecting tokens for  projection\n",
      "indices:    {4641, 3268, 2404, 1158, 13385, 2410, 4302, 30743}\n",
      "dict_items([(\"Lemma('projection.n.02.projection')\", 3), (\"Lemma('projection.n.01.projection')\", 3), (\"Lemma('project.n.02.projection')\", 1)])\n",
      "collecting tokens for  fifteen\n",
      "indices:    {29221, 5157, 26347, 25774, 846, 7822, 8306, 23027, 18717}\n",
      "dict_items([(\"Lemma('fifteen.s.01.fifteen')\", 4), (\"Lemma('fifteen.n.01.fifteen')\", 1)])\n",
      "collecting tokens for  forty\n",
      "indices:    {8744, 3909, 5053}\n",
      "dict_items([(\"Lemma('forty.s.01.forty')\", 3)])\n",
      "collecting tokens for  maggie\n",
      "indices:    {36074}\n",
      "dict_items([])\n",
      "collecting tokens for  snap\n",
      "indices:    {35426, 25573, 19484, 27927, 36089, 12535, 36092, 9661}\n",
      "dict_items([(\"Lemma('snap.v.10.snap')\", 1), (\"Lemma('catch.n.09.snap')\", 1), (\"Lemma('snap.v.07.snap')\", 1), (\"Lemma('snap.v.05.snap')\", 1), (\"Lemma('tear.v.01.snap')\", 1), (\"Lemma('snap.v.01.snap')\", 2)])\n",
      "collecting tokens for  eugenia\n",
      "indices:    {36097}\n",
      "dict_items([])\n",
      "collecting tokens for  possibilities\n",
      "indices:    {32896, 11911, 17800, 12173, 2453, 30882, 3237, 12087, 4538, 16058, 17212, 27837, 16317, 33210, 2880, 13249, 33220, 1354, 33226, 11345, 736, 17763, 11750, 11752, 16107, 33260, 33262, 16110}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('possibility.n.01.possibility')\", 9), (\"Lemma('hypothesis.n.02.possibility')\", 4), (\"Lemma('possibility.n.02.possibility')\", 5), (\"Lemma('possibility.n.04.possibility')\", 2)])\n",
      "collecting tokens for  translated\n",
      "indices:    {24769, 12325, 15879, 4525, 19758, 21806, 10097, 28081, 10103, 4538, 36509, 5407}\n",
      "dict_items([(\"Lemma('translate.v.01.translate')\", 5), (\"Lemma('translate.v.02.translate')\", 3), (\"Lemma('translate.v.05.translate')\", 2), (\"Lemma('understand.v.03.translate')\", 1), (\"Lemma('translate.v.04.translate')\", 1)])\n",
      "collecting tokens for  ties\n",
      "indices:    {2500, 2424, 16420, 23079, 9576, 2514, 27986, 11479, 37015, 31768, 31226, 15102}\n",
      "dict_items([(\"Lemma('affiliation.n.01.tie')\", 4), (\"Lemma('link.n.02.tie')\", 1), (\"Lemma('tie.n.04.tie')\", 1)])\n",
      "collecting tokens for  retention\n",
      "indices:    {16227, 5546, 4047, 5524, 3412, 5590, 16183, 31032, 4057, 5495}\n",
      "dict_items([(\"Lemma('retention.n.01.retention')\", 8), (\"Lemma('memory.n.03.retention')\", 1)])\n",
      "collecting tokens for  climbed\n",
      "indices:    {10499, 36997, 34184, 17547, 9231, 17560, 9380, 10532, 29353, 29226, 18348, 33849, 5824, 17486, 18255, 18127, 21711, 35791, 34127, 6487, 36730, 18663, 7016, 6376, 34290, 22006, 35961, 18682}\n",
      "dict_items([(\"Lemma('climb.v.01.climb')\", 21), (\"Lemma('wax.v.02.climb')\", 1), (\"Lemma('climb.v.02.climb')\", 2)])\n",
      "collecting tokens for  starts\n",
      "indices:    {11140, 20997, 5404, 3615, 20514, 34090, 25264, 26555, 31291, 1094, 24009, 26828, 333, 1997, 29903, 591, 599, 21976, 21978, 17115, 28384, 3694, 21235, 11642, 2685}\n",
      "dict_items([(\"Lemma('start.v.06.start')\", 1), (\"Lemma('get_down.v.07.start')\", 10), (\"Lemma('start.n.01.start')\", 2), (\"Lemma('begin.v.02.start')\", 2), (\"Lemma('start.n.03.start')\", 2), (\"Lemma('originate.v.02.start')\", 1), (\"Lemma('begin.v.03.start')\", 1)])\n",
      "collecting tokens for  tomb\n",
      "indices:    {31674, 9858, 19557, 36422, 871, 31589, 22554, 29308, 29373, 31518}\n",
      "dict_items([(\"Lemma('grave.n.02.tomb')\", 3)])\n",
      "collecting tokens for  overnight\n",
      "indices:    {30501, 33350, 28712, 30062, 30513, 2419, 17114, 34271}\n",
      "dict_items([(\"Lemma('nightlong.s.01.overnight')\", 1), (\"Lemma('overnight.r.01.overnight')\", 1)])\n",
      "collecting tokens for  foolish\n",
      "indices:    {15782, 22758, 33799, 7785, 34796, 13581, 8241, 35323, 19385, 5115}\n",
      "dict_items([(\"Lemma('foolish.a.01.foolish')\", 6)])\n",
      "collecting tokens for  mexicans\n",
      "indices:    {5047}\n",
      "dict_items([(\"Lemma('mexican.n.01.Mexican')\", 1)])\n",
      "collecting tokens for  mess\n",
      "indices:    {13441, 23233, 13442, 35682, 13432, 13446, 5766, 33294, 13426, 12850, 13461, 20021, 13528, 13433, 13438, 23742, 5918, 35039}\n",
      "dict_items([(\"Lemma('botch.v.01.mess_up')\", 1), (\"Lemma('mess.n.01.mess')\", 11), (\"Lemma('mess.n.04.mess')\", 1), (\"Lemma('mess.n.05.mess')\", 1)])\n",
      "collecting tokens for  destructive\n",
      "indices:    {25506, 1156, 12709, 13446, 12712, 25161, 26095, 2705, 3415, 27931}\n",
      "dict_items([(\"Lemma('destructive.a.01.destructive')\", 6)])\n",
      "collecting tokens for  formerly\n",
      "indices:    {8770, 20039, 1928, 21130, 20714, 29034, 20878, 2639, 22261, 34838, 26583}\n",
      "dict_items([(\"Lemma('once.r.03.formerly')\", 4)])\n",
      "collecting tokens for  pile\n",
      "indices:    {36992, 31489, 8290, 1379, 11462, 19146, 26699, 1642, 20111, 22159, 17871, 20086, 7448, 11451, 9148}\n",
      "dict_items([(\"Lemma('pile.n.01.pile')\", 5), (\"Lemma('pile.n.03.pile')\", 2), (\"Lemma('stack.v.02.pile')\", 1)])\n",
      "collecting tokens for  cabin\n",
      "indices:    {23670}\n",
      "dict_items([])\n",
      "collecting tokens for  construct\n",
      "indices:    {4490, 11610, 29629}\n",
      "dict_items([(\"Lemma('manufacture.v.01.construct')\", 1), (\"Lemma('construct.v.03.construct')\", 1), (\"Lemma('construct.v.01.construct')\", 1)])\n",
      "collecting tokens for  dancer\n",
      "indices:    {22400, 774, 776, 26233, 31921, 31922, 31925, 31926, 9663, 31938, 25667, 31941, 25669, 14538, 25674, 31947, 31957, 25688, 2028, 31862, 31863, 31864, 31865, 31867, 380, 31869, 31870}\n",
      "dict_items([(\"Lemma('dancer.n.01.dancer')\", 4)])\n",
      "collecting tokens for  wildly\n",
      "indices:    {18560, 23265, 34098, 30386, 35541, 18905}\n",
      "dict_items([(\"Lemma('wildly.r.01.wildly')\", 2)])\n",
      "collecting tokens for  physically\n",
      "indices:    {1952, 25025, 12226, 2402, 25024, 2437, 1103, 31154, 31735, 30809, 218, 316}\n",
      "dict_items([(\"Lemma('physically.r.01.physically')\", 7)])\n",
      "collecting tokens for  movie\n",
      "indices:    {21505, 10882, 2438, 2333, 27042, 28708, 11044, 11047, 9644, 9645, 10669, 25776, 20930, 21446, 19527, 23119, 22355, 10712, 33370, 20956, 10718, 2142, 2402, 2417, 2418, 30203}\n",
      "dict_items([(\"Lemma('movie.n.01.movie')\", 10)])\n",
      "collecting tokens for  projected\n",
      "indices:    {2402, 35427, 2409, 26442, 32713, 2062, 26809, 11292, 26718}\n",
      "dict_items([(\"Lemma('project.v.04.project')\", 2), (\"Lemma('stick_out.v.01.project')\", 1), (\"Lemma('project.v.03.project')\", 1), (\"Lemma('project.v.01.project')\", 1), (\"Lemma('project.v.05.project')\", 1)])\n",
      "collecting tokens for  remembers\n",
      "indices:    {1217, 2402, 26979, 24806, 13545, 14511, 14543, 25692}\n",
      "dict_items([(\"Lemma('remember.v.02.remember')\", 1), (\"Lemma('remember.v.01.remember')\", 5), (\"Lemma('remember.v.03.remember')\", 2)])\n",
      "collecting tokens for  terminate\n",
      "indices:    {996, 20647, 28522, 15980, 14038, 27159, 15261, 14750}\n",
      "dict_items([(\"Lemma('end.v.01.terminate')\", 2), (\"Lemma('end.v.02.terminate')\", 5)])\n",
      "collecting tokens for  hoped\n",
      "indices:    {35840, 30337, 31618, 20362, 25739, 23692, 20239, 9113, 17566, 25522, 36275, 7858, 36149, 19766, 18870, 23354, 14524, 18110, 36287, 18370, 14531, 10436, 24392, 8521, 22603, 31694, 23248, 21460, 27105, 25956, 25957, 17640, 34026, 23293, 19070}\n",
      "dict_items([(\"Lemma('hope.v.01.hope')\", 14), (\"Lemma('hope.v.02.hope')\", 12), (\"Lemma('hope.v.03.hope')\", 6)])\n",
      "collecting tokens for  pie\n",
      "indices:    {31360, 31361, 31362, 31366, 5608, 29230, 29232, 30227, 11067}\n",
      "dict_items([])\n",
      "collecting tokens for  tonal\n",
      "indices:    {16112, 16097}\n",
      "dict_items([(\"Lemma('tonic.a.02.tonal')\", 2)])\n",
      "collecting tokens for  morphophonemics\n",
      "indices:    {16101, 16102, 16109, 16112, 16117, 16118}\n",
      "dict_items([(\"Lemma('morphophonemics.n.01.morphophonemics')\", 6)])\n",
      "collecting tokens for  adc\n",
      "indices:    {174}\n",
      "dict_items([(\"Lemma('group.n.01.group')\", 1)])\n",
      "collecting tokens for  dentist\n",
      "indices:    {30976, 30977, 31075, 36132, 31046, 30984, 16877, 31061, 37013, 31031, 31066, 31067, 31007}\n",
      "dict_items([(\"Lemma('dentist.n.01.dentist')\", 1)])\n",
      "collecting tokens for  pays\n",
      "indices:    {30083, 2787, 8164, 26566, 11817, 14859, 13968, 32117, 30264, 23035, 22748, 20541}\n",
      "dict_items([(\"Lemma('pay.v.05.pay')\", 1), (\"Lemma('pay.v.01.pay')\", 7), (\"Lemma('pay.v.07.pay')\", 3), (\"Lemma('pay_up.v.01.pay')\", 1)])\n",
      "collecting tokens for  farming\n",
      "indices:    {18209, 12070, 12102, 12103, 12141, 12142, 12143, 12112, 12465, 12113, 12180, 12181, 18298}\n",
      "dict_items([(\"Lemma('farming.n.01.farming')\", 11), (\"Lemma('farm.v.01.farm')\", 2)])\n",
      "collecting tokens for  helpful\n",
      "indices:    {37120, 32261, 30731, 33173, 27414, 25237, 11804, 1825, 1830, 2730, 14650, 17341, 27589, 4295, 15436, 724, 14680, 24922, 23643, 859, 28380, 31199, 10093, 2030, 5879}\n",
      "dict_items([(\"Lemma('helpful.a.01.helpful')\", 9)])\n",
      "collecting tokens for  chronic\n",
      "indices:    {16288, 16269, 3470, 2289, 724, 15860, 16309, 4028, 3805}\n",
      "dict_items([(\"Lemma('chronic.a.01.chronic')\", 9)])\n",
      "collecting tokens for  handicapped\n",
      "indices:    {25024, 15012}\n",
      "dict_items([(\"Lemma('disabled.s.01.handicapped')\", 1)])\n",
      "collecting tokens for  shattered\n",
      "indices:    {35616, 17576, 24201, 30510, 13425, 2421, 30550, 35418, 18939, 5855}\n",
      "dict_items([(\"Lemma('shatter.v.01.shatter')\", 5)])\n",
      "collecting tokens for  potters\n",
      "indices:    {5024, 5027, 4965, 5031, 5034, 5012, 31509, 4983}\n",
      "dict_items([(\"Lemma('potter.n.01.potter')\", 7)])\n",
      "collecting tokens for  inherited\n",
      "indices:    {674, 5027, 37093, 34255, 28080, 22608, 8694, 5213}\n",
      "dict_items([(\"Lemma('inherit.v.01.inherit')\", 8)])\n",
      "collecting tokens for  focused\n",
      "indices:    {4809, 32874, 17739, 36010, 20078, 20627, 1588, 33882}\n",
      "dict_items([(\"Lemma('concentrate.v.02.focus')\", 2)])\n",
      "collecting tokens for  maintaining\n",
      "indices:    {4616, 32660, 15009, 36002, 13993, 1709, 23617, 32706, 32963, 27715, 24017, 13151, 25190, 32998, 27752, 3315, 33012, 885, 11766, 21237, 15483, 27772}\n",
      "dict_items([(\"Lemma('keep.v.01.maintain')\", 10), (\"Lemma('conserve.v.02.maintain')\", 8), (\"Lemma('sustain.v.04.maintain')\", 3), (\"Lemma('wield.v.01.maintain')\", 1)])\n",
      "collecting tokens for  divine\n",
      "indices:    {25475, 13637, 28144, 28146, 32021, 28249, 25500}\n",
      "dict_items([(\"Lemma('divine.s.01.divine')\", 1)])\n",
      "collecting tokens for  journal\n",
      "indices:    {32486}\n",
      "dict_items([])\n",
      "collecting tokens for  bulletin\n",
      "indices:    {30492, 32751}\n",
      "dict_items([])\n",
      "collecting tokens for  producing\n",
      "indices:    {12928, 34694, 14727, 25739, 30734, 32399, 2328, 31002, 12200, 11306, 23211, 2875, 11212, 16334, 4435, 16598, 13660, 11499, 11500, 28654, 3438, 32754, 32117, 4475}\n",
      "dict_items([(\"Lemma('produce.v.03.produce')\", 2), (\"Lemma('produce.v.02.produce')\", 13), (\"Lemma('produce.v.01.produce')\", 8), (\"Lemma('grow.v.07.produce')\", 1)])\n",
      "collecting tokens for  pension\n",
      "indices:    {22051, 22054, 30599, 22055, 11832, 21492, 11830, 24}\n",
      "dict_items([(\"Lemma('pension.n.01.pension')\", 3)])\n",
      "collecting tokens for  sorts\n",
      "indices:    {13250, 26084, 4582, 30632, 2377, 31148, 2575, 29267, 22839}\n",
      "dict_items([(\"Lemma('kind.n.01.sort')\", 4)])\n",
      "collecting tokens for  continuing\n",
      "indices:    {27818, 33162, 25905, 32375, 2203, 15838}\n",
      "dict_items([(\"Lemma('continue.v.01.continue')\", 3), (\"Lemma('continue.v.03.continue')\", 1), (\"Lemma('continue.v.02.continue')\", 1), (\"Lemma('continuing.s.01.continuing')\", 1)])\n",
      "collecting tokens for  usage\n",
      "indices:    {1474, 15938, 15942, 31240, 1224, 25354, 3147, 15920, 15927, 15930}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('use.n.01.usage')\", 8)])\n",
      "collecting tokens for  tactual\n",
      "indices:    {4930, 4907, 4910, 4948, 4919, 4922, 4924}\n",
      "dict_items([(\"Lemma('haptic.a.01.tactual')\", 6)])\n",
      "collecting tokens for  fundamentally\n",
      "indices:    {31970, 32258, 4249, 2469, 27304, 2346, 16441, 20154}\n",
      "dict_items([(\"Lemma('basically.r.01.fundamentally')\", 4)])\n",
      "collecting tokens for  instituted\n",
      "indices:    {9632, 764, 31719, 33033, 23215, 33007, 33009, 25363, 32563, 14746, 32444}\n",
      "dict_items([(\"Lemma('establish.v.02.institute')\", 7), (\"Lemma('institute.v.02.institute')\", 4)])\n",
      "collecting tokens for  alter\n",
      "indices:    {4256, 21955, 9156, 2147, 27081, 14745, 32174, 25363, 13715, 25365, 31893, 31385, 4253}\n",
      "dict_items([(\"Lemma('change.v.01.alter')\", 12), (\"Lemma('alter.v.03.alter')\", 1)])\n",
      "collecting tokens for  rotary\n",
      "indices:    {1289, 20059, 32331}\n",
      "dict_items([(\"Lemma('rotary.a.01.rotary')\", 1), (\"Lemma('group.n.01.group')\", 1)])\n",
      "collecting tokens for  mice\n",
      "indices:    {4390, 4424, 4430, 4433, 10840, 9148, 12509}\n",
      "dict_items([(\"Lemma('mouse.n.01.mouse')\", 7)])\n",
      "collecting tokens for  pam\n",
      "indices:    {24396}\n",
      "dict_items([])\n",
      "collecting tokens for  1920\n",
      "indices:    {27969, 27974, 21549, 24686, 14097, 12306, 14995, 14388, 1045, 32310, 26419, 20600, 23097, 20475, 26781, 21561}\n",
      "dict_items([])\n",
      "collecting tokens for  atom\n",
      "indices:    {3077, 27912, 3084, 27916, 27917, 27918, 27919, 14113, 3235, 27939, 34726, 21288, 3112, 3242, 25263, 27952, 27953, 27954, 27951, 27956, 27957, 27958, 25271, 27959, 27962, 27969, 27970, 27976, 26826, 26829, 27982, 26832, 26833}\n",
      "dict_items([(\"Lemma('atom.n.01.atom')\", 4)])\n",
      "collecting tokens for  1944\n",
      "indices:    {4000, 30306, 3749, 4201, 14481, 21716, 31638, 26198, 20442, 23678}\n",
      "dict_items([])\n",
      "collecting tokens for  san\n",
      "indices:    {35028}\n",
      "dict_items([])\n",
      "collecting tokens for  francisco\n",
      "indices:    {22995}\n",
      "dict_items([])\n",
      "collecting tokens for  debut\n",
      "indices:    {20896, 25986, 1066, 1067, 31819, 13806, 26716, 336, 26002, 31638, 1052, 20893, 20447}\n",
      "dict_items([(\"Lemma('introduction.n.01.debut')\", 5)])\n",
      "collecting tokens for  memorable\n",
      "indices:    {11264, 17925, 25645, 32207, 26514, 13812, 14485, 31638, 761, 922}\n",
      "dict_items([(\"Lemma('memorable.s.01.memorable')\", 6)])\n",
      "collecting tokens for  sweeping\n",
      "indices:    {21889, 26274, 18659, 31290, 37116}\n",
      "dict_items([(\"Lemma('sweeping.s.01.sweeping')\", 1)])\n",
      "collecting tokens for  ceiling\n",
      "indices:    {34049, 19459, 19721, 18705, 35734, 18718, 15010, 15011, 17576, 18739, 9786, 9148, 2007, 29405, 34274, 9192, 34288, 24688, 30576, 30195}\n",
      "dict_items([(\"Lemma('ceiling.n.01.ceiling')\", 7), (\"Lemma('ceiling.n.03.ceiling')\", 2), (\"Lemma('ceiling.n.02.ceiling')\", 3)])\n",
      "collecting tokens for  casual\n",
      "indices:    {33754, 19459, 708, 5222, 18950, 14554, 34827, 31532, 24784, 32560, 26739, 8373, 29334, 698, 26426, 12731}\n",
      "dict_items([(\"Lemma('casual.s.01.casual')\", 3), (\"Lemma('casual.s.03.casual')\", 2), (\"Lemma('casual.s.02.casual')\", 2)])\n",
      "collecting tokens for  mare\n",
      "indices:    {35153, 2838}\n",
      "dict_items([])\n",
      "collecting tokens for  chickens\n",
      "indices:    {12101, 12486, 12073, 16687, 9399}\n",
      "dict_items([(\"Lemma('chicken.n.01.chicken')\", 2), (\"Lemma('chicken.n.02.chicken')\", 3)])\n",
      "collecting tokens for  cats\n",
      "indices:    {37056, 37055, 32065, 3811, 17253, 32042, 36272, 16597, 17238, 17237, 17240, 17244, 36413, 23103}\n",
      "dict_items([(\"Lemma('cat.n.01.cat')\", 5)])\n",
      "collecting tokens for  babies\n",
      "indices:    {20837, 34668, 32845, 36748, 36272, 32848, 30999, 22360, 27194, 32859, 12188, 36287}\n",
      "dict_items([(\"Lemma('baby.n.01.baby')\", 1)])\n",
      "collecting tokens for  interlocking\n",
      "indices:    {29831, 13675, 28748, 28718, 28754, 28732, 5407}\n",
      "dict_items([(\"Lemma('interlacing.s.01.interlocking')\", 2), (\"Lemma('interlock.v.01.interlock')\", 1)])\n",
      "collecting tokens for  workshop\n",
      "indices:    {22336, 20066, 20132, 20021, 9146, 22492, 22335}\n",
      "dict_items([(\"Lemma('workshop.n.01.workshop')\", 4)])\n",
      "collecting tokens for  scheme\n",
      "indices:    {15873, 17922, 33031, 24585, 2569, 15881, 22670, 15374, 9872, 31893, 3507, 28728, 28731, 14917, 28752, 26194, 1495, 14055, 22778, 24574, 26239}\n",
      "dict_items([(\"Lemma('scheme.n.01.scheme')\", 10)])\n",
      "collecting tokens for  65\n",
      "indices:    {3232, 15490, 11778, 22942, 5511, 23304, 135, 23276, 21932, 20172, 28752, 23633, 22353, 4019, 21620, 20185, 21851, 3294}\n",
      "dict_items([])\n",
      "collecting tokens for  testimony\n",
      "indices:    {32641, 23169, 15367, 32649, 3723, 32658, 12441, 32665, 11289, 12193, 13346, 32675, 32690, 18228, 14391, 12220, 30405, 1733, 4937, 20707, 20849, 32631}\n",
      "dict_items([(\"Lemma('testimony.n.02.testimony')\", 4), (\"Lemma('testimony.n.01.testimony')\", 5), (\"Lemma('testimony.n.03.testimony')\", 2)])\n",
      "collecting tokens for  panting\n",
      "indices:    {6049, 24806, 6952, 6190, 8603, 34111}\n",
      "dict_items([(\"Lemma('pant.v.01.pant')\", 5)])\n",
      "collecting tokens for  drag\n",
      "indices:    {14950, 35463, 3305, 17679, 34033, 24178, 19511, 36950, 29175}\n",
      "dict_items([(\"Lemma('haul.v.01.drag')\", 3), (\"Lemma('drag.v.01.drag')\", 3), (\"Lemma('procrastinate.v.01.drag_one's_feet')\", 1), (\"Lemma('drag.n.01.drag')\", 1)])\n",
      "collecting tokens for  author\n",
      "indices:    {1125, 14126, 27089, 2130, 22548, 5215, 12287}\n",
      "dict_items([(\"Lemma('writer.n.01.author')\", 4), (\"Lemma('generator.n.03.author')\", 1)])\n",
      "collecting tokens for  frequencies\n",
      "indices:    {16192, 31297, 2179, 1097, 14794, 14795, 11404, 14796, 14799, 2159, 11410, 2164, 2165, 2166, 16189}\n",
      "dict_items([(\"Lemma('frequency.n.01.frequency')\", 5), (\"Lemma('frequency.n.02.frequency')\", 6)])\n",
      "collecting tokens for  tire\n",
      "indices:    {28945, 19467}\n",
      "dict_items([(\"Lemma('tire.n.01.tire')\", 1)])\n",
      "collecting tokens for  spray\n",
      "indices:    {29786, 36326, 30409, 1707, 12140, 34156, 29774, 8815, 29776, 35252, 1626, 35615}\n",
      "dict_items([(\"Lemma('spray.n.01.spray')\", 2), (\"Lemma('atomizer.n.01.spray')\", 1), (\"Lemma('spray.v.01.spray')\", 1), (\"Lemma('spray.v.02.spray')\", 1)])\n",
      "collecting tokens for  clothing\n",
      "indices:    {23105, 5476, 35815, 7468, 34796, 23215, 2223, 35473, 30516, 21078, 2682, 15643, 700, 15197, 19551}\n",
      "dict_items([(\"Lemma('clothing.n.01.clothing')\", 8)])\n",
      "collecting tokens for  dawn\n",
      "indices:    {35248, 9995}\n",
      "dict_items([])\n",
      "collecting tokens for  lying\n",
      "indices:    {5843, 36788, 21213, 7223}\n",
      "dict_items([(\"Lemma('lie.v.02.lie')\", 4)])\n",
      "collecting tokens for  doaty\n",
      "indices:    {36296}\n",
      "dict_items([])\n",
      "collecting tokens for  newest\n",
      "indices:    {21826, 25161, 33426, 469, 17337, 25274, 765}\n",
      "dict_items([(\"Lemma('new.a.01.new')\", 3)])\n",
      "collecting tokens for  plastic\n",
      "indices:    {29409, 29858, 30052, 29996, 12793, 31021, 28658, 29790, 29436, 8766}\n",
      "dict_items([(\"Lemma('fictile.s.03.plastic')\", 1), (\"Lemma('plastic.n.01.plastic')\", 1)])\n",
      "collecting tokens for  shelf\n",
      "indices:    {26242, 1701, 20137, 34986, 34289, 35668, 14389, 35674, 17535}\n",
      "dict_items([(\"Lemma('shelf.n.01.shelf')\", 4)])\n",
      "collecting tokens for  resolved\n",
      "indices:    {5352, 12929, 27290}\n",
      "dict_items([(\"Lemma('decide.v.02.resolve')\", 2), (\"Lemma('conclude.v.03.resolve')\", 1)])\n",
      "collecting tokens for  workable\n",
      "indices:    {229, 14917, 31717, 23246, 24143, 23865, 11675, 19358}\n",
      "dict_items([(\"Lemma('feasible.s.01.workable')\", 4)])\n",
      "collecting tokens for  curse\n",
      "indices:    {8677, 31848, 33613, 2711, 25370, 28284, 9566, 28287}\n",
      "dict_items([(\"Lemma('execration.n.02.curse')\", 1), (\"Lemma('curse.v.01.curse')\", 1), (\"Lemma('curse.v.02.curse')\", 2), (\"Lemma('hex.n.01.curse')\", 1)])\n",
      "collecting tokens for  formidable\n",
      "indices:    {27745, 24613, 13063, 24040, 5870, 37009, 27733, 25436, 27325}\n",
      "dict_items([(\"Lemma('formidable.s.01.formidable')\", 1)])\n",
      "collecting tokens for  miracle\n",
      "indices:    {952, 935, 10120, 10103}\n",
      "dict_items([(\"Lemma('miracle.n.01.miracle')\", 2), (\"Lemma('miracle.n.02.miracle')\", 1)])\n",
      "collecting tokens for  copies\n",
      "indices:    {8483, 31528, 32745, 32490, 32489, 32488, 15342, 25041, 1812}\n",
      "dict_items([(\"Lemma('transcript.n.02.copy')\", 2), (\"Lemma('copy.n.02.copy')\", 1)])\n",
      "collecting tokens for  tumor\n",
      "indices:    {4192, 32706}\n",
      "dict_items([(\"Lemma('tumor.n.01.tumor')\", 1)])\n",
      "collecting tokens for  grin\n",
      "indices:    {26072, 34088, 18442, 558, 12623, 16980, 24376, 34844, 18238}\n",
      "dict_items([(\"Lemma('smile.n.01.grin')\", 4), (\"Lemma('grin.v.01.grin')\", 1)])\n",
      "collecting tokens for  sox\n",
      "indices:    {392}\n",
      "dict_items([(\"Lemma('group.n.01.group')\", 1)])\n",
      "collecting tokens for  fortunate\n",
      "indices:    {28355, 9157, 1958, 36430, 11470, 5201, 28627, 31508, 30038, 6396, 26269}\n",
      "dict_items([(\"Lemma('fortunate.a.01.fortunate')\", 4), (\"Lemma('fortunate.s.02.fortunate')\", 1)])\n",
      "collecting tokens for  uniforms\n",
      "indices:    {32640, 35842, 19492, 7975, 9576, 903, 9943, 2539, 6023, 21486, 8563, 11763, 25783}\n",
      "dict_items([(\"Lemma('uniform.n.01.uniform')\", 9)])\n",
      "collecting tokens for  allies\n",
      "indices:    {25604, 20233, 5648, 22642, 22586}\n",
      "dict_items([(\"Lemma('ally.n.01.ally')\", 1)])\n",
      "collecting tokens for  persisted\n",
      "indices:    {18017, 30275, 12710, 27526, 28045, 26191, 8472, 35997}\n",
      "dict_items([(\"Lemma('persist.v.03.persist')\", 1), (\"Lemma('persevere.v.01.persist')\", 2), (\"Lemma('prevail.v.03.persist')\", 4)])\n",
      "collecting tokens for  blankets\n",
      "indices:    {35587, 35620, 7590, 2278, 2279, 35085, 24181, 5754}\n",
      "dict_items([(\"Lemma('blanket.v.01.blanket')\", 1), (\"Lemma('blanket.n.01.blanket')\", 4)])\n",
      "collecting tokens for  defeat\n",
      "indices:    {26019, 24839, 26024, 12919, 25227, 24335, 19282, 2516, 27575, 13850, 12956}\n",
      "dict_items([(\"Lemma('defeat.n.01.defeat')\", 4), (\"Lemma('get_the_better_of.v.01.defeat')\", 1), (\"Lemma('frustration.n.01.defeat')\", 1), (\"Lemma('kill.v.02.defeat')\", 1)])\n",
      "collecting tokens for  suspected\n",
      "indices:    {21409, 7970, 1320, 33099, 24811, 9805, 10905, 12502, 19927, 36153, 5983}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('distrust.v.01.suspect')\", 1)])\n",
      "collecting tokens for  insist\n",
      "indices:    {11776, 32133, 1683, 3611, 20257, 27127, 20260, 7076, 15282, 4923, 8385, 11329, 31828, 31066, 20957, 33143, 23906, 14179, 32239, 24436, 30069, 28150, 7671}\n",
      "dict_items([(\"Lemma('insist.v.01.insist')\", 22), (\"Lemma('insist.v.03.insist')\", 1)])\n",
      "collecting tokens for  defending\n",
      "indices:    {25857, 5218, 32101, 19433, 18605, 21278, 336, 22904, 5112, 8030}\n",
      "dict_items([(\"Lemma('defend.v.03.defend')\", 2), (\"Lemma('defend.v.01.defend')\", 4), (\"Lemma('fight.v.02.defend')\", 1), (\"Lemma('defend.v.02.defend')\", 1)])\n",
      "collecting tokens for  72\n",
      "indices:    {22912, 22917, 24837, 22951, 15659, 21463, 1715, 11607, 22904, 1529, 3547, 22877, 14749}\n",
      "dict_items([])\n",
      "collecting tokens for  misfortune\n",
      "indices:    {4674, 2634, 26860, 20047, 22904, 13850, 924, 21341, 19422}\n",
      "dict_items([(\"Lemma('misfortune.n.02.misfortune')\", 3), (\"Lemma('misfortune.n.01.misfortune')\", 3)])\n",
      "collecting tokens for  ah\n",
      "indices:    {18875}\n",
      "dict_items([])\n",
      "collecting tokens for  accurate\n",
      "indices:    {32513, 26120, 28945, 30097, 30617, 31518, 31141, 22951, 29096, 24626, 1205, 7605, 12345, 19520, 23749, 15816, 19800, 11866, 15837, 2795, 32876, 2925, 32124, 25341}\n",
      "dict_items([(\"Lemma('accurate.a.01.accurate')\", 10)])\n",
      "collecting tokens for  label\n",
      "indices:    {23928, 25285, 11685, 22153, 11658, 9069, 26450, 3987, 26325, 23768, 27898, 8860}\n",
      "dict_items([(\"Lemma('label.n.02.label')\", 2), (\"Lemma('label.n.04.label')\", 1), (\"Lemma('label.n.01.label')\", 1), (\"Lemma('label.v.01.label')\", 1), (\"Lemma('label.n.03.label')\", 1)])\n",
      "collecting tokens for  docherty\n",
      "indices:    {17491}\n",
      "dict_items([(\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  features\n",
      "indices:    {5376, 7809, 3842, 3843, 32517, 26120, 32521, 18442, 14605, 25741, 29328, 3856, 13330, 2836, 2582, 22807, 2841, 5274, 1819, 1821, 1822, 1825, 22311, 4648, 34985, 7083, 1836, 22319, 1839, 22448, 1847, 1848, 1849, 1081, 32584, 1866, 1867, 1868, 29133, 10574, 27727, 1226, 3409, 17875, 16083, 16085, 29272, 1884, 16093, 13411, 3812, 28134, 8051, 32757, 2550, 16122, 32765}\n",
      "dict_items([(\"Lemma('feature.n.01.feature')\", 26), (\"Lemma('feature.n.02.feature')\", 7), (\"Lemma('have.v.02.feature')\", 5)])\n",
      "collecting tokens for  twisting\n",
      "indices:    {35203, 23494, 1582, 35635, 18454, 36727, 29560, 12793}\n",
      "dict_items([(\"Lemma('distortion.n.05.twisting')\", 1), (\"Lemma('writhe.v.01.twist')\", 3), (\"Lemma('flex.v.05.twist')\", 1)])\n",
      "collecting tokens for  brains\n",
      "indices:    {8417, 33611, 8197, 16854}\n",
      "dict_items([(\"Lemma('brain.n.02.brain')\", 3)])\n",
      "collecting tokens for  necessities\n",
      "indices:    {7010, 2056, 5258, 2091, 2060, 2062, 12272, 2042, 15643}\n",
      "dict_items([(\"Lemma('necessity.n.02.necessity')\", 6), (\"Lemma('necessity.n.01.necessity')\", 3)])\n",
      "collecting tokens for  hut\n",
      "indices:    {7139, 5868, 7154, 6706, 7155, 7134, 6678, 6739, 7161, 7230}\n",
      "dict_items([(\"Lemma('hut.n.01.hut')\", 9), (\"Lemma('hovel.n.01.hut')\", 1)])\n",
      "collecting tokens for  stevenson\n",
      "indices:    {24145}\n",
      "dict_items([])\n",
      "collecting tokens for  responsibilities\n",
      "indices:    {23554, 32845, 32495, 30033, 28083, 24147, 15413, 17365, 7994, 27900}\n",
      "dict_items([(\"Lemma('duty.n.01.responsibility')\", 3)])\n",
      "collecting tokens for  incidents\n",
      "indices:    {24416, 24417, 12259, 23691, 14286, 27886, 15827, 21688, 19610}\n",
      "dict_items([(\"Lemma('incident.n.01.incident')\", 4)])\n",
      "collecting tokens for  borrowed\n",
      "indices:    {28327, 16455, 32553, 2764, 14286, 7794, 22995, 2392, 33147, 14717, 23551}\n",
      "dict_items([(\"Lemma('borrow.v.01.borrow')\", 8), (\"Lemma('adopt.v.02.borrow')\", 3)])\n",
      "collecting tokens for  edwin\n",
      "indices:    {12599}\n",
      "dict_items([])\n",
      "collecting tokens for  beverly\n",
      "indices:    {21927}\n",
      "dict_items([])\n",
      "collecting tokens for  cubic\n",
      "indices:    {28928, 15140, 28937, 21773, 28910, 28911, 28912, 28909, 21724, 28926, 28927}\n",
      "dict_items([])\n",
      "collecting tokens for  centimeters\n",
      "indices:    {28928, 28910, 28911, 28926, 28927}\n",
      "dict_items([])\n",
      "collecting tokens for  soup\n",
      "indices:    {30495}\n",
      "dict_items([])\n",
      "collecting tokens for  discharges\n",
      "indices:    {4225, 4237, 4207, 4278, 4247, 4217, 4220}\n",
      "dict_items([(\"Lemma('discharge.n.01.discharge')\", 7)])\n",
      "collecting tokens for  era\n",
      "indices:    {18305, 12034, 4994, 22279, 1163, 5003, 5007, 23187, 5013, 1050, 12702, 27294, 10783, 30629, 1193, 11691, 31660, 11184, 31176, 26187, 26189, 11859, 33370, 26333, 31206, 12412, 26493}\n",
      "dict_items([(\"Lemma('era.n.01.era')\", 14)])\n",
      "collecting tokens for  stretch\n",
      "indices:    {31744, 1548, 17038, 16654, 1555, 1556, 36132, 33713, 9665, 2114, 204, 29146, 25436, 26211, 10215, 19175, 240, 9715, 29301}\n",
      "dict_items([(\"Lemma('stretch.n.04.stretch')\", 1), (\"Lemma('reach.n.03.stretch')\", 3), (\"Lemma('stretch.n.01.stretch')\", 1), (\"Lemma('stretch.v.04.stretch')\", 1), (\"Lemma('stretch.n.03.stretch')\", 2), (\"Lemma('stretch.v.02.stretch')\", 2), (\"Lemma('stretch.v.01.stretch')\", 1), (\"Lemma('elongate.v.01.stretch')\", 1), (\"Lemma('stretch.n.05.stretch')\", 1)])\n",
      "collecting tokens for  carriers\n",
      "indices:    {1696, 14978, 13764, 36454, 14030, 347, 14900, 22836, 14907}\n",
      "dict_items([(\"Lemma('carrier.n.01.carrier')\", 3), (\"Lemma('carrier.n.02.carrier')\", 2), (\"Lemma('carrier.n.05.carrier')\", 1)])\n",
      "collecting tokens for  nineteen\n",
      "indices:    {32417, 31691, 9196, 23089, 36082, 32407, 3736, 12281, 13178, 32287}\n",
      "dict_items([(\"Lemma('nineteen.s.01.nineteen')\", 3), (\"Lemma('nineteen.n.01.nineteen')\", 1)])\n",
      "collecting tokens for  eliminating\n",
      "indices:    {12225, 4195, 132, 24907, 9837, 9937, 34679, 20735}\n",
      "dict_items([(\"Lemma('extinguish.v.04.eliminate')\", 5), (\"Lemma('obviate.v.01.eliminate')\", 2), (\"Lemma('eliminate.v.03.eliminate')\", 1)])\n",
      "collecting tokens for  merit\n",
      "indices:    {21665, 11146, 25805, 33134, 20403, 6771, 15221, 25341}\n",
      "dict_items([(\"Lemma('deservingness.n.01.merit')\", 2), (\"Lemma('merit.n.01.merit')\", 1)])\n",
      "collecting tokens for  conditioning\n",
      "indices:    {30112, 30115, 30118, 4263, 30088, 16201, 30090, 3499, 30095, 30096, 34683}\n",
      "dict_items([(\"Lemma('conditioning.n.01.conditioning')\", 2)])\n",
      "collecting tokens for  spell\n",
      "indices:    {1280, 23877, 22437, 5575, 31752, 7753, 1258, 22728, 26871, 7289, 30619, 1278}\n",
      "dict_items([(\"Lemma('go.n.01.spell')\", 1), (\"Lemma('enchantment.n.02.spell')\", 3), (\"Lemma('spell.v.01.spell')\", 1)])\n",
      "collecting tokens for  aerator\n",
      "indices:    {5537, 5538, 5571, 5539, 5573, 5575, 5518, 5519, 5521, 5553, 5492}\n",
      "dict_items([(\"Lemma('aerator.n.01.aerator')\", 11)])\n",
      "collecting tokens for  platform\n",
      "indices:    {17441, 20451, 5575, 29367, 14346, 12207, 47, 26706, 5333, 983}\n",
      "dict_items([(\"Lemma('platform.n.01.platform')\", 4), (\"Lemma('platform.n.02.platform')\", 2)])\n",
      "collecting tokens for  conrad\n",
      "indices:    {16800}\n",
      "dict_items([(\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  bankers\n",
      "indices:    {21890}\n",
      "dict_items([])\n",
      "collecting tokens for  questioned\n",
      "indices:    {21344, 20160, 10625, 1252, 25510, 23206, 21544, 36199, 21994, 7303, 21769, 17327, 13999, 10516, 20693, 21689, 12027, 23167}\n",
      "dict_items([(\"Lemma('question.v.01.question')\", 4), (\"Lemma('interrogate.v.02.question')\", 9), (\"Lemma('interview.v.01.question')\", 3), (\"Lemma('wonder.v.02.question')\", 1), (\"Lemma('question.v.03.question')\", 1)])\n",
      "collecting tokens for  controversial\n",
      "indices:    {25284, 25285, 20390, 23367, 32298, 22443, 11056, 23861, 23862}\n",
      "dict_items([(\"Lemma('controversial.a.01.controversial')\", 1)])\n",
      "collecting tokens for  liver\n",
      "indices:    {4194, 27234, 30466, 11174, 11527, 27244, 11536, 4080, 16592, 2195, 4125, 4082, 11387, 4157, 11519}\n",
      "dict_items([(\"Lemma('liver.n.01.liver')\", 10), (\"Lemma('liver.n.02.liver')\", 1)])\n",
      "collecting tokens for  python\n",
      "indices:    {3685, 3692, 3725, 3695, 3696, 3697, 3698, 3702, 3706}\n",
      "dict_items([(\"Lemma('python.n.01.python')\", 3)])\n",
      "collecting tokens for  laughing\n",
      "indices:    {9313, 10945, 36164, 7877, 17992, 30221, 9165, 9008, 11060, 9717, 8119, 7228, 36095}\n",
      "dict_items([(\"Lemma('laugh.v.01.laugh')\", 12)])\n",
      "collecting tokens for  habits\n",
      "indices:    {7618, 12327, 30153, 27883, 26540, 27180, 12241, 14556, 30998, 2552, 3708, 13949}\n",
      "dict_items([(\"Lemma('habit.n.01.habit')\", 4), (\"Lemma('habit.n.02.habit')\", 3)])\n",
      "collecting tokens for  separately\n",
      "indices:    {23552, 23681, 33028, 22568, 3788, 11436, 1588, 33078, 3708, 34335}\n",
      "dict_items([(\"Lemma('individually.r.01.separately')\", 4)])\n",
      "collecting tokens for  ingenious\n",
      "indices:    {29831, 33031, 30215, 36397, 11054, 18575, 11186, 12756}\n",
      "dict_items([])\n",
      "collecting tokens for  grosse\n",
      "indices:    {33599}\n",
      "dict_items([])\n",
      "collecting tokens for  patronage\n",
      "indices:    {6146, 20634, 12361, 14383, 22864, 29140, 20632, 29209, 29146, 25662}\n",
      "dict_items([(\"Lemma('backing.n.01.patronage')\", 3)])\n",
      "collecting tokens for  treasury\n",
      "indices:    {14887}\n",
      "dict_items([])\n",
      "collecting tokens for  authorized\n",
      "indices:    {22023, 14858, 14863, 14741, 14871, 24219, 14748, 20384, 14754, 24738, 14886, 14887, 22056, 14761, 14890, 14766, 14895, 14898, 23606, 2744, 12225, 23259, 32755, 1395}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('authorize.v.01.authorize')\", 22), (\"Lemma('authorized.a.01.authorized')\", 1)])\n",
      "collecting tokens for  pursuant\n",
      "indices:    {32643, 14854, 14855, 14888, 14889, 14890, 14891, 14856, 14861, 14892, 14895, 14771, 14869, 14871, 14873, 14875, 14748}\n",
      "dict_items([(\"Lemma('pursuant.s.01.pursuant')\", 16)])\n",
      "collecting tokens for  subsection\n",
      "indices:    {14884, 14889, 14858, 14890, 14894, 14895, 14869, 14742, 14873}\n",
      "dict_items([(\"Lemma('subsection.n.01.subsection')\", 9)])\n",
      "collecting tokens for  completing\n",
      "indices:    {354}\n",
      "dict_items([(\"Lemma('complete.v.04.complete')\", 1)])\n",
      "collecting tokens for  tends\n",
      "indices:    {26755, 31882, 11659, 23710, 26277, 1321, 13615, 14258, 14645, 23998, 14150, 31175, 24521, 4689, 26321, 13651, 13654, 726, 23651, 26341, 4723, 13177, 5373}\n",
      "dict_items([(\"Lemma('tend.v.01.tend')\", 21)])\n",
      "collecting tokens for  magnum\n",
      "indices:    {29072}\n",
      "dict_items([])\n",
      "collecting tokens for  alternatives\n",
      "indices:    {1351, 23755, 1357, 27791, 1360, 25807, 29839, 14929, 28532, 32625, 5398, 30263, 20664, 23737}\n",
      "dict_items([(\"Lemma('option.n.02.alternative')\", 5)])\n",
      "collecting tokens for  demographic\n",
      "indices:    {33056, 33027, 33091, 33060, 33059, 33061, 33009, 33013}\n",
      "dict_items([])\n",
      "collecting tokens for  diane\n",
      "indices:    {30945}\n",
      "dict_items([])\n",
      "collecting tokens for  recommendations\n",
      "indices:    {129, 16133, 20328, 170, 14764, 24143, 24847, 176, 18, 32497, 20561, 2040, 29242}\n",
      "dict_items([(\"Lemma('recommendation.n.01.recommendation')\", 7)])\n",
      "collecting tokens for  indignation\n",
      "indices:    {11100, 13759, 16362, 1323, 8019, 22747, 33372, 14623}\n",
      "dict_items([(\"Lemma('indignation.n.01.indignation')\", 6)])\n",
      "collecting tokens for  designs\n",
      "indices:    {22073, 21299, 22284, 30686}\n",
      "dict_items([])\n",
      "collecting tokens for  abstraction\n",
      "indices:    {3235, 13671, 13672, 13673, 3242, 16423, 3244, 13640}\n",
      "dict_items([(\"Lemma('abstraction.n.03.abstraction')\", 2), (\"Lemma('abstraction.n.02.abstraction')\", 3), (\"Lemma('abstraction.n.01.abstraction')\", 3)])\n",
      "collecting tokens for  shrugged\n",
      "indices:    {20544, 36865, 17378, 17699, 8070, 19982, 5711, 19824, 18326, 34687}\n",
      "dict_items([(\"Lemma('shrug.v.01.shrug')\", 9), (\"Lemma('shrug_off.v.01.shrug_off')\", 1)])\n",
      "collecting tokens for  marry\n",
      "indices:    {36865, 36867, 36196, 19461, 13160, 13226, 10236, 16911, 19482, 16892}\n",
      "dict_items([(\"Lemma('marry.v.01.marry')\", 9), (\"Lemma('marry.v.02.marry')\", 1)])\n",
      "collecting tokens for  year-old\n",
      "indices:    {21632, 23045, 21510, 21385, 23312, 27025, 24596, 22040, 28952, 24730, 22180, 23334, 31019, 21547, 23355, 21694, 21568, 21700, 28999, 26708, 21333, 21207, 21475, 33131, 33133, 23150, 22649}\n",
      "dict_items([])\n",
      "collecting tokens for  utility\n",
      "indices:    {21632, 29920, 21442, 131, 14627, 1892, 32517, 21637, 32521, 32969, 23023, 12175, 28659, 27934}\n",
      "dict_items([(\"Lemma('utility.n.01.utility')\", 2), (\"Lemma('utility.n.02.utility')\", 1)])\n",
      "collecting tokens for  pole\n",
      "indices:    {12353, 21635}\n",
      "dict_items([])\n",
      "collecting tokens for  stevens\n",
      "indices:    {27048}\n",
      "dict_items([])\n",
      "collecting tokens for  politician\n",
      "indices:    {10717, 11044, 12676, 23771, 10715, 10620, 26687, 10623}\n",
      "dict_items([(\"Lemma('politician.n.01.politician')\", 5), (\"Lemma('politician.n.02.politician')\", 1)])\n",
      "collecting tokens for  voluntary\n",
      "indices:    {30784, 25026, 33219, 14756, 22409, 20221, 33234, 20531, 20530, 20532, 33238, 32925, 23709, 32894, 33215}\n",
      "dict_items([(\"Lemma('voluntary.a.01.voluntary')\", 1)])\n",
      "collecting tokens for  accustomed\n",
      "indices:    {1597, 24547, 26341, 1798, 12009, 9390, 35197, 16663, 35934, 24573, 14430}\n",
      "dict_items([(\"Lemma('accustomed.a.01.accustomed')\", 5), (\"Lemma('habituate.v.02.accustom')\", 2)])\n",
      "collecting tokens for  react\n",
      "indices:    {3200, 1798, 17383, 14217, 33226, 4140, 13652, 20277, 37046, 33239, 33211, 12955, 670}\n",
      "dict_items([(\"Lemma('react.v.02.react')\", 1), (\"Lemma('react.v.01.react')\", 10), (\"Lemma('react.v.03.react')\", 2)])\n",
      "collecting tokens for  attain\n",
      "indices:    {24768, 1793, 9596, 32966, 2311, 3691, 28016, 32956, 3701, 9176, 32123, 15708}\n",
      "dict_items([(\"Lemma('achieve.v.01.attain')\", 9), (\"Lemma('reach.v.02.attain')\", 3)])\n",
      "collecting tokens for  kirov\n",
      "indices:    {22395}\n",
      "dict_items([])\n",
      "collecting tokens for  quo\n",
      "indices:    {25767, 13951, 33108, 32917, 26197, 23287, 13981, 14207}\n",
      "dict_items([])\n",
      "collecting tokens for  flexibility\n",
      "indices:    {1959, 1960, 1961, 1930, 23915, 32877, 16399, 15473, 1587, 33141, 2008, 2010}\n",
      "dict_items([(\"Lemma('flexibility.n.01.flexibility')\", 7), (\"Lemma('flexibility.n.02.flexibility')\", 2)])\n",
      "collecting tokens for  polished\n",
      "indices:    {29881, 22470, 29576, 30377, 26185, 18541, 6478, 10510, 14553, 11164}\n",
      "dict_items([(\"Lemma('polish.v.01.polish')\", 4), (\"Lemma('polished.a.01.polished')\", 2), (\"Lemma('get_through.v.01.polish_off')\", 1)])\n",
      "collecting tokens for  lane\n",
      "indices:    {31825}\n",
      "dict_items([])\n",
      "collecting tokens for  utopian\n",
      "indices:    {5240}\n",
      "dict_items([(\"Lemma('utopian.a.01.utopian')\", 1)])\n",
      "collecting tokens for  imaginary\n",
      "indices:    {27425, 26594, 8802, 5852, 9661}\n",
      "dict_items([(\"Lemma('fanciful.s.02.imaginary')\", 3)])\n",
      "collecting tokens for  utopia\n",
      "indices:    {5216}\n",
      "dict_items([(\"Lemma('utopia.n.01.Utopia')\", 1)])\n",
      "collecting tokens for  conceived\n",
      "indices:    {16453, 32966, 12231, 12455, 2568, 6060, 1357, 12332, 32174, 35983, 11223, 2164, 26133, 5239, 11224, 11293}\n",
      "dict_items([(\"Lemma('gestate.v.01.conceive')\", 14)])\n",
      "collecting tokens for  spot\n",
      "indices:    {35970, 30244, 6341, 22309, 24039, 18855, 32876, 12814, 35932, 26415, 30257, 12884, 11295, 2940, 12765, 23742, 6687}\n",
      "dict_items([(\"Lemma('descry.v.01.spot')\", 1), (\"Lemma('topographic_point.n.01.spot')\", 5), (\"Lemma('position.n.06.spot')\", 1), (\"Lemma('spot.n.05.spot')\", 1)])\n",
      "collecting tokens for  mining\n",
      "indices:    {5960, 23081, 36140, 14766, 20756, 3647}\n",
      "dict_items([(\"Lemma('mining.n.01.mining')\", 2)])\n",
      "collecting tokens for  defensive\n",
      "indices:    {15840, 355, 3493, 32873, 30316, 301, 25584, 3409, 466, 339, 341, 219, 639}\n",
      "dict_items([(\"Lemma('defensive.a.01.defensive')\", 9), (\"Lemma('defensive.s.02.defensive')\", 1)])\n",
      "collecting tokens for  timed\n",
      "indices:    {32873, 33865, 18090, 32877, 23090, 3861, 310, 37143, 251}\n",
      "dict_items([(\"Lemma('clock.v.01.time')\", 3), (\"Lemma('time.v.02.time')\", 3), (\"Lemma('time.v.03.time')\", 1), (\"Lemma('timed.s.01.timed')\", 1)])\n",
      "collecting tokens for  disappointment\n",
      "indices:    {8450, 14437, 23430, 19339, 20239, 25459, 8917, 35671, 36249, 34940, 26847}\n",
      "dict_items([(\"Lemma('disappointment.n.01.disappointment')\", 4)])\n",
      "collecting tokens for  notably\n",
      "indices:    {15843, 23652, 1732, 2184, 23240, 32202, 25645, 25678, 26998, 1466, 12988}\n",
      "dict_items([(\"Lemma('notably.r.01.notably')\", 5)])\n",
      "collecting tokens for  stephen\n",
      "indices:    {22502}\n",
      "dict_items([])\n",
      "collecting tokens for  reservations\n",
      "indices:    {22338, 31433, 24431, 23952, 22195, 3445, 22357, 14142}\n",
      "dict_items([(\"Lemma('reservation.n.01.reservation')\", 1), (\"Lemma('mental_reservation.n.01.reservation')\", 1)])\n",
      "collecting tokens for  forgive\n",
      "indices:    {12546, 10155, 24270, 24271, 18993, 24281}\n",
      "dict_items([(\"Lemma('forgive.v.01.forgive')\", 6)])\n",
      "collecting tokens for  alaska\n",
      "indices:    {29239}\n",
      "dict_items([])\n",
      "collecting tokens for  packing\n",
      "indices:    {36546, 29715}\n",
      "dict_items([])\n",
      "collecting tokens for  liked\n",
      "indices:    {12545, 30852, 20102, 12039, 9497, 17825, 26280, 22187, 26541, 10037, 26690, 35779, 9311, 30433, 36833, 13794, 10981, 1125, 23146, 5482, 16875, 30444, 36975, 10480, 27124, 25722, 30846}\n",
      "dict_items([(\"Lemma('like.v.02.like')\", 14), (\"Lemma('wish.v.02.like')\", 5), (\"Lemma('like.v.03.like')\", 8)])\n",
      "collecting tokens for  denominations\n",
      "indices:    {13345, 12324, 27654, 27752, 13388, 12316, 13330, 13332, 13333, 13366, 13334, 27640, 12312, 4700, 13373}\n",
      "dict_items([(\"Lemma('denomination.n.01.denomination')\", 9)])\n",
      "collecting tokens for  operated\n",
      "indices:    {8322, 15494, 6, 31369, 32268, 20, 21413, 28711, 4777, 28717, 30255, 10289, 2759, 15182, 28632, 10592, 31982, 32502, 3447, 508, 32893}\n",
      "dict_items([(\"Lemma('operate.v.03.operate')\", 5), (\"Lemma('operate.v.01.operate')\", 9), (\"Lemma('function.v.01.operate')\", 5)])\n",
      "collecting tokens for  wires\n",
      "indices:    {30506, 31021}\n",
      "dict_items([])\n",
      "collecting tokens for  philosopher\n",
      "indices:    {13440, 13640, 11466, 754, 23191, 19608, 14650, 14715, 23836, 14717}\n",
      "dict_items([(\"Lemma('philosopher.n.01.philosopher')\", 8)])\n",
      "collecting tokens for  meredith\n",
      "indices:    {10788}\n",
      "dict_items([])\n",
      "collecting tokens for  scholars\n",
      "indices:    {24736, 24739, 27555, 14661, 5220, 24744, 27531, 23183, 16404, 16405, 24760, 5275, 24766, 6399}\n",
      "dict_items([(\"Lemma('scholar.n.01.scholar')\", 5), (\"Lemma('learner.n.01.scholar')\", 1)])\n",
      "collecting tokens for  fundamental\n",
      "indices:    {14724, 14086, 14087, 14088, 23686, 32908, 31244, 4750, 32016, 23572, 4246, 27291, 5022, 32165, 11686, 33066, 21942, 13367, 24896, 13635, 25667, 4684, 1501, 4960, 4973, 26102, 1401, 22779}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('cardinal.s.01.fundamental')\", 9), (\"Lemma('fundamental.s.02.fundamental')\", 4)])\n",
      "collecting tokens for  toilet\n",
      "indices:    {35689, 35691, 33516, 19506, 35699, 19508, 19509, 15190, 15189, 29692}\n",
      "dict_items([(\"Lemma('toilet.n.01.toilet')\", 3), (\"Lemma('toilet.n.02.toilet')\", 2)])\n",
      "collecting tokens for  emperor\n",
      "indices:    {23552, 28146}\n",
      "dict_items([])\n",
      "collecting tokens for  literally\n",
      "indices:    {5251, 5411, 14341, 6025, 22284, 28656, 12027, 36509}\n",
      "dict_items([(\"Lemma('literally.r.01.literally')\", 3), (\"Lemma('literally.r.02.literally')\", 2)])\n",
      "collecting tokens for  russ\n",
      "indices:    {18598}\n",
      "dict_items([(\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  prayed\n",
      "indices:    {18816, 7044, 36746, 7731, 18835, 28371, 7002, 24287}\n",
      "dict_items([(\"Lemma('pray.v.01.pray')\", 8)])\n",
      "collecting tokens for  bureau\n",
      "indices:    {15296}\n",
      "dict_items([])\n",
      "collecting tokens for  applicants\n",
      "indices:    {2784, 2051, 15753, 15755, 24045, 15758, 15759, 2095}\n",
      "dict_items([(\"Lemma('applicant.n.01.applicant')\", 7)])\n",
      "collecting tokens for  designers\n",
      "indices:    {28661}\n",
      "dict_items([])\n",
      "collecting tokens for  expects\n",
      "indices:    {2051, 27043, 15399, 20712, 26058, 26698, 27692, 113, 22705, 23606, 20791, 792, 20377, 316, 27134, 11294}\n",
      "dict_items([(\"Lemma('expect.v.03.expect')\", 1), (\"Lemma('expect.v.01.expect')\", 11), (\"Lemma('ask.v.04.expect')\", 4)])\n",
      "collecting tokens for  scarcely\n",
      "indices:    {18848, 14433, 34779, 16552, 26505, 25706, 14220, 2096, 23153, 27636, 12213, 23831, 1944, 16507, 17885}\n",
      "dict_items([(\"Lemma('barely.r.01.scarcely')\", 9)])\n",
      "collecting tokens for  sacred\n",
      "indices:    {7032, 28178, 37138}\n",
      "dict_items([(\"Lemma('sacred.a.01.sacred')\", 1)])\n",
      "collecting tokens for  sights\n",
      "indices:    {29346, 35555, 677, 35564, 35574, 35607, 29240, 1948, 29245, 13655}\n",
      "dict_items([(\"Lemma('sight.n.02.sight')\", 3)])\n",
      "collecting tokens for  rubber\n",
      "indices:    {31070, 19881, 35575, 24695, 29108, 11382, 5431, 4925, 29085, 11807}\n",
      "dict_items([(\"Lemma('rubber.n.01.rubber')\", 4)])\n",
      "collecting tokens for  joke\n",
      "indices:    {34532, 34652, 9257, 33304, 33305, 5212, 1008, 18898, 10835, 17624, 26361, 1019, 36156, 30877, 2654}\n",
      "dict_items([(\"Lemma('joke.n.01.joke')\", 6), (\"Lemma('antic.n.01.joke')\", 1), (\"Lemma('joke.v.01.joke')\", 1), (\"Lemma('jest.n.02.joke')\", 1)])\n",
      "collecting tokens for  roar\n",
      "indices:    {19241, 30506, 18699, 18443, 22960, 18898, 35925}\n",
      "dict_items([(\"Lemma('boom.n.01.roar')\", 3), (\"Lemma('bellow.n.01.roar')\", 1)])\n",
      "collecting tokens for  assigned\n",
      "indices:    {27534, 15890, 32790, 14487, 15894, 15900, 33057, 27555, 15908, 15910, 20530, 32323, 15943, 34764, 15953, 35539, 36439, 16093, 15973, 18666, 11883, 27628, 20718, 11773}\n",
      "dict_items([(\"Lemma('assign.v.02.assign')\", 8), (\"Lemma('delegate.v.02.assign')\", 10), (\"Lemma('impute.v.01.assign')\", 1), (\"Lemma('put.v.04.assign')\", 1), (\"Lemma('assign.v.04.assign')\", 2), (\"Lemma('assigned.a.01.assigned')\", 1)])\n",
      "collecting tokens for  acreage\n",
      "indices:    {1889, 5420}\n",
      "dict_items([(\"Lemma('acreage.n.01.acreage')\", 2)])\n",
      "collecting tokens for  adjoining\n",
      "indices:    {1894, 28839, 1895, 35689, 33514, 21361, 22162, 31002, 12125}\n",
      "dict_items([(\"Lemma('border.v.05.adjoin')\", 1)])\n",
      "collecting tokens for  cease\n",
      "indices:    {15842, 13831, 35723, 3632, 22672, 4819, 1494, 13983}\n",
      "dict_items([(\"Lemma('discontinue.v.01.cease')\", 7)])\n",
      "collecting tokens for  followers\n",
      "indices:    {24768, 27745, 23330, 26179, 25189, 5084, 12876, 19343, 19445, 25749, 19352, 20667, 28284}\n",
      "dict_items([(\"Lemma('follower.n.01.follower')\", 5)])\n",
      "collecting tokens for  spared\n",
      "indices:    {27525, 23594, 6444, 24013, 13071, 32241, 36306, 27507}\n",
      "dict_items([(\"Lemma('spare.v.01.spare')\", 4), (\"Lemma('spare.v.02.spare')\", 3), (\"Lemma('spare.v.03.spare')\", 1)])\n",
      "collecting tokens for  delivered\n",
      "indices:    {11009, 32259, 6276, 2187, 11148, 8084, 25493, 11035, 7466, 12587, 13754, 23106, 23492, 15301, 26188, 22995, 22616, 347, 32489, 22894, 27507, 28531, 29945, 762, 21885}\n",
      "dict_items([(\"Lemma('deliver.v.01.deliver')\", 14), (\"Lemma('deliver.v.02.deliver')\", 4), (\"Lemma('extradite.v.01.deliver')\", 2), (\"Lemma('hand_over.v.01.deliver')\", 2), (\"Lemma('render.v.05.deliver')\", 1), (\"Lemma('rescue.v.01.deliver')\", 1)])\n",
      "collecting tokens for  landed\n",
      "indices:    {9188, 21733, 18215, 6281, 34185, 553, 20748, 12814, 18457, 7485}\n",
      "dict_items([(\"Lemma('land.v.01.land')\", 7), (\"Lemma('bring.v.05.land')\", 1), (\"Lemma('land.v.02.land')\", 1), (\"Lemma('land.v.05.land')\", 1)])\n",
      "collecting tokens for  appeals\n",
      "indices:    {21220, 6045}\n",
      "dict_items([(\"Lemma('entreaty.n.01.appeal')\", 1)])\n",
      "collecting tokens for  ruling\n",
      "indices:    {22020, 14468, 22025, 21641, 21642, 31181, 25037, 28142, 4434, 4631, 22040, 569, 20157, 15262}\n",
      "dict_items([(\"Lemma('opinion.n.05.ruling')\", 2), (\"Lemma('govern.v.03.rule')\", 2), (\"Lemma('regnant.s.01.ruling')\", 1)])\n",
      "collecting tokens for  jenny\n",
      "indices:    {36216}\n",
      "dict_items([])\n",
      "collecting tokens for  indirectly\n",
      "indices:    {2720, 12291, 14022, 27782, 27787, 4753, 3319, 33049, 14714, 15229, 27839}\n",
      "dict_items([(\"Lemma('indirectly.r.01.indirectly')\", 7)])\n",
      "collecting tokens for  newly\n",
      "indices:    {21254, 12426, 3986, 20888, 13217, 42, 3757, 3758, 14767, 31665, 14771, 23859, 32709, 30794, 23513, 32738, 15850, 22254, 10099, 21630}\n",
      "dict_items([(\"Lemma('newly.r.01.newly')\", 10)])\n",
      "collecting tokens for  1963\n",
      "indices:    {15052, 15533, 25359, 15537, 14771, 20180, 20181, 890}\n",
      "dict_items([])\n",
      "collecting tokens for  proclaim\n",
      "indices:    {32640, 5281, 32674, 7046, 9768, 32648, 32688, 32657, 32630, 32664, 6843}\n",
      "dict_items([(\"Lemma('proclaim.v.01.proclaim')\", 8), (\"Lemma('proclaim.v.02.proclaim')\", 3)])\n",
      "collecting tokens for  protest\n",
      "indices:    {6146, 23683, 2373, 23688, 16412, 25327, 17936, 23473, 26962, 7920, 1428, 13205, 2710, 9368, 9243, 10172, 6141}\n",
      "dict_items([(\"Lemma('protest.n.01.protest')\", 6), (\"Lemma('protest.v.02.protest')\", 4), (\"Lemma('protest.n.02.protest')\", 3), (\"Lemma('protest.v.01.protest')\", 1)])\n",
      "collecting tokens for  pentagon\n",
      "indices:    {5948}\n",
      "dict_items([(\"Lemma('pentagon.n.01.Pentagon')\", 1)])\n",
      "collecting tokens for  revealed\n",
      "indices:    {3584, 21376, 2434, 19331, 25604, 35207, 30218, 31882, 4758, 27672, 17432, 1056, 12580, 1060, 1068, 31922, 30393, 4802, 4038, 4040, 18265, 25960, 15849, 2665, 886, 31353, 4092}\n",
      "dict_items([(\"Lemma('uncover.v.01.reveal')\", 15), (\"Lemma('unwrap.v.02.reveal')\", 7)])\n",
      "collecting tokens for  ward\n",
      "indices:    {32483}\n",
      "dict_items([])\n",
      "collecting tokens for  karns\n",
      "indices:    {20163}\n",
      "dict_items([])\n",
      "collecting tokens for  gymnastics\n",
      "indices:    {1920, 1955, 1924, 1925, 1929, 1931, 2028, 1938, 2003, 1919}\n",
      "dict_items([(\"Lemma('gymnastics.n.01.gymnastics')\", 10)])\n",
      "collecting tokens for  margin\n",
      "indices:    {5216, 15521, 2028, 32141, 11792, 14131, 31258, 572}\n",
      "dict_items([(\"Lemma('margin.n.02.margin')\", 2), (\"Lemma('margin.n.01.margin')\", 3)])\n",
      "collecting tokens for  crying\n",
      "indices:    {27267, 35209, 35819, 19467, 31150, 13743, 32848, 31537, 26397}\n",
      "dict_items([(\"Lemma('shout.v.02.cry')\", 4), (\"Lemma('cry.v.02.cry')\", 3), (\"Lemma('cry.v.04.cry')\", 1)])\n",
      "collecting tokens for  larkin\n",
      "indices:    {988}\n",
      "dict_items([(\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  baby\n",
      "indices:    {36068, 36248, 10407, 36408, 36076, 36078, 36112, 27473, 8210, 36085, 14550, 7671, 7672, 8442, 7741}\n",
      "dict_items([(\"Lemma('baby.n.01.baby')\", 6)])\n",
      "collecting tokens for  everyday\n",
      "indices:    {24771, 4710, 37000, 23532, 16750, 16751, 28085, 4951, 16732, 16663}\n",
      "dict_items([(\"Lemma('everyday.s.01.everyday')\", 6)])\n",
      "collecting tokens for  willow\n",
      "indices:    {3646, 5438, 3598}\n",
      "dict_items([(\"Lemma('willow.n.01.willow')\", 1)])\n",
      "collecting tokens for  creek\n",
      "indices:    {5090, 9222, 35591, 29148, 10527}\n",
      "dict_items([(\"Lemma('brook.n.01.creek')\", 3)])\n",
      "collecting tokens for  jumped\n",
      "indices:    {18690, 29063, 19207, 34314, 33676, 27022, 33941, 9367, 33827, 33461, 23352, 6214, 6479, 27475, 27481, 19805, 29025, 12647, 617, 21483, 21873}\n",
      "dict_items([(\"Lemma('jump.v.01.jump')\", 8), (\"Lemma('startle.v.02.jump')\", 5), (\"Lemma('jump.v.03.jump')\", 2), (\"Lemma('jump.v.04.jump')\", 1), (\"Lemma('rise.v.11.jump')\", 1), (\"Lemma('jump.v.06.jump')\", 1)])\n",
      "collecting tokens for  seal\n",
      "indices:    {32641, 3255, 32675, 712, 32649, 23754, 3641, 3247, 32690, 32658, 3252, 32631, 16664, 32665, 16667, 29533, 28023}\n",
      "dict_items([(\"Lemma('seal.v.02.seal')\", 1), (\"Lemma('sealing_wax.n.01.seal')\", 2), (\"Lemma('seal.v.01.seal')\", 2)])\n",
      "collecting tokens for  commissioner\n",
      "indices:    {25, 1191}\n",
      "dict_items([(\"Lemma('commissioner.n.01.commissioner')\", 1)])\n",
      "collecting tokens for  novel\n",
      "indices:    {2184, 11401, 27022, 27025, 4885, 13845, 20505, 8350, 30753, 25637, 31793, 10805, 19519, 1088, 27076, 14405, 26565, 27080, 27082, 11343, 31825, 2391, 24920, 11357, 27106, 9186, 2405, 20729, 2170}\n",
      "dict_items([(\"Lemma('novel.n.01.novel')\", 9), (\"Lemma('fresh.s.04.novel')\", 6)])\n",
      "collecting tokens for  yielded\n",
      "indices:    {4041, 36331, 23886, 26769, 3346, 5557, 27320, 17562, 4093}\n",
      "dict_items([(\"Lemma('give_way.v.03.yield')\", 1), (\"Lemma('yield.v.01.yield')\", 4), (\"Lemma('yield_up.v.01.yield_up')\", 1), (\"Lemma('give.v.09.yield')\", 1), (\"Lemma('render.v.04.yield')\", 2)])\n",
      "collecting tokens for  folly\n",
      "indices:    {36337}\n",
      "dict_items([])\n",
      "collecting tokens for  auditorium\n",
      "indices:    {22336, 1178, 14445, 6309}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('auditorium.n.01.auditorium')\", 2)])\n",
      "collecting tokens for  yankee\n",
      "indices:    {12676}\n",
      "dict_items([])\n",
      "collecting tokens for  sergeant\n",
      "indices:    {12831}\n",
      "dict_items([])\n",
      "collecting tokens for  sweetheart\n",
      "indices:    {25344, 25346, 25347, 9924, 9285, 9286, 1127, 26858, 12539}\n",
      "dict_items([(\"Lemma('sweetheart.n.02.sweetheart')\", 3), (\"Lemma('sweetheart.n.01.sweetheart')\", 2)])\n",
      "collecting tokens for  donald\n",
      "indices:    {20678}\n",
      "dict_items([])\n",
      "collecting tokens for  grabbed\n",
      "indices:    {17473, 18469, 230, 10408, 19049, 202, 6957, 19054, 6926, 16881, 10357, 18487, 8119, 18459}\n",
      "dict_items([(\"Lemma('catch.v.04.grab')\", 14)])\n",
      "collecting tokens for  deaf\n",
      "indices:    {7780, 7687, 106, 107, 109, 111, 28091}\n",
      "dict_items([(\"Lemma('deaf.a.01.deaf')\", 4), (\"Lemma('deaf.n.01.deaf')\", 2)])\n",
      "collecting tokens for  counties\n",
      "indices:    {13, 106, 23605, 20493}\n",
      "dict_items([(\"Lemma('county.n.01.county')\", 2)])\n",
      "collecting tokens for  multiple\n",
      "indices:    {31297, 32833, 3240, 32843, 31184, 2256, 21235, 2645, 9787}\n",
      "dict_items([(\"Lemma('multiple.a.01.multiple')\", 3)])\n",
      "collecting tokens for  lend\n",
      "indices:    {6756, 26117}\n",
      "dict_items([(\"Lemma('lend.v.02.lend')\", 2)])\n",
      "collecting tokens for  short-term\n",
      "indices:    {21922, 21956, 32900, 15623, 32554, 5487, 32623, 21967, 32562, 2771, 2772, 32885, 15005}\n",
      "dict_items([(\"Lemma('short-run.s.01.short-term')\", 5)])\n",
      "collecting tokens for  expedition\n",
      "indices:    {10272, 14946, 10178, 10182, 27015, 11498, 11499, 10191, 34486, 9339, 34652, 35998}\n",
      "dict_items([(\"Lemma('expedition.n.01.expedition')\", 4), (\"Lemma('expedition.n.03.expedition')\", 2), (\"Lemma('expedition.n.02.expedition')\", 2)])\n",
      "collecting tokens for  ours\n",
      "indices:    {27462, 5802, 24970, 12940, 31701}\n",
      "dict_items([])\n",
      "collecting tokens for  wagons\n",
      "indices:    {11617, 11608, 36645, 35463, 7849, 21016, 35467, 35404, 34989, 35469, 35447, 35416}\n",
      "dict_items([(\"Lemma('wagon.n.01.wagon')\", 3)])\n",
      "collecting tokens for  aerated\n",
      "indices:    {5509, 5542, 5510, 5546, 5561, 5494, 5495, 5497}\n",
      "dict_items([(\"Lemma('aerated.s.01.aerated')\", 8)])\n",
      "collecting tokens for  lagoon\n",
      "indices:    {5542, 5511, 5510, 5513, 5546, 5515, 5561, 11070}\n",
      "dict_items([(\"Lemma('lagoon.n.01.lagoon')\", 7)])\n",
      "collecting tokens for  collaboration\n",
      "indices:    {31720, 32904, 31725, 14481, 14486, 26487, 14550, 26265, 14554}\n",
      "dict_items([(\"Lemma('collaboration.n.01.collaboration')\", 4)])\n",
      "collecting tokens for  leader\n",
      "indices:    {22626, 22660, 20485, 23749, 27141, 23976, 31530, 22638, 21555, 26102, 16023, 20220, 32223}\n",
      "dict_items([(\"Lemma('leader.n.01.leader')\", 1)])\n",
      "collecting tokens for  toys\n",
      "indices:    {22410, 29996, 22414}\n",
      "dict_items([])\n",
      "collecting tokens for  pastern\n",
      "indices:    {8697}\n",
      "dict_items([])\n",
      "collecting tokens for  medieval\n",
      "indices:    {5225, 5213, 5215, 36023}\n",
      "dict_items([(\"Lemma('medieval.a.01.medieval')\", 3)])\n",
      "collecting tokens for  fathers\n",
      "indices:    {31699, 12574}\n",
      "dict_items([(\"Lemma('father.n.01.father')\", 1)])\n",
      "collecting tokens for  intended\n",
      "indices:    {15232, 27782, 16264, 27787, 22799, 16143, 31002, 677, 27315, 13881, 32063, 23360, 12229, 2764, 26573, 15949, 11985, 23767, 17762, 1507, 27113, 26349, 1008, 1914, 18043}\n",
      "dict_items([(\"Lemma('intend.v.01.intend')\", 15), (\"Lemma('intend.v.02.intend')\", 3), (\"Lemma('intended.a.01.intended')\", 3), (\"Lemma('mean.v.01.intend')\", 2)])\n",
      "collecting tokens for  salary\n",
      "indices:    {11776, 18314, 15757, 21522, 21781, 21528, 21153, 21158, 21161, 6065, 25801, 25803, 25675, 22732, 463, 23506, 20309, 20310, 5079, 17365, 7010, 37093, 36072, 17388, 15609}\n",
      "dict_items([(\"Lemma('wage.n.01.salary')\", 10)])\n",
      "collecting tokens for  meeker\n",
      "indices:    {17360}\n",
      "dict_items([])\n",
      "collecting tokens for  secant\n",
      "indices:    {32800, 32837, 32843, 32813, 32817, 32818, 32827, 32828, 32829}\n",
      "dict_items([])\n",
      "collecting tokens for  employee\n",
      "indices:    {11788, 11796, 15765, 11798, 11801, 15271, 11818, 11820, 22703, 32314, 11838, 11845, 11724, 11727, 11857, 11732, 11736, 2394, 11742, 15487, 11760, 11761, 11775}\n",
      "dict_items([(\"Lemma('employee.n.01.employee')\", 21)])\n",
      "collecting tokens for  investment\n",
      "indices:    {21890, 32149}\n",
      "dict_items([])\n",
      "collecting tokens for  smiles\n",
      "indices:    {26176, 18848, 5604, 26951, 19079, 34887, 25515, 22605, 5976, 27775}\n",
      "dict_items([(\"Lemma('smile.n.01.smile')\", 3), (\"Lemma('smile.v.01.smile')\", 3)])\n",
      "collecting tokens for  laugh\n",
      "indices:    {26467, 7717, 36382, 9704, 10824, 8138, 7271, 19213, 9166, 9167, 9010, 10901, 8118, 36183, 8181, 28284, 12701, 9182}\n",
      "dict_items([(\"Lemma('laugh.v.01.laugh')\", 4), (\"Lemma('laugh.n.01.laugh')\", 9)])\n",
      "collecting tokens for  hebrew\n",
      "indices:    {14455}\n",
      "dict_items([])\n",
      "collecting tokens for  humorous\n",
      "indices:    {27265, 13798, 2647, 13848, 14413, 14415, 14422, 11222, 9176, 27033}\n",
      "dict_items([(\"Lemma('humorous.a.01.humorous')\", 8)])\n",
      "collecting tokens for  comfort\n",
      "indices:    {27268, 24327, 26888, 24331, 22157, 30097, 27027, 21016, 34586, 2203, 21024, 15138, 28710, 27053, 36025, 25147, 699, 4671, 705, 24001, 26053, 19270, 9800, 2517, 15704, 36323, 16867, 9831, 24938, 7276, 28656, 31088, 22138}\n",
      "dict_items([(\"Lemma('comfort.n.02.comfort')\", 5), (\"Lemma('consolation.n.02.comfort')\", 4), (\"Lemma('comfort.v.01.comfort')\", 2), (\"Lemma('comfort.n.01.comfort')\", 1)])\n",
      "collecting tokens for  storm\n",
      "indices:    {21024, 10593, 26401, 29023, 33769, 6474, 18091, 5545, 21197, 21200, 24979, 25139, 18105, 18106, 19385, 19228, 21021, 30111}\n",
      "dict_items([(\"Lemma('storm.v.02.storm')\", 1), (\"Lemma('storm.n.01.storm')\", 5), (\"Lemma('storm.n.02.storm')\", 1)])\n",
      "collecting tokens for  bother\n",
      "indices:    {33856, 36216, 26469, 17829, 6247, 8360, 9830, 10026, 9007, 36784, 16559, 34738, 5874, 15669, 17942, 13208, 6845, 5919}\n",
      "dict_items([(\"Lemma('trouble_oneself.v.01.bother')\", 10), (\"Lemma('annoy.v.01.bother')\", 5), (\"Lemma('trouble.v.02.bother')\", 3)])\n",
      "collecting tokens for  spots\n",
      "indices:    {30240, 3169, 26368, 23110, 31498, 6251, 26506, 2893, 17646, 14319, 31358, 11060, 24472, 24473, 29274, 14557, 29310}\n",
      "dict_items([(\"Lemma('spot.n.06.spot')\", 1), (\"Lemma('topographic_point.n.01.spot')\", 2), (\"Lemma('smudge.n.02.spot')\", 1), (\"Lemma('spot.n.07.spot')\", 1), (\"Lemma('point.n.14.spot')\", 1)])\n",
      "collecting tokens for  artistic\n",
      "indices:    {14609, 20883, 26901, 2711, 13611, 13617, 13619, 13623, 13624, 13629, 13633, 11203, 13635, 13638, 13639, 11087, 11091, 21077, 13654, 4971, 2030, 2671}\n",
      "dict_items([(\"Lemma('artistic.a.01.artistic')\", 17), (\"Lemma('artistic.s.02.artistic')\", 2)])\n",
      "collecting tokens for  procurement\n",
      "indices:    {32455, 15497, 15499, 15501, 15502, 15503, 15539, 2745, 20316}\n",
      "dict_items([(\"Lemma('procurement.n.01.procurement')\", 7)])\n",
      "collecting tokens for  engines\n",
      "indices:    {30369, 30529, 28939, 23341, 28495, 15536, 28913, 28498, 28499, 28437, 28502, 28506, 28668}\n",
      "dict_items([(\"Lemma('engine.n.01.engine')\", 1)])\n",
      "collecting tokens for  80\n",
      "indices:    {29696, 29313, 4128, 20996, 14788, 3207, 25416, 3560, 28667, 21932, 23021, 21264, 24720, 21876, 3290, 11547, 4127}\n",
      "dict_items([(\"Lemma('eighty.s.01.80')\", 7)])\n",
      "collecting tokens for  conant\n",
      "indices:    {23181}\n",
      "dict_items([])\n",
      "collecting tokens for  blanche\n",
      "indices:    {16862}\n",
      "dict_items([(\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  averaged\n",
      "indices:    {5540, 3755, 5550, 32463, 5552, 5590, 3735, 5592, 3737, 5558, 27163, 32348, 5535}\n",
      "dict_items([(\"Lemma('average.v.01.average')\", 11), (\"Lemma('average.v.02.average')\", 1)])\n",
      "collecting tokens for  ads\n",
      "indices:    {9186, 32461, 32463, 10648, 19610, 25243, 23709, 19038}\n",
      "dict_items([(\"Lemma('ad.n.01.ad')\", 4)])\n",
      "collecting tokens for  edition\n",
      "indices:    {1752, 1808, 28178, 32486}\n",
      "dict_items([(\"Lemma('edition.n.02.edition')\", 1), (\"Lemma('edition.n.01.edition')\", 1)])\n",
      "collecting tokens for  crops\n",
      "indices:    {21699, 34916, 12164, 12166, 12071, 3395, 31785, 21989, 12083, 26747, 21502}\n",
      "dict_items([(\"Lemma('crop.n.01.crop')\", 5)])\n",
      "collecting tokens for  oso\n",
      "indices:    {35619}\n",
      "dict_items([])\n",
      "collecting tokens for  crop\n",
      "indices:    {31780, 21988, 21702, 12167, 12484, 34922, 29047, 29115, 22012, 22462}\n",
      "dict_items([(\"Lemma('crop.n.01.crop')\", 2)])\n",
      "collecting tokens for  dealt\n",
      "indices:    {22617, 10853, 14380, 13709, 850, 14420, 629, 28407, 2361, 15259, 2719}\n",
      "dict_items([(\"Lemma('deal.v.03.deal')\", 2), (\"Lemma('cover.v.05.deal')\", 6), (\"Lemma('distribute.v.01.deal')\", 2)])\n",
      "collecting tokens for  cameras\n",
      "indices:    {21505, 9881, 19035, 1036}\n",
      "dict_items([(\"Lemma('camera.n.01.camera')\", 1), (\"Lemma('television_camera.n.01.camera')\", 2)])\n",
      "collecting tokens for  appreciate\n",
      "indices:    {11911, 16525, 13971, 37146, 23836, 22685, 16419, 37156, 27939, 11818, 10297, 22718, 22085, 17744, 23129, 4966, 1768, 6892, 27637, 29046, 1784, 28543}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('appreciate.v.02.appreciate')\", 10), (\"Lemma('prize.v.01.appreciate')\", 2), (\"Lemma('appreciate.v.01.appreciate')\", 10)])\n",
      "collecting tokens for  families\n",
      "indices:    {4485, 32929, 11953, 25139, 16179, 16180, 25662, 32958, 30016, 15173, 25548, 13783, 16217, 12507, 24796, 5486, 28656, 5111, 21628}\n",
      "dict_items([(\"Lemma('class.n.01.family')\", 4), (\"Lemma('family.n.01.family')\", 4), (\"Lemma('family.n.02.family')\", 2)])\n",
      "collecting tokens for  ragged\n",
      "indices:    {5634, 33829, 35593, 8818, 9587, 17784, 13561, 34430}\n",
      "dict_items([(\"Lemma('ragged.s.01.ragged')\", 3), (\"Lemma('ragged.s.02.ragged')\", 1), (\"Lemma('ragged.s.03.ragged')\", 1)])\n",
      "collecting tokens for  tray\n",
      "indices:    {36992, 8833, 10020, 8837, 29160, 9547, 10027, 9403, 8827, 10033, 29429, 26805, 26843, 9244, 8829}\n",
      "dict_items([(\"Lemma('tray.n.01.tray')\", 10)])\n",
      "collecting tokens for  cooler\n",
      "indices:    {29443, 9227, 27051, 27059, 29429, 8341, 2838, 29462, 29467}\n",
      "dict_items([(\"Lemma('cool.a.01.cool')\", 3)])\n",
      "collecting tokens for  dragged\n",
      "indices:    {22656, 17571, 37094, 35432, 35275, 34829, 34034, 36981, 36151, 35003, 8573}\n",
      "dict_items([(\"Lemma('drag.v.01.drag')\", 4), (\"Lemma('haul.v.01.drag')\", 6)])\n",
      "collecting tokens for  upright\n",
      "indices:    {2018, 8423, 28265, 8814, 8819, 1204, 34810, 34332, 19262}\n",
      "dict_items([(\"Lemma('upright.s.01.upright')\", 5), (\"Lemma('good.s.07.upright')\", 1)])\n",
      "collecting tokens for  senior\n",
      "indices:    {267, 153, 155, 31777, 24995, 13228, 1204, 14517, 15414, 15417, 23106, 22341, 9288, 31326, 22879, 21090, 21603, 21602, 33126, 33130, 13298, 13170, 20858}\n",
      "dict_items([(\"Lemma('senior.a.01.senior')\", 3), (\"Lemma('senior.n.01.senior')\", 3), (\"Lemma('senior.s.02.senior')\", 1)])\n",
      "collecting tokens for  crawled\n",
      "indices:    {12192, 30562, 16650, 16682, 35404, 34445, 34956, 34959, 19248, 35407, 36049, 31476, 11124, 19254, 10871, 13567}\n",
      "dict_items([(\"Lemma('crawl.v.01.crawl')\", 15), (\"Lemma('crawl.v.02.crawl')\", 1)])\n",
      "collecting tokens for  restored\n",
      "indices:    {37027, 1700, 4218, 34445, 4207, 29362, 5398, 16663, 25754, 28731}\n",
      "dict_items([(\"Lemma('restore.v.01.restore')\", 5), (\"Lemma('repair.v.01.restore')\", 1), (\"Lemma('regenerate.v.04.restore')\", 1), (\"Lemma('restore.v.03.restore')\", 1)])\n",
      "collecting tokens for  minority\n",
      "indices:    {28000, 27843, 4771, 1573, 16259, 23754, 27886, 2512, 24818, 24821, 27899, 27997, 26719}\n",
      "dict_items([(\"Lemma('minority.n.02.minority')\", 2), (\"Lemma('minority.n.01.minority')\", 2)])\n",
      "collecting tokens for  exercises\n",
      "indices:    {25792, 31264, 1571, 1572, 1573, 1958, 32711, 5220, 24643, 1545, 1547, 5219, 31245, 4719, 1524, 4726, 10615}\n",
      "dict_items([(\"Lemma('exercise.n.04.exercise')\", 2), (\"Lemma('exercise.n.03.exercise')\", 1), (\"Lemma('practice.v.01.exercise')\", 2), (\"Lemma('use.n.01.exercise')\", 1), (\"Lemma('exercise.n.01.exercise')\", 6), (\"Lemma('exert.v.01.exercise')\", 1)])\n",
      "collecting tokens for  hazard\n",
      "indices:    {1706, 27083, 25393, 24369, 31667, 22263, 30777}\n",
      "dict_items([(\"Lemma('hazard.n.01.hazard')\", 1), (\"Lemma('guess.v.02.hazard')\", 1)])\n",
      "collecting tokens for  replace\n",
      "indices:    {24740, 2598, 29417, 20492, 21004, 29100, 24121, 30490, 25308}\n",
      "dict_items([(\"Lemma('supplant.v.01.replace')\", 3), (\"Lemma('replace.v.01.replace')\", 5), (\"Lemma('replace.v.03.replace')\", 1)])\n",
      "collecting tokens for  winchester\n",
      "indices:    {10374}\n",
      "dict_items([])\n",
      "collecting tokens for  lou\n",
      "indices:    {30873}\n",
      "dict_items([])\n",
      "collecting tokens for  rally\n",
      "indices:    {35109, 24103, 12904, 201, 42, 4686, 24592, 21747, 26036, 35869}\n",
      "dict_items([(\"Lemma('call_up.v.04.rally')\", 2), (\"Lemma('beat_up.v.02.rally')\", 3), (\"Lemma('rally.n.02.rally')\", 1), (\"Lemma('rally.n.01.rally')\", 1)])\n",
      "collecting tokens for  savannah\n",
      "indices:    {14507}\n",
      "dict_items([(\"Lemma('location.n.01.location')\", 1)])\n",
      "collecting tokens for  clark\n",
      "indices:    {5140}\n",
      "dict_items([])\n",
      "collecting tokens for  oklahoma\n",
      "indices:    {25646}\n",
      "dict_items([])\n",
      "collecting tokens for  barbara\n",
      "indices:    {7426}\n",
      "dict_items([(\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  committed\n",
      "indices:    {13376, 12641, 12642, 14660, 4615, 27303, 14172, 14919, 15242, 4588, 905, 6835, 27861, 20058, 30938, 32443, 27708}\n",
      "dict_items([(\"Lemma('committed.a.01.committed')\", 3), (\"Lemma('give.v.18.commit')\", 9), (\"Lemma('commit.v.03.commit')\", 3), (\"Lemma('entrust.v.01.commit')\", 1), (\"Lemma('perpetrate.v.01.commit')\", 1)])\n",
      "collecting tokens for  disposed\n",
      "indices:    {27303, 24331, 12366, 20025, 4912, 12945, 22034, 27769, 36889}\n",
      "dict_items([(\"Lemma('discard.v.01.dispose')\", 1), (\"Lemma('dispose.v.01.dispose')\", 2), (\"Lemma('dispose.v.03.dispose')\", 2)])\n",
      "collecting tokens for  september\n",
      "indices:    {14572}\n",
      "dict_items([(\"Lemma('september.n.01.September')\", 1)])\n",
      "collecting tokens for  ross\n",
      "indices:    {30255}\n",
      "dict_items([])\n",
      "collecting tokens for  removal\n",
      "indices:    {11616, 22791, 24426, 28043, 1907, 5557, 5559, 863}\n",
      "dict_items([(\"Lemma('removal.n.01.removal')\", 5)])\n",
      "collecting tokens for  forgot\n",
      "indices:    {7784, 33419}\n",
      "dict_items([(\"Lemma('forget.v.03.forget')\", 2)])\n",
      "collecting tokens for  moist\n",
      "indices:    {22947, 8420, 36039, 4137, 1647, 30417, 9586, 1628, 3679}\n",
      "dict_items([(\"Lemma('damp.s.01.moist')\", 6)])\n",
      "collecting tokens for  cottage\n",
      "indices:    {29824, 30689, 26530, 11907, 36387, 7268, 24348, 5195, 21260, 33548, 36343, 10744, 29820}\n",
      "dict_items([(\"Lemma('bungalow.n.01.cottage')\", 3)])\n",
      "collecting tokens for  indicates\n",
      "indices:    {16006, 16009, 32274, 30243, 15911, 28712, 32937, 28714, 3892, 32308, 3897, 24892, 30269, 31806, 15938, 32592, 4178, 26838, 3928, 3677, 3045, 4200, 11376, 11379, 12031, 22387, 5491, 14716, 11518, 14847}\n",
      "dict_items([(\"Lemma('bespeak.v.01.indicate')\", 19), (\"Lemma('indicate.v.02.indicate')\", 7), (\"Lemma('indicate.v.03.indicate')\", 3), (\"Lemma('indicate.v.05.indicate')\", 1)])\n",
      "collecting tokens for  assumptions\n",
      "indices:    {16066, 27843, 14050, 4901, 34341, 3301, 14054, 16329, 34339, 16333, 3022, 12914, 2835, 12916}\n",
      "dict_items([(\"Lemma('assumption.n.02.assumption')\", 8), (\"Lemma('premise.n.01.assumption')\", 3)])\n",
      "collecting tokens for  sleeve\n",
      "indices:    {10406, 10794, 35245, 25999, 34096, 29684, 35124}\n",
      "dict_items([(\"Lemma('sleeve.n.01.sleeve')\", 2)])\n",
      "collecting tokens for  nodded\n",
      "indices:    {9986, 19971, 35081, 36362, 8331, 17676, 35083, 31503, 18584, 35864, 18330, 5926, 20007, 20010, 18863, 9392, 7987, 17845, 17462, 36406, 34999, 23351, 33977, 7235, 8517, 17862, 10697, 7371, 18507, 17359, 34000, 18921, 8300, 36733, 35958, 19581}\n",
      "dict_items([(\"Lemma('nod.v.02.nod')\", 8), (\"Lemma('nod.v.01.nod')\", 26)])\n",
      "collecting tokens for  apprehension\n",
      "indices:    {36897, 36930, 17059, 35873, 27877, 18853, 13158, 1291, 6897, 28439}\n",
      "dict_items([(\"Lemma('understanding.n.01.apprehension')\", 1), (\"Lemma('apprehension.n.01.apprehension')\", 4)])\n",
      "collecting tokens for  attraction\n",
      "indices:    {24035, 36676, 26021, 20457, 2379, 3308, 22286, 14480, 10099, 3191, 3193, 25115, 14428}\n",
      "dict_items([(\"Lemma('attraction.n.03.attraction')\", 2), (\"Lemma('attraction.n.01.attraction')\", 3), (\"Lemma('attraction.n.04.attraction')\", 1)])\n",
      "collecting tokens for  loves\n",
      "indices:    {27200, 27361, 8388, 11050, 13967, 22073, 785, 13810, 32082, 25688, 28217, 31642, 6010}\n",
      "dict_items([(\"Lemma('love.v.02.love')\", 4), (\"Lemma('love.v.03.love')\", 1), (\"Lemma('love.v.01.love')\", 6), (\"Lemma('beloved.n.01.love')\", 1), (\"Lemma('love.n.01.love')\", 1)])\n",
      "collecting tokens for  alarm\n",
      "indices:    {14593, 12770, 24899, 18632, 2442, 9388, 7730, 34644, 35800, 12760, 12762, 12731, 27838}\n",
      "dict_items([(\"Lemma('alarm.v.02.alarm')\", 1), (\"Lemma('alarm.n.01.alarm')\", 5), (\"Lemma('alarm.n.02.alarm')\", 3)])\n",
      "collecting tokens for  lawyer\n",
      "indices:    {20354, 31747, 21264, 22548, 31126, 36633, 14492, 17951, 22564, 27307, 17339, 24144, 5969, 20436, 20437, 99, 2665, 37098, 492, 17390, 17397, 24699, 509, 6014}\n",
      "dict_items([(\"Lemma('lawyer.n.01.lawyer')\", 11)])\n",
      "collecting tokens for  expressway\n",
      "indices:    {25293, 25294}\n",
      "dict_items([])\n",
      "collecting tokens for  heidenstam\n",
      "indices:    {13833}\n",
      "dict_items([(\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  1859\n",
      "indices:    {5313, 5287, 5288, 5322, 5291, 5327, 22546, 28025, 5306, 5308, 13789}\n",
      "dict_items([])\n",
      "collecting tokens for  whites\n",
      "indices:    {6048, 24416, 25601, 6116, 22866, 24435, 24437, 6041, 35514, 24444, 6141, 23262}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('white.n.01.White')\", 4)])\n",
      "collecting tokens for  negroes\n",
      "indices:    {26749}\n",
      "dict_items([])\n",
      "collecting tokens for  claiming\n",
      "indices:    {2115, 30084, 36997, 27334, 32392, 1321, 18730, 27816, 24435, 245, 4634, 8476, 18302}\n",
      "dict_items([(\"Lemma('claim.v.01.claim')\", 7), (\"Lemma('claim.v.02.claim')\", 3), (\"Lemma('claim.v.03.claim')\", 1), (\"Lemma('claim.v.04.claim')\", 2)])\n",
      "collecting tokens for  ticket\n",
      "indices:    {20484, 35685, 33417, 20490, 33419, 20940, 34637, 20985, 27183, 33423, 948, 20633, 20634}\n",
      "dict_items([(\"Lemma('ticket.n.01.ticket')\", 1)])\n",
      "collecting tokens for  maintains\n",
      "indices:    {23522, 32707, 28133, 11973, 23559, 4684, 32945, 29266, 2739, 2742}\n",
      "dict_items([(\"Lemma('sustain.v.04.maintain')\", 1), (\"Lemma('keep.v.01.maintain')\", 2), (\"Lemma('assert.v.01.maintain')\", 1), (\"Lemma('conserve.v.02.maintain')\", 6)])\n",
      "collecting tokens for  dependable\n",
      "indices:    {7399, 12970, 30572, 28014, 4911, 4658, 30578, 1683}\n",
      "dict_items([(\"Lemma('reliable.a.01.dependable')\", 4), (\"Lemma('dependable.s.02.dependable')\", 1)])\n",
      "collecting tokens for  emphasize\n",
      "indices:    {22144, 11299, 20484, 7608, 682, 5362, 25365, 1722, 24409, 27738, 28125, 1215}\n",
      "dict_items([(\"Lemma('stress.v.01.emphasize')\", 5)])\n",
      "collecting tokens for  earnest\n",
      "indices:    {1345, 36002, 36066, 5095, 27305, 5354, 18031, 24818, 22969}\n",
      "dict_items([(\"Lemma('earnest.s.01.earnest')\", 2), (\"Lemma('earnest.n.01.earnest')\", 1)])\n",
      "collecting tokens for  rabbi\n",
      "indices:    {7584, 7596}\n",
      "dict_items([(\"Lemma('rabbi.n.01.rabbi')\", 1)])\n",
      "collecting tokens for  permanently\n",
      "indices:    {26502, 14886, 27211, 26252, 30748, 27243, 3215, 35668, 12348, 12637}\n",
      "dict_items([(\"Lemma('permanently.r.01.permanently')\", 4)])\n",
      "collecting tokens for  tragedy\n",
      "indices:    {26553, 9859, 30295, 27271, 7655, 5354, 24842, 26578, 26579, 21369, 30549, 28694, 25719, 23668, 24153, 12187, 30751, 7359}\n",
      "dict_items([(\"Lemma('calamity.n.01.tragedy')\", 5)])\n",
      "collecting tokens for  truly\n",
      "indices:    {25888, 25345, 10848, 25028, 1318, 23212, 4980, 13653, 1784, 29945, 28157}\n",
      "dict_items([(\"Lemma('truly.r.01.truly')\", 5)])\n",
      "collecting tokens for  acted\n",
      "indices:    {9664, 11035, 15235, 23779, 22682, 21641, 18252, 26811, 26579, 15225, 9594, 29755, 8220, 31998}\n",
      "dict_items([(\"Lemma('act.v.02.act')\", 4), (\"Lemma('act.v.03.act')\", 2), (\"Lemma('act.v.01.act')\", 4)])\n",
      "collecting tokens for  knowing\n",
      "indices:    {20322, 9783, 9641, 32255, 31121, 25138, 19441, 11511, 10236, 32861, 7743}\n",
      "dict_items([(\"Lemma('know.v.01.know')\", 8), (\"Lemma('know.v.04.know')\", 1), (\"Lemma('knowing.s.01.knowing')\", 1), (\"Lemma('know.v.02.know')\", 1)])\n",
      "collecting tokens for  hormone\n",
      "indices:    {3971, 4004, 3940, 4005, 4008, 3984, 3989, 3990, 3991, 3965}\n",
      "dict_items([(\"Lemma('hormone.n.01.hormone')\", 6)])\n",
      "collecting tokens for  tsh\n",
      "indices:    {3992}\n",
      "dict_items([(\"Lemma('thyrotropin.n.01.TSH')\", 1)])\n",
      "collecting tokens for  drawn\n",
      "indices:    {17924, 5385, 18825, 4622, 14480, 26513, 32411, 32547, 22705, 18354, 25400, 3914, 2895, 27089, 23252, 3929, 19550, 30183, 3564, 32110}\n",
      "dict_items([(\"Lemma('pull.v.01.draw')\", 1), (\"Lemma('draw.v.09.draw')\", 2), (\"Lemma('describe.v.01.draw')\", 1), (\"Lemma('draw.v.04.draw')\", 2), (\"Lemma('draw.v.07.draw')\", 1), (\"Lemma('trace.v.02.draw')\", 3), (\"Lemma('withdraw.v.09.draw')\", 1), (\"Lemma('drawn.s.02.drawn')\", 1), (\"Lemma('draw.v.14.draw')\", 1), (\"Lemma('draw.v.16.draw')\", 1)])\n",
      "collecting tokens for  poland\n",
      "indices:    {7929}\n",
      "dict_items([(\"Lemma('poland.n.01.Poland')\", 1)])\n",
      "collecting tokens for  combinations\n",
      "indices:    {26459, 30563, 15227, 1926, 27563, 16044, 12781, 3609, 22799, 30739, 2169, 11610, 15963}\n",
      "dict_items([(\"Lemma('combination.n.01.combination')\", 8)])\n",
      "collecting tokens for  guessed\n",
      "indices:    {11045, 16646, 7941, 18922, 13579, 19340, 748, 36298, 36750, 16694, 31386, 8697, 10522}\n",
      "dict_items([(\"Lemma('think.v.02.guess')\", 7), (\"Lemma('guess.v.02.guess')\", 3), (\"Lemma('guess.v.04.guess')\", 2), (\"Lemma('estimate.v.01.guess')\", 1)])\n",
      "collecting tokens for  loop\n",
      "indices:    {12637}\n",
      "dict_items([(\"Lemma('location.n.01.location')\", 1)])\n",
      "collecting tokens for  impersonal\n",
      "indices:    {17408, 36003, 19754, 14220, 15727, 31919, 31922, 31895, 13368, 13371, 13341, 31262, 22783}\n",
      "dict_items([(\"Lemma('impersonal.a.01.impersonal')\", 6), (\"Lemma('impersonal.s.02.impersonal')\", 1)])\n",
      "collecting tokens for  emerged\n",
      "indices:    {32009, 2314, 7307, 6923, 34830, 18320, 1056, 9388, 7349, 29392, 24402, 34391, 28122, 35558, 36967, 18932, 885, 12413, 14206}\n",
      "dict_items([(\"Lemma('emerge.v.01.emerge')\", 12), (\"Lemma('issue.v.04.emerge')\", 5), (\"Lemma('emerge.v.03.emerge')\", 1), (\"Lemma('emerge.v.04.emerge')\", 1)])\n",
      "collecting tokens for  revised\n",
      "indices:    {24739, 1224, 32302, 9876, 20820, 14998, 15671}\n",
      "dict_items([(\"Lemma('revise.v.01.revise')\", 2), (\"Lemma('retool.v.01.revise')\", 3), (\"Lemma('revised.s.01.revised')\", 1)])\n",
      "collecting tokens for  environment\n",
      "indices:    {2560, 3330, 2951, 30739, 30745, 30750, 13350, 34225, 13363, 13374, 32959, 2624, 12098, 11216, 15704, 7261, 13663, 15715, 15460, 33000, 15860, 15862, 3323}\n",
      "dict_items([(\"Lemma('environment.n.01.environment')\", 17)])\n",
      "collecting tokens for  eager\n",
      "indices:    {14402, 31134, 14444, 11789, 22000, 5873, 36337, 11475, 29043, 1043, 13078, 1877, 9010, 11258, 22366, 1695}\n",
      "dict_items([(\"Lemma('eager.a.01.eager')\", 10)])\n",
      "collecting tokens for  pirates\n",
      "indices:    {608}\n",
      "dict_items([(\"Lemma('group.n.01.group')\", 1)])\n",
      "collecting tokens for  garth\n",
      "indices:    {17360}\n",
      "dict_items([(\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  hesitated\n",
      "indices:    {10048, 29025, 20387, 7396, 35877, 34024, 17353, 34089, 7592, 35372, 34446, 34963, 35835, 12892, 10045}\n",
      "dict_items([(\"Lemma('hesitate.v.02.hesitate')\", 9), (\"Lemma('hesitate.v.01.hesitate')\", 6)])\n",
      "collecting tokens for  anthony\n",
      "indices:    {1138}\n",
      "dict_items([])\n",
      "collecting tokens for  consult\n",
      "indices:    {257, 32067, 22501, 35729, 28693, 7605, 7031, 30778, 17341}\n",
      "dict_items([(\"Lemma('consult.v.01.consult')\", 6), (\"Lemma('confer.v.01.consult')\", 1), (\"Lemma('consult.v.02.consult')\", 1)])\n",
      "collecting tokens for  underneath\n",
      "indices:    {7017, 29907, 35660, 35734}\n",
      "dict_items([])\n",
      "collecting tokens for  versions\n",
      "indices:    {30048, 1731, 15973, 24744, 2457, 28942, 1745, 29113, 24574}\n",
      "dict_items([(\"Lemma('version.n.01.version')\", 3), (\"Lemma('version.n.02.version')\", 1)])\n",
      "collecting tokens for  gear\n",
      "indices:    {28642, 28643, 34153, 28942, 21295, 28945, 28951}\n",
      "dict_items([])\n",
      "collecting tokens for  nogol\n",
      "indices:    {34508}\n",
      "dict_items([])\n",
      "collecting tokens for  holder\n",
      "indices:    {2945, 2950, 2951, 2952, 2953, 2955, 2896, 2899, 2905, 29659, 29660, 2910, 2911, 2912, 2913, 5602, 2914, 2916, 16994, 2924, 2925, 2929}\n",
      "dict_items([(\"Lemma('holder.n.01.holder')\", 20)])\n",
      "collecting tokens for  upstairs\n",
      "indices:    {35973, 9747, 15385, 6309, 8102, 8751, 7732, 9415, 8779, 7759, 9689, 9572, 9068, 14446, 16879, 5743, 21364, 30580, 9460, 7671, 20092}\n",
      "dict_items([(\"Lemma('upstairs.r.01.upstairs')\", 13), (\"Lemma('upstairs.a.01.upstairs')\", 5)])\n",
      "collecting tokens for  5000\n",
      "indices:    {20706, 16229, 22182, 32439, 21770, 14859, 21803, 27057, 20754, 20178, 21490, 20598, 28951, 2237, 23262}\n",
      "dict_items([])\n",
      "collecting tokens for  employes\n",
      "indices:    {21553, 21490, 25345}\n",
      "dict_items([])\n",
      "collecting tokens for  sharing\n",
      "indices:    {26716}\n",
      "dict_items([(\"Lemma('share.v.02.share')\", 1)])\n",
      "collecting tokens for  tom\n",
      "indices:    {2262}\n",
      "dict_items([(\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  kent\n",
      "indices:    {30517}\n",
      "dict_items([])\n",
      "collecting tokens for  memorial\n",
      "indices:    {29306}\n",
      "dict_items([])\n",
      "collecting tokens for  cooked\n",
      "indices:    {21601, 10888, 29163, 9166, 35029, 9205, 29181, 36990}\n",
      "dict_items([(\"Lemma('cook.v.02.cook')\", 2), (\"Lemma('cook.v.03.cook')\", 1), (\"Lemma('cook.v.01.cook')\", 3)])\n",
      "collecting tokens for  explosive\n",
      "indices:    {7842, 30339, 19177, 35915, 20749, 9166, 28527, 27921, 26738, 29074, 22962, 31989, 343, 21721, 13053, 30271}\n",
      "dict_items([(\"Lemma('explosive.s.02.explosive')\", 3), (\"Lemma('explosive.a.01.explosive')\", 2)])\n",
      "collecting tokens for  speakers\n",
      "indices:    {20980, 629}\n",
      "dict_items([(\"Lemma('speaker.n.01.speaker')\", 1)])\n",
      "collecting tokens for  i.e.\n",
      "indices:    {3425, 4323, 4281, 4326, 4327, 3306, 1515, 4315, 4498, 12244, 4374, 1111, 11097, 4379, 4316, 3037}\n",
      "dict_items([(\"Lemma('i.e..r.01.i.e.')\", 16)])\n",
      "collecting tokens for  experts\n",
      "indices:    {12064, 2337, 12003, 14988, 14970, 12671}\n",
      "dict_items([(\"Lemma('expert.n.01.expert')\", 6)])\n",
      "collecting tokens for  managers\n",
      "indices:    {2720, 4418, 20420, 15753, 15785, 21451, 21452, 21453, 24464, 27312, 671, 21462, 4407, 668, 15775}\n",
      "dict_items([(\"Lemma('director.n.01.manager')\", 4), (\"Lemma('coach.n.01.manager')\", 4)])\n",
      "collecting tokens for  simmons\n",
      "indices:    {23351}\n",
      "dict_items([])\n",
      "collecting tokens for  boxes\n",
      "indices:    {9505, 11106, 20962, 30721, 5806, 17555, 31287, 22268, 7133, 23103}\n",
      "dict_items([(\"Lemma('box.n.01.box')\", 3), (\"Lemma('mailbox.n.01.mailbox')\", 1)])\n",
      "collecting tokens for  nursery\n",
      "indices:    {36097, 34373, 34406, 34407, 24553, 34666, 7311, 36080, 7671, 34426, 34430}\n",
      "dict_items([(\"Lemma('nursery.n.01.nursery')\", 2)])\n",
      "collecting tokens for  professors\n",
      "indices:    {14444, 22703, 20276, 2102, 24796, 2109}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('professor.n.01.professor')\", 3)])\n",
      "collecting tokens for  spectra\n",
      "indices:    {14791, 14794, 14851, 3143}\n",
      "dict_items([(\"Lemma('spectrum.n.01.spectrum')\", 3)])\n",
      "collecting tokens for  circular\n",
      "indices:    {18817, 5511, 3309, 29589, 2782}\n",
      "dict_items([(\"Lemma('round.a.01.circular')\", 3)])\n",
      "collecting tokens for  legends\n",
      "indices:    {2312, 31785, 2318, 2321, 31798, 2358, 2297}\n",
      "dict_items([(\"Lemma('legend.n.01.legend')\", 5)])\n",
      "collecting tokens for  merits\n",
      "indices:    {25282, 14346, 2044, 23372, 22991, 33104, 32336, 434, 31764, 3477, 5276, 27646}\n",
      "dict_items([(\"Lemma('deservingness.n.01.merit')\", 1), (\"Lemma('deserve.v.01.merit')\", 3), (\"Lemma('merit.n.01.merit')\", 3)])\n",
      "collecting tokens for  guns\n",
      "indices:    {18785, 36517, 12998, 9222}\n",
      "dict_items([(\"Lemma('gun.n.01.gun')\", 2)])\n",
      "collecting tokens for  ultraviolet\n",
      "indices:    {11361, 11362, 11364, 3430, 11368, 11369, 11371, 11355, 11356, 11358}\n",
      "dict_items([(\"Lemma('ultraviolet.s.01.ultraviolet')\", 2), (\"Lemma('ultraviolet.n.01.ultraviolet')\", 2)])\n",
      "collecting tokens for  assessment\n",
      "indices:    {32421, 32422, 3430, 21608, 32425, 32426, 32395, 32396, 32397, 32427, 32423, 3405, 24178, 32437, 24024, 32378, 32380, 32127}\n",
      "dict_items([(\"Lemma('appraisal.n.01.assessment')\", 2)])\n",
      "collecting tokens for  lover\n",
      "indices:    {14596, 31589, 26614}\n",
      "dict_items([(\"Lemma('lover.n.01.lover')\", 1)])\n",
      "collecting tokens for  conversion\n",
      "indices:    {11553, 2753, 14727, 4042, 3376, 22098, 14738, 21529, 11549}\n",
      "dict_items([(\"Lemma('conversion.n.01.conversion')\", 6), (\"Lemma('conversion.n.02.conversion')\", 1)])\n",
      "collecting tokens for  chart\n",
      "indices:    {3871}\n",
      "dict_items([(\"Lemma('chart.n.01.chart')\", 1)])\n",
      "collecting tokens for  doubled\n",
      "indices:    {199, 27752, 23529, 20302, 369, 23186, 17972, 20537, 28155, 23452}\n",
      "dict_items([(\"Lemma('double.v.02.double')\", 2), (\"Lemma('double.v.01.double')\", 6), (\"Lemma('double_over.v.01.double_up')\", 1), (\"Lemma('double_over.v.01.double')\", 1)])\n",
      "collecting tokens for  taxable\n",
      "indices:    {32384, 32385, 22022, 22055, 15602, 32381}\n",
      "dict_items([])\n",
      "collecting tokens for  electronics\n",
      "indices:    {11365, 11400, 32493, 11374, 11343, 32466, 11346}\n",
      "dict_items([(\"Lemma('electronics.n.01.electronics')\", 4)])\n",
      "collecting tokens for  whipple\n",
      "indices:    {20810}\n",
      "dict_items([])\n",
      "collecting tokens for  worn\n",
      "indices:    {34976, 19683, 7881, 13577, 35819, 24363, 31498, 10794, 36753, 7985, 6867, 30069, 21146, 21148, 17086}\n",
      "dict_items([(\"Lemma('wear.v.02.wear')\", 3), (\"Lemma('wear.v.04.wear')\", 1), (\"Lemma('wear.v.01.wear')\", 5), (\"Lemma('worn.a.01.worn')\", 2)])\n",
      "collecting tokens for  yield\n",
      "indices:    {23948, 12698, 3232, 7082, 2479, 12466, 30772, 25399, 21815, 21817, 7097, 15677, 25408, 30789, 25414, 25415, 25417, 25418, 21968, 32083, 3293, 3294, 23391, 23393, 23395, 33251, 28529, 27768}\n",
      "dict_items([(\"Lemma('yield.v.01.yield')\", 1), (\"Lemma('output.n.02.yield')\", 3), (\"Lemma('give_way.v.03.yield')\", 4), (\"Lemma('concede.v.03.yield')\", 2), (\"Lemma('render.v.04.yield')\", 1), (\"Lemma('yield.v.05.yield')\", 2), (\"Lemma('yield.n.03.yield')\", 1), (\"Lemma('return.n.06.yield')\", 1), (\"Lemma('move_over.v.01.yield')\", 1)])\n",
      "collecting tokens for  optimism\n",
      "indices:    {32450, 28040, 24201, 7273, 34737, 9618, 21878, 33371, 20252}\n",
      "dict_items([(\"Lemma('optimism.n.01.optimism')\", 2)])\n",
      "collecting tokens for  caliber\n",
      "indices:    {29057, 22713, 22731, 21168, 29073, 21209, 11670, 11705, 5787, 29053, 29087}\n",
      "dict_items([(\"Lemma('quality.n.02.caliber')\", 2), (\"Lemma('bore.n.03.caliber')\", 1)])\n",
      "collecting tokens for  goin\n",
      "indices:    {17857, 35523, 35578, 18543, 35504, 18865, 35125, 35162, 35515, 35167}\n",
      "dict_items([(\"Lemma('travel.v.01.go')\", 5)])\n",
      "collecting tokens for  stating\n",
      "indices:    {5281, 27266, 25976, 12585, 36907, 4012, 14862, 15574, 34295, 12376, 3004, 22814}\n",
      "dict_items([(\"Lemma('state.v.01.state')\", 12)])\n",
      "collecting tokens for  counts\n",
      "indices:    {2368, 3276, 21487, 21488, 13554, 3347, 3348, 30007, 1340, 30719}\n",
      "dict_items([(\"Lemma('count.v.05.count')\", 1), (\"Lemma('count.n.02.count')\", 2), (\"Lemma('count.v.01.count')\", 1), (\"Lemma('consider.v.04.count')\", 1), (\"Lemma('count.v.02.count')\", 1), (\"Lemma('count.n.01.count')\", 1)])\n",
      "collecting tokens for  frozen\n",
      "indices:    {10241, 29445, 34573, 34574, 2322, 29462, 19234, 34608, 3255, 3258, 30523, 3259, 3260, 37056, 3266, 12622, 12376, 34922, 6909}\n",
      "dict_items([(\"Lemma('frozen.a.01.frozen')\", 2), (\"Lemma('frozen.s.02.frozen')\", 2), (\"Lemma('freeze.v.01.freeze')\", 1), (\"Lemma('freeze.v.02.freeze')\", 1), (\"Lemma('frigid.s.03.frozen')\", 1)])\n",
      "collecting tokens for  submit\n",
      "indices:    {32768, 27808, 25092, 12932, 14151, 24904, 10120, 14764, 813, 32527, 25842, 23954, 9780, 15252, 15286}\n",
      "dict_items([(\"Lemma('relegate.v.01.submit')\", 2), (\"Lemma('submit.v.03.submit')\", 2), (\"Lemma('submit.v.02.submit')\", 6), (\"Lemma('take.v.19.submit')\", 1), (\"Lemma('submit.v.01.submit')\", 3), (\"Lemma('present.v.04.submit')\", 1)])\n",
      "collecting tokens for  vecchio\n",
      "indices:    {9943}\n",
      "dict_items([(\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  asleep\n",
      "indices:    {34577, 10299, 10012}\n",
      "dict_items([(\"Lemma('asleep.a.01.asleep')\", 2)])\n",
      "collecting tokens for  dreaming\n",
      "indices:    {36644, 2123, 29996, 6354, 6227, 6454, 10552, 19449, 6843}\n",
      "dict_items([(\"Lemma('dream.v.01.dream')\", 5), (\"Lemma('dream.v.02.dream')\", 4)])\n",
      "collecting tokens for  earthquakes\n",
      "indices:    {12782, 12791}\n",
      "dict_items([(\"Lemma('earthquake.n.01.earthquake')\", 2)])\n",
      "collecting tokens for  colors\n",
      "indices:    {31882, 31856, 24562, 24567, 2200, 697, 27549, 13655}\n",
      "dict_items([(\"Lemma('color.n.01.color')\", 3)])\n",
      "collecting tokens for  accounts\n",
      "indices:    {2496, 3729}\n",
      "dict_items([(\"Lemma('report.n.03.account')\", 1), (\"Lemma('history.n.02.account')\", 1)])\n",
      "collecting tokens for  telegraph\n",
      "indices:    {5140}\n",
      "dict_items([])\n",
      "collecting tokens for  suspect\n",
      "indices:    {24320, 13698, 4880, 23960, 3096, 13976, 36891, 20640, 6819, 16565, 31429, 14407, 2505, 16075, 1744, 18268, 27233, 2666, 17011, 28404, 23924, 17531}\n",
      "dict_items([(\"Lemma('fishy.s.02.suspect')\", 2), (\"Lemma('suspect.v.01.suspect')\", 2), (\"Lemma('suspect.n.01.suspect')\", 1), (\"Lemma('suspect.v.03.suspect')\", 1)])\n",
      "collecting tokens for  produces\n",
      "indices:    {22692, 14373, 4228, 14633, 2666, 26122, 31018, 16014, 32945, 31932, 4474, 1788, 27453}\n",
      "dict_items([(\"Lemma('produce.v.01.produce')\", 6), (\"Lemma('produce.v.03.produce')\", 7)])\n",
      "collecting tokens for  magic\n",
      "indices:    {27521, 27522, 5763, 27525, 27526, 28165, 27530, 27531, 33164, 27536, 21010, 27927, 2588, 26529, 27953, 27979, 22607, 28112, 28113, 6610, 28111, 28116, 28118, 2268, 24035, 24163, 24547, 2666, 14317, 32113, 32114}\n",
      "dict_items([(\"Lemma('magic.n.01.magic')\", 4), (\"Lemma('charming.s.02.magic')\", 2)])\n",
      "collecting tokens for  burnside\n",
      "indices:    {10922}\n",
      "dict_items([])\n",
      "collecting tokens for  programing\n",
      "indices:    {32130, 32133, 26726, 32136, 32138, 26734, 32149, 32121, 32122, 32126, 26751}\n",
      "dict_items([(\"Lemma('program.v.01.program')\", 1)])\n",
      "collecting tokens for  plain\n",
      "indices:    {34911, 29039}\n",
      "dict_items([])\n",
      "collecting tokens for  alternate\n",
      "indices:    {1545, 15116, 12241, 21687, 31295}\n",
      "dict_items([(\"Lemma('alternate.v.01.alternate')\", 1), (\"Lemma('alternate.s.02.alternate')\", 1), (\"Lemma('alternate.s.01.alternate')\", 1)])\n",
      "collecting tokens for  beams\n",
      "indices:    {15104, 15074, 15077, 15078, 15079, 11410, 8504, 29977, 9148}\n",
      "dict_items([(\"Lemma('beam.n.02.beam')\", 7), (\"Lemma('beam.n.03.beam')\", 1)])\n",
      "collecting tokens for  conditioner\n",
      "indices:    {34273, 30113, 30146, 34279, 34313, 34282, 30158, 12111, 30164, 30165, 30167, 30141}\n",
      "dict_items([(\"Lemma('conditioner.n.01.conditioner')\", 1)])\n",
      "collecting tokens for  privately\n",
      "indices:    {20163, 22892, 18302}\n",
      "dict_items([(\"Lemma('privately.r.01.privately')\", 1)])\n",
      "collecting tokens for  believing\n",
      "indices:    {2247, 16723, 12287}\n",
      "dict_items([(\"Lemma('think.v.01.believe')\", 1), (\"Lemma('believe.v.01.believe')\", 1), (\"Lemma('believe.v.03.believe')\", 1)])\n",
      "collecting tokens for  theodore\n",
      "indices:    {29306}\n",
      "dict_items([])\n",
      "collecting tokens for  quantity\n",
      "indices:    {30218, 32270, 17424, 12178, 4128, 1843, 16696, 1859, 1861, 32967, 1359, 1872, 16343, 27226, 32888, 3935, 19170, 25446, 32359, 1902, 16369, 32755, 27125, 11128, 28667, 28925}\n",
      "dict_items([(\"Lemma('measure.n.02.quantity')\", 10), (\"Lemma('quantity.n.02.quantity')\", 5)])\n",
      "collecting tokens for  ray\n",
      "indices:    {27048}\n",
      "dict_items([])\n",
      "collecting tokens for  moore\n",
      "indices:    {1040}\n",
      "dict_items([])\n",
      "collecting tokens for  scenic\n",
      "indices:    {1856, 29284, 1893, 10669, 21075, 29300, 1844, 1847}\n",
      "dict_items([(\"Lemma('scenic.s.01.scenic')\", 5)])\n",
      "collecting tokens for  belly\n",
      "indices:    {9104, 6932, 10904, 18457, 6683, 16174, 34097, 34102, 10552, 27194, 25659, 25662, 25673, 25677, 25682, 25684, 25687, 25688, 10590, 10595}\n",
      "dict_items([(\"Lemma('abdomen.n.01.belly')\", 8), (\"Lemma('belly.n.02.belly')\", 1)])\n",
      "collecting tokens for  cheek\n",
      "indices:    {9600, 10370, 8419, 10402, 33638, 17096, 10985, 6088, 35214, 35281, 10354, 10360, 29946, 12667}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('cheek.n.01.cheek')\", 8)])\n",
      "collecting tokens for  prosecutor\n",
      "indices:    {12234, 20852}\n",
      "dict_items([(\"Lemma('prosecutor.n.01.prosecutor')\", 1)])\n",
      "collecting tokens for  lesson\n",
      "indices:    {32225, 7106, 21896, 32232, 969, 32683, 24619, 12301, 26095, 18290, 15707, 14582, 15708, 32022, 6715, 12220, 25374}\n",
      "dict_items([(\"Lemma('example.n.04.lesson')\", 4), (\"Lemma('lesson.n.01.lesson')\", 2), (\"Lemma('lesson.n.04.lesson')\", 1), (\"Lemma('moral.n.01.lesson')\", 2)])\n",
      "collecting tokens for  dressing\n",
      "indices:    {19842, 9860, 9989, 19977, 9873, 29458, 9624, 37028, 6187, 29487, 19893, 30912, 19915, 30041, 2654, 2662, 35821, 7416, 7420, 36990}\n",
      "dict_items([(\"Lemma('dress.v.01.dress')\", 2)])\n",
      "collecting tokens for  700\n",
      "indices:    {15106, 15112, 21835, 844, 20206, 847, 12496, 5006, 21618, 22003}\n",
      "dict_items([])\n",
      "collecting tokens for  dental\n",
      "indices:    {31072, 31073, 711, 20200, 20199, 20202, 31052, 20173, 20206, 722, 32723}\n",
      "dict_items([(\"Lemma('dental.a.01.dental')\", 2)])\n",
      "collecting tokens for  hymen\n",
      "indices:    {30762, 30763, 30765, 30766, 30772, 30810, 30779, 30781}\n",
      "dict_items([])\n",
      "collecting tokens for  catholicism\n",
      "indices:    {25465}\n",
      "dict_items([])\n",
      "collecting tokens for  sake\n",
      "indices:    {14340, 10763, 35595, 19856, 4242, 17428, 12951, 13346, 6694, 1198, 6709, 20935, 23754, 19538, 32088, 9176, 10586, 35292, 9833, 17902}\n",
      "dict_items([(\"Lemma('sake.n.01.sake')\", 10)])\n",
      "collecting tokens for  meaningful\n",
      "indices:    {32273, 32556, 32366}\n",
      "dict_items([])\n",
      "collecting tokens for  planking\n",
      "indices:    {29763, 29797, 29766, 29767, 29772, 29773, 29725, 29757}\n",
      "dict_items([(\"Lemma('plank.v.01.plank')\", 1)])\n",
      "collecting tokens for  unadjusted\n",
      "indices:    {15040, 15041, 15042, 15043, 15044, 15051, 15054, 15055, 15038}\n",
      "dict_items([(\"Lemma('unadjusted.a.01.unadjusted')\", 9)])\n",
      "collecting tokens for  guaranteed\n",
      "indices:    {31682, 15043, 20195, 25796, 16297, 23823, 25174, 25180, 32446}\n",
      "dict_items([(\"Lemma('undertake.v.03.guarantee')\", 2), (\"Lemma('guarantee.v.01.guarantee')\", 4), (\"Lemma('guarantee.v.02.guarantee')\", 1)])\n",
      "collecting tokens for  similarly\n",
      "indices:    {36480, 4192, 4143, 13649, 15959}\n",
      "dict_items([(\"Lemma('similarly.r.01.similarly')\", 4)])\n",
      "collecting tokens for  vitality\n",
      "indices:    {22145, 24324, 26085, 20297, 5482, 27562, 1068, 31884, 13806, 11343, 2322, 13652, 1018, 1149}\n",
      "dict_items([(\"Lemma('vitality.n.01.vitality')\", 7), (\"Lemma('energy.n.05.vitality')\", 1)])\n",
      "collecting tokens for  prairie\n",
      "indices:    {21332}\n",
      "dict_items([])\n",
      "collecting tokens for  buddy\n",
      "indices:    {18920, 5948, 198}\n",
      "dict_items([(\"Lemma('buddy.n.01.buddy')\", 2)])\n",
      "collecting tokens for  goulding\n",
      "indices:    {12890}\n",
      "dict_items([(\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  unanimously\n",
      "indices:    {11202, 15332, 31716, 5348, 106, 37101, 20821, 31286, 23831, 5335}\n",
      "dict_items([(\"Lemma('unanimously.r.01.unanimously')\", 5)])\n",
      "collecting tokens for  russians\n",
      "indices:    {25446}\n",
      "dict_items([])\n",
      "collecting tokens for  formulas\n",
      "indices:    {28896, 28904, 28170, 28944, 28849, 3026, 28884, 28853, 27223, 28890, 28859, 28893, 25727}\n",
      "dict_items([(\"Lemma('formula.n.01.formula')\", 1)])\n",
      "collecting tokens for  flung\n",
      "indices:    {7170, 35209, 23274, 6957, 17969, 8658, 9043, 8598, 10231, 35612, 8671}\n",
      "dict_items([(\"Lemma('fling.v.01.fling')\", 10)])\n",
      "collecting tokens for  mcclellan\n",
      "indices:    {25344}\n",
      "dict_items([])\n",
      "collecting tokens for  110\n",
      "indices:    {26792, 29072, 274, 25843, 3099, 5532, 29053, 4094, 23551}\n",
      "dict_items([])\n",
      "collecting tokens for  females\n",
      "indices:    {3650, 3684, 3625, 3594, 20715, 13167, 3632, 3671, 3705, 33018, 32923, 33021, 3711}\n",
      "dict_items([(\"Lemma('female.n.01.female')\", 7), (\"Lemma('female.n.02.female')\", 2)])\n",
      "collecting tokens for  category\n",
      "indices:    {3328, 32387, 3461, 26631, 21516, 21517, 32923, 15519, 32431, 12214, 1720, 4539, 4540, 4541, 2504, 4430, 4587, 4592, 23935}\n",
      "dict_items([(\"Lemma('class.n.01.category')\", 11), (\"Lemma('category.n.02.category')\", 1)])\n",
      "collecting tokens for  brushed\n",
      "indices:    {6304, 9473, 29666, 21635, 35485, 6184, 9481, 36968, 31499, 7019, 29615, 33877, 9174, 33624, 34077, 10392, 19869}\n",
      "dict_items([(\"Lemma('brushed.s.02.brushed')\", 1), (\"Lemma('brush.v.02.brush')\", 7), (\"Lemma('brush.v.03.brush')\", 1), (\"Lemma('brush.v.04.brush')\", 1), (\"Lemma('brush.v.01.brush')\", 6)])\n",
      "collecting tokens for  deserted\n",
      "indices:    {35718, 18246, 35405, 18206, 35408, 34325, 33815, 18106, 3614, 7679}\n",
      "dict_items([(\"Lemma('abandon.v.05.desert')\", 1)])\n",
      "collecting tokens for  foremost\n",
      "indices:    {34810, 12743, 25576, 30026, 13900, 27759, 13807, 13338, 13275}\n",
      "dict_items([(\"Lemma('first.s.05.foremost')\", 2)])\n",
      "collecting tokens for  colorful\n",
      "indices:    {21063, 22151, 26633, 3593, 14119, 3609, 26448, 26866, 26742, 1849}\n",
      "dict_items([(\"Lemma('colorful.a.01.colorful')\", 3), (\"Lemma('colorful.a.02.colorful')\", 1)])\n",
      "collecting tokens for  underdeveloped\n",
      "indices:    {4643, 12261, 30987, 32171, 24049, 24981, 31734, 20248, 25628}\n",
      "dict_items([(\"Lemma('developing.s.01.underdeveloped')\", 2)])\n",
      "collecting tokens for  jaw\n",
      "indices:    {31041, 19906, 37123, 31017, 7145, 30987, 30990, 34032, 5618, 31059, 31060, 33750, 29175}\n",
      "dict_items([(\"Lemma('jaw.n.01.jaw')\", 3)])\n",
      "collecting tokens for  railroads\n",
      "indices:    {21957}\n",
      "dict_items([])\n",
      "collecting tokens for  victor\n",
      "indices:    {29039}\n",
      "dict_items([])\n",
      "collecting tokens for  corridor\n",
      "indices:    {5888, 35267, 6309, 9926, 17511, 6313, 6314, 17102, 8784, 17491, 36734}\n",
      "dict_items([(\"Lemma('corridor.n.01.corridor')\", 9)])\n",
      "collecting tokens for  clubs\n",
      "indices:    {24487, 20942, 27439, 179, 24598, 22103}\n",
      "dict_items([])\n",
      "collecting tokens for  heating\n",
      "indices:    {30145, 29412, 30150, 30151, 12170, 30128, 15198, 30196, 30138, 30139, 21245, 19294}\n",
      "dict_items([(\"Lemma('heat.v.01.heat')\", 1), (\"Lemma('heating.n.01.heating')\", 2)])\n",
      "collecting tokens for  nitrogen\n",
      "indices:    {34498}\n",
      "dict_items([])\n",
      "collecting tokens for  agriculture\n",
      "indices:    {2770, 23981, 2630}\n",
      "dict_items([(\"Lemma('agribusiness.n.01.agriculture')\", 1), (\"Lemma('farming.n.01.agriculture')\", 1)])\n",
      "collecting tokens for  infectious\n",
      "indices:    {3456, 8739, 3412, 3455}\n",
      "dict_items([(\"Lemma('infectious.s.01.infectious')\", 3)])\n",
      "collecting tokens for  fate\n",
      "indices:    {26501, 10790, 1393, 8850, 27703, 28121, 923, 23645, 20222}\n",
      "dict_items([(\"Lemma('destiny.n.01.fate')\", 3), (\"Lemma('destiny.n.02.fate')\", 1)])\n",
      "collecting tokens for  imposed\n",
      "indices:    {27745, 21281, 37155, 2532, 22730, 12522, 16396, 15471, 20179, 26901, 16408, 3228, 32125, 4607}\n",
      "dict_items([(\"Lemma('enforce.v.02.impose')\", 9), (\"Lemma('inflict.v.01.impose')\", 3), (\"Lemma('levy.v.01.impose')\", 2)])\n",
      "collecting tokens for  mechanism\n",
      "indices:    {3968, 3969, 4223, 3937, 3973, 3942, 4712, 22730, 3950, 30255, 32723, 3991, 31895, 3931, 21724, 3966, 22783}\n",
      "dict_items([(\"Lemma('mechanism.n.01.mechanism')\", 6), (\"Lemma('mechanism.n.03.mechanism')\", 2), (\"Lemma('mechanism.n.02.mechanism')\", 2)])\n",
      "collecting tokens for  mythological\n",
      "indices:    {1307, 13629}\n",
      "dict_items([(\"Lemma('fabulous.s.02.mythological')\", 2)])\n",
      "collecting tokens for  administered\n",
      "indices:    {23202, 14147, 15683, 19205, 7078, 15687, 16232, 23209, 16247, 15675}\n",
      "dict_items([(\"Lemma('administer.v.01.administer')\", 5), (\"Lemma('administer.v.04.administer')\", 1), (\"Lemma('administer.v.02.administer')\", 4)])\n",
      "collecting tokens for  resolve\n",
      "indices:    {23912, 31777, 31961}\n",
      "dict_items([(\"Lemma('decide.v.02.resolve')\", 1)])\n",
      "collecting tokens for  occurrences\n",
      "indices:    {16101, 15879, 15883, 15885, 2128, 4656, 15890, 9398, 23807}\n",
      "dict_items([(\"Lemma('happening.n.01.occurrence')\", 8)])\n",
      "collecting tokens for  mimesis\n",
      "indices:    {13650, 13626}\n",
      "dict_items([(\"Lemma('mimesis.n.01.mimesis')\", 2)])\n",
      "collecting tokens for  humble\n",
      "indices:    {16225, 28291, 32222, 13639, 31816, 31528, 8778, 32680, 31820, 32685, 24339, 25754, 23838}\n",
      "dict_items([(\"Lemma('humble.s.01.humble')\", 3), (\"Lemma('humble.v.01.humble')\", 1)])\n",
      "collecting tokens for  globe\n",
      "indices:    {3392, 26339, 10213, 13053, 23851, 27948, 24981, 20247, 35418, 1117, 1119}\n",
      "dict_items([(\"Lemma('earth.n.01.globe')\", 5)])\n",
      "collecting tokens for  differ\n",
      "indices:    {12289, 16173, 33198, 28689, 1778, 27100, 27260}\n",
      "dict_items([(\"Lemma('differ.v.01.differ')\", 7)])\n",
      "collecting tokens for  eaten\n",
      "indices:    {4832, 13572, 27181, 27245, 5614, 34996, 17972, 34908}\n",
      "dict_items([(\"Lemma('eat.v.01.eat')\", 7), (\"Lemma('eat.v.02.eat')\", 1)])\n",
      "collecting tokens for  narrative\n",
      "indices:    {31872, 2401, 2412, 2414, 2415, 2447, 2449, 26034, 26677, 13846, 2392}\n",
      "dict_items([(\"Lemma('narrative.n.01.narrative')\", 7), (\"Lemma('narrative.s.01.narrative')\", 1)])\n",
      "collecting tokens for  norm\n",
      "indices:    {28362}\n",
      "dict_items([])\n",
      "collecting tokens for  blast\n",
      "indices:    {194, 25411, 25415, 392, 30506, 20746, 543, 18256, 183, 5759}\n",
      "dict_items([(\"Lemma('blast.v.01.blast')\", 1), (\"Lemma('blast.n.01.blast')\", 2), (\"Lemma('blast.v.03.blast')\", 1), (\"Lemma('bang.n.02.blast')\", 1)])\n",
      "collecting tokens for  clerical\n",
      "indices:    {13249, 27302, 8, 13288, 7370, 20587, 21433, 23548}\n",
      "dict_items([(\"Lemma('clerical.a.01.clerical')\", 3), (\"Lemma('clerical.a.02.clerical')\", 1)])\n",
      "collecting tokens for  absorbed\n",
      "indices:    {3232, 13793, 3236, 3269, 22058, 5834, 110, 20398, 27537, 9329, 23571, 5202, 4149, 4150, 9362, 34683, 25820, 4126}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('absorb.v.01.absorb')\", 5), (\"Lemma('absorb.v.06.absorb')\", 1), (\"Lemma('captive.s.02.absorbed')\", 2), (\"Lemma('absorb.v.02.absorb')\", 3), (\"Lemma('absorb.v.03.absorb')\", 1), (\"Lemma('absorbed.s.02.absorbed')\", 1), (\"Lemma('absorb.v.04.absorb')\", 2), (\"Lemma('absorb.v.05.absorb')\", 2), (\"Lemma('steep.v.01.absorb')\", 1)])\n",
      "collecting tokens for  chlorine\n",
      "indices:    {3231, 3235, 3239, 3240, 3241, 3242, 3244, 3245, 3248, 3251, 3255, 3256, 3258, 3269, 3276, 3279, 3280, 3283, 3284, 3285, 3287, 3293, 3294, 3295, 3296, 3297, 30049, 30063}\n",
      "dict_items([(\"Lemma('chlorine.n.01.chlorine')\", 26)])\n",
      "collecting tokens for  tetrachloride\n",
      "indices:    {3264, 3297, 3266, 3235, 3269, 3239, 3241, 3275, 3276, 3244, 3281, 3253, 3254, 3287, 3256, 3257, 3294}\n",
      "dict_items([])\n",
      "collecting tokens for  placement\n",
      "indices:    {30202, 15003, 29750}\n",
      "dict_items([(\"Lemma('placement.n.02.placement')\", 1)])\n",
      "collecting tokens for  furnishings\n",
      "indices:    {36225, 2050, 2052, 5995, 28621, 17549, 22489, 19519}\n",
      "dict_items([])\n",
      "collecting tokens for  sung\n",
      "indices:    {15968, 27046, 26247, 26504, 8363, 747, 26348, 26347, 28021, 13877, 1054, 26296, 28025, 11035, 26430, 32671}\n",
      "dict_items([(\"Lemma('sing.v.02.sing')\", 2), (\"Lemma('sing.v.01.sing')\", 9)])\n",
      "collecting tokens for  counting\n",
      "indices:    {17125, 22854, 35690, 18506, 17111, 3276, 4397, 30543, 30994, 10263, 17722}\n",
      "dict_items([(\"Lemma('count.v.01.count')\", 6), (\"Lemma('consider.v.04.count')\", 1), (\"Lemma('count.v.06.count')\", 1), (\"Lemma('count.n.02.counting')\", 2)])\n",
      "collecting tokens for  shelters\n",
      "indices:    {15200, 15201, 11906, 15139, 15109, 15111, 25130, 20911, 25071, 25073, 28497, 15155, 11956, 15157, 24977, 25074, 28496, 15193}\n",
      "dict_items([(\"Lemma('shelter.n.02.shelter')\", 1), (\"Lemma('shelter.n.01.shelter')\", 7)])\n",
      "collecting tokens for  mechanisms\n",
      "indices:    {32130, 32997, 3238, 32904, 3945, 22668, 34670, 22737, 32858, 2623}\n",
      "dict_items([(\"Lemma('mechanism.n.02.mechanism')\", 1), (\"Lemma('mechanism.n.01.mechanism')\", 2)])\n",
      "collecting tokens for  energies\n",
      "indices:    {32165, 4678, 3238, 31882, 14195, 4728, 3292, 4669, 3039}\n",
      "dict_items([(\"Lemma('energy.n.01.energy')\", 2), (\"Lemma('energy.n.02.energy')\", 2), (\"Lemma('energy.n.03.energy')\", 1)])\n",
      "collecting tokens for  atoms\n",
      "indices:    {3072, 3076, 3077, 3084, 3086, 3087, 3088, 3090, 3091, 27941, 27942, 3238, 3244, 27950, 27958, 27965, 27971, 14790, 14793, 27979, 27981, 26833, 26834, 26835, 3306, 27253}\n",
      "dict_items([(\"Lemma('atom.n.01.atom')\", 10)])\n",
      "collecting tokens for  bath\n",
      "indices:    {35073, 11417, 3267, 21026, 7492, 14814, 31530, 35032, 30041, 19035, 14812, 734}\n",
      "dict_items([(\"Lemma('bathtub.n.01.bath')\", 1), (\"Lemma('bath.n.02.bath')\", 1), (\"Lemma('bath.n.01.bath')\", 4)])\n",
      "collecting tokens for  cleaned\n",
      "indices:    {7713, 10457}\n",
      "dict_items([(\"Lemma('clean.v.02.clean')\", 1)])\n",
      "collecting tokens for  flowing\n",
      "indices:    {32035, 19525, 31558, 31591, 11304, 7083, 30571, 14905, 7601, 32051, 2873, 21626, 3003, 3004}\n",
      "dict_items([(\"Lemma('run.v.06.flow')\", 5), (\"Lemma('flow.v.03.flow')\", 1), (\"Lemma('flow.n.01.flowing')\", 1), (\"Lemma('flow.v.01.flow')\", 3)])\n",
      "collecting tokens for  dances\n",
      "indices:    {11257, 26979}\n",
      "dict_items([(\"Lemma('dance.n.01.dance')\", 1)])\n",
      "collecting tokens for  complaint\n",
      "indices:    {30432, 4033, 24483, 21674, 14157, 25517, 25488, 21783, 4056, 23964}\n",
      "dict_items([(\"Lemma('ailment.n.01.complaint')\", 3)])\n",
      "collecting tokens for  myth\n",
      "indices:    {28033, 12708, 11036, 14407, 32104, 13642, 12939, 1359, 5016, 1308, 11032, 13916, 2302, 1310}\n",
      "dict_items([(\"Lemma('myth.n.01.myth')\", 11)])\n",
      "collecting tokens for  present-day\n",
      "indices:    {12486, 12461, 12238, 16063, 2642, 31062, 12471, 1430, 1372, 29311}\n",
      "dict_items([(\"Lemma('contemporary.s.02.present-day')\", 8)])\n",
      "collecting tokens for  bank\n",
      "indices:    {21890, 32478}\n",
      "dict_items([])\n",
      "collecting tokens for  shout\n",
      "indices:    {12214, 8647}\n",
      "dict_items([(\"Lemma('shout.v.01.shout')\", 2)])\n",
      "collecting tokens for  nineteenth\n",
      "indices:    {11266, 14596, 16426, 2347, 16413, 27989, 16439, 31997, 2301}\n",
      "dict_items([(\"Lemma('nineteenth.s.01.nineteenth')\", 7)])\n",
      "collecting tokens for  boiling\n",
      "indices:    {7232, 7618, 19810, 29410, 715, 7254, 21814, 10588}\n",
      "dict_items([(\"Lemma('boil.v.02.boil')\", 2), (\"Lemma('boil.v.01.boil')\", 1), (\"Lemma('boil.v.03.boil')\", 1), (\"Lemma('boiling.n.01.boiling')\", 1)])\n",
      "collecting tokens for  reliable\n",
      "indices:    {3332, 3338, 26188, 4814, 11697, 26418, 4242, 4786, 16383, 13975, 32890, 31803, 33084, 14847}\n",
      "dict_items([(\"Lemma('reliable.a.01.reliable')\", 8)])\n",
      "collecting tokens for  estimates\n",
      "indices:    {3065, 20670, 16383}\n",
      "dict_items([(\"Lemma('estimate.n.01.estimate')\", 2)])\n",
      "collecting tokens for  assurance\n",
      "indices:    {32450, 19397, 24198, 27399, 14314, 7276, 11697, 26002, 26897, 11281, 7293, 35967}\n",
      "dict_items([(\"Lemma('assurance.n.01.assurance')\", 5), (\"Lemma('assurance.n.02.assurance')\", 1)])\n",
      "collecting tokens for  communion\n",
      "indices:    {8208, 27281, 1490, 4657, 13498}\n",
      "dict_items([(\"Lemma('communion.n.01.Communion')\", 3), (\"Lemma('communion.n.02.communion')\", 1)])\n",
      "collecting tokens for  sympathetic\n",
      "indices:    {4226, 4227, 4231, 4747, 4237, 4238, 4239, 4240, 27025, 4246, 4249, 14118, 4274, 4276, 4678, 26578, 13527, 6114, 14696, 2156, 4207, 20468, 18299, 11260}\n",
      "dict_items([(\"Lemma('sympathetic.a.01.sympathetic')\", 13), (\"Lemma('charitable.s.03.sympathetic')\", 1), (\"Lemma('sympathetic.a.02.sympathetic')\", 6)])\n",
      "collecting tokens for  fellowship\n",
      "indices:    {27665, 27691, 27269}\n",
      "dict_items([])\n",
      "collecting tokens for  vent\n",
      "indices:    {15141}\n",
      "dict_items([(\"Lemma('vent.n.01.vent')\", 1)])\n",
      "collecting tokens for  impact\n",
      "indices:    {29058, 24195, 24068, 2565, 3334, 3332, 21637, 22025, 26756, 3339, 3341, 34062, 1810, 29077, 8471, 3358, 15520, 26921, 16432, 26748, 24899, 22085, 32464, 26204, 27996, 32869, 31205, 30184, 31849, 32881, 16245, 3324, 19071}\n",
      "dict_items([(\"Lemma('impact.n.01.impact')\", 6), (\"Lemma('impact.n.02.impact')\", 6), (\"Lemma('impingement.n.01.impact')\", 1)])\n",
      "collecting tokens for  anxious\n",
      "indices:    {25761, 15714, 15715, 27429, 4807, 6823, 15721, 7116, 27213, 15725, 24687, 15728, 5110, 37110, 7355, 30877, 20126, 15711}\n",
      "dict_items([(\"Lemma('anxious.s.01.anxious')\", 2)])\n",
      "collecting tokens for  shy\n",
      "indices:    {13049, 8380, 13793, 19207}\n",
      "dict_items([])\n",
      "collecting tokens for  bunks\n",
      "indices:    {15156, 11613}\n",
      "dict_items([(\"Lemma('berth.n.03.bunk')\", 1), (\"Lemma('bunk.n.01.bunk')\", 1)])\n",
      "collecting tokens for  conditioned\n",
      "indices:    {21021, 4261, 20359, 4264, 4265, 14332, 30191, 27088, 4207, 15447, 4249, 4250, 4251, 4252, 4253, 4254}\n",
      "dict_items([(\"Lemma('stipulate.v.01.condition')\", 1), (\"Lemma('condition.v.01.condition')\", 2), (\"Lemma('discipline.v.01.condition')\", 1), (\"Lemma('conditional_reflex.n.01.conditioned_response')\", 1)])\n",
      "collecting tokens for  sensing\n",
      "indices:    {5857, 10596, 11401, 18416, 4657}\n",
      "dict_items([(\"Lemma('feel.v.03.sense')\", 4), (\"Lemma('detection.n.01.sensing')\", 1)])\n",
      "collecting tokens for  neglect\n",
      "indices:    {27580, 6846, 6087}\n",
      "dict_items([(\"Lemma('disregard.n.02.neglect')\", 1), (\"Lemma('neglect.n.02.neglect')\", 1)])\n",
      "collecting tokens for  idle\n",
      "indices:    {355, 18245, 6409, 2452, 18006, 25529, 27322, 22203}\n",
      "dict_items([(\"Lemma('idle.a.01.idle')\", 3), (\"Lemma('baseless.s.01.idle')\", 1)])\n",
      "collecting tokens for  forcing\n",
      "indices:    {14208, 18663, 34087, 25327, 12239, 5041, 34070, 23487}\n",
      "dict_items([(\"Lemma('push.v.01.force')\", 1), (\"Lemma('impel.v.01.force')\", 1), (\"Lemma('coerce.v.01.force')\", 4), (\"Lemma('wedge.v.02.force')\", 1), (\"Lemma('force.v.04.force')\", 1)])\n",
      "collecting tokens for  1930\n",
      "indices:    {31204, 14341, 1927, 14537, 21962, 11339, 31629, 33038, 23312, 5203, 12310, 21847, 2808, 23004, 24830}\n",
      "dict_items([])\n",
      "collecting tokens for  weep\n",
      "indices:    {937, 6794, 26405, 7193}\n",
      "dict_items([(\"Lemma('cry.v.02.weep')\", 3)])\n",
      "collecting tokens for  pen\n",
      "indices:    {22251}\n",
      "dict_items([])\n",
      "collecting tokens for  restrict\n",
      "indices:    {11748, 22887, 4424, 30188, 11217, 3992}\n",
      "dict_items([(\"Lemma('restrict.v.03.restrict')\", 3), (\"Lemma('qualify.v.03.restrict')\", 1), (\"Lemma('restrict.v.01.restrict')\", 2)])\n",
      "collecting tokens for  crouched\n",
      "indices:    {35394, 35435, 6895, 16592, 8495, 7634, 7219, 9337, 8539}\n",
      "dict_items([(\"Lemma('crouch.v.01.crouch')\", 7), (\"Lemma('squat.v.01.crouch')\", 2)])\n",
      "collecting tokens for  policemen\n",
      "indices:    {36929, 21319, 25000, 12683, 20139, 36939, 23326, 12689, 9630}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('policeman.n.01.policeman')\", 3)])\n",
      "collecting tokens for  investigate\n",
      "indices:    {13889, 32770, 20513, 18724, 5124, 2, 18438, 20718}\n",
      "dict_items([(\"Lemma('investigate.v.02.investigate')\", 7), (\"Lemma('investigate.v.01.investigate')\", 1)])\n",
      "collecting tokens for  movies\n",
      "indices:    {36995, 21004, 22419, 2452, 22420, 36883, 2460, 2463, 25643, 9653, 19525, 2379, 340, 2390, 2391, 2394, 1117, 1118, 2409, 16878, 2415, 2419, 2422}\n",
      "dict_items([(\"Lemma('movie.n.01.movie')\", 15)])\n",
      "collecting tokens for  cheap\n",
      "indices:    {23493, 8395, 7468, 6000, 19541, 25654, 29783, 10453, 5434}\n",
      "dict_items([(\"Lemma('brassy.s.02.cheap')\", 1), (\"Lemma('cheap.a.01.cheap')\", 4)])\n",
      "collecting tokens for  journalism\n",
      "indices:    {28562, 25915, 26674, 10655}\n",
      "dict_items([(\"Lemma('journalism.n.01.journalism')\", 1)])\n",
      "collecting tokens for  wayne\n",
      "indices:    {20902}\n",
      "dict_items([])\n",
      "collecting tokens for  miller\n",
      "indices:    {35809}\n",
      "dict_items([])\n",
      "collecting tokens for  dimension\n",
      "indices:    {22688, 4289, 2149, 25446, 28808, 16104, 7887, 2162, 15445, 26295, 32026, 1085}\n",
      "dict_items([(\"Lemma('property.n.04.dimension')\", 3), (\"Lemma('dimension.n.01.dimension')\", 2)])\n",
      "collecting tokens for  threaten\n",
      "indices:    {14948, 23497, 16555, 907, 21900, 14960, 23568, 12306, 28465}\n",
      "dict_items([(\"Lemma('endanger.v.01.threaten')\", 6), (\"Lemma('threaten.v.02.threaten')\", 3)])\n",
      "collecting tokens for  outset\n",
      "indices:    {28512, 1728, 26470, 21226, 31627, 24138, 15249, 16402, 2295, 23736}\n",
      "dict_items([(\"Lemma('beginning.n.02.outset')\", 4)])\n",
      "collecting tokens for  emerge\n",
      "indices:    {4576, 11234, 14690, 20229, 11463, 3624, 3625, 1066, 16395, 21420, 3597, 12789, 15830}\n",
      "dict_items([(\"Lemma('emerge.v.04.emerge')\", 1), (\"Lemma('emerge.v.01.emerge')\", 9), (\"Lemma('issue.v.04.emerge')\", 1), (\"Lemma('emerge.v.03.emerge')\", 2)])\n",
      "collecting tokens for  holiday\n",
      "indices:    {11842, 11845, 25063, 8489, 30893, 11922, 22836, 5205, 8248, 20858, 15549, 11743}\n",
      "dict_items([(\"Lemma('vacation.n.01.holiday')\", 5), (\"Lemma('holiday.n.02.holiday')\", 2)])\n",
      "collecting tokens for  communications\n",
      "indices:    {23705, 37059, 4590, 21534, 31321, 15485, 4606, 12574}\n",
      "dict_items([(\"Lemma('communication.n.02.communication')\", 4)])\n",
      "collecting tokens for  curtain\n",
      "indices:    {26072, 24626, 26251, 36018}\n",
      "dict_items([])\n",
      "collecting tokens for  tube\n",
      "indices:    {14816, 32446}\n",
      "dict_items([(\"Lemma('tube.n.01.tube')\", 1)])\n",
      "collecting tokens for  vessels\n",
      "indices:    {14980, 3786, 28458, 3827, 11380, 11411, 4087, 4091, 32383}\n",
      "dict_items([(\"Lemma('vessel.n.01.vessel')\", 4), (\"Lemma('vessel.n.02.vessel')\", 1)])\n",
      "collecting tokens for  freeman\n",
      "indices:    {23981}\n",
      "dict_items([])\n",
      "collecting tokens for  wider\n",
      "indices:    {16294, 24695}\n",
      "dict_items([(\"Lemma('across-the-board.s.01.wide')\", 1)])\n",
      "collecting tokens for  historic\n",
      "indices:    {4576, 37089, 29984, 23584, 13792, 21890, 29319, 32648, 27758, 20591, 20593, 20627, 21716, 20605, 29238, 32630, 29245, 29247}\n",
      "dict_items([])\n",
      "collecting tokens for  modernization\n",
      "indices:    {4576, 4609, 4615, 4616, 4588, 4591, 23479, 23482, 31837, 15486, 4607}\n",
      "dict_items([(\"Lemma('modernization.n.01.modernization')\", 8)])\n",
      "collecting tokens for  ambitions\n",
      "indices:    {4576, 26757, 32235, 8236, 27152, 13906, 14195, 17339, 31740}\n",
      "dict_items([(\"Lemma('ambition.n.01.ambition')\", 5)])\n",
      "collecting tokens for  competence\n",
      "indices:    {4576, 2084, 24198, 23722, 13291, 13290, 14223, 4596, 15766, 33271, 21083}\n",
      "dict_items([(\"Lemma('competence.n.01.competence')\", 7)])\n",
      "collecting tokens for  nerve\n",
      "indices:    {4576, 31017, 19466, 29395, 8149, 20918, 730, 36826, 18171, 31324}\n",
      "dict_items([(\"Lemma('heart.n.03.nerve')\", 4), (\"Lemma('nerve.n.01.nerve')\", 1)])\n",
      "collecting tokens for  1900\n",
      "indices:    {5189, 5191, 21834, 31788, 847, 5172, 21846, 13911, 2333}\n",
      "dict_items([])\n",
      "collecting tokens for  reward\n",
      "indices:    {17824, 11237, 13964, 29326, 12656, 20754, 36947, 20755, 9490, 26966, 4730, 19387}\n",
      "dict_items([(\"Lemma('wages.n.01.reward')\", 4), (\"Lemma('reward.n.03.reward')\", 1), (\"Lemma('reward.n.02.reward')\", 1)])\n",
      "collecting tokens for  describes\n",
      "indices:    {899, 13830, 3432, 16329, 23211, 13867, 33004, 32082, 27093, 2046, 10616, 14074, 1470}\n",
      "dict_items([(\"Lemma('report.v.01.describe')\", 3), (\"Lemma('describe.v.01.describe')\", 10)])\n",
      "collecting tokens for  speeches\n",
      "indices:    {26882, 32489, 4746, 10508, 20240, 16016, 26038, 9336, 761, 26586, 37147, 24219}\n",
      "dict_items([(\"Lemma('address.n.03.speech')\", 5)])\n",
      "collecting tokens for  operators\n",
      "indices:    {11747, 4356, 4357, 901, 15785, 4346, 4280, 22809, 25210, 5150, 24703}\n",
      "dict_items([(\"Lemma('operator.n.01.operator')\", 4), (\"Lemma('operator.n.02.operator')\", 2), (\"Lemma('telephone_operator.n.01.telephone_operator')\", 1), (\"Lemma('operator.n.03.operator')\", 1)])\n",
      "collecting tokens for  outfit\n",
      "indices:    {19681, 18019, 11043, 901, 29098, 19211, 22287, 29104, 18001, 5909, 16631, 18008}\n",
      "dict_items([(\"Lemma('outfit.n.01.outfit')\", 7), (\"Lemma('outfit.n.02.outfit')\", 1), (\"Lemma('kit.n.02.outfit')\", 1)])\n",
      "collecting tokens for  originally\n",
      "indices:    {24769, 31618, 24195, 26020, 28710, 32510, 1490, 5397, 23829, 23293, 29374}\n",
      "dict_items([(\"Lemma('primitively.r.01.originally')\", 1), (\"Lemma('originally.r.01.originally')\", 1)])\n",
      "collecting tokens for  structures\n",
      "indices:    {14177, 31524, 21244, 3423, 30397, 32904, 13613, 13838, 4592, 29971, 3475, 16118, 9143, 21241, 2556, 16125, 12796, 2047}\n",
      "dict_items([(\"Lemma('structure.n.01.structure')\", 7), (\"Lemma('structure.n.04.structure')\", 1), (\"Lemma('structure.n.03.structure')\", 2)])\n",
      "collecting tokens for  grades\n",
      "indices:    {15680, 769, 29090, 24420, 13276, 13262, 32275, 16179, 13241, 30972, 30397}\n",
      "dict_items([(\"Lemma('class.n.02.grade')\", 5), (\"Lemma('grade.n.02.grade')\", 1)])\n",
      "collecting tokens for  toynbee\n",
      "indices:    {27816}\n",
      "dict_items([])\n",
      "collecting tokens for  soviets\n",
      "indices:    {12940}\n",
      "dict_items([(\"Lemma('soviets.n.01.Soviets')\", 1)])\n",
      "collecting tokens for  un\n",
      "indices:    {25850}\n",
      "dict_items([])\n",
      "collecting tokens for  boots\n",
      "indices:    {30598, 29159, 19270, 17864, 36714, 7883, 6956, 29197, 16719, 7985, 8563, 8596, 18266, 17885}\n",
      "dict_items([(\"Lemma('boot.n.01.boot')\", 9)])\n",
      "collecting tokens for  endured\n",
      "indices:    {1412, 4840, 34825, 31600, 37137, 37139, 13557, 10261}\n",
      "dict_items([(\"Lemma('digest.v.03.endure')\", 3), (\"Lemma('survive.v.01.endure')\", 2), (\"Lemma('suffer.v.01.endure')\", 1), (\"Lemma('weather.v.01.endure')\", 2)])\n",
      "collecting tokens for  documents\n",
      "indices:    {26192, 2717}\n",
      "dict_items([])\n",
      "collecting tokens for  lacking\n",
      "indices:    {23118, 16335, 1749, 26102, 26295, 24831}\n",
      "dict_items([(\"Lemma('deficient.s.01.lacking')\", 1), (\"Lemma('miss.v.06.lack')\", 1)])\n",
      "collecting tokens for  nicely\n",
      "indices:    {5443, 17703, 6088, 28970, 5806, 29426, 26011, 26267}\n",
      "dict_items([(\"Lemma('nicely.r.01.nicely')\", 4)])\n",
      "collecting tokens for  rocks\n",
      "indices:    {18306, 5443, 8867, 1229, 12793, 12783, 36019, 29300, 25274, 18265, 7802, 9147}\n",
      "dict_items([(\"Lemma('rock.n.01.rock')\", 8), (\"Lemma('rock.n.02.rock')\", 1)])\n",
      "collecting tokens for  distinctly\n",
      "indices:    {15841, 1733, 17769, 5228, 22287, 31792, 27089, 3827, 7767}\n",
      "dict_items([(\"Lemma('distinctly.r.01.distinctly')\", 6)])\n",
      "collecting tokens for  row\n",
      "indices:    {29222, 20998, 29673, 25132, 29677, 33423, 274, 30995, 28819, 29273, 24671}\n",
      "dict_items([(\"Lemma('row.v.01.row')\", 1)])\n",
      "collecting tokens for  stupid\n",
      "indices:    {17888, 33609, 5212, 13970, 36792, 10107, 34652, 8670}\n",
      "dict_items([(\"Lemma('stupid.a.01.stupid')\", 5)])\n",
      "collecting tokens for  seed\n",
      "indices:    {21856, 13569, 8929, 1669, 28198, 12488, 35977, 12490, 19273, 19276, 1675, 12489, 19275, 7952, 1619, 1655}\n",
      "dict_items([(\"Lemma('seed.n.02.seed')\", 4), (\"Lemma('seed.n.01.seed')\", 4), (\"Lemma('seed.v.01.seed')\", 1)])\n",
      "collecting tokens for  radical\n",
      "indices:    {5363, 3236, 37094, 16151}\n",
      "dict_items([(\"Lemma('group.n.02.radical')\", 1), (\"Lemma('revolutionary.s.01.radical')\", 1)])\n",
      "collecting tokens for  congregation\n",
      "indices:    {13381, 13351, 13355, 7565, 27661, 9997, 13328, 13390, 13358, 13364, 13338, 21564, 36189, 13343}\n",
      "dict_items([(\"Lemma('congregation.n.01.congregation')\", 10)])\n",
      "collecting tokens for  rocked\n",
      "indices:    {17665, 29025, 36746, 30506, 17610, 31440, 36753, 6363}\n",
      "dict_items([(\"Lemma('rock.v.01.rock')\", 4)])\n",
      "collecting tokens for  pursue\n",
      "indices:    {31746, 32674, 11113, 17865, 14923, 30252, 32049, 11475}\n",
      "dict_items([(\"Lemma('pursue.v.04.pursue')\", 2), (\"Lemma('quest_for.v.01.pursue')\", 3), (\"Lemma('prosecute.v.03.pursue')\", 3)])\n",
      "collecting tokens for  viewed\n",
      "indices:    {16456, 24598}\n",
      "dict_items([(\"Lemma('see.v.05.view')\", 1), (\"Lemma('view.v.02.view')\", 1)])\n",
      "collecting tokens for  weak\n",
      "indices:    {32096, 3137, 3045, 23814, 2024, 1674, 1643, 8761, 15730, 1970, 8564, 12052, 27222, 35636, 17561, 27452, 26173, 36412}\n",
      "dict_items([(\"Lemma('weak.a.01.weak')\", 8), (\"Lemma('watery.s.04.weak')\", 2)])\n",
      "collecting tokens for  bench\n",
      "indices:    {1562, 19990}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('bench.n.01.bench')\", 1)])\n",
      "collecting tokens for  variety\n",
      "indices:    {11906, 32900, 4999, 10123, 13848, 14618, 30747, 10655, 4385, 22566, 14634, 30124, 3504, 29237, 822, 15417, 698, 26945, 25668, 30152, 12232, 21583, 11352, 32858, 11228, 15839, 26335, 27617, 5475, 31591, 28648, 33129, 23530, 13676, 32878, 16251}\n",
      "dict_items([(\"Lemma('diverseness.n.01.variety')\", 3), (\"Lemma('assortment.n.01.variety')\", 12)])\n",
      "collecting tokens for  soils\n",
      "indices:    {3200, 3202, 3203, 12136, 3213, 3185, 3187, 3220, 3197, 3189, 30420, 3196, 3229, 3199}\n",
      "dict_items([(\"Lemma('dirt.n.02.soil')\", 12), (\"Lemma('land.n.02.soil')\", 1)])\n",
      "collecting tokens for  constituents\n",
      "indices:    {3203, 10628, 22858, 3180, 3183, 3229, 24218, 14941}\n",
      "dict_items([(\"Lemma('component.n.03.constituent')\", 4), (\"Lemma('constituent.n.02.constituent')\", 2)])\n",
      "collecting tokens for  wings\n",
      "indices:    {7810, 21731, 35332, 9188, 30536, 26121, 3593, 26891, 30506, 15466, 15541, 9942, 7835}\n",
      "dict_items([(\"Lemma('wing.n.01.wing')\", 4), (\"Lemma('wing.n.02.wing')\", 1), (\"Lemma('wing.n.03.wing')\", 1), (\"Lemma('wing.n.04.wing')\", 1)])\n",
      "collecting tokens for  individualism\n",
      "indices:    {13984, 13827, 13894, 14092, 13901, 13902, 14098, 13907, 13979, 13918, 13951}\n",
      "dict_items([(\"Lemma('individuality.n.01.individualism')\", 9), (\"Lemma('individualism.n.02.individualism')\", 1), (\"Lemma('individualism.n.03.individualism')\", 1)])\n",
      "collecting tokens for  protestants\n",
      "indices:    {25499}\n",
      "dict_items([])\n",
      "collecting tokens for  lucien\n",
      "indices:    {16742}\n",
      "dict_items([(\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  handful\n",
      "indices:    {3, 18469, 7340, 30418, 26260, 25753, 5275, 30205, 25695}\n",
      "dict_items([(\"Lemma('handful.n.02.handful')\", 2), (\"Lemma('handful.n.01.handful')\", 2)])\n",
      "collecting tokens for  polynomial\n",
      "indices:    {4352, 4356, 4362, 4363, 4366, 4379, 4281, 4285, 4287, 4292, 4294, 4297, 4299, 4303, 4307, 4313, 4320, 4321, 4323, 4325, 4326, 4327, 4338, 4340, 4345}\n",
      "dict_items([(\"Lemma('polynomial.n.01.polynomial')\", 24)])\n",
      "collecting tokens for  hymn\n",
      "indices:    {27372, 25332, 28025, 13754, 15965}\n",
      "dict_items([(\"Lemma('hymn.n.01.hymn')\", 1)])\n",
      "collecting tokens for  becoming\n",
      "indices:    {26755, 12936, 23688, 36493, 7822, 19604, 1818, 4635, 7836, 31901, 12191, 29345, 12067, 31909, 26792, 3500, 10800, 1335, 8890, 22844, 26817, 33219, 5450, 16204, 32845, 7629, 26572, 37074, 28263, 12007, 26987, 15724, 3053, 11633, 2805, 26361, 7036, 1662}\n",
      "dict_items([(\"Lemma('become.v.02.become')\", 13), (\"Lemma('become.v.01.become')\", 23)])\n",
      "collecting tokens for  reflection\n",
      "indices:    {4995, 10723, 31174, 16423, 2952, 27145, 13642, 14670, 14703, 14671, 13810, 17590, 29174, 24182, 13531, 17596}\n",
      "dict_items([(\"Lemma('expression.n.02.reflection')\", 3), (\"Lemma('contemplation.n.02.reflection')\", 5), (\"Lemma('reflection.n.05.reflection')\", 2), (\"Lemma('reflection.n.02.reflection')\", 1)])\n",
      "collecting tokens for  notices\n",
      "indices:    {26563, 18212, 18308, 37155, 22247, 4755, 18199, 33375}\n",
      "dict_items([(\"Lemma('notice.n.01.notice')\", 3), (\"Lemma('poster.n.01.notice')\", 1)])\n",
      "collecting tokens for  appropriated\n",
      "indices:    {25094, 14886, 32361, 13645, 32365, 14898, 14748}\n",
      "dict_items([(\"Lemma('allow.v.04.appropriate')\", 7)])\n",
      "collecting tokens for  lands\n",
      "indices:    {26945, 1894, 13831, 1895, 25739, 14766, 25171, 7676, 27733, 30396, 32638}\n",
      "dict_items([(\"Lemma('country.n.02.land')\", 1), (\"Lemma('domain.n.02.land')\", 1), (\"Lemma('land.n.01.land')\", 2)])\n",
      "collecting tokens for  conservation\n",
      "indices:    {4722, 21708, 30406}\n",
      "dict_items([(\"Lemma('conservation.n.01.conservation')\", 1)])\n",
      "collecting tokens for  affected\n",
      "indices:    {14081, 13710, 31006, 13728, 13730, 25391, 25392, 4922, 12224, 31811, 14534, 1864, 16328, 16344, 730, 36709, 1894, 25581, 20335, 4849, 24945, 36979, 24178}\n",
      "dict_items([(\"Lemma('affect.v.01.affect')\", 10), (\"Lemma('affect.v.02.affect')\", 3), (\"Lemma('feign.v.01.affect')\", 1), (\"Lemma('affected.a.01.affected')\", 5), (\"Lemma('affected.a.02.affected')\", 1), (\"Lemma('involve.v.01.affect')\", 1)])\n",
      "collecting tokens for  spaces\n",
      "indices:    {24034, 4292, 32773, 4358, 4357, 11944, 13615, 4369, 10097}\n",
      "dict_items([(\"Lemma('space.n.02.space')\", 2), (\"Lemma('space.n.05.space')\", 1)])\n",
      "collecting tokens for  ordinarily\n",
      "indices:    {23328, 23207, 16012, 3409, 11122}\n",
      "dict_items([(\"Lemma('normally.r.01.ordinarily')\", 3)])\n",
      "collecting tokens for  tastes\n",
      "indices:    {2472, 27549}\n",
      "dict_items([(\"Lemma('preference.n.01.taste')\", 1)])\n",
      "collecting tokens for  strictly\n",
      "indices:    {3719, 18601, 33070, 28686, 13298, 20788, 16372, 4438, 26522, 13534, 1310}\n",
      "dict_items([(\"Lemma('strictly.r.01.strictly')\", 4), (\"Lemma('strictly.r.02.strictly')\", 2)])\n",
      "collecting tokens for  tail\n",
      "indices:    {22464, 21731, 16164, 27019, 7244, 18861, 28977, 3763, 886, 10680, 34425, 30588}\n",
      "dict_items([(\"Lemma('fag_end.n.01.tail')\", 2), (\"Lemma('buttocks.n.01.tail')\", 1), (\"Lemma('tail.n.01.tail')\", 3)])\n",
      "collecting tokens for  emotionally\n",
      "indices:    {32865, 16805, 20233, 15985, 24529}\n",
      "dict_items([(\"Lemma('emotionally.r.02.emotionally')\", 1), (\"Lemma('emotionally.r.01.emotionally')\", 1)])\n",
      "collecting tokens for  scratching\n",
      "indices:    {7188}\n",
      "dict_items([(\"Lemma('rub.v.02.scratch')\", 1)])\n",
      "collecting tokens for  bore\n",
      "indices:    {27302, 28902, 29099, 24305, 24312}\n",
      "dict_items([(\"Lemma('bear.v.01.bear')\", 1), (\"Lemma('bore.v.01.bore')\", 2)])\n",
      "collecting tokens for  trembling\n",
      "indices:    {8850, 24224, 8356, 18853, 24234, 6326, 19254, 10936, 10937, 6843, 33726, 6603, 33740, 7759, 16977, 19161, 8676, 12015, 8817, 10748}\n",
      "dict_items([(\"Lemma('shaky.s.02.trembling')\", 7), (\"Lemma('shaking.n.02.trembling')\", 1), (\"Lemma('tremble.v.01.tremble')\", 2)])\n",
      "collecting tokens for  28\n",
      "indices:    {15105, 23426, 15490, 29963, 24594, 27031, 12568, 12313, 28954, 28573, 28574, 27037, 29984, 929, 20642, 20654, 20655, 20656, 945, 952, 30269, 20168, 29002, 5194, 21323, 3157, 13150, 25697, 21229, 28798}\n",
      "dict_items([(\"Lemma('twenty-eight.s.01.28')\", 4), (\"Lemma('twenty-eighth.s.01.twenty-eighth')\", 2)])\n",
      "collecting tokens for  enters\n",
      "indices:    {26660, 27880, 28617, 31019, 14258, 2035, 2424, 1146, 32028}\n",
      "dict_items([(\"Lemma('enter.v.01.enter')\", 6), (\"Lemma('figure.v.02.enter')\", 2), (\"Lemma('enter.v.06.enter')\", 1)])\n",
      "collecting tokens for  orthodontist\n",
      "indices:    {30976, 31046, 31019, 31020, 31068, 31060, 31030, 31063, 31004, 31037}\n",
      "dict_items([])\n",
      "collecting tokens for  overseas\n",
      "indices:    {28520, 30217, 36456, 27119, 15408, 15407, 27034, 20541, 6046}\n",
      "dict_items([(\"Lemma('overseas.r.02.overseas')\", 1), (\"Lemma('oversea.r.01.overseas')\", 1), (\"Lemma('abroad.s.01.overseas')\", 1)])\n",
      "collecting tokens for  possessed\n",
      "indices:    {7363, 17259, 32653, 5742, 10575, 28112, 18705, 26194, 9939, 28084, 1460, 9527, 13688, 35676}\n",
      "dict_items([(\"Lemma('possess.v.01.possess')\", 9), (\"Lemma('own.v.01.possess')\", 4), (\"Lemma('obsessed.s.02.possessed')\", 1)])\n",
      "collecting tokens for  warmed\n",
      "indices:    {22534, 30570, 9163, 36429, 9939, 22132, 410, 34140}\n",
      "dict_items([(\"Lemma('warm.v.01.warm')\", 1), (\"Lemma('warm_up.v.01.warm_up')\", 1)])\n",
      "collecting tokens for  responded\n",
      "indices:    {28162, 32194, 10947, 5222, 35309, 1231, 18800, 25040, 18771, 13462, 35991, 22679, 27774, 33211, 9342}\n",
      "dict_items([(\"Lemma('react.v.01.respond')\", 11), (\"Lemma('answer.v.01.respond')\", 3), (\"Lemma('respond.v.03.respond')\", 1)])\n",
      "collecting tokens for  beaches\n",
      "indices:    {29344, 37024, 29248, 14947, 1866, 1899, 12747, 29298, 37138, 12728, 29273, 12733}\n",
      "dict_items([(\"Lemma('beach.n.01.beach')\", 6)])\n",
      "collecting tokens for  proclaimed\n",
      "indices:    {5347, 6824, 14984, 18955, 9740, 10101, 16213, 11445, 27290}\n",
      "dict_items([(\"Lemma('predicate.v.02.proclaim')\", 2), (\"Lemma('proclaim.v.01.proclaim')\", 3), (\"Lemma('proclaim.v.02.proclaim')\", 2), (\"Lemma('announced.s.01.proclaimed')\", 2)])\n",
      "collecting tokens for  celebration\n",
      "indices:    {5601, 26980, 21741, 32630, 29943, 27003, 2590}\n",
      "dict_items([(\"Lemma('celebration.n.01.celebration')\", 2)])\n",
      "collecting tokens for  paradise\n",
      "indices:    {142}\n",
      "dict_items([(\"Lemma('location.n.01.location')\", 1)])\n",
      "collecting tokens for  vincent\n",
      "indices:    {21194}\n",
      "dict_items([])\n",
      "collecting tokens for  gospel\n",
      "indices:    {27334}\n",
      "dict_items([])\n",
      "collecting tokens for  showmanship\n",
      "indices:    {21595, 28582, 28607}\n",
      "dict_items([])\n",
      "collecting tokens for  weekly\n",
      "indices:    {10656, 24675, 24677, 30472, 6044, 5523, 5525, 6582, 1369, 2716}\n",
      "dict_items([])\n",
      "collecting tokens for  tragic\n",
      "indices:    {19424, 27031, 9731, 26572, 12204, 13038, 1263, 26575, 9838, 23852, 25395, 26903, 27480, 13849, 893, 12350}\n",
      "dict_items([(\"Lemma('tragic.s.01.tragic')\", 6), (\"Lemma('tragic.a.02.tragic')\", 3)])\n",
      "collecting tokens for  bearing\n",
      "indices:    {12193, 25506, 32771, 35939, 32774, 12841, 33834, 20362, 1103, 26897, 9586, 2037, 7672, 13468, 12190}\n",
      "dict_items([(\"Lemma('bear.v.01.bear')\", 6), (\"Lemma('bearing.n.01.bearing')\", 1), (\"Lemma('bear.v.04.bear')\", 2), (\"Lemma('bearing.n.03.bearing')\", 1)])\n",
      "collecting tokens for  continental\n",
      "indices:    {498}\n",
      "dict_items([(\"Lemma('group.n.01.group')\", 1)])\n",
      "collecting tokens for  disagreement\n",
      "indices:    {20678, 9546, 22635, 24204, 2835, 16378, 21180, 3807}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('disagreement.n.01.disagreement')\", 2), (\"Lemma('discrepancy.n.01.disagreement')\", 2)])\n",
      "collecting tokens for  apartments\n",
      "indices:    {15209, 25144, 17549, 17551, 21234, 25140, 21237, 21240, 21242, 21244}\n",
      "dict_items([(\"Lemma('apartment.n.01.apartment')\", 3)])\n",
      "collecting tokens for  confrontation\n",
      "indices:    {22592, 25890}\n",
      "dict_items([])\n",
      "collecting tokens for  depression\n",
      "indices:    {14341, 31398, 5485, 14097, 19293, 24831}\n",
      "dict_items([(\"Lemma('depression.n.02.depression')\", 3), (\"Lemma('depression.n.04.depression')\", 1)])\n",
      "collecting tokens for  jersey\n",
      "indices:    {7830}\n",
      "dict_items([(\"Lemma('new_jersey.n.01.New_Jersey')\", 1)])\n",
      "collecting tokens for  surprising\n",
      "indices:    {23041, 23042, 28034, 31491, 14593, 5139, 30487, 27801, 32042, 1965, 30257, 30266, 27844, 16456, 31691, 23884, 26060, 5212, 5213, 9182, 14049, 3702, 25723}\n",
      "dict_items([(\"Lemma('surprising.a.01.surprising')\", 8)])\n",
      "collecting tokens for  beds\n",
      "indices:    {21664, 36139, 23025, 9201, 37075, 11955, 36149, 7379, 29403}\n",
      "dict_items([(\"Lemma('bed.n.01.bed')\", 2)])\n",
      "collecting tokens for  synthetic\n",
      "indices:    {3147, 5406, 2063}\n",
      "dict_items([(\"Lemma('man-made.s.01.synthetic')\", 2)])\n",
      "collecting tokens for  cubism\n",
      "indices:    {5411}\n",
      "dict_items([(\"Lemma('cubism.n.01.cubism')\", 1)])\n",
      "collecting tokens for  picasso\n",
      "indices:    {5399}\n",
      "dict_items([(\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  braque\n",
      "indices:    {5399}\n",
      "dict_items([(\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  actives\n",
      "indices:    {3204, 3147, 3212, 3150, 3151, 3216, 3223, 3167}\n",
      "dict_items([(\"Lemma('active_agent.n.01.active')\", 8)])\n",
      "collecting tokens for  priests\n",
      "indices:    {31554, 27779, 25353, 1418, 21419, 5275, 28111, 1423, 1431, 11035}\n",
      "dict_items([(\"Lemma('priest.n.01.priest')\", 5)])\n",
      "collecting tokens for  tappets\n",
      "indices:    {28771, 28814, 28720, 28722, 28723, 28788, 28787, 28725, 28727, 28730}\n",
      "dict_items([])\n",
      "collecting tokens for  hydrogen\n",
      "indices:    {3074, 3079, 3084, 3087, 3088, 3090, 3091, 27924, 27925, 27927, 27929, 27930, 27935, 822, 14790, 14793, 26826, 26829, 26832, 26833, 26834, 26835, 3936, 3051, 3054, 27253, 14845, 14847}\n",
      "dict_items([(\"Lemma('hydrogen.n.01.hydrogen')\", 6)])\n",
      "collecting tokens for  retiring\n",
      "indices:    {30592, 290, 31716, 20908, 20591, 12019, 30644, 20471}\n",
      "dict_items([(\"Lemma('retire.v.01.retire')\", 3), (\"Lemma('retire.v.02.retire')\", 2)])\n",
      "collecting tokens for  convention\n",
      "indices:    {24617, 30475, 11325}\n",
      "dict_items([(\"Lemma('convention.n.02.convention')\", 1)])\n",
      "collecting tokens for  rejection\n",
      "indices:    {15939, 23175, 1353, 27275, 30703, 21424, 30706, 2710, 91, 15358}\n",
      "dict_items([(\"Lemma('rejection.n.01.rejection')\", 4), (\"Lemma('rejection.n.02.rejection')\", 1)])\n",
      "collecting tokens for  sport\n",
      "indices:    {1921, 24451, 1925, 27080, 19960, 526, 36944, 29043, 28628, 28696, 25913, 22938, 28893, 28702}\n",
      "dict_items([(\"Lemma('sport.n.02.sport')\", 1), (\"Lemma('sport.n.01.sport')\", 1)])\n",
      "collecting tokens for  discourage\n",
      "indices:    {20193, 25474, 4584, 37098, 28556, 29881, 14365, 30815}\n",
      "dict_items([(\"Lemma('deter.v.01.discourage')\", 4), (\"Lemma('discourage.v.02.discourage')\", 2), (\"Lemma('warn.v.02.discourage')\", 2)])\n",
      "collecting tokens for  parallel\n",
      "indices:    {29728, 28833, 31874, 5379, 14784, 15970, 1928, 5386, 1487, 12527, 2961, 11508, 11510, 8918, 6938, 28764, 15965, 2430}\n",
      "dict_items([(\"Lemma('parallel.a.01.parallel')\", 9), (\"Lemma('analogue.n.01.parallel')\", 3), (\"Lemma('parallel.v.01.parallel')\", 1), (\"Lemma('latitude.n.03.parallel')\", 1)])\n",
      "collecting tokens for  magnetic\n",
      "indices:    {2875, 3042, 2883, 14787, 11491, 3111, 3052, 14797, 11502, 3119, 11505, 21522, 12405, 21943, 21529, 11483, 11484, 11486}\n",
      "dict_items([(\"Lemma('magnetic.a.01.magnetic')\", 3), (\"Lemma('magnetic.a.02.magnetic')\", 1)])\n",
      "collecting tokens for  murray\n",
      "indices:    {14153}\n",
      "dict_items([])\n",
      "collecting tokens for  cleaners\n",
      "indices:    {21861, 21836, 3181, 3153, 3155, 3157, 17109, 30104}\n",
      "dict_items([(\"Lemma('cleansing_agent.n.01.cleaner')\", 4)])\n",
      "collecting tokens for  amazing\n",
      "indices:    {9603, 25798, 7354, 5004, 3630, 30830, 1393, 8818, 31153, 25905, 30686, 11286, 855, 23002, 12734}\n",
      "dict_items([(\"Lemma('amazing.s.02.amazing')\", 5), (\"Lemma('amazing.s.01.amazing')\", 4)])\n",
      "collecting tokens for  surge\n",
      "indices:    {12678, 838, 12881, 22066, 6581, 31222, 23002, 7614}\n",
      "dict_items([(\"Lemma('billow.v.03.surge')\", 1), (\"Lemma('rush.n.02.surge')\", 3), (\"Lemma('surge.n.02.surge')\", 1)])\n",
      "collecting tokens for  conjugates\n",
      "indices:    {4130, 4194, 4195, 4197, 4198, 32776, 4172, 4173, 4190, 4126}\n",
      "dict_items([(\"Lemma('conjugate_solution.n.01.conjugate')\", 9)])\n",
      "collecting tokens for  furnish\n",
      "indices:    {11265, 26147, 11528, 25224, 15147, 3244, 14027, 22030, 23215, 32750, 15643, 32767}\n",
      "dict_items([(\"Lemma('supply.v.01.furnish')\", 12)])\n",
      "collecting tokens for  germans\n",
      "indices:    {16422}\n",
      "dict_items([(\"Lemma('german.n.01.German')\", 1)])\n",
      "collecting tokens for  engineer\n",
      "indices:    {22180, 13093, 5189, 5126, 15781, 28748, 21715, 15765, 15766, 15770, 1822}\n",
      "dict_items([(\"Lemma('engineer.n.01.engineer')\", 7)])\n",
      "collecting tokens for  edward\n",
      "indices:    {1113}\n",
      "dict_items([])\n",
      "collecting tokens for  truman\n",
      "indices:    {23323}\n",
      "dict_items([])\n",
      "collecting tokens for  promises\n",
      "indices:    {31648, 21061, 21894, 10791, 12938, 14859, 24177, 27345, 25489, 33302, 28406, 28249, 22938, 4635, 5436, 11357, 24863}\n",
      "dict_items([(\"Lemma('promise.v.01.promise')\", 3), (\"Lemma('predict.v.01.promise')\", 3), (\"Lemma('promise.v.04.promise')\", 2), (\"Lemma('promise.n.02.promise')\", 1), (\"Lemma('promise.v.02.promise')\", 1)])\n",
      "collecting tokens for  odds\n",
      "indices:    {27712, 25540, 21894, 10984, 4841, 24013, 26797, 20623, 2229, 37112}\n",
      "dict_items([])\n",
      "collecting tokens for  earnings\n",
      "indices:    {15264, 23426, 25347, 23427, 23397, 22022, 774, 2763, 15629, 23408, 12176, 12084, 21815, 23418}\n",
      "dict_items([(\"Lemma('wage.n.01.earnings')\", 2), (\"Lemma('net_income.n.01.earnings')\", 4)])\n",
      "collecting tokens for  meanings\n",
      "indices:    {16194, 27554, 16196, 15848, 1225, 15850, 16043, 13676, 16173, 26446, 16174, 16208, 15861, 15865, 10810}\n",
      "dict_items([(\"Lemma('meaning.n.02.meaning')\", 7), (\"Lemma('meaning.n.01.meaning')\", 5)])\n",
      "collecting tokens for  comparatively\n",
      "indices:    {15847, 31016, 12042, 13770, 12112, 12944, 16144, 25654, 21916}\n",
      "dict_items([(\"Lemma('relatively.r.01.comparatively')\", 6)])\n",
      "collecting tokens for  economics\n",
      "indices:    {2715}\n",
      "dict_items([])\n",
      "collecting tokens for  outlook\n",
      "indices:    {4993, 27915, 5005, 31118, 16407, 2712, 16286, 2341, 16294, 22572, 11185, 22706, 12217, 14398, 14408, 14922, 1740, 14162, 21971, 23383, 31577, 24031, 4967, 4974, 25584}\n",
      "dict_items([(\"Lemma('expectation.n.01.outlook')\", 5), (\"Lemma('mentality.n.01.outlook')\", 11)])\n",
      "collecting tokens for  pictures\n",
      "indices:    {1042, 25108, 11294, 11296, 29362, 8371, 29240, 11325, 11329, 18754, 11331, 25028, 36168, 29259, 24396, 11091, 4447, 25704, 14952, 29288, 23156, 30718}\n",
      "dict_items([(\"Lemma('picture.n.05.picture')\", 1), (\"Lemma('picture.n.01.picture')\", 1), (\"Lemma('painting.n.01.picture')\", 7), (\"Lemma('mental_picture.n.01.picture')\", 1)])\n",
      "collecting tokens for  variables\n",
      "indices:    {4459, 31947, 15661, 15695, 3282, 16341, 4476, 4479}\n",
      "dict_items([(\"Lemma('variable.n.02.variable')\", 2), (\"Lemma('variable.n.01.variable')\", 2)])\n",
      "collecting tokens for  unknown\n",
      "indices:    {33157, 26504, 18314, 9994, 9616, 28304, 37138, 3091, 33172, 23840, 3361, 8354, 26149, 33704, 13610, 25387, 2987, 13235, 32437, 26807, 24022, 21720, 13785, 17369, 33260, 3054, 11378, 13813, 18300}\n",
      "dict_items([(\"Lemma('unknown.a.01.unknown')\", 11), (\"Lemma('unknown.s.03.unknown')\", 1), (\"Lemma('nameless.s.01.unknown')\", 2), (\"Lemma('obscure.s.04.unknown')\", 1)])\n",
      "collecting tokens for  wrinkled\n",
      "indices:    {19750, 10522, 7598, 9487, 7890, 33589, 16602, 10588}\n",
      "dict_items([(\"Lemma('wrinkle.v.02.wrinkle')\", 1), (\"Lemma('purse.v.02.wrinkle')\", 2)])\n",
      "collecting tokens for  petitions\n",
      "indices:    {43, 20364, 20363, 47, 20722, 20727, 28091}\n",
      "dict_items([(\"Lemma('request.n.01.petition')\", 2)])\n",
      "collecting tokens for  bunch\n",
      "indices:    {5378, 26054, 29199, 16500, 9973, 35288, 6553, 19611, 9916}\n",
      "dict_items([(\"Lemma('crowd.n.02.bunch')\", 3), (\"Lemma('bunch.n.01.bunch')\", 3)])\n",
      "collecting tokens for  riders\n",
      "indices:    {35826}\n",
      "dict_items([])\n",
      "collecting tokens for  adventure\n",
      "indices:    {11948, 2381, 8401, 8376, 33273, 14424, 29277, 13886, 35839}\n",
      "dict_items([(\"Lemma('adventure.n.01.adventure')\", 5), (\"Lemma('gamble.v.01.adventure')\", 1)])\n",
      "collecting tokens for  trot\n",
      "indices:    {28992, 28993, 28963, 29028, 29160, 28970, 12874, 29011, 31385, 29022, 29023}\n",
      "dict_items([(\"Lemma('trot.v.01.trot')\", 5), (\"Lemma('jog.n.02.trot')\", 1)])\n",
      "collecting tokens for  confident\n",
      "indices:    {16196, 23368, 12426, 27467, 24588, 4784, 23121, 20945, 21810, 12822, 22649, 14108, 26462}\n",
      "dict_items([(\"Lemma('confident.a.01.confident')\", 5)])\n",
      "collecting tokens for  dish\n",
      "indices:    {36992, 5378, 8835, 22310, 16679, 29521, 29178, 29501, 30495}\n",
      "dict_items([(\"Lemma('dish.n.01.dish')\", 1), (\"Lemma('dish.n.02.dish')\", 1)])\n",
      "collecting tokens for  sanctuary\n",
      "indices:    {33859, 24041, 24042, 21707, 21710}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([])\n",
      "collecting tokens for  louisiana\n",
      "indices:    {31719}\n",
      "dict_items([])\n",
      "collecting tokens for  warn\n",
      "indices:    {22053, 12229, 30279, 7055, 12221, 22640, 14165, 18141, 11102}\n",
      "dict_items([(\"Lemma('warn.v.01.warn')\", 8), (\"Lemma('warn.v.02.warn')\", 1)])\n",
      "collecting tokens for  comprehensive\n",
      "indices:    {32482, 32969, 32938, 4620, 32496, 13297, 13298, 14195, 13300, 13302, 2807, 15001, 32508, 23545}\n",
      "dict_items([(\"Lemma('comprehensive.a.01.comprehensive')\", 8)])\n",
      "collecting tokens for  ambition\n",
      "indices:    {24161, 36901, 22793, 31722, 23787, 11468, 8239, 752, 6002, 36949, 19546, 36956}\n",
      "dict_items([(\"Lemma('ambition.n.02.ambition')\", 2), (\"Lemma('ambition.n.01.ambition')\", 3)])\n",
      "collecting tokens for  escaped\n",
      "indices:    {9345, 18946, 4579, 36901, 35817, 14285, 22864, 21366, 17432, 12188, 16223}\n",
      "dict_items([(\"Lemma('elude.v.02.escape')\", 2), (\"Lemma('get_off.v.05.escape')\", 2), (\"Lemma('escape.v.01.escape')\", 5), (\"Lemma('miss.v.09.escape')\", 2)])\n",
      "collecting tokens for  mixed\n",
      "indices:    {3586, 26118, 26630, 5524, 33182, 14624, 13728, 2337, 5552, 33072, 5555, 13364, 33075, 3125, 5560, 18617, 5562, 3515, 3259, 1089, 5569, 5572, 13260, 33111}\n",
      "dict_items([(\"Lemma('blend.v.03.mix')\", 1), (\"Lemma('assorted.s.01.mixed')\", 5), (\"Lemma('interracial.s.02.mixed')\", 1), (\"Lemma('mix.v.03.mix')\", 1)])\n",
      "collecting tokens for  glendora\n",
      "indices:    {16687}\n",
      "dict_items([(\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  segregated\n",
      "indices:    {5446, 5482, 24427, 16462, 21426, 13779, 32980, 21461, 32984}\n",
      "dict_items([(\"Lemma('segregate.v.01.segregate')\", 3), (\"Lemma('segregated.a.01.segregated')\", 1)])\n",
      "collecting tokens for  lawrence\n",
      "indices:    {21886}\n",
      "dict_items([])\n",
      "collecting tokens for  wealth\n",
      "indices:    {15012, 12360, 11371, 22797, 13748, 13749, 11352, 25338}\n",
      "dict_items([(\"Lemma('wealth.n.02.wealth')\", 3), (\"Lemma('wealth.n.01.wealth')\", 3)])\n",
      "collecting tokens for  prevents\n",
      "indices:    {7402, 25196, 13710, 26415, 11601}\n",
      "dict_items([(\"Lemma('prevent.v.02.prevent')\", 3), (\"Lemma('prevent.v.01.prevent')\", 2)])\n",
      "collecting tokens for  coverage\n",
      "indices:    {11810, 22051, 29257, 32458, 25292, 15949, 33103, 27888, 32755, 27898}\n",
      "dict_items([(\"Lemma('coverage.n.01.coverage')\", 1), (\"Lemma('coverage.n.02.coverage')\", 1)])\n",
      "collecting tokens for  pulley\n",
      "indices:    {2968, 30933}\n",
      "dict_items([(\"Lemma('pulley.n.01.pulley')\", 1)])\n",
      "collecting tokens for  brave\n",
      "indices:    {26052, 8678, 10782, 27913, 32011, 29484, 13005, 37137, 35283, 1652, 30839, 25245, 10846}\n",
      "dict_items([(\"Lemma('audacious.s.01.brave')\", 1), (\"Lemma('weather.v.01.brave')\", 1), (\"Lemma('brave.a.01.brave')\", 4)])\n",
      "collecting tokens for  marching\n",
      "indices:    {6923, 6929, 1172, 1081, 8698, 9503}\n",
      "dict_items([(\"Lemma('march.v.01.march')\", 3), (\"Lemma('march.v.03.march')\", 1)])\n",
      "collecting tokens for  harvey\n",
      "indices:    {30268}\n",
      "dict_items([])\n",
      "collecting tokens for  loaded\n",
      "indices:    {30273, 20067, 28643, 10020, 5542, 12486, 21700, 12265, 6921, 23340, 19085, 28947, 11475, 22836, 17749, 1591, 22995, 5113}\n",
      "dict_items([(\"Lemma('laden.s.01.loaded')\", 5), (\"Lemma('load.v.01.load')\", 6), (\"Lemma('loaded.s.03.loaded')\", 1)])\n",
      "collecting tokens for  mustard\n",
      "indices:    {29473, 29218, 29506, 29514, 29484, 29517, 29492, 29525, 29498, 29531, 29502}\n",
      "dict_items([])\n",
      "collecting tokens for  robards\n",
      "indices:    {36224}\n",
      "dict_items([])\n",
      "collecting tokens for  confederacy\n",
      "indices:    {22539}\n",
      "dict_items([])\n",
      "collecting tokens for  tony\n",
      "indices:    {258}\n",
      "dict_items([])\n",
      "collecting tokens for  resident\n",
      "indices:    {2500, 21222, 15560, 23209, 26415, 15568, 1874, 25106, 32697}\n",
      "dict_items([(\"Lemma('resident.a.01.resident')\", 2), (\"Lemma('nonmigratory.a.01.resident')\", 1), (\"Lemma('resident.n.01.resident')\", 1)])\n",
      "collecting tokens for  contest\n",
      "indices:    {1570, 23715, 23747, 198, 5706, 22187, 32652, 21586, 28596, 11444, 21589, 10647}\n",
      "dict_items([(\"Lemma('contest.n.01.contest')\", 3), (\"Lemma('contest.n.02.contest')\", 1)])\n",
      "collecting tokens for  worthy\n",
      "indices:    {29209, 12924, 10805, 29015}\n",
      "dict_items([(\"Lemma('worthy.a.01.worthy')\", 2)])\n",
      "collecting tokens for  twins\n",
      "indices:    {393}\n",
      "dict_items([(\"Lemma('group.n.01.group')\", 1)])\n",
      "collecting tokens for  differed\n",
      "indices:    {12550, 10279, 33258, 31980, 3279, 32016, 26096, 4976, 9583, 31988, 32214, 15644}\n",
      "dict_items([(\"Lemma('differ.v.01.differ')\", 11), (\"Lemma('disagree.v.01.differ')\", 1)])\n",
      "collecting tokens for  avoided\n",
      "indices:    {36320, 31713, 30242, 7331, 23914, 5355, 4779, 31988, 18007, 33755, 893, 15198}\n",
      "dict_items([(\"Lemma('avoid.v.03.avoid')\", 6), (\"Lemma('debar.v.02.avoid')\", 4), (\"Lemma('avoid.v.01.avoid')\", 2)])\n",
      "collecting tokens for  undertaken\n",
      "indices:    {24739, 30982, 16270, 3279, 32281, 30779, 14748, 24734, 22495}\n",
      "dict_items([(\"Lemma('undertake.v.01.undertake')\", 8), (\"Lemma('contract.v.01.undertake')\", 1)])\n",
      "collecting tokens for  pot\n",
      "indices:    {7232, 5445, 7238, 9000, 29160, 9004, 36205, 9005, 37039, 9009, 25682, 18675, 19511, 7254, 7255, 18005, 29465, 2326}\n",
      "dict_items([(\"Lemma('toilet.n.02.pot')\", 5), (\"Lemma('pot.n.01.pot')\", 5)])\n",
      "collecting tokens for  integrated\n",
      "indices:    {11234, 24420, 27879, 15820, 22287, 21431, 1753, 26747, 26493}\n",
      "dict_items([(\"Lemma('integrate.v.01.integrate')\", 1), (\"Lemma('incorporate.s.01.integrated')\", 2), (\"Lemma('integrate.v.03.integrate')\", 1)])\n",
      "collecting tokens for  brenner\n",
      "indices:    {18325}\n",
      "dict_items([])\n",
      "collecting tokens for  preparing\n",
      "indices:    {7842, 29538, 27879, 2439, 8392, 26890, 12459, 5290, 11439, 16912, 9361, 3279, 29427, 18232, 32506, 28059, 36988}\n",
      "dict_items([(\"Lemma('cook.v.02.prepare')\", 2), (\"Lemma('organize.v.05.prepare')\", 2), (\"Lemma('fix.v.12.prepare')\", 9), (\"Lemma('prepare.v.03.prepare')\", 2), (\"Lemma('train.v.01.prepare')\", 1)])\n",
      "collecting tokens for  paste\n",
      "indices:    {29506, 2439, 2960, 2961, 10483, 29525, 726, 29881}\n",
      "dict_items([(\"Lemma('glue.v.01.paste')\", 1), (\"Lemma('paste.n.01.paste')\", 3)])\n",
      "collecting tokens for  zing\n",
      "indices:    {19035}\n",
      "dict_items([])\n",
      "collecting tokens for  planetary\n",
      "indices:    {2816, 2817, 2820, 2821, 14791, 3308, 2832, 2813}\n",
      "dict_items([(\"Lemma('planetal.a.01.planetary')\", 8)])\n",
      "collecting tokens for  arrival\n",
      "indices:    {2816, 12765, 36964, 21285, 34762, 3595, 11530, 21171, 18197, 25367, 32856, 9851, 23101}\n",
      "dict_items([(\"Lemma('arrival.n.01.arrival')\", 4), (\"Lemma('arrival.n.02.arrival')\", 1)])\n",
      "collecting tokens for  creatures\n",
      "indices:    {27361, 13571, 1253, 10847, 25327, 30735, 1328, 31920, 34548, 17684, 25332, 10808, 15998, 13375}\n",
      "dict_items([(\"Lemma('animal.n.01.creature')\", 6), (\"Lemma('creature.n.02.creature')\", 1), (\"Lemma('creature.n.03.creature')\", 1)])\n",
      "collecting tokens for  rang\n",
      "indices:    {19008, 36993, 36548, 17764, 17604, 35655, 8264, 16553, 16968, 33386, 17265, 6162, 10481, 17814, 7422, 19007}\n",
      "dict_items([(\"Lemma('call.v.03.ring')\", 1), (\"Lemma('ring.v.01.ring')\", 10), (\"Lemma('ring.v.03.ring')\", 3), (\"Lemma('resound.v.01.ring')\", 1)])\n",
      "collecting tokens for  counted\n",
      "indices:    {33026, 12226, 21794, 16553, 3274, 26127, 2481, 30515, 8211, 20025, 14939, 16285}\n",
      "dict_items([(\"Lemma('count.v.01.count')\", 4), (\"Lemma('count.v.02.count')\", 2), (\"Lemma('count.v.04.count')\", 2), (\"Lemma('consider.v.04.count')\", 1)])\n",
      "collecting tokens for  fancy\n",
      "indices:    {19200, 29473, 11106, 13794, 11460, 10505, 8401, 29170, 26133, 21816, 25915, 34749, 29438, 29855}\n",
      "dict_items([(\"Lemma('fancy.a.01.fancy')\", 2), (\"Lemma('fancy.n.02.fancy')\", 1), (\"Lemma('visualize.v.01.fancy')\", 2), (\"Lemma('fancy.v.02.fancy')\", 1), (\"Lemma('illusion.n.02.fancy')\", 1)])\n",
      "collecting tokens for  likes\n",
      "indices:    {22082, 9540, 2505, 29033, 13903, 12815, 29011, 30455, 24217, 25691, 22079}\n",
      "dict_items([(\"Lemma('like.v.02.like')\", 7), (\"Lemma('like.v.03.like')\", 3), (\"Lemma('wish.v.02.like')\", 1)])\n",
      "collecting tokens for  distilled\n",
      "indices:    {23708}\n",
      "dict_items([])\n",
      "collecting tokens for  stroke\n",
      "indices:    {22914, 21189, 22949, 28902, 35626, 28906, 2669, 23375, 26769, 31922, 28913, 22995, 2648, 572}\n",
      "dict_items([(\"Lemma('stroke.n.01.stroke')\", 1), (\"Lemma('stroke.n.03.stroke')\", 1), (\"Lemma('stroke.n.04.stroke')\", 1), (\"Lemma('stroke.v.02.stroke')\", 1)])\n",
      "collecting tokens for  equality\n",
      "indices:    {31812, 31172, 8042, 24206, 16399, 27886, 31219, 24406, 22744, 28030}\n",
      "dict_items([(\"Lemma('equality.n.01.equality')\", 1), (\"Lemma('equality.n.02.equality')\", 1)])\n",
      "collecting tokens for  implies\n",
      "indices:    {16003, 14598, 14378, 5263, 32816, 1425, 3090, 31219, 24278, 24279, 4439}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('imply.v.02.imply')\", 4), (\"Lemma('imply.v.01.imply')\", 6), (\"Lemma('entail.v.01.imply')\", 1)])\n",
      "collecting tokens for  42\n",
      "indices:    {14720, 25697, 3747, 1699, 20741, 14749, 20168, 3913, 21361, 27060, 5590, 26614, 3929, 16249, 31743, 13149, 29758, 29759}\n",
      "dict_items([])\n",
      "collecting tokens for  dispute\n",
      "indices:    {25921, 12258, 20741, 24263, 25196, 33135, 83, 27285, 25878, 31958}\n",
      "dict_items([(\"Lemma('challenge.v.01.dispute')\", 2), (\"Lemma('dispute.n.01.dispute')\", 2)])\n",
      "collecting tokens for  guam\n",
      "indices:    {15022}\n",
      "dict_items([(\"Lemma('guam.n.01.Guam')\", 1)])\n",
      "collecting tokens for  hawaii\n",
      "indices:    {29239}\n",
      "dict_items([])\n",
      "collecting tokens for  midnight\n",
      "indices:    {21442, 17315, 34524, 3336, 26410, 399, 26129, 10002, 33939, 19700, 21139, 82, 31835, 33916}\n",
      "dict_items([(\"Lemma('midnight.n.01.midnight')\", 6)])\n",
      "collecting tokens for  pohl\n",
      "indices:    {21354}\n",
      "dict_items([])\n",
      "collecting tokens for  victims\n",
      "indices:    {12192, 26178, 21544, 34889, 2280, 12332, 36559, 2287, 2291, 30516, 29395, 21208, 27194, 25371, 23804, 21790, 2239}\n",
      "dict_items([(\"Lemma('victim.n.02.victim')\", 4), (\"Lemma('victim.n.01.victim')\", 2)])\n",
      "collecting tokens for  quacks\n",
      "indices:    {2252, 2289, 2228, 2234, 2237}\n",
      "dict_items([(\"Lemma('quack.n.01.quack')\", 5)])\n",
      "collecting tokens for  dutch\n",
      "indices:    {12761}\n",
      "dict_items([])\n",
      "collecting tokens for  coalition\n",
      "indices:    {20516, 20580, 23960, 23911, 20521, 12621, 20270, 23900, 20568, 20761, 20572}\n",
      "dict_items([(\"Lemma('alliance.n.03.coalition')\", 1)])\n",
      "collecting tokens for  addresses\n",
      "indices:    {15905, 32483, 15944, 25468, 22249, 26099, 25493, 27829, 22265, 24218, 17116}\n",
      "dict_items([(\"Lemma('address.v.01.address')\", 1), (\"Lemma('address.v.03.address')\", 1), (\"Lemma('address.n.01.address')\", 2), (\"Lemma('address.n.02.address')\", 1)])\n",
      "collecting tokens for  moreland\n",
      "indices:    {10746}\n",
      "dict_items([(\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  amusing\n",
      "indices:    {26979, 30215, 26664, 10633, 10763, 19693, 26030, 19726, 23920, 1205, 10651, 26365, 6814}\n",
      "dict_items([])\n",
      "collecting tokens for  counsel\n",
      "indices:    {36298, 15252}\n",
      "dict_items([(\"Lemma('advocate.n.02.counsel')\", 1)])\n",
      "collecting tokens for  assert\n",
      "indices:    {12033, 13858, 14660, 4836, 12008, 11979, 5260, 14385, 31221, 1493, 4826, 5404, 5373, 31998}\n",
      "dict_items([(\"Lemma('assert_oneself.v.01.assert_oneself')\", 3), (\"Lemma('assert.v.01.assert')\", 10), (\"Lemma('assert.v.03.assert')\", 1)])\n",
      "collecting tokens for  decades\n",
      "indices:    {29184, 28045, 22673, 5013, 5016, 31790, 31803, 24259, 31816, 14409, 13258, 14413, 2895, 31184, 13912, 32221, 12259, 5219, 31848, 21097, 12266, 14702, 11502, 32885, 16246, 24185, 4991}\n",
      "dict_items([(\"Lemma('decade.n.01.decade')\", 14)])\n",
      "collecting tokens for  corruption\n",
      "indices:    {20505, 32154, 13980, 22745}\n",
      "dict_items([(\"Lemma('corruptness.n.02.corruption')\", 1)])\n",
      "collecting tokens for  notable\n",
      "indices:    {12512, 26459, 27077, 32262, 31719, 29194, 21995, 26643, 37112, 2458, 13339, 15519}\n",
      "dict_items([(\"Lemma('celebrated.s.01.notable')\", 1), (\"Lemma('noteworthy.s.01.notable')\", 3)])\n",
      "collecting tokens for  ramsey\n",
      "indices:    {339}\n",
      "dict_items([(\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  fix\n",
      "indices:    {32386, 12040, 5616, 6000, 29490, 35956, 9303, 16599, 7258, 10717}\n",
      "dict_items([(\"Lemma('specify.v.02.fix')\", 1), (\"Lemma('repair.v.01.fix')\", 3), (\"Lemma('arrange.v.02.fix_up')\", 1), (\"Lemma('sterilize.v.02.fix')\", 1), (\"Lemma('cook.v.02.fix')\", 3)])\n",
      "collecting tokens for  barney\n",
      "indices:    {33641}\n",
      "dict_items([])\n",
      "collecting tokens for  denied\n",
      "indices:    {15363, 20227, 13197, 14863, 30864, 28063, 13731, 22055, 15272, 25140, 15289, 15290, 15292, 18241, 20162, 30276, 15303, 15304, 4941, 16732, 4958, 23907, 5349, 15334, 103, 20848, 15345}\n",
      "dict_items([(\"Lemma('deny.v.01.deny')\", 7), (\"Lemma('deny.v.03.deny')\", 11), (\"Lemma('deny.v.04.deny')\", 6), (\"Lemma('deny.v.02.deny')\", 2)])\n",
      "collecting tokens for  bobby\n",
      "indices:    {9204, 1663}\n",
      "dict_items([])\n",
      "collecting tokens for  sixteen\n",
      "indices:    {3755, 32719}\n",
      "dict_items([(\"Lemma('sixteen.s.01.sixteen')\", 1)])\n",
      "collecting tokens for  1940\n",
      "indices:    {32320, 4133, 23111, 32265, 20459, 11339, 14572, 32306, 31795, 3762, 14550, 30233, 764}\n",
      "dict_items([])\n",
      "collecting tokens for  1950\n",
      "indices:    {3976, 30221, 33038, 21266, 31788, 25137, 31795, 23219, 12854, 27861, 23514, 353, 22114, 3303, 23529, 32750, 27248, 20465, 248}\n",
      "dict_items([])\n",
      "collecting tokens for  ideally\n",
      "indices:    {22611}\n",
      "dict_items([])\n",
      "collecting tokens for  reins\n",
      "indices:    {6149, 10347, 10315, 35372, 29199, 35154, 7796, 13593}\n",
      "dict_items([(\"Lemma('rein.n.01.rein')\", 5)])\n",
      "collecting tokens for  frequency\n",
      "indices:    {11968, 16188, 30282, 2923, 30730, 11403, 2158, 16179, 3123, 2166, 4218, 1787, 11420, 16191}\n",
      "dict_items([(\"Lemma('frequency.n.01.frequency')\", 6), (\"Lemma('frequency.n.03.frequency')\", 2), (\"Lemma('frequency.n.02.frequency')\", 2)])\n",
      "collecting tokens for  sole\n",
      "indices:    {14240, 2784, 31173, 15242, 1306, 11152, 30512, 28627, 16376, 37017, 11034, 33695, 1119, 895}\n",
      "dict_items([(\"Lemma('exclusive.s.01.sole')\", 2)])\n",
      "collecting tokens for  bleeding\n",
      "indices:    {34977, 25571, 30763, 6318, 35635, 30908, 34879, 6591}\n",
      "dict_items([(\"Lemma('shed_blood.v.02.bleed')\", 4), (\"Lemma('bleed.v.02.bleed')\", 1)])\n",
      "collecting tokens for  ed\n",
      "indices:    {35137}\n",
      "dict_items([])\n",
      "collecting tokens for  lee\n",
      "indices:    {2220}\n",
      "dict_items([(\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  av.\n",
      "indices:    {21312, 21314, 21763, 21316, 21772, 21777, 21785}\n",
      "dict_items([])\n",
      "collecting tokens for  o'clock\n",
      "indices:    {9624, 6374, 9338, 586, 9904, 8338, 8274, 5108, 21142, 18744, 5050, 381}\n",
      "dict_items([(\"Lemma('o'clock.r.01.o'clock')\", 10)])\n",
      "collecting tokens for  lest\n",
      "indices:    {22631, 25326, 28239, 6063, 13586, 13561, 6843, 6875, 6879}\n",
      "dict_items([])\n",
      "collecting tokens for  porch\n",
      "indices:    {20097, 34049, 36098, 35970, 9221, 13583, 2191, 34962, 9500, 24349, 24352, 35105, 10545, 17073, 33856, 10565, 26951, 10569, 18126, 35152, 10579, 18517, 18135, 35159, 18519, 10458, 9304, 18526, 9311, 9312, 18144, 34148, 9066, 9585, 13561, 33789}\n",
      "dict_items([(\"Lemma('porch.n.01.porch')\", 20)])\n",
      "collecting tokens for  pity\n",
      "indices:    {34720, 26215, 5352, 26894, 26577, 7222, 16599, 7225}\n",
      "dict_items([(\"Lemma('commiseration.n.01.pity')\", 2), (\"Lemma('feel_for.v.01.pity')\", 1), (\"Lemma('pity.n.02.pity')\", 1)])\n",
      "collecting tokens for  switched\n",
      "indices:    {30145, 11362, 11364, 33541, 33540, 22986, 26604, 33555, 32341, 8919, 11647}\n",
      "dict_items([(\"Lemma('switch.v.04.switch')\", 1), (\"Lemma('switch.v.03.switch')\", 2), (\"Lemma('switch_over.v.01.switch')\", 2), (\"Lemma('trade.v.04.switch')\", 2)])\n",
      "collecting tokens for  gentle\n",
      "indices:    {1410, 32258, 13058, 19208, 7564, 35988, 27033, 27295, 8355, 6183, 26921, 31022, 28977, 31414, 36411, 5827, 14688, 28385, 30820, 7549}\n",
      "dict_items([(\"Lemma('gentle.s.01.gentle')\", 2), (\"Lemma('gentle.s.02.gentle')\", 4), (\"Lemma('aristocratic.s.01.gentle')\", 1), (\"Lemma('gentle.s.03.gentle')\", 1), (\"Lemma('pacify.v.01.gentle')\", 1)])\n",
      "collecting tokens for  billy\n",
      "indices:    {35490}\n",
      "dict_items([])\n",
      "collecting tokens for  orthodox\n",
      "indices:    {12304, 14687}\n",
      "dict_items([(\"Lemma('orthodox.a.02.orthodox')\", 1)])\n",
      "collecting tokens for  representations\n",
      "indices:    {20609, 4963, 4910, 4913, 4958, 4915, 13629, 1022, 4991}\n",
      "dict_items([(\"Lemma('representation.n.01.representation')\", 5), (\"Lemma('representation.n.02.representation')\", 3)])\n",
      "collecting tokens for  bet\n",
      "indices:    {14242, 10407, 20939, 33337, 20319}\n",
      "dict_items([(\"Lemma('bet.v.01.bet')\", 4)])\n",
      "collecting tokens for  yelled\n",
      "indices:    {6213, 35464, 19880, 19871, 19816, 18802, 18461, 18263, 37047, 19227, 6301, 35391}\n",
      "dict_items([(\"Lemma('yell.v.02.yell')\", 4), (\"Lemma('shout.v.02.yell')\", 8)])\n",
      "collecting tokens for  phonemic\n",
      "indices:    {16100, 16101, 16103, 16117, 16118, 16120}\n",
      "dict_items([(\"Lemma('phonemic.a.01.phonemic')\", 3)])\n",
      "collecting tokens for  egypt\n",
      "indices:    {30861}\n",
      "dict_items([])\n",
      "collecting tokens for  denver\n",
      "indices:    {339}\n",
      "dict_items([(\"Lemma('denver.n.01.Denver')\", 1)])\n",
      "collecting tokens for  compromise\n",
      "indices:    {23904, 27769, 23365, 20823, 31961}\n",
      "dict_items([(\"Lemma('compromise.v.02.compromise')\", 1)])\n",
      "collecting tokens for  arrangement\n",
      "indices:    {1024, 25346, 11401, 15128, 3357, 26404, 22053, 26664, 28718, 27570, 442, 7617, 13253, 16455, 12620, 13908, 12628, 2909, 1130, 11390}\n",
      "dict_items([(\"Lemma('agreement.n.04.arrangement')\", 6), (\"Lemma('placement.n.01.arrangement')\", 2), (\"Lemma('arrangement.n.03.arrangement')\", 1), (\"Lemma('arrangement.n.02.arrangement')\", 2)])\n",
      "collecting tokens for  queens\n",
      "indices:    {24174}\n",
      "dict_items([])\n",
      "collecting tokens for  draft\n",
      "indices:    {25730}\n",
      "dict_items([])\n",
      "collecting tokens for  gram\n",
      "indices:    {5560}\n",
      "dict_items([(\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  grasp\n",
      "indices:    {25504, 15841, 27939, 5957, 17990, 15433, 26187, 10604, 20819, 1591, 25631}\n",
      "dict_items([(\"Lemma('grok.v.01.grasp')\", 5), (\"Lemma('grasp.v.01.grasp')\", 3)])\n",
      "collecting tokens for  assemblies\n",
      "indices:    {22341, 20823}\n",
      "dict_items([])\n",
      "collecting tokens for  ridiculous\n",
      "indices:    {36919}\n",
      "dict_items([])\n",
      "collecting tokens for  restaurants\n",
      "indices:    {3424, 26945, 19559, 28711, 24427, 27087, 11152, 21016}\n",
      "dict_items([(\"Lemma('restaurant.n.01.restaurant')\", 3)])\n",
      "collecting tokens for  collage\n",
      "indices:    {5410, 5378, 5411, 5413, 5383, 5364, 5365, 5398, 5367, 5368, 5401, 5402, 5405, 5406, 5407}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('collage.n.01.collage')\", 15)])\n",
      "collecting tokens for  assist\n",
      "indices:    {14080, 15009, 4586, 20300, 24876, 2735, 15411, 16403, 2782, 21663}\n",
      "dict_items([(\"Lemma('help.v.01.assist')\", 7), (\"Lemma('assist.n.02.assist')\", 1)])\n",
      "collecting tokens for  engage\n",
      "indices:    {32870, 24103, 22767, 32664, 22773, 15000, 11097, 4731, 221, 28831}\n",
      "dict_items([(\"Lemma('prosecute.v.03.engage')\", 9), (\"Lemma('engage.v.06.engage')\", 1)])\n",
      "collecting tokens for  rd\n",
      "indices:    {29984, 26787, 21641, 29963, 28588, 28589, 32688, 15000}\n",
      "dict_items([])\n",
      "collecting tokens for  enacted\n",
      "indices:    {14720, 31201, 14754, 15501, 14766, 15000, 20221, 15487}\n",
      "dict_items([(\"Lemma('ordain.v.01.enact')\", 8)])\n",
      "collecting tokens for  rehabilitation\n",
      "indices:    {15009, 15045, 14109, 20687, 14996, 20212, 14998, 14999, 15001, 15003, 15005, 15006}\n",
      "dict_items([(\"Lemma('reclamation.n.01.rehabilitation')\", 1), (\"Lemma('rehabilitation.n.01.rehabilitation')\", 5)])\n",
      "collecting tokens for  corrected\n",
      "indices:    {29061, 5577, 21195, 23788, 537, 2170, 21949, 31007}\n",
      "dict_items([(\"Lemma('correct.v.01.correct')\", 5), (\"Lemma('chastise.v.01.correct')\", 1), (\"Lemma('right.v.01.correct')\", 2)])\n",
      "collecting tokens for  treat\n",
      "indices:    {11584, 5489, 4773}\n",
      "dict_items([(\"Lemma('treat.v.01.treat')\", 1), (\"Lemma('process.v.01.treat')\", 1), (\"Lemma('treat.v.03.treat')\", 1)])\n",
      "collecting tokens for  bacterial\n",
      "indices:    {11544, 11523, 11525, 11534, 11537, 11570, 11542, 4088, 11545}\n",
      "dict_items([(\"Lemma('bacterial.a.01.bacterial')\", 9)])\n",
      "collecting tokens for  0.1\n",
      "indices:    {4128, 11525, 11528, 4435, 3285, 11542, 11545, 14810}\n",
      "dict_items([])\n",
      "collecting tokens for  split\n",
      "indices:    {1591, 35560, 22602, 474, 16980, 35637, 20629, 1590, 13368, 630, 24602, 6462, 319}\n",
      "dict_items([(\"Lemma('separate.v.08.split')\", 2), (\"Lemma('burst.v.01.split')\", 2), (\"Lemma('separate.v.09.split')\", 1), (\"Lemma('split.n.01.split')\", 2), (\"Lemma('divide.v.01.split')\", 1), (\"Lemma('cleave.v.01.split')\", 2)])\n",
      "collecting tokens for  struggling\n",
      "indices:    {22084, 13573, 11273, 14121, 9996, 17518, 20047, 11922, 36019, 14292, 10458}\n",
      "dict_items([(\"Lemma('fight.v.03.struggle')\", 6), (\"Lemma('struggling.s.01.struggling')\", 3)])\n",
      "collecting tokens for  doubts\n",
      "indices:    {12345, 27331, 9363, 25740}\n",
      "dict_items([(\"Lemma('doubt.n.01.doubt')\", 2)])\n",
      "collecting tokens for  nutrition\n",
      "indices:    {30499, 31013, 30407, 30393, 30427}\n",
      "dict_items([])\n",
      "collecting tokens for  ferry\n",
      "indices:    {35874}\n",
      "dict_items([])\n",
      "collecting tokens for  altogether\n",
      "indices:    {1506, 26659, 4937, 33100, 11278, 18063, 31952, 5265, 5623, 11129, 4926}\n",
      "dict_items([(\"Lemma('wholly.r.01.altogether')\", 7), (\"Lemma('altogether.r.02.altogether')\", 1)])\n",
      "collecting tokens for  context\n",
      "indices:    {15988, 4645, 15382}\n",
      "dict_items([(\"Lemma('context.n.02.context')\", 2), (\"Lemma('context.n.01.context')\", 1)])\n",
      "collecting tokens for  justification\n",
      "indices:    {1474, 12205, 32050, 33108, 4694, 5400, 27705, 14300, 27262}\n",
      "dict_items([(\"Lemma('justification.n.01.justification')\", 3), (\"Lemma('justification.n.02.justification')\", 2)])\n",
      "collecting tokens for  improvements\n",
      "indices:    {15489, 15522, 23427, 30502, 1769, 12170, 25100, 21197, 23376, 24177, 24178, 11734, 15001, 5178, 23421}\n",
      "dict_items([(\"Lemma('improvement.n.01.improvement')\", 3), (\"Lemma('improvement.n.02.improvement')\", 4)])\n",
      "collecting tokens for  province\n",
      "indices:    {23297, 11042, 23557, 4808, 22327, 23255, 31800, 22047}\n",
      "dict_items([(\"Lemma('state.n.01.province')\", 1)])\n",
      "collecting tokens for  mineral\n",
      "indices:    {2783, 30195, 22028, 22175}\n",
      "dict_items([(\"Lemma('mineral.n.01.mineral')\", 1)])\n",
      "collecting tokens for  universities\n",
      "indices:    {2496, 11201, 22690, 2114, 2117, 13065, 11881, 1419, 13770, 24777, 22672, 13265, 13778, 20531, 23579}\n",
      "dict_items([(\"Lemma('university.n.01.university')\", 6), (\"Lemma('university.n.02.university')\", 3)])\n",
      "collecting tokens for  distinguished\n",
      "indices:    {13124, 1513, 5908, 4153, 32218, 14687}\n",
      "dict_items([(\"Lemma('distinguish.v.01.distinguish')\", 2), (\"Lemma('spot.v.02.distinguish')\", 1), (\"Lemma('distinguished.s.01.distinguished')\", 1)])\n",
      "collecting tokens for  senses\n",
      "indices:    {6538, 6539, 13644, 26220, 31148, 4911, 783, 36370, 26548, 2165, 2166, 32119, 31831}\n",
      "dict_items([(\"Lemma('sense.n.03.sense')\", 4), (\"Lemma('sense.n.01.sense')\", 2), (\"Lemma('feel.v.03.sense')\", 2)])\n",
      "collecting tokens for  autistic\n",
      "indices:    {24544, 24549, 24551, 24520, 24519, 24557, 24559, 24529, 24533, 24535, 24537, 24539}\n",
      "dict_items([])\n",
      "collecting tokens for  warwick\n",
      "indices:    {24907}\n",
      "dict_items([])\n",
      "collecting tokens for  suggesting\n",
      "indices:    {1249, 15395, 24911, 32147, 17012, 28598, 7611, 4252}\n",
      "dict_items([(\"Lemma('hint.v.01.suggest')\", 2), (\"Lemma('suggest.v.05.suggest')\", 1), (\"Lemma('propose.v.01.suggest')\", 4), (\"Lemma('suggest.v.03.suggest')\", 1)])\n",
      "collecting tokens for  intonation\n",
      "indices:    {16096, 16097, 11058, 16090, 16092, 16094}\n",
      "dict_items([(\"Lemma('intonation.n.01.intonation')\", 6)])\n",
      "collecting tokens for  eating\n",
      "indices:    {6658, 10853, 33543, 33673, 27180, 27182, 16815, 18128, 36400, 5746, 30451, 36500, 30359, 35961, 27162, 27227, 27165, 14526}\n",
      "dict_items([(\"Lemma('eat.v.01.eat')\", 13), (\"Lemma('eating.n.01.eating')\", 1)])\n",
      "collecting tokens for  jar\n",
      "indices:    {11462, 29608, 29596, 29610, 29611, 29612, 29615, 11505, 29650, 29587, 19292, 9406}\n",
      "dict_items([(\"Lemma('jar.n.01.jar')\", 2)])\n",
      "collecting tokens for  adventures\n",
      "indices:    {768, 4582, 34762, 24653, 1006, 9393, 26711, 23807}\n",
      "dict_items([(\"Lemma('adventure.n.01.adventure')\", 4)])\n",
      "collecting tokens for  magazines\n",
      "indices:    {11872, 801, 19554, 10754, 37059, 33159, 28328, 15207, 26929, 17555, 35667, 37020}\n",
      "dict_items([(\"Lemma('magazine.n.01.magazine')\", 4), (\"Lemma('magazine.n.02.magazine')\", 2)])\n",
      "collecting tokens for  expectations\n",
      "indices:    {33219, 3243, 32335, 12082, 15667, 34674, 661, 1371, 14111}\n",
      "dict_items([(\"Lemma('anticipation.n.04.expectation')\", 2), (\"Lemma('expectation.n.01.expectation')\", 4)])\n",
      "collecting tokens for  bare\n",
      "indices:    {6341, 8806, 36327, 13608, 36718, 1999, 31856, 30257, 28147, 23156, 35765, 33845, 9503}\n",
      "dict_items([(\"Lemma('bare.s.01.bare')\", 2)])\n",
      "collecting tokens for  chambers\n",
      "indices:    {35520, 12189, 32478}\n",
      "dict_items([])\n",
      "collecting tokens for  teaches\n",
      "indices:    {10049, 32229, 32232, 1516, 1517, 13404, 1525, 153, 19580}\n",
      "dict_items([(\"Lemma('teach.v.01.teach')\", 9)])\n",
      "collecting tokens for  quirt\n",
      "indices:    {10408, 10363, 35628, 10383, 10354, 10355, 10290, 10331}\n",
      "dict_items([(\"Lemma('quirt.n.01.quirt')\", 7)])\n",
      "collecting tokens for  encouragement\n",
      "indices:    {23072, 31777, 32161, 28387, 40, 23465, 8461, 32657, 22678, 22808, 27257}\n",
      "dict_items([(\"Lemma('boost.n.01.encouragement')\", 2)])\n",
      "collecting tokens for  lewis\n",
      "indices:    {18215}\n",
      "dict_items([])\n",
      "collecting tokens for  contacts\n",
      "indices:    {32960, 14185, 13354, 13358, 13360, 28785, 13361, 14259, 8218, 32987, 11453, 32475}\n",
      "dict_items([(\"Lemma('liaison.n.02.contact')\", 1), (\"Lemma('contact.n.01.contact')\", 4), (\"Lemma('reach.v.04.contact')\", 1), (\"Lemma('contact.n.05.contact')\", 1)])\n",
      "collecting tokens for  chosen\n",
      "indices:    {5251, 4361, 24330, 32653, 1046, 21145, 31898, 3615, 37024, 13984, 15652, 28583, 23719, 5159, 5160, 26416, 8370, 32055, 4408, 6456, 31932, 37055, 20421, 26438, 35783, 3911, 13642, 23115, 3914, 27086, 30287, 25426, 26710, 5335, 14047, 13279, 14050, 1124, 12389, 7534, 23541, 22391, 36990}\n",
      "dict_items([(\"Lemma('choose.v.01.choose')\", 26), (\"Lemma('choose.v.02.choose')\", 5), (\"Lemma('choose.v.03.choose')\", 3), (\"Lemma('chosen.n.01.chosen')\", 1)])\n",
      "collecting tokens for  deals\n",
      "indices:    {9985, 3876, 4361, 31849, 16139, 6993, 14586, 1246, 26462}\n",
      "dict_items([(\"Lemma('consider.v.03.deal')\", 2), (\"Lemma('cover.v.05.deal')\", 4), (\"Lemma('deal.n.01.deal')\", 1), (\"Lemma('deal.v.03.deal')\", 1)])\n",
      "collecting tokens for  figured\n",
      "indices:    {16576, 9088, 30597, 33670, 34207, 4745, 23307, 22351, 7376, 18644, 33460, 16502, 4761, 30906, 8892, 11231}\n",
      "dict_items([(\"Lemma('calculate.v.02.figure')\", 9), (\"Lemma('visualize.v.01.figure')\", 1), (\"Lemma('figure.v.02.figure')\", 3), (\"Lemma('figure.v.05.figure')\", 1), (\"Lemma('solve.v.01.figure_out')\", 1)])\n",
      "collecting tokens for  reciprocal\n",
      "indices:    {4226, 14690, 8712, 4269, 4271, 25808, 4272, 4277}\n",
      "dict_items([(\"Lemma('reciprocal.a.01.reciprocal')\", 7)])\n",
      "collecting tokens for  horror\n",
      "indices:    {7330, 10754, 19332, 13158, 6922, 2634, 18705, 978, 2644, 5852}\n",
      "dict_items([(\"Lemma('repugnance.n.01.horror')\", 3), (\"Lemma('horror.n.01.horror')\", 5), (\"Lemma('horror.n.02.horror')\", 2)])\n",
      "collecting tokens for  checks\n",
      "indices:    {13026, 32547, 357, 8710, 15591, 36680, 17322, 19470, 14511, 36690, 8725, 24247, 37112, 21787}\n",
      "dict_items([(\"Lemma('check.n.01.check')\", 5), (\"Lemma('assay.n.01.check')\", 1), (\"Lemma('check.n.03.check')\", 1), (\"Lemma('check.v.01.check')\", 1)])\n",
      "collecting tokens for  impressed\n",
      "indices:    {24454, 24588, 22544, 8081, 35730, 36376, 12952, 24745, 35753, 10797, 10798, 23984, 14388, 23487, 1089, 26049, 32450, 35653, 15837, 13544, 26861}\n",
      "dict_items([(\"Lemma('affect.v.05.impress')\", 5), (\"Lemma('impress.v.02.impress')\", 8), (\"Lemma('impress.v.03.impress')\", 1), (\"Lemma('impress.v.04.impress')\", 1)])\n",
      "collecting tokens for  raising\n",
      "indices:    {16384, 20871, 23189, 5536, 14241, 31394, 7849, 20266, 20661, 18103, 20922, 20412, 1600, 12116, 8920, 20707, 27749, 16365, 16366, 10744, 16379, 18941, 16382, 14975}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('raise.v.04.raise')\", 3), (\"Lemma('raise.v.01.raise')\", 5), (\"Lemma('raise.v.03.raise')\", 2), (\"Lemma('grow.v.07.raise')\", 1), (\"Lemma('raise.v.02.raise')\", 3), (\"Lemma('rear.v.02.raise')\", 1), (\"Lemma('raising.s.01.raising')\", 2), (\"Lemma('elevation.n.01.raising')\", 1)])\n",
      "collecting tokens for  richards\n",
      "indices:    {24463}\n",
      "dict_items([])\n",
      "collecting tokens for  feasible\n",
      "indices:    {11810, 11812, 14794, 11754, 32622, 28467, 25523, 23482}\n",
      "dict_items([(\"Lemma('feasible.s.01.feasible')\", 4)])\n",
      "collecting tokens for  guided\n",
      "indices:    {21569, 37027, 15811, 3495, 21576, 31721, 31018, 14632, 29258, 11245, 31033, 34767, 18965, 14649}\n",
      "dict_items([(\"Lemma('guide.v.03.guide')\", 3), (\"Lemma('steer.v.01.guide')\", 4), (\"Lemma('lead.v.01.guide')\", 2)])\n",
      "collecting tokens for  shells\n",
      "indices:    {34689, 7841, 7363, 25785, 13576, 34668, 30413, 30709, 34679, 34744, 34777, 1148, 17757}\n",
      "dict_items([(\"Lemma('shell.n.01.shell')\", 1), (\"Lemma('shell.n.02.shell')\", 2), (\"Lemma('carapace.n.01.shell')\", 1)])\n",
      "collecting tokens for  alongside\n",
      "indices:    {35802, 33892, 5861, 9702, 24458, 23340, 557, 19122, 14420, 14426}\n",
      "dict_items([])\n",
      "collecting tokens for  totally\n",
      "indices:    {1536, 1120, 28484, 23078, 16074, 15277, 4911, 25744, 13360, 25650, 30513, 22388, 9364, 25046, 25846, 22394, 26814}\n",
      "dict_items([(\"Lemma('wholly.r.01.totally')\", 7)])\n",
      "collecting tokens for  theories\n",
      "indices:    {1509, 1510, 16423, 14312, 16426, 26841, 13626, 26811, 26814, 26815}\n",
      "dict_items([(\"Lemma('hypothesis.n.02.theory')\", 3), (\"Lemma('theory.n.01.theory')\", 2), (\"Lemma('theory.n.03.theory')\", 1)])\n",
      "collecting tokens for  neighborhoods\n",
      "indices:    {15648, 15649, 15650, 13254, 27879, 13384, 13383, 13356, 13260, 27885, 24433, 26742, 27899, 6140, 15647}\n",
      "dict_items([(\"Lemma('neighborhood.n.02.neighborhood')\", 4), (\"Lemma('vicinity.n.01.neighborhood')\", 6)])\n",
      "collecting tokens for  sustain\n",
      "indices:    {32932, 13384, 13327, 13365, 15447, 27192, 34745, 14939, 32091, 9336, 36444}\n",
      "dict_items([(\"Lemma('prolong.v.02.sustain')\", 7), (\"Lemma('nourish.v.01.sustain')\", 2), (\"Lemma('sustain.v.04.sustain')\", 2)])\n",
      "collecting tokens for  revenues\n",
      "indices:    {23430, 23432, 23437, 20639, 32554, 32555, 20654, 32559, 20660, 20661, 32568, 14911, 14912, 14913, 23378, 23392, 23399, 23405, 23406, 23409, 32372}\n",
      "dict_items([(\"Lemma('gross.n.02.revenue')\", 3)])\n",
      "collecting tokens for  plug\n",
      "indices:    {2916, 2940, 2955, 23951, 2929, 2899, 7422, 2933, 2938, 2903, 28920, 2937, 24473, 2905, 2908, 2934, 2942}\n",
      "dict_items([(\"Lemma('plug.n.01.plug')\", 13), (\"Lemma('plug.v.01.plug')\", 2)])\n",
      "collecting tokens for  scanned\n",
      "indices:    {18846, 7333, 13799, 34606, 34418, 5780, 2933, 33753, 18526, 34623}\n",
      "dict_items([(\"Lemma('scan.v.02.scan')\", 5), (\"Lemma('scan.v.03.scan')\", 1), (\"Lemma('scan.v.01.scan')\", 3)])\n",
      "collecting tokens for  daniel\n",
      "indices:    {90}\n",
      "dict_items([])\n",
      "collecting tokens for  corporations\n",
      "indices:    {14215, 14220, 24144, 14224, 14230, 14239}\n",
      "dict_items([(\"Lemma('corporation.n.01.corporation')\", 5)])\n",
      "collecting tokens for  sanctions\n",
      "indices:    {4733, 32935, 11101, 5264, 12275, 12277, 32986, 32989}\n",
      "dict_items([(\"Lemma('sanction.n.02.sanction')\", 1), (\"Lemma('approve.v.01.sanction')\", 2), (\"Lemma('sanction.n.01.sanction')\", 2)])\n",
      "collecting tokens for  tappet\n",
      "indices:    {28832, 28833, 28800, 28805, 28806, 28743, 28808, 28810, 28811, 28812, 28720, 28721, 28792, 28729, 28831}\n",
      "dict_items([])\n",
      "collecting tokens for  syllables\n",
      "indices:    {16048, 16044}\n",
      "dict_items([(\"Lemma('syllable.n.01.syllable')\", 2)])\n",
      "collecting tokens for  sadly\n",
      "indices:    {7136, 26114, 34020, 7751, 6002, 6931, 6035, 8789, 13206, 1400}\n",
      "dict_items([(\"Lemma('sadly.r.01.sadly')\", 7), (\"Lemma('sadly.r.02.sadly')\", 1)])\n",
      "collecting tokens for  characters\n",
      "indices:    {26242, 15877, 13848, 26142, 13855, 8104, 26566, 26567, 26569, 14411, 14418, 14419, 14421, 14422, 14428, 1249, 2529, 1251, 22123, 1013, 14582, 12663, 31102}\n",
      "dict_items([(\"Lemma('character.n.05.character')\", 4), (\"Lemma('fictional_character.n.01.character')\", 7), (\"Lemma('character.n.04.character')\", 3)])\n",
      "collecting tokens for  creating\n",
      "indices:    {30734, 7569, 23701, 14234, 22042, 30750, 36126, 5412, 26926, 25138, 27831, 14919, 31827, 5079, 14179, 4587, 11499, 22765, 33136, 1783, 32120, 2297, 29565}\n",
      "dict_items([(\"Lemma('make.v.03.create')\", 19), (\"Lemma('create.v.02.create')\", 4)])\n",
      "collecting tokens for  ranged\n",
      "indices:    {20704, 2466, 12615, 5546, 33131, 33132, 33130, 22994, 5587, 3283, 20692, 3735, 5593, 20670}\n",
      "dict_items([(\"Lemma('range.v.01.range')\", 13), (\"Lemma('range.v.05.range')\", 1)])\n",
      "collecting tokens for  biblical\n",
      "indices:    {24744}\n",
      "dict_items([])\n",
      "collecting tokens for  customs\n",
      "indices:    {28001, 16452, 34378, 22798, 29839, 16433, 16434, 30230, 16409, 25818}\n",
      "dict_items([(\"Lemma('custom.n.02.custom')\", 2), (\"Lemma('custom.n.01.custom')\", 2)])\n",
      "collecting tokens for  polish\n",
      "indices:    {12992}\n",
      "dict_items([(\"Lemma('polish.a.01.Polish')\", 1)])\n",
      "collecting tokens for  vitamins\n",
      "indices:    {30496, 30437, 27174, 36073, 1710, 1711, 27183, 27225, 11515}\n",
      "dict_items([(\"Lemma('vitamin.n.01.vitamin')\", 2)])\n",
      "collecting tokens for  pin\n",
      "indices:    {34724, 36165, 34726, 18948, 36297, 29675, 28622, 29679, 20278, 27960, 1663}\n",
      "dict_items([(\"Lemma('pin.v.02.pin')\", 1)])\n",
      "collecting tokens for  tactics\n",
      "indices:    {11712, 36512, 15462, 25065, 23692, 12812, 25454, 12243, 25780, 23930, 20574}\n",
      "dict_items([(\"Lemma('tactics.n.01.tactics')\", 2), (\"Lemma('tactic.n.01.tactic')\", 2)])\n",
      "collecting tokens for  referring\n",
      "indices:    {3899, 13698, 34724, 25261, 35728, 13780, 13845, 15862, 14199, 3897, 25819}\n",
      "dict_items([(\"Lemma('consult.v.02.refer')\", 1), (\"Lemma('mention.v.01.refer')\", 4), (\"Lemma('denote.v.02.refer')\", 2), (\"Lemma('refer.v.04.refer')\", 1), (\"Lemma('refer.v.02.refer')\", 3)])\n",
      "collecting tokens for  traditionally\n",
      "indices:    {15480, 27559}\n",
      "dict_items([(\"Lemma('traditionally.r.01.traditionally')\", 1)])\n",
      "collecting tokens for  addressed\n",
      "indices:    {9375, 27259, 8387, 13125, 22408, 5656, 36491, 7672, 36697, 8859, 20893, 12574, 36479}\n",
      "dict_items([(\"Lemma('address.v.01.address')\", 6), (\"Lemma('address.v.04.address')\", 1), (\"Lemma('address.v.03.address')\", 2), (\"Lemma('addressed.a.01.addressed')\", 1), (\"Lemma('address.v.02.address')\", 1), (\"Lemma('address.v.05.address')\", 1)])\n",
      "collecting tokens for  scared\n",
      "indices:    {14536, 9032, 6536, 7380, 19066, 16063}\n",
      "dict_items([(\"Lemma('frighten.v.01.scare')\", 2)])\n",
      "collecting tokens for  mahzeer\n",
      "indices:    {17502}\n",
      "dict_items([(\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  eloquent\n",
      "indices:    {26946, 32259, 37156, 26693, 24426, 26763, 31727, 914, 19699, 11221}\n",
      "dict_items([(\"Lemma('eloquent.s.01.eloquent')\", 3)])\n",
      "collecting tokens for  deemed\n",
      "indices:    {26496, 14224}\n",
      "dict_items([(\"Lemma('deem.v.01.deem')\", 2)])\n",
      "collecting tokens for  silently\n",
      "indices:    {36768, 25376, 35845, 31785, 30953, 13131, 10546, 10390, 24311, 34138, 26527}\n",
      "dict_items([(\"Lemma('mutely.r.01.silently')\", 3)])\n",
      "collecting tokens for  desert\n",
      "indices:    {1835, 23308, 7894, 31510}\n",
      "dict_items([(\"Lemma('desert.n.01.desert')\", 2)])\n",
      "collecting tokens for  socialism\n",
      "indices:    {25057, 14098, 11212}\n",
      "dict_items([(\"Lemma('socialism.n.01.socialism')\", 2)])\n",
      "collecting tokens for  dissolved\n",
      "indices:    {4128, 30496, 5572, 13636, 5574, 5577, 5580, 5581, 1644, 10236, 3581}\n",
      "dict_items([(\"Lemma('dissolved.s.01.dissolved')\", 5), (\"Lemma('dissolve.v.03.dissolve')\", 2), (\"Lemma('disband.v.02.dissolve')\", 1), (\"Lemma('dissolve.v.02.dissolve')\", 2)])\n",
      "collecting tokens for  lb\n",
      "indices:    {5540, 5541, 5581, 5582, 5490, 5493, 5591, 5592}\n",
      "dict_items([(\"Lemma('pound.n.01.lb')\", 8)])\n",
      "collecting tokens for  filly\n",
      "indices:    {28992, 29028, 28996, 28998, 29036, 239, 29010, 29011, 29022}\n",
      "dict_items([(\"Lemma('filly.n.01.filly')\", 1)])\n",
      "collecting tokens for  respective\n",
      "indices:    {28800, 20609, 29921, 30016, 25063, 23113, 25769, 15056, 27540, 823, 760, 24153, 13949}\n",
      "dict_items([(\"Lemma('respective.s.01.respective')\", 4)])\n",
      "collecting tokens for  wash\n",
      "indices:    {3169, 23233, 3172, 3173, 18663, 9480, 18665, 26539, 9452, 19085, 22322, 31446, 11319, 30076, 35036}\n",
      "dict_items([(\"Lemma('wash.n.02.wash')\", 3), (\"Lemma('wash.n.03.wash')\", 2), (\"Lemma('wash.v.02.wash')\", 3), (\"Lemma('wash.n.01.wash')\", 1)])\n",
      "collecting tokens for  timely\n",
      "indices:    {24098, 15334, 15571, 15572, 14581, 20248, 31961, 22648, 15550}\n",
      "dict_items([(\"Lemma('timely.s.01.timely')\", 3), (\"Lemma('timely.s.02.timely')\", 1), (\"Lemma('seasonably.r.02.timely')\", 1)])\n",
      "collecting tokens for  retirement\n",
      "indices:    {11778, 30596, 11780, 30600, 11799, 11931, 24098, 22050, 22053, 11818, 31658, 30643, 11828, 21823, 12103, 20172, 20048, 20179, 14932, 20185, 14938}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('retirement.n.01.retirement')\", 9), (\"Lemma('retirement.n.02.retirement')\", 1)])\n",
      "collecting tokens for  politicians\n",
      "indices:    {5472, 6017, 10627, 23370, 24653, 23771, 27151, 23601, 20500, 20503, 12667, 1182}\n",
      "dict_items([(\"Lemma('politician.n.02.politician')\", 2), (\"Lemma('politician.n.01.politician')\", 3)])\n",
      "collecting tokens for  afternoons\n",
      "indices:    {26434, 20034, 35718, 11475, 26451, 30484, 35670, 16918, 26968, 35643, 7677, 447}\n",
      "dict_items([(\"Lemma('afternoon.n.01.afternoon')\", 5)])\n",
      "collecting tokens for  drawings\n",
      "indices:    {2048, 26765, 29713, 26771, 29716, 21275, 26144, 28834, 7588, 26539, 26155, 7595, 19513, 7611, 19515, 9150, 961, 25706, 26111}\n",
      "dict_items([(\"Lemma('drawing.n.01.drawing')\", 3), (\"Lemma('drawing.n.02.drawing')\", 5)])\n",
      "collecting tokens for  ave.\n",
      "indices:    {21635}\n",
      "dict_items([])\n",
      "collecting tokens for  crossroads\n",
      "indices:    {7683, 33384, 7658, 7692, 20628, 6998, 7707, 7804, 36446, 4255}\n",
      "dict_items([(\"Lemma('juncture.n.02.crossroads')\", 1), (\"Lemma('crossroads.n.03.crossroads')\", 1), (\"Lemma('hamlet.n.01.crossroads')\", 4), (\"Lemma('intersection.n.02.crossroad')\", 1)])\n",
      "collecting tokens for  elevated\n",
      "indices:    {20669}\n",
      "dict_items([])\n",
      "collecting tokens for  flights\n",
      "indices:    {21734, 31560, 18729, 34761, 18796, 18672, 18705, 26421, 18517, 17560, 24124, 17469, 30559}\n",
      "dict_items([(\"Lemma('flight.n.05.flight')\", 2), (\"Lemma('flight.n.03.flight')\", 3), (\"Lemma('flight.n.01.flight')\", 2)])\n",
      "collecting tokens for  discharge\n",
      "indices:    {14626, 14787, 14438, 11499, 14608, 11505, 11506, 24946, 4277, 17365, 20187, 14780, 25022, 25023}\n",
      "dict_items([(\"Lemma('discharge.n.01.discharge')\", 3), (\"Lemma('dispatch.v.02.discharge')\", 2), (\"Lemma('discharge.n.02.discharge')\", 3), (\"Lemma('discharge.n.05.discharge')\", 1), (\"Lemma('discharge.n.04.discharge')\", 1)])\n",
      "collecting tokens for  represent\n",
      "indices:    {23943, 14860, 32653, 15248, 15896, 4122, 15902, 5028, 22697, 33080, 2234, 14148, 28743, 4431, 28635, 4187, 32225, 2671, 34545, 2682, 16125, 26110}\n",
      "dict_items([(\"Lemma('represent.v.04.represent')\", 3), (\"Lemma('typify.v.02.represent')\", 6), (\"Lemma('represent.v.01.represent')\", 8), (\"Lemma('exemplify.v.01.represent')\", 2), (\"Lemma('constitute.v.01.represent')\", 1), (\"Lemma('represent.v.03.represent')\", 1), (\"Lemma('represent.v.05.represent')\", 1)])\n",
      "collecting tokens for  crashed\n",
      "indices:    {6462, 33729, 12738, 12740, 30387, 21717, 35351, 12728, 18649, 6906, 5054}\n",
      "dict_items([(\"Lemma('crash.v.01.crash')\", 6), (\"Lemma('crash.v.04.crash')\", 1), (\"Lemma('crash.v.02.crash')\", 3), (\"Lemma('crash.v.03.crash')\", 1)])\n",
      "collecting tokens for  kowalski\n",
      "indices:    {21369}\n",
      "dict_items([])\n",
      "collecting tokens for  constituted\n",
      "indices:    {20161, 15236, 20165, 20164, 14694, 22821, 31732, 27996, 10941}\n",
      "dict_items([(\"Lemma('appoint.v.01.constitute')\", 1), (\"Lemma('constitute.v.01.constitute')\", 8)])\n",
      "collecting tokens for  historian\n",
      "indices:    {2305, 4995, 14691, 14694, 14664, 14697, 14699, 14700, 4973, 13779, 22548, 13749, 23192, 6809}\n",
      "dict_items([(\"Lemma('historian.n.01.historian')\", 12)])\n",
      "collecting tokens for  salesman\n",
      "indices:    {15745, 11944, 21768, 11082, 34251, 22347, 21329, 30962, 16500, 15738, 15742}\n",
      "dict_items([(\"Lemma('salesman.n.01.salesman')\", 6)])\n",
      "collecting tokens for  balloon\n",
      "indices:    {23552, 11189}\n",
      "dict_items([])\n",
      "collecting tokens for  flash\n",
      "indices:    {6464, 18853, 21893, 20744, 18957, 29262, 29294, 33271, 31320, 22170, 34879}\n",
      "dict_items([(\"Lemma('flash.n.02.flash')\", 2), (\"Lemma('flash.v.01.flash')\", 2), (\"Lemma('flash.n.01.flash')\", 1)])\n",
      "collecting tokens for  scott\n",
      "indices:    {26473}\n",
      "dict_items([])\n",
      "collecting tokens for  charming\n",
      "indices:    {11072, 22115, 2279, 34794, 27088, 8376, 18842, 26363, 1212, 36478}\n",
      "dict_items([(\"Lemma('charming.s.01.charming')\", 5)])\n",
      "collecting tokens for  leather\n",
      "indices:    {708, 29582, 31120, 7857, 11032, 9626, 19550}\n",
      "dict_items([(\"Lemma('leather.n.01.leather')\", 4)])\n",
      "collecting tokens for  graduates\n",
      "indices:    {13312, 16257, 2499, 25030, 13288, 25258, 20847, 21393, 23226, 13279}\n",
      "dict_items([(\"Lemma('graduate.v.01.graduate')\", 3), (\"Lemma('alumnus.n.01.graduate')\", 3)])\n",
      "collecting tokens for  accused\n",
      "indices:    {21312, 21313, 20512, 21540, 18212, 21286, 21255, 21415, 18215, 24014, 7067, 22559}\n",
      "dict_items([(\"Lemma('accuse.v.01.accuse')\", 12)])\n",
      "collecting tokens for  conceivable\n",
      "indices:    {3778, 26211, 16228, 25449, 16173, 1360, 721, 9906, 27837, 24479}\n",
      "dict_items([(\"Lemma('conceivable.s.01.conceivable')\", 1)])\n",
      "collecting tokens for  governed\n",
      "indices:    {25601, 27972, 32292, 23560, 13705, 13706, 13708, 27295, 31697, 13714, 16410, 16415}\n",
      "dict_items([(\"Lemma('governed.n.01.governed')\", 4), (\"Lemma('govern.v.03.govern')\", 2), (\"Lemma('regulate.v.02.govern')\", 5)])\n",
      "collecting tokens for  gambling\n",
      "indices:    {22977, 36674, 6117, 27432, 17706, 2250, 28010, 6961, 12662, 37175, 17722, 21755, 6077, 37151}\n",
      "dict_items([(\"Lemma('gambling.n.01.gambling')\", 4), (\"Lemma('gamble.v.01.gamble')\", 1)])\n",
      "collecting tokens for  commercials\n",
      "indices:    {23712, 19075, 26724, 26120, 27048, 35668, 19034, 19000, 23706, 19071}\n",
      "dict_items([(\"Lemma('commercial.n.01.commercial')\", 4)])\n",
      "collecting tokens for  underwater\n",
      "indices:    {21297, 37138, 19075, 21293}\n",
      "dict_items([])\n",
      "collecting tokens for  se\n",
      "indices:    {21443}\n",
      "dict_items([])\n",
      "collecting tokens for  accompanying\n",
      "indices:    {22305, 16356, 4677, 16365, 32686, 32688, 30033, 15827, 4948, 29941, 30229}\n",
      "dict_items([(\"Lemma('attach_to.v.01.accompany')\", 6), (\"Lemma('play_along.v.02.accompany')\", 1)])\n",
      "collecting tokens for  marble\n",
      "indices:    {9840, 5077, 30903, 7609, 7354}\n",
      "dict_items([(\"Lemma('marble.n.01.marble')\", 3)])\n",
      "collecting tokens for  conservatism\n",
      "indices:    {25888, 25829, 14121, 14122, 14124, 14128, 14130, 16284}\n",
      "dict_items([(\"Lemma('conservatism.n.01.conservatism')\", 6)])\n",
      "collecting tokens for  invention\n",
      "indices:    {11462, 2570, 13674, 2571, 2574, 29934, 13620, 13429, 5205, 13623, 13624, 13626, 2559}\n",
      "dict_items([(\"Lemma('invention.n.03.invention')\", 3), (\"Lemma('invention.n.02.invention')\", 3), (\"Lemma('invention.n.01.invention')\", 6)])\n",
      "collecting tokens for  airport\n",
      "indices:    {26945, 20500, 23301}\n",
      "dict_items([])\n",
      "collecting tokens for  vermont\n",
      "indices:    {29955}\n",
      "dict_items([])\n",
      "collecting tokens for  snapped\n",
      "indices:    {36064, 35619, 13572, 20951, 254, 17887}\n",
      "dict_items([(\"Lemma('snap.v.01.snap')\", 2), (\"Lemma('tear.v.01.snap')\", 2), (\"Lemma('snap.v.06.snap')\", 1), (\"Lemma('snap.v.03.snap')\", 1)])\n",
      "collecting tokens for  selecting\n",
      "indices:    {11613}\n",
      "dict_items([(\"Lemma('choose.v.01.select')\", 1)])\n",
      "collecting tokens for  hitting\n",
      "indices:    {609, 22978, 22979, 21635, 18445, 23086, 6645, 441, 7290}\n",
      "dict_items([(\"Lemma('hit.n.01.hit')\", 1), (\"Lemma('hit.v.02.hit')\", 2), (\"Lemma('hit.v.03.hit')\", 1), (\"Lemma('reach.v.01.hit')\", 1), (\"Lemma('hit.v.01.hit')\", 2), (\"Lemma('score.v.01.hit')\", 1)])\n",
      "collecting tokens for  sonata\n",
      "indices:    {26790}\n",
      "dict_items([])\n",
      "collecting tokens for  complicated\n",
      "indices:    {23268, 15460, 19515, 4939, 4749, 32239, 27951, 14223, 3184, 15507, 29424, 4024, 887, 3192, 4057, 28859, 26524, 32223}\n",
      "dict_items([(\"Lemma('complicated.s.01.complicated')\", 8), (\"Lemma('complicate.v.02.complicate')\", 2), (\"Lemma('complicate.v.01.complicate')\", 3)])\n",
      "collecting tokens for  honestly\n",
      "indices:    {13826, 549, 4586, 19723, 25260, 27029, 1205, 18583, 4638}\n",
      "dict_items([(\"Lemma('honestly.r.01.honestly')\", 6), (\"Lemma('honestly.r.02.honestly')\", 1)])\n",
      "collecting tokens for  careers\n",
      "indices:    {25349, 21882, 22384, 31709, 13268, 661, 31742, 14938, 9148, 13277, 31774}\n",
      "dict_items([(\"Lemma('career.n.01.career')\", 4), (\"Lemma('career.n.02.career')\", 1)])\n",
      "collecting tokens for  microscope\n",
      "indices:    {34336, 11361, 11371, 4145, 4179, 11355, 9148, 11359}\n",
      "dict_items([(\"Lemma('microscope.n.01.microscope')\", 7)])\n",
      "collecting tokens for  wired\n",
      "indices:    {7652, 15146, 12170, 31347, 5811, 5113, 9148, 22270}\n",
      "dict_items([(\"Lemma('wire.v.03.wire')\", 1), (\"Lemma('wire.v.01.wire')\", 3), (\"Lemma('wired.a.01.wired')\", 1), (\"Lemma('cable.v.01.wire')\", 2)])\n",
      "collecting tokens for  disastrous\n",
      "indices:    {25888, 834, 28100, 12712, 23977, 26024, 23976, 25772, 34444, 16399, 11991, 30266, 9148}\n",
      "dict_items([(\"Lemma('black.s.06.disastrous')\", 5)])\n",
      "collecting tokens for  scientist\n",
      "indices:    {31712, 21711, 34225, 21266, 21724, 23190, 20503, 19608, 27900}\n",
      "dict_items([(\"Lemma('scientist.n.01.scientist')\", 1)])\n",
      "collecting tokens for  deadly\n",
      "indices:    {31779, 30372, 5095, 25161, 34092, 17420, 29070, 850, 2707, 12221, 29055}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('deadly.s.01.deadly')\", 4)])\n",
      "collecting tokens for  anti-semitism\n",
      "indices:    {12206}\n",
      "dict_items([(\"Lemma('anti-semitism.n.01.anti-Semitism')\", 1)])\n",
      "collecting tokens for  disabled\n",
      "indices:    {11779, 11780, 11781, 24945, 14995, 14997, 24950, 14999, 15003}\n",
      "dict_items([(\"Lemma('disabled.n.01.disabled')\", 2), (\"Lemma('disabled.s.01.disabled')\", 5)])\n",
      "collecting tokens for  productive\n",
      "indices:    {13377, 25601, 30403, 11746, 11779, 335, 14995, 2741, 2742, 14359, 2744, 11773}\n",
      "dict_items([(\"Lemma('productive.a.01.productive')\", 8), (\"Lemma('generative.a.01.productive')\", 1), (\"Lemma('productive.s.03.productive')\", 1)])\n",
      "collecting tokens for  herbert\n",
      "indices:    {20936}\n",
      "dict_items([])\n",
      "collecting tokens for  preacher\n",
      "indices:    {7072, 7074, 25896, 7052, 6414, 14418, 6418, 6039, 36216, 6394}\n",
      "dict_items([(\"Lemma('preacher.n.01.preacher')\", 8)])\n",
      "collecting tokens for  identity\n",
      "indices:    {30218, 1290, 14219, 5777, 5405, 13343, 22059, 17326, 13372, 32963, 13383, 13385, 4302, 4303, 13136, 13393, 16210, 7129, 27737, 14427, 13151, 11488, 4577, 14580, 14581, 4724}\n",
      "dict_items([(\"Lemma('identity.n.01.identity')\", 12), (\"Lemma('identity.n.04.identity')\", 2), (\"Lemma('identity.n.02.identity')\", 5), (\"Lemma('identity.n.03.identity')\", 2)])\n",
      "collecting tokens for  parent\n",
      "indices:    {22059, 15629, 22414, 15630, 1934, 15825, 33169, 10703, 15663, 15662}\n",
      "dict_items([(\"Lemma('parent.n.01.parent')\", 7)])\n",
      "collecting tokens for  simplest\n",
      "indices:    {20387, 20037, 31206, 2412, 32494, 26901, 29431, 30140, 2558}\n",
      "dict_items([(\"Lemma('simple.a.01.simple')\", 3)])\n",
      "collecting tokens for  tempted\n",
      "indices:    {8261, 25896, 36301, 26901, 31997, 11483, 12956, 14237, 23742}\n",
      "dict_items([(\"Lemma('entice.v.01.tempt')\", 2), (\"Lemma('tempt.v.01.tempt')\", 4), (\"Lemma('tempt.v.03.tempt')\", 1), (\"Lemma('charm.v.04.tempt')\", 1)])\n",
      "collecting tokens for  johnny\n",
      "indices:    {22995}\n",
      "dict_items([])\n",
      "collecting tokens for  mckinley\n",
      "indices:    {5744}\n",
      "dict_items([])\n",
      "collecting tokens for  randolph\n",
      "indices:    {7707}\n",
      "dict_items([])\n",
      "collecting tokens for  argue\n",
      "indices:    {27265, 22785, 6787, 14661, 14667, 5484, 14384, 25649, 14674, 36311, 3481, 22743, 4827, 14653, 27262, 27743}\n",
      "dict_items([(\"Lemma('argue.v.02.argue')\", 4), (\"Lemma('argue.v.01.argue')\", 12)])\n",
      "collecting tokens for  restricted\n",
      "indices:    {16096, 10273, 25921, 10691, 16164, 1860, 2824, 36527, 27923, 27862, 22743}\n",
      "dict_items([(\"Lemma('restrict.v.02.restrict')\", 4), (\"Lemma('restrict.v.01.restrict')\", 3), (\"Lemma('restricted.a.01.restricted')\", 2), (\"Lemma('restricted.s.02.restricted')\", 1)])\n",
      "collecting tokens for  penetration\n",
      "indices:    {30816, 1761, 30786, 14949, 22632, 30799, 14959, 30772, 30806, 30810, 30811, 3420}\n",
      "dict_items([(\"Lemma('penetration.n.01.penetration')\", 2), (\"Lemma('penetration.n.03.penetration')\", 1), (\"Lemma('penetration.n.02.penetration')\", 1)])\n",
      "collecting tokens for  attacks\n",
      "indices:    {24130, 28151, 30277, 27237, 20253, 15723, 21405, 27184, 23798, 25751, 23004, 23863, 21406}\n",
      "dict_items([(\"Lemma('attack.v.05.attack')\", 1), (\"Lemma('attack.v.02.attack')\", 1)])\n",
      "collecting tokens for  explosion\n",
      "indices:    {6272, 12706, 18627, 14782, 454, 20747, 20235, 15159, 21361, 21364, 35351, 27928, 26174, 30015}\n",
      "dict_items([(\"Lemma('explosion.n.01.explosion')\", 4), (\"Lemma('explosion.n.02.explosion')\", 2)])\n",
      "collecting tokens for  arranging\n",
      "indices:    {28613, 20847}\n",
      "dict_items([(\"Lemma('arrange.v.02.arrange')\", 1)])\n",
      "collecting tokens for  progressive\n",
      "indices:    {32256, 27746, 4771, 31785, 26379, 27757, 2159, 4784, 26419, 4758, 3126, 2167, 32250, 24413}\n",
      "dict_items([(\"Lemma('progressive.a.01.progressive')\", 3), (\"Lemma('progressive.s.02.progressive')\", 3)])\n",
      "collecting tokens for  lemon\n",
      "indices:    {10680, 385}\n",
      "dict_items([(\"Lemma('lemon.n.01.lemon')\", 1), (\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  cd\n",
      "indices:    {20307}\n",
      "dict_items([])\n",
      "collecting tokens for  blooming\n",
      "indices:    {1664, 1668, 1608, 1674, 1612, 1653, 9493, 18843, 9500}\n",
      "dict_items([(\"Lemma('blooming.n.01.blooming')\", 3), (\"Lemma('bloom.v.01.bloom')\", 3)])\n",
      "collecting tokens for  hereby\n",
      "indices:    {14754, 29955, 14886, 2156, 14766, 14898, 14749}\n",
      "dict_items([(\"Lemma('hereby.r.01.hereby')\", 6)])\n",
      "collecting tokens for  calhoun\n",
      "indices:    {34220}\n",
      "dict_items([])\n",
      "collecting tokens for  protestantism\n",
      "indices:    {28020}\n",
      "dict_items([])\n",
      "collecting tokens for  genius\n",
      "indices:    {13953, 27298, 11459, 29926, 26088, 31722, 26092, 36208, 2648, 31738, 37115, 2654}\n",
      "dict_items([(\"Lemma('genius.n.01.genius')\", 2), (\"Lemma('brilliance.n.03.genius')\", 2)])\n",
      "collecting tokens for  awarded\n",
      "indices:    {11459, 22180, 2277, 21224, 28584, 11338, 21644, 20948, 11446, 11447, 7162}\n",
      "dict_items([(\"Lemma('award.v.01.award')\", 6), (\"Lemma('award.v.02.award')\", 1)])\n",
      "collecting tokens for  attach\n",
      "indices:    {29890, 15581, 20075, 20076, 15595, 20084, 27862, 2269, 15930, 31515, 8860, 2077, 31134}\n",
      "dict_items([(\"Lemma('attach.v.01.attach')\", 10), (\"Lemma('attach.v.02.attach')\", 1), (\"Lemma('attach.v.03.attach')\", 1)])\n",
      "collecting tokens for  depot\n",
      "indices:    {5169}\n",
      "dict_items([])\n",
      "collecting tokens for  anywhere\n",
      "indices:    {36456, 22173, 22397}\n",
      "dict_items([])\n",
      "collecting tokens for  quote\n",
      "indices:    {25185, 14692, 13831, 25896, 2247, 23019, 24469, 13845, 31575, 3356, 14076, 14079}\n",
      "dict_items([(\"Lemma('quote.v.01.quote')\", 10)])\n",
      "collecting tokens for  tries\n",
      "indices:    {288, 289, 26758, 263, 23050, 7627, 26576, 31953, 274, 24339, 10612, 2686, 26175}\n",
      "dict_items([(\"Lemma('try.v.01.try')\", 9), (\"Lemma('attempt.n.01.try')\", 4)])\n",
      "collecting tokens for  minneapolis\n",
      "indices:    {22179}\n",
      "dict_items([])\n",
      "collecting tokens for  sensory\n",
      "indices:    {4226, 34756, 2149, 4039, 2156, 2167, 13660, 13661}\n",
      "dict_items([(\"Lemma('centripetal.s.03.sensory')\", 4), (\"Lemma('sensory.a.02.sensory')\", 3)])\n",
      "collecting tokens for  cranston\n",
      "indices:    {21650}\n",
      "dict_items([])\n",
      "collecting tokens for  ashamed\n",
      "indices:    {35064, 25338, 36111}\n",
      "dict_items([])\n",
      "collecting tokens for  gods\n",
      "indices:    {28091, 25349, 20966, 7795}\n",
      "dict_items([(\"Lemma('deity.n.01.god')\", 1)])\n",
      "collecting tokens for  screw\n",
      "indices:    {29888, 20358, 28809, 34712, 29788, 28797}\n",
      "dict_items([])\n",
      "collecting tokens for  flush\n",
      "indices:    {18465, 15074, 28804, 33516, 28797, 19351, 29755, 19773, 28830}\n",
      "dict_items([(\"Lemma('flush.r.01.flush')\", 1), (\"Lemma('flower.n.03.flush')\", 1), (\"Lemma('bloom.n.04.flush')\", 1), (\"Lemma('flush.s.01.flush')\", 1), (\"Lemma('flush.v.02.flush')\", 1)])\n",
      "collecting tokens for  ruanda-urundi\n",
      "indices:    {33062}\n",
      "dict_items([])\n",
      "collecting tokens for  indians\n",
      "indices:    {508}\n",
      "dict_items([(\"Lemma('group.n.01.group')\", 1)])\n",
      "collecting tokens for  vs.\n",
      "indices:    {33200, 22802, 29077, 17919}\n",
      "dict_items([])\n",
      "collecting tokens for  reflect\n",
      "indices:    {29408, 27872, 4963, 31268, 15012, 11369, 11370, 13612, 26765, 15054, 15503, 15280, 13615, 3987, 11412, 32505, 26586, 31837}\n",
      "dict_items([(\"Lemma('reflect.v.01.reflect')\", 10), (\"Lemma('reflect.v.03.reflect')\", 6), (\"Lemma('reflect.v.04.reflect')\", 1), (\"Lemma('chew_over.v.01.reflect')\", 1)])\n",
      "collecting tokens for  consisted\n",
      "indices:    {26624, 26629, 32519, 14997, 2198, 26664, 21931, 26417, 12342, 26427, 3265, 30529, 36929, 35654, 4166, 2380, 4174, 2897, 32466, 36311, 2903}\n",
      "dict_items([])\n",
      "collecting tokens for  depressed\n",
      "indices:    {24065, 33378, 30243, 24068, 20119, 16300, 10798, 25487, 33269, 24823}\n",
      "dict_items([(\"Lemma('depressed.s.01.depressed')\", 1), (\"Lemma('depress.v.01.depress')\", 2)])\n",
      "collecting tokens for  claire\n",
      "indices:    {8476}\n",
      "dict_items([(\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  fans\n",
      "indices:    {449, 386, 35688, 35692, 26255, 26256, 26289, 7921, 35734, 24598, 19512, 23097, 29053, 35678, 959}\n",
      "dict_items([(\"Lemma('sports_fan.n.01.fan')\", 2), (\"Lemma('fan.n.03.fan')\", 1), (\"Lemma('fan.n.01.fan')\", 2)])\n",
      "collecting tokens for  trujillo\n",
      "indices:    {23664}\n",
      "dict_items([])\n",
      "collecting tokens for  slate\n",
      "indices:    {6376, 21481, 20485}\n",
      "dict_items([])\n",
      "collecting tokens for  lumber\n",
      "indices:    {15117}\n",
      "dict_items([(\"Lemma('lumber.n.01.lumber')\", 1)])\n",
      "collecting tokens for  merchants\n",
      "indices:    {12520, 12521, 31567, 4784, 13010, 21205, 7833, 7866}\n",
      "dict_items([(\"Lemma('merchant.n.01.merchant')\", 6)])\n",
      "collecting tokens for  tale\n",
      "indices:    {2368, 17249, 12708, 25776, 26228, 7957, 26230, 7958, 25972, 2362, 28157}\n",
      "dict_items([(\"Lemma('narrative.n.01.tale')\", 5)])\n",
      "collecting tokens for  wrist\n",
      "indices:    {3875, 8829}\n",
      "dict_items([(\"Lemma('wrist.n.01.wrist')\", 2)])\n",
      "collecting tokens for  fool\n",
      "indices:    {27392, 35330, 9090, 16646, 10120, 12817, 2581, 8983, 34076, 35229, 16672, 8996, 34981, 35236, 34869, 10293, 6075, 9532, 29906, 36474, 8663, 17756, 17503, 22241, 17634, 17644, 16497, 9593, 16506, 36219, 36476}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('jester.n.01.fool')\", 1), (\"Lemma('fool.n.01.fool')\", 8), (\"Lemma('fool.v.01.fool')\", 3), (\"Lemma('chump.n.01.fool')\", 6)])\n",
      "collecting tokens for  adjusting\n",
      "indices:    {32571, 14789, 29893, 32615, 32617, 32587, 16437, 18683, 9789, 32574}\n",
      "dict_items([(\"Lemma('adjust.v.01.adjust')\", 6), (\"Lemma('align.v.01.adjust')\", 2), (\"Lemma('adjust.v.04.adjust')\", 1)])\n",
      "collecting tokens for  contrasts\n",
      "indices:    {14659, 16104, 16081, 1809, 27541, 16086, 23511, 34523, 5278}\n",
      "dict_items([(\"Lemma('contrast.n.01.contrast')\", 4), (\"Lemma('line.n.29.contrast')\", 1), (\"Lemma('contrast.v.01.contrast')\", 1)])\n",
      "collecting tokens for  tie\n",
      "indices:    {22924, 29677, 13422, 20975, 35762, 27958, 11382}\n",
      "dict_items([(\"Lemma('tie.v.01.tie')\", 3), (\"Lemma('necktie.n.01.tie')\", 1), (\"Lemma('tie.v.05.tie')\", 1)])\n",
      "collecting tokens for  sera\n",
      "indices:    {3584, 4160, 3589, 3590, 3527, 3576, 3519, 3532, 3507, 3508, 3510, 4150, 3512, 4126, 4158, 4159}\n",
      "dict_items([(\"Lemma('serum.n.01.serum')\", 16)])\n",
      "collecting tokens for  antibodies\n",
      "indices:    {3586, 3527, 3504, 4177, 3507, 3508, 3510, 3515, 3583}\n",
      "dict_items([(\"Lemma('antibody.n.01.antibody')\", 7)])\n",
      "collecting tokens for  albumin\n",
      "indices:    {3587, 3525, 3526, 3527, 3529, 3514, 3515, 3517}\n",
      "dict_items([(\"Lemma('albumin.n.01.albumin')\", 8)])\n",
      "collecting tokens for  indirect\n",
      "indices:    {14624, 4129, 3587, 22821, 3527, 4199, 4169, 3530, 4650, 4142, 4125, 4182, 3514, 3515, 3517, 4190, 4191}\n",
      "dict_items([(\"Lemma('indirect.s.01.indirect')\", 8), (\"Lemma('indirect.a.02.indirect')\", 2)])\n",
      "collecting tokens for  prevention\n",
      "indices:    {12323, 12260, 32900, 11525, 11529, 11537, 178, 20446}\n",
      "dict_items([(\"Lemma('prevention.n.01.prevention')\", 5)])\n",
      "collecting tokens for  jail\n",
      "indices:    {21210}\n",
      "dict_items([])\n",
      "collecting tokens for  han\n",
      "indices:    {27559}\n",
      "dict_items([])\n",
      "collecting tokens for  cow\n",
      "indices:    {18208, 3844, 24716, 18316, 11566, 18287, 28365, 10449, 6930, 12116, 31382, 3800, 12090, 18299, 3805, 18271}\n",
      "dict_items([(\"Lemma('cow.n.01.cow')\", 13)])\n",
      "collecting tokens for  summit\n",
      "indices:    {22656, 22595, 22596, 22661, 22629, 22600, 27134}\n",
      "dict_items([])\n",
      "collecting tokens for  decomposition\n",
      "indices:    {3105, 4326, 4294, 4360, 4362, 4301, 3092, 4374, 4311, 3101}\n",
      "dict_items([(\"Lemma('decomposition.n.02.decomposition')\", 3), (\"Lemma('decomposition.n.01.decomposition')\", 7)])\n",
      "collecting tokens for  computed\n",
      "indices:    {28930, 15907, 28901, 15912, 28937, 28906, 2940, 28940, 2957, 22060, 14830, 3561, 15924, 15892, 4438, 28855, 28917, 3132}\n",
      "dict_items([(\"Lemma('calculate.v.01.compute')\", 18)])\n",
      "collecting tokens for  advise\n",
      "indices:    {30723, 25637, 31686, 7338, 17360, 9910, 30778, 25021}\n",
      "dict_items([(\"Lemma('rede.v.02.advise')\", 4), (\"Lemma('advise.v.02.advise')\", 2), (\"Lemma('advice.n.01.advice')\", 1)])\n",
      "collecting tokens for  consent\n",
      "indices:    {15460, 25637, 32199, 25096, 16425, 13705, 22665, 13708, 13706, 22769, 13714, 24085, 20381, 2431}\n",
      "dict_items([(\"Lemma('consent.n.01.consent')\", 7), (\"Lemma('accept.v.03.consent')\", 1)])\n",
      "collecting tokens for  pierre\n",
      "indices:    {5861}\n",
      "dict_items([(\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  jessica\n",
      "indices:    {9575}\n",
      "dict_items([(\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  hostess\n",
      "indices:    {11018, 9355, 9549, 37141, 21141, 21143, 9595, 36508}\n",
      "dict_items([(\"Lemma('hostess.n.01.hostess')\", 1), (\"Lemma('stewardess.n.01.hostess')\", 1), (\"Lemma('hostess.n.02.hostess')\", 2)])\n",
      "collecting tokens for  compete\n",
      "indices:    {25826, 23491, 22756, 5477, 11657, 3242, 30539, 14064, 22769, 14452, 28598, 20342, 3962, 24605, 28575}\n",
      "dict_items([(\"Lemma('compete.v.01.compete')\", 15)])\n",
      "collecting tokens for  fictional\n",
      "indices:    {31841, 13890, 13893, 13895, 13896, 13899, 2412, 7277, 27024, 2706, 13906, 13917}\n",
      "dict_items([(\"Lemma('fictional.a.01.fictional')\", 7), (\"Lemma('fabricated.s.01.fictional')\", 3)])\n",
      "collecting tokens for  airplanes\n",
      "indices:    {32391, 3495, 13067, 32407, 32410, 32380, 18686, 30559}\n",
      "dict_items([(\"Lemma('airplane.n.01.airplane')\", 3)])\n",
      "collecting tokens for  chores\n",
      "indices:    {224, 12577, 12100, 36071, 30058, 28365, 11998, 25009, 23026, 7700, 33431, 21370, 190}\n",
      "dict_items([(\"Lemma('job.n.02.chore')\", 6)])\n",
      "collecting tokens for  bastard\n",
      "indices:    {18432, 35520, 17634, 17674, 6508, 19820, 8144, 5939, 9908, 5909, 19804, 6623}\n",
      "dict_items([(\"Lemma('asshole.n.01.bastard')\", 11)])\n",
      "collecting tokens for  museums\n",
      "indices:    {32069, 29318, 1008, 29299, 32630, 31580, 31581, 29278}\n",
      "dict_items([(\"Lemma('museum.n.01.museum')\", 1)])\n",
      "collecting tokens for  demanding\n",
      "indices:    {25346, 30819, 12068, 6825, 8237, 15727, 37009, 27762, 13463, 22009, 11707, 13214}\n",
      "dict_items([(\"Lemma('demand.v.01.demand')\", 4), (\"Lemma('necessitate.v.01.demand')\", 2), (\"Lemma('demanding.a.01.demanding')\", 4)])\n",
      "collecting tokens for  francesca\n",
      "indices:    {37049}\n",
      "dict_items([])\n",
      "collecting tokens for  prince\n",
      "indices:    {24018}\n",
      "dict_items([])\n",
      "collecting tokens for  pro-western\n",
      "indices:    {20291}\n",
      "dict_items([])\n",
      "collecting tokens for  casey\n",
      "indices:    {23323}\n",
      "dict_items([])\n",
      "collecting tokens for  reform\n",
      "indices:    {4608, 4609, 4610, 22787, 28036, 4612, 24073, 28042, 32161, 23591, 20407, 20281, 5309, 25794, 2377, 27863, 28016, 23669, 14455}\n",
      "dict_items([(\"Lemma('reform.v.01.reform')\", 1), (\"Lemma('reform.n.01.reform')\", 1)])\n",
      "collecting tokens for  dreadful\n",
      "indices:    {12194, 7814, 22874, 27443, 27799, 6392, 11162, 36958}\n",
      "dict_items([(\"Lemma('awful.s.02.dreadful')\", 3), (\"Lemma('atrocious.s.02.dreadful')\", 1)])\n",
      "collecting tokens for  entertained\n",
      "indices:    {21120, 21121, 7403, 21131, 14446, 9934, 27160, 21145, 36958}\n",
      "dict_items([(\"Lemma('entertain.v.01.entertain')\", 8), (\"Lemma('entertain.v.02.entertain')\", 1)])\n",
      "collecting tokens for  viola\n",
      "indices:    {36978}\n",
      "dict_items([])\n",
      "collecting tokens for  meadow\n",
      "indices:    {10457, 20021, 23542}\n",
      "dict_items([(\"Lemma('hayfield.n.01.meadow')\", 2)])\n",
      "collecting tokens for  saami\n",
      "indices:    {11875}\n",
      "dict_items([(\"Lemma('group.n.01.group')\", 1)])\n",
      "collecting tokens for  detective\n",
      "indices:    {34020, 13893, 21542, 13901, 13904, 12689, 13971, 13941, 12663, 13976, 13918, 13983}\n",
      "dict_items([(\"Lemma('detective.n.01.detective')\", 7)])\n",
      "collecting tokens for  rare\n",
      "indices:    {9345, 14851, 23050, 23190, 1047, 13565, 671, 26529, 2083, 37158, 12711, 11053, 20915, 9401, 24002, 27211, 23885, 31823, 31825, 29272, 20952, 22490, 29152, 4963, 23780, 26982, 30825, 30845}\n",
      "dict_items([(\"Lemma('rare.s.01.rare')\", 5), (\"Lemma('rare.s.02.rare')\", 2), (\"Lemma('rare.s.03.rare')\", 2)])\n",
      "collecting tokens for  chuck\n",
      "indices:    {29890, 371}\n",
      "dict_items([])\n",
      "collecting tokens for  returns\n",
      "indices:    {15567}\n",
      "dict_items([(\"Lemma('tax_return.n.01.return')\", 1)])\n",
      "collecting tokens for  helpless\n",
      "indices:    {37093, 12038, 9902, 34063, 13358, 34065, 7794, 1267, 1245, 36954, 28507, 34429, 445}\n",
      "dict_items([(\"Lemma('helpless.s.02.helpless')\", 3), (\"Lemma('helpless.s.01.helpless')\", 3), (\"Lemma('helpless.s.03.helpless')\", 1)])\n",
      "collecting tokens for  explicit\n",
      "indices:    {26465, 16129, 10691, 16410, 27302, 14377, 16333, 31985, 27860, 20469, 16404, 27865, 16442}\n",
      "dict_items([(\"Lemma('explicit.a.01.explicit')\", 7)])\n",
      "collecting tokens for  equals\n",
      "indices:    {25188, 16453, 28875, 28911, 3036}\n",
      "dict_items([(\"Lemma('equal.v.01.equal')\", 4), (\"Lemma('peer.n.01.equal')\", 1)])\n",
      "collecting tokens for  limitations\n",
      "indices:    {28456, 26057, 26058, 27886, 15471, 14767, 37104, 34739, 23508, 14741, 14998, 14871, 27992, 2746}\n",
      "dict_items([(\"Lemma('limitation.n.02.limitation')\", 3), (\"Lemma('restriction.n.01.limitation')\", 3)])\n",
      "collecting tokens for  customary\n",
      "indices:    {20226, 27044, 8263, 19324, 15324, 12524, 2990, 4723, 23703, 34205, 11452, 2077, 32894}\n",
      "dict_items([(\"Lemma('customary.s.01.customary')\", 4), (\"Lemma('accustomed.s.02.customary')\", 4)])\n",
      "collecting tokens for  gentlemen\n",
      "indices:    {34722, 36963, 9634, 26598, 27278, 33758, 6135, 23064, 27258, 24823, 9949, 24990, 831}\n",
      "dict_items([(\"Lemma('gentleman.n.01.gentleman')\", 4)])\n",
      "collecting tokens for  lighting\n",
      "indices:    {15131, 1179}\n",
      "dict_items([(\"Lemma('lighting.n.02.lighting')\", 1), (\"Lemma('light.n.09.lighting')\", 1)])\n",
      "collecting tokens for  productivity\n",
      "indices:    {13376, 11724, 16375, 16376, 16377, 4604}\n",
      "dict_items([(\"Lemma('productiveness.n.01.productivity')\", 6)])\n",
      "collecting tokens for  negotiate\n",
      "indices:    {25162, 21455, 27804, 27452, 22591, 27455}\n",
      "dict_items([(\"Lemma('negociate.v.06.negotiate')\", 6)])\n",
      "collecting tokens for  mid\n",
      "indices:    {1419, 18444, 15533, 25423, 13680, 1265, 4757, 9142, 15863, 1429, 12377, 15514, 7580}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('mid.s.01.mid')\", 8), (\"Lemma('center.s.01.middle')\", 1)])\n",
      "collecting tokens for  oxford\n",
      "indices:    {14387}\n",
      "dict_items([(\"Lemma('location.n.01.location')\", 1)])\n",
      "collecting tokens for  symbolic\n",
      "indices:    {26401, 13767, 2667, 13740, 27534, 15862, 26807, 15864, 31162, 27548}\n",
      "dict_items([(\"Lemma('emblematic.s.01.symbolic')\", 2), (\"Lemma('symbolic.a.01.symbolic')\", 2), (\"Lemma('symbolic.a.03.symbolic')\", 1)])\n",
      "collecting tokens for  conceivably\n",
      "indices:    {17199, 30256, 28469, 26965, 3798, 16668, 27801, 2139, 27548}\n",
      "dict_items([(\"Lemma('conceivably.r.01.conceivably')\", 4)])\n",
      "collecting tokens for  distinguish\n",
      "indices:    {4224, 4231, 11785, 2346, 32011, 13968, 4405, 31605, 13626, 14685, 2333}\n",
      "dict_items([(\"Lemma('distinguish.v.01.distinguish')\", 9), (\"Lemma('spot.v.02.distinguish')\", 2)])\n",
      "collecting tokens for  superstition\n",
      "indices:    {2368, 18694, 1234, 7892, 12788, 2358, 2588}\n",
      "dict_items([(\"Lemma('superstition.n.01.superstition')\", 7)])\n",
      "collecting tokens for  chien\n",
      "indices:    {12491}\n",
      "dict_items([])\n",
      "collecting tokens for  emerson\n",
      "indices:    {27281}\n",
      "dict_items([])\n",
      "collecting tokens for  watercolor\n",
      "indices:    {11301, 11338, 11282, 11283, 11324}\n",
      "dict_items([(\"Lemma('watercolor.n.01.watercolor')\", 3), (\"Lemma('watercolor.n.02.watercolor')\", 2)])\n",
      "collecting tokens for  disarmament\n",
      "indices:    {22624, 23747, 21746, 23284, 24661, 27127, 25181}\n",
      "dict_items([])\n",
      "collecting tokens for  intentions\n",
      "indices:    {25280, 27872, 24451, 20494, 11217, 22706, 31157, 22613, 34390, 21973, 20415, 17018, 21980, 17726, 25279}\n",
      "dict_items([(\"Lemma('purpose.n.01.intention')\", 2), (\"Lemma('intention.n.02.intention')\", 1)])\n",
      "collecting tokens for  scrambled\n",
      "indices:    {22912, 17987, 34308, 17829, 19273, 34102, 925, 6335}\n",
      "dict_items([(\"Lemma('clamber.v.01.scramble')\", 3), (\"Lemma('scramble.v.01.scramble')\", 4), (\"Lemma('scrambled.s.01.scrambled')\", 1)])\n",
      "collecting tokens for  melting\n",
      "indices:    {1472, 7109, 5445, 36205, 2893, 912, 25682, 30163, 2326, 18968, 29407}\n",
      "dict_items([(\"Lemma('melt.v.01.melt')\", 3), (\"Lemma('dissolve.v.09.melt')\", 1), (\"Lemma('thaw.n.01.melting')\", 1), (\"Lemma('liquescent.s.01.melting')\", 1), (\"Lemma('mellow.v.02.melt')\", 1)])\n",
      "collecting tokens for  mirror\n",
      "indices:    {11362, 8740, 7461, 26757, 22150, 12305, 17590, 36502, 9467, 19644, 16478, 11359}\n",
      "dict_items([(\"Lemma('mirror.n.01.mirror')\", 8), (\"Lemma('mirror.v.01.mirror')\", 1)])\n",
      "collecting tokens for  latin\n",
      "indices:    {26631}\n",
      "dict_items([])\n",
      "collecting tokens for  hampshire\n",
      "indices:    {30536}\n",
      "dict_items([])\n",
      "collecting tokens for  rely\n",
      "indices:    {4929, 4578, 26114, 17513, 25577, 5263, 16209, 19350, 15385, 22654}\n",
      "dict_items([(\"Lemma('trust.v.01.rely')\", 1)])\n",
      "collecting tokens for  distinctive\n",
      "indices:    {24674, 12291, 3843, 14531, 1799, 1768, 12296, 29963, 1867, 16209, 31860, 13237}\n",
      "dict_items([(\"Lemma('distinctive.s.01.distinctive')\", 5), (\"Lemma('classifiable.s.01.distinctive')\", 3)])\n",
      "collecting tokens for  noting\n",
      "indices:    {14400, 23463, 36969, 27339, 13300, 20309, 5752, 31167}\n",
      "dict_items([(\"Lemma('note.v.01.note')\", 4), (\"Lemma('note.v.03.note')\", 2), (\"Lemma('notice.v.02.note')\", 2)])\n",
      "collecting tokens for  lasting\n",
      "indices:    {37093, 24301, 9681, 31827, 14485, 32664, 11929, 36475, 29406, 22143}\n",
      "dict_items([(\"Lemma('permanent.a.01.lasting')\", 2), (\"Lemma('last.v.01.last')\", 1), (\"Lemma('durable.s.01.lasting')\", 1)])\n",
      "collecting tokens for  ludie\n",
      "indices:    {6493}\n",
      "dict_items([(\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  players\n",
      "indices:    {1730, 22403, 324, 22405, 299, 19887, 19892, 629, 19897, 635, 668, 19837}\n",
      "dict_items([(\"Lemma('player.n.01.player')\", 9), (\"Lemma('musician.n.01.player')\", 1)])\n",
      "collecting tokens for  hohlbein\n",
      "indices:    {17395}\n",
      "dict_items([(\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  threshold\n",
      "indices:    {22449, 3358}\n",
      "dict_items([(\"Lemma('threshold.n.01.threshold')\", 1)])\n",
      "collecting tokens for  ballot\n",
      "indices:    {22372, 135, 21353, 138, 139, 47, 25554, 32022, 20375, 20831}\n",
      "dict_items([(\"Lemma('ballot.n.01.ballot')\", 3), (\"Lemma('vote.n.01.ballot')\", 1)])\n",
      "collecting tokens for  tense\n",
      "indices:    {30243, 24805, 25704, 10282, 10284, 10288, 22868, 30262}\n",
      "dict_items([(\"Lemma('tense.n.01.tense')\", 1)])\n",
      "collecting tokens for  jacques\n",
      "indices:    {6828}\n",
      "dict_items([])\n",
      "collecting tokens for  census\n",
      "indices:    {33088, 33090, 33093, 4814, 25360, 26738, 33080, 33083}\n",
      "dict_items([(\"Lemma('census.n.01.census')\", 1)])\n",
      "collecting tokens for  receiver\n",
      "indices:    {14880, 16994, 14794, 11404, 17296, 17820, 14428, 14879}\n",
      "dict_items([(\"Lemma('telephone_receiver.n.01.receiver')\", 3), (\"Lemma('receiver.n.01.receiver')\", 2), (\"Lemma('liquidator.n.02.receiver')\", 2), (\"Lemma('recipient.n.01.receiver')\", 1)])\n",
      "collecting tokens for  pill\n",
      "indices:    {11399, 11401, 20074, 11403, 11404, 11405, 7273, 27953}\n",
      "dict_items([(\"Lemma('pill.n.01.pill')\", 5), (\"Lemma('pill.n.02.pill')\", 1)])\n",
      "collecting tokens for  worst\n",
      "indices:    {6542, 12819, 1941, 32023, 17052, 27805, 27807, 10145, 13864, 30512, 6089, 21961, 32121, 15441, 9941, 35544, 627, 7289, 31997}\n",
      "dict_items([(\"Lemma('worst.a.01.worst')\", 8), (\"Lemma('worst.n.01.worst')\", 2)])\n",
      "collecting tokens for  locally\n",
      "indices:    {29858, 22403, 20324, 5162, 23756, 20305, 11611, 32568, 32984, 21371}\n",
      "dict_items([(\"Lemma('locally.r.01.locally')\", 2)])\n",
      "collecting tokens for  250\n",
      "indices:    {13059, 12486, 14825, 21579, 12940, 27949, 142, 29968, 27185, 22546, 22131, 23190, 23035}\n",
      "dict_items([])\n",
      "collecting tokens for  objections\n",
      "indices:    {34689, 29924, 15846, 27223, 15273, 23945, 5231, 24212, 12213, 27286, 17782}\n",
      "dict_items([(\"Lemma('expostulation.n.01.objection')\", 3), (\"Lemma('protest.n.02.objection')\", 1), (\"Lemma('objection.n.02.objection')\", 1)])\n",
      "collecting tokens for  singers\n",
      "indices:    {26752, 26312, 26315, 14540, 1069, 26382, 34734, 26290, 34747, 20894}\n",
      "dict_items([(\"Lemma('singer.n.01.singer')\", 2)])\n",
      "collecting tokens for  servants\n",
      "indices:    {12577, 12578, 37122, 21254, 21286, 31785, 8234, 23949, 6030, 31567, 19, 21272, 21275}\n",
      "dict_items([(\"Lemma('servant.n.01.servant')\", 4)])\n",
      "collecting tokens for  btu\n",
      "indices:    {30167}\n",
      "dict_items([])\n",
      "collecting tokens for  bronchial\n",
      "indices:    {3848, 3849, 3850, 3771, 3773, 3782, 3785, 3787, 3789, 3790, 3791, 3793, 3794, 3795, 3799, 3807, 3808, 3813, 3817, 3818, 3820, 3824, 3826, 3828, 3829, 3830, 3836}\n",
      "dict_items([(\"Lemma('bronchial.a.01.bronchial')\", 4)])\n",
      "collecting tokens for  curb\n",
      "indices:    {33474, 33443, 33444, 33411, 32068, 13604, 33960, 33738, 17006, 19120, 17043}\n",
      "dict_items([(\"Lemma('suppress.v.01.curb')\", 1), (\"Lemma('curb.n.01.curb')\", 4)])\n",
      "collecting tokens for  eve\n",
      "indices:    {1509}\n",
      "dict_items([(\"Lemma('eve.n.01.Eve')\", 1)])\n",
      "collecting tokens for  beneficial\n",
      "indices:    {31233, 14721, 14724, 14727, 4239, 24179, 14356, 2773}\n",
      "dict_items([(\"Lemma('beneficial.s.01.beneficial')\", 6)])\n",
      "collecting tokens for  capita\n",
      "indices:    {15009, 15012, 23528, 15017, 15018, 15019, 15020, 15021, 15022, 15059, 15061, 15063, 15065}\n",
      "dict_items([])\n",
      "collecting tokens for  sauce\n",
      "indices:    {29217, 29510, 29222, 29514, 29501, 29484, 29517, 30476, 29519, 29520, 29458, 29427, 29492, 29498, 29531, 29181, 29503}\n",
      "dict_items([])\n",
      "collecting tokens for  mix\n",
      "indices:    {29181, 10921, 5358, 26513, 29458, 13332, 29781, 29529, 37082, 1085}\n",
      "dict_items([(\"Lemma('blend.v.03.mix')\", 5), (\"Lemma('mix.v.04.mix')\", 1), (\"Lemma('desegregate.v.01.mix')\", 1)])\n",
      "collecting tokens for  compulsivity\n",
      "indices:    {15696, 15665, 15699, 15667, 15669, 15701, 15706, 15676, 15679}\n",
      "dict_items([(\"Lemma('compulsiveness.n.01.compulsivity')\", 9)])\n",
      "collecting tokens for  circles\n",
      "indices:    {16136, 780, 13346, 24616, 10927, 27958, 6840, 17208, 2617, 2493, 2498, 24649, 24657, 8913, 36055, 13538, 28904, 6760, 24572, 8575}\n",
      "dict_items([(\"Lemma('circle.n.01.circle')\", 5), (\"Lemma('set.n.05.circle')\", 7), (\"Lemma('lap.n.05.circle')\", 1)])\n",
      "collecting tokens for  praised\n",
      "indices:    {36385, 28164, 24649, 25930, 24940, 303, 22548, 14456, 25, 28156, 12991}\n",
      "dict_items([(\"Lemma('praise.v.01.praise')\", 11)])\n",
      "collecting tokens for  replacement\n",
      "indices:    {4065, 16289, 16197, 453, 4103, 16173, 30512, 1232, 32338, 32339, 25845, 29114, 14044, 26205, 25727}\n",
      "dict_items([(\"Lemma('surrogate.n.01.replacement')\", 1), (\"Lemma('substitution.n.01.replacement')\", 2), (\"Lemma('replacement.n.01.replacement')\", 4), (\"Lemma('substitute.n.01.replacement')\", 1)])\n",
      "collecting tokens for  hire\n",
      "indices:    {16257, 17697, 12133, 20102, 12136, 5138, 6134, 855, 20310, 15097, 15739, 12126, 12127}\n",
      "dict_items([(\"Lemma('hire.v.01.hire')\", 12), (\"Lemma('rent.v.04.hire')\", 1)])\n",
      "collecting tokens for  monopoly\n",
      "indices:    {5447, 22793, 22765, 22800, 13910, 15383, 27831, 4634, 25212, 15229}\n",
      "dict_items([(\"Lemma('monopoly.n.02.monopoly')\", 2), (\"Lemma('monopoly.n.01.monopoly')\", 3)])\n",
      "collecting tokens for  ham\n",
      "indices:    {29217, 29218, 28583, 19468, 29524, 29493, 29492, 22136, 22137}\n",
      "dict_items([])\n",
      "collecting tokens for  buzz\n",
      "indices:    {36685}\n",
      "dict_items([])\n",
      "collecting tokens for  spending\n",
      "indices:    {21125, 21127, 21128, 25484, 8086, 25888, 36128, 32546, 24868, 32550, 30894, 22062, 20662, 20664, 5049, 8123, 7483, 28357, 28499, 23636, 15843, 17383, 20972, 20973, 20974, 33139, 11763, 11646}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('spend.v.02.spend')\", 5), (\"Lemma('spend.v.01.spend')\", 12), (\"Lemma('spending.n.01.spending')\", 1)])\n",
      "collecting tokens for  fleet\n",
      "indices:    {36497}\n",
      "dict_items([])\n",
      "collecting tokens for  fork\n",
      "indices:    {36932, 31941, 34153, 5643, 8847, 29519, 8848, 8850, 18451, 29205, 19454}\n",
      "dict_items([(\"Lemma('fork.n.04.fork')\", 1), (\"Lemma('fork.n.01.fork')\", 4), (\"Lemma('fork.n.03.fork')\", 1)])\n",
      "collecting tokens for  sensation\n",
      "indices:    {6181, 27175, 14600, 13673, 31915, 9197, 4910, 14643, 36950, 32088, 219}\n",
      "dict_items([(\"Lemma('ace.n.03.sensation')\", 1), (\"Lemma('sensation.n.01.sensation')\", 5)])\n",
      "collecting tokens for  spokesman\n",
      "indices:    {27844, 21638, 20713, 21161, 21163, 21776, 15249, 21778, 21429, 20151}\n",
      "dict_items([(\"Lemma('spokesman.n.01.spokesman')\", 1)])\n",
      "collecting tokens for  bursting\n",
      "indices:    {12804, 24348, 8263, 6890, 19274, 1802, 1561, 8433, 36697, 9466, 35420, 7293, 19036}\n",
      "dict_items([(\"Lemma('burst.v.01.burst')\", 4), (\"Lemma('break.v.09.burst')\", 1), (\"Lemma('burst.v.04.burst')\", 1), (\"Lemma('explode.v.02.burst')\", 3), (\"Lemma('abound.v.02.burst')\", 2)])\n",
      "collecting tokens for  dumped\n",
      "indices:    {34148, 6629, 34169, 9004, 35118, 7254, 35769, 35420, 19454}\n",
      "dict_items([(\"Lemma('dump.v.01.dump')\", 8), (\"Lemma('dump.v.02.dump')\", 1)])\n",
      "collecting tokens for  staying\n",
      "indices:    {26593, 24570, 33898, 26924, 27217, 13044, 2389, 18488, 25367, 25368, 17146}\n",
      "dict_items([(\"Lemma('stay.v.02.stay')\", 3), (\"Lemma('stay.v.01.stay')\", 3), (\"Lemma('bide.v.01.stay')\", 2), (\"Lemma('stay.v.05.stay')\", 1)])\n",
      "collecting tokens for  trivial\n",
      "indices:    {8480, 19610, 2600, 23691, 8395, 2701, 35669, 22746, 16126}\n",
      "dict_items([(\"Lemma('fiddling.s.01.trivial')\", 3)])\n",
      "collecting tokens for  lectures\n",
      "indices:    {25976, 2393, 25972, 14445}\n",
      "dict_items([(\"Lemma('lecture.n.01.lecture')\", 1)])\n",
      "collecting tokens for  devote\n",
      "indices:    {36769, 13826, 4385, 26727, 25929, 25964, 12236, 11475, 20149, 13272}\n",
      "dict_items([(\"Lemma('give.v.18.devote')\", 6), (\"Lemma('give.v.10.devote')\", 4)])\n",
      "collecting tokens for  steeple\n",
      "indices:    {6379, 6382, 7889, 9170, 6386, 6389, 6391, 6393, 6426}\n",
      "dict_items([(\"Lemma('steeple.n.01.steeple')\", 9)])\n",
      "collecting tokens for  investigated\n",
      "indices:    {11745, 3177, 2860, 14798, 14064, 14066, 15644, 21623, 14808, 2874, 14812, 32924, 3710}\n",
      "dict_items([(\"Lemma('investigate.v.02.investigate')\", 1), (\"Lemma('investigate.v.01.investigate')\", 12)])\n",
      "collecting tokens for  dislike\n",
      "indices:    {3680, 5987, 2532, 12231, 35944, 37034, 12906, 35724, 14318, 17397, 2487, 14652}\n",
      "dict_items([(\"Lemma('dislike.v.01.dislike')\", 4), (\"Lemma('dislike.n.02.dislike')\", 2), (\"Lemma('disfavor.n.02.dislike')\", 4)])\n",
      "collecting tokens for  relax\n",
      "indices:    {5856, 25157, 18983, 31528, 16366, 6450, 33206, 8763, 3004}\n",
      "dict_items([(\"Lemma('relax.v.01.relax')\", 7), (\"Lemma('loosen.v.07.relax')\", 1), (\"Lemma('relax.v.04.relax')\", 1)])\n",
      "collecting tokens for  kohnstamm\n",
      "indices:    {33229}\n",
      "dict_items([])\n",
      "collecting tokens for  rockefeller\n",
      "indices:    {25441}\n",
      "dict_items([])\n",
      "collecting tokens for  considerations\n",
      "indices:    {16124, 25293, 27534, 15151, 15223, 3473, 27885, 12307, 25044, 25043, 3798, 15127, 16246, 25045, 3420, 32798}\n",
      "dict_items([(\"Lemma('circumstance.n.03.consideration')\", 7), (\"Lemma('consideration.n.01.consideration')\", 1), (\"Lemma('consideration.n.03.consideration')\", 1)])\n",
      "collecting tokens for  degrees\n",
      "indices:    {2849, 30148, 12772, 30149, 2118, 4108, 31376, 30160, 33234, 12599, 28759, 15673, 2106, 27165, 2110}\n",
      "dict_items([(\"Lemma('academic_degree.n.01.degree')\", 4), (\"Lemma('degree.n.04.degree')\", 2), (\"Lemma('degree.n.01.degree')\", 1), (\"Lemma('degree.n.02.degree')\", 1)])\n",
      "collecting tokens for  customer\n",
      "indices:    {10689, 11682, 16579, 15237, 16554, 11661, 25006, 27858, 15220, 33429, 11639, 11640, 11644, 17693}\n",
      "dict_items([(\"Lemma('customer.n.01.customer')\", 11)])\n",
      "collecting tokens for  f-plane\n",
      "indices:    {4544, 4513, 4515, 4518, 4554, 4535, 4506, 4539}\n",
      "dict_items([])\n",
      "collecting tokens for  prisoners\n",
      "indices:    {34272, 19343, 24700, 24702, 34271}\n",
      "dict_items([(\"Lemma('prisoner.n.01.prisoner')\", 1)])\n",
      "collecting tokens for  goldberg\n",
      "indices:    {20810}\n",
      "dict_items([])\n",
      "collecting tokens for  privileged\n",
      "indices:    {22816, 37121, 24220, 25971, 32215, 442, 14459, 4796, 14430}\n",
      "dict_items([(\"Lemma('privileged.a.01.privileged')\", 4)])\n",
      "collecting tokens for  slightest\n",
      "indices:    {17057, 16898, 18307, 749, 2605, 4597, 27317, 14459, 11485}\n",
      "dict_items([])\n",
      "collecting tokens for  reforms\n",
      "indices:    {4609, 21955, 20260, 31719, 28078, 20431, 20467, 23639, 28409, 14459, 24189}\n",
      "dict_items([(\"Lemma('reform.n.01.reform')\", 1), (\"Lemma('reform.n.02.reform')\", 1)])\n",
      "collecting tokens for  sheer\n",
      "indices:    {2886, 29800, 752, 5909, 34557}\n",
      "dict_items([(\"Lemma('absolute.s.02.sheer')\", 2)])\n",
      "collecting tokens for  salvation\n",
      "indices:    {20992, 27459}\n",
      "dict_items([])\n",
      "collecting tokens for  infant\n",
      "indices:    {7265, 15396, 33028, 23207, 28071, 34665, 32150, 8862}\n",
      "dict_items([(\"Lemma('baby.n.01.infant')\", 2)])\n",
      "collecting tokens for  congregations\n",
      "indices:    {1408, 27261, 28009, 24333, 13341, 13363, 13332, 13365, 13367, 13339, 13373, 13342}\n",
      "dict_items([(\"Lemma('congregation.n.01.congregation')\", 9)])\n",
      "collecting tokens for  survival\n",
      "indices:    {31100, 25542}\n",
      "dict_items([])\n",
      "collecting tokens for  leaf\n",
      "indices:    {31489, 1666, 13540, 7429, 30416, 29233, 30000, 29236, 9174, 30425, 30075, 36318}\n",
      "dict_items([(\"Lemma('leaf.n.01.leaf')\", 2)])\n",
      "collecting tokens for  establishing\n",
      "indices:    {15681, 22691, 14172, 20298, 32458, 22028, 4749, 32590, 32144, 16306, 32723, 32565, 32149, 2744, 4764, 32127}\n",
      "dict_items([(\"Lemma('establish.v.05.establish')\", 2), (\"Lemma('establish.v.01.establish')\", 9), (\"Lemma('lay_down.v.01.establish')\", 4), (\"Lemma('establish.v.02.establish')\", 1)])\n",
      "collecting tokens for  handy\n",
      "indices:    {9376, 28837, 10886, 28839, 552, 29320, 29815, 35359}\n",
      "dict_items([(\"Lemma('handy.s.01.handy')\", 1), (\"Lemma('handy.s.02.handy')\", 1)])\n",
      "collecting tokens for  unitarian\n",
      "indices:    {27281}\n",
      "dict_items([])\n",
      "collecting tokens for  grim\n",
      "indices:    {19112, 36010, 36652, 19309, 27698, 33269, 4886, 13848, 36122}\n",
      "dict_items([(\"Lemma('grim.s.01.grim')\", 2), (\"Lemma('black.s.09.grim')\", 1)])\n",
      "collecting tokens for  passengers\n",
      "indices:    {29698, 24125, 23304, 25353, 27986, 29203, 29202, 25205, 22198, 10230, 23317, 24123, 14907, 9628, 25053, 24124}\n",
      "dict_items([(\"Lemma('passenger.n.01.passenger')\", 3)])\n",
      "collecting tokens for  coats\n",
      "indices:    {29665, 6914, 29571, 29614, 18095, 29616, 3828, 9655}\n",
      "dict_items([(\"Lemma('coat.n.01.coat')\", 1), (\"Lemma('coat.v.02.coat')\", 1), (\"Lemma('coating.n.01.coat')\", 1)])\n",
      "collecting tokens for  phenomena\n",
      "indices:    {2625, 4385, 11485, 11461, 32872, 28105, 34826, 30221, 2861, 3184, 2866, 3224, 2166, 3320, 26809, 16091, 2140, 16059}\n",
      "dict_items([(\"Lemma('phenomenon.n.01.phenomenon')\", 11)])\n",
      "collecting tokens for  occurring\n",
      "indices:    {3105, 14693, 3878, 3975, 32937, 3978, 3820, 17646, 2866, 4243, 4117, 14683, 3836, 3805}\n",
      "dict_items([(\"Lemma('happen.v.01.occur')\", 9)])\n",
      "collecting tokens for  sheep\n",
      "indices:    {4161, 3844, 10821, 10822, 11589, 10824, 11561, 10823, 11115, 11515, 31412, 21589, 11511, 11547, 11548, 36415}\n",
      "dict_items([(\"Lemma('sheep.n.01.sheep')\", 11)])\n",
      "collecting tokens for  bloat\n",
      "indices:    {11552, 11526, 11592, 11548, 11579, 11580, 11581, 11519}\n",
      "dict_items([(\"Lemma('bloat.n.01.bloat')\", 8)])\n",
      "collecting tokens for  substituted\n",
      "indices:    {32288, 16001, 4034, 11843, 16197, 6760, 2286, 28944, 3281, 11731, 14454}\n",
      "dict_items([(\"Lemma('substitute.v.01.substitute')\", 7), (\"Lemma('substitute.v.02.substitute')\", 4)])\n",
      "collecting tokens for  rejects\n",
      "indices:    {13954, 3720, 3723, 26191, 3728, 1362, 25747, 31930}\n",
      "dict_items([(\"Lemma('reject.v.01.reject')\", 7), (\"Lemma('disapprove.v.02.reject')\", 1)])\n",
      "collecting tokens for  porous\n",
      "indices:    {2888, 2856, 2891, 2892, 2955, 1647, 2927, 2929, 2903, 2908, 1631}\n",
      "dict_items([(\"Lemma('porous.s.01.porous')\", 11)])\n",
      "collecting tokens for  economically\n",
      "indices:    {27881, 20771, 20781, 5415}\n",
      "dict_items([(\"Lemma('economically.r.01.economically')\", 1)])\n",
      "collecting tokens for  taxi\n",
      "indices:    {5895, 18696, 17736, 35723, 21772, 13518, 19694, 21168, 20500, 36536}\n",
      "dict_items([(\"Lemma('cab.n.03.taxi')\", 3)])\n",
      "collecting tokens for  timothy\n",
      "indices:    {29955}\n",
      "dict_items([])\n",
      "collecting tokens for  northeast\n",
      "indices:    {21508}\n",
      "dict_items([])\n",
      "collecting tokens for  illustrations\n",
      "indices:    {32718}\n",
      "dict_items([])\n",
      "collecting tokens for  advocate\n",
      "indices:    {28069, 12968, 25161, 474, 2485, 30839, 25306, 23931}\n",
      "dict_items([(\"Lemma('preach.v.02.advocate')\", 1), (\"Lemma('recommend.v.01.advocate')\", 3), (\"Lemma('advocate.n.01.advocate')\", 2)])\n",
      "collecting tokens for  filling\n",
      "indices:    {22179, 17829, 22182, 37031, 3786, 3787, 3788, 3279, 15217, 20561, 27380, 36886, 29654, 18904, 12154, 35549, 29982}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('fill.v.01.fill')\", 7), (\"Lemma('filling.n.01.filling')\", 1), (\"Lemma('meet.v.04.fill')\", 1), (\"Lemma('filling.n.02.filling')\", 2)])\n",
      "collecting tokens for  dynamic\n",
      "indices:    {32869, 27687, 1737, 27562, 31212, 23184, 1810, 15763, 31892, 20469, 21817, 21819, 32062}\n",
      "dict_items([(\"Lemma('dynamic.a.01.dynamic')\", 3)])\n",
      "collecting tokens for  patch\n",
      "indices:    {992, 35263, 30636, 16717, 7807, 19125, 16731, 19229, 26175}\n",
      "dict_items([(\"Lemma('plot.n.02.patch')\", 3), (\"Lemma('patch.n.03.patch')\", 2)])\n",
      "collecting tokens for  objection\n",
      "indices:    {8352, 11488, 27106, 20705, 12194, 32200, 32201, 20714, 15281, 24152}\n",
      "dict_items([(\"Lemma('expostulation.n.01.objection')\", 3), (\"Lemma('protest.n.02.objection')\", 1)])\n",
      "collecting tokens for  christians\n",
      "indices:    {27263}\n",
      "dict_items([])\n",
      "collecting tokens for  paths\n",
      "indices:    {27776, 7905, 7906, 7840, 20773, 23113, 24782, 24790}\n",
      "dict_items([(\"Lemma('way.n.05.path')\", 2), (\"Lemma('path.n.02.path')\", 1)])\n",
      "collecting tokens for  foster\n",
      "indices:    {9995}\n",
      "dict_items([])\n",
      "collecting tokens for  spirits\n",
      "indices:    {28096, 9052, 1227, 28079, 28146, 13044, 12532, 28117, 1659, 23708}\n",
      "dict_items([(\"Lemma('spirit.n.04.spirit')\", 2), (\"Lemma('emotional_state.n.01.spirit')\", 2), (\"Lemma('liquor.n.01.spirits')\", 1)])\n",
      "collecting tokens for  robbery\n",
      "indices:    {2418}\n",
      "dict_items([])\n",
      "collecting tokens for  retail\n",
      "indices:    {28640, 11654, 24009, 22063, 21553, 5466, 25247}\n",
      "dict_items([(\"Lemma('retail.v.01.retail')\", 1), (\"Lemma('retail.n.01.retail')\", 1)])\n",
      "collecting tokens for  anniversary\n",
      "indices:    {21666, 22379, 28300, 12854, 601, 32633}\n",
      "dict_items([(\"Lemma('anniversary.n.01.anniversary')\", 2)])\n",
      "collecting tokens for  aerosol\n",
      "indices:    {3454, 3459, 3486, 3401, 3436, 3414, 3450, 3422}\n",
      "dict_items([(\"Lemma('aerosol.n.01.aerosol')\", 8)])\n",
      "collecting tokens for  listened\n",
      "indices:    {19460, 30853, 17798, 16652, 34572, 17298, 6044, 22564, 9385, 9386, 1726, 18626, 1731, 6607, 33365, 8572, 8300, 17782, 33270, 33912, 10108, 6014}\n",
      "dict_items([(\"Lemma('listen.v.01.listen')\", 14), (\"Lemma('listen.v.02.listen')\", 8)])\n",
      "collecting tokens for  helen\n",
      "indices:    {26761}\n",
      "dict_items([])\n",
      "collecting tokens for  cream\n",
      "indices:    {29506, 29187, 29507, 29381, 36069, 5160, 31147, 29484, 29489, 8210, 22132, 27191, 29498, 29181, 29502, 10615}\n",
      "dict_items([(\"Lemma('cream.n.01.cream')\", 2)])\n",
      "collecting tokens for  campus\n",
      "indices:    {5963, 20493}\n",
      "dict_items([(\"Lemma('campus.n.01.campus')\", 1)])\n",
      "collecting tokens for  recalls\n",
      "indices:    {865, 26946, 26199, 10695, 24111, 23029, 13367, 24794, 27518}\n",
      "dict_items([(\"Lemma('remember.v.01.recall')\", 5), (\"Lemma('echo.v.03.recall')\", 1), (\"Lemma('hark_back.v.01.recall')\", 3)])\n",
      "collecting tokens for  aluminum\n",
      "indices:    {14785, 2915, 2949, 29413, 29864, 34570, 29868, 3248, 3250, 10483, 14773, 29754, 29755, 2911}\n",
      "dict_items([(\"Lemma('aluminum.n.01.aluminum')\", 5)])\n",
      "collecting tokens for  employs\n",
      "indices:    {21858, 14822, 6023, 11790, 26959, 13939, 14779, 21848, 21851}\n",
      "dict_items([(\"Lemma('use.v.01.employ')\", 7), (\"Lemma('hire.v.01.employ')\", 2)])\n",
      "collecting tokens for  sherman\n",
      "indices:    {21787}\n",
      "dict_items([])\n",
      "collecting tokens for  sketches\n",
      "indices:    {11298, 7587, 14426, 11302, 26937, 13848, 14415, 1106, 14418, 7605, 26136, 7545, 7546, 11291}\n",
      "dict_items([(\"Lemma('sketch.n.01.sketch')\", 8), (\"Lemma('sketch.v.02.sketch')\", 1), (\"Lemma('sketch.n.02.sketch')\", 4)])\n",
      "collecting tokens for  interstate\n",
      "indices:    {21644}\n",
      "dict_items([])\n",
      "collecting tokens for  capillary\n",
      "indices:    {3143, 3144, 3849, 3850, 3793, 3772, 3197, 3262}\n",
      "dict_items([(\"Lemma('capillary.n.01.capillary')\", 2)])\n",
      "collecting tokens for  cab\n",
      "indices:    {33754, 18916, 18950, 23143, 18955, 21164, 21166, 18897, 33748, 33812, 25658}\n",
      "dict_items([(\"Lemma('cab.n.01.cab')\", 4)])\n",
      "collecting tokens for  miscellaneous\n",
      "indices:    {11937, 14861, 3189}\n",
      "dict_items([(\"Lemma('assorted.s.01.miscellaneous')\", 1)])\n",
      "collecting tokens for  protected\n",
      "indices:    {36125, 23942, 3226, 23722, 1678, 28655, 33852, 5009, 25361, 29938, 29366, 12153, 34842, 3227, 4796, 27069, 13567}\n",
      "dict_items([(\"Lemma('protect.v.01.protect')\", 12), (\"Lemma('protect.v.02.protect')\", 1)])\n",
      "collecting tokens for  rebellion\n",
      "indices:    {31814, 7846, 5287, 32075, 25547, 25709, 22864, 7861, 13205, 1463}\n",
      "dict_items([(\"Lemma('rebellion.n.02.rebellion')\", 5)])\n",
      "collecting tokens for  disciplined\n",
      "indices:    {12961, 1061, 6923, 26423, 12278, 7670, 11256, 1917}\n",
      "dict_items([(\"Lemma('disciplined.s.01.disciplined')\", 4), (\"Lemma('discipline.v.01.discipline')\", 2), (\"Lemma('disciplined.s.02.disciplined')\", 1)])\n",
      "collecting tokens for  leaped\n",
      "indices:    {35617, 29223, 11240, 35591, 26129, 26419, 12890, 6906, 17246, 19039}\n",
      "dict_items([(\"Lemma('jump.v.01.leap')\", 8), (\"Lemma('leap.v.02.leap')\", 1)])\n",
      "collecting tokens for  residence\n",
      "indices:    {33024, 29191, 12168, 6029, 17549, 13331, 32417, 32422, 5432, 9144, 13116, 2495, 27841, 13382, 14539, 4811, 11100, 15596, 15597, 15598, 33020, 22262, 32380}\n",
      "dict_items([(\"Lemma('residence.n.02.residence')\", 2), (\"Lemma('residence.n.01.residence')\", 10), (\"Lemma('residency.n.01.residence')\", 2), (\"Lemma('mansion.n.02.residence')\", 1)])\n",
      "collecting tokens for  seated\n",
      "indices:    {27747, 17543, 2191, 21045, 5333, 17526, 28729, 22522, 21691}\n",
      "dict_items([(\"Lemma('seat.v.01.seat')\", 2), (\"Lemma('seat.v.02.seat')\", 1), (\"Lemma('induct.v.01.seat')\", 1), (\"Lemma('seated.a.01.seated')\", 1)])\n",
      "collecting tokens for  skills\n",
      "indices:    {641, 16258, 32899, 27910, 29968, 1173, 16289, 16290, 16292, 15782, 174, 23092, 13249, 1731, 13261, 27864, 11611, 13281, 4577, 13284, 13285, 13286, 16232, 13291, 14065, 16254}\n",
      "dict_items([(\"Lemma('skill.n.01.skill')\", 18), (\"Lemma('skill.n.02.skill')\", 3)])\n",
      "collecting tokens for  super\n",
      "indices:    {1545}\n",
      "dict_items([])\n",
      "collecting tokens for  dick\n",
      "indices:    {20936}\n",
      "dict_items([])\n",
      "collecting tokens for  gather\n",
      "indices:    {19328, 21890, 2686, 25515, 36207, 15166, 5111, 9780, 5975, 1021, 31582}\n",
      "dict_items([(\"Lemma('gather.v.05.gather')\", 1), (\"Lemma('gather.v.01.gather')\", 5), (\"Lemma('gather.v.04.gather')\", 1), (\"Lemma('meet.v.07.gather')\", 1), (\"Lemma('accumulate.v.02.gather')\", 1)])\n",
      "collecting tokens for  entertain\n",
      "indices:    {29508, 34377, 21133, 1198, 20975, 36274, 21139, 21142, 10870, 8921, 20924, 21119}\n",
      "dict_items([(\"Lemma('entertain.v.01.entertain')\", 12)])\n",
      "collecting tokens for  kids\n",
      "indices:    {5633, 5637, 13201, 21009, 35099, 18077, 25256, 681, 25257, 297, 19888, 16947, 20924, 9291, 10317, 19534, 22352, 20954, 10870}\n",
      "dict_items([(\"Lemma('child.n.01.kid')\", 12), (\"Lemma('pull_the_leg_of.v.01.kid')\", 1)])\n",
      "collecting tokens for  fraction\n",
      "indices:    {3984, 4177, 3580, 3354, 2268}\n",
      "dict_items([(\"Lemma('fraction.n.01.fraction')\", 2), (\"Lemma('fraction.n.03.fraction')\", 1), (\"Lemma('fraction.n.02.fraction')\", 2)])\n",
      "collecting tokens for  transformation\n",
      "indices:    {32771, 32778, 34667, 32781, 14701, 14611, 32822, 31190, 13914, 26588}\n",
      "dict_items([(\"Lemma('transformation.n.01.transformation')\", 3)])\n",
      "collecting tokens for  solitary\n",
      "indices:    {13793, 26689, 7587, 13962, 3662, 2158, 5296, 30198, 35769}\n",
      "dict_items([(\"Lemma('lone.s.02.solitary')\", 3), (\"Lemma('nongregarious.s.01.solitary')\", 1)])\n",
      "collecting tokens for  deny\n",
      "indices:    {31495, 2568, 22793, 20492, 13714, 24211, 5268, 24860, 14367, 22054, 23719, 8231, 31785, 2089, 14380, 2353, 24115, 14650, 28101, 5445, 8522, 11084, 17230, 11087, 31829, 2140, 25823, 19427, 5225, 33259, 5357, 2543, 14705, 22775, 3835}\n",
      "dict_items([(\"Lemma('deny.v.02.deny')\", 16), (\"Lemma('deny.v.01.deny')\", 12), (\"Lemma('deny.v.04.deny')\", 6), (\"Lemma('deny.v.03.deny')\", 1)])\n",
      "collecting tokens for  lever\n",
      "indices:    {29124, 28742, 28720, 29873, 28721, 28728, 28729, 11866, 28732, 20349, 29887}\n",
      "dict_items([(\"Lemma('lever.n.01.lever')\", 1)])\n",
      "collecting tokens for  blatz\n",
      "indices:    {20137}\n",
      "dict_items([])\n",
      "collecting tokens for  assault\n",
      "indices:    {12642, 21539, 32259, 13871, 21488, 21487, 35926, 14623}\n",
      "dict_items([(\"Lemma('assault.n.01.assault')\", 1), (\"Lemma('assault.n.02.assault')\", 1)])\n",
      "collecting tokens for  cursing\n",
      "indices:    {7143, 6923, 18639, 34033, 8050, 9011, 12893}\n",
      "dict_items([(\"Lemma('curse.v.02.curse')\", 3), (\"Lemma('curse.v.01.curse')\", 2), (\"Lemma('curse.v.03.curse')\", 1)])\n",
      "collecting tokens for  entities\n",
      "indices:    {14208, 1227, 22061, 5392, 1232, 13649, 1236, 14616}\n",
      "dict_items([(\"Lemma('entity.n.01.entity')\", 7)])\n",
      "collecting tokens for  approaches\n",
      "indices:    {14977, 31874, 32904, 31114, 4490, 4492, 11670, 31899, 25504, 13619, 1726, 26565, 3015, 14666, 28748, 14670, 26574, 7902, 23912, 30827, 5485, 11632}\n",
      "dict_items([(\"Lemma('access.n.03.approach')\", 2), (\"Lemma('approach.v.01.approach')\", 3), (\"Lemma('approach.n.01.approach')\", 5), (\"Lemma('border_on.v.01.approach')\", 4)])\n",
      "collecting tokens for  el\n",
      "indices:    {23301}\n",
      "dict_items([])\n",
      "collecting tokens for  applies\n",
      "indices:    {16320, 3361, 31298, 15364, 2791, 32871, 4850, 32662, 3030, 1498, 25084, 5246}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('apply.v.02.apply')\", 10), (\"Lemma('use.v.01.apply')\", 1), (\"Lemma('lend_oneself.v.01.apply')\", 1)])\n",
      "collecting tokens for  fog\n",
      "indices:    {12403}\n",
      "dict_items([(\"Lemma('fog.n.01.fog')\", 1)])\n",
      "collecting tokens for  claimed\n",
      "indices:    {3808, 7683, 5316, 15626, 15627, 3821, 15314, 11283, 22036, 23157, 37108, 15351, 17016, 348, 3645, 31678, 15327}\n",
      "dict_items([(\"Lemma('claim.v.01.claim')\", 9), (\"Lemma('claim.v.03.claim')\", 3), (\"Lemma('claim.v.02.claim')\", 3), (\"Lemma('claim.v.05.claim')\", 1), (\"Lemma('claim.v.04.claim')\", 1)])\n",
      "collecting tokens for  towels\n",
      "indices:    {21026, 29448, 9098, 29996, 9104, 9107, 9012, 9014, 9337, 30043}\n",
      "dict_items([(\"Lemma('towel.n.01.towel')\", 6)])\n",
      "collecting tokens for  partisan\n",
      "indices:    {24832, 24102, 24103, 23794, 23798, 32214, 8250, 26394, 24606, 24831}\n",
      "dict_items([])\n",
      "collecting tokens for  sustained\n",
      "indices:    {8450, 32159, 26861, 32335, 34744, 15290, 4923, 32127}\n",
      "dict_items([(\"Lemma('suffer.v.02.sustain')\", 2), (\"Lemma('hold.v.10.sustain')\", 1), (\"Lemma('sustain.v.06.sustain')\", 1), (\"Lemma('prolong.v.02.sustain')\", 1)])\n",
      "collecting tokens for  missionary\n",
      "indices:    {28039}\n",
      "dict_items([])\n",
      "collecting tokens for  reflects\n",
      "indices:    {2304, 11425, 5473, 32635, 27777, 771, 2374, 32071, 32362, 11914, 13356, 11981, 24054, 14679, 32120, 14683}\n",
      "dict_items([(\"Lemma('chew_over.v.01.reflect')\", 3), (\"Lemma('reflect.v.01.reflect')\", 12), (\"Lemma('reflect.v.03.reflect')\", 1)])\n",
      "collecting tokens for  expecting\n",
      "indices:    {9216, 9794, 34962}\n",
      "dict_items([(\"Lemma('expect.v.01.expect')\", 2), (\"Lemma('expect.v.03.expect')\", 1)])\n",
      "collecting tokens for  tours\n",
      "indices:    {27009, 22532, 29288, 29258, 29259, 7467, 27161, 36447}\n",
      "dict_items([(\"Lemma('location.n.01.location')\", 1)])\n",
      "collecting tokens for  gaining\n",
      "indices:    {22721, 12641, 13387, 29038, 33084, 27391}\n",
      "dict_items([(\"Lemma('acquire.v.05.gain')\", 2), (\"Lemma('derive.v.02.gain')\", 3), (\"Lemma('reach.v.01.gain')\", 1)])\n",
      "collecting tokens for  israel\n",
      "indices:    {27754}\n",
      "dict_items([])\n",
      "collecting tokens for  muller\n",
      "indices:    {17536}\n",
      "dict_items([(\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  aesthetic\n",
      "indices:    {5025, 13929, 14602, 14618, 31532, 5021, 32079, 11250, 11189, 14616, 4665, 31546, 14652, 1789, 13464}\n",
      "dict_items([(\"Lemma('aesthetic.a.02.aesthetic')\", 2), (\"Lemma('aesthetic.a.01.aesthetic')\", 10)])\n",
      "collecting tokens for  radius\n",
      "indices:    {1892, 3368, 3025, 28945, 3345, 3381, 28951}\n",
      "dict_items([(\"Lemma('radius.n.03.radius')\", 1), (\"Lemma('radius.n.01.radius')\", 3)])\n",
      "collecting tokens for  solar\n",
      "indices:    {2592, 2832, 34483}\n",
      "dict_items([])\n",
      "collecting tokens for  conformity\n",
      "indices:    {28006, 28007, 15663, 28016, 13392, 15667, 32986, 13373, 13374}\n",
      "dict_items([(\"Lemma('conformity.n.03.conformity')\", 1), (\"Lemma('conformity.n.01.conformity')\", 2), (\"Lemma('conformity.n.02.conformity')\", 2)])\n",
      "collecting tokens for  cigarettes\n",
      "indices:    {5602, 34277, 17674, 37067, 17802, 16590, 17680, 9585, 18005, 9146}\n",
      "dict_items([(\"Lemma('cigarette.n.01.cigarette')\", 8)])\n",
      "collecting tokens for  specialization\n",
      "indices:    {26720, 1571, 27910, 1575, 23535, 2098, 756, 27864}\n",
      "dict_items([(\"Lemma('specialization.n.01.specialization')\", 2), (\"Lemma('specialization.n.02.specialization')\", 2)])\n",
      "collecting tokens for  faster\n",
      "indices:    {10149, 11622, 17893, 24044, 10093, 31024, 23090, 6521, 29114, 20284, 6909}\n",
      "dict_items([(\"Lemma('fast.a.01.fast')\", 5), (\"Lemma('quicker.r.01.faster')\", 1)])\n",
      "collecting tokens for  select\n",
      "indices:    {28579, 27141, 14121, 28459, 27629, 28141, 13722, 12144, 19350, 31897, 15930}\n",
      "dict_items([(\"Lemma('choice.s.01.select')\", 1), (\"Lemma('choose.v.01.select')\", 9)])\n",
      "collecting tokens for  gradient\n",
      "indices:    {14816, 2179, 2954, 3570, 3509, 3543, 3544, 3545, 2875, 3581, 14814}\n",
      "dict_items([(\"Lemma('gradient.n.01.gradient')\", 9)])\n",
      "collecting tokens for  sober\n",
      "indices:    {3541}\n",
      "dict_items([(\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  instructions\n",
      "indices:    {29538, 30084, 35689, 7594, 28756, 15093, 24148}\n",
      "dict_items([(\"Lemma('instruction_manual.n.01.instructions')\", 1), (\"Lemma('direction.n.06.instruction')\", 1)])\n",
      "collecting tokens for  undergoing\n",
      "indices:    {15462, 328, 13321, 7532, 33229, 31253, 14840, 2971, 31837, 3006}\n",
      "dict_items([])\n",
      "collecting tokens for  manufacturer\n",
      "indices:    {7105, 11684, 21925, 21828, 11577, 29576, 11673, 11659, 11628, 11660, 6961, 22770, 5333, 5433, 22812, 22142, 11647}\n",
      "dict_items([(\"Lemma('manufacturer.n.01.manufacturer')\", 7), (\"Lemma('manufacturer.n.02.manufacturer')\", 4)])\n",
      "collecting tokens for  ate\n",
      "indices:    {8161, 5606, 9229, 16686, 1488, 5652, 8794, 8856, 36634}\n",
      "dict_items([(\"Lemma('eat.v.01.eat')\", 3), (\"Lemma('eat.v.02.eat')\", 5)])\n",
      "collecting tokens for  afterwards\n",
      "indices:    {27283, 8156}\n",
      "dict_items([(\"Lemma('subsequently.r.01.afterwards')\", 1)])\n",
      "collecting tokens for  strengthen\n",
      "indices:    {24164, 13350, 23724, 13357, 23727, 15730, 14739, 20820, 23543, 22586, 24667, 27135}\n",
      "dict_items([(\"Lemma('strengthen.v.01.strengthen')\", 11), (\"Lemma('strengthen.v.02.strengthen')\", 1)])\n",
      "collecting tokens for  boost\n",
      "indices:    {20704, 14634, 16363, 23628, 5420, 23378, 20178, 20181, 21878, 662, 30232, 11097, 23643, 24028}\n",
      "dict_items([(\"Lemma('boost.v.04.boost')\", 1), (\"Lemma('boost.v.02.boost')\", 1), (\"Lemma('boost.n.01.boost')\", 3), (\"Lemma('hike.v.01.boost')\", 2), (\"Lemma('rise.n.09.boost')\", 1)])\n",
      "collecting tokens for  sunny\n",
      "indices:    {36098, 36069, 26986, 20909, 26798, 1521}\n",
      "dict_items([(\"Lemma('cheery.s.01.sunny')\", 1)])\n",
      "collecting tokens for  laura\n",
      "indices:    {7306}\n",
      "dict_items([])\n",
      "collecting tokens for  self-help\n",
      "indices:    {32163, 32164, 13094, 32138, 32142, 32144, 32148, 32186, 32159}\n",
      "dict_items([(\"Lemma('self-help.n.01.self-help')\", 1)])\n",
      "collecting tokens for  profitable\n",
      "indices:    {28450, 25732, 16328, 12081, 25809, 14420, 15252, 5462, 11511, 15384}\n",
      "dict_items([(\"Lemma('profitable.a.01.profitable')\", 4)])\n",
      "collecting tokens for  emission\n",
      "indices:    {2851, 3107, 2823, 2824, 2793, 2794, 2800, 2804, 2805, 2841, 2842, 2812}\n",
      "dict_items([(\"Lemma('emission.n.01.emission')\", 4)])\n",
      "collecting tokens for  epidemic\n",
      "indices:    {3488, 3489, 3490, 1256, 3477, 3484, 3486, 3487}\n",
      "dict_items([(\"Lemma('epidemic.a.01.epidemic')\", 5), (\"Lemma('epidemic.n.01.epidemic')\", 3)])\n",
      "collecting tokens for  brass\n",
      "indices:    {35329, 25221, 35974, 26632, 28812, 17551, 11119, 9490, 28754, 12818, 7446, 28822, 11129, 26042, 6428}\n",
      "dict_items([(\"Lemma('brass.n.01.brass')\", 6), (\"Lemma('administration.n.02.brass')\", 1)])\n",
      "collecting tokens for  valued\n",
      "indices:    {4369, 4504, 32411, 4515, 4516, 4522, 4528, 4535, 31545, 4541, 2494, 4544, 21827, 21830, 4568, 21618, 21619, 21620, 21621}\n",
      "dict_items([(\"Lemma('valued.s.01.valued')\", 10), (\"Lemma('value.v.01.value')\", 2), (\"Lemma('prize.v.01.value')\", 1)])\n",
      "collecting tokens for  900\n",
      "indices:    {20805, 27174, 30091, 21165, 25487, 21619, 27223, 27226}\n",
      "dict_items([])\n",
      "collecting tokens for  arises\n",
      "indices:    {2692, 20261, 10725, 25540, 25800, 14344, 10737, 1235, 13623}\n",
      "dict_items([(\"Lemma('arise.v.02.arise')\", 1), (\"Lemma('originate.v.01.arise')\", 7), (\"Lemma('arise.v.04.arise')\", 1)])\n",
      "collecting tokens for  arlen\n",
      "indices:    {14547}\n",
      "dict_items([])\n",
      "collecting tokens for  plato\n",
      "indices:    {5233}\n",
      "dict_items([(\"Lemma('plato.n.01.Plato')\", 1)])\n",
      "collecting tokens for  thyroxine\n",
      "indices:    {3941, 3950, 3955, 3958, 3960, 3961, 3962}\n",
      "dict_items([(\"Lemma('thyroxine.n.01.thyroxine')\", 7)])\n",
      "collecting tokens for  elections\n",
      "indices:    {4770, 4773, 4775, 4744, 4745, 4778, 4747, 4779, 4760, 4782, 5275, 4757, 4759, 23960, 4794, 4763}\n",
      "dict_items([(\"Lemma('election.n.01.election')\", 15)])\n",
      "collecting tokens for  discussing\n",
      "indices:    {1431, 7331, 22564, 27622, 37037, 23822, 3856, 4369, 32978, 4823, 25404}\n",
      "dict_items([(\"Lemma('hash_out.v.01.discuss')\", 4), (\"Lemma('discourse.v.01.discuss')\", 7)])\n",
      "collecting tokens for  clue\n",
      "indices:    {34210, 5987, 36036, 1091, 14120, 30830, 13935, 2578, 23478, 4247, 5884}\n",
      "dict_items([(\"Lemma('hint.n.02.clue')\", 6), (\"Lemma('clue.n.02.clue')\", 1)])\n",
      "collecting tokens for  hamilton\n",
      "indices:    {31700}\n",
      "dict_items([])\n",
      "collecting tokens for  trains\n",
      "indices:    {13217, 7969, 20907, 8787, 28469, 25205, 29976, 11770, 10526}\n",
      "dict_items([(\"Lemma('aim.v.01.train')\", 1), (\"Lemma('train.n.01.train')\", 3)])\n",
      "collecting tokens for  execution\n",
      "indices:    {2386, 2587, 25359}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('performance.n.03.execution')\", 1)])\n",
      "collecting tokens for  hoag\n",
      "indices:    {17532}\n",
      "dict_items([(\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  shivering\n",
      "indices:    {36128, 2114}\n",
      "dict_items([(\"Lemma('shudder.v.02.shiver')\", 1)])\n",
      "collecting tokens for  dreamed\n",
      "indices:    {2145, 18881, 34465, 22210, 22187, 6732, 6767, 36913, 14007, 2170, 7036, 16509}\n",
      "dict_items([(\"Lemma('dream.v.01.dream')\", 6), (\"Lemma('dreamed.s.01.dreamed')\", 1), (\"Lemma('dream.v.02.dream')\", 3)])\n",
      "collecting tokens for  mate\n",
      "indices:    {12447, 5729, 3625, 32986, 31500, 3629, 8366, 12337, 32956, 12438, 32925, 3702, 32922, 32987, 12380, 10237, 3711}\n",
      "dict_items([(\"Lemma('mate.n.01.mate')\", 4), (\"Lemma('copulate.v.01.mate')\", 4), (\"Lemma('match.n.04.mate')\", 1), (\"Lemma('spouse.n.01.mate')\", 1), (\"Lemma('mate.n.03.mate')\", 1)])\n",
      "collecting tokens for  compatible\n",
      "indices:    {24894, 16396, 32019, 14739, 27317, 3006, 4692, 14171, 32990, 14207}\n",
      "dict_items([(\"Lemma('compatible.a.01.compatible')\", 5)])\n",
      "collecting tokens for  rival\n",
      "indices:    {223, 24740, 20485, 12236, 5464, 26814, 23903}\n",
      "dict_items([(\"Lemma('rival.n.01.rival')\", 1), (\"Lemma('equal.v.02.rival')\", 1)])\n",
      "collecting tokens for  enabled\n",
      "indices:    {18504, 33227, 11091, 8500, 23957, 29755, 2556, 13182, 671}\n",
      "dict_items([(\"Lemma('enable.v.01.enable')\", 9)])\n",
      "collecting tokens for  reared\n",
      "indices:    {6336, 12422, 22089, 6321, 6902}\n",
      "dict_items([(\"Lemma('rise.v.04.rear')\", 1), (\"Lemma('rear.v.02.rear')\", 1), (\"Lemma('rear.v.01.rear')\", 3)])\n",
      "collecting tokens for  cups\n",
      "indices:    {3617, 30052, 5863, 29455, 8692, 18005, 29529, 29435, 29403}\n",
      "dict_items([(\"Lemma('cup.n.03.cup')\", 2), (\"Lemma('cup.n.01.cup')\", 2)])\n",
      "collecting tokens for  ammunition\n",
      "indices:    {11872, 11900, 35411, 11896, 11898, 35452, 11901}\n",
      "dict_items([(\"Lemma('ammunition.n.01.ammunition')\", 4)])\n",
      "collecting tokens for  prospective\n",
      "indices:    {25635, 2724, 14727, 32488, 25035, 34765, 24045, 32622, 2192, 16274, 11956, 33052, 14746, 13276, 21439}\n",
      "dict_items([(\"Lemma('prospective.a.01.prospective')\", 5)])\n",
      "collecting tokens for  cracked\n",
      "indices:    {36064, 35590, 36937, 365, 35214, 8815, 21872, 30449, 35568, 18643, 19157, 6904, 7355}\n",
      "dict_items([(\"Lemma('crack.v.04.crack')\", 1), (\"Lemma('crack.v.02.crack')\", 3), (\"Lemma('snap.v.06.crack')\", 2), (\"Lemma('break_through.v.01.crack')\", 1), (\"Lemma('chapped.s.01.cracked')\", 1), (\"Lemma('snap.v.03.crack')\", 1)])\n",
      "collecting tokens for  loved\n",
      "indices:    {31744, 7680, 14466, 27395, 8199, 36872, 16905, 9609, 33279, 14477, 16668, 30886, 13617, 37170, 19380, 36808, 36810, 36816, 27478, 32216, 28254, 8800, 34785, 36834, 27369, 23786, 6252, 6255, 36849, 10226, 35187, 35185, 36213, 19583}\n",
      "dict_items([(\"Lemma('love.v.02.love')\", 6), (\"Lemma('love.v.01.love')\", 20), (\"Lemma('love.v.03.love')\", 6)])\n",
      "collecting tokens for  rescue\n",
      "indices:    {6312, 24937, 22826, 1515, 24940, 32714, 1482, 5107, 11032, 20317, 20318}\n",
      "dict_items([(\"Lemma('rescue.v.01.rescue')\", 4), (\"Lemma('rescue.n.01.rescue')\", 2)])\n",
      "collecting tokens for  trucks\n",
      "indices:    {24833, 25250, 25251, 25253, 25255, 23342, 21999, 10713, 21630, 20316, 20317, 20318}\n",
      "dict_items([(\"Lemma('truck.n.01.truck')\", 1)])\n",
      "collecting tokens for  sizable\n",
      "indices:    {26054, 27049, 21994, 26473, 35468, 23630, 21870, 2832, 23734, 15645}\n",
      "dict_items([(\"Lemma('ample.s.03.sizable')\", 2)])\n",
      "collecting tokens for  decade\n",
      "indices:    {24323, 11658, 14091, 20622, 5275, 3997, 21288, 32169, 21290, 20778, 32172, 32173, 430, 9142, 12475, 11722, 2389, 28629, 5220, 11620, 26736, 26744, 24831}\n",
      "dict_items([(\"Lemma('decade.n.01.decade')\", 11)])\n",
      "collecting tokens for  politely\n",
      "indices:    {34724, 36286, 7302, 22891, 16913, 22485, 10870, 34709, 17886}\n",
      "dict_items([(\"Lemma('politely.r.01.politely')\", 4)])\n",
      "collecting tokens for  hart\n",
      "indices:    {1212}\n",
      "dict_items([])\n",
      "collecting tokens for  precipitated\n",
      "indices:    {12256, 32908, 30830, 3566, 3249, 3542, 20153, 3582, 4127}\n",
      "dict_items([(\"Lemma('precipitate.v.02.precipitate')\", 4), (\"Lemma('precipitate.v.01.precipitate')\", 4)])\n",
      "collecting tokens for  flatness\n",
      "indices:    {5388}\n",
      "dict_items([(\"Lemma('two-dimensionality.n.01.flatness')\", 1)])\n",
      "collecting tokens for  phoenix\n",
      "indices:    {23356}\n",
      "dict_items([])\n",
      "collecting tokens for  moss\n",
      "indices:    {23128, 34479}\n",
      "dict_items([])\n",
      "collecting tokens for  manned\n",
      "indices:    {28481, 15527, 28464, 28465, 28471, 21721, 15514, 15515, 28510}\n",
      "dict_items([(\"Lemma('manned.a.01.manned')\", 3)])\n",
      "collecting tokens for  ballroom\n",
      "indices:    {7781, 22189, 21586, 21139, 22070, 7775}\n",
      "dict_items([(\"Lemma('ballroom.n.01.ballroom')\", 2)])\n",
      "collecting tokens for  influenced\n",
      "indices:    {31874, 11203, 28070, 743, 31911, 28107, 27563, 26766, 25711, 5016, 24120, 14714, 1371}\n",
      "dict_items([(\"Lemma('determine.v.02.influence')\", 4), (\"Lemma('influence.v.01.influence')\", 9)])\n",
      "collecting tokens for  anti-slavery\n",
      "indices:    {28064, 28065, 28069, 28070, 28073, 28042, 28078, 28055, 28058, 28059}\n",
      "dict_items([])\n",
      "collecting tokens for  depending\n",
      "indices:    {3425}\n",
      "dict_items([])\n",
      "collecting tokens for  casework\n",
      "indices:    {32896, 32864, 32899, 32871, 32904, 32874, 32881, 32882, 32884, 32885, 32888, 32889}\n",
      "dict_items([])\n",
      "collecting tokens for  preferably\n",
      "indices:    {32865, 12965, 1673, 3598, 30546, 20437, 1079, 30779}\n",
      "dict_items([(\"Lemma('preferably.r.01.preferably')\", 4)])\n",
      "collecting tokens for  contradiction\n",
      "indices:    {13985, 24194, 13924, 4558, 32818, 6804, 31989, 6805, 27703, 13979, 10621}\n",
      "dict_items([(\"Lemma('contradiction.n.01.contradiction')\", 6), (\"Lemma('contradiction.n.02.contradiction')\", 1)])\n",
      "collecting tokens for  dangers\n",
      "indices:    {24194, 2594, 33704, 21900, 23568, 32017, 12306, 19349, 19320, 24858, 25407}\n",
      "dict_items([(\"Lemma('risk.n.02.danger')\", 3), (\"Lemma('danger.n.03.danger')\", 1)])\n",
      "collecting tokens for  couch\n",
      "indices:    {7264, 7588, 36965, 36967, 34983, 31120, 23025, 9556, 35093, 14558}\n",
      "dict_items([(\"Lemma('sofa.n.01.couch')\", 4)])\n",
      "collecting tokens for  sank\n",
      "indices:    {14112, 35104, 33827, 24357, 22983, 8584, 30378, 22960, 10001, 9556, 21908, 36052}\n",
      "dict_items([(\"Lemma('slump.v.03.sink')\", 2), (\"Lemma('sink.v.04.sink')\", 1), (\"Lemma('sink.v.02.sink')\", 2), (\"Lemma('sink.v.03.sink')\", 2), (\"Lemma('sink.v.01.sink')\", 3), (\"Lemma('sink.v.05.sink')\", 2)])\n",
      "collecting tokens for  consisting\n",
      "indices:    {3872, 4544, 15683, 3204, 15748, 32772, 30492, 1544, 32810, 32940, 26413, 31693, 31021, 10097, 26423, 4444, 22494}\n",
      "dict_items([(\"Lemma('dwell.v.02.consist')\", 1)])\n",
      "collecting tokens for  op.\n",
      "indices:    {26792}\n",
      "dict_items([])\n",
      "collecting tokens for  wealthy\n",
      "indices:    {19559, 30856, 21327, 4784, 30930, 30867, 5333, 28636}\n",
      "dict_items([(\"Lemma('affluent.s.01.wealthy')\", 3)])\n",
      "collecting tokens for  proteins\n",
      "indices:    {3552, 4194, 3939, 27239, 3950, 4126, 3962, 4158, 4127}\n",
      "dict_items([(\"Lemma('protein.n.01.protein')\", 8)])\n",
      "collecting tokens for  volumes\n",
      "indices:    {23525, 28936, 27882, 26925, 23536, 753}\n",
      "dict_items([(\"Lemma('volume.n.04.volume')\", 1)])\n",
      "collecting tokens for  supplement\n",
      "indices:    {32751, 32486, 3919}\n",
      "dict_items([(\"Lemma('addendum.n.01.supplement')\", 1)])\n",
      "collecting tokens for  tend\n",
      "indices:    {28808, 3215, 3216, 22799, 13331, 11412, 5404, 21922, 4772, 13221, 3626, 16441, 2630, 16206, 27740, 31850, 5484, 13171, 26995, 3194}\n",
      "dict_items([(\"Lemma('tend.v.01.tend')\", 20)])\n",
      "collecting tokens for  grain\n",
      "indices:    {27904, 30437, 23847, 23848, 19273, 24135, 29064, 19275, 29069, 16685, 29073, 23987, 29910, 18361, 22011}\n",
      "dict_items([(\"Lemma('grain.n.02.grain')\", 1), (\"Lemma('grain.n.01.grain')\", 1)])\n",
      "collecting tokens for  divorce\n",
      "indices:    {13889, 13895, 22568, 30249, 30250, 33227, 8811, 26641, 10199, 2068, 10198, 27383, 10201, 26, 20347, 10236}\n",
      "dict_items([(\"Lemma('divorce.n.01.divorce')\", 8), (\"Lemma('disassociate.v.01.divorce')\", 3)])\n",
      "collecting tokens for  aroused\n",
      "indices:    {22882, 6754, 2693, 22662, 838, 11174, 36937, 27753, 4203, 15724, 13806, 35759, 28600, 20507}\n",
      "dict_items([(\"Lemma('arouse.v.01.arouse')\", 9), (\"Lemma('stimulate.v.04.arouse')\", 1), (\"Lemma('stimulated.s.01.aroused')\", 1), (\"Lemma('raise.v.07.arouse')\", 1)])\n",
      "collecting tokens for  likewise\n",
      "indices:    {11128, 3258, 15531, 4256}\n",
      "dict_items([(\"Lemma('similarly.r.01.likewise')\", 3), (\"Lemma('besides.r.02.likewise')\", 1)])\n",
      "collecting tokens for  wasted\n",
      "indices:    {32183, 1795, 15755, 6903, 26415, 37040, 18292, 18452, 35959, 26687, 37119}\n",
      "dict_items([(\"Lemma('waste.v.01.waste')\", 4), (\"Lemma('waste.v.02.waste')\", 5), (\"Lemma('otiose.s.01.wasted')\", 1), (\"Lemma('squandered.s.01.wasted')\", 1)])\n",
      "collecting tokens for  thigh\n",
      "indices:    {4033, 35430, 34185, 271, 1584, 1594, 34876, 34878}\n",
      "dict_items([(\"Lemma('thigh.n.01.thigh')\", 4)])\n",
      "collecting tokens for  flooded\n",
      "indices:    {14341, 12775, 7850, 33743, 13776, 9807, 378, 7931}\n",
      "dict_items([(\"Lemma('flood.v.02.flood')\", 2), (\"Lemma('deluge.v.01.flood')\", 5), (\"Lemma('afloat.s.03.flooded')\", 1)])\n",
      "collecting tokens for  preoccupied\n",
      "indices:    {10144, 22754, 31269, 12006, 13453, 20244, 28341, 27098}\n",
      "dict_items([(\"Lemma('bemused.s.01.preoccupied')\", 1), (\"Lemma('haunted.s.01.preoccupied')\", 1), (\"Lemma('preoccupy.v.01.preoccupy')\", 1)])\n",
      "collecting tokens for  conflict\n",
      "indices:    {32008, 36239, 2704, 2708, 13205, 25751, 20247, 23962, 26522, 7839, 20515, 27302, 22825, 941, 13364, 20148, 28475, 21437, 581, 26827, 16462, 27729, 31196, 14428, 12642, 22630, 26100, 16379}\n",
      "dict_items([(\"Lemma('conflict.n.04.conflict')\", 2), (\"Lemma('conflict.v.01.conflict')\", 2), (\"Lemma('conflict.n.02.conflict')\", 2), (\"Lemma('conflict.v.02.conflict')\", 1), (\"Lemma('conflict.n.05.conflict')\", 2), (\"Lemma('conflict.n.01.conflict')\", 4)])\n",
      "collecting tokens for  seventeen\n",
      "indices:    {36640, 12642, 11109, 11338, 19470, 21711, 8373, 14710}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('seventeen.s.01.seventeen')\", 6)])\n",
      "collecting tokens for  bass\n",
      "indices:    {26008, 29150, 26620, 26413, 22302, 1750, 26423, 1720, 7003, 1788, 1725, 34750, 11231}\n",
      "dict_items([(\"Lemma('bass.n.01.bass')\", 1), (\"Lemma('bass.n.02.bass')\", 1)])\n",
      "collecting tokens for  spectacular\n",
      "indices:    {12962, 29989, 26982, 22951, 29328}\n",
      "dict_items([(\"Lemma('dramatic.s.02.spectacular')\", 1)])\n",
      "collecting tokens for  hodges\n",
      "indices:    {24026}\n",
      "dict_items([])\n",
      "collecting tokens for  paso\n",
      "indices:    {23301}\n",
      "dict_items([])\n",
      "collecting tokens for  tooth\n",
      "indices:    {31009, 31018, 31020, 31056, 30994, 31029, 30998, 31065, 31039}\n",
      "dict_items([])\n",
      "collecting tokens for  buddhism\n",
      "indices:    {28125}\n",
      "dict_items([])\n",
      "collecting tokens for  launched\n",
      "indices:    {21248, 28634, 12706, 28644, 22886, 4589, 32180, 20404, 7895, 15513, 37050, 31292, 21405}\n",
      "dict_items([(\"Lemma('launch.v.02.launch')\", 3), (\"Lemma('launch.v.03.launch')\", 3), (\"Lemma('establish.v.01.launch')\", 4), (\"Lemma('plunge.v.04.launch')\", 1)])\n",
      "collecting tokens for  meek\n",
      "indices:    {325}\n",
      "dict_items([(\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  peered\n",
      "indices:    {17445, 8518, 17864, 30507, 35404, 18187, 5869, 35407, 35440, 17555, 35414, 8602, 17596}\n",
      "dict_items([(\"Lemma('peer.v.01.peer')\", 13)])\n",
      "collecting tokens for  puzzled\n",
      "indices:    {5859, 1606, 34953, 34954, 5356, 7377, 10675, 7891, 12436, 8602, 30973, 10687}\n",
      "dict_items([(\"Lemma('perplex.v.01.puzzle')\", 6), (\"Lemma('at_a_loss.s.01.puzzled')\", 3)])\n",
      "collecting tokens for  receives\n",
      "indices:    {13248, 32453, 32870, 31238, 14859, 1515, 15725, 24910, 27343, 13, 15358, 31544, 12763, 2686}\n",
      "dict_items([(\"Lemma('experience.v.03.receive')\", 2), (\"Lemma('receive.v.01.receive')\", 6), (\"Lemma('receive.v.02.receive')\", 4), (\"Lemma('receive.v.06.receive')\", 1), (\"Lemma('pick_up.v.09.receive')\", 1)])\n",
      "collecting tokens for  prompt\n",
      "indices:    {28954}\n",
      "dict_items([])\n",
      "collecting tokens for  justify\n",
      "indices:    {16289, 25381, 27781, 24648, 14697, 4632, 21901, 25454, 16816, 14706, 11667, 25044, 32082, 1234, 25045, 24632, 1331}\n",
      "dict_items([(\"Lemma('justify.v.02.justify')\", 7), (\"Lemma('justify.v.01.justify')\", 10)])\n",
      "collecting tokens for  conception\n",
      "indices:    {5253, 24582, 13839, 12306, 12314, 13851, 12323, 4645, 27565, 2479, 27082, 13902, 4693, 27489, 27501, 5235, 5236, 11897, 25979, 12286, 25983}\n",
      "dict_items([(\"Lemma('concept.n.01.conception')\", 7), (\"Lemma('invention.n.01.conception')\", 1), (\"Lemma('creation.n.03.conception')\", 2), (\"Lemma('conception.n.02.conception')\", 4)])\n",
      "collecting tokens for  adoption\n",
      "indices:    {32546, 5348, 32616, 32624, 32374, 20823, 11897, 20475, 32761}\n",
      "dict_items([(\"Lemma('adoption.n.01.adoption')\", 2)])\n",
      "collecting tokens for  crest\n",
      "indices:    {8907, 18956, 12718, 12719, 7729, 12724, 36635, 35197}\n",
      "dict_items([(\"Lemma('crest.n.01.crest')\", 5), (\"Lemma('peak.n.04.crest')\", 1)])\n",
      "collecting tokens for  latent\n",
      "indices:    {11492, 32998, 15849, 1321, 15852, 31094, 18844, 13948, 11487}\n",
      "dict_items([(\"Lemma('latent.s.01.latent')\", 6), (\"Lemma('latent.s.02.latent')\", 1)])\n",
      "collecting tokens for  functioning\n",
      "indices:    {15816, 29096, 33194, 32909, 32846, 25501, 17549, 4913, 15763, 14167, 32859, 35709}\n",
      "dict_items([(\"Lemma('function.v.01.function')\", 2), (\"Lemma('functioning.a.01.functioning')\", 1)])\n",
      "collecting tokens for  proceeds\n",
      "indices:    {21377, 11411, 12620, 32655}\n",
      "dict_items([(\"Lemma('proceed.v.04.proceed')\", 1), (\"Lemma('return.n.06.proceeds')\", 1)])\n",
      "collecting tokens for  skirt\n",
      "indices:    {16964, 16965, 18154, 36779, 19467, 9549, 13550, 21041, 31387, 21148, 21053}\n",
      "dict_items([(\"Lemma('skirt.n.01.skirt')\", 4), (\"Lemma('skirt.n.02.skirt')\", 2), (\"Lemma('hedge.v.01.skirt')\", 1)])\n",
      "collecting tokens for  cooks\n",
      "indices:    {35489, 35490, 29155, 12870, 29191, 29210, 35542, 986}\n",
      "dict_items([(\"Lemma('cook.n.01.cook')\", 2)])\n",
      "collecting tokens for  psychologist\n",
      "indices:    {12000, 15748, 2188, 12045, 9326, 12015, 8143, 12630, 11992}\n",
      "dict_items([(\"Lemma('psychologist.n.01.psychologist')\", 9)])\n",
      "collecting tokens for  impressive\n",
      "indices:    {31872, 33411, 26503, 2184, 26891, 13325, 22672, 31124, 23701, 278, 25374, 26915, 26404, 26276, 1190, 28964, 26409, 11443, 2230, 2234, 32445, 13636, 1733, 23890, 2391, 31328, 31330, 26725, 8299, 1005, 20592, 9337, 27770, 1150}\n",
      "dict_items([(\"Lemma('impressive.a.01.impressive')\", 14)])\n",
      "collecting tokens for  labeled\n",
      "indices:    {23360, 8865, 11427, 4196, 6569, 4395, 3569, 17339, 2972, 4125}\n",
      "dict_items([(\"Lemma('label.v.01.label')\", 5), (\"Lemma('labeled.a.01.labeled')\", 2), (\"Lemma('tag.v.01.label')\", 2), (\"Lemma('pronounce.v.02.label')\", 1)])\n",
      "collecting tokens for  dictates\n",
      "indices:    {25285, 34379, 14201, 13903, 31953, 31058, 3802, 31898, 4733}\n",
      "dict_items([(\"Lemma('order.v.03.dictate')\", 4), (\"Lemma('dictate.n.01.dictate')\", 1), (\"Lemma('dictate.n.02.dictate')\", 1)])\n",
      "collecting tokens for  networks\n",
      "indices:    {31298, 27748, 14026, 14060, 25933, 14062, 25934, 14061, 14001, 32178, 25944, 25945, 11167}\n",
      "dict_items([(\"Lemma('network.n.01.network')\", 5), (\"Lemma('network.n.02.network')\", 1)])\n",
      "collecting tokens for  plasma\n",
      "indices:    {4097, 2878, 2865, 2867, 2879, 3578, 3579, 3581, 3962, 14847}\n",
      "dict_items([(\"Lemma('plasma.n.01.plasma')\", 5)])\n",
      "collecting tokens for  adequately\n",
      "indices:    {2626, 5256, 12170, 22699, 32399, 20720, 11515, 2582, 21752, 15001, 16091, 33214}\n",
      "dict_items([(\"Lemma('adequately.r.01.adequately')\", 5)])\n",
      "collecting tokens for  ye\n",
      "indices:    {31588, 13737, 24271, 36886, 5975}\n",
      "dict_items([])\n",
      "collecting tokens for  2000\n",
      "indices:    {28640, 32513, 23745, 24677, 28327, 12424, 32488, 20203, 12940, 3634, 25074, 21692, 2237}\n",
      "dict_items([])\n",
      "collecting tokens for  rag\n",
      "indices:    {34188, 12883, 34132, 30556, 26621, 9470}\n",
      "dict_items([(\"Lemma('rag.n.01.rag')\", 2)])\n",
      "collecting tokens for  define\n",
      "indices:    {4573, 15876, 32222, 13707, 32239, 14128, 4658, 4569, 22586, 28316, 1693, 2334}\n",
      "dict_items([(\"Lemma('define.v.02.define')\", 3), (\"Lemma('specify.v.03.define')\", 7), (\"Lemma('define.v.03.define')\", 2)])\n",
      "collecting tokens for  symbols\n",
      "indices:    {31168, 30237, 2149, 15717, 35560, 15720, 28874, 4203, 2156, 28879, 1307, 30225, 4724, 7032, 31163, 28861, 27551}\n",
      "dict_items([(\"Lemma('symbol.n.01.symbol')\", 8)])\n",
      "collecting tokens for  snatched\n",
      "indices:    {35681, 8646, 8075, 17741, 18959, 35442, 30356, 17815, 18680, 9661}\n",
      "dict_items([(\"Lemma('snatch.v.01.snatch')\", 8), (\"Lemma('snatch.v.02.snatch')\", 1)])\n",
      "collecting tokens for  elegant\n",
      "indices:    {26304, 24714}\n",
      "dict_items([])\n",
      "collecting tokens for  glaze\n",
      "indices:    {29614}\n",
      "dict_items([(\"Lemma('glaze.v.01.glaze')\", 1)])\n",
      "collecting tokens for  zoo\n",
      "indices:    {9401, 3755}\n",
      "dict_items([(\"Lemma('menagerie.n.02.zoo')\", 1)])\n",
      "collecting tokens for  manners\n",
      "indices:    {8744, 29921, 9421, 26765}\n",
      "dict_items([(\"Lemma('manners.n.01.manners')\", 2)])\n",
      "collecting tokens for  hiding\n",
      "indices:    {9092, 9081, 5064, 34603, 14285, 18638, 18351, 34639, 17549, 19344, 18232, 18265, 9083, 8923}\n",
      "dict_items([(\"Lemma('hide.v.02.hide')\", 2), (\"Lemma('concealment.n.03.hiding')\", 2), (\"Lemma('hide.v.01.hide')\", 4)])\n",
      "collecting tokens for  delivery\n",
      "indices:    {30534}\n",
      "dict_items([])\n",
      "collecting tokens for  inability\n",
      "indices:    {32848, 14629}\n",
      "dict_items([(\"Lemma('inability.n.01.inability')\", 1)])\n",
      "collecting tokens for  radically\n",
      "indices:    {25451, 1516, 4686, 26096, 4817, 27250, 5012, 27256, 31806, 13695}\n",
      "dict_items([(\"Lemma('radically.r.01.radically')\", 5)])\n",
      "collecting tokens for  purified\n",
      "indices:    {3247, 3251, 4166, 3255}\n",
      "dict_items([])\n",
      "collecting tokens for  clergyman\n",
      "indices:    {35622, 13362, 10706, 10708, 28021, 1428, 1400, 12667, 35485, 14462}\n",
      "dict_items([(\"Lemma('clergyman.n.01.clergyman')\", 7)])\n",
      "collecting tokens for  mild\n",
      "indices:    {864, 30148, 13158, 4264, 27287, 19471, 11314, 30839, 32445}\n",
      "dict_items([(\"Lemma('mild.a.01.mild')\", 5)])\n",
      "collecting tokens for  stumbled\n",
      "indices:    {34786, 27465, 17578, 6347, 9964, 33869, 11505, 27250, 7635, 8628, 34108, 36028, 18494}\n",
      "dict_items([(\"Lemma('stumble.v.02.stumble')\", 4), (\"Lemma('stumble.v.01.stumble')\", 7), (\"Lemma('stumble.v.03.stumble')\", 2)])\n",
      "collecting tokens for  midway\n",
      "indices:    {12761}\n",
      "dict_items([(\"Lemma('location.n.01.location')\", 1)])\n",
      "collecting tokens for  wound\n",
      "indices:    {4201, 5099, 27281, 16601, 5659, 9053}\n",
      "dict_items([(\"Lemma('wound.n.01.wound')\", 2), (\"Lemma('wind.v.03.wind')\", 1), (\"Lemma('arouse.v.07.wind_up')\", 1)])\n",
      "collecting tokens for  skies\n",
      "indices:    {26400, 11331, 26924, 21585, 6457}\n",
      "dict_items([(\"Lemma('sky.n.01.sky')\", 2)])\n",
      "collecting tokens for  screwed\n",
      "indices:    {29730, 29734, 29735, 6825, 29805, 29742, 29807, 29744, 29810, 29751, 29879}\n",
      "dict_items([])\n",
      "collecting tokens for  feathers\n",
      "indices:    {9344, 7809, 22436, 35557, 35206, 7816, 9069, 16690, 29075}\n",
      "dict_items([(\"Lemma('feather.n.01.feather')\", 5)])\n",
      "collecting tokens for  kinds\n",
      "indices:    {29440, 32385, 6146, 11908, 12038, 30089, 25741, 3599, 13201, 32273, 3871, 14624, 30500, 25772, 14001, 21814, 31544, 31294, 3648, 16578, 13634, 25671, 969, 30412, 31566, 13390, 15839, 24940, 11634, 20085}\n",
      "dict_items([(\"Lemma('kind.n.01.kind')\", 16)])\n",
      "collecting tokens for  noble\n",
      "indices:    {22400, 10848, 5351, 12455, 27082, 12299, 19212, 23950, 24339, 26165, 32214, 24922, 9630, 12479}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('noble.a.02.noble')\", 2), (\"Lemma('noble.a.03.noble')\", 1), (\"Lemma('baronial.s.01.noble')\", 1)])\n",
      "collecting tokens for  hillsboro\n",
      "indices:    {21602}\n",
      "dict_items([])\n",
      "collecting tokens for  ill\n",
      "indices:    {1328, 2220, 20220}\n",
      "dict_items([(\"Lemma('ill.r.01.ill')\", 1), (\"Lemma('ill.a.01.ill')\", 1)])\n",
      "collecting tokens for  substitute\n",
      "indices:    {22725, 1644, 812, 24695, 32062}\n",
      "dict_items([(\"Lemma('substitute.n.01.substitute')\", 1), (\"Lemma('substitute.v.01.substitute')\", 2)])\n",
      "collecting tokens for  optimistic\n",
      "indices:    {24029, 24781, 14111, 21877, 27932, 20573, 16446, 28063}\n",
      "dict_items([(\"Lemma('optimistic.a.01.optimistic')\", 2)])\n",
      "collecting tokens for  benjamin\n",
      "indices:    {21210}\n",
      "dict_items([])\n",
      "collecting tokens for  denomination\n",
      "indices:    {27269, 20838, 20840, 14462, 20820, 20825, 27610, 27677, 27673}\n",
      "dict_items([(\"Lemma('denomination.n.01.denomination')\", 1)])\n",
      "collecting tokens for  calcium\n",
      "indices:    {3200, 3107, 27240, 3281, 27953, 27954, 27956, 27958, 4056}\n",
      "dict_items([(\"Lemma('calcium.n.01.calcium')\", 2)])\n",
      "collecting tokens for  container\n",
      "indices:    {33509, 3143, 3146, 33613, 5614, 29647, 29648, 15190, 31482}\n",
      "dict_items([(\"Lemma('container.n.01.container')\", 4)])\n",
      "collecting tokens for  merger\n",
      "indices:    {14917, 21958, 23973, 25964, 14924, 14926, 21965, 14929, 21820, 36703}\n",
      "dict_items([(\"Lemma('amalgamation.n.01.merger')\", 4)])\n",
      "collecting tokens for  anionic\n",
      "indices:    {3205, 3568, 3572, 3575, 3577, 3583}\n",
      "dict_items([(\"Lemma('anionic_detergent.n.01.anionic')\", 4), (\"Lemma('anionic.a.01.anionic')\", 2)])\n",
      "collecting tokens for  specificity\n",
      "indices:    {4164, 4167, 4231, 4175, 3954, 4157, 4178, 4125}\n",
      "dict_items([(\"Lemma('specificity.n.01.specificity')\", 7), (\"Lemma('specificity.n.02.specificity')\", 1)])\n",
      "collecting tokens for  wtv\n",
      "indices:    {4192}\n",
      "dict_items([])\n",
      "collecting tokens for  ns\n",
      "indices:    {28584, 4153}\n",
      "dict_items([])\n",
      "collecting tokens for  potato\n",
      "indices:    {26979, 30406, 4167, 555, 4143, 4176, 21816, 21818, 21820, 21821}\n",
      "dict_items([])\n",
      "collecting tokens for  virus\n",
      "indices:    {25379, 4196, 4167, 4201, 4202, 4143, 4176, 4183, 14169}\n",
      "dict_items([(\"Lemma('virus.n.01.virus')\", 4)])\n",
      "collecting tokens for  antigen\n",
      "indices:    {4167, 4200, 4199, 4202, 4156, 4182, 4183, 4185, 4186, 4188, 4189}\n",
      "dict_items([(\"Lemma('antigen.n.01.antigen')\", 11)])\n",
      "collecting tokens for  enlisted\n",
      "indices:    {30338, 228, 26694, 28073, 12906, 32751, 24721, 498, 12823, 14430}\n",
      "dict_items([(\"Lemma('engage.v.08.enlist')\", 4), (\"Lemma('enlist.v.03.enlist')\", 1), (\"Lemma('enlist.v.01.enlist')\", 2)])\n",
      "collecting tokens for  rebels\n",
      "indices:    {7674}\n",
      "dict_items([(\"Lemma('rebel.n.01.Rebel')\", 1)])\n",
      "collecting tokens for  nonspecific\n",
      "indices:    {4161, 4163, 4196, 4195, 4198, 4173, 4177, 4179, 4148, 4153, 4155, 4156, 4158}\n",
      "dict_items([(\"Lemma('nonspecific.a.01.nonspecific')\", 13)])\n",
      "collecting tokens for  maine\n",
      "indices:    {23372}\n",
      "dict_items([])\n",
      "collecting tokens for  rests\n",
      "indices:    {15842, 14214, 36361, 36363, 1362, 13919}\n",
      "dict_items([(\"Lemma('rest.v.03.rest')\", 2), (\"Lemma('repose_on.v.01.rest_on')\", 1), (\"Lemma('lie.v.06.rest')\", 2)])\n",
      "collecting tokens for  segregation\n",
      "indices:    {20640, 32959, 27023, 32980, 23160, 20636, 20638, 20639}\n",
      "dict_items([])\n",
      "collecting tokens for  anchor\n",
      "indices:    {30370, 12451, 7845, 12454, 29350, 12333, 4720, 28789, 26616}\n",
      "dict_items([(\"Lemma('anchor.n.01.anchor')\", 3), (\"Lemma('anchor.n.02.anchor')\", 1)])\n",
      "collecting tokens for  persuaded\n",
      "indices:    {10976, 10980, 28327, 9545, 31434, 7562, 1001, 12400, 12464, 34003, 15285, 34903, 32184, 32186, 25370, 32190}\n",
      "dict_items([(\"Lemma('carry.v.23.persuade')\", 9), (\"Lemma('persuade.v.02.persuade')\", 7)])\n",
      "collecting tokens for  adopt\n",
      "indices:    {20384, 24192, 16294, 22894, 2614, 12566, 32186, 21437, 32190, 31775}\n",
      "dict_items([(\"Lemma('adopt.v.01.adopt')\", 8), (\"Lemma('adopt.v.02.adopt')\", 1), (\"Lemma('assume.v.02.adopt')\", 1)])\n",
      "collecting tokens for  vocabulary\n",
      "indices:    {18848, 16161, 16199, 10219, 16183, 33620, 2231, 18904, 32057, 31899, 2396}\n",
      "dict_items([(\"Lemma('vocabulary.n.01.vocabulary')\", 5), (\"Lemma('vocabulary.n.02.vocabulary')\", 2), (\"Lemma('vocabulary.n.03.vocabulary')\", 1)])\n",
      "collecting tokens for  swadesh\n",
      "indices:    {16162}\n",
      "dict_items([(\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  impulses\n",
      "indices:    {26689, 26307, 14629, 2156, 4204, 2158, 12239, 4631, 19607, 14618, 5023}\n",
      "dict_items([(\"Lemma('nerve_impulse.n.01.impulse')\", 2), (\"Lemma('urge.n.01.impulse')\", 4), (\"Lemma('pulsation.n.01.impulse')\", 1), (\"Lemma('caprice.n.01.impulse')\", 2)])\n",
      "collecting tokens for  elite\n",
      "indices:    {5250, 5251, 16522, 28142, 34672, 31732, 23225, 5243, 5245}\n",
      "dict_items([(\"Lemma('elite.n.01.elite')\", 4), (\"Lemma('group.n.01.group')\", 1)])\n",
      "collecting tokens for  moonlight\n",
      "indices:    {35297, 6727, 36423, 7017, 35341, 7795, 35320, 9308, 35388, 7775}\n",
      "dict_items([(\"Lemma('moonlight.n.01.moonlight')\", 5)])\n",
      "collecting tokens for  memories\n",
      "indices:    {4578, 14531, 14404, 1095, 6794, 30829, 13839, 28400, 30739, 13876, 7795, 11252, 9399, 1182}\n",
      "dict_items([(\"Lemma('memory.n.03.memory')\", 2), (\"Lemma('memory.n.01.memory')\", 9)])\n",
      "collecting tokens for  deae-cellulose\n",
      "indices:    {3541}\n",
      "dict_items([(\"Lemma('diethylaminoethyl_cellulose.n.01.DEAE_cellulose')\", 1)])\n",
      "collecting tokens for  tune\n",
      "indices:    {6560, 22299}\n",
      "dict_items([(\"Lemma('tune.n.01.tune')\", 1)])\n",
      "collecting tokens for  anger\n",
      "indices:    {6915, 14623, 35109, 18021, 16835, 32850, 26165, 33271, 30233, 7068, 6975}\n",
      "dict_items([(\"Lemma('anger.n.01.anger')\", 6)])\n",
      "collecting tokens for  reads\n",
      "indices:    {14593, 29954, 24761, 900, 24746, 24752, 15985, 31671, 23190, 26454, 20825, 15229}\n",
      "dict_items([(\"Lemma('read.v.01.read')\", 4), (\"Lemma('read.v.02.read')\", 8)])\n",
      "collecting tokens for  woods\n",
      "indices:    {22977, 18499, 1252, 36004, 34151, 7212, 7213, 1263, 10677, 29910, 30489, 20026, 22142, 22911}\n",
      "dict_items([(\"Lemma('forest.n.01.woods')\", 6)])\n",
      "collecting tokens for  detectable\n",
      "indices:    {4199, 14792, 14793, 12723, 3286, 3576, 4186, 4189}\n",
      "dict_items([(\"Lemma('detectable.s.01.detectable')\", 7), (\"Lemma('detectable.s.02.detectable')\", 1)])\n",
      "collecting tokens for  seemingly\n",
      "indices:    {32225, 8583, 37096, 34407, 33255, 31880, 33132, 2125, 15405, 22545, 8370, 14263, 12728, 4254}\n",
      "dict_items([(\"Lemma('apparently.r.01.seemingly')\", 7)])\n",
      "collecting tokens for  accordance\n",
      "indices:    {5345, 32931, 34378, 3370, 34379, 32877, 31758, 4595, 19380, 14871, 14872, 24219, 13149, 14879}\n",
      "dict_items([(\"Lemma('accord.n.02.accordance')\", 8)])\n",
      "collecting tokens for  madison\n",
      "indices:    {31700}\n",
      "dict_items([])\n",
      "collecting tokens for  morse\n",
      "indices:    {20810}\n",
      "dict_items([])\n",
      "collecting tokens for  charley\n",
      "indices:    {33893}\n",
      "dict_items([])\n",
      "collecting tokens for  megatons\n",
      "indices:    {25414, 25415, 25416, 25417, 25418, 817, 25395, 25399}\n",
      "dict_items([(\"Lemma('megaton.n.01.megaton')\", 1)])\n",
      "collecting tokens for  interval\n",
      "indices:    {4544, 33089, 4542, 31204, 4550, 27750, 30376, 4523, 32622, 4559, 6901, 13592, 4539, 2844, 4541, 6910}\n",
      "dict_items([(\"Lemma('time_interval.n.01.interval')\", 4), (\"Lemma('interval.n.02.interval')\", 6)])\n",
      "collecting tokens for  dec.\n",
      "indices:    {21666}\n",
      "dict_items([])\n",
      "collecting tokens for  morale\n",
      "indices:    {25537, 13179, 1659}\n",
      "dict_items([(\"Lemma('morale.n.01.morale')\", 1)])\n",
      "collecting tokens for  diplomatic\n",
      "indices:    {23688, 12695, 26141, 23844, 12965, 22828, 20273, 20277, 26042, 827, 22845, 23615, 27715, 27718, 26186, 34392, 34400, 23659, 22635, 24187}\n",
      "dict_items([(\"Lemma('diplomatic.a.01.diplomatic')\", 2), (\"Lemma('diplomatic.a.02.diplomatic')\", 1)])\n",
      "collecting tokens for  preventive\n",
      "indices:    {25763, 31077, 32903, 32871, 32905, 3481, 32877, 32880, 32881, 32882, 11604, 32889, 26042}\n",
      "dict_items([(\"Lemma('preventive.s.01.preventive')\", 1)])\n",
      "collecting tokens for  hemisphere\n",
      "indices:    {21905, 14941, 24182, 14959}\n",
      "dict_items([(\"Lemma('hemisphere.n.01.hemisphere')\", 1)])\n",
      "collecting tokens for  rhythm\n",
      "indices:    {6563, 26276, 30215, 1799, 14634, 14540, 12279, 33750, 32055, 22300, 6909, 12286}\n",
      "dict_items([(\"Lemma('rhythm.n.02.rhythm')\", 2), (\"Lemma('rhythm.n.01.rhythm')\", 2), (\"Lemma('rhythm.n.04.rhythm')\", 1), (\"Lemma('rhythm_method_of_birth_control.n.01.rhythm')\", 1)])\n",
      "collecting tokens for  notions\n",
      "indices:    {14304, 15428, 16452, 2662, 30407, 22660, 16422, 14255, 14673, 14328, 14074, 31515, 14431}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('notion.n.02.notion')\", 3), (\"Lemma('impression.n.01.notion')\", 6)])\n",
      "collecting tokens for  hammer\n",
      "indices:    {18379, 13988, 16716}\n",
      "dict_items([(\"Lemma('hammer.n.01.hammer')\", 1)])\n",
      "collecting tokens for  confession\n",
      "indices:    {21346, 21354, 7037, 16790, 32088, 36189}\n",
      "dict_items([(\"Lemma('confession.n.01.confession')\", 1), (\"Lemma('confession.n.02.confession')\", 1)])\n",
      "collecting tokens for  impulse\n",
      "indices:    {28064, 6177, 32036, 31493, 36966, 33226, 34607, 6968, 34131, 36820, 36821, 36344, 3354, 35963, 4668, 18525, 32062}\n",
      "dict_items([(\"Lemma('urge.n.01.impulse')\", 3), (\"Lemma('impulse.n.05.impulse')\", 1), (\"Lemma('caprice.n.01.impulse')\", 1)])\n",
      "collecting tokens for  perceive\n",
      "indices:    {4960, 25506, 33190, 33263, 33264, 34355, 4958}\n",
      "dict_items([(\"Lemma('perceive.v.01.perceive')\", 7)])\n",
      "collecting tokens for  youngest\n",
      "indices:    {21696, 12676, 10981, 14475, 31691, 12913, 19506, 8370, 20891, 21693}\n",
      "dict_items([(\"Lemma('young.a.01.young')\", 6)])\n",
      "collecting tokens for  waking\n",
      "indices:    {34609, 8122, 2123}\n",
      "dict_items([(\"Lemma('wake.v.01.wake')\", 2)])\n",
      "collecting tokens for  guys\n",
      "indices:    {14563, 422, 34470, 6554, 6577, 19858, 6546, 17876, 12629, 2423, 19993, 19994, 34779, 20031}\n",
      "dict_items([(\"Lemma('guy.n.01.guy')\", 11)])\n",
      "collecting tokens for  locations\n",
      "indices:    {32353, 32451, 31144, 24885, 2911, 32472, 3449, 12765, 31295}\n",
      "dict_items([(\"Lemma('location.n.01.location')\", 3)])\n",
      "collecting tokens for  bastards\n",
      "indices:    {6593, 19873, 6565, 6662, 6655, 6572, 33389, 6677, 6586, 33403, 2495}\n",
      "dict_items([(\"Lemma('asshole.n.01.bastard')\", 9)])\n",
      "collecting tokens for  temperatures\n",
      "indices:    {3231, 2944, 2946, 2916, 21099, 684, 2957, 14830, 14809, 30160, 2835, 14804, 2804, 1913, 14814, 14815}\n",
      "dict_items([(\"Lemma('temperature.n.01.temperature')\", 13)])\n",
      "collecting tokens for  cane\n",
      "indices:    {22144, 10561, 22147, 21702, 7047, 4050, 16948, 27037}\n",
      "dict_items([(\"Lemma('cane.n.01.cane')\", 4)])\n",
      "collecting tokens for  effluent\n",
      "indices:    {5536, 5537, 5490, 5549, 5550, 5522, 5491, 5556, 5557, 5524, 5558, 5592, 5593, 5594, 5595, 5596, 5535}\n",
      "dict_items([(\"Lemma('effluent.n.01.effluent')\", 17)])\n",
      "collecting tokens for  nails\n",
      "indices:    {29761, 20100, 13096, 29836, 29868, 14323, 29715, 9174, 29720, 29721, 29722, 20060}\n",
      "dict_items([(\"Lemma('nail.n.02.nail')\", 3), (\"Lemma('nail.n.01.nail')\", 1)])\n",
      "collecting tokens for  pouring\n",
      "indices:    {7112, 16617, 19114, 14315, 8785, 12884, 23989, 9110}\n",
      "dict_items([(\"Lemma('pour.v.04.pour')\", 2), (\"Lemma('pour.v.02.pour')\", 1), (\"Lemma('pour.v.01.pour')\", 3), (\"Lemma('decant.v.01.pour')\", 1)])\n",
      "collecting tokens for  bottles\n",
      "indices:    {36963, 30948, 2917, 30052, 14315, 33579, 19537, 9629}\n",
      "dict_items([(\"Lemma('bottle.n.01.bottle')\", 4)])\n",
      "collecting tokens for  sensations\n",
      "indices:    {26433, 9601, 32072, 13644, 31535, 31887, 4921, 32090, 4956, 4959}\n",
      "dict_items([(\"Lemma('sensation.n.03.sensation')\", 1), (\"Lemma('sensation.n.01.sensation')\", 4)])\n",
      "collecting tokens for  ill.\n",
      "indices:    {659}\n",
      "dict_items([(\"Lemma('location.n.01.location')\", 1)])\n",
      "collecting tokens for  fluorescence\n",
      "indices:    {4170, 4145, 4148, 4152, 4153, 4154, 4155, 4158, 4159}\n",
      "dict_items([(\"Lemma('fluorescence.n.01.fluorescence')\", 9)])\n",
      "collecting tokens for  bunk\n",
      "indices:    {11608, 34567, 34572, 34575, 34584, 7154, 34611, 7219, 34579, 29815, 29816, 11610, 11614}\n",
      "dict_items([(\"Lemma('berth.n.03.bunk')\", 2), (\"Lemma('bunk.n.01.bunk')\", 1)])\n",
      "collecting tokens for  log\n",
      "indices:    {5059, 6733, 6735, 18226, 7219, 6738, 6742, 7133}\n",
      "dict_items([(\"Lemma('log.n.01.log')\", 5)])\n",
      "collecting tokens for  ego\n",
      "indices:    {773, 32870, 15838, 8237, 10847, 1519, 32881, 12060, 20030, 32895}\n",
      "dict_items([(\"Lemma('ego.n.01.ego')\", 6), (\"Lemma('self.n.01.ego')\", 1)])\n",
      "collecting tokens for  convenience\n",
      "indices:    {21079, 9800, 28656, 8274, 21237, 29462, 21238, 17694}\n",
      "dict_items([(\"Lemma('convenience.n.02.convenience')\", 1), (\"Lemma('convenience.n.01.convenience')\", 2)])\n",
      "collecting tokens for  illegal\n",
      "indices:    {13920, 23688, 7711, 22996, 22806, 14230, 20154, 37151}\n",
      "dict_items([(\"Lemma('illegal.a.01.illegal')\", 3)])\n",
      "collecting tokens for  brodie\n",
      "indices:    {31015}\n",
      "dict_items([])\n",
      "collecting tokens for  counterparts\n",
      "indices:    {13184, 14411, 13647, 13171, 13235, 4633, 13950, 14463}\n",
      "dict_items([(\"Lemma('counterpart.n.01.counterpart')\", 7), (\"Lemma('counterpart.n.02.counterpart')\", 1)])\n",
      "collecting tokens for  fashionable\n",
      "indices:    {36544, 13702, 26334, 37141, 30901, 29145, 10683, 30942, 13726}\n",
      "dict_items([(\"Lemma('fashionable.a.01.fashionable')\", 3)])\n",
      "collecting tokens for  pedersen\n",
      "indices:    {8952}\n",
      "dict_items([(\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  convictions\n",
      "indices:    {5345, 1281, 28323, 28073, 4683, 24844, 24018, 27349, 36791, 14431}\n",
      "dict_items([(\"Lemma('conviction.n.01.conviction')\", 4)])\n",
      "collecting tokens for  monstrous\n",
      "indices:    {25376, 17024, 3748, 524, 3727, 24788, 4887, 2654}\n",
      "dict_items([(\"Lemma('grotesque.s.01.monstrous')\", 1), (\"Lemma('monstrous.s.01.monstrous')\", 3), (\"Lemma('atrocious.s.01.monstrous')\", 2)])\n",
      "collecting tokens for  spokesmen\n",
      "indices:    {23843, 20260, 25447, 23888, 20378, 23931, 20285, 24606}\n",
      "dict_items([])\n",
      "collecting tokens for  petition\n",
      "indices:    {33, 29921, 35, 20362, 21645, 27, 15260, 32221, 31}\n",
      "dict_items([(\"Lemma('request.n.01.petition')\", 4), (\"Lemma('petition.v.01.petition')\", 1)])\n",
      "collecting tokens for  thyroglobulin\n",
      "indices:    {3969, 3939, 3945, 3947, 3949, 3985, 3986, 3987, 3955, 3988, 3959, 3961, 3962, 3934}\n",
      "dict_items([(\"Lemma('thyroglobulin.n.01.thyroglobulin')\", 14)])\n",
      "collecting tokens for  camping\n",
      "indices:    {1857, 11905, 11906, 11938, 11949, 11933}\n",
      "dict_items([(\"Lemma('camp.v.01.camp')\", 1), (\"Lemma('camping.n.01.camping')\", 5)])\n",
      "collecting tokens for  anne\n",
      "indices:    {21210}\n",
      "dict_items([])\n",
      "collecting tokens for  diagonalizable\n",
      "indices:    {4288, 4352, 4355, 4293, 4330, 4339, 4340, 4341, 4342, 4347, 4351}\n",
      "dict_items([(\"Lemma('diagonalizable.a.01.diagonalizable')\", 11)])\n",
      "collecting tokens for  commute\n",
      "indices:    {4355, 4341, 4344, 4345, 4346, 4347, 4348}\n",
      "dict_items([(\"Lemma('commute.v.01.commute')\", 7)])\n",
      "collecting tokens for  secured\n",
      "indices:    {3489, 18179, 27624, 2762, 29965, 23823, 36884, 29721, 7197}\n",
      "dict_items([(\"Lemma('procure.v.01.secure')\", 5), (\"Lemma('secure.v.03.secure')\", 1), (\"Lemma('fasten.v.01.secure')\", 2)])\n",
      "collecting tokens for  glue\n",
      "indices:    {29749}\n",
      "dict_items([])\n",
      "collecting tokens for  tremendously\n",
      "indices:    {12035, 12709, 11056, 12787, 32211, 27416, 14905, 24606}\n",
      "dict_items([(\"Lemma('enormously.r.01.tremendously')\", 5)])\n",
      "collecting tokens for  prevailing\n",
      "indices:    {31200, 25410, 31171, 25610, 32427, 28108, 13233, 29849, 27807}\n",
      "dict_items([(\"Lemma('predominate.v.01.prevail')\", 1), (\"Lemma('prevail.v.03.prevail')\", 1)])\n",
      "collecting tokens for  relieved\n",
      "indices:    {35808, 9538, 4677, 19079, 17646, 24113, 6934, 20119, 35001, 18330, 187, 4860, 35997, 4859}\n",
      "dict_items([(\"Lemma('relieve.v.01.relieve')\", 2), (\"Lemma('unbosom.v.01.relieve')\", 1), (\"Lemma('take_over.v.03.relieve')\", 2), (\"Lemma('alleviated.s.01.relieved')\", 5), (\"Lemma('exempt.v.01.relieve')\", 1)])\n",
      "collecting tokens for  loosely\n",
      "indices:    {3360, 451, 5655, 29414, 18887, 10570, 31246, 29551, 8887, 7902}\n",
      "dict_items([(\"Lemma('loosely.r.01.loosely')\", 6)])\n",
      "collecting tokens for  boot\n",
      "indices:    {9058, 26276, 16716, 1262, 18639, 35663, 17657, 17884, 34525, 30268}\n",
      "dict_items([(\"Lemma('boot.n.01.boot')\", 3), (\"Lemma('boot.n.02.boot')\", 1)])\n",
      "collecting tokens for  mouse\n",
      "indices:    {4394, 22324}\n",
      "dict_items([(\"Lemma('mouse.n.01.mouse')\", 1)])\n",
      "collecting tokens for  radioactive\n",
      "indices:    {25376, 3241, 4042, 25389, 25390, 21775, 3258, 34555}\n",
      "dict_items([(\"Lemma('radioactive.a.01.radioactive')\", 3)])\n",
      "collecting tokens for  costly\n",
      "indices:    {132, 20199, 37096, 25033, 7210, 12300, 22807, 23421}\n",
      "dict_items([(\"Lemma('costly.s.02.costly')\", 1), (\"Lemma('dearly-won.s.01.costly')\", 2)])\n",
      "collecting tokens for  interlobular\n",
      "indices:    {3846, 3784, 3785, 3787, 3854, 3794, 3800, 3775}\n",
      "dict_items([(\"Lemma('interlobular.a.01.interlobular')\", 8)])\n",
      "collecting tokens for  middle-class\n",
      "indices:    {13379, 13382, 2665, 13385, 13388, 32048, 13332, 13333, 13372, 15645, 13343}\n",
      "dict_items([(\"Lemma('middle-class.a.01.middle-class')\", 10)])\n",
      "collecting tokens for  battery\n",
      "indices:    {7822}\n",
      "dict_items([(\"Lemma('location.n.01.location')\", 1)])\n",
      "collecting tokens for  reactionary\n",
      "indices:    {6586}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('reactionary.s.01.reactionary')\", 1)])\n",
      "collecting tokens for  solved\n",
      "indices:    {4611, 20997, 22951, 18248, 7498, 4626, 2134, 32954, 28892, 3261, 18367}\n",
      "dict_items([(\"Lemma('resolve.v.06.solve')\", 2), (\"Lemma('solve.v.01.solve')\", 8), (\"Lemma('solved.a.01.solved')\", 1)])\n",
      "collecting tokens for  obtaining\n",
      "indices:    {3297, 3234, 3237, 3302, 21385, 20362, 5306, 3261, 33022}\n",
      "dict_items([(\"Lemma('obtain.v.01.obtain')\", 9)])\n",
      "collecting tokens for  width\n",
      "indices:    {1891, 29670, 1549, 19279, 29778, 29237, 2840, 13113, 29759}\n",
      "dict_items([(\"Lemma('width.n.01.width')\", 4)])\n",
      "collecting tokens for  arrow\n",
      "indices:    {3923, 22092, 3919}\n",
      "dict_items([(\"Lemma('arrow.n.01.arrow')\", 2)])\n",
      "collecting tokens for  participated\n",
      "indices:    {25792, 25858, 8260, 11883, 31761, 11891, 28630, 31771}\n",
      "dict_items([(\"Lemma('participate.v.01.participate')\", 8)])\n",
      "collecting tokens for  habit\n",
      "indices:    {2115, 17347, 37061, 30887, 34383, 30996, 20052, 30999, 5275, 16924}\n",
      "dict_items([(\"Lemma('habit.n.01.habit')\", 2), (\"Lemma('habit.n.02.habit')\", 2), (\"Lemma('habit.n.03.habit')\", 1)])\n",
      "collecting tokens for  adding\n",
      "indices:    {36992, 10657, 2115, 31139, 20774, 20838, 30120, 32203, 24396, 6925, 2605, 31130, 29360, 29554, 29782, 36216, 23834, 30237}\n",
      "dict_items([(\"Lemma('add.v.01.add')\", 10), (\"Lemma('add.v.02.add')\", 5)])\n",
      "collecting tokens for  thereof\n",
      "indices:    {14880, 12291, 14856, 32393, 14859, 14763, 27758}\n",
      "dict_items([(\"Lemma('thereof.r.01.thereof')\", 5)])\n",
      "collecting tokens for  tearing\n",
      "indices:    {21635, 5064, 27434, 8366, 8495, 18577, 6901, 7032}\n",
      "dict_items([(\"Lemma('pluck.v.05.tear')\", 1), (\"Lemma('tear.v.01.tear')\", 4), (\"Lemma('tear.v.03.tear')\", 1)])\n",
      "collecting tokens for  st\n",
      "indices:    {21316, 32389, 21320, 20168, 32690, 30291, 32631, 20731}\n",
      "dict_items([])\n",
      "collecting tokens for  document\n",
      "indices:    {1729, 29919, 24195, 26121, 24177, 25082, 25726, 25727}\n",
      "dict_items([(\"Lemma('document.n.02.document')\", 1)])\n",
      "collecting tokens for  prevot\n",
      "indices:    {5790}\n",
      "dict_items([(\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  taxed\n",
      "indices:    {23395, 23396, 22052, 32393, 32394, 5419, 5420, 32437, 22043, 32413}\n",
      "dict_items([(\"Lemma('tax.v.01.tax')\", 10)])\n",
      "collecting tokens for  austin\n",
      "indices:    {16436}\n",
      "dict_items([(\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  deficit\n",
      "indices:    {25477, 25481, 25483, 24109, 25487, 23990, 24220, 94}\n",
      "dict_items([(\"Lemma('deficit.n.01.deficit')\", 1)])\n",
      "collecting tokens for  lifetime\n",
      "indices:    {23137, 31719, 33294, 23567, 27283, 17365, 439, 22489}\n",
      "dict_items([(\"Lemma('life.n.05.lifetime')\", 2)])\n",
      "collecting tokens for  partners\n",
      "indices:    {12003, 24644, 11959, 32107, 34765, 12239, 19030, 34775, 22711, 7771, 1596}\n",
      "dict_items([(\"Lemma('collaborator.n.03.partner')\", 3), (\"Lemma('spouse.n.01.partner')\", 3)])\n",
      "collecting tokens for  linked\n",
      "indices:    {13946, 32908, 4661, 8239}\n",
      "dict_items([(\"Lemma('associate.v.01.link')\", 4)])\n",
      "collecting tokens for  remind\n",
      "indices:    {28039, 1418, 19690, 37002, 28429, 29935, 15670, 25276, 25311}\n",
      "dict_items([(\"Lemma('remind.v.01.remind')\", 6), (\"Lemma('prompt.v.03.remind')\", 3)])\n",
      "collecting tokens for  moliere\n",
      "indices:    {26566}\n",
      "dict_items([])\n",
      "collecting tokens for  bounds\n",
      "indices:    {9953, 802, 25350, 25354, 10898, 535, 536, 1471}\n",
      "dict_items([(\"Lemma('boundary.n.01.bounds')\", 1)])\n",
      "collecting tokens for  sweat\n",
      "indices:    {7112, 6952, 18840, 18170, 31485, 19166}\n",
      "dict_items([(\"Lemma('perspiration.n.01.sweat')\", 3), (\"Lemma('sweat.v.01.sweat')\", 1)])\n",
      "collecting tokens for  squares\n",
      "indices:    {4483, 32100, 4486, 32045, 4495, 4569, 32058, 20060, 29405, 34206}\n",
      "dict_items([(\"Lemma('square.n.01.square')\", 4)])\n",
      "collecting tokens for  halfway\n",
      "indices:    {36481, 13156, 35238, 9515, 7349, 27574, 16182}\n",
      "dict_items([(\"Lemma('center.s.01.halfway')\", 2), (\"Lemma('halfway.r.01.halfway')\", 1)])\n",
      "collecting tokens for  driveway\n",
      "indices:    {8736, 29347, 20743, 20744, 13577, 17642, 9192, 33712, 9169, 30419}\n",
      "dict_items([(\"Lemma('driveway.n.01.driveway')\", 5)])\n",
      "collecting tokens for  istiqlal\n",
      "indices:    {4752}\n",
      "dict_items([])\n",
      "collecting tokens for  flashlight\n",
      "indices:    {15146, 34155, 15149, 13006, 34190, 17581, 30357, 34175}\n",
      "dict_items([(\"Lemma('flashlight.n.01.flashlight')\", 3)])\n",
      "collecting tokens for  aims\n",
      "indices:    {16224, 16161, 2339, 23463, 2312, 13321, 22602, 23954, 32664, 14488, 13150}\n",
      "dict_items([(\"Lemma('aim.v.02.aim')\", 1), (\"Lemma('purpose.n.01.aim')\", 4), (\"Lemma('aim.n.02.aim')\", 2)])\n",
      "collecting tokens for  provincial\n",
      "indices:    {32225, 4808, 9359, 13204, 7834}\n",
      "dict_items([(\"Lemma('provincial.a.02.provincial')\", 2), (\"Lemma('provincial.a.01.provincial')\", 1)])\n",
      "collecting tokens for  populated\n",
      "indices:    {26817, 24449, 24034, 15012, 1253, 12423, 28167, 1232, 17685, 23512}\n",
      "dict_items([(\"Lemma('populated.s.01.populated')\", 2), (\"Lemma('populate.v.01.populate')\", 6)])\n",
      "collecting tokens for  dumb\n",
      "indices:    {35489, 7385, 775, 23051, 6540, 33561, 6680, 6681, 6685, 33662, 18399}\n",
      "dict_items([(\"Lemma('dense.s.04.dumb')\", 7)])\n",
      "collecting tokens for  barnett\n",
      "indices:    {20620}\n",
      "dict_items([])\n",
      "collecting tokens for  honeymoon\n",
      "indices:    {19200, 21026, 30793, 21035, 20621, 30805, 16923, 30812, 25758}\n",
      "dict_items([(\"Lemma('honeymoon.v.01.honeymoon')\", 1), (\"Lemma('honeymoon.n.01.honeymoon')\", 2)])\n",
      "collecting tokens for  contributes\n",
      "indices:    {34730, 28362, 2030, 3771, 32988, 14622, 10655}\n",
      "dict_items([(\"Lemma('contribute.v.03.contribute')\", 1), (\"Lemma('lend.v.01.contribute')\", 4), (\"Lemma('contribute.v.02.contribute')\", 2)])\n",
      "collecting tokens for  polynomials\n",
      "indices:    {4327, 4297, 4305, 4338, 4306, 4308, 4341, 4281, 4285}\n",
      "dict_items([(\"Lemma('polynomial.n.01.polynomial')\", 7)])\n",
      "collecting tokens for  substances\n",
      "indices:    {4198, 3241, 3209, 3216, 3189}\n",
      "dict_items([(\"Lemma('substance.n.01.substance')\", 5)])\n",
      "collecting tokens for  swift\n",
      "indices:    {36196, 17023}\n",
      "dict_items([(\"Lemma('fleet.s.01.swift')\", 1)])\n",
      "collecting tokens for  fatigue\n",
      "indices:    {11233, 36066, 26699, 32848, 1939, 8538, 1788, 4030, 34591}\n",
      "dict_items([(\"Lemma('fatigue.n.01.fatigue')\", 4)])\n",
      "collecting tokens for  berry\n",
      "indices:    {113}\n",
      "dict_items([(\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  termination\n",
      "indices:    {32164, 27781, 1510, 1511, 1513, 27790, 22043, 27804}\n",
      "dict_items([(\"Lemma('termination.n.01.termination')\", 3)])\n",
      "collecting tokens for  enclosed\n",
      "indices:    {13184, 36321, 5379, 27589, 29833, 3657, 36047, 33848}\n",
      "dict_items([(\"Lemma('envelop.v.01.enclose')\", 3), (\"Lemma('enclose.v.02.enclose')\", 2), (\"Lemma('enclose.v.03.enclose')\", 1)])\n",
      "collecting tokens for  stereo\n",
      "indices:    {768, 26304, 27044, 26505, 1100, 748, 26510, 1808, 26514, 1079, 1087}\n",
      "dict_items([(\"Lemma('stereo.n.01.stereo')\", 5), (\"Lemma('stereophonic.s.01.stereo')\", 1)])\n",
      "collecting tokens for  tenure\n",
      "indices:    {22722, 22723, 31622, 22732, 25805, 17367, 22719}\n",
      "dict_items([(\"Lemma('tenure.n.01.tenure')\", 1)])\n",
      "collecting tokens for  richardson\n",
      "indices:    {30291}\n",
      "dict_items([])\n",
      "collecting tokens for  jonathan\n",
      "indices:    {36196}\n",
      "dict_items([])\n",
      "collecting tokens for  grimly\n",
      "indices:    {8680, 36141, 10780, 8818, 33939, 33977, 21274, 16764, 7709}\n",
      "dict_items([(\"Lemma('grimly.r.01.grimly')\", 5)])\n",
      "collecting tokens for  rolling\n",
      "indices:    {2018, 5763, 35351, 7300, 9789, 35613, 23693, 10031, 7839, 22962, 8119, 1851, 7709, 29246, 36415}\n",
      "dict_items([(\"Lemma('roll.v.03.roll')\", 3), (\"Lemma('roll.v.01.roll')\", 6), (\"Lemma('rolled.s.02.rolling')\", 1)])\n",
      "collecting tokens for  fuel\n",
      "indices:    {15520, 21729, 15522, 15521, 36132, 36134, 30151, 19276, 23316, 27066}\n",
      "dict_items([(\"Lemma('fuel.n.01.fuel')\", 4)])\n",
      "collecting tokens for  unite\n",
      "indices:    {12263, 4713, 27691, 26036, 20568, 1403, 31998, 27583}\n",
      "dict_items([(\"Lemma('unify.v.01.unite')\", 4), (\"Lemma('unite.v.01.unite')\", 4)])\n",
      "collecting tokens for  manifold\n",
      "indices:    {3257, 3258, 3277, 3279, 3260, 3288, 3289, 3290, 3259, 3292, 13464}\n",
      "dict_items([(\"Lemma('manifold.n.01.manifold')\", 10), (\"Lemma('manifold.s.01.manifold')\", 1)])\n",
      "collecting tokens for  gates\n",
      "indices:    {22850, 5475, 13542, 13580, 13586, 23382, 11767, 19385, 7967}\n",
      "dict_items([(\"Lemma('gate.n.01.gate')\", 7)])\n",
      "collecting tokens for  philosophy\n",
      "indices:    {33121, 14691, 27275, 25836, 751, 14161, 14098, 13621, 11862, 23542, 13464, 30393}\n",
      "dict_items([(\"Lemma('doctrine.n.01.philosophy')\", 5), (\"Lemma('philosophy.n.02.philosophy')\", 2)])\n",
      "collecting tokens for  ann\n",
      "indices:    {21886}\n",
      "dict_items([])\n",
      "collecting tokens for  fiedler\n",
      "indices:    {21731}\n",
      "dict_items([])\n",
      "collecting tokens for  explored\n",
      "indices:    {2785, 27884, 12365, 26545, 10805, 11414, 30235, 31132}\n",
      "dict_items([(\"Lemma('research.v.02.explore')\", 6), (\"Lemma('explore.v.02.explore')\", 1), (\"Lemma('explore.v.03.explore')\", 1)])\n",
      "collecting tokens for  pre\n",
      "indices:    {15109, 11685, 29769, 15053, 11664, 11026, 1813}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([])\n",
      "collecting tokens for  improves\n",
      "indices:    {11572}\n",
      "dict_items([(\"Lemma('better.v.02.improve')\", 1)])\n",
      "collecting tokens for  gesture\n",
      "indices:    {12695, 27927, 28571, 26527, 31400, 22962, 31481, 20282, 17596, 19264, 8909, 7117, 7120, 7123, 7127, 7129, 34912, 1383, 36472, 15993}\n",
      "dict_items([(\"Lemma('gesture.n.03.gesture')\", 2), (\"Lemma('gesture.n.02.gesture')\", 4), (\"Lemma('gesture.n.01.gesture')\", 5)])\n",
      "collecting tokens for  oregon\n",
      "indices:    {13043}\n",
      "dict_items([(\"Lemma('oregon.n.01.Oregon')\", 1)])\n",
      "collecting tokens for  democrat\n",
      "indices:    {26698}\n",
      "dict_items([])\n",
      "collecting tokens for  requests\n",
      "indices:    {16305, 32356, 36436}\n",
      "dict_items([(\"Lemma('request.n.02.request')\", 1)])\n",
      "collecting tokens for  kremlin\n",
      "indices:    {12978}\n",
      "dict_items([(\"Lemma('group.n.01.group')\", 1)])\n",
      "collecting tokens for  sponsors\n",
      "indices:    {26724, 29288, 27658, 27659, 21106, 32915, 23763, 12669}\n",
      "dict_items([(\"Lemma('sponsor.v.01.sponsor')\", 1), (\"Lemma('patron.n.03.sponsor')\", 1)])\n",
      "collecting tokens for  furiously\n",
      "indices:    {35592, 35596, 18926, 17839, 18927, 12434, 6644, 36470, 24508}\n",
      "dict_items([(\"Lemma('furiously.r.01.furiously')\", 3), (\"Lemma('furiously.r.02.furiously')\", 2)])\n",
      "collecting tokens for  guest\n",
      "indices:    {1024, 31622, 17159, 31631, 31635, 9364, 11031, 9381, 31276, 14012, 9177, 32742, 17129, 22379, 22380, 22127, 22384, 21491, 12659}\n",
      "dict_items([(\"Lemma('guest.n.01.guest')\", 8)])\n",
      "collecting tokens for  disposition\n",
      "indices:    {32258, 20386, 36069, 29036, 26926, 1521, 25557, 30107, 671}\n",
      "dict_items([(\"Lemma('disposition.n.01.disposition')\", 2)])\n",
      "collecting tokens for  insight\n",
      "indices:    {32864, 17056, 27298, 14623, 14438, 14280, 26792, 14666, 28362, 31889, 13942, 11355, 1757, 13631}\n",
      "dict_items([(\"Lemma('penetration.n.02.insight')\", 5), (\"Lemma('insight.n.03.insight')\", 2), (\"Lemma('insight.n.02.insight')\", 2)])\n",
      "collecting tokens for  passive\n",
      "indices:    {8581, 28458, 12050, 7539, 27098, 12059, 8380, 11965, 32863}\n",
      "dict_items([(\"Lemma('passive.a.01.passive')\", 5), (\"Lemma('passive.s.02.passive')\", 1)])\n",
      "collecting tokens for  stirred\n",
      "indices:    {22826, 23280, 34609, 34322, 34897, 7255, 24631, 24665, 11451}\n",
      "dict_items([(\"Lemma('touch.v.03.stir')\", 1), (\"Lemma('stimulate.v.06.stir')\", 2), (\"Lemma('stir.v.02.stir')\", 2), (\"Lemma('stir.v.01.stir')\", 1), (\"Lemma('stimulate.v.03.stir')\", 1)])\n",
      "collecting tokens for  indicators\n",
      "indices:    {3876, 3877, 3878, 32935, 3912, 3886, 4242, 30260, 2713}\n",
      "dict_items([(\"Lemma('index.n.02.indicator')\", 6), (\"Lemma('indicator.n.02.indicator')\", 1)])\n",
      "collecting tokens for  seward\n",
      "indices:    {6172}\n",
      "dict_items([(\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  advances\n",
      "indices:    {2624, 27329, 11622, 33062, 2630, 23566, 15508, 4693, 11351, 2231, 2556}\n",
      "dict_items([(\"Lemma('improvement.n.01.advance')\", 6), (\"Lemma('progress.n.03.advance')\", 1), (\"Lemma('advance.v.05.advance')\", 1)])\n",
      "collecting tokens for  locked\n",
      "indices:    {28736, 16610, 28739, 35972, 33639, 17610, 28089, 12396, 30410, 9008, 34034, 1593, 18554, 7197, 7454}\n",
      "dict_items([(\"Lemma('lock_in.v.02.lock_up')\", 1), (\"Lemma('interlock.v.03.lock')\", 1), (\"Lemma('lock.v.06.lock')\", 1), (\"Lemma('lock_in.v.02.lock')\", 1), (\"Lemma('lock.v.03.lock')\", 2), (\"Lemma('lock.v.04.lock')\", 1), (\"Lemma('lock.v.01.lock')\", 3), (\"Lemma('engage.v.10.lock')\", 2)])\n",
      "collecting tokens for  tubes\n",
      "indices:    {3297, 11455, 3524, 3530, 3562, 29996, 3277, 35677, 3279, 3285, 2198, 3255, 8918, 3290, 3259, 31260, 2200, 3263}\n",
      "dict_items([(\"Lemma('tube.n.01.tube')\", 12), (\"Lemma('tube.n.02.tube')\", 1), (\"Lemma('pipe.n.03.tube')\", 1)])\n",
      "collecting tokens for  two-thirds\n",
      "indices:    {20643, 26055, 24169, 138, 22889, 5129, 5421, 21971}\n",
      "dict_items([(\"Lemma('two-thirds.n.01.two-thirds')\", 3)])\n",
      "collecting tokens for  henri\n",
      "indices:    {1521}\n",
      "dict_items([])\n",
      "collecting tokens for  slums\n",
      "indices:    {5633, 24203, 32043, 28333, 20524, 24210, 12152}\n",
      "dict_items([(\"Lemma('slum.n.01.slum')\", 2)])\n",
      "collecting tokens for  sturdy\n",
      "indices:    {18563, 29351, 29963, 33708, 12333, 14416, 30772, 20084, 23766}\n",
      "dict_items([(\"Lemma('hardy.s.01.sturdy')\", 4)])\n",
      "collecting tokens for  dominate\n",
      "indices:    {5476, 24198, 12041, 27146, 1802, 14415, 22964, 14173}\n",
      "dict_items([(\"Lemma('predominate.v.01.dominate')\", 2), (\"Lemma('dominate.v.03.dominate')\", 2), (\"Lemma('dominate.v.02.dominate')\", 4)])\n",
      "collecting tokens for  conversely\n",
      "indices:    {4240, 4314}\n",
      "dict_items([(\"Lemma('conversely.r.01.conversely')\", 2)])\n",
      "collecting tokens for  spontaneously\n",
      "indices:    {28384, 33219, 1231, 33235, 4243, 22933, 33240, 32059}\n",
      "dict_items([(\"Lemma('spontaneously.r.01.spontaneously')\", 2)])\n",
      "collecting tokens for  garry\n",
      "indices:    {12499}\n",
      "dict_items([])\n",
      "collecting tokens for  cope\n",
      "indices:    {4673, 13058, 17250, 31206, 30054, 12038, 30794, 25771, 20300, 11663, 23568, 1267, 14999, 2553, 14234, 2556, 24831}\n",
      "dict_items([(\"Lemma('cope.v.01.cope')\", 4)])\n",
      "collecting tokens for  loud\n",
      "indices:    {13408, 26618, 25989, 7048, 33482, 33614, 31150, 33554, 20883, 6739, 33465, 7194}\n",
      "dict_items([(\"Lemma('loud.a.01.loud')\", 2)])\n",
      "collecting tokens for  impurities\n",
      "indices:    {3200, 3297, 3107, 3111, 3242, 7289, 3997}\n",
      "dict_items([(\"Lemma('impurity.n.02.impurity')\", 3), (\"Lemma('impurity.n.01.impurity')\", 4)])\n",
      "collecting tokens for  touches\n",
      "indices:    {26244, 26084, 20932, 29834, 22990, 29616, 2645, 14423, 26777, 1082, 13883, 703}\n",
      "dict_items([(\"Lemma('touch.n.04.touch')\", 1), (\"Lemma('refer.v.02.touch')\", 2), (\"Lemma('reach.v.06.touch')\", 1), (\"Lemma('touch.n.06.touch')\", 1), (\"Lemma('touch.n.03.touch')\", 1), (\"Lemma('touch_on.v.01.touch_on')\", 1)])\n",
      "collecting tokens for  blades\n",
      "indices:    {12581, 28746, 28747, 27181, 33838, 29902, 31570, 1556, 21206, 9471}\n",
      "dict_items([(\"Lemma('blade.n.02.blade')\", 1), (\"Lemma('blade.n.03.blade')\", 1)])\n",
      "collecting tokens for  richmond\n",
      "indices:    {3749}\n",
      "dict_items([])\n",
      "collecting tokens for  terrain\n",
      "indices:    {3682, 25570, 23746, 23753, 11862, 30553, 29851, 25788}\n",
      "dict_items([(\"Lemma('terrain.n.01.terrain')\", 2)])\n",
      "collecting tokens for  lit\n",
      "indices:    {9632, 36642, 12678, 5767, 9192, 14159, 7729, 36920, 18362, 29277}\n",
      "dict_items([(\"Lemma('light.v.01.light')\", 5), (\"Lemma('ignite.v.01.light')\", 1), (\"Lemma('light_up.v.05.light')\", 1), (\"Lemma('illuminated.s.01.lit')\", 1)])\n",
      "collecting tokens for  respiratory\n",
      "indices:    {3776, 3815, 3402, 3851, 3852, 11374, 3406, 11537, 3409, 11545, 3770, 3420, 3455}\n",
      "dict_items([(\"Lemma('respiratory.a.01.respiratory')\", 10)])\n",
      "collecting tokens for  hip\n",
      "indices:    {34948, 262, 17928, 34025, 34026, 1588, 23349, 22293, 32700}\n",
      "dict_items([(\"Lemma('hip.n.01.hip')\", 2)])\n",
      "collecting tokens for  indifferent\n",
      "indices:    {16581, 32230, 5605, 36005, 13837, 1358, 7824, 28626, 8569}\n",
      "dict_items([(\"Lemma('apathetic.s.02.indifferent')\", 4), (\"Lemma('immaterial.s.05.indifferent')\", 1), (\"Lemma('indifferent.s.02.indifferent')\", 1)])\n",
      "collecting tokens for  weights\n",
      "indices:    {2978, 16188, 2962, 1523, 2964, 31129, 31130, 29084}\n",
      "dict_items([(\"Lemma('weight.n.04.weight')\", 2), (\"Lemma('slant.v.02.weight')\", 1), (\"Lemma('weight.n.02.weight')\", 1)])\n",
      "collecting tokens for  marshall\n",
      "indices:    {28362}\n",
      "dict_items([])\n",
      "collecting tokens for  crawl\n",
      "indices:    {17920, 8616, 8585, 8589, 8595, 31477, 10808, 35545}\n",
      "dict_items([(\"Lemma('crawl.n.01.crawl')\", 1), (\"Lemma('crawl.v.01.crawl')\", 6)])\n",
      "collecting tokens for  co-optation\n",
      "indices:    {13358, 13350, 13359}\n",
      "dict_items([(\"Lemma('co-option.n.01.co-optation')\", 3)])\n",
      "collecting tokens for  gripped\n",
      "indices:    {23179, 34061, 2575, 19282, 19284, 35636, 1273, 19226, 33851, 18143}\n",
      "dict_items([(\"Lemma('grip.v.01.grip')\", 5), (\"Lemma('fascinate.v.02.grip')\", 2), (\"Lemma('grapple.v.02.grip')\", 2)])\n",
      "collecting tokens for  rankin\n",
      "indices:    {35809}\n",
      "dict_items([])\n",
      "collecting tokens for  buckskin\n",
      "indices:    {18368, 18371, 18439, 18348, 18477, 18478, 18363, 18460}\n",
      "dict_items([(\"Lemma('buckskin.n.01.buckskin')\", 8)])\n",
      "collecting tokens for  avocado\n",
      "indices:    {1700, 1687, 1705, 1704, 1686, 36886, 1688, 1689, 1694, 1695}\n",
      "dict_items([(\"Lemma('avocado.n.01.avocado')\", 9)])\n",
      "collecting tokens for  repair\n",
      "indices:    {32353, 8806, 28711, 6120, 25224, 35723, 18254, 6035, 13367, 32344, 57, 24700, 20669, 17599}\n",
      "dict_items([(\"Lemma('repair.n.01.repair')\", 4), (\"Lemma('repair.v.01.repair')\", 3), (\"Lemma('repair.n.02.repair')\", 1)])\n",
      "collecting tokens for  democracy\n",
      "indices:    {16430, 23918, 13774, 22705, 14103}\n",
      "dict_items([(\"Lemma('democracy.n.01.democracy')\", 2), (\"Lemma('democracy.n.02.democracy')\", 1)])\n",
      "collecting tokens for  collector\n",
      "indices:    {36633}\n",
      "dict_items([])\n",
      "collecting tokens for  beaten\n",
      "indices:    {19248, 29236}\n",
      "dict_items([])\n",
      "collecting tokens for  nomination\n",
      "indices:    {20482, 4739, 20419, 2186, 2187, 22604, 20430, 20435, 20447}\n",
      "dict_items([(\"Lemma('nomination.n.01.nomination')\", 3)])\n",
      "collecting tokens for  frightening\n",
      "indices:    {2242, 14627, 26920, 33675, 12622, 2384, 12787, 28532, 20953, 10811, 25278}\n",
      "dict_items([(\"Lemma('awful.s.02.frightening')\", 6)])\n",
      "collecting tokens for  statistical\n",
      "indices:    {33057, 33059}\n",
      "dict_items([])\n",
      "collecting tokens for  discrepancy\n",
      "indices:    {25481, 15690, 15692, 15372, 15694, 22675, 14774, 3320, 21979}\n",
      "dict_items([(\"Lemma('discrepancy.n.01.discrepancy')\", 3), (\"Lemma('discrepancy.n.02.discrepancy')\", 3)])\n",
      "collecting tokens for  aug.\n",
      "indices:    {23313}\n",
      "dict_items([])\n",
      "collecting tokens for  resting\n",
      "indices:    {27374}\n",
      "dict_items([(\"Lemma('rest.v.05.rest')\", 1)])\n",
      "collecting tokens for  shaft\n",
      "indices:    {3906, 34755, 34178, 24362, 29902, 3919, 29873, 28946, 3923, 6430}\n",
      "dict_items([(\"Lemma('shaft.n.01.shaft')\", 3)])\n",
      "collecting tokens for  guideposts\n",
      "indices:    {28300}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([])\n",
      "collecting tokens for  reasoning\n",
      "indices:    {12225, 15683, 15364, 34340, 34117, 22793, 34441, 27893, 30807, 2175}\n",
      "dict_items([(\"Lemma('reasoning.n.01.reasoning')\", 4)])\n",
      "collecting tokens for  boredom\n",
      "indices:    {32089, 10481}\n",
      "dict_items([(\"Lemma('boredom.n.01.boredom')\", 1)])\n",
      "collecting tokens for  unstable\n",
      "indices:    {16196, 16228, 16198, 24071, 16200, 2929, 9628, 13374}\n",
      "dict_items([(\"Lemma('unstable.a.01.unstable')\", 5), (\"Lemma('unstable.s.02.unstable')\", 1), (\"Lemma('precarious.s.01.unstable')\", 1)])\n",
      "collecting tokens for  pockets\n",
      "indices:    {34083, 11940, 102, 20550, 18566, 17680, 2609, 29565}\n",
      "dict_items([(\"Lemma('pocket.n.03.pocket')\", 2), (\"Lemma('pouch.n.02.pocket')\", 1), (\"Lemma('pocket.n.01.pocket')\", 2)])\n",
      "collecting tokens for  thorough\n",
      "indices:    {11267, 11640, 5160, 16137, 4972, 1905, 29716, 1240, 25498}\n",
      "dict_items([(\"Lemma('thorough.s.01.thorough')\", 4), (\"Lemma('exhaustive.s.01.thorough')\", 3)])\n",
      "collecting tokens for  enabling\n",
      "indices:    {28673, 20385, 4674, 11, 32495, 20432, 32497, 1588, 2133, 24, 123}\n",
      "dict_items([(\"Lemma('enable.v.01.enable')\", 5), (\"Lemma('enabling.a.01.enabling')\", 1)])\n",
      "collecting tokens for  inspection\n",
      "indices:    {24132, 14757, 12744, 17579, 4973, 2222, 15374, 11128, 20253}\n",
      "dict_items([])\n",
      "collecting tokens for  conscientious\n",
      "indices:    {15303, 31595, 15374, 10674, 17652, 24215, 15288, 25401, 30617, 24957}\n",
      "dict_items([(\"Lemma('conscientious.s.01.conscientious')\", 2)])\n",
      "collecting tokens for  inclined\n",
      "indices:    {14950, 1480, 17229, 13198, 11918, 14384, 1009, 22066, 34867, 24442}\n",
      "dict_items([(\"Lemma('inclined.a.01.inclined')\", 4), (\"Lemma('tend.v.01.incline')\", 4)])\n",
      "collecting tokens for  supervision\n",
      "indices:    {29952, 15811, 16452, 5166, 5651, 33012, 20440, 26041, 20443, 4797, 5177}\n",
      "dict_items([(\"Lemma('supervision.n.01.supervision')\", 6)])\n",
      "collecting tokens for  extending\n",
      "indices:    {5152, 22754, 32674, 13348, 22809, 1896, 22667, 14412, 29266, 35987, 22676, 5142, 119, 2198, 23833, 21147}\n",
      "dict_items([(\"Lemma('widen.v.04.extend')\", 5), (\"Lemma('extend.v.04.extend')\", 1), (\"Lemma('run.v.03.extend')\", 7), (\"Lemma('cover.v.03.extend')\", 1), (\"Lemma('exsert.v.01.extend')\", 1), (\"Lemma('prolong.v.01.extend')\", 1)])\n",
      "collecting tokens for  analyses\n",
      "indices:    {16066, 15524, 32267, 15791, 16055, 32345, 3388, 15709}\n",
      "dict_items([(\"Lemma('analysis.n.01.analysis')\", 6)])\n",
      "collecting tokens for  ordering\n",
      "indices:    {5248, 16449, 15937, 30434, 15946, 28142, 16436, 5244}\n",
      "dict_items([(\"Lemma('ordering.n.01.ordering')\", 4), (\"Lemma('order.n.15.ordering')\", 2)])\n",
      "collecting tokens for  threats\n",
      "indices:    {36992, 24417, 18245, 18183, 30891, 37004, 6961, 5074, 82, 28696, 12505}\n",
      "dict_items([(\"Lemma('threat.n.02.threat')\", 4), (\"Lemma('threat.n.03.threat')\", 2)])\n",
      "collecting tokens for  1040\n",
      "indices:    {15584, 15553, 15586, 15552, 15554, 12488, 15593, 15626, 15594, 15600, 15639, 15640}\n",
      "dict_items([])\n",
      "collecting tokens for  justified\n",
      "indices:    {1025, 16346, 22755, 13156, 14024, 31758, 26201, 16345, 3002, 25371, 16348, 25086}\n",
      "dict_items([(\"Lemma('apologize.v.02.justify')\", 2), (\"Lemma('justify.v.01.justify')\", 7), (\"Lemma('justify.v.02.justify')\", 1)])\n",
      "collecting tokens for  don\n",
      "indices:    {380}\n",
      "dict_items([])\n",
      "collecting tokens for  eighteenth\n",
      "indices:    {2301, 24581}\n",
      "dict_items([(\"Lemma('eighteenth.s.01.eighteenth')\", 1)])\n",
      "collecting tokens for  stuart\n",
      "indices:    {36074}\n",
      "dict_items([])\n",
      "collecting tokens for  burr\n",
      "indices:    {12809, 31740, 18948}\n",
      "dict_items([(\"Lemma('burr.n.02.burr')\", 1)])\n",
      "collecting tokens for  groupings\n",
      "indices:    {27554, 23244, 4718, 13372, 16178, 13368, 4699, 23196, 27549}\n",
      "dict_items([(\"Lemma('group.n.01.grouping')\", 4), (\"Lemma('grouping.n.02.grouping')\", 1)])\n",
      "collecting tokens for  seas\n",
      "indices:    {32256, 32648, 31181, 16463, 23696, 12372, 24118, 12348}\n",
      "dict_items([(\"Lemma('sea.n.01.sea')\", 2)])\n",
      "collecting tokens for  planners\n",
      "indices:    {23746, 30532, 4613, 25574, 23430, 32904, 5423, 24915, 1855, 24918, 25820, 26687}\n",
      "dict_items([(\"Lemma('planner.n.01.planner')\", 3)])\n",
      "collecting tokens for  alert\n",
      "indices:    {35969, 19333, 21385, 34570, 1941, 6426, 30241, 30403, 17352, 15824, 30033, 11101, 30813, 5603, 31342, 6894, 8814, 29299, 17652, 33142, 5627, 31358}\n",
      "dict_items([(\"Lemma('alert.a.01.alert')\", 7), (\"Lemma('alarm.v.02.alert')\", 4)])\n",
      "collecting tokens for  chester\n",
      "indices:    {12641}\n",
      "dict_items([])\n",
      "collecting tokens for  beard\n",
      "indices:    {36546, 7564, 36883, 1273, 36734}\n",
      "dict_items([(\"Lemma('beard.n.01.beard')\", 2)])\n",
      "collecting tokens for  timing\n",
      "indices:    {32896, 11395, 22664, 1930, 11228, 29421, 27250, 281, 22619, 284, 285, 12895}\n",
      "dict_items([(\"Lemma('timing.n.01.timing')\", 6), (\"Lemma('clock.v.01.time')\", 1)])\n",
      "collecting tokens for  welch\n",
      "indices:    {36971}\n",
      "dict_items([])\n",
      "collecting tokens for  essex\n",
      "indices:    {29945}\n",
      "dict_items([])\n",
      "collecting tokens for  failing\n",
      "indices:    {24458, 197}\n",
      "dict_items([(\"Lemma('fail.v.02.fail')\", 2)])\n",
      "collecting tokens for  havana\n",
      "indices:    {23327}\n",
      "dict_items([])\n",
      "collecting tokens for  drums\n",
      "indices:    {1092}\n",
      "dict_items([(\"Lemma('drum.n.01.drum')\", 1)])\n",
      "collecting tokens for  commanded\n",
      "indices:    {13573, 12362, 33803, 12338, 6323, 7826, 10515, 31734, 12371, 19157, 10489}\n",
      "dict_items([(\"Lemma('command.v.02.command')\", 5), (\"Lemma('dominate.v.05.command')\", 1), (\"Lemma('command.v.03.command')\", 1), (\"Lemma('command.v.01.command')\", 4)])\n",
      "collecting tokens for  fertility\n",
      "indices:    {30465, 33089, 33028, 32998, 32967, 35977, 32953, 32955, 32956}\n",
      "dict_items([])\n",
      "collecting tokens for  patrolman\n",
      "indices:    {23348}\n",
      "dict_items([])\n",
      "collecting tokens for  screws\n",
      "indices:    {28775, 29737, 28814, 29774, 28786, 28787, 29715, 29749, 29879}\n",
      "dict_items([])\n",
      "collecting tokens for  opponent\n",
      "indices:    {28449, 31719, 841, 24779, 18834, 13942, 28442, 24860}\n",
      "dict_items([(\"Lemma('opposition.n.04.opponent')\", 1)])\n",
      "collecting tokens for  pathological\n",
      "indices:    {4224, 27723, 27725, 4276, 3988, 4246, 4215, 32858, 4255}\n",
      "dict_items([(\"Lemma('pathological.a.01.pathological')\", 5), (\"Lemma('pathological.s.02.pathological')\", 1)])\n",
      "collecting tokens for  lucia\n",
      "indices:    {1073}\n",
      "dict_items([(\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  achieving\n",
      "indices:    {2880, 12929, 14740, 26197, 32918, 31929, 11258, 35999}\n",
      "dict_items([(\"Lemma('achieve.v.01.achieve')\", 7)])\n",
      "collecting tokens for  homogeneous\n",
      "indices:    {2375, 4110, 13327, 2320, 31791, 13711, 2326, 13784}\n",
      "dict_items([(\"Lemma('homogeneous.a.01.homogeneous')\", 7)])\n",
      "collecting tokens for  experimentation\n",
      "indices:    {30754, 11235, 32900, 32907, 11219, 727, 34745, 11226, 14397, 4254}\n",
      "dict_items([(\"Lemma('experiment.n.01.experimentation')\", 3), (\"Lemma('experiment.n.02.experimentation')\", 3)])\n",
      "collecting tokens for  da\n",
      "indices:    {34911}\n",
      "dict_items([])\n",
      "collecting tokens for  transparent\n",
      "indices:    {19526, 13575, 2408, 29577, 11369, 29614, 2809, 37112, 11353}\n",
      "dict_items([(\"Lemma('crystalline.s.03.transparent')\", 5), (\"Lemma('diaphanous.s.01.transparent')\", 1)])\n",
      "collecting tokens for  empire\n",
      "indices:    {20800}\n",
      "dict_items([])\n",
      "collecting tokens for  shocked\n",
      "indices:    {24202, 14091, 24305, 30833, 7480, 24985, 22746, 25211, 19423}\n",
      "dict_items([(\"Lemma('shock.v.02.shock')\", 2), (\"Lemma('shock.v.01.shock')\", 3)])\n",
      "collecting tokens for  owe\n",
      "indices:    {15584, 32227, 22692, 6568, 26602, 18605, 22683}\n",
      "dict_items([(\"Lemma('owe.v.01.owe')\", 4), (\"Lemma('owe.v.02.owe')\", 2), (\"Lemma('owe.v.03.owe')\", 1)])\n",
      "collecting tokens for  frankie\n",
      "indices:    {19990}\n",
      "dict_items([(\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  mileage\n",
      "indices:    {32289, 32290, 32296, 22475, 32273, 32279}\n",
      "dict_items([])\n",
      "collecting tokens for  doubted\n",
      "indices:    {10240, 641, 16709, 18376, 35757, 19280, 34192, 22963, 9459}\n",
      "dict_items([(\"Lemma('doubt.v.01.doubt')\", 9)])\n",
      "collecting tokens for  logic\n",
      "indices:    {22241, 35524, 14919, 7273, 37104, 16657, 1015, 4696, 5401}\n",
      "dict_items([(\"Lemma('logic.n.02.logic')\", 2), (\"Lemma('logic.n.03.logic')\", 1), (\"Lemma('logic.n.01.logic')\", 2)])\n",
      "collecting tokens for  canadian\n",
      "indices:    {32716}\n",
      "dict_items([])\n",
      "collecting tokens for  carl\n",
      "indices:    {21886}\n",
      "dict_items([])\n",
      "collecting tokens for  plow\n",
      "indices:    {2393, 23107, 33796, 21206}\n",
      "dict_items([])\n",
      "collecting tokens for  backs\n",
      "indices:    {25827, 33804, 26828, 30034, 35637, 26805, 23033, 24795, 7900}\n",
      "dict_items([(\"Lemma('back.v.01.back')\", 1)])\n",
      "collecting tokens for  screaming\n",
      "indices:    {33829, 12423, 17576, 10827, 6923, 19889, 13522, 13523, 35637, 30903, 6204, 12893}\n",
      "dict_items([(\"Lemma('shout.v.02.scream')\", 6), (\"Lemma('yell.v.02.scream')\", 1), (\"Lemma('screaming.s.01.screaming')\", 1), (\"Lemma('scream.n.01.screaming')\", 1)])\n",
      "collecting tokens for  mentally\n",
      "indices:    {36896, 25025, 25024, 30243, 24358, 17352, 14312, 5967, 11632, 33270, 23638, 17206, 124, 14269}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('mentally.r.01.mentally')\", 5)])\n",
      "collecting tokens for  alveolar\n",
      "indices:    {3808, 3817, 3850, 3793, 3410, 3794, 3770, 3803, 3807}\n",
      "dict_items([(\"Lemma('alveolar.a.01.alveolar')\", 8)])\n",
      "collecting tokens for  straw\n",
      "indices:    {10497, 706, 6500, 8103, 9512, 13575, 9325, 9326, 26704, 9361, 18480, 9494, 1657, 29982}\n",
      "dict_items([(\"Lemma('straw.n.01.straw')\", 8), (\"Lemma('straw.s.01.straw')\", 1), (\"Lemma('chaff.n.01.straw')\", 1)])\n",
      "collecting tokens for  suitcase\n",
      "indices:    {34144, 10497, 34136, 16937, 34154, 34155, 34158, 34127, 17199, 17138, 17139, 34132, 9944, 15741}\n",
      "dict_items([(\"Lemma('bag.n.06.suitcase')\", 7)])\n",
      "collecting tokens for  catcher\n",
      "indices:    {19842, 19811, 19816, 19833, 19818, 19793, 22995, 19832, 185, 186, 19804, 19806}\n",
      "dict_items([(\"Lemma('catcher.n.01.catcher')\", 11)])\n",
      "collecting tokens for  egg\n",
      "indices:    {3616, 9337, 3618, 3655, 3624, 1706, 30413, 9394, 29236, 3641}\n",
      "dict_items([(\"Lemma('egg.n.01.egg')\", 6)])\n",
      "collecting tokens for  disturbed\n",
      "indices:    {10786, 35651, 31940, 1250, 12547, 27330, 12676, 24529, 6289, 33267, 27322, 4917, 31475, 27320, 8346, 35995, 12254}\n",
      "dict_items([(\"Lemma('disquieted.s.01.disturbed')\", 1), (\"Lemma('disturb.v.01.disturb')\", 6), (\"Lemma('touch.v.11.disturb')\", 1), (\"Lemma('disturbed.s.03.disturbed')\", 1), (\"Lemma('agitate.v.06.disturb')\", 3), (\"Lemma('interrupt.v.02.disturb')\", 1)])\n",
      "collecting tokens for  swinging\n",
      "indices:    {18648, 36721, 9465}\n",
      "dict_items([(\"Lemma('swing.v.01.swing')\", 1), (\"Lemma('swing.v.02.swing')\", 1)])\n",
      "collecting tokens for  erect\n",
      "indices:    {4490, 8524, 36716, 35570, 4564, 35605, 11768, 8506, 24829, 8574}\n",
      "dict_items([(\"Lemma('erect.a.01.erect')\", 3), (\"Lemma('raise.v.09.erect')\", 4)])\n",
      "collecting tokens for  minimize\n",
      "indices:    {16450, 11747, 4775, 5392, 32625, 3125, 25302, 4765, 11775}\n",
      "dict_items([(\"Lemma('minimize.v.01.minimize')\", 9)])\n",
      "collecting tokens for  triumph\n",
      "indices:    {192, 27272, 2654, 8844, 333, 8238, 24015, 36239, 861, 22960, 460, 36948, 1784, 14525, 830}\n",
      "dict_items([(\"Lemma('prevail.v.04.triumph')\", 1), (\"Lemma('victory.n.01.triumph')\", 5), (\"Lemma('triumph.n.02.triumph')\", 5)])\n",
      "collecting tokens for  beg\n",
      "indices:    {28291, 24297, 35981, 36462, 33390, 14262, 8279, 8572, 8669}\n",
      "dict_items([(\"Lemma('solicit.v.01.beg')\", 3), (\"Lemma('beg.v.01.beg')\", 4), (\"Lemma('beg.v.03.beg')\", 1)])\n",
      "collecting tokens for  thirteen\n",
      "indices:    {546}\n",
      "dict_items([(\"Lemma('thirteen.n.01.thirteen')\", 1)])\n",
      "collecting tokens for  schedules\n",
      "indices:    {11747, 20997, 24421, 16521, 21878, 6168, 22618, 33053}\n",
      "dict_items([(\"Lemma('agenda.n.01.schedule')\", 2), (\"Lemma('schedule.n.02.schedule')\", 1)])\n",
      "collecting tokens for  competing\n",
      "indices:    {16192, 23488, 11648, 25921, 22795, 5200, 11250, 1942, 15231, 12697, 25917, 20671}\n",
      "dict_items([(\"Lemma('compete.v.01.compete')\", 7)])\n",
      "collecting tokens for  louder\n",
      "indices:    {5656, 809, 6731, 35600, 17848, 17850, 33788, 1086}\n",
      "dict_items([(\"Lemma('loud.a.01.loud')\", 5), (\"Lemma('brassy.s.02.loud')\", 1)])\n",
      "collecting tokens for  prohibition\n",
      "indices:    {23708, 13702}\n",
      "dict_items([(\"Lemma('prohibition.n.01.prohibition')\", 1)])\n",
      "collecting tokens for  loses\n",
      "indices:    {11489, 25863, 13704, 13674, 24171, 24242, 2322, 31002}\n",
      "dict_items([(\"Lemma('lose.v.01.lose')\", 6), (\"Lemma('lose.v.07.lose')\", 1), (\"Lemma('lose.v.02.lose')\", 1)])\n",
      "collecting tokens for  tent\n",
      "indices:    {8480, 7143, 7113, 8492, 11953, 7154, 22516, 22522, 7131, 7197}\n",
      "dict_items([(\"Lemma('tent.n.01.tent')\", 8)])\n",
      "collecting tokens for  eighteen\n",
      "indices:    {31560, 32423}\n",
      "dict_items([])\n",
      "collecting tokens for  shipping\n",
      "indices:    {1696, 11545, 11529, 11531, 25005, 11597, 11537, 11541, 11605, 22009, 21722, 11519}\n",
      "dict_items([(\"Lemma('transportation.n.05.shipping')\", 4), (\"Lemma('transport.v.04.ship')\", 2)])\n",
      "collecting tokens for  roebuck\n",
      "indices:    {18875}\n",
      "dict_items([])\n",
      "collecting tokens for  planted\n",
      "indices:    {18563, 14601, 1610, 13549, 23988, 22011, 13562, 9499, 13566}\n",
      "dict_items([(\"Lemma('deep-rooted.s.01.planted')\", 1), (\"Lemma('implant.v.01.plant')\", 1), (\"Lemma('plant.v.01.plant')\", 5)])\n",
      "collecting tokens for  controller\n",
      "indices:    {20669}\n",
      "dict_items([])\n",
      "collecting tokens for  defects\n",
      "indices:    {4039, 14253, 29550, 33038, 11378, 32146, 25396, 1812, 29562}\n",
      "dict_items([(\"Lemma('defect.n.02.defect')\", 1), (\"Lemma('defect.n.01.defect')\", 2), (\"Lemma('defect.n.03.defect')\", 1)])\n",
      "collecting tokens for  generators\n",
      "indices:    {32776, 32780, 32781, 2865, 2867, 32820, 32821, 32798, 2879}\n",
      "dict_items([(\"Lemma('generator.n.01.generator')\", 3)])\n",
      "collecting tokens for  plowing\n",
      "indices:    {12133, 30406, 12134, 12136, 30411, 21196, 12434, 20443}\n",
      "dict_items([(\"Lemma('plow.v.01.plow')\", 4), (\"Lemma('plowing.n.01.plowing')\", 1), (\"Lemma('plow.v.03.plow')\", 1)])\n",
      "collecting tokens for  despair\n",
      "indices:    {11075, 18853, 1158, 13965, 526, 15857, 33586, 17013, 29173, 13400, 13401, 35711}\n",
      "dict_items([(\"Lemma('despair.n.02.despair')\", 2), (\"Lemma('despair.n.01.despair')\", 6), (\"Lemma('despair.v.01.despair')\", 2)])\n",
      "collecting tokens for  oriented\n",
      "indices:    {2304, 15424, 30119, 24843, 3213, 13165, 27570, 16282}\n",
      "dict_items([(\"Lemma('oriented.a.01.oriented')\", 4), (\"Lemma('orient.v.01.orient')\", 2), (\"Lemma('orient.v.03.orient')\", 1)])\n",
      "collecting tokens for  hurricane\n",
      "indices:    {24012, 19248, 32440, 27066, 31227}\n",
      "dict_items([])\n",
      "collecting tokens for  publications\n",
      "indices:    {756, 2749}\n",
      "dict_items([(\"Lemma('publication.n.01.publication')\", 1)])\n",
      "collecting tokens for  squeeze\n",
      "indices:    {20359, 36074, 18287, 25936, 25650, 2194, 8158, 27966}\n",
      "dict_items([(\"Lemma('squash.v.01.squeeze')\", 4), (\"Lemma('squeeze.n.01.squeeze')\", 1), (\"Lemma('wedge.v.02.squeeze')\", 1)])\n",
      "collecting tokens for  monroe\n",
      "indices:    {14959}\n",
      "dict_items([])\n",
      "collecting tokens for  satisfactorily\n",
      "indices:    {4162, 4194, 21956, 4173, 1072, 4177, 4179, 13304}\n",
      "dict_items([(\"Lemma('satisfactorily.r.01.satisfactorily')\", 7)])\n",
      "collecting tokens for  thurber\n",
      "indices:    {26185}\n",
      "dict_items([])\n",
      "collecting tokens for  quit\n",
      "indices:    {24144, 12251, 36236, 18468}\n",
      "dict_items([(\"Lemma('discontinue.v.01.quit')\", 3), (\"Lemma('leave_office.v.01.quit')\", 1)])\n",
      "collecting tokens for  kohnstamm-negative\n",
      "indices:    {33192}\n",
      "dict_items([])\n",
      "collecting tokens for  ideals\n",
      "indices:    {11211, 28016, 26907, 28020, 4665, 4667, 25339}\n",
      "dict_items([(\"Lemma('ideal.n.01.ideal')\", 3)])\n",
      "collecting tokens for  collect\n",
      "indices:    {29153, 22916, 8710, 2217, 27949, 23931, 20948, 6261, 3667, 11835, 36668, 26622}\n",
      "dict_items([(\"Lemma('collect.v.02.collect')\", 5), (\"Lemma('collect.v.05.collect')\", 1), (\"Lemma('gather.v.01.collect')\", 4), (\"Lemma('roll_up.v.02.collect')\", 2)])\n",
      "collecting tokens for  trophy\n",
      "indices:    {28584}\n",
      "dict_items([])\n",
      "collecting tokens for  examine\n",
      "indices:    {15424, 26785, 16130, 20327, 4791, 4010, 11629, 27982, 35470, 14352, 34736, 3639, 17561, 5367, 2044, 17023}\n",
      "dict_items([(\"Lemma('analyze.v.01.examine')\", 8), (\"Lemma('examine.v.02.examine')\", 3), (\"Lemma('probe.v.01.examine')\", 4), (\"Lemma('test.v.01.examine')\", 1)])\n",
      "collecting tokens for  persians\n",
      "indices:    {31536}\n",
      "dict_items([])\n",
      "collecting tokens for  frankfurter\n",
      "indices:    {29472, 29508, 29478, 29512, 29481, 29521, 29533, 29534}\n",
      "dict_items([])\n",
      "collecting tokens for  tents\n",
      "indices:    {31859, 11907, 11927}\n",
      "dict_items([(\"Lemma('tent.n.01.tent')\", 2)])\n",
      "collecting tokens for  moritz\n",
      "indices:    {286}\n",
      "dict_items([(\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  exhausted\n",
      "indices:    {6049, 11433, 1354, 13963, 34960, 27316, 10517, 33849, 24796, 34941, 36543}\n",
      "dict_items([(\"Lemma('consume.v.05.exhaust')\", 2), (\"Lemma('exhausted.s.01.exhausted')\", 3), (\"Lemma('exhaust.v.01.exhaust')\", 2)])\n",
      "collecting tokens for  voyage\n",
      "indices:    {12388, 32645, 12390, 31684, 10250, 12363, 13739, 12334, 12338, 12376, 12377, 12350, 12345}\n",
      "dict_items([(\"Lemma('ocean_trip.n.01.voyage')\", 9), (\"Lemma('voyage.n.02.voyage')\", 1)])\n",
      "collecting tokens for  forbidden\n",
      "indices:    {2657, 12324, 25156, 13990, 14634, 25676, 6797, 34798, 21327, 812, 13586, 31358}\n",
      "dict_items([(\"Lemma('forbid.v.01.forbid')\", 7), (\"Lemma('forbidden.s.01.forbidden')\", 4)])\n",
      "collecting tokens for  screamed\n",
      "indices:    {30913, 35618, 18436, 35589, 10828, 6292, 19804, 20025, 6300, 33372}\n",
      "dict_items([(\"Lemma('shout.v.02.scream')\", 8), (\"Lemma('yell.v.02.scream')\", 1)])\n",
      "collecting tokens for  barrier\n",
      "indices:    {34755, 31111, 35625, 30927, 30781, 4148, 7829, 24829}\n",
      "dict_items([(\"Lemma('barrier.n.01.barrier')\", 2)])\n",
      "collecting tokens for  theologians\n",
      "indices:    {14592, 5218, 13346, 27850, 25470, 5236, 14713, 1501, 14590}\n",
      "dict_items([(\"Lemma('theologian.n.01.theologian')\", 7)])\n",
      "collecting tokens for  marksman\n",
      "indices:    {4387, 4424, 4460, 4430, 17136, 4435, 4437, 4477}\n",
      "dict_items([(\"Lemma('marksman.n.01.marksman')\", 8)])\n",
      "collecting tokens for  viewpoint\n",
      "indices:    {14148, 12292, 12325, 12265, 1354, 4430, 3822, 12305, 20593, 3828, 13719, 26522}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('point_of_view.n.01.viewpoint')\", 10)])\n",
      "collecting tokens for  bull's-eye\n",
      "indices:    {4387, 777, 4394, 4460, 780, 4430, 4401, 4435, 4437}\n",
      "dict_items([(\"Lemma('bull's_eye.n.01.bull's_eye')\", 6), (\"Lemma('bell_ringer.n.03.bull's_eye')\", 1), (\"Lemma('bull's_eye.n.02.bull's_eye')\", 2)])\n",
      "collecting tokens for  eagerly\n",
      "indices:    {17764, 30821, 12015, 27025, 35027, 15827, 4762}\n",
      "dict_items([(\"Lemma('eagerly.r.01.eagerly')\", 4)])\n",
      "collecting tokens for  skiff\n",
      "indices:    {34434, 34436, 8648, 34447, 34421, 34422, 34426, 34428, 8573, 8639}\n",
      "dict_items([(\"Lemma('skiff.n.01.skiff')\", 3)])\n",
      "collecting tokens for  purchasing\n",
      "indices:    {11777, 20315, 23555, 32453, 6, 2737, 15230, 32305, 2772, 24054, 24057, 2779, 2750, 31775}\n",
      "dict_items([(\"Lemma('buy.v.01.purchase')\", 7)])\n",
      "collecting tokens for  1945\n",
      "indices:    {5120, 12709, 12933, 20585, 25418, 21421, 25263, 26191, 31636, 3999}\n",
      "dict_items([])\n",
      "collecting tokens for  prosperity\n",
      "indices:    {24033, 28098, 12917, 25176, 27769}\n",
      "dict_items([])\n",
      "collecting tokens for  apt\n",
      "indices:    {33282, 3242, 14220, 30833, 2290, 26514, 2289, 2357, 5404, 22108}\n",
      "dict_items([])\n",
      "collecting tokens for  founded\n",
      "indices:    {24675, 29339, 22688, 27559}\n",
      "dict_items([(\"Lemma('establish.v.01.found')\", 2), (\"Lemma('establish.v.02.found')\", 1)])\n",
      "collecting tokens for  invitation\n",
      "indices:    {24850, 27341, 25638}\n",
      "dict_items([])\n",
      "collecting tokens for  victim\n",
      "indices:    {18306, 32067, 31941, 16841, 2188, 21165, 36945, 36883, 14291, 21171, 20726, 3639, 28443, 25374}\n",
      "dict_items([(\"Lemma('victim.n.01.victim')\", 5)])\n",
      "collecting tokens for  certainty\n",
      "indices:    {17984, 4672, 19714, 31171, 27812, 30310, 27817, 24300, 15663, 27794, 33586, 27803}\n",
      "dict_items([(\"Lemma('certainty.n.01.certainty')\", 3), (\"Lemma('certainty.n.02.certainty')\", 1)])\n",
      "collecting tokens for  gland\n",
      "indices:    {3939, 740, 4005, 744, 4042, 3980, 3950, 3984, 3989}\n",
      "dict_items([(\"Lemma('gland.n.01.gland')\", 3)])\n",
      "collecting tokens for  glove\n",
      "indices:    {34025, 202, 24489, 19885, 369, 187, 220, 19806}\n",
      "dict_items([(\"Lemma('baseball_glove.n.01.glove')\", 6)])\n",
      "collecting tokens for  brandt\n",
      "indices:    {24516}\n",
      "dict_items([])\n",
      "collecting tokens for  husbands\n",
      "indices:    {37057, 37025, 12069, 12010, 3595, 15279, 12048, 25009, 13176, 12315, 12573, 21086, 12031}\n",
      "dict_items([(\"Lemma('husband.n.01.husband')\", 9)])\n",
      "collecting tokens for  foundations\n",
      "indices:    {4993, 28034, 14088, 27287, 2234, 29851, 4990, 5023}\n",
      "dict_items([(\"Lemma('foundation.n.02.foundation')\", 1), (\"Lemma('foundation.n.01.foundation')\", 3), (\"Lemma('foundation.n.03.foundation')\", 1)])\n",
      "collecting tokens for  fusion\n",
      "indices:    {28101, 3911, 34377, 25417, 34447, 34448, 3922, 4212, 25397, 921, 34428, 34461}\n",
      "dict_items([(\"Lemma('fusion.n.01.fusion')\", 4)])\n",
      "collecting tokens for  walker\n",
      "indices:    {16919}\n",
      "dict_items([])\n",
      "collecting tokens for  visits\n",
      "indices:    {23554, 14474, 16043, 32459, 32877, 35725, 32853, 31031, 32473, 32859, 32476}\n",
      "dict_items([(\"Lemma('visit.n.01.visit')\", 2)])\n",
      "collecting tokens for  humidity\n",
      "indices:    {30199, 3443, 30101, 23831, 3416, 30172, 30174, 30175}\n",
      "dict_items([(\"Lemma('humidity.n.01.humidity')\", 1)])\n",
      "collecting tokens for  luis\n",
      "indices:    {18085}\n",
      "dict_items([])\n",
      "collecting tokens for  three-dimensional\n",
      "indices:    {4963, 5407, 32741, 5392, 5397, 7606, 19094, 5375}\n",
      "dict_items([(\"Lemma('three-dimensional.s.01.three-dimensional')\", 5)])\n",
      "collecting tokens for  everlasting\n",
      "indices:    {27395, 28261, 28247, 27369, 34890, 36303, 25269, 25751}\n",
      "dict_items([])\n",
      "collecting tokens for  patches\n",
      "indices:    {31457, 5381, 11114, 4076, 19124, 19162, 34206, 27007}\n",
      "dict_items([(\"Lemma('spot.n.05.patch')\", 5)])\n",
      "collecting tokens for  150\n",
      "indices:    {27334, 29129, 5066, 15146, 3563, 25675, 30543, 22493, 21169, 23578, 28669, 159}\n",
      "dict_items([])\n",
      "collecting tokens for  insert\n",
      "indices:    {28832, 28805, 36966, 28809, 29418, 29099, 29100, 28789, 28791, 28856}\n",
      "dict_items([(\"Lemma('insert.v.01.insert')\", 6), (\"Lemma('insert.v.02.insert')\", 1)])\n",
      "collecting tokens for  chorus\n",
      "indices:    {20391, 26443, 1164, 27981, 26448, 26802, 26803, 32218, 25692, 6046}\n",
      "dict_items([(\"Lemma('refrain.n.01.chorus')\", 1)])\n",
      "collecting tokens for  delighted\n",
      "indices:    {30977, 10693, 19687, 26087, 22508, 6253, 6799, 23154, 10005, 24218, 1213, 9342}\n",
      "dict_items([(\"Lemma('please.v.01.delight')\", 4), (\"Lemma('delighted.s.01.delighted')\", 3)])\n",
      "collecting tokens for  cavalry\n",
      "indices:    {12856}\n",
      "dict_items([])\n",
      "collecting tokens for  mercury\n",
      "indices:    {14825, 5319}\n",
      "dict_items([])\n",
      "collecting tokens for  phony\n",
      "indices:    {17826, 33574, 2248, 2254, 15826, 2228, 33495, 2232, 33943, 30879}\n",
      "dict_items([(\"Lemma('bogus.s.01.phony')\", 6)])\n",
      "collecting tokens for  counseling\n",
      "indices:    {1316, 23780, 2724, 16230, 14997, 15003}\n",
      "dict_items([(\"Lemma('guidance.n.01.counseling')\", 4)])\n",
      "collecting tokens for  pursued\n",
      "indices:    {12929, 10877, 18601, 23372, 21389, 13390, 2447, 31613}\n",
      "dict_items([(\"Lemma('prosecute.v.03.pursue')\", 5), (\"Lemma('pursue.v.02.pursue')\", 1), (\"Lemma('pursue.v.04.pursue')\", 1), (\"Lemma('pursued.n.01.pursued')\", 1)])\n",
      "collecting tokens for  dots\n",
      "indices:    {21260, 7730, 4952, 3894, 3864, 4953, 3866, 3870}\n",
      "dict_items([(\"Lemma('point.n.09.dot')\", 7)])\n",
      "collecting tokens for  homely\n",
      "indices:    {31972, 19269, 7977, 16750, 16751, 19183, 16732, 19773, 12574}\n",
      "dict_items([(\"Lemma('homely.s.03.homely')\", 1), (\"Lemma('homelike.s.01.homely')\", 3), (\"Lemma('homely.s.01.homely')\", 4)])\n",
      "collecting tokens for  insects\n",
      "indices:    {34574}\n",
      "dict_items([])\n",
      "collecting tokens for  presiding\n",
      "indices:    {6093}\n",
      "dict_items([])\n",
      "collecting tokens for  collecting\n",
      "indices:    {11107, 3624, 34763, 9521, 30709, 30718, 23134}\n",
      "dict_items([(\"Lemma('roll_up.v.02.collect')\", 3), (\"Lemma('collect.v.04.collect')\", 2), (\"Lemma('collect.v.02.collect')\", 1)])\n",
      "collecting tokens for  unprecedented\n",
      "indices:    {1056, 25472, 14921, 22995, 34421, 16920, 22782, 863}\n",
      "dict_items([(\"Lemma('unprecedented.a.01.unprecedented')\", 4)])\n",
      "collecting tokens for  appearances\n",
      "indices:    {30310, 27110, 9833, 26507, 26798, 20915, 31635, 26425, 22334, 21759}\n",
      "dict_items([(\"Lemma('appearance.n.01.appearance')\", 1)])\n",
      "collecting tokens for  gop\n",
      "indices:    {24821}\n",
      "dict_items([])\n",
      "collecting tokens for  shaefer\n",
      "indices:    {2218}\n",
      "dict_items([])\n",
      "collecting tokens for  stereotype\n",
      "indices:    {25927, 15849, 15850, 15851, 31820, 24460, 15852, 25915, 22715}\n",
      "dict_items([(\"Lemma('stereotype.n.01.stereotype')\", 4)])\n",
      "collecting tokens for  sometime\n",
      "indices:    {11105, 20522, 16591}\n",
      "dict_items([(\"Lemma('sometime.r.01.sometime')\", 2)])\n",
      "collecting tokens for  noticeable\n",
      "indices:    {20232, 33160, 1098, 20234, 30990, 34191, 3576, 3288}\n",
      "dict_items([(\"Lemma('noticeable.a.01.noticeable')\", 2), (\"Lemma('detectable.s.01.noticeable')\", 1)])\n",
      "collecting tokens for  cop\n",
      "indices:    {17568, 7028, 30958, 1191}\n",
      "dict_items([(\"Lemma('bull.n.05.cop')\", 2)])\n",
      "collecting tokens for  infrared\n",
      "indices:    {3114, 2794, 28524, 2808, 14840, 2809, 2810}\n",
      "dict_items([(\"Lemma('infrared.s.01.infrared')\", 1)])\n",
      "collecting tokens for  cigar\n",
      "indices:    {17890, 35845, 11151, 33460, 29204, 18134, 6489, 17886}\n",
      "dict_items([(\"Lemma('cigar.n.01.cigar')\", 3)])\n",
      "collecting tokens for  puzzle\n",
      "indices:    {27043, 27531, 9995, 28718, 28815, 23664, 23221, 6203}\n",
      "dict_items([])\n",
      "collecting tokens for  kicking\n",
      "indices:    {6885, 281, 35627, 34669, 271, 10927, 34036, 1976, 1977}\n",
      "dict_items([(\"Lemma('kick.v.02.kick')\", 4), (\"Lemma('kick.v.03.kick')\", 1), (\"Lemma('kick.v.01.kick')\", 2)])\n",
      "collecting tokens for  decent\n",
      "indices:    {9675, 14252, 21017, 20591, 32240, 8503, 15449, 26910}\n",
      "dict_items([(\"Lemma('becoming.s.01.decent')\", 1), (\"Lemma('decent.s.01.decent')\", 3)])\n",
      "collecting tokens for  undue\n",
      "indices:    {32872, 25389, 14925, 11310, 27214, 19, 22612, 29886}\n",
      "dict_items([(\"Lemma('undue.a.01.undue')\", 2), (\"Lemma('undue.a.02.undue')\", 1)])\n",
      "collecting tokens for  sixties\n",
      "indices:    {11620, 7370, 19555, 11636}\n",
      "dict_items([(\"Lemma('sixties.n.01.sixties')\", 2), (\"Lemma('sixties.n.02.sixties')\", 1)])\n",
      "collecting tokens for  interpret\n",
      "indices:    {4994, 22665, 4908, 18349, 4276, 5013, 31161, 27871}\n",
      "dict_items([(\"Lemma('represent.v.09.interpret')\", 2), (\"Lemma('rede.v.01.interpret')\", 2), (\"Lemma('interpret.v.01.interpret')\", 4)])\n",
      "collecting tokens for  supporting\n",
      "indices:    {32960, 25857, 5346, 32164, 10538, 15725, 15727, 15539, 32916, 29878, 28696, 28795, 31773, 15006}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('support.n.08.supporting')\", 1), (\"Lemma('back.v.01.support')\", 1), (\"Lemma('hold.v.10.support')\", 2), (\"Lemma('support.v.02.support')\", 1), (\"Lemma('support.v.01.support')\", 3), (\"Lemma('encouraging.s.02.supporting')\", 2)])\n",
      "collecting tokens for  gradual\n",
      "indices:    {13216, 31808, 31850, 23476, 4022, 30807}\n",
      "dict_items([(\"Lemma('gradual.a.01.gradual')\", 2)])\n",
      "collecting tokens for  cereal\n",
      "indices:    {30448, 30450, 30451, 30452, 30454, 30455, 30488, 37081, 30493}\n",
      "dict_items([])\n",
      "collecting tokens for  trigger\n",
      "indices:    {18822, 31304, 18408, 29068, 6925, 29070, 18609, 35573, 5910, 31256, 29113}\n",
      "dict_items([(\"Lemma('trip.v.04.trigger')\", 1), (\"Lemma('gun_trigger.n.01.trigger')\", 4)])\n",
      "collecting tokens for  satire\n",
      "indices:    {10858, 10859, 1006, 10832, 14482, 27027, 11187, 10805}\n",
      "dict_items([(\"Lemma('sarcasm.n.01.satire')\", 7)])\n",
      "collecting tokens for  await\n",
      "indices:    {5472, 23589, 2570, 2559, 7695, 3759, 4991}\n",
      "dict_items([(\"Lemma('expect.v.03.await')\", 7)])\n",
      "collecting tokens for  titles\n",
      "indices:    {1091, 33093, 2046}\n",
      "dict_items([(\"Lemma('title.n.03.title')\", 1)])\n",
      "collecting tokens for  silk\n",
      "indices:    {37056, 35744, 22080, 21152, 7777, 18853, 9549, 7601, 9719, 7354, 21148}\n",
      "dict_items([(\"Lemma('silk.n.01.silk')\", 5), (\"Lemma('silk.n.02.silk')\", 1)])\n",
      "collecting tokens for  historically\n",
      "indices:    {4725}\n",
      "dict_items([(\"Lemma('historically.r.01.historically')\", 1)])\n",
      "collecting tokens for  virtues\n",
      "indices:    {26241, 13198, 26095, 26062, 19094, 23128, 26173, 27295}\n",
      "dict_items([(\"Lemma('merit.n.01.virtue')\", 2)])\n",
      "collecting tokens for  simultaneous\n",
      "indices:    {22532, 3550, 11366, 26122, 3827, 22645, 2910, 22591}\n",
      "dict_items([(\"Lemma('coincident.s.01.simultaneous')\", 4)])\n",
      "collecting tokens for  tunnel\n",
      "indices:    {34176, 31555, 34180, 34184, 34154, 34155, 32170, 35860, 34169}\n",
      "dict_items([(\"Lemma('burrow.v.01.tunnel')\", 1)])\n",
      "collecting tokens for  creates\n",
      "indices:    {1249, 13924, 10633, 15724, 24528, 30737, 23666, 27127, 13979, 27708}\n",
      "dict_items([(\"Lemma('make.v.03.create')\", 8), (\"Lemma('create.v.02.create')\", 2)])\n",
      "collecting tokens for  permission\n",
      "indices:    {27810, 32706, 35689, 18699, 6832, 20948, 469, 9592}\n",
      "dict_items([(\"Lemma('permission.n.01.permission')\", 3), (\"Lemma('license.n.04.permission')\", 1)])\n",
      "collecting tokens for  encouraging\n",
      "indices:    {22849, 20295, 22824, 27240, 32503, 20844, 26189, 21236, 22356, 16245, 28565, 27900}\n",
      "dict_items([(\"Lemma('promote.v.01.encourage')\", 7), (\"Lemma('encourage.v.02.encourage')\", 1)])\n",
      "collecting tokens for  bronchioles\n",
      "indices:    {3776, 3815, 3783, 3851, 3852, 3803, 3772}\n",
      "dict_items([(\"Lemma('bronchiole.n.01.bronchiole')\", 7)])\n",
      "collecting tokens for  deputies\n",
      "indices:    {31337, 5102, 5048, 23, 18264, 5049, 24154, 24155, 23326}\n",
      "dict_items([(\"Lemma('deputy.n.01.deputy')\", 4), (\"Lemma('deputy.n.02.deputy')\", 1)])\n",
      "collecting tokens for  defended\n",
      "indices:    {15777, 27269, 26571, 24111, 7731, 31959, 12473, 23863}\n",
      "dict_items([(\"Lemma('defend.v.03.defend')\", 1), (\"Lemma('defend.v.02.defend')\", 3), (\"Lemma('defend.v.01.defend')\", 4)])\n",
      "collecting tokens for  disappointed\n",
      "indices:    {13825, 31739, 6445, 12496, 36627, 10015, 36566, 8347, 10428, 35743}\n",
      "dict_items([(\"Lemma('defeated.s.02.disappointed')\", 4), (\"Lemma('disappoint.v.01.disappoint')\", 4)])\n",
      "collecting tokens for  tailored\n",
      "indices:    {14049, 11970, 36453, 17704, 13321, 17866, 14543, 692, 32159}\n",
      "dict_items([(\"Lemma('tailored.s.01.tailored')\", 3), (\"Lemma('tailor.v.01.tailor')\", 5), (\"Lemma('cut.v.07.tailor')\", 1)])\n",
      "collecting tokens for  charging\n",
      "indices:    {12804, 20074, 7306, 23632, 21777, 18450, 35441, 35541}\n",
      "dict_items([(\"Lemma('charge.v.01.charge')\", 3), (\"Lemma('tear.v.03.charge')\", 1), (\"Lemma('charge.v.02.charge')\", 1), (\"Lemma('charge.v.03.charge')\", 2)])\n",
      "collecting tokens for  paradoxically\n",
      "indices:    {32052, 22807}\n",
      "dict_items([])\n",
      "collecting tokens for  drivers\n",
      "indices:    {18852, 12870, 23143, 5895, 24459, 21772, 24461, 24462, 25233, 18870, 4407, 32280, 32281, 4410, 11773}\n",
      "dict_items([(\"Lemma('driver.n.01.driver')\", 6)])\n",
      "collecting tokens for  cooperate\n",
      "indices:    {28673, 27011, 11877, 20678, 33061, 21450, 14736, 13936, 14738, 20788}\n",
      "dict_items([(\"Lemma('collaborate.v.01.cooperate')\", 10)])\n",
      "collecting tokens for  sorbed\n",
      "indices:    {3213, 3214, 3215, 3216, 3218, 3220, 3196}\n",
      "dict_items([(\"Lemma('sorb.v.01.sorb')\", 5), (\"Lemma('occluded.s.02.sorbed')\", 2)])\n",
      "collecting tokens for  greasy\n",
      "indices:    {3187, 33589}\n",
      "dict_items([(\"Lemma('greasy.s.01.greasy')\", 1)])\n",
      "collecting tokens for  concord\n",
      "indices:    {30543}\n",
      "dict_items([])\n",
      "collecting tokens for  condensed\n",
      "indices:    {7115, 15852, 3245, 3216, 15859, 2457, 3258}\n",
      "dict_items([(\"Lemma('condense.v.01.condense')\", 2)])\n",
      "collecting tokens for  toll-road\n",
      "indices:    {23429, 23435, 23376, 23380, 23383, 23387, 23389, 23391}\n",
      "dict_items([])\n",
      "collecting tokens for  protested\n",
      "indices:    {10849, 20132, 10885, 35364, 5079, 20538, 32027, 16412, 36062}\n",
      "dict_items([(\"Lemma('protest.v.01.protest')\", 6), (\"Lemma('protest.v.02.protest')\", 3)])\n",
      "collecting tokens for  rail\n",
      "indices:    {23492, 34062, 33841, 18226, 10579, 8049, 14905, 29786, 5435, 18526}\n",
      "dict_items([(\"Lemma('rail.n.02.rail')\", 3), (\"Lemma('railing.n.01.rail')\", 2)])\n",
      "collecting tokens for  foreigners\n",
      "indices:    {1407, 31975, 10766, 14191, 10768, 25851, 16415}\n",
      "dict_items([(\"Lemma('foreigner.n.01.foreigner')\", 5)])\n",
      "collecting tokens for  mg.\n",
      "indices:    {4034, 4036, 4042, 4048, 4049, 4051, 4022, 4029, 4031}\n",
      "dict_items([(\"Lemma('milligram.n.01.mg')\", 9)])\n",
      "collecting tokens for  41\n",
      "indices:    {23008, 288, 20581, 264, 21808, 21777, 21169, 21617, 667}\n",
      "dict_items([])\n",
      "collecting tokens for  squad\n",
      "indices:    {225, 30945, 6627, 24937, 6570, 24940, 6540, 30958, 6677, 6582, 316, 8510}\n",
      "dict_items([(\"Lemma('squad.n.01.squad')\", 6), (\"Lemma('team.n.01.squad')\", 2)])\n",
      "collecting tokens for  downstairs\n",
      "indices:    {16673, 10020, 36328, 9674, 22538, 5744, 9011, 33401, 9403}\n",
      "dict_items([(\"Lemma('downstairs.r.01.downstairs')\", 6)])\n",
      "collecting tokens for  preparations\n",
      "indices:    {13120, 4003, 4804, 30282, 7659, 7756, 14801, 11571, 10268, 3999}\n",
      "dict_items([(\"Lemma('formulation.n.01.preparation')\", 3), (\"Lemma('preparation.n.01.preparation')\", 5), (\"Lemma('planning.n.03.preparation')\", 1)])\n",
      "collecting tokens for  dramatically\n",
      "indices:    {1504, 13862, 1064, 1544, 32846, 1563, 1436}\n",
      "dict_items([(\"Lemma('dramatically.r.01.dramatically')\", 3), (\"Lemma('dramatically.r.02.dramatically')\", 2), (\"Lemma('dramatically.r.03.dramatically')\", 1)])\n",
      "collecting tokens for  sisters\n",
      "indices:    {21474, 16011, 3595, 21552, 14480, 36369, 21467}\n",
      "dict_items([(\"Lemma('sister.n.01.sister')\", 3)])\n",
      "collecting tokens for  bloom\n",
      "indices:    {1636, 36325, 1669, 8744, 1659, 1676, 3598, 1683, 21467, 11549, 9503}\n",
      "dict_items([(\"Lemma('bloom.v.01.bloom')\", 4), (\"Lemma('bloom.n.04.bloom')\", 1), (\"Lemma('blooming.n.01.bloom')\", 2), (\"Lemma('flower.n.02.bloom')\", 1), (\"Lemma('bloom.n.03.bloom')\", 1)])\n",
      "collecting tokens for  nelson\n",
      "indices:    {13739}\n",
      "dict_items([])\n",
      "collecting tokens for  entertaining\n",
      "indices:    {1217, 26242, 21126, 22439, 967, 26505, 21130, 8267, 21143}\n",
      "dict_items([(\"Lemma('entertain.v.01.entertain')\", 4)])\n",
      "collecting tokens for  buffalo\n",
      "indices:    {334}\n",
      "dict_items([(\"Lemma('location.n.01.location')\", 1)])\n",
      "collecting tokens for  scholar\n",
      "indices:    {27521, 31177, 23117, 2317, 23183, 23184, 22705, 24764}\n",
      "dict_items([(\"Lemma('scholar.n.01.scholar')\", 1)])\n",
      "collecting tokens for  arguments\n",
      "indices:    {5600, 25444, 14350, 24949, 8249, 21531, 25436, 26814, 14431}\n",
      "dict_items([(\"Lemma('controversy.n.01.argument')\", 2), (\"Lemma('argument.n.01.argument')\", 2)])\n",
      "collecting tokens for  aided\n",
      "indices:    {11113, 25866, 33101, 35696, 23764, 12244, 1973, 20284}\n",
      "dict_items([(\"Lemma('help.v.01.aid')\", 7), (\"Lemma('help.v.02.aid')\", 1)])\n",
      "collecting tokens for  advisers\n",
      "indices:    {28419, 22828, 22640, 22353, 22737, 20153, 23283, 24658, 21401, 24668, 24158}\n",
      "dict_items([])\n",
      "collecting tokens for  concentrate\n",
      "indices:    {23081, 3948, 34606, 20273, 21236, 11351, 13400, 32985}\n",
      "dict_items([(\"Lemma('concentrate.v.02.concentrate')\", 2), (\"Lemma('concentrate.v.01.concentrate')\", 1), (\"Lemma('concentrate.v.05.concentrate')\", 1), (\"Lemma('concentrate.n.03.concentrate')\", 1), (\"Lemma('centralize.v.01.concentrate')\", 1)])\n",
      "collecting tokens for  develops\n",
      "indices:    {16131, 12101, 23527, 31915, 1550, 1011, 14071, 2713, 4221}\n",
      "dict_items([(\"Lemma('explicate.v.02.develop')\", 1), (\"Lemma('originate.v.01.develop')\", 2), (\"Lemma('develop.v.03.develop')\", 3), (\"Lemma('grow.v.08.develop')\", 1), (\"Lemma('evolve.v.01.develop')\", 1), (\"Lemma('train.v.01.develop')\", 1)])\n",
      "collecting tokens for  holidays\n",
      "indices:    {11744, 11841, 11745, 25735, 11838, 21129, 24692, 13141, 20862}\n",
      "dict_items([(\"Lemma('vacation.n.01.holiday')\", 3), (\"Lemma('holiday.n.02.holiday')\", 2)])\n",
      "collecting tokens for  violin\n",
      "indices:    {26624, 22403, 25995, 911, 26612, 918, 31608, 22201, 22203, 31613}\n",
      "dict_items([(\"Lemma('violin.n.01.violin')\", 2)])\n",
      "collecting tokens for  portions\n",
      "indices:    {5095, 31271, 11370, 3856, 3094, 2198, 20150, 27227}\n",
      "dict_items([(\"Lemma('part.n.02.portion')\", 1), (\"Lemma('part.n.01.portion')\", 4)])\n",
      "collecting tokens for  pseudo\n",
      "indices:    {1360, 14576, 15826, 14580, 14196, 2198, 14201}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('pseudo.s.01.pseudo')\", 7)])\n",
      "collecting tokens for  harvest\n",
      "indices:    {13973}\n",
      "dict_items([])\n",
      "collecting tokens for  promoted\n",
      "indices:    {10114, 1191, 15216, 11892, 15221, 10167, 33049, 28091, 31614}\n",
      "dict_items([(\"Lemma('promote.v.01.promote')\", 3), (\"Lemma('promote.v.02.promote')\", 5), (\"Lemma('advertise.v.02.promote')\", 1)])\n",
      "collecting tokens for  ditch\n",
      "indices:    {18945, 33826, 5059, 33806, 5522, 5558, 33848, 33823}\n",
      "dict_items([(\"Lemma('ditch.n.01.ditch')\", 2)])\n",
      "collecting tokens for  bow\n",
      "indices:    {30890, 21252, 9430}\n",
      "dict_items([(\"Lemma('bow.n.01.bow')\", 1), (\"Lemma('submit.v.06.bow')\", 1)])\n",
      "collecting tokens for  null\n",
      "indices:    {4289, 4290, 32099, 4292, 14822, 4328, 4298, 4366, 4371, 4314}\n",
      "dict_items([(\"Lemma('null.s.01.null')\", 1)])\n",
      "collecting tokens for  hemphill\n",
      "indices:    {20669}\n",
      "dict_items([])\n",
      "collecting tokens for  nilpotent\n",
      "indices:    {4352, 4355, 4357, 4336, 4339, 4340, 4341, 4342, 4348, 4349, 4351}\n",
      "dict_items([(\"Lemma('nilpotent.a.01.nilpotent')\", 11)])\n",
      "collecting tokens for  computer\n",
      "indices:    {34434, 15938, 14852, 34340, 34338, 11395, 15880, 34435, 15883, 15891}\n",
      "dict_items([(\"Lemma('computer.n.01.computer')\", 5)])\n",
      "collecting tokens for  frederick\n",
      "indices:    {884}\n",
      "dict_items([])\n",
      "collecting tokens for  diffusion\n",
      "indices:    {3424, 14827, 14829, 14830, 4722, 16214, 3454}\n",
      "dict_items([(\"Lemma('diffusion.n.02.diffusion')\", 1), (\"Lemma('diffusion.n.01.diffusion')\", 5), (\"Lemma('dissemination.n.02.diffusion')\", 1)])\n",
      "collecting tokens for  access\n",
      "indices:    {23424, 11618, 23524, 24452, 15012, 5422, 25167, 5424, 30545, 27154, 11766, 15292, 23935}\n",
      "dict_items([(\"Lemma('access.n.02.access')\", 2), (\"Lemma('access.n.03.access')\", 1), (\"Lemma('entree.n.02.access')\", 2)])\n",
      "collecting tokens for  mob\n",
      "indices:    {865, 12965, 9991, 6312, 6314, 21676, 30031, 9848, 12633, 9882, 21755}\n",
      "dict_items([(\"Lemma('mob.n.01.mob')\", 6), (\"Lemma('syndicate.n.01.mob')\", 1)])\n",
      "collecting tokens for  tips\n",
      "indices:    {8609, 11937, 29287, 29480, 29257, 25674, 10571, 25675, 17100, 9747, 3894, 7324}\n",
      "dict_items([(\"Lemma('tip.n.01.tip')\", 4), (\"Lemma('gratuity.n.01.tip')\", 1), (\"Lemma('tip.n.03.tip')\", 1)])\n",
      "collecting tokens for  pleasantly\n",
      "indices:    {24354, 10886, 9353, 10348, 26515, 33748, 34876, 1758, 36351}\n",
      "dict_items([(\"Lemma('pleasantly.r.02.pleasantly')\", 2), (\"Lemma('pleasantly.r.01.pleasantly')\", 2)])\n",
      "collecting tokens for  subsequently\n",
      "indices:    {3095}\n",
      "dict_items([(\"Lemma('subsequently.r.01.subsequently')\", 1)])\n",
      "collecting tokens for  turnpikes\n",
      "indices:    {23424, 23392, 23399, 23436, 23376, 23380, 23413, 23381, 23383, 23419}\n",
      "dict_items([])\n",
      "collecting tokens for  burns\n",
      "indices:    {19582, 25590}\n",
      "dict_items([(\"Lemma('burn.v.01.burn')\", 1), (\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  undertake\n",
      "indices:    {2784, 32193, 21953, 22373, 14151, 14727, 25452, 12141, 20025, 24062}\n",
      "dict_items([(\"Lemma('undertake.v.03.undertake')\", 2), (\"Lemma('undertake.v.01.undertake')\", 8)])\n",
      "collecting tokens for  stormy\n",
      "indices:    {34613}\n",
      "dict_items([])\n",
      "collecting tokens for  jimmy\n",
      "indices:    {21559}\n",
      "dict_items([])\n",
      "collecting tokens for  deduction\n",
      "indices:    {15545, 24970}\n",
      "dict_items([(\"Lemma('tax_write-off.n.01.deduction')\", 1)])\n",
      "collecting tokens for  71\n",
      "indices:    {22951, 16174, 16175, 3027, 16179, 16180, 23131, 29660, 22942, 31}\n",
      "dict_items([])\n",
      "collecting tokens for  korea\n",
      "indices:    {25858}\n",
      "dict_items([])\n",
      "collecting tokens for  novels\n",
      "indices:    {7457, 967, 25640, 14411, 26925, 13841, 14422, 2457, 19610, 14399}\n",
      "dict_items([(\"Lemma('novel.n.01.novel')\", 8)])\n",
      "collecting tokens for  jurisdiction\n",
      "indices:    {14880, 15493, 24070, 25193, 25194, 25195, 14860, 5426, 22551, 25019, 14879}\n",
      "dict_items([(\"Lemma('legal_power.n.01.jurisdiction')\", 4), (\"Lemma('jurisdiction.n.02.jurisdiction')\", 1)])\n",
      "collecting tokens for  easter\n",
      "indices:    {21129}\n",
      "dict_items([])\n",
      "collecting tokens for  refers\n",
      "indices:    {11046, 31656, 30248, 2123, 25996, 14669, 30158, 2139, 13532}\n",
      "dict_items([(\"Lemma('refer.v.02.refer')\", 4), (\"Lemma('mention.v.01.refer')\", 5)])\n",
      "collecting tokens for  noon\n",
      "indices:    {20800, 9222, 3336, 22072, 20874, 10481, 16562, 13395, 30584, 17112, 10457, 34524}\n",
      "dict_items([(\"Lemma('noon.n.01.noon')\", 7)])\n",
      "collecting tokens for  participating\n",
      "indices:    {20257, 27684, 22407, 4711, 36071, 27670, 21881, 21146}\n",
      "dict_items([(\"Lemma('participate.v.01.participate')\", 5)])\n",
      "collecting tokens for  bush\n",
      "indices:    {84}\n",
      "dict_items([(\"Lemma('person.n.01.person')\", 1)])\n",
      "collecting tokens for  closest\n",
      "indices:    {33156, 26215, 31400, 24844, 22924, 16814, 26671, 6839}\n",
      "dict_items([(\"Lemma('close.a.02.close')\", 1)])\n",
      "collecting tokens for  consulted\n",
      "indices:    {15435, 36075, 23181, 2254, 15439, 33423, 20369, 1106, 15437, 17357, 61}\n",
      "dict_items([(\"Lemma('consult.v.01.consult')\", 8), (\"Lemma('consult.v.02.consult')\", 2)])\n",
      "collecting tokens for  metropolis\n",
      "indices:    {13376, 13380, 13381, 13326, 13365, 13369, 13371, 29246}\n",
      "dict_items([(\"Lemma('city.n.01.metropolis')\", 7)])\n",
      "collecting tokens for  bronx\n",
      "indices:    {20493}\n",
      "dict_items([])\n",
      "collecting tokens for  pray\n",
      "indices:    {27360, 12549, 24326, 22373, 6440, 6444, 32241, 24275, 28371, 25270}\n",
      "dict_items([(\"Lemma('pray.v.01.pray')\", 9)])\n",
      "collecting tokens for  grasped\n",
      "indices:    {13666, 13572, 13641, 7595, 4908, 35438, 8814, 8817, 1274}\n",
      "dict_items([(\"Lemma('grasp.v.01.grasp')\", 6), (\"Lemma('grok.v.01.grasp')\", 3)])\n",
      "collecting tokens for  180\n",
      "indices:    {865, 22986, 21324, 3278, 27185, 1944, 217, 20187, 3231}\n",
      "dict_items([])\n",
      "collecting tokens for  approve\n",
      "indices:    {25312, 25186, 1002, 14417, 20211, 53, 23702, 17720, 7577}\n",
      "dict_items([(\"Lemma('approve.v.01.approve')\", 7), (\"Lemma('approve.v.02.approve')\", 2)])\n",
      "collecting tokens for  uniquely\n",
      "indices:    {32256, 22689, 28130, 4340, 4372, 32055, 3071, 4471}\n",
      "dict_items([(\"Lemma('uniquely.r.01.uniquely')\", 4)])\n",
      "collecting tokens for  sailed\n",
      "indices:    {12368, 17648, 12434, 12371, 12400, 12727, 12378, 19388, 30268}\n",
      "dict_items([(\"Lemma('sail.v.01.sail')\", 8), (\"Lemma('sail.v.03.sail')\", 1)])\n",
      "collecting tokens for  speaks\n",
      "indices:    {10811, 26093, 26201, 27440, 31090, 13814, 31769, 26202, 31163}\n",
      "dict_items([(\"Lemma('talk.v.02.speak')\", 3), (\"Lemma('speak.v.03.speak')\", 1), (\"Lemma('talk.v.01.speak')\", 4)])\n",
      "collecting tokens for  violently\n",
      "indices:    {37031, 31912, 14217, 14410, 19335, 12981, 6588, 33726}\n",
      "dict_items([(\"Lemma('violently.r.01.violently')\", 5)])\n",
      "collecting tokens for  perfection\n",
      "indices:    {672, 28226, 29480, 1930, 527, 26098, 1460, 13814, 28031}\n",
      "dict_items([(\"Lemma('perfection.n.01.perfection')\", 5)])\n",
      "collecting tokens for  flair\n",
      "indices:    {31272, 26796, 30253, 11214, 36302, 11248, 28661, 14552}\n",
      "dict_items([(\"Lemma('flair.n.01.flair')\", 2), (\"Lemma('dash.n.01.flair')\", 1)])\n",
      "collecting tokens for  comic\n",
      "indices:    {20913, 14593, 21009, 10655}\n",
      "dict_items([(\"Lemma('amusing.s.02.comic')\", 1)])\n",
      "collecting tokens for  oldest\n",
      "indices:    {33313, 24294, 31691, 23115, 28398, 24703, 19319, 4699, 30845, 26591}\n",
      "dict_items([(\"Lemma('old.a.01.old')\", 1)])\n",
      "collecting tokens for  neo\n",
      "indices:    {11250, 4215}\n",
      "dict_items([(\"Lemma('neo.s.01.neo')\", 1), (\"Lemma('neocortical.a.01.neocortical')\", 1)])\n",
      "collecting tokens for  secular\n",
      "indices:    {4715, 14095, 22704, 4721, 28115, 27763, 27768, 27770, 36604, 14078}\n",
      "dict_items([])\n",
      "collecting tokens for  acquainted\n",
      "indices:    {27616, 33156, 7629, 30703, 12143, 14002, 27641, 26142}\n",
      "dict_items([(\"Lemma('acquainted.s.01.acquainted')\", 1)])\n",
      "collecting tokens for  generalized\n",
      "indices:    {4485, 14599, 32871, 3818, 2991, 4030, 3805, 3838}\n",
      "dict_items([(\"Lemma('generalized.s.01.generalized')\", 4), (\"Lemma('generalize.v.01.generalize')\", 2)])\n",
      "collecting tokens for  decides\n",
      "indices:    {11968, 25413, 20998, 31303, 34221, 31021, 14229, 27322}\n",
      "dict_items([(\"Lemma('decide.v.01.decide')\", 8)])\n",
      "collecting tokens for  unified\n",
      "indices:    {11298, 4706, 4934, 23240, 4713, 33009, 25618, 22676, 16415}\n",
      "dict_items([(\"Lemma('incorporate.s.01.unified')\", 5), (\"Lemma('unify.v.01.unify')\", 1)])\n",
      "collecting tokens for  1943\n",
      "indices:    {14245, 22095, 3762, 14998, 14999, 30296, 15002, 30268}\n",
      "dict_items([])\n",
      "collecting tokens for  summoned\n",
      "indices:    {17829, 7336, 21194, 21963, 36914, 18229, 12661, 22870}\n",
      "dict_items([(\"Lemma('summon.v.01.summon')\", 7), (\"Lemma('summon.v.02.summon')\", 1)])\n",
      "collecting tokens for  strenuous\n",
      "indices:    {28582, 31595, 13169, 20278, 27575, 27321, 28379, 36543}\n",
      "dict_items([(\"Lemma('strenuous.s.01.strenuous')\", 1)])\n",
      "collecting tokens for  investigators\n",
      "indices:    {4003, 32900, 4011, 33068, 11502, 2895, 4240, 33198, 3506, 11413, 3998, 23167}\n",
      "dict_items([(\"Lemma('research_worker.n.01.investigator')\", 8)])\n",
      "collecting tokens for  blade\n",
      "indices:    {35198, 29766, 7369, 28747, 34096, 29904, 34100, 30648, 28318}\n",
      "dict_items([(\"Lemma('blade.n.01.blade')\", 1)])\n",
      "collecting tokens for  spinning\n",
      "indices:    {13060, 6405, 6733, 18447, 6735, 6738, 36639}\n",
      "dict_items([(\"Lemma('spin.v.02.spin')\", 3), (\"Lemma('spin.v.01.spin')\", 4)])\n",
      "collecting tokens for  leaning\n",
      "indices:    {8576, 9188, 33796, 8934, 34969}\n",
      "dict_items([(\"Lemma('lean.v.02.lean')\", 1), (\"Lemma('lean.v.01.lean')\", 2)])\n",
      "collecting tokens for  essence\n",
      "indices:    {28385, 14121, 2061, 30765, 28144, 14577, 25589, 20247, 13628}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([(\"Lemma('kernel.n.03.essence')\", 2)])\n",
      "collecting tokens for  coins\n",
      "indices:    {18949, 31945, 17581, 21616, 21618, 30709, 31898, 14719}\n",
      "dict_items([(\"Lemma('coin.n.01.coin')\", 3)])\n",
      "collecting tokens for  pursuit\n",
      "indices:    {5220, 36010, 22699, 32076, 29964, 25198, 36911, 21330, 31989, 13695}\n",
      "dict_items([(\"Lemma('pursuit.n.02.pursuit')\", 1), (\"Lemma('pursuit.n.01.pursuit')\", 1)])\n",
      "collecting tokens for  gene\n",
      "indices:    {12641}\n",
      "dict_items([])\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Now that we have our word index, we want to construct the evaluation dataset\n",
    "\n",
    "for each word in the index, we want\n",
    "\n",
    "We iterate through the words in the dictionary.\n",
    "if that word has a frequency of  > 600 or < 7, we move on.\n",
    "If it has the right frequency, we pull the indices of the sentences containing that word\n",
    "we shuffle these indices and access in random order. \n",
    "We go through the shuffled indices,\n",
    "    and we check if we have collected < 50 of this sense.\n",
    "    if not, we collect this token for the evaluation dataset\n",
    "\n",
    "collection means:\n",
    "    we construct a row of data like\n",
    "        word sense\n",
    "        word form\n",
    "        token\n",
    "        \n",
    "        \n",
    "at the end we save the data in a csv file called 'semcor_wu_palmer_eval_data.csv'\n",
    "\"\"\"\n",
    "\n",
    "def get_sense_in_tagged_sentence(word, tagged_sentence):\n",
    "    for chunk in tagged_sentence:\n",
    "\n",
    "        chunk_string = ' '.join(chunk.leaves())\n",
    "\n",
    "        \"\"\"\n",
    "        if we find the word we're looking for in this chunk,\n",
    "        and that chunk has a wordnet sense (function words dont)\n",
    "        then scoop it up\n",
    "\n",
    "        \"\"\"            \n",
    "        if chunk_string.lower() == word:\n",
    "            #print(\"found %s\" % word)\n",
    "            #print(chunk.label())\n",
    "\n",
    "            #wn_lemma = cunk.label()\n",
    "            if isinstance(chunk.label() , Lemma):\n",
    "                return chunk.label()\n",
    "    # if we get to the end of the loop. we didn't find the word we were looking for\n",
    "    return None\n",
    "\n",
    "\n",
    "def collect_tokens(word, indices, sents, tagged_sents):\n",
    "    \"\"\"\n",
    "    takes a word and a list of indices\n",
    "    returns tuples containing \n",
    "        word\n",
    "        sentence_string\n",
    "        sense\n",
    "    \"\"\"\n",
    "    sense_count = Counter()\n",
    "\n",
    "    print(\"collecting tokens for \", word)\n",
    "    print(\"indices:   \", indices)\n",
    "    tokens = []\n",
    "    \n",
    "    # indices is a list of all of the sentence ids containing this word\n",
    "    indices = list(indices)\n",
    "    # visit these sentences in random order\n",
    "    random.shuffle(indices)\n",
    "    for index in indices:\n",
    "        \n",
    "        #print(word)\n",
    "        #print(index)\n",
    "        tagged_sentence = tagged_sents[index]\n",
    "        #print(tagged_sentence)\n",
    "        sentence = sents[index]\n",
    "        #print(sentence)\n",
    "\n",
    "        sentence = ' '.join(sentence)\n",
    "        sense = get_sense_in_tagged_sentence(word, tagged_sentence)\n",
    "        #print(sense)\n",
    "        \n",
    "        if sense is None:\n",
    "            # we have a word in the sentence matching this word form but it doesnt constitute a chunk on its own;\n",
    "            # part of some MWE.\n",
    "            continue\n",
    "        \n",
    "        #print(sense.name())\n",
    "        \n",
    "        sense = str(sense)\n",
    "        if sense_count[sense] <= 25:\n",
    "            tokens.append((word, sentence, sense))\n",
    "            sense_count[sense] += 1\n",
    "    \n",
    "    print(sense_count.items())\n",
    "    return tokens, sense_count\n",
    "\n",
    "\n",
    "def collect_tokens_for_all_words_to_file(path, sense_path, word_index, semcor_lexicon, sents, tagged_sents):\n",
    "    with open(path, 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "\n",
    "        with open(sense_path, 'w', newline='') as sensefile:\n",
    "            sensewriter = csv.writer(sensefile)\n",
    "        \n",
    "            for word, indices in word_index.items():\n",
    "                #print(word)\n",
    "                #print(indices)\n",
    "\n",
    "                frequency = semcor_lexicon[word]\n",
    "                if frequency < 600 and frequency > 7:\n",
    "                    rows, sense_count = collect_tokens(word, indices, sents, tagged_sents)\n",
    "\n",
    "                    writer.writerows(rows)                    \n",
    "                    sensewriter.writerow(sense_count.items())\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# DEBUG TEST\n",
    "#collect_tokens('heart', word_index['heart'], sents, tagged_sents)\n",
    "\n",
    "collect_tokens_for_all_words_to_file('semcor_wu_palmer_eval_data.csv', 'semcor_sense_counts.csv', word_index, semcor_lexicon, sents, tagged_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37176\n",
      "37176\n",
      "38642\n",
      "38642\n"
     ]
    }
   ],
   "source": [
    "print(len(sents))\n",
    "print(len(tagged_sents))\n",
    "print(len(word_index))\n",
    "print(len(semcor_lexicon))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "models and save paths\n",
    "\n",
    "\"\"\"\n",
    "models = [\n",
    "    'trained_models/model.plsr.buchanan.allbuthomoyms.5k.300components.500max_iters',\n",
    "    'trained_models/model.plsr.buchanan.allbuthomoyms.1k.300components.500max_iters',\n",
    "    #'trained_models/model.plsr.buchanan.allbuthomoyms.glove.300components.300max_iters',\n",
    "    'trained_models/model.ffnn.buchanan.allbuthomoyms.5k.50epochs.0.5dropout.lr1e-4.hsize300',\n",
    "    'trained_models/model.ffnn.buchanan.allbuthomoyms.1k.50epochs.0.5dropout.lr1e-4.hsize300',\n",
    "    #'trained_models/model.ffnn.buchanan.allbuthomoyms.glove.50epochs.0.5dropout.lr1e-4.hsize300',\n",
    "    'trained_models/model.modabs.buchanan.allbuthomoyms.5k',\n",
    "    'trained_models/model.modabs.buchanan.allbuthomoyms.1k',\n",
    "    #'trained_models/model.modabs.buchanan.allbuthomoyms.glove'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************\n",
      "*** Evaluating trained_models/model.plsr.buchanan.allbuthomoyms.5k.300components.500max_iters model ***\n",
      "****************************************\n",
      "processed 0 words\n",
      "processed 500 words\n",
      "processed 1000 words\n",
      "processed 1500 words\n",
      "processed 2000 words\n",
      "processed 2500 words\n",
      "processed 3000 words\n",
      "processed 3500 words\n",
      "processed 4000 words\n",
      "processed 4500 words\n",
      "processed 5000 words\n",
      "processed 5500 words\n",
      "processed 6000 words\n",
      "****************************************\n",
      "*** Evaluating trained_models/model.plsr.buchanan.allbuthomoyms.1k.300components.500max_iters model ***\n",
      "****************************************\n",
      "processed 0 words\n",
      "processed 500 words\n",
      "processed 1000 words\n",
      "processed 1500 words\n",
      "processed 2000 words\n",
      "processed 2500 words\n",
      "processed 3000 words\n",
      "processed 3500 words\n",
      "processed 4000 words\n",
      "processed 4500 words\n",
      "processed 5000 words\n",
      "processed 5500 words\n",
      "processed 6000 words\n",
      "****************************************\n",
      "*** Evaluating trained_models/model.ffnn.buchanan.allbuthomoyms.5k.50epochs.0.5dropout.lr1e-4.hsize300 model ***\n",
      "****************************************\n",
      "processed 0 words\n",
      "processed 500 words\n",
      "processed 1000 words\n",
      "processed 1500 words\n",
      "processed 2000 words\n",
      "processed 2500 words\n",
      "processed 3000 words\n",
      "processed 3500 words\n",
      "processed 4000 words\n",
      "processed 4500 words\n",
      "processed 5000 words\n",
      "processed 5500 words\n",
      "processed 6000 words\n",
      "****************************************\n",
      "*** Evaluating trained_models/model.ffnn.buchanan.allbuthomoyms.1k.50epochs.0.5dropout.lr1e-4.hsize300 model ***\n",
      "****************************************\n",
      "processed 0 words\n",
      "processed 500 words\n",
      "processed 1000 words\n",
      "processed 1500 words\n",
      "processed 2000 words\n",
      "processed 2500 words\n",
      "processed 3000 words\n",
      "processed 3500 words\n",
      "processed 4000 words\n",
      "processed 4500 words\n",
      "processed 5000 words\n",
      "processed 5500 words\n",
      "processed 6000 words\n",
      "****************************************\n",
      "*** Evaluating trained_models/model.modabs.buchanan.allbuthomoyms.5k model ***\n",
      "****************************************\n",
      "processed 0 words\n",
      "processed 500 words\n",
      "processed 1000 words\n",
      "processed 1500 words\n",
      "processed 2000 words\n",
      "processed 2500 words\n",
      "processed 3000 words\n",
      "processed 3500 words\n",
      "processed 4000 words\n",
      "processed 4500 words\n",
      "processed 5000 words\n",
      "processed 5500 words\n",
      "processed 6000 words\n",
      "****************************************\n",
      "*** Evaluating trained_models/model.modabs.buchanan.allbuthomoyms.1k model ***\n",
      "****************************************\n",
      "processed 0 words\n",
      "processed 500 words\n",
      "processed 1000 words\n",
      "processed 1500 words\n",
      "processed 2000 words\n",
      "processed 2500 words\n",
      "processed 3000 words\n",
      "processed 3500 words\n",
      "processed 4000 words\n",
      "processed 4500 words\n",
      "processed 5000 words\n",
      "processed 5500 words\n",
      "processed 6000 words\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Now, we have our dataset that we want to analyze. We just need to do:\n",
    "\n",
    "for each model we want to evaluate, run the following script:\n",
    "\n",
    "open the file of data\n",
    "\n",
    "read it in as a dataframe\n",
    "\n",
    "for each of the unique words in that dataset\n",
    "\n",
    "    we calculate pairwise distances between each otoken and every otehr token\n",
    "    and construct a similarities dataset. \n",
    "    \n",
    "    then we run correlations for that word???\n",
    "    and store into a file\n",
    "\"\"\"\n",
    "\n",
    "def lemma_from_string(lemma_string):\n",
    "    # grabs everything in between (' ') in a string\n",
    "    # (needed to update from r\"'(.*?)'\" to deal with cases with quotes in word like o'clock)\n",
    "    string = re.findall(r\"\\('(.*?)'\\)\", lemma_string)[0]\n",
    "    #print(string)\n",
    "    lemma = wn.lemma(string)\n",
    "    return lemma\n",
    "\n",
    "def make_predictions(df, model, bert):\n",
    "    predictions = []\n",
    "    for index, row in df.iterrows():\n",
    "\n",
    "        #print(row.word_form)\n",
    "        #print(row.context)\n",
    "\n",
    "        predicted_vector = model.predict_in_context(row.word_form, row.context, bert)\n",
    "\n",
    "        predictions.append(predicted_vector)\n",
    "    return predictions\n",
    "\n",
    "def get_pairwise_wu_palmer_data(model, df, bert, outfile):\n",
    "    unique_words = df.word_form.unique()\n",
    "    \n",
    "    #run_stats = [0] * len(unique_words)\n",
    "    run_stats = []\n",
    "\n",
    "    for i in range(0, len(unique_words)):\n",
    "        if i % 500 == 0:\n",
    "            print(\"processed %s words\" % i)\n",
    "        \n",
    "        # a dataframe containing all the tokens of this word\n",
    "        word = unique_words[i]\n",
    "        word_data = df[df.word_form == word].copy()\n",
    "\n",
    "        n_senses = len(word_data['wn_lemma'].unique())\n",
    "\n",
    "        predictions = make_predictions(word_data, model, bert)\n",
    "        \n",
    "        word_data['prediction'] = predictions\n",
    "        \n",
    "        #print(word_data)\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        then we calculate the pairwise distances between all of the vectors, only counting one pair one time\n",
    "\n",
    "        \"\"\"\n",
    "        vals_for_this_word = []\n",
    "#         cosines_for_this_word = []\n",
    "#         wup_sims_for_this_word = []\n",
    "#         sense_1 = []\n",
    "#         sense_2 = []\n",
    "\n",
    "        # pop the first token off the list\n",
    "        num_toks = len(word_data)\n",
    "        for i in range(0,num_toks):\n",
    "            # compare it with each of the other tokens\n",
    "            # dont have to compare to any earlier\n",
    "            for j in range(i+1,num_toks):\n",
    "\n",
    "                #print(df.iloc[i])\n",
    "                #print(df.iloc[j])\n",
    "\n",
    "                # calculate cosine similarity between the two vectors\n",
    "                cos_sim = 1 - cosine(word_data.iloc[i].prediction, word_data.iloc[j].prediction)\n",
    "\n",
    "                # and wu palmer similarity between the two wn lemmas\n",
    "                lemma_1 = lemma_from_string(word_data.iloc[i].wn_lemma)\n",
    "                lemma_2 = lemma_from_string(word_data.iloc[j].wn_lemma)\n",
    "                synset1 = lemma_1.synset()\n",
    "                synset2 = lemma_2.synset()\n",
    "                wup_sim = synset1.wup_similarity(synset2)\n",
    "\n",
    "                # if we can't compute a distance for these senses / recognize them, discard\n",
    "                if type(wup_sim) == float:\n",
    "                    # store this data point into a list\n",
    "                    vals_for_this_word.append((word, lemma_1, lemma_2, cos_sim, wup_sim))\n",
    "        \n",
    "        \n",
    "        token_similarities = pd.DataFrame.from_records(vals_for_this_word, columns = [\"lemma\", \"token_sense_1\", \"token_sense_2\", \"cos_sim\", \"wup_sim\"])\n",
    "        token_similarities['n_senses'] = n_senses\n",
    "        \n",
    "        #print(token_similarities)\n",
    "        token_similarities.to_csv(outfile, mode='a', header=False)\n",
    "        \n",
    "        \n",
    "        # run correlation on this word\n",
    "#         if sense_similarities is not None:\n",
    "#             n = len(word_data)\n",
    "#             n_senses = len(word_data['wn_lemma'].unique())\n",
    "#             #print(word)\n",
    "#             #print(n)\n",
    "#             #print(sense_similarities)\n",
    "#             pearson, pearson_p, spearman, spearman_p = run_correlation(sense_similarities)\n",
    "#             # store the values for this word into a dataframe\n",
    "#             #run_stats[i] = (word, n, pearson, pearson_p, spearman, spearman_p)\n",
    "#             run_stats.append((word, n, n_senses, pearson, pearson_p, spearman, spearman_p))\n",
    "\n",
    "    #res = pd.DataFrame.from_records(run_stats, columns = [\"word\", \"n\", \"n_senses\", \"pearson\", \"pearson_p\", \"spearman\", \"spearman_p\"])\n",
    "    return None\n",
    "\n",
    "    #print(all_sense_similarities)\n",
    "    #return all_sense_similarities\n",
    "        \n",
    "        \n",
    "def run_correlation(sense_similarities):\n",
    "    \"\"\"\n",
    "    :sense_similarities: dataframe with columns\n",
    "        cosine_sims \n",
    "        wup_sims\n",
    "    \"\"\"\n",
    "    if sense_similarities is None:\n",
    "        # not really sure why we're getting none values here it should be impossible\n",
    "        return (float(\"nan\"), float(\"nan\"), float(\"nan\"), float(\"nan\"))\n",
    "    elif len(sense_similarities['wup_sim'].unique()) == 1:\n",
    "        # the correlation will be garbage with a constant y value; skip to avoid warnings\n",
    "        return (float(\"nan\"), float(\"nan\"), float(\"nan\"), float(\"nan\"))\n",
    "\n",
    "    if len(sense_similarities) > 1 :\n",
    "        #print(word)\n",
    "\n",
    "        cos_sims = sense_similarities['cos_sim']\n",
    "        wup_sims = sense_similarities['wup_sim']\n",
    "\n",
    "        pearson, pearson_p = pearsonr(cos_sims, wup_sims )\n",
    "        #print('Pearsons correlation: %.3f, p-value: %s'  % (pearson, pearson_p))\n",
    "\n",
    "        spearman, spearman_p = spearmanr(cos_sims, wup_sims )\n",
    "        #print('Spearmans correlation: %.3f, p-value: %s'  % (spearman, spearman_p))\n",
    "\n",
    "        return (pearson, pearson_p, spearman, spearman_p)\n",
    "    return (float(\"nan\"), float(\"nan\"), float(\"nan\"), float(\"nan\"))\n",
    "\n",
    "def plot_sims():\n",
    "    cos_sims = sense_similarities['cos_sim']\n",
    "    wup_sims = sense_similarities['wup_sim']\n",
    "    plt.scatter(wup_sims, cos_sims)\n",
    "    plt.title(\"Wordnet similarity of homonymous senses plotted against cosine similarity of predicted vectors of two tokens in semantic feature space\")\n",
    "    plt.xlabel(\"Wu and Palmer Similarity\")\n",
    "    plt.ylabel(\"Cosine Similarity\")\n",
    "    plt.show()\n",
    "        \n",
    "\n",
    "df = pd.read_csv('semcor_wu_palmer_eval_data.csv', names = [\"word_form\", \"context\", \"wn_lemma\"])\n",
    "\n",
    "\n",
    "\n",
    "for save_path in models:\n",
    "    print(\"****************************************\")\n",
    "    print(\"*** Evaluating %s model ***\" % save_path)\n",
    "    print(\"****************************************\")\n",
    "    model = torch.load(save_path)\n",
    "    out_path = 'results/semcor_pairwise_data_' + os.path.split(save_path)[1] + '.csv'\n",
    "\n",
    "    # remove results file if exists\n",
    "    if os.path.exists(out_path):\n",
    "        os.remove(out_path)\n",
    "    get_pairwise_wu_palmer_data(model, df, bert, out_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Conc.M</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>roadsweeper</th>\n",
       "      <td>4.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>traindriver</th>\n",
       "      <td>4.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tush</th>\n",
       "      <td>4.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hairdress</th>\n",
       "      <td>3.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pharmaceutics</th>\n",
       "      <td>3.77</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Conc.M\n",
       "Word                 \n",
       "roadsweeper      4.85\n",
       "traindriver      4.54\n",
       "tush             4.45\n",
       "hairdress        3.93\n",
       "pharmaceutics    3.77"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brysbaert_filename = \"/Users/gabriellachronis/data/Concreteness_ratings_Brysbaert_et_al_BRM.csv\"\n",
    "concreteness_df = pd.read_csv(brysbaert_filename, sep='\\t')\n",
    "concreteness_df= concreteness_df[[\"Word\", \"Conc.M\"]]\n",
    "concreteness_df = concreteness_df.set_index(\"Word\")\n",
    "concreteness_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************\n",
      "*** Saturating pairwise data for model: trained_models/model.plsr.buchanan.allbuthomoyms.5k.300components.500max_iters ***\n",
      "****************************************\n",
      "          lemma                          token_sense_1  \\\n",
      "0  performances  Lemma('performance.n.02.performance')   \n",
      "1  performances  Lemma('performance.n.02.performance')   \n",
      "2  performances  Lemma('performance.n.02.performance')   \n",
      "3  performances  Lemma('performance.n.02.performance')   \n",
      "4  performances  Lemma('performance.n.02.performance')   \n",
      "\n",
      "                           token_sense_2   cos_sim   wup_sim  n_senses  \\\n",
      "0  Lemma('performance.n.03.performance')  0.364395  0.555556         3   \n",
      "1  Lemma('performance.n.01.performance')  0.755421  0.444444         3   \n",
      "2  Lemma('performance.n.02.performance')  0.793253  1.000000         3   \n",
      "3  Lemma('performance.n.01.performance')  0.698643  0.444444         3   \n",
      "4  Lemma('performance.n.02.performance')  0.749393  1.000000         3   \n",
      "\n",
      "   wn_bin sense1_pos  Conc.M  conc_bin  \n",
      "0       1          n     NaN       NaN  \n",
      "1       1          n     NaN       NaN  \n",
      "2       1          n     NaN       NaN  \n",
      "3       1          n     NaN       NaN  \n",
      "4       1          n     NaN       NaN  \n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "dewfieow",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-129-152c612f2058>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;31m#csv_input.to_csv(outfile, index=False)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dewfieow\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mException\u001b[0m: dewfieow"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Now we need to go in and add abstractness value and \n",
    "bin number of senses into polysemy band\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "cols = [\"lemma\", \"token_sense_1\", \"token_sense_2\", \"cos_sim\", \"wup_sim\", \"n_senses\"]\n",
    "\n",
    "for save_path in models:\n",
    "    print(\"****************************************\")\n",
    "    print(\"*** Saturating pairwise data for model: %s ***\" % save_path)\n",
    "    print(\"****************************************\")\n",
    "    infile = 'results/semcor_pairwise_data_' + os.path.split(save_path)[1] + '.csv'\n",
    "\n",
    "    outfile = 'results/saturated_semcor_pairwise_data_' + os.path.split(save_path)[1] + '.csv'\n",
    "\n",
    "    csv_input = pd.read_csv(infile, names=cols)\n",
    "    \n",
    "    csv_input['wn_bin'] = pd.cut(csv_input.n_senses, \n",
    "                        bins = [0, 2.1, 4.1, 6.1, 8.1, 10.1, 20.1, 50.1, 200], labels = False)\n",
    "\n",
    "    # add POS rows\n",
    "    pos1s = []\n",
    "    pos2s = []\n",
    "    for index, row in csv_input.iterrows():\n",
    "        pos1 = re.findall(r\"\\.(.*?)\\.\", row.token_sense_1)[0]\n",
    "        pos2 = re.findall(r\"\\.(.*?)\\.\", row.token_sense_2)[0]\n",
    "        pos1s.append(pos1)\n",
    "        pos2s.append(pos2)\n",
    "    \n",
    "    csv_input['sense1_pos'] = pos1s\n",
    "    csv_input['sense2_pos'] = pos2s\n",
    "    \n",
    "    # add concreteness\n",
    "    csv_input = csv_input.join(concreteness_df, how = \"left\", on = \"lemma\")\n",
    "    \n",
    "    csv_input['conc_bin'] = pd.cut(csv_input['Conc.M'], \n",
    "                        bins = [0, 2.3, 4.5, 10], labels = False)\n",
    "    \n",
    "    # remove token sense columns\n",
    "    csv_input.drop(['token_sense_1'], axis=1)\n",
    "    csv_input.drop(['token_sense_2'], axis=1)\n",
    "    \n",
    "    #print(csv_input.where(csv_input['Conc.M'].notnull()))\n",
    "    print(csv_input.head())\n",
    "    #csv_input.to_csv(outfile, index=False)\n",
    "    \n",
    "    raise Exception(\"dewfieow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lemma('performance.n.02.performance')"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemma_from_string(csv_input.iloc[0].token_sense_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
